{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOy1lrpe0cIB0HcuND8trF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5d12ff2c6a9e43e795b2d5fa9b39ec1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85b6ab180ed34cf28c7f832c929677ae",
              "IPY_MODEL_d75303f81bae4822a2f4905f16fa39a4",
              "IPY_MODEL_736b5b6f5a774d9ea16a5b9f734120bc"
            ],
            "layout": "IPY_MODEL_a2119b76098042f984a9b17a492476ca"
          }
        },
        "85b6ab180ed34cf28c7f832c929677ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eca30074e63d4c14b16c598138265ad7",
            "placeholder": "​",
            "style": "IPY_MODEL_dcaf5935469c491dba454de3c30190cf",
            "value": "modules.json: 100%"
          }
        },
        "d75303f81bae4822a2f4905f16fa39a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85e27a322dd5420a84125fbdf1b990fb",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_038aed1f48b74b948b024eef10985b0d",
            "value": 349
          }
        },
        "736b5b6f5a774d9ea16a5b9f734120bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_908c961d6dc1453f8a1b08a5f3f884cd",
            "placeholder": "​",
            "style": "IPY_MODEL_19ef46162f594764b017b91888d8e945",
            "value": " 349/349 [00:00&lt;00:00, 5.76kB/s]"
          }
        },
        "a2119b76098042f984a9b17a492476ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eca30074e63d4c14b16c598138265ad7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcaf5935469c491dba454de3c30190cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85e27a322dd5420a84125fbdf1b990fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "038aed1f48b74b948b024eef10985b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "908c961d6dc1453f8a1b08a5f3f884cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19ef46162f594764b017b91888d8e945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15070fcef87a4b328e38662ea0cb6ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03ec9add99734690a777bc157f91ede9",
              "IPY_MODEL_52d43372a5274c32b831288c63bf08be",
              "IPY_MODEL_7af0c7277af7455e80b05ba6f9dad42e"
            ],
            "layout": "IPY_MODEL_de596fa468a5449bb3c5eab1668d1d1e"
          }
        },
        "03ec9add99734690a777bc157f91ede9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b707c085167f4107bbe45b736aa2c036",
            "placeholder": "​",
            "style": "IPY_MODEL_e5b8939f7d2942338b7dc011e275d062",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "52d43372a5274c32b831288c63bf08be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2691def85a940b4a9a6df6447a62d4e",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcec439cc5894c39ac917033182d10aa",
            "value": 116
          }
        },
        "7af0c7277af7455e80b05ba6f9dad42e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9865dcccb0246c4ab7a852af516a80c",
            "placeholder": "​",
            "style": "IPY_MODEL_ee04b141710a4155bca570e06ef5175c",
            "value": " 116/116 [00:00&lt;00:00, 8.80kB/s]"
          }
        },
        "de596fa468a5449bb3c5eab1668d1d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b707c085167f4107bbe45b736aa2c036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5b8939f7d2942338b7dc011e275d062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2691def85a940b4a9a6df6447a62d4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcec439cc5894c39ac917033182d10aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9865dcccb0246c4ab7a852af516a80c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee04b141710a4155bca570e06ef5175c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbdae9fae1734b9dbc91703f85d88a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36d713d77dd74675bf0f5e1fa4ec9f80",
              "IPY_MODEL_f94996fb025046b680181108a6ccae3b",
              "IPY_MODEL_f97c6ffa6f294cbd8cb2c44f21f64537"
            ],
            "layout": "IPY_MODEL_9c21a02730ba4c19aa4fb89e3fe5fe3c"
          }
        },
        "36d713d77dd74675bf0f5e1fa4ec9f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2a83400aa6643ab8bbbbfb4e34d0e0e",
            "placeholder": "​",
            "style": "IPY_MODEL_7e00a1423e39449391d081a4e9192a4e",
            "value": "README.md: "
          }
        },
        "f94996fb025046b680181108a6ccae3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a3bf6dedac541ca905478006ee7378c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a307508177784465aa4b5028d4696876",
            "value": 1
          }
        },
        "f97c6ffa6f294cbd8cb2c44f21f64537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_512f37d2e10244fdb89c0520b2126c54",
            "placeholder": "​",
            "style": "IPY_MODEL_acd7d19bf2204d83ae8fd77b74d79268",
            "value": " 10.5k/? [00:00&lt;00:00, 582kB/s]"
          }
        },
        "9c21a02730ba4c19aa4fb89e3fe5fe3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2a83400aa6643ab8bbbbfb4e34d0e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e00a1423e39449391d081a4e9192a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a3bf6dedac541ca905478006ee7378c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a307508177784465aa4b5028d4696876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "512f37d2e10244fdb89c0520b2126c54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acd7d19bf2204d83ae8fd77b74d79268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dd424a9a97b4df1ba11836b30751100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b7b57bfb8d84ceba8d7176b82fae5a9",
              "IPY_MODEL_555fe4d137cd4ef3b2fdf8949b931d26",
              "IPY_MODEL_05f3103539844f6f932cde7221005546"
            ],
            "layout": "IPY_MODEL_b8e50fcf31f7443bbcdd80b2e1bfc88b"
          }
        },
        "2b7b57bfb8d84ceba8d7176b82fae5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ce64650708a4508b42c1cff11460b84",
            "placeholder": "​",
            "style": "IPY_MODEL_ac8f19ce088d46cb987b0a24623f8e9c",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "555fe4d137cd4ef3b2fdf8949b931d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9791e33c671545a3906858f47ecd347e",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3029b0217cfb48bdafa781908d242fb8",
            "value": 53
          }
        },
        "05f3103539844f6f932cde7221005546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5cdd396a5d147c696d6ed153696d27f",
            "placeholder": "​",
            "style": "IPY_MODEL_129ea6797a4043189cfaa998572ed9fc",
            "value": " 53.0/53.0 [00:00&lt;00:00, 1.14kB/s]"
          }
        },
        "b8e50fcf31f7443bbcdd80b2e1bfc88b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ce64650708a4508b42c1cff11460b84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac8f19ce088d46cb987b0a24623f8e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9791e33c671545a3906858f47ecd347e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3029b0217cfb48bdafa781908d242fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5cdd396a5d147c696d6ed153696d27f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "129ea6797a4043189cfaa998572ed9fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83b51d613f6c48d6b5191c050865a132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c235392a6b5440997b3fdea6feb2bf8",
              "IPY_MODEL_33b1434e2de94a58907674f4fa1237ae",
              "IPY_MODEL_21a1d95091454037832aeb30235b439d"
            ],
            "layout": "IPY_MODEL_e6200c99d3694788a0af04cb5c8b7477"
          }
        },
        "2c235392a6b5440997b3fdea6feb2bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ad5f69120be4dd687a92bf776b519ab",
            "placeholder": "​",
            "style": "IPY_MODEL_f3dd7a53a8c348018ccad5d707d17057",
            "value": "config.json: 100%"
          }
        },
        "33b1434e2de94a58907674f4fa1237ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa2069b88d874ffdb0c1c0bede3a6713",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aef15b74d3aa4374938f13bd03fda9a1",
            "value": 612
          }
        },
        "21a1d95091454037832aeb30235b439d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abe39049655a4fec86164437fa4e89b1",
            "placeholder": "​",
            "style": "IPY_MODEL_e05de0a631aa411c80c7272e631dcd5c",
            "value": " 612/612 [00:00&lt;00:00, 7.83kB/s]"
          }
        },
        "e6200c99d3694788a0af04cb5c8b7477": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ad5f69120be4dd687a92bf776b519ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3dd7a53a8c348018ccad5d707d17057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa2069b88d874ffdb0c1c0bede3a6713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aef15b74d3aa4374938f13bd03fda9a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abe39049655a4fec86164437fa4e89b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e05de0a631aa411c80c7272e631dcd5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4487e2b9e704c68908ce2cee2711822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f35c67ca912e4729a228b48e88b89934",
              "IPY_MODEL_496003d8161a4188b35cb3998ad092f7",
              "IPY_MODEL_d6a949fd8c98429cb44fedcae615b386"
            ],
            "layout": "IPY_MODEL_3efc44491151457eaaa4630b030f752c"
          }
        },
        "f35c67ca912e4729a228b48e88b89934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a233c051baa04092a0f53578b32156fb",
            "placeholder": "​",
            "style": "IPY_MODEL_804164cf17634537a67c4039609b932f",
            "value": "model.safetensors: 100%"
          }
        },
        "496003d8161a4188b35cb3998ad092f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bf4398ea76c40e9854bf34463fba8ee",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7828c0c759c4f78872c32976df86507",
            "value": 90868376
          }
        },
        "d6a949fd8c98429cb44fedcae615b386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0bf0ef61ec645af8059e0a51ecc0913",
            "placeholder": "​",
            "style": "IPY_MODEL_ade7aaa511a34626b0468f852c38eeea",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 129MB/s]"
          }
        },
        "3efc44491151457eaaa4630b030f752c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a233c051baa04092a0f53578b32156fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "804164cf17634537a67c4039609b932f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bf4398ea76c40e9854bf34463fba8ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7828c0c759c4f78872c32976df86507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0bf0ef61ec645af8059e0a51ecc0913": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ade7aaa511a34626b0468f852c38eeea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c682d54ed1144b6faaef92484c21d0a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e4516fd26f14c2da43c5e908f52d8f5",
              "IPY_MODEL_b6699227c51342d08dd9b85cb886b171",
              "IPY_MODEL_d3513b2cb5ff4514991aa30f4a8f3f31"
            ],
            "layout": "IPY_MODEL_02f5a56b5a944633aed50d5d82b518a3"
          }
        },
        "6e4516fd26f14c2da43c5e908f52d8f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a92a57b90c554bcaa5465578381bded3",
            "placeholder": "​",
            "style": "IPY_MODEL_4375ba8b644d4ef991617f8947273546",
            "value": "Loading weights: 100%"
          }
        },
        "b6699227c51342d08dd9b85cb886b171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28348b6b98c346789edbd62eb020c148",
            "max": 103,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06c5a3d212344dd69b0ee58d70dbcac4",
            "value": 103
          }
        },
        "d3513b2cb5ff4514991aa30f4a8f3f31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea6246c14763490d9671f32d0354f970",
            "placeholder": "​",
            "style": "IPY_MODEL_e0f0cedeba58456785204b4eff6100b2",
            "value": " 103/103 [00:00&lt;00:00, 391.85it/s, Materializing param=pooler.dense.weight]"
          }
        },
        "02f5a56b5a944633aed50d5d82b518a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a92a57b90c554bcaa5465578381bded3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4375ba8b644d4ef991617f8947273546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28348b6b98c346789edbd62eb020c148": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06c5a3d212344dd69b0ee58d70dbcac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea6246c14763490d9671f32d0354f970": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0f0cedeba58456785204b4eff6100b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c54cadd70a24beabd2acb048fc970c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7e1dce0cd3e43ed9dacf7468c7e9b46",
              "IPY_MODEL_25b77992ebf247e682172df2567aef71",
              "IPY_MODEL_2ccf9b6bd74e441984aad0e82bec4c5c"
            ],
            "layout": "IPY_MODEL_c8c492ca13c84b159438106a66d4b092"
          }
        },
        "e7e1dce0cd3e43ed9dacf7468c7e9b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd704bfa269c43ee808ecf911b5b6e0a",
            "placeholder": "​",
            "style": "IPY_MODEL_71812c830ec24d1e8d3028eee78694c8",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "25b77992ebf247e682172df2567aef71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd8e18f48fab49feafe602beb919aec9",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c11f2d66218f4e7eb3df6db37f7f94fd",
            "value": 350
          }
        },
        "2ccf9b6bd74e441984aad0e82bec4c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b52a7872560482695c929ddf889d3d8",
            "placeholder": "​",
            "style": "IPY_MODEL_969d5c6a4d694999989bc17003c5f7dd",
            "value": " 350/350 [00:00&lt;00:00, 10.6kB/s]"
          }
        },
        "c8c492ca13c84b159438106a66d4b092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd704bfa269c43ee808ecf911b5b6e0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71812c830ec24d1e8d3028eee78694c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd8e18f48fab49feafe602beb919aec9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c11f2d66218f4e7eb3df6db37f7f94fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b52a7872560482695c929ddf889d3d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "969d5c6a4d694999989bc17003c5f7dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ee901c530cc4a0bb3f0f8b78c947f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d1c387e6dc246cfae29ce88be761c32",
              "IPY_MODEL_805a3495d8af46788e9b692651508e2c",
              "IPY_MODEL_57991fa73ce949198a8af3cbf9cac34b"
            ],
            "layout": "IPY_MODEL_e211fd99961245b5997665d7b1f57b77"
          }
        },
        "7d1c387e6dc246cfae29ce88be761c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7529beebedc4372af65d04a32f0d6cf",
            "placeholder": "​",
            "style": "IPY_MODEL_7cbf74340b8b428fafa46135c68f98f0",
            "value": "vocab.txt: "
          }
        },
        "805a3495d8af46788e9b692651508e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_644e4e732cfd4448aa5d9eb527f5ac08",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71ad05d3a64d4e37b347869ac90b25c3",
            "value": 1
          }
        },
        "57991fa73ce949198a8af3cbf9cac34b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3d0ae1a5152438e82e5294b584f2c33",
            "placeholder": "​",
            "style": "IPY_MODEL_31f017a09add4373a58e024090358fc8",
            "value": " 232k/? [00:00&lt;00:00, 5.52MB/s]"
          }
        },
        "e211fd99961245b5997665d7b1f57b77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7529beebedc4372af65d04a32f0d6cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cbf74340b8b428fafa46135c68f98f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "644e4e732cfd4448aa5d9eb527f5ac08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "71ad05d3a64d4e37b347869ac90b25c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3d0ae1a5152438e82e5294b584f2c33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31f017a09add4373a58e024090358fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a7047c35b0648bebb3e1446156a5134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4543f887df544272b6831fc1ffecbea6",
              "IPY_MODEL_0539916615e14eea837e9b70487e77d0",
              "IPY_MODEL_0bbccf87b8c94cfdb5d602dba73fa536"
            ],
            "layout": "IPY_MODEL_6820e262772c4b539008b79b31ccb38c"
          }
        },
        "4543f887df544272b6831fc1ffecbea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61d64cb7741048b0885167fc28adc9e6",
            "placeholder": "​",
            "style": "IPY_MODEL_64cfcc2e378549aba5abbe9e47769ce2",
            "value": "tokenizer.json: "
          }
        },
        "0539916615e14eea837e9b70487e77d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_348c3eb263664464a3e66eb5b8b00ce1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa0daa80cee641048d80c90d2de28ca3",
            "value": 1
          }
        },
        "0bbccf87b8c94cfdb5d602dba73fa536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2166a41190e342ff80d7ed65c09e1e1a",
            "placeholder": "​",
            "style": "IPY_MODEL_a86ac762603541b39d54c82d28e08f99",
            "value": " 466k/? [00:00&lt;00:00, 15.3MB/s]"
          }
        },
        "6820e262772c4b539008b79b31ccb38c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61d64cb7741048b0885167fc28adc9e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64cfcc2e378549aba5abbe9e47769ce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "348c3eb263664464a3e66eb5b8b00ce1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "aa0daa80cee641048d80c90d2de28ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2166a41190e342ff80d7ed65c09e1e1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a86ac762603541b39d54c82d28e08f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55316840b7174199b8ad75a64d80f794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b37bdf2a0f254b068234c0739c6017d9",
              "IPY_MODEL_ba20d46f594641bcac6027c0cc643a24",
              "IPY_MODEL_841910e93e6142cbafeb64ff95fe5f6e"
            ],
            "layout": "IPY_MODEL_90b27b30fd684d7da7b58d0dbb1b94fb"
          }
        },
        "b37bdf2a0f254b068234c0739c6017d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f77723abe2bd46b08dca858dc3185370",
            "placeholder": "​",
            "style": "IPY_MODEL_8053fe4a369f4d218c67513042f5a676",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "ba20d46f594641bcac6027c0cc643a24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e329fd4471a64e60b39df88cb1862250",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88b2804de7f049fbae418fb721a27aed",
            "value": 112
          }
        },
        "841910e93e6142cbafeb64ff95fe5f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1698e7446a614f6cad9ce1b467d23f39",
            "placeholder": "​",
            "style": "IPY_MODEL_6927bc77e3734b0581ed1be81e16d8f6",
            "value": " 112/112 [00:00&lt;00:00, 8.09kB/s]"
          }
        },
        "90b27b30fd684d7da7b58d0dbb1b94fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f77723abe2bd46b08dca858dc3185370": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8053fe4a369f4d218c67513042f5a676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e329fd4471a64e60b39df88cb1862250": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88b2804de7f049fbae418fb721a27aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1698e7446a614f6cad9ce1b467d23f39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6927bc77e3734b0581ed1be81e16d8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7511a42e18ed4992994cf19a3bfd382b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5aa1cb6fea454dda955765098e398a71",
              "IPY_MODEL_18914457124a40929fe52e1a6a67a216",
              "IPY_MODEL_a7127d2d7f4d409a870ccaa2e313011b"
            ],
            "layout": "IPY_MODEL_4a8ff325c3fa4e9898d0f65957e5f1f3"
          }
        },
        "5aa1cb6fea454dda955765098e398a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c0898baf1974001bd92c0bdb0fd5d9e",
            "placeholder": "​",
            "style": "IPY_MODEL_fc83ea9753564da0ae18424f843a0ce5",
            "value": "config.json: 100%"
          }
        },
        "18914457124a40929fe52e1a6a67a216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c4c04267db5466ab9e2c416ec6461e5",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a98528fcde144ec8ee8322ad5e19270",
            "value": 190
          }
        },
        "a7127d2d7f4d409a870ccaa2e313011b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_224e77ffe68f49d5abc219c9c86d2122",
            "placeholder": "​",
            "style": "IPY_MODEL_aef4a1df4b3e43bf8c51db3d0e6c1694",
            "value": " 190/190 [00:00&lt;00:00, 10.3kB/s]"
          }
        },
        "4a8ff325c3fa4e9898d0f65957e5f1f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c0898baf1974001bd92c0bdb0fd5d9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc83ea9753564da0ae18424f843a0ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c4c04267db5466ab9e2c416ec6461e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a98528fcde144ec8ee8322ad5e19270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "224e77ffe68f49d5abc219c9c86d2122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aef4a1df4b3e43bf8c51db3d0e6c1694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb49c31b4f4147738b2d0ffaa8689776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fca5917cfa7b42068e3db7b9c0ff425d",
              "IPY_MODEL_106662407263469bafaa3f8408e79930",
              "IPY_MODEL_f869c8cf84e745f0969e789b338efd17"
            ],
            "layout": "IPY_MODEL_7df8dff2403c401a991cebd85ef95323"
          }
        },
        "fca5917cfa7b42068e3db7b9c0ff425d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_801a49b29a1c4010a6b6b7b9a0b4e5c6",
            "placeholder": "​",
            "style": "IPY_MODEL_95d2c11892054f578c44617c97c3397f",
            "value": "Loading weights: 100%"
          }
        },
        "106662407263469bafaa3f8408e79930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad1227f079dc4320b59e9b9a8260379b",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4098167b0da243dc91ae0348e90629c8",
            "value": 190
          }
        },
        "f869c8cf84e745f0969e789b338efd17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9cd28ac4145465887a4ecfaa6606841",
            "placeholder": "​",
            "style": "IPY_MODEL_34c4a46ae5d04a7cb357dd58f096378c",
            "value": " 190/190 [00:00&lt;00:00, 551.88it/s, Materializing param=shared.weight]"
          }
        },
        "7df8dff2403c401a991cebd85ef95323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "801a49b29a1c4010a6b6b7b9a0b4e5c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95d2c11892054f578c44617c97c3397f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad1227f079dc4320b59e9b9a8260379b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4098167b0da243dc91ae0348e90629c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9cd28ac4145465887a4ecfaa6606841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34c4a46ae5d04a7cb357dd58f096378c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivaprajapati34390-netizen/ML-project/blob/main/RAG_System_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTenZltMVQjp",
        "outputId": "1e6e50d8-9b06-4cc6-cf28-0b98e24d2556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.0.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.3)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.10)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-text-splitters\n",
            "  Downloading langchain_text_splitters-1.1.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.24.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.24.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.10.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.10 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.13)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.46)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.4)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.13.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.7.3)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (1.33)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (0.14.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (0.3.6)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (3.6.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (0.24.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.10->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.8->langchain) (1.12.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (8.3.1)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (0.0.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (0.1.2)\n",
            "Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.1-py3-none-any.whl (35 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, faiss-cpu, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 faiss-cpu-1.13.2 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-text-splitters-1.1.1 marshmallow-3.26.2 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers sentence-transformers faiss-cpu langchain langchain-community langchain-text-splitters"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ku2bB8RPMUTS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "7a1003ac",
        "outputId": "2a91f120-9e59-44d2-8acf-1326b7e45428"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# This will open a file picker dialog to upload files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1d158f63-6460-4e91-8344-f9a20ba857f8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1d158f63-6460-4e91-8344-f9a20ba857f8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving machine.txt.txt to machine.txt.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "XOmZMEXEcX8Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Initialize the Text Splitter\n",
        "# This splitter is smart. It tries to split on paragraphs (\"\\n\\n\"),\n",
        "# then newlines (\"\\n\"), then spaces (\" \"), to keep semantically\n",
        "# related text together as much as possible.\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=150,  # Max size of a chunk\n",
        "    chunk_overlap=20, # Overlap to maintain context between chunks\n",
        "    length_function=len\n",
        ")"
      ],
      "metadata": {
        "id": "LFC5V3QJjQs6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create the chunks\n",
        "\n",
        "# Get the content of the uploaded file and decode it from bytes to a string\n",
        "file_name = 'machine.txt.txt'\n",
        "file_content = uploaded[file_name].decode('utf-8')\n",
        "\n",
        "chunks = text_splitter.split_text(file_content)\n",
        "\n",
        "print(f\"We have {len(chunks)} chunks:\")\n",
        "for i, chunk in enumerate(chunks):\n",
        "    print(f\"--- Chunk {i+1} ---\\n{chunk}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCTC0N2aMGp2",
        "outputId": "396d4b93-232e-4bd6-e4b2-538d45689761"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 18284 chunks:\n",
            "--- Chunk 1 ---\n",
            "﻿2n\n",
            "U d\n",
            "\n",
            "T pd  \n",
            "e E\n",
            "n a d\n",
            "so te it\n",
            "\n",
            "r d i\n",
            "F o\n",
            "lo  fo n\n",
            "\n",
            "w r\n",
            "2\n",
            "\n",
            "--- Chunk 2 ---\n",
            "w r\n",
            "2   \n",
            "\n",
            "Hands-on  \n",
            "Machine Learning  \n",
            " with Scikit-Learn,  \n",
            "Keras & TensorFlow\n",
            "Concepts, Tools, and Techniques  \n",
            "to Build Intelligent Systems\n",
            "\n",
            "TM\n",
            "\n",
            "--- Chunk 3 ---\n",
            "TM\n",
            "\n",
            "Aurélien Géron\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SECOND EDITION\n",
            "\n",
            "Hands-On Machine Learning with\n",
            "Scikit-Learn, Keras, and\n",
            "\n",
            "TensorFlow\n",
            "Concepts, Tools, and Techniques to\n",
            "\n",
            "--- Chunk 4 ---\n",
            "Build Intelligent Systems\n",
            "\n",
            "Aurélien Géron\n",
            "\n",
            "Beijing Boston Farnham Sebastopol Tokyo\n",
            "\n",
            "--- Chunk 5 ---\n",
            "Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\n",
            "by Aurélien Géron\n",
            "Copyright © 2019 Kiwisoft S.A.S. All rights reserved.\n",
            "\n",
            "--- Chunk 6 ---\n",
            "Printed in Canada.\n",
            "Published by O’Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472.\n",
            "\n",
            "--- Chunk 7 ---\n",
            "O’Reilly books may be purchased for educational, business, or sales promotional use. Online editions are\n",
            "\n",
            "--- Chunk 8 ---\n",
            "also available for most titles (http://oreilly.com). For more information, contact our corporate/institutional\n",
            "\n",
            "--- Chunk 9 ---\n",
            "sales department: 800-998-9938 or corporate@oreilly.com.\n",
            "\n",
            "--- Chunk 10 ---\n",
            "Editors: Rachel Roumeliotis and Nicole Tache Indexer: Judith McConville\n",
            "Production Editor: Kristen Brown Interior Designer: David Futato\n",
            "\n",
            "--- Chunk 11 ---\n",
            "Copyeditor: Amanda Kersey Cover Designer: Karen Montgomery\n",
            "Proofreader: Rachel Head Illustrator: Rebecca Demarest\n",
            "\n",
            "--- Chunk 12 ---\n",
            "September 2019:  Second Edition\n",
            "\n",
            "--- Chunk 13 ---\n",
            "Revision History for the Second Edition\n",
            "2019-09-05: First Release\n",
            "2019-10-11: Second Release\n",
            "2019-11-22: Third Release\n",
            "\n",
            "--- Chunk 14 ---\n",
            "See http://oreilly.com/catalog/errata.csp?isbn=9781492032649 for release details.\n",
            "\n",
            "--- Chunk 15 ---\n",
            "The O’Reilly logo is a registered trademark of O’Reilly Media, Inc. Hands-On Machine Learning with\n",
            "\n",
            "--- Chunk 16 ---\n",
            "Scikit-Learn, Keras, and TensorFlow, the cover image, and related trade dress are trademarks of O’Reilly\n",
            "Media, Inc.\n",
            "\n",
            "--- Chunk 17 ---\n",
            "Media, Inc.\n",
            "The views expressed in this work are those of the author, and do not represent the publisher’s views.\n",
            "\n",
            "--- Chunk 18 ---\n",
            "While the publisher and the author have used good faith efforts to ensure that the information and\n",
            "\n",
            "--- Chunk 19 ---\n",
            "instructions contained in this work are accurate, the publisher and the author disclaim all responsibility\n",
            "\n",
            "--- Chunk 20 ---\n",
            "for errors or omissions, including without limitation responsibility for damages resulting from the use of\n",
            "\n",
            "--- Chunk 21 ---\n",
            "or reliance on this work. Use of the information and instructions contained in this work is at your own\n",
            "\n",
            "--- Chunk 22 ---\n",
            "risk. If any code samples or other technology this work contains or describes is subject to open source\n",
            "\n",
            "--- Chunk 23 ---\n",
            "licenses or the intellectual property rights of others, it is your responsibility to ensure that your use\n",
            "\n",
            "--- Chunk 24 ---\n",
            "thereof complies with such licenses and/or rights.\n",
            "\n",
            "--- Chunk 25 ---\n",
            "978-1-492-03264-9\n",
            "[TI]\n",
            "\n",
            "\n",
            "\n",
            "Table of Contents\n",
            "\n",
            "--- Chunk 26 ---\n",
            "Preface. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "\n",
            "--- Chunk 27 ---\n",
            ". . . . . . . . .  xv\n",
            "\n",
            "--- Chunk 28 ---\n",
            "Part I. The Fundamentals of Machine Learning\n",
            "\n",
            "--- Chunk 29 ---\n",
            "1. The Machine Learning Landscape. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1\n",
            "\n",
            "--- Chunk 30 ---\n",
            "What Is Machine Learning?                                                                                           2\n",
            "\n",
            "--- Chunk 31 ---\n",
            "Why Use Machine Learning?                                                                                         2\n",
            "\n",
            "--- Chunk 32 ---\n",
            "Examples of Applications                                                                                               5\n",
            "\n",
            "--- Chunk 33 ---\n",
            "Types of Machine Learning Systems                                                                             7\n",
            "\n",
            "--- Chunk 34 ---\n",
            "Supervised/Unsupervised Learning                                                                           7\n",
            "\n",
            "--- Chunk 35 ---\n",
            "Batch and Online Learning                                                                                       14\n",
            "\n",
            "--- Chunk 36 ---\n",
            "Instance-Based Versus Model-Based Learning                                                      17\n",
            "\n",
            "--- Chunk 37 ---\n",
            "Main Challenges of Machine Learning                                                                       23\n",
            "\n",
            "--- Chunk 38 ---\n",
            "Insufficient Quantity of Training Data                                                                   23\n",
            "\n",
            "--- Chunk 39 ---\n",
            "Nonrepresentative Training Data                                                                            25\n",
            "\n",
            "--- Chunk 40 ---\n",
            "Poor-Quality Data                                                                                                      26\n",
            "\n",
            "--- Chunk 41 ---\n",
            "Irrelevant Features                                                                                                     27\n",
            "\n",
            "--- Chunk 42 ---\n",
            "Overfitting the Training Data                                                                                   27\n",
            "\n",
            "--- Chunk 43 ---\n",
            "Underfitting the Training Data                                                                                29\n",
            "\n",
            "--- Chunk 44 ---\n",
            "Stepping Back                                                                                                             30\n",
            "\n",
            "--- Chunk 45 ---\n",
            "Testing and Validating                                                                                                   30\n",
            "\n",
            "--- Chunk 46 ---\n",
            "Hyperparameter Tuning and Model Selection                                                       31\n",
            "\n",
            "--- Chunk 47 ---\n",
            "Data Mismatch                                                                                                           32\n",
            "\n",
            "--- Chunk 48 ---\n",
            "Exercises                                                                                                                          33\n",
            "\n",
            "--- Chunk 49 ---\n",
            "2. End-to-End Machine Learning Project. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  35\n",
            "\n",
            "--- Chunk 50 ---\n",
            "Working with Real Data                                                                                                35\n",
            "\n",
            "--- Chunk 51 ---\n",
            "iii\n",
            "\n",
            "--- Chunk 52 ---\n",
            "Look at the Big Picture                                                                                                  37\n",
            "\n",
            "--- Chunk 53 ---\n",
            "Frame the Problem                                                                                                    37\n",
            "\n",
            "--- Chunk 54 ---\n",
            "Select a Performance Measure                                                                                  39\n",
            "\n",
            "--- Chunk 55 ---\n",
            "Check the Assumptions                                                                                             42\n",
            "\n",
            "--- Chunk 56 ---\n",
            "Get the Data                                                                                                                    42\n",
            "\n",
            "--- Chunk 57 ---\n",
            "Create the Workspace                                                                                                42\n",
            "\n",
            "--- Chunk 58 ---\n",
            "Download the Data                                                                                                    46\n",
            "\n",
            "--- Chunk 59 ---\n",
            "Take a Quick Look at the Data Structure                                                                47\n",
            "\n",
            "--- Chunk 60 ---\n",
            "Create a Test Set                                                                                                          51\n",
            "\n",
            "--- Chunk 61 ---\n",
            "Discover and Visualize the Data to Gain Insights                                                     56\n",
            "\n",
            "--- Chunk 62 ---\n",
            "Visualizing Geographical Data                                                                                 56\n",
            "\n",
            "--- Chunk 63 ---\n",
            "Looking for Correlations                                                                                           58\n",
            "\n",
            "--- Chunk 64 ---\n",
            "Experimenting with Attribute Combinations                                                        61\n",
            "\n",
            "--- Chunk 65 ---\n",
            "Prepare the Data for Machine Learning Algorithms                                                62\n",
            "\n",
            "--- Chunk 66 ---\n",
            "Data Cleaning                                                                                                             63\n",
            "\n",
            "--- Chunk 67 ---\n",
            "Handling Text and Categorical Attributes                                                              65\n",
            "\n",
            "--- Chunk 68 ---\n",
            "Custom Transformers                                                                                                68\n",
            "\n",
            "--- Chunk 69 ---\n",
            "Feature Scaling                                                                                                            69\n",
            "\n",
            "--- Chunk 70 ---\n",
            "Transformation Pipelines                                                                                          70\n",
            "\n",
            "--- Chunk 71 ---\n",
            "Select and Train a Model                                                                                               72\n",
            "\n",
            "--- Chunk 72 ---\n",
            "Training and Evaluating on the Training Set                                                         72\n",
            "\n",
            "--- Chunk 73 ---\n",
            "Better Evaluation Using Cross-Validation                                                              73\n",
            "\n",
            "--- Chunk 74 ---\n",
            "Fine-Tune Your Model                                                                                                  75\n",
            "\n",
            "--- Chunk 75 ---\n",
            "Grid Search                                                                                                                 76\n",
            "\n",
            "--- Chunk 76 ---\n",
            "Randomized Search                                                                                                   78\n",
            "\n",
            "--- Chunk 77 ---\n",
            "Ensemble Methods                                                                                                     78\n",
            "\n",
            "--- Chunk 78 ---\n",
            "Analyze the Best Models and Their Errors                                                             78\n",
            "\n",
            "--- Chunk 79 ---\n",
            "Evaluate Your System on the Test Set                                                                      79\n",
            "\n",
            "--- Chunk 80 ---\n",
            "Launch, Monitor, and Maintain Your System                                                            80\n",
            "\n",
            "--- Chunk 81 ---\n",
            "Try It Out!                                                                                                                       83\n",
            "\n",
            "--- Chunk 82 ---\n",
            "Exercises                                                                                                                          84\n",
            "\n",
            "--- Chunk 83 ---\n",
            "3. Classification. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  85\n",
            "\n",
            "--- Chunk 84 ---\n",
            "MNIST                                                                                                                             85\n",
            "\n",
            "--- Chunk 85 ---\n",
            "Training a Binary Classifier                                                                                          88\n",
            "\n",
            "--- Chunk 86 ---\n",
            "Performance Measures                                                                                                  88\n",
            "\n",
            "--- Chunk 87 ---\n",
            "Measuring Accuracy Using Cross-Validation                                                        89\n",
            "\n",
            "--- Chunk 88 ---\n",
            "Confusion Matrix                                                                                                       90\n",
            "\n",
            "--- Chunk 89 ---\n",
            "Precision and Recall                                                                                                   92\n",
            "\n",
            "--- Chunk 90 ---\n",
            "Precision/Recall Trade-off                                                                                        93\n",
            "\n",
            "--- Chunk 91 ---\n",
            "The ROC Curve                                                                                                          97\n",
            "\n",
            "--- Chunk 92 ---\n",
            "Multiclass Classification                                                                                             100\n",
            "\n",
            "iv | Table of Contents\n",
            "\n",
            "--- Chunk 93 ---\n",
            "Error Analysis                                                                                                              102\n",
            "\n",
            "--- Chunk 94 ---\n",
            "Multilabel Classification                                                                                             106\n",
            "\n",
            "--- Chunk 95 ---\n",
            "Multioutput Classification                                                                                          107\n",
            "\n",
            "--- Chunk 96 ---\n",
            "Exercises                                                                                                                        108\n",
            "\n",
            "--- Chunk 97 ---\n",
            "4. Training Models. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  111\n",
            "\n",
            "--- Chunk 98 ---\n",
            "Linear Regression                                                                                                        112\n",
            "\n",
            "--- Chunk 99 ---\n",
            "The Normal Equation                                                                                              114\n",
            "\n",
            "--- Chunk 100 ---\n",
            "Computational Complexity                                                                                    117\n",
            "\n",
            "--- Chunk 101 ---\n",
            "Gradient Descent                                                                                                         118\n",
            "\n",
            "--- Chunk 102 ---\n",
            "Batch Gradient Descent                                                                                           121\n",
            "\n",
            "--- Chunk 103 ---\n",
            "Stochastic Gradient Descent                                                                                   124\n",
            "\n",
            "--- Chunk 104 ---\n",
            "Mini-batch Gradient Descent                                                                                 127\n",
            "\n",
            "--- Chunk 105 ---\n",
            "Polynomial Regression                                                                                                128\n",
            "\n",
            "--- Chunk 106 ---\n",
            "Learning Curves                                                                                                           130\n",
            "\n",
            "--- Chunk 107 ---\n",
            "Regularized Linear Models                                                                                         134\n",
            "\n",
            "--- Chunk 108 ---\n",
            "Ridge Regression                                                                                                      135\n",
            "\n",
            "--- Chunk 109 ---\n",
            "Lasso Regression                                                                                                      137\n",
            "\n",
            "--- Chunk 110 ---\n",
            "Elastic Net                                                                                                                 140\n",
            "\n",
            "--- Chunk 111 ---\n",
            "Early Stopping                                                                                                          141\n",
            "\n",
            "--- Chunk 112 ---\n",
            "Logistic Regression                                                                                                      142\n",
            "\n",
            "--- Chunk 113 ---\n",
            "Estimating Probabilities                                                                                          143\n",
            "\n",
            "--- Chunk 114 ---\n",
            "Training and Cost Function                                                                                   144\n",
            "\n",
            "--- Chunk 115 ---\n",
            "Decision Boundaries                                                                                                145\n",
            "\n",
            "--- Chunk 116 ---\n",
            "Softmax Regression                                                                                                  148\n",
            "\n",
            "--- Chunk 117 ---\n",
            "Exercises                                                                                                                        151\n",
            "\n",
            "--- Chunk 118 ---\n",
            "5. Support Vector Machines. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  153\n",
            "\n",
            "--- Chunk 119 ---\n",
            "Linear SVM Classification                                                                                          153\n",
            "\n",
            "--- Chunk 120 ---\n",
            "Soft Margin Classification                                                                                       154\n",
            "\n",
            "--- Chunk 121 ---\n",
            "Nonlinear SVM Classification                                                                                   157\n",
            "\n",
            "--- Chunk 122 ---\n",
            "Polynomial Kernel                                                                                                   158\n",
            "\n",
            "--- Chunk 123 ---\n",
            "Similarity Features                                                                                                   159\n",
            "\n",
            "--- Chunk 124 ---\n",
            "Gaussian RBF Kernel                                                                                               160\n",
            "\n",
            "--- Chunk 125 ---\n",
            "Computational Complexity                                                                                    162\n",
            "\n",
            "--- Chunk 126 ---\n",
            "SVM Regression                                                                                                           162\n",
            "\n",
            "--- Chunk 127 ---\n",
            "Under the Hood                                                                                                           164\n",
            "\n",
            "--- Chunk 128 ---\n",
            "Decision Function and Predictions                                                                       165\n",
            "\n",
            "--- Chunk 129 ---\n",
            "Training Objective                                                                                                   166\n",
            "\n",
            "--- Chunk 130 ---\n",
            "Quadratic Programming                                                                                         167\n",
            "\n",
            "--- Chunk 131 ---\n",
            "The Dual Problem                                                                                                    168\n",
            "\n",
            "--- Chunk 132 ---\n",
            "Kernelized SVMs                                                                                                      169\n",
            "\n",
            "--- Chunk 133 ---\n",
            "Table of Contents | v\n",
            "\n",
            "--- Chunk 134 ---\n",
            "Online SVMs                                                                                                            172\n",
            "\n",
            "--- Chunk 135 ---\n",
            "Exercises                                                                                                                        174\n",
            "\n",
            "--- Chunk 136 ---\n",
            "6. Decision Trees. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  175\n",
            "\n",
            "--- Chunk 137 ---\n",
            "Training and Visualizing a Decision Tree                                                                175\n",
            "\n",
            "--- Chunk 138 ---\n",
            "Making Predictions                                                                                                     176\n",
            "\n",
            "--- Chunk 139 ---\n",
            "Estimating Class Probabilities                                                                                   178\n",
            "\n",
            "--- Chunk 140 ---\n",
            "The CART Training Algorithm                                                                                 179\n",
            "\n",
            "--- Chunk 141 ---\n",
            "Computational Complexity                                                                                        180\n",
            "\n",
            "--- Chunk 142 ---\n",
            "Gini Impurity or Entropy?                                                                                         180\n",
            "\n",
            "--- Chunk 143 ---\n",
            "Regularization Hyperparameters                                                                              181\n",
            "\n",
            "--- Chunk 144 ---\n",
            "Regression                                                                                                                     183\n",
            "\n",
            "--- Chunk 145 ---\n",
            "Instability                                                                                                                      185\n",
            "\n",
            "--- Chunk 146 ---\n",
            "Exercises                                                                                                                        186\n",
            "\n",
            "--- Chunk 147 ---\n",
            "7. Ensemble Learning and Random Forests. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  189\n",
            "\n",
            "--- Chunk 148 ---\n",
            "Voting Classifiers                                                                                                         189\n",
            "\n",
            "--- Chunk 149 ---\n",
            "Bagging and Pasting                                                                                                    192\n",
            "\n",
            "--- Chunk 150 ---\n",
            "Bagging and Pasting in Scikit-Learn                                                                     194\n",
            "\n",
            "--- Chunk 151 ---\n",
            "Out-of-Bag Evaluation                                                                                            195\n",
            "\n",
            "--- Chunk 152 ---\n",
            "Random Patches and Random Subspaces                                                                196\n",
            "\n",
            "--- Chunk 153 ---\n",
            "Random Forests                                                                                                           197\n",
            "\n",
            "--- Chunk 154 ---\n",
            "Extra-Trees                                                                                                                198\n",
            "\n",
            "--- Chunk 155 ---\n",
            "Feature Importance                                                                                                  198\n",
            "\n",
            "--- Chunk 156 ---\n",
            "Boosting                                                                                                                        199\n",
            "\n",
            "--- Chunk 157 ---\n",
            "AdaBoost                                                                                                                   200\n",
            "\n",
            "--- Chunk 158 ---\n",
            "Gradient Boosting                                                                                                    203\n",
            "\n",
            "--- Chunk 159 ---\n",
            "Stacking                                                                                                                         208\n",
            "\n",
            "--- Chunk 160 ---\n",
            "Exercises                                                                                                                        211\n",
            "\n",
            "--- Chunk 161 ---\n",
            "8. Dimensionality Reduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  213\n",
            "\n",
            "--- Chunk 162 ---\n",
            "The Curse of Dimensionality                                                                                     214\n",
            "\n",
            "--- Chunk 163 ---\n",
            "Main Approaches for Dimensionality Reduction                                                   215\n",
            "\n",
            "--- Chunk 164 ---\n",
            "Projection                                                                                                                  215\n",
            "\n",
            "--- Chunk 165 ---\n",
            "Manifold Learning                                                                                                   218\n",
            "\n",
            "--- Chunk 166 ---\n",
            "PCA                                                                                                                                219\n",
            "\n",
            "--- Chunk 167 ---\n",
            "Preserving the Variance                                                                                          219\n",
            "\n",
            "--- Chunk 168 ---\n",
            "Principal Components                                                                                            220\n",
            "\n",
            "--- Chunk 169 ---\n",
            "Projecting Down to d Dimensions                                                                        221\n",
            "\n",
            "--- Chunk 170 ---\n",
            "Using Scikit-Learn                                                                                                    222\n",
            "\n",
            "--- Chunk 171 ---\n",
            "Explained Variance Ratio                                                                                        222\n",
            "\n",
            "--- Chunk 172 ---\n",
            "Choosing the Right Number of Dimensions                                                       223\n",
            "\n",
            "--- Chunk 173 ---\n",
            "vi | Table of Contents\n",
            "\n",
            "--- Chunk 174 ---\n",
            "PCA for Compression                                                                                             224\n",
            "\n",
            "--- Chunk 175 ---\n",
            "Randomized PCA                                                                                                    225\n",
            "\n",
            "--- Chunk 176 ---\n",
            "Incremental PCA                                                                                                     225\n",
            "\n",
            "--- Chunk 177 ---\n",
            "Kernel PCA                                                                                                                   226\n",
            "\n",
            "--- Chunk 178 ---\n",
            "Selecting a Kernel and Tuning Hyperparameters                                                227\n",
            "\n",
            "--- Chunk 179 ---\n",
            "LLE                                                                                                                                 230\n",
            "\n",
            "--- Chunk 180 ---\n",
            "Other Dimensionality Reduction Techniques                                                         232\n",
            "\n",
            "--- Chunk 181 ---\n",
            "Exercises                                                                                                                        233\n",
            "\n",
            "--- Chunk 182 ---\n",
            "9. Unsupervised Learning Techniques. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  235\n",
            "\n",
            "--- Chunk 183 ---\n",
            "Clustering                                                                                                                      236\n",
            "\n",
            "--- Chunk 184 ---\n",
            "K-Means                                                                                                                    238\n",
            "\n",
            "--- Chunk 185 ---\n",
            "Limits of K-Means                                                                                                   248\n",
            "\n",
            "--- Chunk 186 ---\n",
            "Using Clustering for Image Segmentation                                                           249\n",
            "\n",
            "--- Chunk 187 ---\n",
            "Using Clustering for Preprocessing                                                                       251\n",
            "\n",
            "--- Chunk 188 ---\n",
            "Using Clustering for Semi-Supervised Learning                                                 253\n",
            "\n",
            "--- Chunk 189 ---\n",
            "DBSCAN                                                                                                                   255\n",
            "\n",
            "--- Chunk 190 ---\n",
            "Other Clustering Algorithms                                                                                 258\n",
            "\n",
            "--- Chunk 191 ---\n",
            "Gaussian Mixtures                                                                                                       260\n",
            "\n",
            "--- Chunk 192 ---\n",
            "Anomaly Detection Using Gaussian Mixtures                                                    266\n",
            "\n",
            "--- Chunk 193 ---\n",
            "Selecting the Number of Clusters                                                                          267\n",
            "\n",
            "--- Chunk 194 ---\n",
            "Bayesian Gaussian Mixture Models                                                                      270\n",
            "\n",
            "--- Chunk 195 ---\n",
            "Other Algorithms for Anomaly and Novelty Detection                                    274\n",
            "\n",
            "--- Chunk 196 ---\n",
            "Exercises                                                                                                                        275\n",
            "\n",
            "--- Chunk 197 ---\n",
            "Part II. Neural Networks and Deep Learning\n",
            "\n",
            "--- Chunk 198 ---\n",
            "10. Introduction to Artificial Neural Networks with Keras. . . . . . . . . . . . . . . . . . . . . . . . . .  279\n",
            "\n",
            "--- Chunk 199 ---\n",
            "From Biological to Artificial Neurons                                                                      280\n",
            "\n",
            "--- Chunk 200 ---\n",
            "Biological Neurons                                                                                                   281\n",
            "\n",
            "--- Chunk 201 ---\n",
            "Logical Computations with Neurons                                                                    283\n",
            "\n",
            "--- Chunk 202 ---\n",
            "The Perceptron                                                                                                         284\n",
            "\n",
            "--- Chunk 203 ---\n",
            "The Multilayer Perceptron and Backpropagation                                               289\n",
            "\n",
            "--- Chunk 204 ---\n",
            "Regression MLPs                                                                                                      292\n",
            "\n",
            "--- Chunk 205 ---\n",
            "Classification MLPs                                                                                                 294\n",
            "\n",
            "--- Chunk 206 ---\n",
            "Implementing MLPs with Keras                                                                                295\n",
            "\n",
            "--- Chunk 207 ---\n",
            "Installing TensorFlow 2                                                                                           296\n",
            "\n",
            "--- Chunk 208 ---\n",
            "Building an Image Classifier Using the Sequential API                                     297\n",
            "\n",
            "--- Chunk 209 ---\n",
            "Building a Regression MLP Using the Sequential API                                       307\n",
            "\n",
            "--- Chunk 210 ---\n",
            "Building Complex Models Using the Functional API                                        308\n",
            "\n",
            "--- Chunk 211 ---\n",
            "Using the Subclassing API to Build Dynamic Models                                        313\n",
            "\n",
            "--- Chunk 212 ---\n",
            "Table of Contents | vii\n",
            "\n",
            "--- Chunk 213 ---\n",
            "Saving and Restoring a Model                                                                                314\n",
            "\n",
            "--- Chunk 214 ---\n",
            "Using Callbacks                                                                                                        315\n",
            "\n",
            "--- Chunk 215 ---\n",
            "Using TensorBoard for Visualization                                                                    317\n",
            "\n",
            "--- Chunk 216 ---\n",
            "Fine-Tuning Neural Network Hyperparameters                                                     320\n",
            "\n",
            "--- Chunk 217 ---\n",
            "Number of Hidden Layers                                                                                      323\n",
            "\n",
            "--- Chunk 218 ---\n",
            "Number of Neurons per Hidden Layer                                                                 324\n",
            "\n",
            "--- Chunk 219 ---\n",
            "Learning Rate, Batch Size, and Other Hyperparameters                                    325\n",
            "\n",
            "--- Chunk 220 ---\n",
            "Exercises                                                                                                                        327\n",
            "\n",
            "--- Chunk 221 ---\n",
            "11. Training Deep Neural Networks. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  331\n",
            "\n",
            "--- Chunk 222 ---\n",
            "The Vanishing/Exploding Gradients Problems                                                      332\n",
            "\n",
            "--- Chunk 223 ---\n",
            "Glorot and He Initialization                                                                                   333\n",
            "\n",
            "--- Chunk 224 ---\n",
            "Nonsaturating Activation Functions                                                                     335\n",
            "\n",
            "--- Chunk 225 ---\n",
            "Batch Normalization                                                                                                338\n",
            "\n",
            "--- Chunk 226 ---\n",
            "Gradient Clipping                                                                                                    345\n",
            "\n",
            "--- Chunk 227 ---\n",
            "Reusing Pretrained Layers                                                                                          345\n",
            "\n",
            "--- Chunk 228 ---\n",
            "Transfer Learning with Keras                                                                                 347\n",
            "\n",
            "--- Chunk 229 ---\n",
            "Unsupervised Pretraining                                                                                       349\n",
            "\n",
            "--- Chunk 230 ---\n",
            "Pretraining on an Auxiliary Task                                                                           350\n",
            "\n",
            "--- Chunk 231 ---\n",
            "Faster Optimizers                                                                                                         351\n",
            "\n",
            "--- Chunk 232 ---\n",
            "Momentum Optimization                                                                                      351\n",
            "\n",
            "--- Chunk 233 ---\n",
            "Nesterov Accelerated Gradient                                                                              353\n",
            "\n",
            "--- Chunk 234 ---\n",
            "AdaGrad                                                                                                                    354\n",
            "\n",
            "--- Chunk 235 ---\n",
            "RMSProp                                                                                                                   355\n",
            "\n",
            "--- Chunk 236 ---\n",
            "Adam and Nadam Optimization                                                                           356\n",
            "\n",
            "--- Chunk 237 ---\n",
            "Learning Rate Scheduling                                                                                       359\n",
            "\n",
            "--- Chunk 238 ---\n",
            "Avoiding Overfitting Through Regularization                                                        364\n",
            "\n",
            "--- Chunk 239 ---\n",
            "ℓ1 and ℓ2 Regularization                                                                                           364\n",
            "\n",
            "--- Chunk 240 ---\n",
            "Dropout                                                                                                                     365\n",
            "\n",
            "--- Chunk 241 ---\n",
            "Monte Carlo (MC) Dropout                                                                                   368\n",
            "\n",
            "--- Chunk 242 ---\n",
            "Max-Norm Regularization                                                                                      370\n",
            "\n",
            "--- Chunk 243 ---\n",
            "Summary and Practical Guidelines                                                                           371\n",
            "\n",
            "--- Chunk 244 ---\n",
            "Exercises                                                                                                                        373\n",
            "\n",
            "--- Chunk 245 ---\n",
            "12. Custom Models and Training with TensorFlow. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  375\n",
            "\n",
            "--- Chunk 246 ---\n",
            "A Quick Tour of TensorFlow                                                                                     376\n",
            "\n",
            "--- Chunk 247 ---\n",
            "Using TensorFlow like NumPy                                                                                  379\n",
            "\n",
            "--- Chunk 248 ---\n",
            "Tensors and Operations                                                                                          379\n",
            "\n",
            "--- Chunk 249 ---\n",
            "Tensors and NumPy                                                                                                381\n",
            "\n",
            "--- Chunk 250 ---\n",
            "Type Conversions                                                                                                     381\n",
            "\n",
            "--- Chunk 251 ---\n",
            "Variables                                                                                                                    382\n",
            "\n",
            "--- Chunk 252 ---\n",
            "Other Data Structures                                                                                             383\n",
            "\n",
            "--- Chunk 253 ---\n",
            "viii | Table of Contents\n",
            "\n",
            "--- Chunk 254 ---\n",
            "Customizing Models and Training Algorithms                                                      384\n",
            "\n",
            "--- Chunk 255 ---\n",
            "Custom Loss Functions                                                                                           384\n",
            "\n",
            "--- Chunk 256 ---\n",
            "Saving and Loading Models That Contain Custom Components                    385\n",
            "\n",
            "--- Chunk 257 ---\n",
            "Custom Activation Functions, Initializers, Regularizers, and Constraints     387\n",
            "\n",
            "--- Chunk 258 ---\n",
            "Custom Metrics                                                                                                        388\n",
            "\n",
            "--- Chunk 259 ---\n",
            "Custom Layers                                                                                                          391\n",
            "\n",
            "--- Chunk 260 ---\n",
            "Custom Models                                                                                                        394\n",
            "\n",
            "--- Chunk 261 ---\n",
            "Losses and Metrics Based on Model Internals                                                     397\n",
            "\n",
            "--- Chunk 262 ---\n",
            "Computing Gradients Using Autodiff                                                                   399\n",
            "\n",
            "--- Chunk 263 ---\n",
            "Custom Training Loops                                                                                          402\n",
            "\n",
            "--- Chunk 264 ---\n",
            "TensorFlow Functions and Graphs                                                                           405\n",
            "\n",
            "--- Chunk 265 ---\n",
            "AutoGraph and Tracing                                                                                          407\n",
            "\n",
            "--- Chunk 266 ---\n",
            "TF Function Rules                                                                                                    409\n",
            "\n",
            "--- Chunk 267 ---\n",
            "Exercises                                                                                                                        410\n",
            "\n",
            "--- Chunk 268 ---\n",
            "13. Loading and Preprocessing Data with TensorFlow. . . . . . . . . . . . . . . . . . . . . . . . . . . . .  413\n",
            "\n",
            "--- Chunk 269 ---\n",
            "The Data API                                                                                                                414\n",
            "\n",
            "--- Chunk 270 ---\n",
            "Chaining Transformations                                                                                      415\n",
            "\n",
            "--- Chunk 271 ---\n",
            "Shuffling the Data                                                                                                    416\n",
            "\n",
            "--- Chunk 272 ---\n",
            "Preprocessing the Data                                                                                            419\n",
            "\n",
            "--- Chunk 273 ---\n",
            "Putting Everything Together                                                                                  420\n",
            "\n",
            "--- Chunk 274 ---\n",
            "Prefetching                                                                                                                421\n",
            "\n",
            "--- Chunk 275 ---\n",
            "Using the Dataset with tf.keras                                                                               423\n",
            "\n",
            "--- Chunk 276 ---\n",
            "The TFRecord Format                                                                                                424\n",
            "\n",
            "--- Chunk 277 ---\n",
            "Compressed TFRecord Files                                                                                   425\n",
            "\n",
            "--- Chunk 278 ---\n",
            "A Brief Introduction to Protocol Buffers                                                              425\n",
            "\n",
            "--- Chunk 279 ---\n",
            "TensorFlow Protobufs                                                                                             427\n",
            "\n",
            "--- Chunk 280 ---\n",
            "Loading and Parsing Examples                                                                              428\n",
            "\n",
            "--- Chunk 281 ---\n",
            "Handling Lists of Lists Using the SequenceExample Protobuf                         429\n",
            "\n",
            "--- Chunk 282 ---\n",
            "Preprocessing the Input Features                                                                              430\n",
            "\n",
            "--- Chunk 283 ---\n",
            "Encoding Categorical Features Using One-Hot Vectors                                    431\n",
            "\n",
            "--- Chunk 284 ---\n",
            "Encoding Categorical Features Using Embeddings                                            433\n",
            "\n",
            "--- Chunk 285 ---\n",
            "Keras Preprocessing Layers                                                                                    437\n",
            "\n",
            "--- Chunk 286 ---\n",
            "TF Transform                                                                                                               439\n",
            "\n",
            "--- Chunk 287 ---\n",
            "The TensorFlow Datasets (TFDS) Project                                                                441\n",
            "\n",
            "--- Chunk 288 ---\n",
            "Exercises                                                                                                                        442\n",
            "\n",
            "--- Chunk 289 ---\n",
            "14. Deep Computer Vision Using Convolutional Neural Networks. . . . . . . . . . . . . . . . . . .  445\n",
            "\n",
            "--- Chunk 290 ---\n",
            "The Architecture of the Visual Cortex                                                                     446\n",
            "\n",
            "--- Chunk 291 ---\n",
            "Convolutional Layers                                                                                                  448\n",
            "\n",
            "--- Chunk 292 ---\n",
            "Filters                                                                                                                         450\n",
            "\n",
            "--- Chunk 293 ---\n",
            "Stacking Multiple Feature Maps                                                                             451\n",
            "\n",
            "--- Chunk 294 ---\n",
            "Table of Contents | ix\n",
            "\n",
            "--- Chunk 295 ---\n",
            "TensorFlow Implementation                                                                                  453\n",
            "\n",
            "--- Chunk 296 ---\n",
            "Memory Requirements                                                                                           456\n",
            "\n",
            "--- Chunk 297 ---\n",
            "Pooling Layers                                                                                                              456\n",
            "\n",
            "--- Chunk 298 ---\n",
            "TensorFlow Implementation                                                                                  458\n",
            "\n",
            "--- Chunk 299 ---\n",
            "CNN Architectures                                                                                                      460\n",
            "\n",
            "--- Chunk 300 ---\n",
            "LeNet-5                                                                                                                      463\n",
            "\n",
            "--- Chunk 301 ---\n",
            "AlexNet                                                                                                                      464\n",
            "\n",
            "--- Chunk 302 ---\n",
            "GoogLeNet                                                                                                                466\n",
            "\n",
            "--- Chunk 303 ---\n",
            "VGGNet                                                                                                                     470\n",
            "\n",
            "--- Chunk 304 ---\n",
            "ResNet                                                                                                                        471\n",
            "\n",
            "--- Chunk 305 ---\n",
            "Xception                                                                                                                    474\n",
            "\n",
            "--- Chunk 306 ---\n",
            "SENet                                                                                                                         476\n",
            "\n",
            "--- Chunk 307 ---\n",
            "Implementing a ResNet-34 CNN Using Keras                                                        478\n",
            "\n",
            "--- Chunk 308 ---\n",
            "Using Pretrained Models from Keras                                                                       479\n",
            "\n",
            "--- Chunk 309 ---\n",
            "Pretrained Models for Transfer Learning                                                                 481\n",
            "\n",
            "--- Chunk 310 ---\n",
            "Classification and Localization                                                                                  483\n",
            "\n",
            "--- Chunk 311 ---\n",
            "Object Detection                                                                                                          485\n",
            "\n",
            "--- Chunk 312 ---\n",
            "Fully Convolutional Networks                                                                               487\n",
            "\n",
            "--- Chunk 313 ---\n",
            "You Only Look Once (YOLO)                                                                                489\n",
            "\n",
            "--- Chunk 314 ---\n",
            "Semantic Segmentation                                                                                               492\n",
            "\n",
            "--- Chunk 315 ---\n",
            "Exercises                                                                                                                        496\n",
            "\n",
            "--- Chunk 316 ---\n",
            "15. Processing Sequences Using RNNs and CNNs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  497\n",
            "\n",
            "--- Chunk 317 ---\n",
            "Recurrent Neurons and Layers                                                                                  498\n",
            "\n",
            "--- Chunk 318 ---\n",
            "Memory Cells                                                                                                           500\n",
            "\n",
            "--- Chunk 319 ---\n",
            "Input and Output Sequences                                                                                  501\n",
            "\n",
            "--- Chunk 320 ---\n",
            "Training RNNs                                                                                                             502\n",
            "\n",
            "--- Chunk 321 ---\n",
            "Forecasting a Time Series                                                                                           503\n",
            "\n",
            "--- Chunk 322 ---\n",
            "Baseline Metrics                                                                                                        505\n",
            "\n",
            "--- Chunk 323 ---\n",
            "Implementing a Simple RNN                                                                                 505\n",
            "\n",
            "--- Chunk 324 ---\n",
            "Deep RNNs                                                                                                               506\n",
            "\n",
            "--- Chunk 325 ---\n",
            "Forecasting Several Time Steps Ahead                                                                 508\n",
            "\n",
            "--- Chunk 326 ---\n",
            "Handling Long Sequences                                                                                          511\n",
            "\n",
            "--- Chunk 327 ---\n",
            "Fighting the Unstable Gradients Problem                                                            512\n",
            "\n",
            "--- Chunk 328 ---\n",
            "Tackling the Short-Term Memory Problem                                                         514\n",
            "\n",
            "--- Chunk 329 ---\n",
            "Exercises                                                                                                                        523\n",
            "\n",
            "--- Chunk 330 ---\n",
            "16. Natural Language Processing with RNNs and Attention. . . . . . . . . . . . . . . . . . . . . . . .  525\n",
            "\n",
            "--- Chunk 331 ---\n",
            "Generating Shakespearean Text Using a Character RNN                                      526\n",
            "\n",
            "--- Chunk 332 ---\n",
            "Creating the Training Dataset                                                                                527\n",
            "\n",
            "--- Chunk 333 ---\n",
            "How to Split a Sequential Dataset                                                                          527\n",
            "\n",
            "--- Chunk 334 ---\n",
            "Chopping the Sequential Dataset into Multiple Windows                                528\n",
            "\n",
            "--- Chunk 335 ---\n",
            "x | Table of Contents\n",
            "\n",
            "--- Chunk 336 ---\n",
            "Building and Training the Char-RNN Model                                                      530\n",
            "\n",
            "--- Chunk 337 ---\n",
            "Using the Char-RNN Model                                                                                   531\n",
            "\n",
            "--- Chunk 338 ---\n",
            "Generating Fake Shakespearean Text                                                                    531\n",
            "\n",
            "--- Chunk 339 ---\n",
            "Stateful RNN                                                                                                             532\n",
            "\n",
            "--- Chunk 340 ---\n",
            "Sentiment Analysis                                                                                                      534\n",
            "\n",
            "--- Chunk 341 ---\n",
            "Masking                                                                                                                     538\n",
            "\n",
            "--- Chunk 342 ---\n",
            "Reusing Pretrained Embeddings                                                                           540\n",
            "\n",
            "--- Chunk 343 ---\n",
            "An Encoder–Decoder Network for Neural Machine Translation                        542\n",
            "\n",
            "--- Chunk 344 ---\n",
            "Bidirectional RNNs                                                                                                  546\n",
            "\n",
            "--- Chunk 345 ---\n",
            "Beam Search                                                                                                              547\n",
            "\n",
            "--- Chunk 346 ---\n",
            "Attention Mechanisms                                                                                                549\n",
            "\n",
            "--- Chunk 347 ---\n",
            "Visual Attention                                                                                                       552\n",
            "\n",
            "--- Chunk 348 ---\n",
            "Attention Is All You Need: The Transformer Architecture                                554\n",
            "\n",
            "--- Chunk 349 ---\n",
            "Recent Innovations in Language Models                                                                 563\n",
            "\n",
            "--- Chunk 350 ---\n",
            "Exercises                                                                                                                        565\n",
            "\n",
            "--- Chunk 351 ---\n",
            "17. Representation Learning and Generative Learning Using Autoencoders and GANs.  567\n",
            "\n",
            "--- Chunk 352 ---\n",
            "Efficient Data Representations                                                                                   569\n",
            "\n",
            "--- Chunk 353 ---\n",
            "Performing PCA with an Undercomplete Linear Autoencoder                           570\n",
            "\n",
            "--- Chunk 354 ---\n",
            "Stacked Autoencoders                                                                                                 572\n",
            "\n",
            "--- Chunk 355 ---\n",
            "Implementing a Stacked Autoencoder Using Keras                                            572\n",
            "\n",
            "--- Chunk 356 ---\n",
            "Visualizing the Reconstructions                                                                            574\n",
            "\n",
            "--- Chunk 357 ---\n",
            "Visualizing the Fashion MNIST Dataset                                                              574\n",
            "\n",
            "--- Chunk 358 ---\n",
            "Unsupervised Pretraining Using Stacked Autoencoders                                   576\n",
            "\n",
            "--- Chunk 359 ---\n",
            "Tying Weights                                                                                                           577\n",
            "\n",
            "--- Chunk 360 ---\n",
            "Training One Autoencoder at a Time                                                                   578\n",
            "\n",
            "--- Chunk 361 ---\n",
            "Convolutional Autoencoders                                                                                     579\n",
            "\n",
            "--- Chunk 362 ---\n",
            "Recurrent Autoencoders                                                                                             580\n",
            "\n",
            "--- Chunk 363 ---\n",
            "Denoising Autoencoders                                                                                            581\n",
            "\n",
            "--- Chunk 364 ---\n",
            "Sparse Autoencoders                                                                                                   582\n",
            "\n",
            "--- Chunk 365 ---\n",
            "Variational Autoencoders                                                                                           586\n",
            "\n",
            "--- Chunk 366 ---\n",
            "Generating Fashion MNIST Images                                                                      590\n",
            "\n",
            "--- Chunk 367 ---\n",
            "Generative Adversarial Networks                                                                              592\n",
            "\n",
            "--- Chunk 368 ---\n",
            "The Difficulties of Training GANs                                                                        596\n",
            "\n",
            "--- Chunk 369 ---\n",
            "Deep Convolutional GANs                                                                                     598\n",
            "\n",
            "--- Chunk 370 ---\n",
            "Progressive Growing of GANs                                                                               601\n",
            "\n",
            "--- Chunk 371 ---\n",
            "StyleGANs                                                                                                                 604\n",
            "\n",
            "--- Chunk 372 ---\n",
            "Exercises                                                                                                                        607\n",
            "\n",
            "--- Chunk 373 ---\n",
            "18. Reinforcement Learning. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  609\n",
            "\n",
            "--- Chunk 374 ---\n",
            "Learning to Optimize Rewards                                                                                  610\n",
            "\n",
            "--- Chunk 375 ---\n",
            "Policy Search                                                                                                                 612\n",
            "\n",
            "--- Chunk 376 ---\n",
            "Table of Contents | xi\n",
            "\n",
            "--- Chunk 377 ---\n",
            "Introduction to OpenAI Gym                                                                                   613\n",
            "\n",
            "--- Chunk 378 ---\n",
            "Neural Network Policies                                                                                             617\n",
            "\n",
            "--- Chunk 379 ---\n",
            "Evaluating Actions: The Credit Assignment Problem                                           619\n",
            "\n",
            "--- Chunk 380 ---\n",
            "Policy Gradients                                                                                                           620\n",
            "\n",
            "--- Chunk 381 ---\n",
            "Markov Decision Processes                                                                                        625\n",
            "\n",
            "--- Chunk 382 ---\n",
            "Temporal Difference Learning                                                                                   629\n",
            "\n",
            "--- Chunk 383 ---\n",
            "Q-Learning                                                                                                                   630\n",
            "\n",
            "--- Chunk 384 ---\n",
            "Exploration Policies                                                                                                 632\n",
            "\n",
            "--- Chunk 385 ---\n",
            "Approximate Q-Learning and Deep Q-Learning                                                633\n",
            "\n",
            "--- Chunk 386 ---\n",
            "Implementing Deep Q-Learning                                                                               634\n",
            "\n",
            "--- Chunk 387 ---\n",
            "Deep Q-Learning Variants                                                                                         639\n",
            "\n",
            "--- Chunk 388 ---\n",
            "Fixed Q-Value Targets                                                                                             639\n",
            "\n",
            "--- Chunk 389 ---\n",
            "Double DQN                                                                                                            640\n",
            "\n",
            "--- Chunk 390 ---\n",
            "Prioritized Experience Replay                                                                                640\n",
            "\n",
            "--- Chunk 391 ---\n",
            "Dueling DQN                                                                                                           641\n",
            "\n",
            "--- Chunk 392 ---\n",
            "The TF-Agents Library                                                                                               642\n",
            "\n",
            "--- Chunk 393 ---\n",
            "Installing TF-Agents                                                                                                643\n",
            "\n",
            "--- Chunk 394 ---\n",
            "TF-Agents Environments                                                                                        643\n",
            "\n",
            "--- Chunk 395 ---\n",
            "Environment Specifications                                                                                    644\n",
            "\n",
            "--- Chunk 396 ---\n",
            "Environment Wrappers and Atari Preprocessing                                               645\n",
            "\n",
            "--- Chunk 397 ---\n",
            "Training Architecture                                                                                              649\n",
            "\n",
            "--- Chunk 398 ---\n",
            "Creating the Deep Q-Network                                                                               650\n",
            "\n",
            "--- Chunk 399 ---\n",
            "Creating the DQN Agent                                                                                        652\n",
            "\n",
            "--- Chunk 400 ---\n",
            "Creating the Replay Buffer and the Corresponding Observer                          654\n",
            "\n",
            "--- Chunk 401 ---\n",
            "Creating Training Metrics                                                                                       655\n",
            "\n",
            "--- Chunk 402 ---\n",
            "Creating the Collect Driver                                                                                    656\n",
            "\n",
            "--- Chunk 403 ---\n",
            "Creating the Dataset                                                                                                658\n",
            "\n",
            "--- Chunk 404 ---\n",
            "Creating the Training Loop                                                                                    661\n",
            "\n",
            "--- Chunk 405 ---\n",
            "Overview of Some Popular RL Algorithms                                                             662\n",
            "\n",
            "--- Chunk 406 ---\n",
            "Exercises                                                                                                                        664\n",
            "\n",
            "--- Chunk 407 ---\n",
            "19. Training and Deploying TensorFlow Models at Scale. . . . . . . . . . . . . . . . . . . . . . . . . . .  667\n",
            "\n",
            "--- Chunk 408 ---\n",
            "Serving a TensorFlow Model                                                                                      668\n",
            "\n",
            "--- Chunk 409 ---\n",
            "Using TensorFlow Serving                                                                                      668\n",
            "\n",
            "--- Chunk 410 ---\n",
            "Creating a Prediction Service on GCP AI Platform                                            677\n",
            "\n",
            "--- Chunk 411 ---\n",
            "Using the Prediction Service                                                                                  682\n",
            "\n",
            "--- Chunk 412 ---\n",
            "Deploying a Model to a Mobile or Embedded Device                                           685\n",
            "\n",
            "--- Chunk 413 ---\n",
            "Using GPUs to Speed Up Computations                                                                  689\n",
            "\n",
            "--- Chunk 414 ---\n",
            "Getting Your Own GPU                                                                                          690\n",
            "\n",
            "--- Chunk 415 ---\n",
            "Using a GPU-Equipped Virtual Machine                                                             692\n",
            "\n",
            "--- Chunk 416 ---\n",
            "Colaboratory                                                                                                             693\n",
            "\n",
            "--- Chunk 417 ---\n",
            "Managing the GPU RAM                                                                                       694\n",
            "\n",
            "--- Chunk 418 ---\n",
            "xii | Table of Contents\n",
            "\n",
            "--- Chunk 419 ---\n",
            "Placing Operations and Variables on Devices                                                     697\n",
            "\n",
            "--- Chunk 420 ---\n",
            "Parallel Execution Across Multiple Devices                                                         699\n",
            "\n",
            "--- Chunk 421 ---\n",
            "Training Models Across Multiple Devices                                                               701\n",
            "\n",
            "--- Chunk 422 ---\n",
            "Model Parallelism                                                                                                     701\n",
            "\n",
            "--- Chunk 423 ---\n",
            "Data Parallelism                                                                                                        704\n",
            "\n",
            "--- Chunk 424 ---\n",
            "Training at Scale Using the Distribution Strategies API                                    709\n",
            "\n",
            "--- Chunk 425 ---\n",
            "Training a Model on a TensorFlow Cluster                                                          711\n",
            "\n",
            "--- Chunk 426 ---\n",
            "Running Large Training Jobs on Google Cloud AI Platform                            714\n",
            "\n",
            "--- Chunk 427 ---\n",
            "Black Box Hyperparameter Tuning on AI Platform                                           716\n",
            "\n",
            "--- Chunk 428 ---\n",
            "Exercises                                                                                                                        717\n",
            "\n",
            "--- Chunk 429 ---\n",
            "Thank You!                                                                                                                   718\n",
            "\n",
            "--- Chunk 430 ---\n",
            "A. Exercise Solutions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  719\n",
            "\n",
            "--- Chunk 431 ---\n",
            "B. Machine Learning Project Checklist. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  755\n",
            "\n",
            "--- Chunk 432 ---\n",
            "C. SVM Dual Problem. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  761\n",
            "\n",
            "--- Chunk 433 ---\n",
            "D. Autodiff. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  765\n",
            "\n",
            "--- Chunk 434 ---\n",
            "E. Other Popular ANN Architectures. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  773\n",
            "\n",
            "--- Chunk 435 ---\n",
            "F. Special Data Structures. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  783\n",
            "\n",
            "--- Chunk 436 ---\n",
            "G. TensorFlow Graphs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  791\n",
            "\n",
            "--- Chunk 437 ---\n",
            "Index. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "\n",
            "--- Chunk 438 ---\n",
            ". . . . . . . . .  801\n",
            "\n",
            "--- Chunk 439 ---\n",
            "Table of Contents | xiii\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Preface\n",
            "\n",
            "--- Chunk 440 ---\n",
            "The Machine Learning Tsunami\n",
            "In 2006, Geoffrey Hinton et al. published a paper1 showing how to train a deep neural\n",
            "\n",
            "--- Chunk 441 ---\n",
            "network capable of recognizing handwritten digits with state-of-the-art precision\n",
            "\n",
            "--- Chunk 442 ---\n",
            "(>98%). They branded this technique “Deep Learning.” A deep neural network is a\n",
            "\n",
            "--- Chunk 443 ---\n",
            "(very) simplified model of our cerebral cortex, composed of a stack of layers of artifi‐\n",
            "\n",
            "--- Chunk 444 ---\n",
            "cial neurons. Training a deep neural net was widely considered impossible at the\n",
            "\n",
            "--- Chunk 445 ---\n",
            "time,2 and most researchers had abandoned the idea in the late 1990s. This paper\n",
            "\n",
            "--- Chunk 446 ---\n",
            "revived the interest of the scientific community, and before long many new papers\n",
            "\n",
            "--- Chunk 447 ---\n",
            "demonstrated that Deep Learning was not only possible, but capable of mind-\n",
            "\n",
            "--- Chunk 448 ---\n",
            "blowing achievements that no other Machine Learning (ML) technique could hope to\n",
            "\n",
            "--- Chunk 449 ---\n",
            "match (with the help of tremendous computing power and great amounts of data).\n",
            "This enthusiasm soon extended to many other areas of Machine Learning.\n",
            "\n",
            "--- Chunk 450 ---\n",
            "A decade or so later, Machine Learning has conquered the industry: it is at the heart\n",
            "\n",
            "--- Chunk 451 ---\n",
            "of much of the magic in today’s high-tech products, ranking your web search results,\n",
            "\n",
            "--- Chunk 452 ---\n",
            "powering your smartphone’s speech recognition, recommending videos, and beating\n",
            "\n",
            "--- Chunk 453 ---\n",
            "the world champion at the game of Go. Before you know it, it will be driving your car.\n",
            "\n",
            "--- Chunk 454 ---\n",
            "Machine Learning in Your Projects\n",
            "So, naturally you are excited about Machine Learning and would love to join the\n",
            "party!\n",
            "\n",
            "--- Chunk 455 ---\n",
            "1 Geoffrey E. Hinton et al., “A Fast Learning Algorithm for Deep Belief Nets,” Neural Computation 18 (2006):\n",
            "1527–1554.\n",
            "\n",
            "--- Chunk 456 ---\n",
            "2 Despite the fact that Yann LeCun’s deep convolutional neural networks had worked well for image recognition\n",
            "\n",
            "--- Chunk 457 ---\n",
            "since the 1990s, although they were not as general-purpose.\n",
            "\n",
            "--- Chunk 458 ---\n",
            "xv\n",
            "\n",
            "--- Chunk 459 ---\n",
            "Perhaps you would like to give your homemade robot a brain of its own? Make it rec‐\n",
            "ognize faces? Or learn to walk around?\n",
            "\n",
            "--- Chunk 460 ---\n",
            "Or maybe your company has tons of data (user logs, financial data, production data,\n",
            "\n",
            "--- Chunk 461 ---\n",
            "machine sensor data, hotline stats, HR reports, etc.), and more than likely you could\n",
            "\n",
            "--- Chunk 462 ---\n",
            "unearth some hidden gems if you just knew where to look. With Machine Learning,\n",
            "you could accomplish the following and more:\n",
            "\n",
            "--- Chunk 463 ---\n",
            "• Segment customers and find the best marketing strategy for each group.\n",
            "• Recommend products for each client based on what similar clients bought.\n",
            "\n",
            "--- Chunk 464 ---\n",
            "• Detect which transactions are likely to be fraudulent.\n",
            "• Forecast next year’s revenue.\n",
            "\n",
            "--- Chunk 465 ---\n",
            "Whatever the reason, you have decided to learn Machine Learning and implement it\n",
            "in your projects. Great idea!\n",
            "\n",
            "--- Chunk 466 ---\n",
            "Objective and Approach\n",
            "This book assumes that you know close to nothing about Machine Learning. Its goal\n",
            "\n",
            "--- Chunk 467 ---\n",
            "is to give you the concepts, tools, and intuition you need to implement programs\n",
            "capable of learning from data.\n",
            "\n",
            "--- Chunk 468 ---\n",
            "We will cover a large number of techniques, from the simplest and most commonly\n",
            "\n",
            "--- Chunk 469 ---\n",
            "used (such as Linear Regression) to some of the Deep Learning techniques that regu‐\n",
            "larly win competitions.\n",
            "\n",
            "--- Chunk 470 ---\n",
            "Rather than implementing our own toy versions of each algorithm, we will be using\n",
            "production-ready Python frameworks:\n",
            "\n",
            "--- Chunk 471 ---\n",
            "• Scikit-Learn is very easy to use, yet it implements many Machine Learning algo‐\n",
            "\n",
            "--- Chunk 472 ---\n",
            "rithms efficiently, so it makes for a great entry point to learning Machine Learn‐\n",
            "\n",
            "--- Chunk 473 ---\n",
            "ing. It was created by David Cournapeau in 2007, and is now led by a team of\n",
            "\n",
            "--- Chunk 474 ---\n",
            "researchers at the French Institute for Research in Computer Science and Auto‐\n",
            "mation (Inria).\n",
            "\n",
            "--- Chunk 475 ---\n",
            "• TensorFlow is a more complex library for distributed numerical computation. It\n",
            "\n",
            "--- Chunk 476 ---\n",
            "makes it possible to train and run very large neural networks efficiently by dis‐\n",
            "\n",
            "--- Chunk 477 ---\n",
            "tributing the computations across potentially hundreds of multi-GPU (graphics\n",
            "\n",
            "--- Chunk 478 ---\n",
            "processing unit) servers. TensorFlow (TF) was created at Google and supports\n",
            "\n",
            "--- Chunk 479 ---\n",
            "many of its large-scale Machine Learning applications. It was open sourced in\n",
            "November 2015, and version 2.0 was released in September 2019.\n",
            "\n",
            "--- Chunk 480 ---\n",
            "• Keras is a high-level Deep Learning API that makes it very simple to train and\n",
            "\n",
            "--- Chunk 481 ---\n",
            "run neural networks. It can run on top of either TensorFlow, Theano, or Micro‐\n",
            "\n",
            "--- Chunk 482 ---\n",
            "soft Cognitive Toolkit (formerly known as CNTK). TensorFlow comes with its\n",
            "\n",
            "--- Chunk 483 ---\n",
            "xvi | Preface\n",
            "\n",
            "--- Chunk 484 ---\n",
            "own implementation of this API, called tf.keras, which provides support for some\n",
            "\n",
            "--- Chunk 485 ---\n",
            "advanced TensorFlow features (e.g., the ability to efficiently load data).\n",
            "\n",
            "--- Chunk 486 ---\n",
            "The book favors a hands-on approach, growing an intuitive understanding of\n",
            "\n",
            "--- Chunk 487 ---\n",
            "Machine Learning through concrete working examples and just a little bit of theory.\n",
            "\n",
            "--- Chunk 488 ---\n",
            "While you can read this book without picking up your laptop, I highly recommend\n",
            "\n",
            "--- Chunk 489 ---\n",
            "you experiment with the code examples available online as Jupyter notebooks at\n",
            "https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 490 ---\n",
            "Prerequisites\n",
            "This book assumes that you have some Python programming experience and that you\n",
            "\n",
            "--- Chunk 491 ---\n",
            "are familiar with Python’s main scientific libraries—in particular, NumPy, pandas,\n",
            "and Matplotlib.\n",
            "\n",
            "--- Chunk 492 ---\n",
            "and Matplotlib.\n",
            "Also, if you care about what’s under the hood, you should have a reasonable under‐\n",
            "\n",
            "--- Chunk 493 ---\n",
            "standing of college-level math as well (calculus, linear algebra, probabilities, and sta‐\n",
            "tistics).\n",
            "\n",
            "--- Chunk 494 ---\n",
            "tistics).\n",
            "If you don’t know Python yet, http://learnpython.org/ is a great place to start. The offi‐\n",
            "cial tutorial on Python.org is also quite good.\n",
            "\n",
            "--- Chunk 495 ---\n",
            "If you have never used Jupyter, Chapter 2 will guide you through installation and the\n",
            "basics: it is a powerful tool to have in your toolbox.\n",
            "\n",
            "--- Chunk 496 ---\n",
            "If you are not familiar with Python’s scientific libraries, the provided Jupyter note‐\n",
            "\n",
            "--- Chunk 497 ---\n",
            "books include a few tutorials. There is also a quick math tutorial for linear algebra.\n",
            "\n",
            "--- Chunk 498 ---\n",
            "Roadmap\n",
            "This book is organized in two parts. Part I, The Fundamentals of Machine Learning,\n",
            "covers the following topics:\n",
            "\n",
            "--- Chunk 499 ---\n",
            "• What Machine Learning is, what problems it tries to solve, and the main cate‐\n",
            "gories and fundamental concepts of its systems\n",
            "\n",
            "--- Chunk 500 ---\n",
            "• The steps in a typical Machine Learning project\n",
            "• Learning by fitting a model to data\n",
            "• Optimizing a cost function\n",
            "\n",
            "--- Chunk 501 ---\n",
            "• Handling, cleaning, and preparing data\n",
            "• Selecting and engineering features\n",
            "• Selecting a model and tuning hyperparameters using cross-validation\n",
            "\n",
            "--- Chunk 502 ---\n",
            "• The challenges of Machine Learning, in particular underfitting and overfitting\n",
            "\n",
            "--- Chunk 503 ---\n",
            "(the bias/variance trade-off)\n",
            "\n",
            "Preface | xvii\n",
            "\n",
            "--- Chunk 504 ---\n",
            "• The most common learning algorithms: Linear and Polynomial Regression,\n",
            "Logistic Regression, k-Nearest Neighbors, Support Vector Machines, Decision\n",
            "\n",
            "--- Chunk 505 ---\n",
            "Trees, Random Forests, and Ensemble methods\n",
            "\n",
            "--- Chunk 506 ---\n",
            "• Reducing the dimensionality of the training data to fight the “curse of dimen‐\n",
            "sionality”\n",
            "\n",
            "--- Chunk 507 ---\n",
            "• Other unsupervised learning techniques, including clustering, density estima‐\n",
            "tion, and anomaly detection\n",
            "\n",
            "--- Chunk 508 ---\n",
            "Part II, Neural Networks and Deep Learning, covers the following topics:\n",
            "\n",
            "--- Chunk 509 ---\n",
            "• What neural nets are and what they’re good for\n",
            "• Building and training neural nets using TensorFlow and Keras\n",
            "\n",
            "--- Chunk 510 ---\n",
            "• The most important neural net architectures: feedforward neural nets for tabular\n",
            "\n",
            "--- Chunk 511 ---\n",
            "data, convolutional nets for computer vision, recurrent nets and long short-term\n",
            "\n",
            "--- Chunk 512 ---\n",
            "memory (LSTM) nets for sequence processing, encoder/decoders and Trans‐\n",
            "\n",
            "--- Chunk 513 ---\n",
            "formers for natural language processing, autoencoders and generative adversarial\n",
            "networks (GANs) for generative learning\n",
            "\n",
            "--- Chunk 514 ---\n",
            "• Techniques for training deep neural nets\n",
            "• How to build an agent (e.g., a bot in a game) that can learn good strategies\n",
            "\n",
            "--- Chunk 515 ---\n",
            "through trial and error, using Reinforcement Learning\n",
            "• Loading and preprocessing large amounts of data efficiently\n",
            "\n",
            "--- Chunk 516 ---\n",
            "• Training and deploying TensorFlow models at scale\n",
            "\n",
            "--- Chunk 517 ---\n",
            "The first part is based mostly on Scikit-Learn, while the second part uses TensorFlow\n",
            "and Keras.\n",
            "\n",
            "--- Chunk 518 ---\n",
            "Don’t jump into deep waters too hastily: while Deep Learning is no\n",
            "doubt one of the most exciting areas in Machine Learning, you\n",
            "\n",
            "--- Chunk 519 ---\n",
            "should master the fundamentals first. Moreover, most problems\n",
            "can be solved quite well using simpler techniques such as Random\n",
            "\n",
            "--- Chunk 520 ---\n",
            "Forests and Ensemble methods (discussed in Part I). Deep Learn‐\n",
            "ing is best suited for complex problems such as image recognition,\n",
            "\n",
            "--- Chunk 521 ---\n",
            "speech recognition, or natural language processing, provided you\n",
            "have enough data, computing power, and patience.\n",
            "\n",
            "--- Chunk 522 ---\n",
            "xviii | Preface\n",
            "\n",
            "\n",
            "\n",
            "Changes in the Second Edition\n",
            "This second edition has six main objectives:\n",
            "\n",
            "--- Chunk 523 ---\n",
            "1. Cover additional ML topics: more unsupervised learning techniques (including\n",
            "\n",
            "--- Chunk 524 ---\n",
            "clustering, anomaly detection, density estimation, and mixture models); more\n",
            "\n",
            "--- Chunk 525 ---\n",
            "techniques for training deep nets (including self-normalized networks); addi‐\n",
            "\n",
            "--- Chunk 526 ---\n",
            "tional computer vision techniques (including Xception, SENet, object detection\n",
            "with YOLO, and semantic segmentation using R-CNN); handling sequences\n",
            "\n",
            "--- Chunk 527 ---\n",
            "using covolutional neural networks (CNNs, including WaveNet); natural lan‐\n",
            "guage processing using recurrent neural networks (RNNs), CNNs, and Trans‐\n",
            "\n",
            "--- Chunk 528 ---\n",
            "formers; and GANs.\n",
            "\n",
            "--- Chunk 529 ---\n",
            "2. Cover additional libraries and APIs (Keras, the Data API, TF-Agents for Rein‐\n",
            "\n",
            "--- Chunk 530 ---\n",
            "forcement Learning) and training and deploying TF models at scale using the\n",
            "\n",
            "--- Chunk 531 ---\n",
            "Distribution Strategies API, TF-Serving, and Google Cloud AI Platform. Also\n",
            "\n",
            "--- Chunk 532 ---\n",
            "briefly introduce TF Transform, TFLite, TF Addons/Seq2Seq, and TensorFlow.js.\n",
            "\n",
            "--- Chunk 533 ---\n",
            "3. Discuss some of the latest important results from Deep Learning research.\n",
            "\n",
            "--- Chunk 534 ---\n",
            "4. Migrate all TensorFlow chapters to TensorFlow 2, and use TensorFlow’s imple‐\n",
            "\n",
            "--- Chunk 535 ---\n",
            "mentation of the Keras API (tf.keras) whenever possible.\n",
            "5. Update the code examples to use the latest versions of Scikit-Learn, NumPy, pan‐\n",
            "\n",
            "--- Chunk 536 ---\n",
            "das, Matplotlib, and other libraries.\n",
            "6. Clarify some sections and fix some errors, thanks to plenty of great feedback\n",
            "\n",
            "from readers.\n",
            "\n",
            "--- Chunk 537 ---\n",
            "Some chapters were added, others were rewritten, and a few were reordered. See\n",
            "\n",
            "--- Chunk 538 ---\n",
            "https://homl.info/changes2 for more details on what changed in the second edition.\n",
            "\n",
            "--- Chunk 539 ---\n",
            "Other Resources\n",
            "Many excellent resources are available to learn about Machine Learning. For example,\n",
            "\n",
            "--- Chunk 540 ---\n",
            "Andrew Ng’s ML course on Coursera is amazing, although it requires a significant\n",
            "time investment (think months).\n",
            "\n",
            "--- Chunk 541 ---\n",
            "There are also many interesting websites about Machine Learning, including of\n",
            "\n",
            "--- Chunk 542 ---\n",
            "course Scikit-Learn’s exceptional User Guide. You may also enjoy Dataquest, which\n",
            "\n",
            "--- Chunk 543 ---\n",
            "provides very nice interactive tutorials, and ML blogs such as those listed on Quora.\n",
            "\n",
            "--- Chunk 544 ---\n",
            "Finally, the Deep Learning website has a good list of resources to check out to learn\n",
            "more.\n",
            "\n",
            "--- Chunk 545 ---\n",
            "more.\n",
            "There are many other introductory books about Machine Learning. In particular:\n",
            "\n",
            "--- Chunk 546 ---\n",
            "Preface | xix\n",
            "\n",
            "--- Chunk 547 ---\n",
            "• Joel Grus’s Data Science from Scratch (O’Reilly) presents the fundamentals of\n",
            "\n",
            "--- Chunk 548 ---\n",
            "Machine Learning and implements some of the main algorithms in pure Python\n",
            "(from scratch, as the name suggests).\n",
            "\n",
            "--- Chunk 549 ---\n",
            "• Stephen Marsland’s Machine Learning: An Algorithmic Perspective (Chapman &\n",
            "\n",
            "--- Chunk 550 ---\n",
            "Hall) is a great introduction to Machine Learning, covering a wide range of topics\n",
            "\n",
            "--- Chunk 551 ---\n",
            "in depth with code examples in Python (also from scratch, but using NumPy).\n",
            "\n",
            "--- Chunk 552 ---\n",
            "• Sebastian Raschka’s Python Machine Learning (Packt Publishing) is also a great\n",
            "\n",
            "--- Chunk 553 ---\n",
            "introduction to Machine Learning and leverages Python open source libraries\n",
            "(Pylearn 2 and Theano).\n",
            "\n",
            "--- Chunk 554 ---\n",
            "• François Chollet’s Deep Learning with Python (Manning) is a very practical book\n",
            "\n",
            "--- Chunk 555 ---\n",
            "that covers a large range of topics in a clear and concise way, as you might expect\n",
            "\n",
            "--- Chunk 556 ---\n",
            "from the author of the excellent Keras library. It favors code examples over math‐\n",
            "ematical theory.\n",
            "\n",
            "--- Chunk 557 ---\n",
            "• Andriy Burkov’s The Hundred-Page Machine Learning Book is very short and cov‐\n",
            "\n",
            "--- Chunk 558 ---\n",
            "ers an impressive range of topics, introducing them in approachable terms\n",
            "without shying away from the math equations.\n",
            "\n",
            "--- Chunk 559 ---\n",
            "• Yaser S. Abu-Mostafa, Malik Magdon-Ismail, and Hsuan-Tien Lin’s Learning from\n",
            "\n",
            "--- Chunk 560 ---\n",
            "Data (AMLBook) is a rather theoretical approach to ML that provides deep\n",
            "insights, in particular on the bias/variance trade-off (see Chapter 4).\n",
            "\n",
            "--- Chunk 561 ---\n",
            "• Stuart Russell and Peter Norvig’s Artificial Intelligence: A Modern Approach, 3rd\n",
            "\n",
            "--- Chunk 562 ---\n",
            "Edition (Pearson), is a great (and huge) book covering an incredible amount of\n",
            "topics, including Machine Learning. It helps put ML into perspective.\n",
            "\n",
            "--- Chunk 563 ---\n",
            "Finally, joining ML competition websites such as Kaggle.com will allow you to prac‐\n",
            "\n",
            "--- Chunk 564 ---\n",
            "tice your skills on real-world problems, with help and insights from some of the best\n",
            "ML professionals out there.\n",
            "\n",
            "--- Chunk 565 ---\n",
            "Conventions Used in This Book\n",
            "The following typographical conventions are used in this book:\n",
            "Italic\n",
            "\n",
            "--- Chunk 566 ---\n",
            "Indicates new terms, URLs, email addresses, filenames, and file extensions.\n",
            "Constant width\n",
            "\n",
            "--- Chunk 567 ---\n",
            "Used for program listings, as well as within paragraphs to refer to program ele‐\n",
            "\n",
            "--- Chunk 568 ---\n",
            "ments such as variable or function names, databases, data types, environment\n",
            "variables, statements and keywords.\n",
            "\n",
            "--- Chunk 569 ---\n",
            "Constant width bold\n",
            "Shows commands or other text that should be typed literally by the user.\n",
            "\n",
            "xx | Preface\n",
            "\n",
            "--- Chunk 570 ---\n",
            "xx | Preface\n",
            "\n",
            "\n",
            "\n",
            "Constant width italic\n",
            "Shows text that should be replaced with user-supplied values or by values deter‐\n",
            "mined by context.\n",
            "\n",
            "--- Chunk 571 ---\n",
            "This element signifies a tip or suggestion.\n",
            "\n",
            "This element signifies a general note.\n",
            "\n",
            "This element indicates a warning or caution.\n",
            "\n",
            "--- Chunk 572 ---\n",
            "Code Examples\n",
            "There is a series of Jupyter notebooks full of supplemental material, such as code\n",
            "\n",
            "--- Chunk 573 ---\n",
            "examples and exercises, available for download at https://github.com/ageron/handson-\n",
            "ml2.\n",
            "\n",
            "--- Chunk 574 ---\n",
            "ml2.\n",
            "Some of the code examples in the book leave out repetitive sections or details that are\n",
            "\n",
            "--- Chunk 575 ---\n",
            "obvious or unrelated to Machine Learning. This keeps the focus on the important\n",
            "\n",
            "--- Chunk 576 ---\n",
            "parts of the code and saves space to cover more topics. If you want the full code\n",
            "examples, they are all available in the Jupyter notebooks.\n",
            "\n",
            "--- Chunk 577 ---\n",
            "Note that when the code examples display some outputs, these code examples are\n",
            "\n",
            "--- Chunk 578 ---\n",
            "shown with Python prompts (>>> and ...), as in a Python shell, to clearly distinguish\n",
            "\n",
            "--- Chunk 579 ---\n",
            "the code from the outputs. For example, this code defines the square() function,\n",
            "then it computes and displays the square of 3:\n",
            "\n",
            "--- Chunk 580 ---\n",
            ">>> def square(x):\n",
            "...     return x ** 2\n",
            "...\n",
            ">>> result = square(3)\n",
            ">>> result\n",
            "9\n",
            "\n",
            "--- Chunk 581 ---\n",
            "When code does not display anything, prompts are not used. However, the result may\n",
            "sometimes be shown as a comment, like this:\n",
            "\n",
            "Preface | xxi\n",
            "\n",
            "--- Chunk 582 ---\n",
            "Preface | xxi\n",
            "\n",
            "\n",
            "\n",
            "def square(x):\n",
            "    return x ** 2\n",
            "\n",
            "result = square(3)  # result is 9\n",
            "\n",
            "--- Chunk 583 ---\n",
            "Using Code Examples\n",
            "This book is here to help you get your job done. In general, if example code is offered\n",
            "\n",
            "--- Chunk 584 ---\n",
            "with this book, you may use it in your programs and documentation. You do not\n",
            "\n",
            "--- Chunk 585 ---\n",
            "need to contact us for permission unless you’re reproducing a significant portion of\n",
            "\n",
            "--- Chunk 586 ---\n",
            "the code. For example, writing a program that uses several chunks of code from this\n",
            "\n",
            "--- Chunk 587 ---\n",
            "book does not require permission. Selling or distributing a CD-ROM of examples\n",
            "\n",
            "--- Chunk 588 ---\n",
            "from O’Reilly books does require permission. Answering a question by citing this\n",
            "\n",
            "--- Chunk 589 ---\n",
            "book and quoting example code does not require permission. Incorporating a signifi‐\n",
            "\n",
            "--- Chunk 590 ---\n",
            "cant amount of example code from this book into your product’s documentation does\n",
            "require permission.\n",
            "\n",
            "--- Chunk 591 ---\n",
            "require permission.\n",
            "We appreciate, but do not require, attribution. An attribution usually includes the\n",
            "\n",
            "--- Chunk 592 ---\n",
            "title, author, publisher, and ISBN. For example: “Hands-On Machine Learning with\n",
            "\n",
            "--- Chunk 593 ---\n",
            "Scikit-Learn, Keras, and TensorFlow, 2nd Edition, by Aurélien Géron (O’Reilly).\n",
            "\n",
            "--- Chunk 594 ---\n",
            "Copyright 2019 Kiwisoft S.A.S., 978-1-492-03264-9.” If you feel your use of code\n",
            "\n",
            "--- Chunk 595 ---\n",
            "examples falls outside fair use or the permission given above, feel free to contact us at\n",
            "permissions@oreilly.com.\n",
            "\n",
            "--- Chunk 596 ---\n",
            "O’Reilly Online Learning\n",
            "For almost 40 years, O’Reilly Media has provided technology\n",
            "and business training, knowledge, and insight to help compa‐\n",
            "\n",
            "--- Chunk 597 ---\n",
            "nies succeed.\n",
            "\n",
            "--- Chunk 598 ---\n",
            "Our unique network of experts and innovators share their knowledge and expertise\n",
            "\n",
            "--- Chunk 599 ---\n",
            "through books, articles, conferences, and our online learning platform. O’Reilly’s\n",
            "\n",
            "--- Chunk 600 ---\n",
            "online learning platform gives you on-demand access to live training courses, in-\n",
            "\n",
            "--- Chunk 601 ---\n",
            "depth learning paths, interactive coding environments, and a vast collection of text\n",
            "\n",
            "--- Chunk 602 ---\n",
            "and video from O’Reilly and 200+ other publishers. For more information, please\n",
            "visit http://oreilly.com.\n",
            "\n",
            "--- Chunk 603 ---\n",
            "xxii | Preface\n",
            "\n",
            "\n",
            "\n",
            "How to Contact Us\n",
            "Please address comments and questions concerning this book to the publisher:\n",
            "\n",
            "--- Chunk 604 ---\n",
            "O’Reilly Media, Inc.\n",
            "1005 Gravenstein Highway North\n",
            "Sebastopol, CA 95472\n",
            "800-998-9938 (in the United States or Canada)\n",
            "\n",
            "--- Chunk 605 ---\n",
            "707-829-0515 (international or local)\n",
            "707-829-0104 (fax)\n",
            "\n",
            "--- Chunk 606 ---\n",
            "We have a web page for this book, where we list errata, examples, and any additional\n",
            "\n",
            "--- Chunk 607 ---\n",
            "information. You can access this page at https://homl.info/oreilly2.\n",
            "To comment or ask technical questions about this book, send email to bookques‐\n",
            "\n",
            "--- Chunk 608 ---\n",
            "tions@oreilly.com.\n",
            "For more information about our books, courses, conferences, and news, see our web‐\n",
            "site at http://www.oreilly.com.\n",
            "\n",
            "--- Chunk 609 ---\n",
            "Find us on Facebook: http://facebook.com/oreilly\n",
            "Follow us on Twitter: http://twitter.com/oreillymedia\n",
            "\n",
            "--- Chunk 610 ---\n",
            "Watch us on YouTube: http://www.youtube.com/oreillymedia\n",
            "\n",
            "--- Chunk 611 ---\n",
            "Acknowledgments\n",
            "Never in my wildest dreams did I imagine that the first edition of this book would get\n",
            "\n",
            "--- Chunk 612 ---\n",
            "such a large audience. I received so many messages from readers, many asking ques‐\n",
            "\n",
            "--- Chunk 613 ---\n",
            "tions, some kindly pointing out errata, and most sending me encouraging words. I\n",
            "\n",
            "--- Chunk 614 ---\n",
            "cannot express how grateful I am to all these readers for their tremendous support.\n",
            "\n",
            "--- Chunk 615 ---\n",
            "Thank you all so very much! Please do not hesitate to file issues on GitHub if you find\n",
            "\n",
            "--- Chunk 616 ---\n",
            "errors in the code examples (or just to ask questions), or to submit errata if you find\n",
            "\n",
            "--- Chunk 617 ---\n",
            "errors in the text. Some readers also shared how this book helped them get their first\n",
            "\n",
            "--- Chunk 618 ---\n",
            "job, or how it helped them solve a concrete problem they were working on. I find\n",
            "\n",
            "--- Chunk 619 ---\n",
            "such feedback incredibly motivating. If you find this book helpful, I would love it if\n",
            "\n",
            "--- Chunk 620 ---\n",
            "you could share your story with me, either privately (e.g., via LinkedIn) or publicly\n",
            "(e.g., in a tweet or through an Amazon review).\n",
            "\n",
            "--- Chunk 621 ---\n",
            "I am also incredibly thankful to all the amazing people who took time out of their\n",
            "\n",
            "--- Chunk 622 ---\n",
            "busy lives to review my book with such care. In particular, I would like to thank Fran‐\n",
            "\n",
            "--- Chunk 623 ---\n",
            "çois Chollet for reviewing all the chapters based on Keras and TensorFlow and giving\n",
            "\n",
            "--- Chunk 624 ---\n",
            "me some great in-depth feedback. Since Keras is one of the main additions to this sec‐\n",
            "\n",
            "--- Chunk 625 ---\n",
            "ond edition, having its author review the book was invaluable. I highly recommend\n",
            "\n",
            "--- Chunk 626 ---\n",
            "Preface | xxiii\n",
            "\n",
            "--- Chunk 627 ---\n",
            "François’s book Deep Learning with Python (Manning): it has the conciseness, clarity,\n",
            "\n",
            "--- Chunk 628 ---\n",
            "and depth of the Keras library itself. Special thanks as well to Ankur Patel, who\n",
            "\n",
            "--- Chunk 629 ---\n",
            "reviewed every chapter of this second edition and gave me excellent feedback, in par‐\n",
            "\n",
            "--- Chunk 630 ---\n",
            "ticular on Chapter 9, which covers unsupervised learning techniques. He could write\n",
            "\n",
            "--- Chunk 631 ---\n",
            "a whole book on the topic… oh, wait, he did! Do check out Hands-On Unsupervised\n",
            "\n",
            "--- Chunk 632 ---\n",
            "Learning Using Python: How to Build Applied Machine Learning Solutions from Unla‐\n",
            "\n",
            "--- Chunk 633 ---\n",
            "beled Data (O’Reilly). Huge thanks as well to Olzhas Akpambetov, who reviewed all\n",
            "\n",
            "--- Chunk 634 ---\n",
            "the chapters in the second part of the book, tested much of the code, and offered\n",
            "\n",
            "--- Chunk 635 ---\n",
            "many great suggestions. I’m grateful to Mark Daoust, Jon Krohn, Dominic Monn,\n",
            "\n",
            "--- Chunk 636 ---\n",
            "and Josh Patterson for reviewing the second part of this book so thoroughly and\n",
            "\n",
            "--- Chunk 637 ---\n",
            "offering their expertise. They left no stone unturned and provided amazingly useful\n",
            "feedback.\n",
            "\n",
            "--- Chunk 638 ---\n",
            "feedback.\n",
            "While writing this second edition, I was fortunate enough to get plenty of help from\n",
            "\n",
            "--- Chunk 639 ---\n",
            "members of the TensorFlow team—in particular Martin Wicke, who tirelessly\n",
            "\n",
            "--- Chunk 640 ---\n",
            "answered dozens of my questions and dispatched the rest to the right people, includ‐\n",
            "\n",
            "--- Chunk 641 ---\n",
            "ing Karmel Allison, Paige Bailey, Eugene Brevdo, William Chargin, Daniel “Wolff ”\n",
            "\n",
            "--- Chunk 642 ---\n",
            "Dobson, Nick Felt, Bruce Fontaine, Goldie Gadde, Sandeep Gupta, Priya Gupta,\n",
            "\n",
            "--- Chunk 643 ---\n",
            "Kevin Haas, Konstantinos Katsiapis ,Viacheslav Kovalevskyi, Allen Lavoie, Clemens\n",
            "\n",
            "--- Chunk 644 ---\n",
            "Mewald, Dan Moldovan, Sean Morgan, Tom O’Malley, Alexandre Passos, André Sus‐\n",
            "\n",
            "--- Chunk 645 ---\n",
            "ano Pinto, Anthony Platanios, Oscar Ramirez, Anna Revinskaya, Saurabh Saxena,\n",
            "\n",
            "--- Chunk 646 ---\n",
            "Ryan Sepassi, Jiri Simsa, Xiaodan Song, Christina Sorokin, Dustin Tran, Todd Wang,\n",
            "\n",
            "--- Chunk 647 ---\n",
            "Pete Warden (who also reviewed the first edition) Edd Wilder-James, and Yuefeng\n",
            "\n",
            "--- Chunk 648 ---\n",
            "Zhou, all of whom were tremendously helpful. Huge thanks to all of you, and to all\n",
            "\n",
            "--- Chunk 649 ---\n",
            "other members of the TensorFlow team, not just for your help, but also for making\n",
            "\n",
            "--- Chunk 650 ---\n",
            "such a great library! Special thanks to Irene Giannoumis and Robert Crowe of the\n",
            "TFX team for reviewing Chapters 13 and 19 in depth.\n",
            "\n",
            "--- Chunk 651 ---\n",
            "Many thanks as well to O’Reilly’s fantastic staff, in particular Nicole Taché, who gave\n",
            "\n",
            "--- Chunk 652 ---\n",
            "me insightful feedback and was always cheerful, encouraging, and helpful: I could not\n",
            "\n",
            "--- Chunk 653 ---\n",
            "dream of a better editor. Big thanks to Michele Cronin as well, who was very helpful\n",
            "\n",
            "--- Chunk 654 ---\n",
            "(and patient) at the start of this second edition, and to Kristen Brown, the production\n",
            "\n",
            "--- Chunk 655 ---\n",
            "editor for the second edition, who saw it through all the steps (she also coordinated\n",
            "\n",
            "--- Chunk 656 ---\n",
            "fixes and updates for each reprint of the first edition). Thanks as well to Rachel Mon‐\n",
            "\n",
            "--- Chunk 657 ---\n",
            "aghan and Amanda Kersey for their thorough copyediting (respectively for the first\n",
            "\n",
            "--- Chunk 658 ---\n",
            "and second edition), and to Johnny O’Toole who managed the relationship with\n",
            "\n",
            "--- Chunk 659 ---\n",
            "Amazon and answered many of my questions. Thanks to Marie Beaugureau, Ben\n",
            "\n",
            "--- Chunk 660 ---\n",
            "Lorica, Mike Loukides, and Laurel Ruma for believing in this project and helping me\n",
            "\n",
            "--- Chunk 661 ---\n",
            "define its scope. Thanks to Matt Hacker and all of the Atlas team for answering all my\n",
            "\n",
            "--- Chunk 662 ---\n",
            "technical questions regarding formatting, AsciiDoc, and LaTeX, and thanks to Nick\n",
            "\n",
            "--- Chunk 663 ---\n",
            "Adams, Rebecca Demarest, Rachel Head, Judith McConville, Helen Monroe, Karen\n",
            "\n",
            "--- Chunk 664 ---\n",
            "Montgomery, Rachel Roumeliotis, and everyone else at O’Reilly who contributed to\n",
            "this book.\n",
            "\n",
            "--- Chunk 665 ---\n",
            "xxiv | Preface\n",
            "\n",
            "--- Chunk 666 ---\n",
            "I would also like to thank my former Google colleagues, in particular the YouTube\n",
            "\n",
            "--- Chunk 667 ---\n",
            "video classification team, for teaching me so much about Machine Learning. I could\n",
            "\n",
            "--- Chunk 668 ---\n",
            "never have started the first edition without them. Special thanks to my personal ML\n",
            "\n",
            "--- Chunk 669 ---\n",
            "gurus: Clément Courbet, Julien Dubois, Mathias Kende, Daniel Kitachewsky, James\n",
            "\n",
            "--- Chunk 670 ---\n",
            "Pack, Alexander Pak, Anosh Raj, Vitor Sessak, Wiktor Tomczak, Ingrid von Glehn,\n",
            "\n",
            "--- Chunk 671 ---\n",
            "and Rich Washington. And thanks to everyone else I worked with at YouTube and in\n",
            "\n",
            "--- Chunk 672 ---\n",
            "the amazing Google research teams in Mountain View. Many thanks as well to Martin\n",
            "\n",
            "--- Chunk 673 ---\n",
            "Andrews, Sam Witteveen, and Jason Zaman for welcoming me into their Google\n",
            "\n",
            "--- Chunk 674 ---\n",
            "Developer Experts group in Singapore, with the kind support of Soonson Kwon, and\n",
            "\n",
            "--- Chunk 675 ---\n",
            "for all the great discussions we had about Deep Learning and TensorFlow. Anyone\n",
            "\n",
            "--- Chunk 676 ---\n",
            "interested in Deep Learning in Singapore should definitely join their Deep Learning\n",
            "\n",
            "--- Chunk 677 ---\n",
            "Singapore meetup. Jason deserves special thanks for sharing some of his TFLite\n",
            "expertise for Chapter 19!\n",
            "\n",
            "--- Chunk 678 ---\n",
            "I will never forget the kind people who reviewed the first edition of this book, includ‐\n",
            "\n",
            "--- Chunk 679 ---\n",
            "ing David Andrzejewski, Lukas Biewald, Justin Francis, Vincent Guilbeau, Eddy\n",
            "\n",
            "--- Chunk 680 ---\n",
            "Hung, Karim Matrah, Grégoire Mesnil, Salim Sémaoune, Iain Smears, Michel Tessier,\n",
            "\n",
            "--- Chunk 681 ---\n",
            "Ingrid von Glehn, Pete Warden, and of course my dear brother Sylvain. Special\n",
            "\n",
            "--- Chunk 682 ---\n",
            "thanks to Haesun Park, who gave me plenty of excellent feedback and caught several\n",
            "\n",
            "--- Chunk 683 ---\n",
            "errors while he was writing the Korean translation of the first edition of this book. He\n",
            "\n",
            "--- Chunk 684 ---\n",
            "also translated the Jupyter notebooks into Korean, not to mention TensorFlow’s doc‐\n",
            "\n",
            "--- Chunk 685 ---\n",
            "umentation. I do not speak Korean, but judging by the quality of his feedback, all his\n",
            "\n",
            "--- Chunk 686 ---\n",
            "translations must be truly excellent! Haesun also kindly contributed some of the solu‐\n",
            "tions to the exercises in this second edition.\n",
            "\n",
            "--- Chunk 687 ---\n",
            "Last but not least, I am infinitely grateful to my beloved wife, Emmanuelle, and to our\n",
            "\n",
            "--- Chunk 688 ---\n",
            "three wonderful children, Alexandre, Rémi, and Gabrielle, for encouraging me to\n",
            "\n",
            "--- Chunk 689 ---\n",
            "work hard on this book. I’m also thankful to them for their insatiable curiosity:\n",
            "\n",
            "--- Chunk 690 ---\n",
            "explaining some of the most difficult concepts in this book to my wife and children\n",
            "\n",
            "--- Chunk 691 ---\n",
            "helped me clarify my thoughts and directly improved many parts of it. And they keep\n",
            "bringing me cookies and coffee! What more can one dream of?\n",
            "\n",
            "--- Chunk 692 ---\n",
            "Preface | xxv\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "PART I\n",
            "The Fundamentals of\n",
            "\n",
            "Machine Learning\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER 1\n",
            "The Machine Learning Landscape\n",
            "\n",
            "--- Chunk 693 ---\n",
            "When most people hear “Machine Learning,” they picture a robot: a dependable but‐\n",
            "\n",
            "--- Chunk 694 ---\n",
            "ler or a deadly Terminator, depending on who you ask. But Machine Learning is not\n",
            "\n",
            "--- Chunk 695 ---\n",
            "just a futuristic fantasy; it’s already here. In fact, it has been around for decades in\n",
            "\n",
            "--- Chunk 696 ---\n",
            "some specialized applications, such as Optical Character Recognition (OCR). But the\n",
            "\n",
            "--- Chunk 697 ---\n",
            "first ML application that really became mainstream, improving the lives of hundreds\n",
            "\n",
            "--- Chunk 698 ---\n",
            "of millions of people, took over the world back in the 1990s: the spam filter. It’s not\n",
            "\n",
            "--- Chunk 699 ---\n",
            "exactly a self-aware Skynet, but it does technically qualify as Machine Learning (it has\n",
            "\n",
            "--- Chunk 700 ---\n",
            "actually learned so well that you seldom need to flag an email as spam anymore). It\n",
            "\n",
            "--- Chunk 701 ---\n",
            "was followed by hundreds of ML applications that now quietly power hundreds of\n",
            "\n",
            "--- Chunk 702 ---\n",
            "products and features that you use regularly, from better recommendations to voice\n",
            "search.\n",
            "\n",
            "--- Chunk 703 ---\n",
            "search.\n",
            "Where does Machine Learning start and where does it end? What exactly does it\n",
            "\n",
            "--- Chunk 704 ---\n",
            "mean for a machine to learn something? If I download a copy of Wikipedia, has my\n",
            "\n",
            "--- Chunk 705 ---\n",
            "computer really learned something? Is it suddenly smarter? In this chapter we will\n",
            "\n",
            "--- Chunk 706 ---\n",
            "start by clarifying what Machine Learning is and why you may want to use it.\n",
            "\n",
            "--- Chunk 707 ---\n",
            "Then, before we set out to explore the Machine Learning continent, we will take a\n",
            "\n",
            "--- Chunk 708 ---\n",
            "look at the map and learn about the main regions and the most notable landmarks:\n",
            "\n",
            "--- Chunk 709 ---\n",
            "supervised versus unsupervised learning, online versus batch learning, instance-\n",
            "\n",
            "--- Chunk 710 ---\n",
            "based versus model-based learning. Then we will look at the workflow of a typical ML\n",
            "\n",
            "--- Chunk 711 ---\n",
            "project, discuss the main challenges you may face, and cover how to evaluate and\n",
            "fine-tune a Machine Learning system.\n",
            "\n",
            "--- Chunk 712 ---\n",
            "This chapter introduces a lot of fundamental concepts (and jargon) that every data\n",
            "\n",
            "--- Chunk 713 ---\n",
            "scientist should know by heart. It will be a high-level overview (it’s the only chapter\n",
            "\n",
            "--- Chunk 714 ---\n",
            "without much code), all rather simple, but you should make sure everything is crystal\n",
            "\n",
            "--- Chunk 715 ---\n",
            "clear to you before continuing on to the rest of the book. So grab a coffee and let’s get\n",
            "started!\n",
            "\n",
            "--- Chunk 716 ---\n",
            "1\n",
            "\n",
            "--- Chunk 717 ---\n",
            "If you already know all the Machine Learning basics, you may want\n",
            "to skip directly to Chapter 2. If you are not sure, try to answer all\n",
            "\n",
            "--- Chunk 718 ---\n",
            "the questions listed at the end of the chapter before moving on.\n",
            "\n",
            "--- Chunk 719 ---\n",
            "What Is Machine Learning?\n",
            "Machine Learning is the science (and art) of programming computers so they can\n",
            "learn from data.\n",
            "\n",
            "--- Chunk 720 ---\n",
            "learn from data.\n",
            "Here is a slightly more general definition:\n",
            "\n",
            "--- Chunk 721 ---\n",
            "[Machine Learning is the] field of study that gives computers the ability to learn\n",
            "without being explicitly programmed.\n",
            "\n",
            "—Arthur Samuel, 1959\n",
            "\n",
            "--- Chunk 722 ---\n",
            "And a more engineering-oriented one:\n",
            "A computer program is said to learn from experience E with respect to some task T\n",
            "\n",
            "--- Chunk 723 ---\n",
            "and some performance measure P, if its performance on T, as measured by P,\n",
            "improves with experience E.\n",
            "\n",
            "--- Chunk 724 ---\n",
            "—Tom Mitchell, 1997\n",
            "\n",
            "--- Chunk 725 ---\n",
            "Your spam filter is a Machine Learning program that, given examples of spam emails\n",
            "\n",
            "--- Chunk 726 ---\n",
            "(e.g., flagged by users) and examples of regular (nonspam, also called “ham”) emails,\n",
            "\n",
            "--- Chunk 727 ---\n",
            "can learn to flag spam. The examples that the system uses to learn are called the train‐\n",
            "\n",
            "--- Chunk 728 ---\n",
            "ing set. Each training example is called a training instance (or sample). In this case, the\n",
            "\n",
            "--- Chunk 729 ---\n",
            "task T is to flag spam for new emails, the experience E is the training data, and the\n",
            "\n",
            "--- Chunk 730 ---\n",
            "performance measure P needs to be defined; for example, you can use the ratio of\n",
            "\n",
            "--- Chunk 731 ---\n",
            "correctly classified emails. This particular performance measure is called accuracy,\n",
            "and it is often used in classification tasks.\n",
            "\n",
            "--- Chunk 732 ---\n",
            "If you just download a copy of Wikipedia, your computer has a lot more data, but it is\n",
            "\n",
            "--- Chunk 733 ---\n",
            "not suddenly better at any task. Thus, downloading a copy of Wikipedia is not\n",
            "Machine Learning.\n",
            "\n",
            "--- Chunk 734 ---\n",
            "Why Use Machine Learning?\n",
            "Consider how you would write a spam filter using traditional programming techni‐\n",
            "ques (Figure 1-1):\n",
            "\n",
            "--- Chunk 735 ---\n",
            "1. First you would consider what spam typically looks like. You might notice that\n",
            "\n",
            "--- Chunk 736 ---\n",
            "some words or phrases (such as “4U,” “credit card,” “free,” and “amazing”) tend to\n",
            "\n",
            "--- Chunk 737 ---\n",
            "come up a lot in the subject line. Perhaps you would also notice a few other pat‐\n",
            "\n",
            "--- Chunk 738 ---\n",
            "terns in the sender’s name, the email’s body, and other parts of the email.\n",
            "\n",
            "--- Chunk 739 ---\n",
            "2 | Chapter 1: The Machine Learning Landscape\n",
            "\n",
            "--- Chunk 740 ---\n",
            "2. You would write a detection algorithm for each of the patterns that you noticed,\n",
            "\n",
            "--- Chunk 741 ---\n",
            "and your program would flag emails as spam if a number of these patterns were\n",
            "detected.\n",
            "\n",
            "--- Chunk 742 ---\n",
            "3. You would test your program and repeat steps 1 and 2 until it was good enough\n",
            "to launch.\n",
            "\n",
            "Figure 1-1. The traditional approach\n",
            "\n",
            "--- Chunk 743 ---\n",
            "Since the problem is difficult, your program will likely become a long list of complex\n",
            "rules—pretty hard to maintain.\n",
            "\n",
            "--- Chunk 744 ---\n",
            "In contrast, a spam filter based on Machine Learning techniques automatically learns\n",
            "\n",
            "--- Chunk 745 ---\n",
            "which words and phrases are good predictors of spam by detecting unusually fre‐\n",
            "\n",
            "--- Chunk 746 ---\n",
            "quent patterns of words in the spam examples compared to the ham examples\n",
            "\n",
            "--- Chunk 747 ---\n",
            "(Figure 1-2). The program is much shorter, easier to maintain, and most likely more\n",
            "accurate.\n",
            "\n",
            "--- Chunk 748 ---\n",
            "accurate.\n",
            "What if spammers notice that all their emails containing “4U” are blocked? They\n",
            "\n",
            "--- Chunk 749 ---\n",
            "might start writing “For U” instead. A spam filter using traditional programming\n",
            "\n",
            "--- Chunk 750 ---\n",
            "techniques would need to be updated to flag “For U” emails. If spammers keep work‐\n",
            "\n",
            "--- Chunk 751 ---\n",
            "ing around your spam filter, you will need to keep writing new rules forever.\n",
            "\n",
            "--- Chunk 752 ---\n",
            "In contrast, a spam filter based on Machine Learning techniques automatically noti‐\n",
            "\n",
            "--- Chunk 753 ---\n",
            "ces that “For U” has become unusually frequent in spam flagged by users, and it starts\n",
            "flagging them without your intervention (Figure 1-3).\n",
            "\n",
            "--- Chunk 754 ---\n",
            "Why Use Machine Learning? | 3\n",
            "\n",
            "\n",
            "\n",
            "Figure 1-2. The Machine Learning approach\n",
            "\n",
            "Figure 1-3. Automatically adapting to change\n",
            "\n",
            "--- Chunk 755 ---\n",
            "Another area where Machine Learning shines is for problems that either are too com‐\n",
            "\n",
            "--- Chunk 756 ---\n",
            "plex for traditional approaches or have no known algorithm. For example, consider\n",
            "\n",
            "--- Chunk 757 ---\n",
            "speech recognition. Say you want to start simple and write a program capable of dis‐\n",
            "\n",
            "--- Chunk 758 ---\n",
            "tinguishing the words “one” and “two.” You might notice that the word “two” starts\n",
            "\n",
            "--- Chunk 759 ---\n",
            "with a high-pitch sound (“T”), so you could hardcode an algorithm that measures\n",
            "\n",
            "--- Chunk 760 ---\n",
            "high-pitch sound intensity and use that to distinguish ones and twos—but obviously\n",
            "\n",
            "--- Chunk 761 ---\n",
            "this technique will not scale to thousands of words spoken by millions of very differ‐\n",
            "\n",
            "--- Chunk 762 ---\n",
            "ent people in noisy environments and in dozens of languages. The best solution (at\n",
            "\n",
            "--- Chunk 763 ---\n",
            "least today) is to write an algorithm that learns by itself, given many example record‐\n",
            "ings for each word.\n",
            "\n",
            "--- Chunk 764 ---\n",
            "ings for each word.\n",
            "Finally, Machine Learning can help humans learn (Figure 1-4). ML algorithms can be\n",
            "\n",
            "--- Chunk 765 ---\n",
            "inspected to see what they have learned (although for some algorithms this can be\n",
            "\n",
            "--- Chunk 766 ---\n",
            "tricky). For instance, once a spam filter has been trained on enough spam, it can\n",
            "\n",
            "--- Chunk 767 ---\n",
            "easily be inspected to reveal the list of words and combinations of words that it\n",
            "\n",
            "--- Chunk 768 ---\n",
            "believes are the best predictors of spam. Sometimes this will reveal unsuspected\n",
            "\n",
            "--- Chunk 769 ---\n",
            "4 | Chapter 1: The Machine Learning Landscape\n",
            "\n",
            "--- Chunk 770 ---\n",
            "correlations or new trends, and thereby lead to a better understanding of the prob‐\n",
            "\n",
            "--- Chunk 771 ---\n",
            "lem. Applying ML techniques to dig into large amounts of data can help discover pat‐\n",
            "\n",
            "--- Chunk 772 ---\n",
            "terns that were not immediately apparent. This is called data mining.\n",
            "\n",
            "--- Chunk 773 ---\n",
            "Figure 1-4. Machine Learning can help humans learn\n",
            "\n",
            "To summarize, Machine Learning is great for:\n",
            "\n",
            "--- Chunk 774 ---\n",
            "• Problems for which existing solutions require a lot of fine-tuning or long lists of\n",
            "\n",
            "--- Chunk 775 ---\n",
            "rules: one Machine Learning algorithm can often simplify code and perform bet‐\n",
            "ter than the traditional approach.\n",
            "\n",
            "--- Chunk 776 ---\n",
            "• Complex problems for which using a traditional approach yields no good solu‐\n",
            "\n",
            "--- Chunk 777 ---\n",
            "tion: the best Machine Learning techniques can perhaps find a solution.\n",
            "\n",
            "--- Chunk 778 ---\n",
            "• Fluctuating environments: a Machine Learning system can adapt to new data.\n",
            "• Getting insights about complex problems and large amounts of data.\n",
            "\n",
            "--- Chunk 779 ---\n",
            "Examples of Applications\n",
            "Let’s look at some concrete examples of Machine Learning tasks, along with the tech‐\n",
            "niques that can tackle them:\n",
            "\n",
            "--- Chunk 780 ---\n",
            "Analyzing images of products on a production line to automatically classify them\n",
            "\n",
            "--- Chunk 781 ---\n",
            "This is image classification, typically performed using convolutional neural net‐\n",
            "works (CNNs; see Chapter 14).\n",
            "\n",
            "Examples of Applications | 5\n",
            "\n",
            "--- Chunk 782 ---\n",
            "Detecting tumors in brain scans\n",
            "This is semantic segmentation, where each pixel in the image is classified (as we\n",
            "\n",
            "--- Chunk 783 ---\n",
            "want to determine the exact location and shape of tumors), typically using CNNs\n",
            "as well.\n",
            "\n",
            "--- Chunk 784 ---\n",
            "Automatically classifying news articles\n",
            "This is natural language processing (NLP), and more specifically text classifica‐\n",
            "\n",
            "--- Chunk 785 ---\n",
            "tion, which can be tackled using recurrent neural networks (RNNs), CNNs, or\n",
            "Transformers (see Chapter 16).\n",
            "\n",
            "--- Chunk 786 ---\n",
            "Automatically flagging offensive comments on discussion forums\n",
            "This is also text classification, using the same NLP tools.\n",
            "\n",
            "--- Chunk 787 ---\n",
            "Summarizing long documents automatically\n",
            "This is a branch of NLP called text summarization, again using the same tools.\n",
            "\n",
            "--- Chunk 788 ---\n",
            "Creating a chatbot or a personal assistant\n",
            "This involves many NLP components, including natural language understanding\n",
            "\n",
            "--- Chunk 789 ---\n",
            "(NLU) and question-answering modules.\n",
            "\n",
            "--- Chunk 790 ---\n",
            "Forecasting your company’s revenue next year, based on many performance metrics\n",
            "\n",
            "--- Chunk 791 ---\n",
            "This is a regression task (i.e., predicting values) that may be tackled using any\n",
            "\n",
            "--- Chunk 792 ---\n",
            "regression model, such as a Linear Regression or Polynomial Regression model\n",
            "\n",
            "--- Chunk 793 ---\n",
            "(see Chapter 4), a regression SVM (see Chapter 5), a regression Random Forest\n",
            "\n",
            "--- Chunk 794 ---\n",
            "(see Chapter 7), or an artificial neural network (see Chapter 10). If you want to\n",
            "\n",
            "--- Chunk 795 ---\n",
            "take into account sequences of past performance metrics, you may want to use\n",
            "RNNs, CNNs, or Transformers (see Chapters 15 and 16).\n",
            "\n",
            "--- Chunk 796 ---\n",
            "Making your app react to voice commands\n",
            "This is speech recognition, which requires processing audio samples: since they\n",
            "\n",
            "--- Chunk 797 ---\n",
            "are long and complex sequences, they are typically processed using RNNs, CNNs,\n",
            "or Transformers (see Chapters 15 and 16).\n",
            "\n",
            "--- Chunk 798 ---\n",
            "Detecting credit card fraud\n",
            "This is anomaly detection (see Chapter 9).\n",
            "\n",
            "--- Chunk 799 ---\n",
            "Segmenting clients based on their purchases so that you can design a different marketing\n",
            "strategy for each segment\n",
            "\n",
            "--- Chunk 800 ---\n",
            "This is clustering (see Chapter 9).\n",
            "Representing a complex, high-dimensional dataset in a clear and insightful diagram\n",
            "\n",
            "--- Chunk 801 ---\n",
            "This is data visualization, often involving dimensionality reduction techniques\n",
            "(see Chapter 8).\n",
            "\n",
            "--- Chunk 802 ---\n",
            "Recommending a product that a client may be interested in, based on past purchases\n",
            "\n",
            "--- Chunk 803 ---\n",
            "This is a recommender system. One approach is to feed past purchases (and\n",
            "\n",
            "--- Chunk 804 ---\n",
            "other information about the client) to an artificial neural network (see Chap‐\n",
            "\n",
            "--- Chunk 805 ---\n",
            "6 | Chapter 1: The Machine Learning Landscape\n",
            "\n",
            "--- Chunk 806 ---\n",
            "ter 10), and get it to output the most likely next purchase. This neural net would\n",
            "\n",
            "--- Chunk 807 ---\n",
            "typically be trained on past sequences of purchases across all clients.\n",
            "\n",
            "--- Chunk 808 ---\n",
            "Building an intelligent bot for a game\n",
            "This is often tackled using Reinforcement Learning (RL; see Chapter 18), which\n",
            "\n",
            "--- Chunk 809 ---\n",
            "is a branch of Machine Learning that trains agents (such as bots) to pick the\n",
            "\n",
            "--- Chunk 810 ---\n",
            "actions that will maximize their rewards over time (e.g., a bot may get a reward\n",
            "\n",
            "--- Chunk 811 ---\n",
            "every time the player loses some life points), within a given environment (such as\n",
            "\n",
            "--- Chunk 812 ---\n",
            "the game). The famous AlphaGo program that beat the world champion at the\n",
            "game of Go was built using RL.\n",
            "\n",
            "--- Chunk 813 ---\n",
            "This list could go on and on, but hopefully it gives you a sense of the incredible\n",
            "\n",
            "--- Chunk 814 ---\n",
            "breadth and complexity of the tasks that Machine Learning can tackle, and the types\n",
            "of techniques that you would use for each task.\n",
            "\n",
            "--- Chunk 815 ---\n",
            "Types of Machine Learning Systems\n",
            "There are so many different types of Machine Learning systems that it is useful to\n",
            "\n",
            "--- Chunk 816 ---\n",
            "classify them in broad categories, based on the following criteria:\n",
            "\n",
            "--- Chunk 817 ---\n",
            "• Whether or not they are trained with human supervision (supervised, unsuper‐\n",
            "vised, semisupervised, and Reinforcement Learning)\n",
            "\n",
            "--- Chunk 818 ---\n",
            "• Whether or not they can learn incrementally on the fly (online versus batch\n",
            "learning)\n",
            "\n",
            "--- Chunk 819 ---\n",
            "• Whether they work by simply comparing new data points to known data points,\n",
            "\n",
            "--- Chunk 820 ---\n",
            "or instead by detecting patterns in the training data and building a predictive\n",
            "\n",
            "--- Chunk 821 ---\n",
            "model, much like scientists do (instance-based versus model-based learning)\n",
            "\n",
            "--- Chunk 822 ---\n",
            "These criteria are not exclusive; you can combine them in any way you like. For\n",
            "\n",
            "--- Chunk 823 ---\n",
            "example, a state-of-the-art spam filter may learn on the fly using a deep neural net‐\n",
            "\n",
            "--- Chunk 824 ---\n",
            "work model trained using examples of spam and ham; this makes it an online, model-\n",
            "based, supervised learning system.\n",
            "\n",
            "--- Chunk 825 ---\n",
            "Let’s look at each of these criteria a bit more closely.\n",
            "\n",
            "--- Chunk 826 ---\n",
            "Supervised/Unsupervised Learning\n",
            "Machine Learning systems can be classified according to the amount and type of\n",
            "\n",
            "--- Chunk 827 ---\n",
            "supervision they get during training. There are four major categories: supervised\n",
            "\n",
            "--- Chunk 828 ---\n",
            "learning, unsupervised learning, semisupervised learning, and Reinforcement\n",
            "Learning.\n",
            "\n",
            "--- Chunk 829 ---\n",
            "Types of Machine Learning Systems | 7\n",
            "\n",
            "--- Chunk 830 ---\n",
            "Supervised learning\n",
            "In supervised learning, the training set you feed to the algorithm includes the desired\n",
            "solutions, called labels (Figure 1-5).\n",
            "\n",
            "--- Chunk 831 ---\n",
            "Figure 1-5. A labeled training set for spam classification (an example of supervised\n",
            "learning)\n",
            "\n",
            "--- Chunk 832 ---\n",
            "A typical supervised learning task is classification. The spam filter is a good example\n",
            "\n",
            "--- Chunk 833 ---\n",
            "of this: it is trained with many example emails along with their class (spam or ham),\n",
            "and it must learn how to classify new emails.\n",
            "\n",
            "--- Chunk 834 ---\n",
            "Another typical task is to predict a target numeric value, such as the price of a car,\n",
            "\n",
            "--- Chunk 835 ---\n",
            "given a set of features (mileage, age, brand, etc.) called predictors. This sort of task is\n",
            "\n",
            "--- Chunk 836 ---\n",
            "called regression (Figure 1-6).1 To train the system, you need to give it many examples\n",
            "\n",
            "--- Chunk 837 ---\n",
            "of cars, including both their predictors and their labels (i.e., their prices).\n",
            "\n",
            "--- Chunk 838 ---\n",
            "In Machine Learning an attribute is a data type (e.g., “mileage”),\n",
            "while a feature has several meanings, depending on the context, but\n",
            "\n",
            "--- Chunk 839 ---\n",
            "generally means an attribute plus its value (e.g., “mileage =\n",
            "15,000”). Many people use the words attribute and feature inter‐\n",
            "changeably.\n",
            "\n",
            "--- Chunk 840 ---\n",
            "Note that some regression algorithms can be used for classification as well, and vice\n",
            "\n",
            "--- Chunk 841 ---\n",
            "versa. For example, Logistic Regression is commonly used for classification, as it can\n",
            "\n",
            "--- Chunk 842 ---\n",
            "output a value that corresponds to the probability of belonging to a given class (e.g.,\n",
            "20% chance of being spam).\n",
            "\n",
            "--- Chunk 843 ---\n",
            "1 Fun fact: this odd-sounding name is a statistics term introduced by Francis Galton while he was studying the\n",
            "\n",
            "--- Chunk 844 ---\n",
            "fact that the children of tall people tend to be shorter than their parents. Since the children were shorter, he\n",
            "\n",
            "--- Chunk 845 ---\n",
            "called this regression to the mean. This name was then applied to the methods he used to analyze correlations\n",
            "between variables.\n",
            "\n",
            "--- Chunk 846 ---\n",
            "8 | Chapter 1: The Machine Learning Landscape\n",
            "\n",
            "--- Chunk 847 ---\n",
            "Figure 1-6. A regression problem: predict a value, given an input feature (there are usu‐\n",
            "\n",
            "--- Chunk 848 ---\n",
            "ally multiple input features, and sometimes multiple output values)\n",
            "\n",
            "--- Chunk 849 ---\n",
            "Here are some of the most important supervised learning algorithms (covered in this\n",
            "book):\n",
            "\n",
            "--- Chunk 850 ---\n",
            "• k-Nearest Neighbors\n",
            "• Linear Regression\n",
            "• Logistic Regression\n",
            "• Support Vector Machines (SVMs)\n",
            "• Decision Trees and Random Forests\n",
            "\n",
            "--- Chunk 851 ---\n",
            "• Neural networks2\n",
            "\n",
            "--- Chunk 852 ---\n",
            "Unsupervised learning\n",
            "In unsupervised learning, as you might guess, the training data is unlabeled\n",
            "\n",
            "--- Chunk 853 ---\n",
            "(Figure 1-7). The system tries to learn without a teacher.\n",
            "\n",
            "--- Chunk 854 ---\n",
            "2 Some neural network architectures can be unsupervised, such as autoencoders and restricted Boltzmann\n",
            "\n",
            "--- Chunk 855 ---\n",
            "machines. They can also be semisupervised, such as in deep belief networks and unsupervised pretraining.\n",
            "\n",
            "--- Chunk 856 ---\n",
            "Types of Machine Learning Systems | 9\n",
            "\n",
            "\n",
            "\n",
            "Figure 1-7. An unlabeled training set for unsupervised learning\n",
            "\n",
            "--- Chunk 857 ---\n",
            "Here are some of the most important unsupervised learning algorithms (most of\n",
            "these are covered in Chapters 8 and 9):\n",
            "\n",
            "--- Chunk 858 ---\n",
            "• Clustering\n",
            "— K-Means\n",
            "— DBSCAN\n",
            "— Hierarchical Cluster Analysis (HCA)\n",
            "\n",
            "• Anomaly detection and novelty detection\n",
            "— One-class SVM\n",
            "— Isolation Forest\n",
            "\n",
            "--- Chunk 859 ---\n",
            "• Visualization and dimensionality reduction\n",
            "— Principal Component Analysis (PCA)\n",
            "— Kernel PCA\n",
            "— Locally Linear Embedding (LLE)\n",
            "\n",
            "--- Chunk 860 ---\n",
            "— t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
            "\n",
            "--- Chunk 861 ---\n",
            "• Association rule learning\n",
            "— Apriori\n",
            "— Eclat\n",
            "\n",
            "--- Chunk 862 ---\n",
            "For example, say you have a lot of data about your blog’s visitors. You may want to\n",
            "\n",
            "--- Chunk 863 ---\n",
            "run a clustering algorithm to try to detect groups of similar visitors (Figure 1-8). At\n",
            "\n",
            "--- Chunk 864 ---\n",
            "no point do you tell the algorithm which group a visitor belongs to: it finds those\n",
            "\n",
            "--- Chunk 865 ---\n",
            "connections without your help. For example, it might notice that 40% of your visitors\n",
            "\n",
            "--- Chunk 866 ---\n",
            "are males who love comic books and generally read your blog in the evening, while\n",
            "\n",
            "--- Chunk 867 ---\n",
            "20% are young sci-fi lovers who visit during the weekends. If you use a hierarchical\n",
            "\n",
            "--- Chunk 868 ---\n",
            "clustering algorithm, it may also subdivide each group into smaller groups. This may\n",
            "help you target your posts for each group.\n",
            "\n",
            "--- Chunk 869 ---\n",
            "10 | Chapter 1: The Machine Learning Landscape\n",
            "\n",
            "\n",
            "\n",
            "Figure 1-8. Clustering\n",
            "\n",
            "--- Chunk 870 ---\n",
            "Visualization algorithms are also good examples of unsupervised learning algorithms:\n",
            "\n",
            "--- Chunk 871 ---\n",
            "you feed them a lot of complex and unlabeled data, and they output a 2D or 3D rep‐\n",
            "\n",
            "--- Chunk 872 ---\n",
            "resentation of your data that can easily be plotted (Figure 1-9). These algorithms try\n",
            "\n",
            "--- Chunk 873 ---\n",
            "to preserve as much structure as they can (e.g., trying to keep separate clusters in the\n",
            "\n",
            "--- Chunk 874 ---\n",
            "input space from overlapping in the visualization) so that you can understand how\n",
            "the data is organized and perhaps identify unsuspected patterns.\n",
            "\n",
            "--- Chunk 875 ---\n",
            "Figure 1-9. Example of a t-SNE visualization highlighting semantic clusters3\n",
            "\n",
            "--- Chunk 876 ---\n",
            "3 Notice how animals are rather well separated from vehicles and how horses are close to deer but far from\n",
            "\n",
            "--- Chunk 877 ---\n",
            "birds. Figure reproduced with permission from Richard Socher et al., “Zero-Shot Learning Through Cross-\n",
            "\n",
            "--- Chunk 878 ---\n",
            "Modal Transfer,” Proceedings of the 26th International Conference on Neural Information Processing Systems 1\n",
            "(2013): 935–943.\n",
            "\n",
            "--- Chunk 879 ---\n",
            "Types of Machine Learning Systems | 11\n",
            "\n",
            "--- Chunk 880 ---\n",
            "A related task is dimensionality reduction, in which the goal is to simplify the data\n",
            "\n",
            "--- Chunk 881 ---\n",
            "without losing too much information. One way to do this is to merge several correla‐\n",
            "\n",
            "--- Chunk 882 ---\n",
            "ted features into one. For example, a car’s mileage may be strongly correlated with its\n",
            "\n",
            "--- Chunk 883 ---\n",
            "age, so the dimensionality reduction algorithm will merge them into one feature that\n",
            "\n",
            "--- Chunk 884 ---\n",
            "represents the car’s wear and tear. This is called feature extraction.\n",
            "\n",
            "--- Chunk 885 ---\n",
            "It is often a good idea to try to reduce the dimension of your train‐\n",
            "ing data using a dimensionality reduction algorithm before you\n",
            "\n",
            "--- Chunk 886 ---\n",
            "feed it to another Machine Learning algorithm (such as a super‐\n",
            "vised learning algorithm). It will run much faster, the data will take\n",
            "\n",
            "--- Chunk 887 ---\n",
            "up less disk and memory space, and in some cases it may also per‐\n",
            "form better.\n",
            "\n",
            "--- Chunk 888 ---\n",
            "Yet another important unsupervised task is anomaly detection—for example, detect‐\n",
            "\n",
            "--- Chunk 889 ---\n",
            "ing unusual credit card transactions to prevent fraud, catching manufacturing defects,\n",
            "\n",
            "--- Chunk 890 ---\n",
            "or automatically removing outliers from a dataset before feeding it to another learn‐\n",
            "\n",
            "--- Chunk 891 ---\n",
            "ing algorithm. The system is shown mostly normal instances during training, so it\n",
            "\n",
            "--- Chunk 892 ---\n",
            "learns to recognize them; then, when it sees a new instance, it can tell whether it looks\n",
            "\n",
            "--- Chunk 893 ---\n",
            "like a normal one or whether it is likely an anomaly (see Figure 1-10). A very similar\n",
            "\n",
            "--- Chunk 894 ---\n",
            "task is novelty detection: it aims to detect new instances that look different from all\n",
            "\n",
            "--- Chunk 895 ---\n",
            "instances in the training set. This requires having a very “clean” training set, devoid of\n",
            "\n",
            "--- Chunk 896 ---\n",
            "any instance that you would like the algorithm to detect. For example, if you have\n",
            "\n",
            "--- Chunk 897 ---\n",
            "thousands of pictures of dogs, and 1% of these pictures represent Chihuahuas, then a\n",
            "\n",
            "--- Chunk 898 ---\n",
            "novelty detection algorithm should not treat new pictures of Chihuahuas as novelties.\n",
            "\n",
            "--- Chunk 899 ---\n",
            "On the other hand, anomaly detection algorithms may consider these dogs as so rare\n",
            "\n",
            "--- Chunk 900 ---\n",
            "and so different from other dogs that they would likely classify them as anomalies (no\n",
            "offense to Chihuahuas).\n",
            "\n",
            "--- Chunk 901 ---\n",
            "Figure 1-10. Anomaly detection\n",
            "\n",
            "--- Chunk 902 ---\n",
            "Finally, another common unsupervised task is association rule learning, in which the\n",
            "\n",
            "--- Chunk 903 ---\n",
            "goal is to dig into large amounts of data and discover interesting relations between\n",
            "\n",
            "--- Chunk 904 ---\n",
            "12 | Chapter 1: The Machine Learning Landscape\n",
            "\n",
            "--- Chunk 905 ---\n",
            "attributes. For example, suppose you own a supermarket. Running an association rule\n",
            "\n",
            "--- Chunk 906 ---\n",
            "on your sales logs may reveal that people who purchase barbecue sauce and potato\n",
            "\n",
            "--- Chunk 907 ---\n",
            "chips also tend to buy steak. Thus, you may want to place these items close to one\n",
            "another.\n",
            "\n",
            "--- Chunk 908 ---\n",
            "Semisupervised learning\n",
            "Since labeling data is usually time-consuming and costly, you will often have plenty of\n",
            "\n",
            "--- Chunk 909 ---\n",
            "unlabeled instances, and few labeled instances. Some algorithms can deal with data\n",
            "\n",
            "--- Chunk 910 ---\n",
            "that’s partially labeled. This is called semisupervised learning (Figure 1-11).\n",
            "\n",
            "--- Chunk 911 ---\n",
            "Figure 1-11. Semisupervised learning with two classes (triangles and squares): the unla‐\n",
            "\n",
            "--- Chunk 912 ---\n",
            "beled examples (circles) help classify a new instance (the cross) into the triangle class\n",
            "\n",
            "--- Chunk 913 ---\n",
            "rather than the square class, even though it is closer to the labeled squares\n",
            "\n",
            "--- Chunk 914 ---\n",
            "Some photo-hosting services, such as Google Photos, are good examples of this. Once\n",
            "\n",
            "--- Chunk 915 ---\n",
            "you upload all your family photos to the service, it automatically recognizes that the\n",
            "\n",
            "--- Chunk 916 ---\n",
            "same person A shows up in photos 1, 5, and 11, while another person B shows up in\n",
            "\n",
            "--- Chunk 917 ---\n",
            "photos 2, 5, and 7. This is the unsupervised part of the algorithm (clustering). Now all\n",
            "\n",
            "--- Chunk 918 ---\n",
            "the system needs is for you to tell it who these people are. Just add one label per per‐\n",
            "\n",
            "--- Chunk 919 ---\n",
            "son4 and it is able to name everyone in every photo, which is useful for searching\n",
            "photos.\n",
            "\n",
            "--- Chunk 920 ---\n",
            "photos.\n",
            "Most semisupervised learning algorithms are combinations of unsupervised and\n",
            "\n",
            "--- Chunk 921 ---\n",
            "supervised algorithms. For example, deep belief networks (DBNs) are based on unsu‐\n",
            "\n",
            "--- Chunk 922 ---\n",
            "pervised components called restricted Boltzmann machines (RBMs) stacked on top of\n",
            "\n",
            "--- Chunk 923 ---\n",
            "one another. RBMs are trained sequentially in an unsupervised manner, and then the\n",
            "whole system is fine-tuned using supervised learning techniques.\n",
            "\n",
            "--- Chunk 924 ---\n",
            "4 That’s when the system works perfectly. In practice it often creates a few clusters per person, and sometimes\n",
            "\n",
            "--- Chunk 925 ---\n",
            "mixes up two people who look alike, so you may need to provide a few labels per person and manually clean\n",
            "up some clusters.\n",
            "\n",
            "--- Chunk 926 ---\n",
            "Types of Machine Learning Systems | 13\n",
            "\n",
            "--- Chunk 927 ---\n",
            "Reinforcement Learning\n",
            "Reinforcement Learning is a very different beast. The learning system, called an agent\n",
            "\n",
            "--- Chunk 928 ---\n",
            "in this context, can observe the environment, select and perform actions, and get\n",
            "\n",
            "--- Chunk 929 ---\n",
            "rewards in return (or penalties in the form of negative rewards, as shown in\n",
            "\n",
            "--- Chunk 930 ---\n",
            "Figure 1-12). It must then learn by itself what is the best strategy, called a policy, to get\n",
            "\n",
            "--- Chunk 931 ---\n",
            "the most reward over time. A policy defines what action the agent should choose\n",
            "when it is in a given situation.\n",
            "\n",
            "--- Chunk 932 ---\n",
            "Figure 1-12. Reinforcement Learning\n",
            "\n",
            "--- Chunk 933 ---\n",
            "For example, many robots implement Reinforcement Learning algorithms to learn\n",
            "\n",
            "--- Chunk 934 ---\n",
            "how to walk. DeepMind’s AlphaGo program is also a good example of Reinforcement\n",
            "\n",
            "--- Chunk 935 ---\n",
            "Learning: it made the headlines in May 2017 when it beat the world champion Ke Jie\n",
            "\n",
            "--- Chunk 936 ---\n",
            "at the game of Go. It learned its winning policy by analyzing millions of games, and\n",
            "\n",
            "--- Chunk 937 ---\n",
            "then playing many games against itself. Note that learning was turned off during the\n",
            "\n",
            "--- Chunk 938 ---\n",
            "games against the champion; AlphaGo was just applying the policy it had learned.\n",
            "\n",
            "--- Chunk 939 ---\n",
            "Batch and Online Learning\n",
            "Another criterion used to classify Machine Learning systems is whether or not the\n",
            "\n",
            "--- Chunk 940 ---\n",
            "system can learn incrementally from a stream of incoming data.\n",
            "\n",
            "--- Chunk 941 ---\n",
            "14 | Chapter 1: The Machine Learning Landscape\n",
            "\n",
            "--- Chunk 942 ---\n",
            "Batch learning\n",
            "In batch learning, the system is incapable of learning incrementally: it must be trained\n",
            "\n",
            "--- Chunk 943 ---\n",
            "using all the available data. This will generally take a lot of time and computing\n",
            "\n",
            "--- Chunk 944 ---\n",
            "resources, so it is typically done offline. First the system is trained, and then it is\n",
            "\n",
            "--- Chunk 945 ---\n",
            "launched into production and runs without learning anymore; it just applies what it\n",
            "has learned. This is called offline learning.\n",
            "\n",
            "--- Chunk 946 ---\n",
            "If you want a batch learning system to know about new data (such as a new type of\n",
            "\n",
            "--- Chunk 947 ---\n",
            "spam), you need to train a new version of the system from scratch on the full dataset\n",
            "\n",
            "--- Chunk 948 ---\n",
            "(not just the new data, but also the old data), then stop the old system and replace it\n",
            "with the new one.\n",
            "\n",
            "--- Chunk 949 ---\n",
            "with the new one.\n",
            "Fortunately, the whole process of training, evaluating, and launching a Machine\n",
            "\n",
            "--- Chunk 950 ---\n",
            "Learning system can be automated fairly easily (as shown in Figure 1-3), so even a\n",
            "\n",
            "--- Chunk 951 ---\n",
            "batch learning system can adapt to change. Simply update the data and train a new\n",
            "version of the system from scratch as often as needed.\n",
            "\n",
            "--- Chunk 952 ---\n",
            "This solution is simple and often works fine, but training using the full set of data can\n",
            "\n",
            "--- Chunk 953 ---\n",
            "take many hours, so you would typically train a new system only every 24 hours or\n",
            "\n",
            "--- Chunk 954 ---\n",
            "even just weekly. If your system needs to adapt to rapidly changing data (e.g., to pre‐\n",
            "dict stock prices), then you need a more reactive solution.\n",
            "\n",
            "--- Chunk 955 ---\n",
            "Also, training on the full set of data requires a lot of computing resources (CPU,\n",
            "\n",
            "--- Chunk 956 ---\n",
            "memory space, disk space, disk I/O, network I/O, etc.). If you have a lot of data and\n",
            "\n",
            "--- Chunk 957 ---\n",
            "you automate your system to train from scratch every day, it will end up costing you a\n",
            "\n",
            "--- Chunk 958 ---\n",
            "lot of money. If the amount of data is huge, it may even be impossible to use a batch\n",
            "learning algorithm.\n",
            "\n",
            "--- Chunk 959 ---\n",
            "learning algorithm.\n",
            "Finally, if your system needs to be able to learn autonomously and it has limited\n",
            "\n",
            "--- Chunk 960 ---\n",
            "resources (e.g., a smartphone application or a rover on Mars), then carrying around\n",
            "\n",
            "--- Chunk 961 ---\n",
            "large amounts of training data and taking up a lot of resources to train for hours\n",
            "every day is a showstopper.\n",
            "\n",
            "--- Chunk 962 ---\n",
            "Fortunately, a better option in all these cases is to use algorithms that are capable of\n",
            "learning incrementally.\n",
            "\n",
            "--- Chunk 963 ---\n",
            "Online learning\n",
            "In online learning, you train the system incrementally by feeding it data instances\n",
            "\n",
            "--- Chunk 964 ---\n",
            "sequentially, either individually or in small groups called mini-batches. Each learning\n",
            "\n",
            "--- Chunk 965 ---\n",
            "step is fast and cheap, so the system can learn about new data on the fly, as it arrives\n",
            "(see Figure 1-13).\n",
            "\n",
            "--- Chunk 966 ---\n",
            "Types of Machine Learning Systems | 15\n",
            "\n",
            "--- Chunk 967 ---\n",
            "Figure 1-13. In online learning, a model is trained and launched into production, and\n",
            "then it keeps learning as new data comes in\n",
            "\n",
            "--- Chunk 968 ---\n",
            "Online learning is great for systems that receive data as a continuous flow (e.g., stock\n",
            "\n",
            "--- Chunk 969 ---\n",
            "prices) and need to adapt to change rapidly or autonomously. It is also a good option\n",
            "\n",
            "--- Chunk 970 ---\n",
            "if you have limited computing resources: once an online learning system has learned\n",
            "\n",
            "--- Chunk 971 ---\n",
            "about new data instances, it does not need them anymore, so you can discard them\n",
            "\n",
            "--- Chunk 972 ---\n",
            "(unless you want to be able to roll back to a previous state and “replay” the data). This\n",
            "can save a huge amount of space.\n",
            "\n",
            "--- Chunk 973 ---\n",
            "Online learning algorithms can also be used to train systems on huge datasets that\n",
            "\n",
            "--- Chunk 974 ---\n",
            "cannot fit in one machine’s main memory (this is called out-of-core learning). The\n",
            "\n",
            "--- Chunk 975 ---\n",
            "algorithm loads part of the data, runs a training step on that data, and repeats the\n",
            "process until it has run on all of the data (see Figure 1-14).\n",
            "\n",
            "--- Chunk 976 ---\n",
            "Out-of-core learning is usually done offline (i.e., not on the live\n",
            "system), so online learning can be a confusing name. Think of it as\n",
            "\n",
            "--- Chunk 977 ---\n",
            "incremental learning.\n",
            "\n",
            "--- Chunk 978 ---\n",
            "One important parameter of online learning systems is how fast they should adapt to\n",
            "\n",
            "--- Chunk 979 ---\n",
            "changing data: this is called the learning rate. If you set a high learning rate, then your\n",
            "\n",
            "--- Chunk 980 ---\n",
            "system will rapidly adapt to new data, but it will also tend to quickly forget the old\n",
            "\n",
            "--- Chunk 981 ---\n",
            "data (you don’t want a spam filter to flag only the latest kinds of spam it was shown).\n",
            "\n",
            "--- Chunk 982 ---\n",
            "Conversely, if you set a low learning rate, the system will have more inertia; that is, it\n",
            "\n",
            "--- Chunk 983 ---\n",
            "will learn more slowly, but it will also be less sensitive to noise in the new data or to\n",
            "sequences of nonrepresentative data points (outliers).\n",
            "\n",
            "--- Chunk 984 ---\n",
            "16 | Chapter 1: The Machine Learning Landscape\n",
            "\n",
            "\n",
            "\n",
            "Figure 1-14. Using online learning to handle huge datasets\n",
            "\n",
            "--- Chunk 985 ---\n",
            "A big challenge with online learning is that if bad data is fed to the system, the sys‐\n",
            "\n",
            "--- Chunk 986 ---\n",
            "tem’s performance will gradually decline. If it’s a live system, your clients will notice.\n",
            "\n",
            "--- Chunk 987 ---\n",
            "For example, bad data could come from a malfunctioning sensor on a robot, or from\n",
            "\n",
            "--- Chunk 988 ---\n",
            "someone spamming a search engine to try to rank high in search results. To reduce\n",
            "\n",
            "--- Chunk 989 ---\n",
            "this risk, you need to monitor your system closely and promptly switch learning off\n",
            "\n",
            "--- Chunk 990 ---\n",
            "(and possibly revert to a previously working state) if you detect a drop in perfor‐\n",
            "\n",
            "--- Chunk 991 ---\n",
            "mance. You may also want to monitor the input data and react to abnormal data (e.g.,\n",
            "using an anomaly detection algorithm).\n",
            "\n",
            "--- Chunk 992 ---\n",
            "Instance-Based Versus Model-Based Learning\n",
            "One more way to categorize Machine Learning systems is by how they generalize.\n",
            "\n",
            "--- Chunk 993 ---\n",
            "Most Machine Learning tasks are about making predictions. This means that given a\n",
            "\n",
            "--- Chunk 994 ---\n",
            "number of training examples, the system needs to be able to make good predictions\n",
            "\n",
            "--- Chunk 995 ---\n",
            "for (generalize to) examples it has never seen before. Having a good performance\n",
            "\n",
            "--- Chunk 996 ---\n",
            "measure on the training data is good, but insufficient; the true goal is to perform well\n",
            "on new instances.\n",
            "\n",
            "--- Chunk 997 ---\n",
            "on new instances.\n",
            "There are two main approaches to generalization: instance-based learning and\n",
            "model-based learning.\n",
            "\n",
            "--- Chunk 998 ---\n",
            "Instance-based learning\n",
            "Possibly the most trivial form of learning is simply to learn by heart. If you were to\n",
            "\n",
            "--- Chunk 999 ---\n",
            "create a spam filter this way, it would just flag all emails that are identical to emails\n",
            "\n",
            "--- Chunk 1000 ---\n",
            "that have already been flagged by users—not the worst solution, but certainly not the\n",
            "best.\n",
            "\n",
            "--- Chunk 1001 ---\n",
            "Types of Machine Learning Systems | 17\n",
            "\n",
            "--- Chunk 1002 ---\n",
            "Instead of just flagging emails that are identical to known spam emails, your spam\n",
            "\n",
            "--- Chunk 1003 ---\n",
            "filter could be programmed to also flag emails that are very similar to known spam\n",
            "\n",
            "--- Chunk 1004 ---\n",
            "emails. This requires a measure of similarity between two emails. A (very basic) simi‐\n",
            "\n",
            "--- Chunk 1005 ---\n",
            "larity measure between two emails could be to count the number of words they have\n",
            "\n",
            "--- Chunk 1006 ---\n",
            "in common. The system would flag an email as spam if it has many words in com‐\n",
            "mon with a known spam email.\n",
            "\n",
            "--- Chunk 1007 ---\n",
            "This is called instance-based learning: the system learns the examples by heart, then\n",
            "\n",
            "--- Chunk 1008 ---\n",
            "generalizes to new cases by using a similarity measure to compare them to the\n",
            "\n",
            "--- Chunk 1009 ---\n",
            "learned examples (or a subset of them). For example, in Figure 1-15 the new instance\n",
            "\n",
            "--- Chunk 1010 ---\n",
            "would be classified as a triangle because the majority of the most similar instances\n",
            "belong to that class.\n",
            "\n",
            "--- Chunk 1011 ---\n",
            "Figure 1-15. Instance-based learning\n",
            "\n",
            "--- Chunk 1012 ---\n",
            "Model-based learning\n",
            "Another way to generalize from a set of examples is to build a model of these exam‐\n",
            "\n",
            "--- Chunk 1013 ---\n",
            "ples and then use that model to make predictions. This is called model-based learning\n",
            "(Figure 1-16).\n",
            "\n",
            "--- Chunk 1014 ---\n",
            "Figure 1-16. Model-based learning\n",
            "\n",
            "18 | Chapter 1: The Machine Learning Landscape\n",
            "\n",
            "--- Chunk 1015 ---\n",
            "For example, suppose you want to know if money makes people happy, so you down‐\n",
            "\n",
            "--- Chunk 1016 ---\n",
            "load the Better Life Index data from the OECD’s website and stats about gross domes‐\n",
            "\n",
            "--- Chunk 1017 ---\n",
            "tic product (GDP) per capita from the IMF’s website. Then you join the tables and\n",
            "sort by GDP per capita. Table 1-1 shows an excerpt of what you get.\n",
            "\n",
            "--- Chunk 1018 ---\n",
            "Table 1-1. Does money make people happier?\n",
            "Country GDP per capita (USD) Life satisfaction\n",
            "Hungary 12,240 4.9\n",
            "Korea 27,195 5.8\n",
            "France 37,675 6.5\n",
            "\n",
            "--- Chunk 1019 ---\n",
            "France 37,675 6.5\n",
            "Australia 50,962 7.3\n",
            "United States 55,805 7.2\n",
            "\n",
            "--- Chunk 1020 ---\n",
            "Let’s plot the data for these countries (Figure 1-17).\n",
            "\n",
            "Figure 1-17. Do you see a trend here?\n",
            "\n",
            "--- Chunk 1021 ---\n",
            "There does seem to be a trend here! Although the data is noisy (i.e., partly random), it\n",
            "\n",
            "--- Chunk 1022 ---\n",
            "looks like life satisfaction goes up more or less linearly as the country’s GDP per cap‐\n",
            "\n",
            "--- Chunk 1023 ---\n",
            "ita increases. So you decide to model life satisfaction as a linear function of GDP per\n",
            "\n",
            "--- Chunk 1024 ---\n",
            "capita. This step is called model selection: you selected a linear model of life satisfac‐\n",
            "\n",
            "--- Chunk 1025 ---\n",
            "tion with just one attribute, GDP per capita (Equation 1-1).\n",
            "\n",
            "--- Chunk 1026 ---\n",
            "Equation 1-1. A simple linear model\n",
            "life_satisfaction = θ0 + θ1 × GDP_per_capita\n",
            "\n",
            "Types of Machine Learning Systems | 19\n",
            "\n",
            "--- Chunk 1027 ---\n",
            "This model has two model parameters, θ0 and θ1.5 By tweaking these parameters, you\n",
            "\n",
            "--- Chunk 1028 ---\n",
            "can make your model represent any linear function, as shown in Figure 1-18.\n",
            "\n",
            "--- Chunk 1029 ---\n",
            "Figure 1-18. A few possible linear models\n",
            "\n",
            "--- Chunk 1030 ---\n",
            "Before you can use your model, you need to define the parameter values θ0 and θ1.\n",
            "\n",
            "--- Chunk 1031 ---\n",
            "How can you know which values will make your model perform best? To answer this\n",
            "\n",
            "--- Chunk 1032 ---\n",
            "question, you need to specify a performance measure. You can either define a utility\n",
            "\n",
            "--- Chunk 1033 ---\n",
            "function (or fitness function) that measures how good your model is, or you can define\n",
            "\n",
            "--- Chunk 1034 ---\n",
            "a cost function that measures how bad it is. For Linear Regression problems, people\n",
            "\n",
            "--- Chunk 1035 ---\n",
            "typically use a cost function that measures the distance between the linear model’s\n",
            "\n",
            "--- Chunk 1036 ---\n",
            "predictions and the training examples; the objective is to minimize this distance.\n",
            "\n",
            "--- Chunk 1037 ---\n",
            "This is where the Linear Regression algorithm comes in: you feed it your training\n",
            "\n",
            "--- Chunk 1038 ---\n",
            "examples, and it finds the parameters that make the linear model fit best to your data.\n",
            "\n",
            "--- Chunk 1039 ---\n",
            "This is called training the model. In our case, the algorithm finds that the optimal\n",
            "parameter values are θ0 = 4.85 and θ1 = 4.91 × 10–5.\n",
            "\n",
            "--- Chunk 1040 ---\n",
            "Confusingly, the same word “model” can refer to a type of model\n",
            "(e.g., Linear Regression), to a fully specified model architecture (e.g.,\n",
            "\n",
            "--- Chunk 1041 ---\n",
            "Linear Regression with one input and one output), or to the final\n",
            "trained model ready to be used for predictions (e.g., Linear Regres‐\n",
            "\n",
            "--- Chunk 1042 ---\n",
            "sion with one input and one output, using θ0 = 4.85 and θ1 = 4.91 ×\n",
            "10–5). Model selection consists in choosing the type of model and\n",
            "\n",
            "--- Chunk 1043 ---\n",
            "fully specifying its architecture. Training a model means running\n",
            "an algorithm to find the model parameters that will make it best fit\n",
            "\n",
            "--- Chunk 1044 ---\n",
            "the training data (and hopefully make good predictions on new\n",
            "data).\n",
            "\n",
            "--- Chunk 1045 ---\n",
            "5 By convention, the Greek letter θ (theta) is frequently used to represent model parameters.\n",
            "\n",
            "20 | Chapter 1: The Machine Learning Landscape\n",
            "\n",
            "--- Chunk 1046 ---\n",
            "Now the model fits the training data as closely as possible (for a linear model), as you\n",
            "can see in Figure 1-19.\n",
            "\n",
            "--- Chunk 1047 ---\n",
            "Figure 1-19. The linear model that fits the training data best\n",
            "\n",
            "--- Chunk 1048 ---\n",
            "You are finally ready to run the model to make predictions. For example, say you\n",
            "\n",
            "--- Chunk 1049 ---\n",
            "want to know how happy Cypriots are, and the OECD data does not have the answer.\n",
            "\n",
            "--- Chunk 1050 ---\n",
            "Fortunately, you can use your model to make a good prediction: you look up Cyprus’s\n",
            "\n",
            "--- Chunk 1051 ---\n",
            "GDP per capita, find $22,587, and then apply your model and find that life satisfac‐\n",
            "\n",
            "--- Chunk 1052 ---\n",
            "tion is likely to be somewhere around 4.85 + 22,587 × 4.91 × 10-5 = 5.96.\n",
            "\n",
            "--- Chunk 1053 ---\n",
            "To whet your appetite, Example 1-1 shows the Python code that loads the data, pre‐\n",
            "\n",
            "--- Chunk 1054 ---\n",
            "pares it,6 creates a scatterplot for visualization, and then trains a linear model and\n",
            "makes a prediction.7\n",
            "\n",
            "--- Chunk 1055 ---\n",
            "Example 1-1. Training and running a linear model using Scikit-Learn\n",
            "import matplotlib.pyplot as plt\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "\n",
            "--- Chunk 1056 ---\n",
            "import pandas as pd\n",
            "import sklearn.linear_model\n",
            "\n",
            "--- Chunk 1057 ---\n",
            "# Load the data\n",
            "oecd_bli = pd.read_csv(\"oecd_bli_2015.csv\", thousands=',')\n",
            "\n",
            "--- Chunk 1058 ---\n",
            "gdp_per_capita = pd.read_csv(\"gdp_per_capita.csv\",thousands=',',delimiter='\\t',\n",
            "                             encoding='latin1', na_values=\"n/a\")\n",
            "\n",
            "--- Chunk 1059 ---\n",
            "6 The prepare_country_stats() function’s definition is not shown here (see this chapter’s Jupyter notebook if\n",
            "\n",
            "--- Chunk 1060 ---\n",
            "you want all the gory details). It’s just boring pandas code that joins the life satisfaction data from the OECD\n",
            "\n",
            "--- Chunk 1061 ---\n",
            "with the GDP per capita data from the IMF.\n",
            "\n",
            "--- Chunk 1062 ---\n",
            "7 It’s OK if you don’t understand all the code yet; we will present Scikit-Learn in the following chapters.\n",
            "\n",
            "Types of Machine Learning Systems | 21\n",
            "\n",
            "--- Chunk 1063 ---\n",
            "# Prepare the data\n",
            "country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)\n",
            "X = np.c_[country_stats[\"GDP per capita\"]]\n",
            "\n",
            "--- Chunk 1064 ---\n",
            "y = np.c_[country_stats[\"Life satisfaction\"]]\n",
            "\n",
            "--- Chunk 1065 ---\n",
            "# Visualize the data\n",
            "country_stats.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction')\n",
            "plt.show()\n",
            "\n",
            "--- Chunk 1066 ---\n",
            "# Select a linear model\n",
            "model = sklearn.linear_model.LinearRegression()\n",
            "\n",
            "# Train the model\n",
            "model.fit(X, y)\n",
            "\n",
            "--- Chunk 1067 ---\n",
            "# Make a prediction for Cyprus\n",
            "X_new = [[22587]]  # Cyprus's GDP per capita\n",
            "print(model.predict(X_new)) # outputs [[ 5.96242338]]\n",
            "\n",
            "--- Chunk 1068 ---\n",
            "If you had used an instance-based learning algorithm instead, you\n",
            "would have found that Slovenia has the closest GDP per capita to\n",
            "\n",
            "--- Chunk 1069 ---\n",
            "that of Cyprus ($20,732), and since the OECD data tells us that\n",
            "Slovenians’ life satisfaction is 5.7, you would have predicted a life\n",
            "\n",
            "--- Chunk 1070 ---\n",
            "satisfaction of 5.7 for Cyprus. If you zoom out a bit and look at the\n",
            "two next-closest countries, you will find Portugal and Spain with\n",
            "\n",
            "--- Chunk 1071 ---\n",
            "life satisfactions of 5.1 and 6.5, respectively. Averaging these three\n",
            "values, you get 5.77, which is pretty close to your model-based pre‐\n",
            "\n",
            "--- Chunk 1072 ---\n",
            "diction. This simple algorithm is called k-Nearest Neighbors regres‐\n",
            "sion (in this example, k = 3).\n",
            "\n",
            "--- Chunk 1073 ---\n",
            "Replacing the Linear Regression model with k-Nearest Neighbors\n",
            "regression in the previous code is as simple as replacing these two\n",
            "lines:\n",
            "\n",
            "--- Chunk 1074 ---\n",
            "import sklearn.linear_model\n",
            "model = sklearn.linear_model.LinearRegression()\n",
            "\n",
            "--- Chunk 1075 ---\n",
            "with these two:\n",
            "import sklearn.neighbors\n",
            "model = sklearn.neighbors.KNeighborsRegressor(\n",
            "    n_neighbors=3)\n",
            "\n",
            "--- Chunk 1076 ---\n",
            "If all went well, your model will make good predictions. If not, you may need to use\n",
            "\n",
            "--- Chunk 1077 ---\n",
            "more attributes (employment rate, health, air pollution, etc.), get more or better-\n",
            "\n",
            "--- Chunk 1078 ---\n",
            "quality training data, or perhaps select a more powerful model (e.g., a Polynomial\n",
            "Regression model).\n",
            "\n",
            "--- Chunk 1079 ---\n",
            "22 | Chapter 1: The Machine Learning Landscape\n",
            "\n",
            "\n",
            "\n",
            "In summary:\n",
            "\n",
            "--- Chunk 1080 ---\n",
            "In summary:\n",
            "\n",
            "• You studied the data.\n",
            "• You selected a model.\n",
            "• You trained it on the training data (i.e., the learning algorithm searched for the\n",
            "\n",
            "--- Chunk 1081 ---\n",
            "model parameter values that minimize a cost function).\n",
            "• Finally, you applied the model to make predictions on new cases (this is called\n",
            "\n",
            "--- Chunk 1082 ---\n",
            "inference), hoping that this model will generalize well.\n",
            "\n",
            "--- Chunk 1083 ---\n",
            "This is what a typical Machine Learning project looks like. In Chapter 2 you will\n",
            "experience this firsthand by going through a project end to end.\n",
            "\n",
            "--- Chunk 1084 ---\n",
            "We have covered a lot of ground so far: you now know what Machine Learning is\n",
            "\n",
            "--- Chunk 1085 ---\n",
            "really about, why it is useful, what some of the most common categories of ML sys‐\n",
            "\n",
            "--- Chunk 1086 ---\n",
            "tems are, and what a typical project workflow looks like. Now let’s look at what can go\n",
            "\n",
            "--- Chunk 1087 ---\n",
            "wrong in learning and prevent you from making accurate predictions.\n",
            "\n",
            "--- Chunk 1088 ---\n",
            "Main Challenges of Machine Learning\n",
            "In short, since your main task is to select a learning algorithm and train it on some\n",
            "\n",
            "--- Chunk 1089 ---\n",
            "data, the two things that can go wrong are “bad algorithm” and “bad data.” Let’s start\n",
            "with examples of bad data.\n",
            "\n",
            "--- Chunk 1090 ---\n",
            "Insufficient Quantity of Training Data\n",
            "For a toddler to learn what an apple is, all it takes is for you to point to an apple and\n",
            "\n",
            "--- Chunk 1091 ---\n",
            "say “apple” (possibly repeating this procedure a few times). Now the child is able to\n",
            "recognize apples in all sorts of colors and shapes. Genius.\n",
            "\n",
            "--- Chunk 1092 ---\n",
            "Machine Learning is not quite there yet; it takes a lot of data for most Machine Learn‐\n",
            "\n",
            "--- Chunk 1093 ---\n",
            "ing algorithms to work properly. Even for very simple problems you typically need\n",
            "\n",
            "--- Chunk 1094 ---\n",
            "thousands of examples, and for complex problems such as image or speech recogni‐\n",
            "\n",
            "--- Chunk 1095 ---\n",
            "tion you may need millions of examples (unless you can reuse parts of an existing\n",
            "model).\n",
            "\n",
            "--- Chunk 1096 ---\n",
            "Main Challenges of Machine Learning | 23\n",
            "\n",
            "--- Chunk 1097 ---\n",
            "The Unreasonable Effectiveness of Data\n",
            "In a famous paper published in 2001, Microsoft researchers Michele Banko and Eric\n",
            "\n",
            "--- Chunk 1098 ---\n",
            "Brill showed that very different Machine Learning algorithms, including fairly simple\n",
            "\n",
            "--- Chunk 1099 ---\n",
            "ones, performed almost identically well on a complex problem of natural language\n",
            "\n",
            "--- Chunk 1100 ---\n",
            "disambiguation8 once they were given enough data (as you can see in Figure 1-20).\n",
            "\n",
            "--- Chunk 1101 ---\n",
            "Figure 1-20. The importance of data versus algorithms9\n",
            "\n",
            "--- Chunk 1102 ---\n",
            "As the authors put it, “these results suggest that we may want to reconsider the trade-\n",
            "\n",
            "--- Chunk 1103 ---\n",
            "off between spending time and money on algorithm development versus spending it\n",
            "on corpus development.”\n",
            "\n",
            "--- Chunk 1104 ---\n",
            "The idea that data matters more than algorithms for complex problems was further\n",
            "\n",
            "--- Chunk 1105 ---\n",
            "popularized by Peter Norvig et al. in a paper titled “The Unreasonable Effectiveness\n",
            "\n",
            "--- Chunk 1106 ---\n",
            "of Data”, published in 2009.10 It should be noted, however, that small- and medium-\n",
            "\n",
            "--- Chunk 1107 ---\n",
            "sized datasets are still very common, and it is not always easy or cheap to get extra\n",
            "training data—so don’t abandon algorithms just yet.\n",
            "\n",
            "--- Chunk 1108 ---\n",
            "8 For example, knowing whether to write “to,” “two,” or “too,” depending on the context.\n",
            "\n",
            "--- Chunk 1109 ---\n",
            "9 Figure reproduced with permission from Michele Banko and Eric Brill, “Scaling to Very Very Large Corpora\n",
            "\n",
            "--- Chunk 1110 ---\n",
            "for Natural Language Disambiguation,” Proceedings of the 39th Annual Meeting of the Association for Compu‐\n",
            "tational Linguistics (2001): 26–33.\n",
            "\n",
            "--- Chunk 1111 ---\n",
            "10 Peter Norvig et al., “The Unreasonable Effectiveness of Data,” IEEE Intelligent Systems 24, no. 2 (2009): 8–12.\n",
            "\n",
            "--- Chunk 1112 ---\n",
            "24 | Chapter 1: The Machine Learning Landscape\n",
            "\n",
            "--- Chunk 1113 ---\n",
            "Nonrepresentative Training Data\n",
            "In order to generalize well, it is crucial that your training data be representative of the\n",
            "\n",
            "--- Chunk 1114 ---\n",
            "new cases you want to generalize to. This is true whether you use instance-based\n",
            "learning or model-based learning.\n",
            "\n",
            "--- Chunk 1115 ---\n",
            "For example, the set of countries we used earlier for training the linear model was not\n",
            "\n",
            "--- Chunk 1116 ---\n",
            "perfectly representative; a few countries were missing. Figure 1-21 shows what the\n",
            "data looks like when you add the missing countries.\n",
            "\n",
            "--- Chunk 1117 ---\n",
            "Figure 1-21. A more representative training sample\n",
            "\n",
            "--- Chunk 1118 ---\n",
            "If you train a linear model on this data, you get the solid line, while the old model is\n",
            "\n",
            "--- Chunk 1119 ---\n",
            "represented by the dotted line. As you can see, not only does adding a few missing\n",
            "\n",
            "--- Chunk 1120 ---\n",
            "countries significantly alter the model, but it makes it clear that such a simple linear\n",
            "\n",
            "--- Chunk 1121 ---\n",
            "model is probably never going to work well. It seems that very rich countries are not\n",
            "\n",
            "--- Chunk 1122 ---\n",
            "happier than moderately rich countries (in fact, they seem unhappier), and con‐\n",
            "versely some poor countries seem happier than many rich countries.\n",
            "\n",
            "--- Chunk 1123 ---\n",
            "By using a nonrepresentative training set, we trained a model that is unlikely to make\n",
            "\n",
            "--- Chunk 1124 ---\n",
            "accurate predictions, especially for very poor and very rich countries.\n",
            "\n",
            "--- Chunk 1125 ---\n",
            "It is crucial to use a training set that is representative of the cases you want to general‐\n",
            "\n",
            "--- Chunk 1126 ---\n",
            "ize to. This is often harder than it sounds: if the sample is too small, you will have\n",
            "\n",
            "--- Chunk 1127 ---\n",
            "sampling noise (i.e., nonrepresentative data as a result of chance), but even very large\n",
            "\n",
            "--- Chunk 1128 ---\n",
            "samples can be nonrepresentative if the sampling method is flawed. This is called\n",
            "sampling bias.\n",
            "\n",
            "--- Chunk 1129 ---\n",
            "Main Challenges of Machine Learning | 25\n",
            "\n",
            "--- Chunk 1130 ---\n",
            "Examples of Sampling Bias\n",
            "Perhaps the most famous example of sampling bias happened during the US presi‐\n",
            "\n",
            "--- Chunk 1131 ---\n",
            "dential election in 1936, which pitted Landon against Roosevelt: the Literary Digest\n",
            "\n",
            "--- Chunk 1132 ---\n",
            "conducted a very large poll, sending mail to about 10 million people. It got 2.4 million\n",
            "\n",
            "--- Chunk 1133 ---\n",
            "answers, and predicted with high confidence that Landon would get 57% of the votes.\n",
            "\n",
            "--- Chunk 1134 ---\n",
            "Instead, Roosevelt won with 62% of the votes. The flaw was in the Literary Digest’s\n",
            "sampling method:\n",
            "\n",
            "--- Chunk 1135 ---\n",
            "• First, to obtain the addresses to send the polls to, the Literary Digest used tele‐\n",
            "\n",
            "--- Chunk 1136 ---\n",
            "phone directories, lists of magazine subscribers, club membership lists, and the\n",
            "\n",
            "--- Chunk 1137 ---\n",
            "like. All of these lists tended to favor wealthier people, who were more likely to\n",
            "vote Republican (hence Landon).\n",
            "\n",
            "--- Chunk 1138 ---\n",
            "• Second, less than 25% of the people who were polled answered. Again this intro‐\n",
            "\n",
            "--- Chunk 1139 ---\n",
            "duced a sampling bias, by potentially ruling out people who didn’t care much\n",
            "\n",
            "--- Chunk 1140 ---\n",
            "about politics, people who didn’t like the Literary Digest, and other key groups.\n",
            "This is a special type of sampling bias called nonresponse bias.\n",
            "\n",
            "--- Chunk 1141 ---\n",
            "Here is another example: say you want to build a system to recognize funk music vid‐\n",
            "\n",
            "--- Chunk 1142 ---\n",
            "eos. One way to build your training set is to search for “funk music” on YouTube and\n",
            "\n",
            "--- Chunk 1143 ---\n",
            "use the resulting videos. But this assumes that YouTube’s search engine returns a set of\n",
            "\n",
            "--- Chunk 1144 ---\n",
            "videos that are representative of all the funk music videos on YouTube. In reality, the\n",
            "\n",
            "--- Chunk 1145 ---\n",
            "search results are likely to be biased toward popular artists (and if you live in Brazil\n",
            "\n",
            "--- Chunk 1146 ---\n",
            "you will get a lot of “funk carioca” videos, which sound nothing like James Brown).\n",
            "On the other hand, how else can you get a large training set?\n",
            "\n",
            "--- Chunk 1147 ---\n",
            "Poor-Quality Data\n",
            "Obviously, if your training data is full of errors, outliers, and noise (e.g., due to poor-\n",
            "\n",
            "--- Chunk 1148 ---\n",
            "quality measurements), it will make it harder for the system to detect the underlying\n",
            "\n",
            "--- Chunk 1149 ---\n",
            "patterns, so your system is less likely to perform well. It is often well worth the effort\n",
            "\n",
            "--- Chunk 1150 ---\n",
            "to spend time cleaning up your training data. The truth is, most data scientists spend\n",
            "\n",
            "--- Chunk 1151 ---\n",
            "a significant part of their time doing just that. The following are a couple of examples\n",
            "of when you’d want to clean up training data:\n",
            "\n",
            "--- Chunk 1152 ---\n",
            "• If some instances are clearly outliers, it may help to simply discard them or try to\n",
            "fix the errors manually.\n",
            "\n",
            "--- Chunk 1153 ---\n",
            "• If some instances are missing a few features (e.g., 5% of your customers did not\n",
            "\n",
            "--- Chunk 1154 ---\n",
            "specify their age), you must decide whether you want to ignore this attribute alto‐\n",
            "\n",
            "--- Chunk 1155 ---\n",
            "gether, ignore these instances, fill in the missing values (e.g., with the median\n",
            "age), or train one model with the feature and one model without it.\n",
            "\n",
            "--- Chunk 1156 ---\n",
            "26 | Chapter 1: The Machine Learning Landscape\n",
            "\n",
            "--- Chunk 1157 ---\n",
            "Irrelevant Features\n",
            "As the saying goes: garbage in, garbage out. Your system will only be capable of learn‐\n",
            "\n",
            "--- Chunk 1158 ---\n",
            "ing if the training data contains enough relevant features and not too many irrelevant\n",
            "\n",
            "--- Chunk 1159 ---\n",
            "ones. A critical part of the success of a Machine Learning project is coming up with a\n",
            "\n",
            "--- Chunk 1160 ---\n",
            "good set of features to train on. This process, called feature engineering, involves the\n",
            "following steps:\n",
            "\n",
            "--- Chunk 1161 ---\n",
            "• Feature selection (selecting the most useful features to train on among existing\n",
            "features)\n",
            "\n",
            "--- Chunk 1162 ---\n",
            "• Feature extraction (combining existing features to produce a more useful one—as\n",
            "we saw earlier, dimensionality reduction algorithms can help)\n",
            "\n",
            "--- Chunk 1163 ---\n",
            "• Creating new features by gathering new data\n",
            "\n",
            "--- Chunk 1164 ---\n",
            "Now that we have looked at many examples of bad data, let’s look at a couple of exam‐\n",
            "ples of bad algorithms.\n",
            "\n",
            "--- Chunk 1165 ---\n",
            "Overfitting the Training Data\n",
            "Say you are visiting a foreign country and the taxi driver rips you off. You might be\n",
            "\n",
            "--- Chunk 1166 ---\n",
            "tempted to say that all taxi drivers in that country are thieves. Overgeneralizing is\n",
            "\n",
            "--- Chunk 1167 ---\n",
            "something that we humans do all too often, and unfortunately machines can fall into\n",
            "\n",
            "--- Chunk 1168 ---\n",
            "the same trap if we are not careful. In Machine Learning this is called overfitting: it\n",
            "\n",
            "--- Chunk 1169 ---\n",
            "means that the model performs well on the training data, but it does not generalize\n",
            "well.\n",
            "\n",
            "--- Chunk 1170 ---\n",
            "well.\n",
            "Figure 1-22 shows an example of a high-degree polynomial life satisfaction model\n",
            "\n",
            "--- Chunk 1171 ---\n",
            "that strongly overfits the training data. Even though it performs much better on the\n",
            "\n",
            "--- Chunk 1172 ---\n",
            "training data than the simple linear model, would you really trust its predictions?\n",
            "\n",
            "--- Chunk 1173 ---\n",
            "Figure 1-22. Overfitting the training data\n",
            "\n",
            "Main Challenges of Machine Learning | 27\n",
            "\n",
            "--- Chunk 1174 ---\n",
            "Complex models such as deep neural networks can detect subtle patterns in the data,\n",
            "\n",
            "--- Chunk 1175 ---\n",
            "but if the training set is noisy, or if it is too small (which introduces sampling noise),\n",
            "\n",
            "--- Chunk 1176 ---\n",
            "then the model is likely to detect patterns in the noise itself. Obviously these patterns\n",
            "\n",
            "--- Chunk 1177 ---\n",
            "will not generalize to new instances. For example, say you feed your life satisfaction\n",
            "\n",
            "--- Chunk 1178 ---\n",
            "model many more attributes, including uninformative ones such as the country’s\n",
            "\n",
            "--- Chunk 1179 ---\n",
            "name. In that case, a complex model may detect patterns like the fact that all coun‐\n",
            "\n",
            "--- Chunk 1180 ---\n",
            "tries in the training data with a w in their name have a life satisfaction greater than 7:\n",
            "\n",
            "--- Chunk 1181 ---\n",
            "New Zealand (7.3), Norway (7.4), Sweden (7.2), and Switzerland (7.5). How confident\n",
            "\n",
            "--- Chunk 1182 ---\n",
            "are you that the w-satisfaction rule generalizes to Rwanda or Zimbabwe? Obviously\n",
            "\n",
            "--- Chunk 1183 ---\n",
            "this pattern occurred in the training data by pure chance, but the model has no way\n",
            "\n",
            "--- Chunk 1184 ---\n",
            "to tell whether a pattern is real or simply the result of noise in the data.\n",
            "\n",
            "--- Chunk 1185 ---\n",
            "Overfitting happens when the model is too complex relative to the\n",
            "amount and noisiness of the training data. Here are possible solu‐\n",
            "tions:\n",
            "\n",
            "--- Chunk 1186 ---\n",
            "• Simplify the model by selecting one with fewer parameters\n",
            "(e.g., a linear model rather than a high-degree polynomial\n",
            "\n",
            "--- Chunk 1187 ---\n",
            "model), by reducing the number of attributes in the training\n",
            "data, or by constraining the model.\n",
            "\n",
            "--- Chunk 1188 ---\n",
            "• Gather more training data.\n",
            "• Reduce the noise in the training data (e.g., fix data errors and\n",
            "\n",
            "remove outliers).\n",
            "\n",
            "--- Chunk 1189 ---\n",
            "Constraining a model to make it simpler and reduce the risk of overfitting is called\n",
            "\n",
            "--- Chunk 1190 ---\n",
            "regularization. For example, the linear model we defined earlier has two parameters,\n",
            "\n",
            "--- Chunk 1191 ---\n",
            "θ0 and θ1. This gives the learning algorithm two degrees of freedom to adapt the model\n",
            "\n",
            "--- Chunk 1192 ---\n",
            "to the training data: it can tweak both the height (θ0) and the slope (θ1) of the line. If\n",
            "\n",
            "--- Chunk 1193 ---\n",
            "we forced θ1 = 0, the algorithm would have only one degree of freedom and would\n",
            "\n",
            "--- Chunk 1194 ---\n",
            "have a much harder time fitting the data properly: all it could do is move the line up\n",
            "\n",
            "--- Chunk 1195 ---\n",
            "or down to get as close as possible to the training instances, so it would end up\n",
            "\n",
            "--- Chunk 1196 ---\n",
            "around the mean. A very simple model indeed! If we allow the algorithm to modify θ1\n",
            "\n",
            "--- Chunk 1197 ---\n",
            "but we force it to keep it small, then the learning algorithm will effectively have some‐\n",
            "\n",
            "--- Chunk 1198 ---\n",
            "where in between one and two degrees of freedom. It will produce a model that’s sim‐\n",
            "\n",
            "--- Chunk 1199 ---\n",
            "pler than one with two degrees of freedom, but more complex than one with just one.\n",
            "\n",
            "--- Chunk 1200 ---\n",
            "You want to find the right balance between fitting the training data perfectly and\n",
            "\n",
            "--- Chunk 1201 ---\n",
            "keeping the model simple enough to ensure that it will generalize well.\n",
            "\n",
            "--- Chunk 1202 ---\n",
            "Figure 1-23 shows three models. The dotted line represents the original model that\n",
            "\n",
            "--- Chunk 1203 ---\n",
            "was trained on the countries represented as circles (without the countries represented\n",
            "\n",
            "--- Chunk 1204 ---\n",
            "as squares), the dashed line is our second model trained with all countries (circles and\n",
            "\n",
            "--- Chunk 1205 ---\n",
            "squares), and the solid line is a model trained with the same data as the first model\n",
            "\n",
            "--- Chunk 1206 ---\n",
            "28 | Chapter 1: The Machine Learning Landscape\n",
            "\n",
            "--- Chunk 1207 ---\n",
            "but with a regularization constraint. You can see that regularization forced the model\n",
            "\n",
            "--- Chunk 1208 ---\n",
            "to have a smaller slope: this model does not fit the training data (circles) as well as the\n",
            "\n",
            "--- Chunk 1209 ---\n",
            "first model, but it actually generalizes better to new examples that it did not see dur‐\n",
            "ing training (squares).\n",
            "\n",
            "--- Chunk 1210 ---\n",
            "Figure 1-23. Regularization reduces the risk of overfitting\n",
            "\n",
            "--- Chunk 1211 ---\n",
            "The amount of regularization to apply during learning can be controlled by a hyper‐\n",
            "\n",
            "--- Chunk 1212 ---\n",
            "parameter. A hyperparameter is a parameter of a learning algorithm (not of the\n",
            "\n",
            "--- Chunk 1213 ---\n",
            "model). As such, it is not affected by the learning algorithm itself; it must be set prior\n",
            "\n",
            "--- Chunk 1214 ---\n",
            "to training and remains constant during training. If you set the regularization hyper‐\n",
            "\n",
            "--- Chunk 1215 ---\n",
            "parameter to a very large value, you will get an almost flat model (a slope close to\n",
            "\n",
            "--- Chunk 1216 ---\n",
            "zero); the learning algorithm will almost certainly not overfit the training data, but it\n",
            "\n",
            "--- Chunk 1217 ---\n",
            "will be less likely to find a good solution. Tuning hyperparameters is an important\n",
            "\n",
            "--- Chunk 1218 ---\n",
            "part of building a Machine Learning system (you will see a detailed example in the\n",
            "next chapter).\n",
            "\n",
            "--- Chunk 1219 ---\n",
            "Underfitting the Training Data\n",
            "As you might guess, underfitting is the opposite of overfitting: it occurs when your\n",
            "\n",
            "--- Chunk 1220 ---\n",
            "model is too simple to learn the underlying structure of the data. For example, a lin‐\n",
            "\n",
            "--- Chunk 1221 ---\n",
            "ear model of life satisfaction is prone to underfit; reality is just more complex than\n",
            "\n",
            "--- Chunk 1222 ---\n",
            "the model, so its predictions are bound to be inaccurate, even on the training\n",
            "examples.\n",
            "Here are the main options for fixing this problem:\n",
            "\n",
            "--- Chunk 1223 ---\n",
            "• Select a more powerful model, with more parameters.\n",
            "• Feed better features to the learning algorithm (feature engineering).\n",
            "\n",
            "--- Chunk 1224 ---\n",
            "• Reduce the constraints on the model (e.g., reduce the regularization hyperpara‐\n",
            "\n",
            "--- Chunk 1225 ---\n",
            "meter).\n",
            "\n",
            "Main Challenges of Machine Learning | 29\n",
            "\n",
            "--- Chunk 1226 ---\n",
            "Stepping Back\n",
            "By now you know a lot about Machine Learning. However, we went through so many\n",
            "\n",
            "--- Chunk 1227 ---\n",
            "concepts that you may be feeling a little lost, so let’s step back and look at the big\n",
            "picture:\n",
            "\n",
            "--- Chunk 1228 ---\n",
            "• Machine Learning is about making machines get better at some task by learning\n",
            "from data, instead of having to explicitly code rules.\n",
            "\n",
            "--- Chunk 1229 ---\n",
            "• There are many different types of ML systems: supervised or not, batch or online,\n",
            "instance-based or model-based.\n",
            "\n",
            "--- Chunk 1230 ---\n",
            "• In an ML project you gather data in a training set, and you feed the training set to\n",
            "\n",
            "--- Chunk 1231 ---\n",
            "a learning algorithm. If the algorithm is model-based, it tunes some parameters\n",
            "\n",
            "--- Chunk 1232 ---\n",
            "to fit the model to the training set (i.e., to make good predictions on the training\n",
            "\n",
            "--- Chunk 1233 ---\n",
            "set itself), and then hopefully it will be able to make good predictions on new\n",
            "\n",
            "--- Chunk 1234 ---\n",
            "cases as well. If the algorithm is instance-based, it just learns the examples by\n",
            "\n",
            "--- Chunk 1235 ---\n",
            "heart and generalizes to new instances by using a similarity measure to compare\n",
            "them to the learned instances.\n",
            "\n",
            "--- Chunk 1236 ---\n",
            "• The system will not perform well if your training set is too small, or if the data is\n",
            "\n",
            "--- Chunk 1237 ---\n",
            "not representative, is noisy, or is polluted with irrelevant features (garbage in,\n",
            "\n",
            "--- Chunk 1238 ---\n",
            "garbage out). Lastly, your model needs to be neither too simple (in which case it\n",
            "will underfit) nor too complex (in which case it will overfit).\n",
            "\n",
            "--- Chunk 1239 ---\n",
            "There’s just one last important topic to cover: once you have trained a model, you\n",
            "\n",
            "--- Chunk 1240 ---\n",
            "don’t want to just “hope” it generalizes to new cases. You want to evaluate it and fine-\n",
            "tune it if necessary. Let’s see how to do that.\n",
            "\n",
            "--- Chunk 1241 ---\n",
            "Testing and Validating\n",
            "The only way to know how well a model will generalize to new cases is to actually try\n",
            "\n",
            "--- Chunk 1242 ---\n",
            "it out on new cases. One way to do that is to put your model in production and moni‐\n",
            "\n",
            "--- Chunk 1243 ---\n",
            "tor how well it performs. This works well, but if your model is horribly bad, your\n",
            "users will complain—not the best idea.\n",
            "\n",
            "--- Chunk 1244 ---\n",
            "A better option is to split your data into two sets: the training set and the test set. As\n",
            "\n",
            "--- Chunk 1245 ---\n",
            "these names imply, you train your model using the training set, and you test it using\n",
            "\n",
            "--- Chunk 1246 ---\n",
            "the test set. The error rate on new cases is called the generalization error (or out-of-\n",
            "\n",
            "--- Chunk 1247 ---\n",
            "sample error), and by evaluating your model on the test set, you get an estimate of this\n",
            "\n",
            "--- Chunk 1248 ---\n",
            "error. This value tells you how well your model will perform on instances it has never\n",
            "seen before.\n",
            "\n",
            "--- Chunk 1249 ---\n",
            "seen before.\n",
            "If the training error is low (i.e., your model makes few mistakes on the training set)\n",
            "\n",
            "--- Chunk 1250 ---\n",
            "but the generalization error is high, it means that your model is overfitting the train‐\n",
            "ing data.\n",
            "\n",
            "--- Chunk 1251 ---\n",
            "30 | Chapter 1: The Machine Learning Landscape\n",
            "\n",
            "--- Chunk 1252 ---\n",
            "It is common to use 80% of the data for training and hold out 20%\n",
            "for testing. However, this depends on the size of the dataset: if it\n",
            "\n",
            "--- Chunk 1253 ---\n",
            "contains 10 million instances, then holding out 1% means your test\n",
            "set will contain 100,000 instances, probably more than enough to\n",
            "\n",
            "--- Chunk 1254 ---\n",
            "get a good estimate of the generalization error.\n",
            "\n",
            "--- Chunk 1255 ---\n",
            "Hyperparameter Tuning and Model Selection\n",
            "Evaluating a model is simple enough: just use a test set. But suppose you are hesitat‐\n",
            "\n",
            "--- Chunk 1256 ---\n",
            "ing between two types of models (say, a linear model and a polynomial model): how\n",
            "\n",
            "--- Chunk 1257 ---\n",
            "can you decide between them? One option is to train both and compare how well\n",
            "they generalize using the test set.\n",
            "\n",
            "--- Chunk 1258 ---\n",
            "Now suppose that the linear model generalizes better, but you want to apply some\n",
            "\n",
            "--- Chunk 1259 ---\n",
            "regularization to avoid overfitting. The question is, how do you choose the value of\n",
            "\n",
            "--- Chunk 1260 ---\n",
            "the regularization hyperparameter? One option is to train 100 different models using\n",
            "\n",
            "--- Chunk 1261 ---\n",
            "100 different values for this hyperparameter. Suppose you find the best hyperparame‐\n",
            "\n",
            "--- Chunk 1262 ---\n",
            "ter value that produces a model with the lowest generalization error—say, just 5%\n",
            "\n",
            "--- Chunk 1263 ---\n",
            "error. You launch this model into production, but unfortunately it does not perform\n",
            "as well as expected and produces 15% errors. What just happened?\n",
            "\n",
            "--- Chunk 1264 ---\n",
            "The problem is that you measured the generalization error multiple times on the test\n",
            "\n",
            "--- Chunk 1265 ---\n",
            "set, and you adapted the model and hyperparameters to produce the best model for\n",
            "\n",
            "--- Chunk 1266 ---\n",
            "that particular set. This means that the model is unlikely to perform as well on new\n",
            "data.\n",
            "\n",
            "--- Chunk 1267 ---\n",
            "data.\n",
            "A common solution to this problem is called holdout validation: you simply hold out\n",
            "\n",
            "--- Chunk 1268 ---\n",
            "part of the training set to evaluate several candidate models and select the best one.\n",
            "\n",
            "--- Chunk 1269 ---\n",
            "The new held-out set is called the validation set (or sometimes the development set, or\n",
            "\n",
            "--- Chunk 1270 ---\n",
            "dev set). More specifically, you train multiple models with various hyperparameters\n",
            "\n",
            "--- Chunk 1271 ---\n",
            "on the reduced training set (i.e., the full training set minus the validation set), and\n",
            "\n",
            "--- Chunk 1272 ---\n",
            "you select the model that performs best on the validation set. After this holdout vali‐\n",
            "\n",
            "--- Chunk 1273 ---\n",
            "dation process, you train the best model on the full training set (including the valida‐\n",
            "\n",
            "--- Chunk 1274 ---\n",
            "tion set), and this gives you the final model. Lastly, you evaluate this final model on\n",
            "the test set to get an estimate of the generalization error.\n",
            "\n",
            "--- Chunk 1275 ---\n",
            "This solution usually works quite well. However, if the validation set is too small, then\n",
            "\n",
            "--- Chunk 1276 ---\n",
            "model evaluations will be imprecise: you may end up selecting a suboptimal model by\n",
            "\n",
            "--- Chunk 1277 ---\n",
            "mistake. Conversely, if the validation set is too large, then the remaining training set\n",
            "\n",
            "--- Chunk 1278 ---\n",
            "will be much smaller than the full training set. Why is this bad? Well, since the final\n",
            "\n",
            "--- Chunk 1279 ---\n",
            "model will be trained on the full training set, it is not ideal to compare candidate\n",
            "\n",
            "--- Chunk 1280 ---\n",
            "models trained on a much smaller training set. It would be like selecting the fastest\n",
            "\n",
            "--- Chunk 1281 ---\n",
            "sprinter to participate in a marathon. One way to solve this problem is to perform\n",
            "\n",
            "--- Chunk 1282 ---\n",
            "repeated cross-validation, using many small validation sets. Each model is evaluated\n",
            "\n",
            "--- Chunk 1283 ---\n",
            "once per validation set after it is trained on the rest of the data. By averaging out all\n",
            "\n",
            "--- Chunk 1284 ---\n",
            "Testing and Validating | 31\n",
            "\n",
            "--- Chunk 1285 ---\n",
            "the evaluations of a model, you get a much more accurate measure of its perfor‐\n",
            "\n",
            "--- Chunk 1286 ---\n",
            "mance. There is a drawback, however: the training time is multiplied by the number\n",
            "of validation sets.\n",
            "\n",
            "--- Chunk 1287 ---\n",
            "Data Mismatch\n",
            "In some cases, it’s easy to get a large amount of data for training, but this data proba‐\n",
            "\n",
            "--- Chunk 1288 ---\n",
            "bly won’t be perfectly representative of the data that will be used in production. For\n",
            "\n",
            "--- Chunk 1289 ---\n",
            "example, suppose you want to create a mobile app to take pictures of flowers and\n",
            "\n",
            "--- Chunk 1290 ---\n",
            "automatically determine their species. You can easily download millions of pictures of\n",
            "\n",
            "--- Chunk 1291 ---\n",
            "flowers on the web, but they won’t be perfectly representative of the pictures that will\n",
            "\n",
            "--- Chunk 1292 ---\n",
            "actually be taken using the app on a mobile device. Perhaps you only have 10,000 rep‐\n",
            "\n",
            "--- Chunk 1293 ---\n",
            "resentative pictures (i.e., actually taken with the app). In this case, the most important\n",
            "\n",
            "--- Chunk 1294 ---\n",
            "rule to remember is that the validation set and the test set must be as representative as\n",
            "\n",
            "--- Chunk 1295 ---\n",
            "possible of the data you expect to use in production, so they should be composed\n",
            "\n",
            "--- Chunk 1296 ---\n",
            "exclusively of representative pictures: you can shuffle them and put half in the valida‐\n",
            "\n",
            "--- Chunk 1297 ---\n",
            "tion set and half in the test set (making sure that no duplicates or near-duplicates end\n",
            "\n",
            "--- Chunk 1298 ---\n",
            "up in both sets). But after training your model on the web pictures, if you observe\n",
            "\n",
            "--- Chunk 1299 ---\n",
            "that the performance of the model on the validation set is disappointing, you will not\n",
            "\n",
            "--- Chunk 1300 ---\n",
            "know whether this is because your model has overfit the training set, or whether this\n",
            "\n",
            "--- Chunk 1301 ---\n",
            "is just due to the mismatch between the web pictures and the mobile app pictures.\n",
            "\n",
            "--- Chunk 1302 ---\n",
            "One solution is to hold out some of the training pictures (from the web) in yet\n",
            "\n",
            "--- Chunk 1303 ---\n",
            "another set that Andrew Ng calls the train-dev set. After the model is trained (on the\n",
            "\n",
            "--- Chunk 1304 ---\n",
            "training set, not on the train-dev set), you can evaluate it on the train-dev set. If it\n",
            "\n",
            "--- Chunk 1305 ---\n",
            "performs well, then the model is not overfitting the training set. If it performs poorly\n",
            "\n",
            "--- Chunk 1306 ---\n",
            "on the validation set, the problem must be coming from the data mismatch. You can\n",
            "\n",
            "--- Chunk 1307 ---\n",
            "try to tackle this problem by preprocessing the web images to make them look more\n",
            "\n",
            "--- Chunk 1308 ---\n",
            "like the pictures that will be taken by the mobile app, and then retraining the model.\n",
            "\n",
            "--- Chunk 1309 ---\n",
            "Conversely, if the model performs poorly on the train-dev set, then it must have over‐\n",
            "\n",
            "--- Chunk 1310 ---\n",
            "fit the training set, so you should try to simplify or regularize the model, get more\n",
            "training data, and clean up the training data.\n",
            "\n",
            "--- Chunk 1311 ---\n",
            "32 | Chapter 1: The Machine Learning Landscape\n",
            "\n",
            "--- Chunk 1312 ---\n",
            "No Free Lunch Theorem\n",
            "A model is a simplified version of the observations. The simplifications are meant to\n",
            "\n",
            "--- Chunk 1313 ---\n",
            "discard the superfluous details that are unlikely to generalize to new instances. To\n",
            "\n",
            "--- Chunk 1314 ---\n",
            "decide what data to discard and what data to keep, you must make assumptions. For\n",
            "\n",
            "--- Chunk 1315 ---\n",
            "example, a linear model makes the assumption that the data is fundamentally linear\n",
            "\n",
            "--- Chunk 1316 ---\n",
            "and that the distance between the instances and the straight line is just noise, which\n",
            "can safely be ignored.\n",
            "\n",
            "--- Chunk 1317 ---\n",
            "In a famous 1996 paper,11 David Wolpert demonstrated that if you make absolutely\n",
            "\n",
            "--- Chunk 1318 ---\n",
            "no assumption about the data, then there is no reason to prefer one model over any\n",
            "\n",
            "--- Chunk 1319 ---\n",
            "other. This is called the No Free Lunch (NFL) theorem. For some datasets the best\n",
            "\n",
            "--- Chunk 1320 ---\n",
            "model is a linear model, while for other datasets it is a neural network. There is no\n",
            "\n",
            "--- Chunk 1321 ---\n",
            "model that is a priori guaranteed to work better (hence the name of the theorem). The\n",
            "\n",
            "--- Chunk 1322 ---\n",
            "only way to know for sure which model is best is to evaluate them all. Since this is not\n",
            "\n",
            "--- Chunk 1323 ---\n",
            "possible, in practice you make some reasonable assumptions about the data and eval‐\n",
            "\n",
            "--- Chunk 1324 ---\n",
            "uate only a few reasonable models. For example, for simple tasks you may evaluate\n",
            "\n",
            "--- Chunk 1325 ---\n",
            "linear models with various levels of regularization, and for a complex problem you\n",
            "may evaluate various neural networks.\n",
            "\n",
            "--- Chunk 1326 ---\n",
            "Exercises\n",
            "In this chapter we have covered some of the most important concepts in Machine\n",
            "\n",
            "--- Chunk 1327 ---\n",
            "Learning. In the next chapters we will dive deeper and write more code, but before we\n",
            "do, make sure you know how to answer the following questions:\n",
            "\n",
            "--- Chunk 1328 ---\n",
            "1. How would you define Machine Learning?\n",
            "2. Can you name four types of problems where it shines?\n",
            "3. What is a labeled training set?\n",
            "\n",
            "--- Chunk 1329 ---\n",
            "4. What are the two most common supervised tasks?\n",
            "5. Can you name four common unsupervised tasks?\n",
            "\n",
            "--- Chunk 1330 ---\n",
            "6. What type of Machine Learning algorithm would you use to allow a robot to\n",
            "\n",
            "--- Chunk 1331 ---\n",
            "walk in various unknown terrains?\n",
            "7. What type of algorithm would you use to segment your customers into multiple\n",
            "\n",
            "--- Chunk 1332 ---\n",
            "groups?\n",
            "8. Would you frame the problem of spam detection as a supervised learning prob‐\n",
            "\n",
            "lem or an unsupervised learning problem?\n",
            "\n",
            "--- Chunk 1333 ---\n",
            "11 David Wolpert, “The Lack of A Priori Distinctions Between Learning Algorithms,” Neural Computation 8, no.\n",
            "7 (1996): 1341–1390.\n",
            "\n",
            "Exercises | 33\n",
            "\n",
            "--- Chunk 1334 ---\n",
            "9. What is an online learning system?\n",
            "10. What is out-of-core learning?\n",
            "\n",
            "--- Chunk 1335 ---\n",
            "11. What type of learning algorithm relies on a similarity measure to make predic‐\n",
            "\n",
            "--- Chunk 1336 ---\n",
            "tions?\n",
            "12. What is the difference between a model parameter and a learning algorithm’s\n",
            "\n",
            "--- Chunk 1337 ---\n",
            "hyperparameter?\n",
            "13. What do model-based learning algorithms search for? What is the most common\n",
            "\n",
            "--- Chunk 1338 ---\n",
            "strategy they use to succeed? How do they make predictions?\n",
            "14. Can you name four of the main challenges in Machine Learning?\n",
            "\n",
            "--- Chunk 1339 ---\n",
            "15. If your model performs great on the training data but generalizes poorly to new\n",
            "\n",
            "--- Chunk 1340 ---\n",
            "instances, what is happening? Can you name three possible solutions?\n",
            "16. What is a test set, and why would you want to use it?\n",
            "\n",
            "--- Chunk 1341 ---\n",
            "17. What is the purpose of a validation set?\n",
            "18. What is the train-dev set, when do you need it, and how do you use it?\n",
            "\n",
            "--- Chunk 1342 ---\n",
            "19. What can go wrong if you tune hyperparameters using the test set?\n",
            "\n",
            "--- Chunk 1343 ---\n",
            "Solutions to these exercises are available in Appendix A.\n",
            "\n",
            "34 | Chapter 1: The Machine Learning Landscape\n",
            "\n",
            "--- Chunk 1344 ---\n",
            "CHAPTER 2\n",
            "End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 1345 ---\n",
            "In this chapter you will work through an example project end to end, pretending to\n",
            "\n",
            "--- Chunk 1346 ---\n",
            "be a recently hired data scientist at a real estate company.1 Here are the main steps\n",
            "you will go through:\n",
            "\n",
            "--- Chunk 1347 ---\n",
            "1. Look at the big picture.\n",
            "2. Get the data.\n",
            "3. Discover and visualize the data to gain insights.\n",
            "\n",
            "--- Chunk 1348 ---\n",
            "4. Prepare the data for Machine Learning algorithms.\n",
            "5. Select a model and train it.\n",
            "6. Fine-tune your model.\n",
            "7. Present your solution.\n",
            "\n",
            "--- Chunk 1349 ---\n",
            "8. Launch, monitor, and maintain your system.\n",
            "\n",
            "--- Chunk 1350 ---\n",
            "Working with Real Data\n",
            "When you are learning about Machine Learning, it is best to experiment with real-\n",
            "\n",
            "--- Chunk 1351 ---\n",
            "world data, not artificial datasets. Fortunately, there are thousands of open datasets to\n",
            "\n",
            "--- Chunk 1352 ---\n",
            "choose from, ranging across all sorts of domains. Here are a few places you can look\n",
            "to get data:\n",
            "\n",
            "--- Chunk 1353 ---\n",
            "1 The example project is fictitious; the goal is to illustrate the main steps of a Machine Learning project, not to\n",
            "\n",
            "--- Chunk 1354 ---\n",
            "learn anything about the real estate business.\n",
            "\n",
            "--- Chunk 1355 ---\n",
            "35\n",
            "\n",
            "\n",
            "\n",
            "• Popular open data repositories\n",
            "— UC Irvine Machine Learning Repository\n",
            "— Kaggle datasets\n",
            "— Amazon’s AWS datasets\n",
            "\n",
            "--- Chunk 1356 ---\n",
            "• Meta portals (they list open data repositories)\n",
            "— Data Portals\n",
            "— OpenDataMonitor\n",
            "— Quandl\n",
            "\n",
            "--- Chunk 1357 ---\n",
            "• Other pages listing many popular open data repositories\n",
            "— Wikipedia’s list of Machine Learning datasets\n",
            "— Quora.com\n",
            "— The datasets subreddit\n",
            "\n",
            "--- Chunk 1358 ---\n",
            "In this chapter we’ll use the California Housing Prices dataset from the StatLib repos‐\n",
            "\n",
            "--- Chunk 1359 ---\n",
            "itory2 (see Figure 2-1). This dataset is based on data from the 1990 California census.\n",
            "\n",
            "--- Chunk 1360 ---\n",
            "It is not exactly recent (a nice house in the Bay Area was still affordable at the time),\n",
            "\n",
            "--- Chunk 1361 ---\n",
            "but it has many qualities for learning, so we will pretend it is recent data. For teaching\n",
            "\n",
            "--- Chunk 1362 ---\n",
            "purposes I’ve added a categorical attribute and removed a few features.\n",
            "\n",
            "--- Chunk 1363 ---\n",
            "Figure 2-1. California housing prices\n",
            "\n",
            "--- Chunk 1364 ---\n",
            "2 The original dataset appeared in R. Kelley Pace and Ronald Barry, “Sparse Spatial Autoregressions,” Statistics\n",
            "\n",
            "--- Chunk 1365 ---\n",
            "& Probability Letters 33, no. 3 (1997): 291–297.\n",
            "\n",
            "--- Chunk 1366 ---\n",
            "36 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 1367 ---\n",
            "Look at the Big Picture\n",
            "Welcome to the Machine Learning Housing Corporation! Your first task is to use Cal‐\n",
            "\n",
            "--- Chunk 1368 ---\n",
            "ifornia census data to build a model of housing prices in the state. This data includes\n",
            "\n",
            "--- Chunk 1369 ---\n",
            "metrics such as the population, median income, and median housing price for each\n",
            "\n",
            "--- Chunk 1370 ---\n",
            "block group in California. Block groups are the smallest geographical unit for which\n",
            "\n",
            "--- Chunk 1371 ---\n",
            "the US Census Bureau publishes sample data (a block group typically has a popula‐\n",
            "\n",
            "--- Chunk 1372 ---\n",
            "tion of 600 to 3,000 people). We will call them “districts” for short.\n",
            "\n",
            "--- Chunk 1373 ---\n",
            "Your model should learn from this data and be able to predict the median housing\n",
            "price in any district, given all the other metrics.\n",
            "\n",
            "--- Chunk 1374 ---\n",
            "Since you are a well-organized data scientist, the first thing you\n",
            "should do is pull out your Machine Learning project checklist. You\n",
            "\n",
            "--- Chunk 1375 ---\n",
            "can start with the one in Appendix B; it should work reasonably\n",
            "well for most Machine Learning projects, but make sure to adapt it\n",
            "\n",
            "--- Chunk 1376 ---\n",
            "to your needs. In this chapter we will go through many checklist\n",
            "items, but we will also skip a few, either because they are self-\n",
            "\n",
            "--- Chunk 1377 ---\n",
            "explanatory or because they will be discussed in later chapters.\n",
            "\n",
            "--- Chunk 1378 ---\n",
            "Frame the Problem\n",
            "The first question to ask your boss is what exactly the business objective is. Building a\n",
            "\n",
            "--- Chunk 1379 ---\n",
            "model is probably not the end goal. How does the company expect to use and benefit\n",
            "\n",
            "--- Chunk 1380 ---\n",
            "from this model? Knowing the objective is important because it will determine how\n",
            "\n",
            "--- Chunk 1381 ---\n",
            "you frame the problem, which algorithms you will select, which performance meas‐\n",
            "\n",
            "--- Chunk 1382 ---\n",
            "ure you will use to evaluate your model, and how much effort you will spend tweak‐\n",
            "ing it.\n",
            "\n",
            "--- Chunk 1383 ---\n",
            "ing it.\n",
            "Your boss answers that your model’s output (a prediction of a district’s median hous‐\n",
            "\n",
            "--- Chunk 1384 ---\n",
            "ing price) will be fed to another Machine Learning system (see Figure 2-2), along\n",
            "\n",
            "--- Chunk 1385 ---\n",
            "with many other signals.3 This downstream system will determine whether it is worth\n",
            "\n",
            "--- Chunk 1386 ---\n",
            "investing in a given area or not. Getting this right is critical, as it directly affects\n",
            "revenue.\n",
            "\n",
            "--- Chunk 1387 ---\n",
            "3 A piece of information fed to a Machine Learning system is often called a signal, in reference to Claude Shan‐\n",
            "\n",
            "--- Chunk 1388 ---\n",
            "non’s information theory, which he developed at Bell Labs to improve telecommunications. His theory: you\n",
            "want a high signal-to-noise ratio.\n",
            "\n",
            "--- Chunk 1389 ---\n",
            "Look at the Big Picture | 37\n",
            "\n",
            "\n",
            "\n",
            "Figure 2-2. A Machine Learning pipeline for real estate investments\n",
            "\n",
            "--- Chunk 1390 ---\n",
            "Pipelines\n",
            "A sequence of data processing components is called a data pipeline. Pipelines are very\n",
            "\n",
            "--- Chunk 1391 ---\n",
            "common in Machine Learning systems, since there is a lot of data to manipulate and\n",
            "many data transformations to apply.\n",
            "\n",
            "--- Chunk 1392 ---\n",
            "Components typically run asynchronously. Each component pulls in a large amount\n",
            "\n",
            "--- Chunk 1393 ---\n",
            "of data, processes it, and spits out the result in another data store. Then, some time\n",
            "\n",
            "--- Chunk 1394 ---\n",
            "later, the next component in the pipeline pulls this data and spits out its own output.\n",
            "\n",
            "--- Chunk 1395 ---\n",
            "Each component is fairly self-contained: the interface between components is simply\n",
            "\n",
            "--- Chunk 1396 ---\n",
            "the data store. This makes the system simple to grasp (with the help of a data flow\n",
            "\n",
            "--- Chunk 1397 ---\n",
            "graph), and different teams can focus on different components. Moreover, if a com‐\n",
            "\n",
            "--- Chunk 1398 ---\n",
            "ponent breaks down, the downstream components can often continue to run nor‐\n",
            "\n",
            "--- Chunk 1399 ---\n",
            "mally (at least for a while) by just using the last output from the broken component.\n",
            "This makes the architecture quite robust.\n",
            "\n",
            "--- Chunk 1400 ---\n",
            "On the other hand, a broken component can go unnoticed for some time if proper\n",
            "\n",
            "--- Chunk 1401 ---\n",
            "monitoring is not implemented. The data gets stale and the overall system’s perfor‐\n",
            "mance drops.\n",
            "\n",
            "--- Chunk 1402 ---\n",
            "The next question to ask your boss is what the current solution looks like (if any).\n",
            "\n",
            "--- Chunk 1403 ---\n",
            "The current situation will often give you a reference for performance, as well as\n",
            "\n",
            "--- Chunk 1404 ---\n",
            "insights on how to solve the problem. Your boss answers that the district housing pri‐\n",
            "\n",
            "--- Chunk 1405 ---\n",
            "ces are currently estimated manually by experts: a team gathers up-to-date informa‐\n",
            "\n",
            "--- Chunk 1406 ---\n",
            "tion about a district, and when they cannot get the median housing price, they\n",
            "estimate it using complex rules.\n",
            "\n",
            "--- Chunk 1407 ---\n",
            "This is costly and time-consuming, and their estimates are not great; in cases where\n",
            "\n",
            "--- Chunk 1408 ---\n",
            "they manage to find out the actual median housing price, they often realize that their\n",
            "\n",
            "--- Chunk 1409 ---\n",
            "estimates were off by more than 20%. This is why the company thinks that it would\n",
            "\n",
            "--- Chunk 1410 ---\n",
            "be useful to train a model to predict a district’s median housing price, given other\n",
            "\n",
            "--- Chunk 1411 ---\n",
            "38 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 1412 ---\n",
            "data about that district. The census data looks like a great dataset to exploit for this\n",
            "\n",
            "--- Chunk 1413 ---\n",
            "purpose, since it includes the median housing prices of thousands of districts, as well\n",
            "as other data.\n",
            "\n",
            "--- Chunk 1414 ---\n",
            "as other data.\n",
            "With all this information, you are now ready to start designing your system. First,\n",
            "\n",
            "--- Chunk 1415 ---\n",
            "you need to frame the problem: is it supervised, unsupervised, or Reinforcement\n",
            "\n",
            "--- Chunk 1416 ---\n",
            "Learning? Is it a classification task, a regression task, or something else? Should you\n",
            "\n",
            "--- Chunk 1417 ---\n",
            "use batch learning or online learning techniques? Before you read on, pause and try\n",
            "to answer these questions for yourself.\n",
            "\n",
            "--- Chunk 1418 ---\n",
            "Have you found the answers? Let’s see: it is clearly a typical supervised learning task,\n",
            "\n",
            "--- Chunk 1419 ---\n",
            "since you are given labeled training examples (each instance comes with the expected\n",
            "\n",
            "--- Chunk 1420 ---\n",
            "output, i.e., the district’s median housing price). It is also a typical regression task,\n",
            "\n",
            "--- Chunk 1421 ---\n",
            "since you are asked to predict a value. More specifically, this is a multiple regression\n",
            "\n",
            "--- Chunk 1422 ---\n",
            "problem, since the system will use multiple features to make a prediction (it will use\n",
            "\n",
            "--- Chunk 1423 ---\n",
            "the district’s population, the median income, etc.). It is also a univariate regression\n",
            "\n",
            "--- Chunk 1424 ---\n",
            "problem, since we are only trying to predict a single value for each district. If we were\n",
            "\n",
            "--- Chunk 1425 ---\n",
            "trying to predict multiple values per district, it would be a multivariate regression\n",
            "\n",
            "--- Chunk 1426 ---\n",
            "problem. Finally, there is no continuous flow of data coming into the system, there is\n",
            "\n",
            "--- Chunk 1427 ---\n",
            "no particular need to adjust to changing data rapidly, and the data is small enough to\n",
            "fit in memory, so plain batch learning should do just fine.\n",
            "\n",
            "--- Chunk 1428 ---\n",
            "If the data were huge, you could either split your batch learning\n",
            "work across multiple servers (using the MapReduce technique) or\n",
            "\n",
            "--- Chunk 1429 ---\n",
            "use an online learning technique.\n",
            "\n",
            "--- Chunk 1430 ---\n",
            "Select a Performance Measure\n",
            "Your next step is to select a performance measure. A typical performance measure for\n",
            "\n",
            "--- Chunk 1431 ---\n",
            "regression problems is the Root Mean Square Error (RMSE). It gives an idea of how\n",
            "\n",
            "--- Chunk 1432 ---\n",
            "much error the system typically makes in its predictions, with a higher weight for\n",
            "\n",
            "--- Chunk 1433 ---\n",
            "large errors. Equation 2-1 shows the mathematical formula to compute the RMSE.\n",
            "\n",
            "--- Chunk 1434 ---\n",
            "Equation 2-1. Root Mean Square Error (RMSE)\n",
            "m\n",
            "\n",
            "RMSE X, h = 1\n",
            "m ∑ h x i − y i 2\n",
            "\n",
            "i = 1\n",
            "\n",
            "Look at the Big Picture | 39\n",
            "\n",
            "--- Chunk 1435 ---\n",
            "Notations\n",
            "This equation introduces several very common Machine Learning notations that we\n",
            "will use throughout this book:\n",
            "\n",
            "--- Chunk 1436 ---\n",
            "• m is the number of instances in the dataset you are measuring the RMSE on.\n",
            "\n",
            "--- Chunk 1437 ---\n",
            "— For example, if you are evaluating the RMSE on a validation set of 2,000 dis‐\n",
            "\n",
            "--- Chunk 1438 ---\n",
            "tricts, then m = 2,000.\n",
            "• x(i) is a vector of all the feature values (excluding the label) of the ith instance in\n",
            "\n",
            "--- Chunk 1439 ---\n",
            "the dataset, and y(i) is its label (the desired output value for that instance).\n",
            "\n",
            "--- Chunk 1440 ---\n",
            "— For example, if the first district in the dataset is located at longitude –118.29°,\n",
            "\n",
            "--- Chunk 1441 ---\n",
            "latitude 33.91°, and it has 1,416 inhabitants with a median income of $38,372,\n",
            "\n",
            "--- Chunk 1442 ---\n",
            "and the median house value is $156,400 (ignoring the other features for now),\n",
            "then:\n",
            "\n",
            "--- Chunk 1443 ---\n",
            "−118.29\n",
            "33.91\n",
            "\n",
            "x 1 =\n",
            "1,416\n",
            "\n",
            "38,372\n",
            "\n",
            "and:\n",
            "\n",
            "y 1 = 156,400\n",
            "\n",
            "--- Chunk 1444 ---\n",
            "• X is a matrix containing all the feature values (excluding labels) of all instances in\n",
            "\n",
            "--- Chunk 1445 ---\n",
            "the dataset. There is one row per instance, and the ith row is equal to the trans‐\n",
            "pose of x(i), noted (x(i))⊺.4\n",
            "\n",
            "--- Chunk 1446 ---\n",
            "— For example, if the first district is as just described, then the matrix X looks\n",
            "like this:\n",
            "\n",
            "x 1 ⊺\n",
            "\n",
            "x 2 ⊺\n",
            "\n",
            "−118.29 33.91 1,416 38,372\n",
            "X = ⋮ =\n",
            "\n",
            "--- Chunk 1447 ---\n",
            "⋮ ⋮ ⋮ ⋮\n",
            "x 1999 ⊺\n",
            "\n",
            "x 2000 ⊺\n",
            "\n",
            "4 Recall that the transpose operator flips a column vector into a row vector (and vice versa).\n",
            "\n",
            "--- Chunk 1448 ---\n",
            "40 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 1449 ---\n",
            "• h is your system’s prediction function, also called a hypothesis. When your system\n",
            "\n",
            "--- Chunk 1450 ---\n",
            "is given an instance’s feature vector x(i), it outputs a predicted value ŷ(i) = h(x(i))\n",
            "for that instance (ŷ is pronounced “y-hat”).\n",
            "\n",
            "--- Chunk 1451 ---\n",
            "— For example, if your system predicts that the median housing price in the first\n",
            "\n",
            "--- Chunk 1452 ---\n",
            "district is $158,400, then ŷ(1) = h(x(1)) = 158,400. The prediction error for this\n",
            "district is ŷ(1) – y(1) = 2,000.\n",
            "\n",
            "--- Chunk 1453 ---\n",
            "• RMSE(X,h) is the cost function measured on the set of examples using your\n",
            "hypothesis h.\n",
            "\n",
            "--- Chunk 1454 ---\n",
            "We use lowercase italic font for scalar values (such as m or y(i)) and function names\n",
            "\n",
            "--- Chunk 1455 ---\n",
            "(such as h), lowercase bold font for vectors (such as x(i)), and uppercase bold font for\n",
            "matrices (such as X).\n",
            "\n",
            "--- Chunk 1456 ---\n",
            "Even though the RMSE is generally the preferred performance measure for regression\n",
            "\n",
            "--- Chunk 1457 ---\n",
            "tasks, in some contexts you may prefer to use another function. For example, suppose\n",
            "\n",
            "--- Chunk 1458 ---\n",
            "that there are many outlier districts. In that case, you may consider using the mean\n",
            "\n",
            "--- Chunk 1459 ---\n",
            "absolute error (MAE, also called the average absolute deviation; see Equation 2-2):\n",
            "\n",
            "--- Chunk 1460 ---\n",
            "Equation 2-2. Mean absolute error (MAE)\n",
            "m\n",
            "\n",
            "MAE X, h = 1\n",
            "m ∑ h x i − y i\n",
            "\n",
            "i = 1\n",
            "\n",
            "--- Chunk 1461 ---\n",
            "Both the RMSE and the MAE are ways to measure the distance between two vectors:\n",
            "\n",
            "--- Chunk 1462 ---\n",
            "the vector of predictions and the vector of target values. Various distance measures,\n",
            "or norms, are possible:\n",
            "\n",
            "--- Chunk 1463 ---\n",
            "• Computing the root of a sum of squares (RMSE) corresponds to the Euclidean\n",
            "\n",
            "--- Chunk 1464 ---\n",
            "norm: this is the notion of distance you are familiar with. It is also called the ℓ2\n",
            "norm, noted ∥ · ∥2 (or just ∥ · ∥).\n",
            "\n",
            "--- Chunk 1465 ---\n",
            "• Computing the sum of absolutes (MAE) corresponds to the ℓ1 norm, noted ∥ · ∥1.\n",
            "\n",
            "--- Chunk 1466 ---\n",
            "This is sometimes called the Manhattan norm because it measures the distance\n",
            "\n",
            "--- Chunk 1467 ---\n",
            "between two points in a city if you can only travel along orthogonal city blocks.\n",
            "\n",
            "--- Chunk 1468 ---\n",
            "• More generally, the ℓk norm of a vector v containing n elements is defined as ∥v∥k\n",
            "\n",
            "--- Chunk 1469 ---\n",
            "= (|v0|k + |v1|k + ... + |vn|k)1/k. ℓ0 gives the number of nonzero elements in the vec‐\n",
            "tor, and ℓ∞ gives the maximum absolute value in the vector.\n",
            "\n",
            "--- Chunk 1470 ---\n",
            "• The higher the norm index, the more it focuses on large values and neglects small\n",
            "\n",
            "--- Chunk 1471 ---\n",
            "ones. This is why the RMSE is more sensitive to outliers than the MAE. But when\n",
            "\n",
            "--- Chunk 1472 ---\n",
            "outliers are exponentially rare (like in a bell-shaped curve), the RMSE performs\n",
            "very well and is generally preferred.\n",
            "\n",
            "--- Chunk 1473 ---\n",
            "Look at the Big Picture | 41\n",
            "\n",
            "--- Chunk 1474 ---\n",
            "Check the Assumptions\n",
            "Lastly, it is good practice to list and verify the assumptions that have been made so far\n",
            "\n",
            "--- Chunk 1475 ---\n",
            "(by you or others); this can help you catch serious issues early on. For example, the\n",
            "\n",
            "--- Chunk 1476 ---\n",
            "district prices that your system outputs are going to be fed into a downstream\n",
            "\n",
            "--- Chunk 1477 ---\n",
            "Machine Learning system, and you assume that these prices are going to be used as\n",
            "\n",
            "--- Chunk 1478 ---\n",
            "such. But what if the downstream system converts the prices into categories (e.g.,\n",
            "\n",
            "--- Chunk 1479 ---\n",
            "“cheap,” “medium,” or “expensive”) and then uses those categories instead of the pri‐\n",
            "\n",
            "--- Chunk 1480 ---\n",
            "ces themselves? In this case, getting the price perfectly right is not important at all;\n",
            "\n",
            "--- Chunk 1481 ---\n",
            "your system just needs to get the category right. If that’s so, then the problem should\n",
            "\n",
            "--- Chunk 1482 ---\n",
            "have been framed as a classification task, not a regression task. You don’t want to find\n",
            "this out after working on a regression system for months.\n",
            "\n",
            "--- Chunk 1483 ---\n",
            "Fortunately, after talking with the team in charge of the downstream system, you are\n",
            "\n",
            "--- Chunk 1484 ---\n",
            "confident that they do indeed need the actual prices, not just categories. Great! You’re\n",
            "all set, the lights are green, and you can start coding now!\n",
            "\n",
            "--- Chunk 1485 ---\n",
            "Get the Data\n",
            "It’s time to get your hands dirty. Don’t hesitate to pick up your laptop and walk\n",
            "\n",
            "--- Chunk 1486 ---\n",
            "through the following code examples in a Jupyter notebook. The full Jupyter note‐\n",
            "book is available at https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 1487 ---\n",
            "Create the Workspace\n",
            "First you will need to have Python installed. It is probably already installed on your\n",
            "\n",
            "--- Chunk 1488 ---\n",
            "system. If not, you can get it at https://www.python.org/.5\n",
            "\n",
            "--- Chunk 1489 ---\n",
            "Next you need to create a workspace directory for your Machine Learning code and\n",
            "\n",
            "--- Chunk 1490 ---\n",
            "datasets. Open a terminal and type the following commands (after the $ prompts):\n",
            "\n",
            "--- Chunk 1491 ---\n",
            "$ export ML_PATH=\"$HOME/ml\"      # You can change the path if you prefer\n",
            "$ mkdir -p $ML_PATH\n",
            "\n",
            "--- Chunk 1492 ---\n",
            "You will need a number of Python modules: Jupyter, NumPy, pandas, Matplotlib, and\n",
            "\n",
            "--- Chunk 1493 ---\n",
            "Scikit-Learn. If you already have Jupyter running with all these modules installed,\n",
            "\n",
            "--- Chunk 1494 ---\n",
            "you can safely skip to “Download the Data” on page 46. If you don’t have them yet,\n",
            "\n",
            "--- Chunk 1495 ---\n",
            "there are many ways to install them (and their dependencies). You can use your\n",
            "\n",
            "--- Chunk 1496 ---\n",
            "system’s packaging system (e.g., apt-get on Ubuntu, or MacPorts or Homebrew on\n",
            "\n",
            "--- Chunk 1497 ---\n",
            "macOS), install a Scientific Python distribution such as Anaconda and use its packag‐\n",
            "\n",
            "--- Chunk 1498 ---\n",
            "ing system, or just use Python’s own packaging system, pip, which is included by\n",
            "\n",
            "--- Chunk 1499 ---\n",
            "5 The latest version of Python 3 is recommended. Python 2.7+ may work too, but now that it’s deprecated, all\n",
            "\n",
            "--- Chunk 1500 ---\n",
            "major scientific libraries are dropping support for it, so you should migrate to Python 3 as soon as possible.\n",
            "\n",
            "--- Chunk 1501 ---\n",
            "42 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 1502 ---\n",
            "default with the Python binary installers (since Python 2.7.9).6 You can check to see if\n",
            "pip is installed by typing the following command:\n",
            "\n",
            "--- Chunk 1503 ---\n",
            "$ python3 -m pip --version\n",
            "pip 19.3.1 from [...]/lib/python3.7/site-packages/pip (python 3.7)\n",
            "\n",
            "--- Chunk 1504 ---\n",
            "You should make sure you have a recent version of pip installed. To upgrade the pip\n",
            "module, type the following (the exact version may differ):7\n",
            "\n",
            "--- Chunk 1505 ---\n",
            "$ python3 -m pip install --user -U pip\n",
            "Collecting pip\n",
            "[...]\n",
            "Successfully installed pip-19.3.1\n",
            "\n",
            "--- Chunk 1506 ---\n",
            "Creating an Isolated Environment\n",
            "If you would like to work in an isolated environment (which is strongly recom‐\n",
            "\n",
            "--- Chunk 1507 ---\n",
            "mended so that you can work on different projects without having conflicting library\n",
            "\n",
            "--- Chunk 1508 ---\n",
            "versions), install virtualenv8 by running the following pip command (again, if you\n",
            "\n",
            "--- Chunk 1509 ---\n",
            "want virtualenv to be installed for all users on your machine, remove --user and run\n",
            "this command with administrator rights):\n",
            "\n",
            "--- Chunk 1510 ---\n",
            "$ python3 -m pip install --user -U virtualenv\n",
            "Collecting virtualenv\n",
            "[...]\n",
            "Successfully installed virtualenv-16.7.6\n",
            "\n",
            "--- Chunk 1511 ---\n",
            "Now you can create an isolated Python environment by typing this:\n",
            "$ cd $ML_PATH\n",
            "$ python3 -m virtualenv my_env\n",
            "Using base prefix '[...]'\n",
            "\n",
            "--- Chunk 1512 ---\n",
            "New python executable in [...]/ml/my_env/bin/python3\n",
            "Also creating executable in [...]/ml/my_env/bin/python\n",
            "Installing setuptools, pip, wheel...done.\n",
            "\n",
            "--- Chunk 1513 ---\n",
            "Now every time you want to activate this environment, just open a terminal and type\n",
            "the following:\n",
            "\n",
            "--- Chunk 1514 ---\n",
            "6 I’ll show the installation steps using pip in a bash shell on a Linux or macOS system. You may need to adapt\n",
            "\n",
            "--- Chunk 1515 ---\n",
            "these commands to your own system. On Windows, I recommend installing Anaconda instead.\n",
            "\n",
            "--- Chunk 1516 ---\n",
            "7 If you want to upgrade pip for all users on your machine rather than just your own user, you should remove\n",
            "\n",
            "--- Chunk 1517 ---\n",
            "the --user option and make sure you have administrator rights (e.g., by adding sudo before the whole com‐\n",
            "mand on Linux or macOS).\n",
            "\n",
            "--- Chunk 1518 ---\n",
            "8 Alternative tools include venv (very similar to virtualenv and included in the standard library), virtualenv‐\n",
            "\n",
            "--- Chunk 1519 ---\n",
            "wrapper (provides extra functionalities on top of virtualenv), pyenv (allows easy switching between Python\n",
            "\n",
            "--- Chunk 1520 ---\n",
            "versions), and pipenv (a great packaging tool by the same author as the popular requests library, built on top\n",
            "of pip and virtualenv).\n",
            "\n",
            "--- Chunk 1521 ---\n",
            "Get the Data | 43\n",
            "\n",
            "\n",
            "\n",
            "$ cd $ML_PATH\n",
            "$ source my_env/bin/activate # on Linux or macOS\n",
            "$ .\\my_env\\Scripts\\activate  # on Windows\n",
            "\n",
            "--- Chunk 1522 ---\n",
            "To deactivate this environment, type deactivate. While the environment is active,\n",
            "\n",
            "--- Chunk 1523 ---\n",
            "any package you install using pip will be installed in this isolated environment, and\n",
            "\n",
            "--- Chunk 1524 ---\n",
            "Python will only have access to these packages (if you also want access to the system’s\n",
            "\n",
            "--- Chunk 1525 ---\n",
            "packages, you should create the environment using virtualenv’s --system-site-\n",
            "\n",
            "--- Chunk 1526 ---\n",
            "packages option). Check out virtualenv’s documentation for more information.\n",
            "\n",
            "--- Chunk 1527 ---\n",
            "Now you can install all the required modules and their dependencies using this sim‐\n",
            "\n",
            "--- Chunk 1528 ---\n",
            "ple pip command (if you are not using a virtualenv, you will need the --user option\n",
            "or administrator rights):\n",
            "\n",
            "--- Chunk 1529 ---\n",
            "$ python3 -m pip install -U jupyter matplotlib numpy pandas scipy scikit-learn\n",
            "Collecting jupyter\n",
            "\n",
            "--- Chunk 1530 ---\n",
            "Collecting jupyter\n",
            "  Downloading https://[...]/jupyter-1.0.0-py2.py3-none-any.whl\n",
            "Collecting matplotlib\n",
            "  [...]\n",
            "\n",
            "--- Chunk 1531 ---\n",
            "If you created a virtualenv, you need to register it to Jupyter and give it a name:\n",
            "$ python3 -m ipykernel install --user --name=python3\n",
            "\n",
            "--- Chunk 1532 ---\n",
            "Now you can fire up Jupyter by typing the following command:\n",
            "$ jupyter notebook\n",
            "[...] Serving notebooks from local directory: [...]/ml\n",
            "\n",
            "--- Chunk 1533 ---\n",
            "[...] The Jupyter Notebook is running at:\n",
            "[...] http://localhost:8888/?token=60995e108e44ac8d8865a[...]\n",
            "\n",
            "--- Chunk 1534 ---\n",
            "[...]  or http://127.0.0.1:8889/?token=60995e108e44ac8d8865a[...]\n",
            "[...] Use Control-C to stop this server and shut down all kernels [...]\n",
            "\n",
            "--- Chunk 1535 ---\n",
            "A Jupyter server is now running in your terminal, listening to port 8888. You can visit\n",
            "\n",
            "--- Chunk 1536 ---\n",
            "this server by opening your web browser to http://localhost:8888/ (this usually hap‐\n",
            "\n",
            "--- Chunk 1537 ---\n",
            "pens automatically when the server starts). You should see your empty workspace\n",
            "\n",
            "--- Chunk 1538 ---\n",
            "directory (containing only the env directory if you followed the preceding virtualenv\n",
            "instructions).\n",
            "\n",
            "--- Chunk 1539 ---\n",
            "instructions).\n",
            "Now create a new Python notebook by clicking the New button and selecting the\n",
            "\n",
            "--- Chunk 1540 ---\n",
            "appropriate Python version9 (see Figure 2-3). Doing that will create a new notebook\n",
            "\n",
            "--- Chunk 1541 ---\n",
            "file called Untitled.ipynb in your workspace, start a Jupyter Python kernel to run the\n",
            "\n",
            "--- Chunk 1542 ---\n",
            "notebook, and open this notebook in a new tab. You should start by renaming this\n",
            "\n",
            "--- Chunk 1543 ---\n",
            "notebook to “Housing” (this will automatically rename the file to Housing.ipynb) by\n",
            "clicking Untitled and typing the new name.\n",
            "\n",
            "--- Chunk 1544 ---\n",
            "9 Note that Jupyter can handle multiple versions of Python, and even many other languages such as R or\n",
            "Octave.\n",
            "\n",
            "--- Chunk 1545 ---\n",
            "44 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "\n",
            "\n",
            "Figure 2-3. Your workspace in Jupyter\n",
            "\n",
            "--- Chunk 1546 ---\n",
            "A notebook contains a list of cells. Each cell can contain executable code or formatted\n",
            "\n",
            "--- Chunk 1547 ---\n",
            "text. Right now the notebook contains only one empty code cell, labeled “In [1]:”. Try\n",
            "\n",
            "--- Chunk 1548 ---\n",
            "typing print(\"Hello world!\") in the cell and clicking the play button (see\n",
            "\n",
            "--- Chunk 1549 ---\n",
            "Figure 2-4) or pressing Shift-Enter. This sends the current cell to this notebook’s\n",
            "\n",
            "--- Chunk 1550 ---\n",
            "Python kernel, which runs it and returns the output. The result is displayed below the\n",
            "\n",
            "--- Chunk 1551 ---\n",
            "cell, and since you’ve reached the end of the notebook, a new cell is automatically cre‐\n",
            "\n",
            "--- Chunk 1552 ---\n",
            "ated. Go through the User Interface Tour from Jupyter’s Help menu to learn the\n",
            "basics.\n",
            "\n",
            "--- Chunk 1553 ---\n",
            "Figure 2-4. Hello world Python notebook\n",
            "\n",
            "Get the Data | 45\n",
            "\n",
            "--- Chunk 1554 ---\n",
            "Download the Data\n",
            "In typical environments your data would be available in a relational database (or\n",
            "\n",
            "--- Chunk 1555 ---\n",
            "some other common data store) and spread across multiple tables/documents/files.\n",
            "\n",
            "--- Chunk 1556 ---\n",
            "To access it, you would first need to get your credentials and access authorizations10\n",
            "\n",
            "--- Chunk 1557 ---\n",
            "and familiarize yourself with the data schema. In this project, however, things are\n",
            "\n",
            "--- Chunk 1558 ---\n",
            "much simpler: you will just download a single compressed file, housing.tgz, which\n",
            "\n",
            "--- Chunk 1559 ---\n",
            "contains a comma-separated values (CSV) file called housing.csv with all the data.\n",
            "\n",
            "--- Chunk 1560 ---\n",
            "You could use your web browser to download the file and run tar xzf housing.tgz\n",
            "\n",
            "--- Chunk 1561 ---\n",
            "to decompress it and extract the CSV file, but it is preferable to create a small func‐\n",
            "\n",
            "--- Chunk 1562 ---\n",
            "tion to do that. Having a function that downloads the data is useful in particular if the\n",
            "\n",
            "--- Chunk 1563 ---\n",
            "data changes regularly: you can write a small script that uses the function to fetch the\n",
            "\n",
            "--- Chunk 1564 ---\n",
            "latest data (or you can set up a scheduled job to do that automatically at regular inter‐\n",
            "\n",
            "--- Chunk 1565 ---\n",
            "vals). Automating the process of fetching the data is also useful if you need to install\n",
            "the dataset on multiple machines.\n",
            "\n",
            "--- Chunk 1566 ---\n",
            "Here is the function to fetch the data:11\n",
            "\n",
            "--- Chunk 1567 ---\n",
            "import os\n",
            "import tarfile\n",
            "import urllib\n",
            "\n",
            "--- Chunk 1568 ---\n",
            "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
            "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
            "\n",
            "--- Chunk 1569 ---\n",
            "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
            "\n",
            "--- Chunk 1570 ---\n",
            "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
            "    os.makedirs(housing_path, exist_ok=True)\n",
            "\n",
            "--- Chunk 1571 ---\n",
            "tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
            "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
            "\n",
            "--- Chunk 1572 ---\n",
            "housing_tgz = tarfile.open(tgz_path)\n",
            "    housing_tgz.extractall(path=housing_path)\n",
            "    housing_tgz.close()\n",
            "\n",
            "--- Chunk 1573 ---\n",
            "Now when you call fetch_housing_data(), it creates a datasets/housing directory in\n",
            "\n",
            "--- Chunk 1574 ---\n",
            "your workspace, downloads the housing.tgz file, and extracts the housing.csv file from\n",
            "it in this directory.\n",
            "\n",
            "--- Chunk 1575 ---\n",
            "10 You might also need to check legal constraints, such as private fields that should never be copied to unsafe\n",
            "data stores.\n",
            "\n",
            "--- Chunk 1576 ---\n",
            "11 In a real project you would save this code in a Python file, but for now you can just write it in your Jupyter\n",
            "notebook.\n",
            "\n",
            "--- Chunk 1577 ---\n",
            "46 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 1578 ---\n",
            "Now let’s load the data using pandas. Once again, you should write a small function\n",
            "to load the data:\n",
            "\n",
            "import pandas as pd\n",
            "\n",
            "--- Chunk 1579 ---\n",
            "def load_housing_data(housing_path=HOUSING_PATH):\n",
            "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
            "    return pd.read_csv(csv_path)\n",
            "\n",
            "--- Chunk 1580 ---\n",
            "This function returns a pandas DataFrame object containing all the data.\n",
            "\n",
            "--- Chunk 1581 ---\n",
            "Take a Quick Look at the Data Structure\n",
            "Let’s take a look at the top five rows using the DataFrame’s head() method (see\n",
            "Figure 2-5).\n",
            "\n",
            "--- Chunk 1582 ---\n",
            "Figure 2-5. Top five rows in the dataset\n",
            "\n",
            "--- Chunk 1583 ---\n",
            "Each row represents one district. There are 10 attributes (you can see the first 6 in the\n",
            "\n",
            "--- Chunk 1584 ---\n",
            "screenshot): longitude, latitude, housing_median_age, total_rooms, total_bed\n",
            "rooms, population, households, median_income, median_house_value, and\n",
            "\n",
            "--- Chunk 1585 ---\n",
            "ocean_proximity.\n",
            "The info() method is useful to get a quick description of the data, in particular the\n",
            "\n",
            "--- Chunk 1586 ---\n",
            "total number of rows, each attribute’s type, and the number of nonnull values (see\n",
            "Figure 2-6).\n",
            "\n",
            "--- Chunk 1587 ---\n",
            "Get the Data | 47\n",
            "\n",
            "\n",
            "\n",
            "Figure 2-6. Housing info\n",
            "\n",
            "--- Chunk 1588 ---\n",
            "There are 20,640 instances in the dataset, which means that it is fairly small by\n",
            "\n",
            "--- Chunk 1589 ---\n",
            "Machine Learning standards, but it’s perfect to get started. Notice that the total_bed\n",
            "\n",
            "--- Chunk 1590 ---\n",
            "rooms attribute has only 20,433 nonnull values, meaning that 207 districts are missing\n",
            "this feature. We will need to take care of this later.\n",
            "\n",
            "--- Chunk 1591 ---\n",
            "All attributes are numerical, except the ocean_proximity field. Its type is object, so it\n",
            "\n",
            "--- Chunk 1592 ---\n",
            "could hold any kind of Python object. But since you loaded this data from a CSV file,\n",
            "\n",
            "--- Chunk 1593 ---\n",
            "you know that it must be a text attribute. When you looked at the top five rows, you\n",
            "\n",
            "--- Chunk 1594 ---\n",
            "probably noticed that the values in the ocean_proximity column were repetitive,\n",
            "\n",
            "--- Chunk 1595 ---\n",
            "which means that it is probably a categorical attribute. You can find out what cate‐\n",
            "\n",
            "--- Chunk 1596 ---\n",
            "gories exist and how many districts belong to each category by using the\n",
            "value_counts() method:\n",
            "\n",
            "--- Chunk 1597 ---\n",
            ">>> housing[\"ocean_proximity\"].value_counts()\n",
            "<1H OCEAN     9136\n",
            "INLAND        6551\n",
            "NEAR OCEAN    2658\n",
            "NEAR BAY      2290\n",
            "ISLAND           5\n",
            "\n",
            "--- Chunk 1598 ---\n",
            "ISLAND           5\n",
            "Name: ocean_proximity, dtype: int64\n",
            "\n",
            "--- Chunk 1599 ---\n",
            "Let’s look at the other fields. The describe() method shows a summary of the\n",
            "numerical attributes (Figure 2-7).\n",
            "\n",
            "--- Chunk 1600 ---\n",
            "48 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "\n",
            "\n",
            "Figure 2-7. Summary of each numerical attribute\n",
            "\n",
            "--- Chunk 1601 ---\n",
            "The count, mean, min, and max rows are self-explanatory. Note that the null values are\n",
            "\n",
            "--- Chunk 1602 ---\n",
            "ignored (so, for example, the count of total_bedrooms is 20,433, not 20,640). The\n",
            "\n",
            "--- Chunk 1603 ---\n",
            "std row shows the standard deviation, which measures how dispersed the values are.12\n",
            "\n",
            "--- Chunk 1604 ---\n",
            "The 25%, 50%, and 75% rows show the corresponding percentiles: a percentile indi‐\n",
            "\n",
            "--- Chunk 1605 ---\n",
            "cates the value below which a given percentage of observations in a group of observa‐\n",
            "\n",
            "--- Chunk 1606 ---\n",
            "tions fall. For example, 25% of the districts have a housing_median_age lower than\n",
            "\n",
            "--- Chunk 1607 ---\n",
            "18, while 50% are lower than 29 and 75% are lower than 37. These are often called the\n",
            "\n",
            "--- Chunk 1608 ---\n",
            "25th percentile (or first quartile), the median, and the 75th percentile (or third\n",
            "quartile).\n",
            "\n",
            "--- Chunk 1609 ---\n",
            "quartile).\n",
            "Another quick way to get a feel of the type of data you are dealing with is to plot a\n",
            "\n",
            "--- Chunk 1610 ---\n",
            "histogram for each numerical attribute. A histogram shows the number of instances\n",
            "\n",
            "--- Chunk 1611 ---\n",
            "(on the vertical axis) that have a given value range (on the horizontal axis). You can\n",
            "\n",
            "--- Chunk 1612 ---\n",
            "either plot this one attribute at a time, or you can call the hist() method on the\n",
            "\n",
            "--- Chunk 1613 ---\n",
            "whole dataset (as shown in the following code example), and it will plot a histogram\n",
            "for each numerical attribute (see Figure 2-8):\n",
            "\n",
            "--- Chunk 1614 ---\n",
            "%matplotlib inline   # only in a Jupyter notebook\n",
            "import matplotlib.pyplot as plt\n",
            "housing.hist(bins=50, figsize=(20,15))\n",
            "plt.show()\n",
            "\n",
            "--- Chunk 1615 ---\n",
            "12 The standard deviation is generally denoted σ (the Greek letter sigma), and it is the square root of the var‐\n",
            "\n",
            "--- Chunk 1616 ---\n",
            "iance, which is the average of the squared deviation from the mean. When a feature has a bell-shaped normal\n",
            "\n",
            "--- Chunk 1617 ---\n",
            "distribution (also called a Gaussian distribution), which is very common, the “68-95-99.7” rule applies: about\n",
            "\n",
            "--- Chunk 1618 ---\n",
            "68% of the values fall within 1σ of the mean, 95% within 2σ, and 99.7% within 3σ.\n",
            "\n",
            "--- Chunk 1619 ---\n",
            "Get the Data | 49\n",
            "\n",
            "--- Chunk 1620 ---\n",
            "The hist() method relies on Matplotlib, which in turn relies on a\n",
            "user-specified graphical backend to draw on your screen. So before\n",
            "\n",
            "--- Chunk 1621 ---\n",
            "you can plot anything, you need to specify which backend Matplot‐\n",
            "lib should use. The simplest option is to use Jupyter’s magic com‐\n",
            "\n",
            "--- Chunk 1622 ---\n",
            "mand %matplotlib inline. This tells Jupyter to set up Matplotlib\n",
            "so it uses Jupyter’s own backend. Plots are then rendered within the\n",
            "\n",
            "--- Chunk 1623 ---\n",
            "notebook itself. Note that calling show() is optional in a Jupyter\n",
            "notebook, as Jupyter will automatically display plots when a cell is\n",
            "executed.\n",
            "\n",
            "--- Chunk 1624 ---\n",
            "Figure 2-8. A histogram for each numerical attribute\n",
            "\n",
            "There are a few things you might notice in these histograms:\n",
            "\n",
            "--- Chunk 1625 ---\n",
            "1. First, the median income attribute does not look like it is expressed in US dollars\n",
            "\n",
            "--- Chunk 1626 ---\n",
            "(USD). After checking with the team that collected the data, you are told that the\n",
            "\n",
            "--- Chunk 1627 ---\n",
            "data has been scaled and capped at 15 (actually, 15.0001) for higher median\n",
            "\n",
            "--- Chunk 1628 ---\n",
            "incomes, and at 0.5 (actually, 0.4999) for lower median incomes. The numbers\n",
            "\n",
            "--- Chunk 1629 ---\n",
            "represent roughly tens of thousands of dollars (e.g., 3 actually means about\n",
            "\n",
            "--- Chunk 1630 ---\n",
            "$30,000). Working with preprocessed attributes is common in Machine Learning,\n",
            "\n",
            "--- Chunk 1631 ---\n",
            "50 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 1632 ---\n",
            "and it is not necessarily a problem, but you should try to understand how the\n",
            "data was computed.\n",
            "\n",
            "--- Chunk 1633 ---\n",
            "2. The housing median age and the median house value were also capped. The lat‐\n",
            "\n",
            "--- Chunk 1634 ---\n",
            "ter may be a serious problem since it is your target attribute (your labels). Your\n",
            "\n",
            "--- Chunk 1635 ---\n",
            "Machine Learning algorithms may learn that prices never go beyond that limit.\n",
            "\n",
            "--- Chunk 1636 ---\n",
            "You need to check with your client team (the team that will use your system’s out‐\n",
            "\n",
            "--- Chunk 1637 ---\n",
            "put) to see if this is a problem or not. If they tell you that they need precise pre‐\n",
            "dictions even beyond $500,000, then you have two options:\n",
            "\n",
            "--- Chunk 1638 ---\n",
            "a. Collect proper labels for the districts whose labels were capped.\n",
            "\n",
            "--- Chunk 1639 ---\n",
            "b. Remove those districts from the training set (and also from the test set, since\n",
            "\n",
            "--- Chunk 1640 ---\n",
            "your system should not be evaluated poorly if it predicts values beyond\n",
            "$500,000).\n",
            "\n",
            "--- Chunk 1641 ---\n",
            "3. These attributes have very different scales. We will discuss this later in this chap‐\n",
            "ter, when we explore feature scaling.\n",
            "\n",
            "--- Chunk 1642 ---\n",
            "4. Finally, many histograms are tail-heavy: they extend much farther to the right of\n",
            "\n",
            "--- Chunk 1643 ---\n",
            "the median than to the left. This may make it a bit harder for some Machine\n",
            "\n",
            "--- Chunk 1644 ---\n",
            "Learning algorithms to detect patterns. We will try transforming these attributes\n",
            "later on to have more bell-shaped distributions.\n",
            "\n",
            "--- Chunk 1645 ---\n",
            "Hopefully you now have a better understanding of the kind of data you are dealing\n",
            "with.\n",
            "\n",
            "--- Chunk 1646 ---\n",
            "Wait! Before you look at the data any further, you need to create a\n",
            "test set, put it aside, and never look at it.\n",
            "\n",
            "--- Chunk 1647 ---\n",
            "Create a Test Set\n",
            "It may sound strange to voluntarily set aside part of the data at this stage. After all,\n",
            "\n",
            "--- Chunk 1648 ---\n",
            "you have only taken a quick glance at the data, and surely you should learn a whole\n",
            "\n",
            "--- Chunk 1649 ---\n",
            "lot more about it before you decide what algorithms to use, right? This is true, but\n",
            "\n",
            "--- Chunk 1650 ---\n",
            "your brain is an amazing pattern detection system, which means that it is highly\n",
            "\n",
            "--- Chunk 1651 ---\n",
            "prone to overfitting: if you look at the test set, you may stumble upon some seemingly\n",
            "\n",
            "--- Chunk 1652 ---\n",
            "interesting pattern in the test data that leads you to select a particular kind of\n",
            "\n",
            "--- Chunk 1653 ---\n",
            "Machine Learning model. When you estimate the generalization error using the test\n",
            "\n",
            "--- Chunk 1654 ---\n",
            "set, your estimate will be too optimistic, and you will launch a system that will not\n",
            "perform as well as expected. This is called data snooping bias.\n",
            "\n",
            "--- Chunk 1655 ---\n",
            "Creating a test set is theoretically simple: pick some instances randomly, typically\n",
            "\n",
            "--- Chunk 1656 ---\n",
            "20% of the dataset (or less if your dataset is very large), and set them aside:\n",
            "\n",
            "--- Chunk 1657 ---\n",
            "Get the Data | 51\n",
            "\n",
            "\n",
            "\n",
            "import numpy as np\n",
            "\n",
            "--- Chunk 1658 ---\n",
            "def split_train_test(data, test_ratio):\n",
            "    shuffled_indices = np.random.permutation(len(data))\n",
            "    test_set_size = int(len(data) * test_ratio)\n",
            "\n",
            "--- Chunk 1659 ---\n",
            "test_indices = shuffled_indices[:test_set_size]\n",
            "    train_indices = shuffled_indices[test_set_size:]\n",
            "\n",
            "--- Chunk 1660 ---\n",
            "return data.iloc[train_indices], data.iloc[test_indices]\n",
            "\n",
            "--- Chunk 1661 ---\n",
            "You can then use this function like this:13\n",
            "\n",
            "--- Chunk 1662 ---\n",
            ">>> train_set, test_set = split_train_test(housing, 0.2)\n",
            ">>> len(train_set)\n",
            "16512\n",
            ">>> len(test_set)\n",
            "4128\n",
            "\n",
            "--- Chunk 1663 ---\n",
            "Well, this works, but it is not perfect: if you run the program again, it will generate a\n",
            "\n",
            "--- Chunk 1664 ---\n",
            "different test set! Over time, you (or your Machine Learning algorithms) will get to\n",
            "see the whole dataset, which is what you want to avoid.\n",
            "\n",
            "--- Chunk 1665 ---\n",
            "One solution is to save the test set on the first run and then load it in subsequent\n",
            "\n",
            "--- Chunk 1666 ---\n",
            "runs. Another option is to set the random number generator’s seed (e.g., with np.ran\n",
            "\n",
            "--- Chunk 1667 ---\n",
            "dom.seed(42))14 before calling np.random.permutation() so that it always generates\n",
            "the same shuffled indices.\n",
            "\n",
            "--- Chunk 1668 ---\n",
            "But both these solutions will break the next time you fetch an updated dataset. To\n",
            "\n",
            "--- Chunk 1669 ---\n",
            "have a stable train/test split even after updating the dataset, a common solution is to\n",
            "\n",
            "--- Chunk 1670 ---\n",
            "use each instance’s identifier to decide whether or not it should go in the test set\n",
            "\n",
            "--- Chunk 1671 ---\n",
            "(assuming instances have a unique and immutable identifier). For example, you could\n",
            "\n",
            "--- Chunk 1672 ---\n",
            "compute a hash of each instance’s identifier and put that instance in the test set if the\n",
            "\n",
            "--- Chunk 1673 ---\n",
            "hash is lower than or equal to 20% of the maximum hash value. This ensures that the\n",
            "\n",
            "--- Chunk 1674 ---\n",
            "test set will remain consistent across multiple runs, even if you refresh the dataset.\n",
            "\n",
            "--- Chunk 1675 ---\n",
            "The new test set will contain 20% of the new instances, but it will not contain any\n",
            "instance that was previously in the training set.\n",
            "\n",
            "--- Chunk 1676 ---\n",
            "Here is a possible implementation:\n",
            "\n",
            "--- Chunk 1677 ---\n",
            "from zlib import crc32\n",
            "\n",
            "def test_set_check(identifier, test_ratio):\n",
            "    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
            "\n",
            "--- Chunk 1678 ---\n",
            "13 In this book, when a code example contains a mix of code and outputs, as is the case here, it is formatted like\n",
            "\n",
            "--- Chunk 1679 ---\n",
            "in the Python interpreter, for better readability: the code lines are prefixed with >>> (or ... for indented\n",
            "blocks), and the outputs have no prefix.\n",
            "\n",
            "--- Chunk 1680 ---\n",
            "14 You will often see people set the random seed to 42. This number has no special property, other than to be the\n",
            "\n",
            "--- Chunk 1681 ---\n",
            "Answer to the Ultimate Question of Life, the Universe, and Everything.\n",
            "\n",
            "--- Chunk 1682 ---\n",
            "52 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 1683 ---\n",
            "def split_train_test_by_id(data, test_ratio, id_column):\n",
            "    ids = data[id_column]\n",
            "\n",
            "--- Chunk 1684 ---\n",
            "in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n",
            "    return data.loc[~in_test_set], data.loc[in_test_set]\n",
            "\n",
            "--- Chunk 1685 ---\n",
            "Unfortunately, the housing dataset does not have an identifier column. The simplest\n",
            "solution is to use the row index as the ID:\n",
            "\n",
            "--- Chunk 1686 ---\n",
            "housing_with_id = housing.reset_index()   # adds an `index` column\n",
            "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"index\")\n",
            "\n",
            "--- Chunk 1687 ---\n",
            "If you use the row index as a unique identifier, you need to make sure that new data\n",
            "\n",
            "--- Chunk 1688 ---\n",
            "gets appended to the end of the dataset and that no row ever gets deleted. If this is not\n",
            "\n",
            "--- Chunk 1689 ---\n",
            "possible, then you can try to use the most stable features to build a unique identifier.\n",
            "\n",
            "--- Chunk 1690 ---\n",
            "For example, a district’s latitude and longitude are guaranteed to be stable for a few\n",
            "million years, so you could combine them into an ID like so:15\n",
            "\n",
            "--- Chunk 1691 ---\n",
            "housing_with_id[\"id\"] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\n",
            "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"id\")\n",
            "\n",
            "--- Chunk 1692 ---\n",
            "Scikit-Learn provides a few functions to split datasets into multiple subsets in various\n",
            "\n",
            "--- Chunk 1693 ---\n",
            "ways. The simplest function is train_test_split(), which does pretty much the\n",
            "\n",
            "--- Chunk 1694 ---\n",
            "same thing as the function split_train_test(), with a couple of additional features.\n",
            "\n",
            "--- Chunk 1695 ---\n",
            "First, there is a random_state parameter that allows you to set the random generator\n",
            "\n",
            "--- Chunk 1696 ---\n",
            "seed. Second, you can pass it multiple datasets with an identical number of rows, and\n",
            "\n",
            "--- Chunk 1697 ---\n",
            "it will split them on the same indices (this is very useful, for example, if you have a\n",
            "separate DataFrame for labels):\n",
            "\n",
            "--- Chunk 1698 ---\n",
            "from sklearn.model_selection import train_test_split\n",
            "\n",
            "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
            "\n",
            "--- Chunk 1699 ---\n",
            "So far we have considered purely random sampling methods. This is generally fine if\n",
            "\n",
            "--- Chunk 1700 ---\n",
            "your dataset is large enough (especially relative to the number of attributes), but if it\n",
            "\n",
            "--- Chunk 1701 ---\n",
            "is not, you run the risk of introducing a significant sampling bias. When a survey\n",
            "\n",
            "--- Chunk 1702 ---\n",
            "company decides to call 1,000 people to ask them a few questions, they don’t just pick\n",
            "\n",
            "--- Chunk 1703 ---\n",
            "1,000 people randomly in a phone book. They try to ensure that these 1,000 people\n",
            "\n",
            "--- Chunk 1704 ---\n",
            "are representative of the whole population. For example, the US population is 51.3%\n",
            "\n",
            "--- Chunk 1705 ---\n",
            "females and 48.7% males, so a well-conducted survey in the US would try to maintain\n",
            "\n",
            "--- Chunk 1706 ---\n",
            "this ratio in the sample: 513 female and 487 male. This is called stratified sampling:\n",
            "\n",
            "--- Chunk 1707 ---\n",
            "the population is divided into homogeneous subgroups called strata, and the right\n",
            "\n",
            "--- Chunk 1708 ---\n",
            "number of instances are sampled from each stratum to guarantee that the test set is\n",
            "\n",
            "--- Chunk 1709 ---\n",
            "representative of the overall population. If the people running the survey used purely\n",
            "\n",
            "--- Chunk 1710 ---\n",
            "random sampling, there would be about a 12% chance of sampling a skewed test set\n",
            "\n",
            "--- Chunk 1711 ---\n",
            "15 The location information is actually quite coarse, and as a result many districts will have the exact same ID, so\n",
            "\n",
            "--- Chunk 1712 ---\n",
            "they will end up in the same set (test or train). This introduces some unfortunate sampling bias.\n",
            "\n",
            "--- Chunk 1713 ---\n",
            "Get the Data | 53\n",
            "\n",
            "--- Chunk 1714 ---\n",
            "that was either less than 49% female or more than 54% female. Either way, the survey\n",
            "results would be significantly biased.\n",
            "\n",
            "--- Chunk 1715 ---\n",
            "Suppose you chatted with experts who told you that the median income is a very\n",
            "\n",
            "--- Chunk 1716 ---\n",
            "important attribute to predict median housing prices. You may want to ensure that\n",
            "\n",
            "--- Chunk 1717 ---\n",
            "the test set is representative of the various categories of incomes in the whole dataset.\n",
            "\n",
            "--- Chunk 1718 ---\n",
            "Since the median income is a continuous numerical attribute, you first need to create\n",
            "\n",
            "--- Chunk 1719 ---\n",
            "an income category attribute. Let’s look at the median income histogram more closely\n",
            "\n",
            "--- Chunk 1720 ---\n",
            "(back in Figure 2-8): most median income values are clustered around 1.5 to 6 (i.e.,\n",
            "\n",
            "--- Chunk 1721 ---\n",
            "$15,000–$60,000), but some median incomes go far beyond 6. It is important to have\n",
            "\n",
            "--- Chunk 1722 ---\n",
            "a sufficient number of instances in your dataset for each stratum, or else the estimate\n",
            "\n",
            "--- Chunk 1723 ---\n",
            "of a stratum’s importance may be biased. This means that you should not have too\n",
            "\n",
            "--- Chunk 1724 ---\n",
            "many strata, and each stratum should be large enough. The following code uses the\n",
            "\n",
            "--- Chunk 1725 ---\n",
            "pd.cut() function to create an income category attribute with five categories (labeled\n",
            "\n",
            "--- Chunk 1726 ---\n",
            "from 1 to 5): category 1 ranges from 0 to 1.5 (i.e., less than $15,000), category 2 from\n",
            "1.5 to 3, and so on:\n",
            "\n",
            "--- Chunk 1727 ---\n",
            "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
            "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
            "\n",
            "--- Chunk 1728 ---\n",
            "labels=[1, 2, 3, 4, 5])\n",
            "\n",
            "--- Chunk 1729 ---\n",
            "These income categories are represented in Figure 2-9:\n",
            "housing[\"income_cat\"].hist()\n",
            "\n",
            "Figure 2-9. Histogram of income categories\n",
            "\n",
            "--- Chunk 1730 ---\n",
            "Now you are ready to do stratified sampling based on the income category. For this\n",
            "you can use Scikit-Learn’s StratifiedShuffleSplit class:\n",
            "\n",
            "--- Chunk 1731 ---\n",
            "54 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "\n",
            "\n",
            "from sklearn.model_selection import StratifiedShuffleSplit\n",
            "\n",
            "--- Chunk 1732 ---\n",
            "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
            "\n",
            "--- Chunk 1733 ---\n",
            "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
            "    strat_train_set = housing.loc[train_index]\n",
            "\n",
            "--- Chunk 1734 ---\n",
            "strat_test_set = housing.loc[test_index]\n",
            "\n",
            "--- Chunk 1735 ---\n",
            "Let’s see if this worked as expected. You can start by looking at the income category\n",
            "proportions in the test set:\n",
            "\n",
            "--- Chunk 1736 ---\n",
            ">>> strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)\n",
            "3    0.350533\n",
            "2    0.318798\n",
            "4    0.176357\n",
            "5    0.114583\n",
            "1    0.039729\n",
            "\n",
            "--- Chunk 1737 ---\n",
            "1    0.039729\n",
            "Name: income_cat, dtype: float64\n",
            "\n",
            "--- Chunk 1738 ---\n",
            "With similar code you can measure the income category proportions in the full data‐\n",
            "\n",
            "--- Chunk 1739 ---\n",
            "set. Figure 2-10 compares the income category proportions in the overall dataset, in\n",
            "\n",
            "--- Chunk 1740 ---\n",
            "the test set generated with stratified sampling, and in a test set generated using purely\n",
            "\n",
            "--- Chunk 1741 ---\n",
            "random sampling. As you can see, the test set generated using stratified sampling has\n",
            "\n",
            "--- Chunk 1742 ---\n",
            "income category proportions almost identical to those in the full dataset, whereas the\n",
            "test set generated using purely random sampling is skewed.\n",
            "\n",
            "--- Chunk 1743 ---\n",
            "Figure 2-10. Sampling bias comparison of stratified versus purely random sampling\n",
            "\n",
            "--- Chunk 1744 ---\n",
            "Now you should remove the income_cat attribute so the data is back to its original\n",
            "state:\n",
            "\n",
            "--- Chunk 1745 ---\n",
            "for set_ in (strat_train_set, strat_test_set):\n",
            "    set_.drop(\"income_cat\", axis=1, inplace=True)\n",
            "\n",
            "--- Chunk 1746 ---\n",
            "We spent quite a bit of time on test set generation for a good reason: this is an often\n",
            "\n",
            "--- Chunk 1747 ---\n",
            "neglected but critical part of a Machine Learning project. Moreover, many of these\n",
            "\n",
            "--- Chunk 1748 ---\n",
            "ideas will be useful later when we discuss cross-validation. Now it’s time to move on\n",
            "to the next stage: exploring the data.\n",
            "\n",
            "--- Chunk 1749 ---\n",
            "Get the Data | 55\n",
            "\n",
            "--- Chunk 1750 ---\n",
            "Discover and Visualize the Data to Gain Insights\n",
            "So far you have only taken a quick glance at the data to get a general understanding of\n",
            "\n",
            "--- Chunk 1751 ---\n",
            "the kind of data you are manipulating. Now the goal is to go into a little more depth.\n",
            "\n",
            "--- Chunk 1752 ---\n",
            "First, make sure you have put the test set aside and you are only exploring the train‐\n",
            "\n",
            "--- Chunk 1753 ---\n",
            "ing set. Also, if the training set is very large, you may want to sample an exploration\n",
            "\n",
            "--- Chunk 1754 ---\n",
            "set, to make manipulations easy and fast. In our case, the set is quite small, so you can\n",
            "\n",
            "--- Chunk 1755 ---\n",
            "just work directly on the full set. Let’s create a copy so that you can play with it\n",
            "without harming the training set:\n",
            "\n",
            "--- Chunk 1756 ---\n",
            "housing = strat_train_set.copy()\n",
            "\n",
            "--- Chunk 1757 ---\n",
            "Visualizing Geographical Data\n",
            "Since there is geographical information (latitude and longitude), it is a good idea to\n",
            "\n",
            "--- Chunk 1758 ---\n",
            "create a scatterplot of all districts to visualize the data (Figure 2-11):\n",
            "\n",
            "--- Chunk 1759 ---\n",
            "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")\n",
            "\n",
            "Figure 2-11. A geographical scatterplot of the data\n",
            "\n",
            "--- Chunk 1760 ---\n",
            "This looks like California all right, but other than that it is hard to see any particular\n",
            "\n",
            "--- Chunk 1761 ---\n",
            "pattern. Setting the alpha option to 0.1 makes it much easier to visualize the places\n",
            "where there is a high density of data points (Figure 2-12):\n",
            "\n",
            "--- Chunk 1762 ---\n",
            "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)\n",
            "\n",
            "56 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 1763 ---\n",
            "Figure 2-12. A better visualization that highlights high-density areas\n",
            "\n",
            "--- Chunk 1764 ---\n",
            "Now that’s much better: you can clearly see the high-density areas, namely the Bay\n",
            "\n",
            "--- Chunk 1765 ---\n",
            "Area and around Los Angeles and San Diego, plus a long line of fairly high density in\n",
            "the Central Valley, in particular around Sacramento and Fresno.\n",
            "\n",
            "--- Chunk 1766 ---\n",
            "Our brains are very good at spotting patterns in pictures, but you may need to play\n",
            "\n",
            "--- Chunk 1767 ---\n",
            "around with visualization parameters to make the patterns stand out.\n",
            "\n",
            "--- Chunk 1768 ---\n",
            "Now let’s look at the housing prices (Figure 2-13). The radius of each circle represents\n",
            "\n",
            "--- Chunk 1769 ---\n",
            "the district’s population (option s), and the color represents the price (option c). We\n",
            "\n",
            "--- Chunk 1770 ---\n",
            "will use a predefined color map (option cmap) called jet, which ranges from blue\n",
            "(low values) to red (high prices):16\n",
            "\n",
            "--- Chunk 1771 ---\n",
            "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
            "    s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
            "\n",
            "--- Chunk 1772 ---\n",
            "c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
            ")\n",
            "plt.legend()\n",
            "\n",
            "--- Chunk 1773 ---\n",
            "16 If you are reading this in grayscale, grab a red pen and scribble over most of the coastline from the Bay Area\n",
            "\n",
            "--- Chunk 1774 ---\n",
            "down to San Diego (as you might expect). You can add a patch of yellow around Sacramento as well.\n",
            "\n",
            "--- Chunk 1775 ---\n",
            "Discover and Visualize the Data to Gain Insights | 57\n",
            "\n",
            "--- Chunk 1776 ---\n",
            "Figure 2-13. California housing prices: red is expensive, blue is cheap, larger circles indi‐\n",
            "cate areas with a larger population\n",
            "\n",
            "--- Chunk 1777 ---\n",
            "This image tells you that the housing prices are very much related to the location\n",
            "\n",
            "--- Chunk 1778 ---\n",
            "(e.g., close to the ocean) and to the population density, as you probably knew already.\n",
            "\n",
            "--- Chunk 1779 ---\n",
            "A clustering algorithm should be useful for detecting the main cluster and for adding\n",
            "\n",
            "--- Chunk 1780 ---\n",
            "new features that measure the proximity to the cluster centers. The ocean proximity\n",
            "\n",
            "--- Chunk 1781 ---\n",
            "attribute may be useful as well, although in Northern California the housing prices in\n",
            "\n",
            "--- Chunk 1782 ---\n",
            "coastal districts are not too high, so it is not a simple rule.\n",
            "\n",
            "--- Chunk 1783 ---\n",
            "Looking for Correlations\n",
            "Since the dataset is not too large, you can easily compute the standard correlation\n",
            "\n",
            "--- Chunk 1784 ---\n",
            "coefficient (also called Pearson’s r) between every pair of attributes using the corr()\n",
            "method:\n",
            "\n",
            "--- Chunk 1785 ---\n",
            "corr_matrix = housing.corr()\n",
            "\n",
            "--- Chunk 1786 ---\n",
            "Now let’s look at how much each attribute correlates with the median house value:\n",
            ">>> corr_matrix[\"median_house_value\"].sort_values(ascending=False)\n",
            "\n",
            "--- Chunk 1787 ---\n",
            "median_house_value    1.000000\n",
            "median_income         0.687170\n",
            "total_rooms           0.135231\n",
            "housing_median_age    0.114220\n",
            "\n",
            "--- Chunk 1788 ---\n",
            "58 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 1789 ---\n",
            "households            0.064702\n",
            "total_bedrooms        0.047865\n",
            "population           -0.026699\n",
            "longitude            -0.047279\n",
            "\n",
            "--- Chunk 1790 ---\n",
            "latitude             -0.142826\n",
            "Name: median_house_value, dtype: float64\n",
            "\n",
            "--- Chunk 1791 ---\n",
            "The correlation coefficient ranges from –1 to 1. When it is close to 1, it means that\n",
            "\n",
            "--- Chunk 1792 ---\n",
            "there is a strong positive correlation; for example, the median house value tends to go\n",
            "\n",
            "--- Chunk 1793 ---\n",
            "up when the median income goes up. When the coefficient is close to –1, it means\n",
            "\n",
            "--- Chunk 1794 ---\n",
            "that there is a strong negative correlation; you can see a small negative correlation\n",
            "\n",
            "--- Chunk 1795 ---\n",
            "between the latitude and the median house value (i.e., prices have a slight tendency to\n",
            "\n",
            "--- Chunk 1796 ---\n",
            "go down when you go north). Finally, coefficients close to 0 mean that there is no\n",
            "\n",
            "--- Chunk 1797 ---\n",
            "linear correlation. Figure 2-14 shows various plots along with the correlation coeffi‐\n",
            "cient between their horizontal and vertical axes.\n",
            "\n",
            "--- Chunk 1798 ---\n",
            "Figure 2-14. Standard correlation coefficient of various datasets (source: Wikipedia;\n",
            "public domain image)\n",
            "\n",
            "--- Chunk 1799 ---\n",
            "The correlation coefficient only measures linear correlations (“if x\n",
            "goes up, then y generally goes up/down”). It may completely miss\n",
            "\n",
            "--- Chunk 1800 ---\n",
            "out on nonlinear relationships (e.g., “if x is close to 0, then y gener‐\n",
            "ally goes up”). Note how all the plots of the bottom row have a cor‐\n",
            "\n",
            "--- Chunk 1801 ---\n",
            "relation coefficient equal to 0, despite the fact that their axes are\n",
            "clearly not independent: these are examples of nonlinear relation‐\n",
            "\n",
            "--- Chunk 1802 ---\n",
            "ships. Also, the second row shows examples where the correlation\n",
            "coefficient is equal to 1 or –1; notice that this has nothing to do\n",
            "\n",
            "--- Chunk 1803 ---\n",
            "with the slope. For example, your height in inches has a correlation\n",
            "coefficient of 1 with your height in feet or in nanometers.\n",
            "\n",
            "--- Chunk 1804 ---\n",
            "Another way to check for correlation between attributes is to use the pandas\n",
            "\n",
            "--- Chunk 1805 ---\n",
            "scatter_matrix() function, which plots every numerical attribute against every\n",
            "\n",
            "--- Chunk 1806 ---\n",
            "Discover and Visualize the Data to Gain Insights | 59\n",
            "\n",
            "--- Chunk 1807 ---\n",
            "other numerical attribute. Since there are now 11 numerical attributes, you would get\n",
            "\n",
            "--- Chunk 1808 ---\n",
            "112 = 121 plots, which would not fit on a page—so let’s just focus on a few promising\n",
            "\n",
            "--- Chunk 1809 ---\n",
            "attributes that seem most correlated with the median housing value (Figure 2-15):\n",
            "\n",
            "--- Chunk 1810 ---\n",
            "from pandas.plotting import scatter_matrix\n",
            "\n",
            "--- Chunk 1811 ---\n",
            "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
            "              \"housing_median_age\"]\n",
            "\n",
            "--- Chunk 1812 ---\n",
            "scatter_matrix(housing[attributes], figsize=(12, 8))\n",
            "\n",
            "--- Chunk 1813 ---\n",
            "Figure 2-15. This scatter matrix plots every numerical attribute against every other\n",
            "\n",
            "--- Chunk 1814 ---\n",
            "numerical attribute, plus a histogram of each numerical attribute\n",
            "\n",
            "--- Chunk 1815 ---\n",
            "The main diagonal (top left to bottom right) would be full of straight lines if pandas\n",
            "\n",
            "--- Chunk 1816 ---\n",
            "plotted each variable against itself, which would not be very useful. So instead pandas\n",
            "\n",
            "--- Chunk 1817 ---\n",
            "displays a histogram of each attribute (other options are available; see the pandas\n",
            "documentation for more details).\n",
            "\n",
            "--- Chunk 1818 ---\n",
            "The most promising attribute to predict the median house value is the median\n",
            "income, so let’s zoom in on their correlation scatterplot (Figure 2-16):\n",
            "\n",
            "--- Chunk 1819 ---\n",
            "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n",
            "             alpha=0.1)\n",
            "\n",
            "60 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 1820 ---\n",
            "Figure 2-16. Median income versus median house value\n",
            "\n",
            "--- Chunk 1821 ---\n",
            "This plot reveals a few things. First, the correlation is indeed very strong; you can\n",
            "\n",
            "--- Chunk 1822 ---\n",
            "clearly see the upward trend, and the points are not too dispersed. Second, the price\n",
            "\n",
            "--- Chunk 1823 ---\n",
            "cap that we noticed earlier is clearly visible as a horizontal line at $500,000. But this\n",
            "\n",
            "--- Chunk 1824 ---\n",
            "plot reveals other less obvious straight lines: a horizontal line around $450,000,\n",
            "\n",
            "--- Chunk 1825 ---\n",
            "another around $350,000, perhaps one around $280,000, and a few more below that.\n",
            "\n",
            "--- Chunk 1826 ---\n",
            "You may want to try removing the corresponding districts to prevent your algorithms\n",
            "from learning to reproduce these data quirks.\n",
            "\n",
            "--- Chunk 1827 ---\n",
            "Experimenting with Attribute Combinations\n",
            "Hopefully the previous sections gave you an idea of a few ways you can explore the\n",
            "\n",
            "--- Chunk 1828 ---\n",
            "data and gain insights. You identified a few data quirks that you may want to clean up\n",
            "\n",
            "--- Chunk 1829 ---\n",
            "before feeding the data to a Machine Learning algorithm, and you found interesting\n",
            "\n",
            "--- Chunk 1830 ---\n",
            "correlations between attributes, in particular with the target attribute. You also\n",
            "\n",
            "--- Chunk 1831 ---\n",
            "noticed that some attributes have a tail-heavy distribution, so you may want to trans‐\n",
            "\n",
            "--- Chunk 1832 ---\n",
            "form them (e.g., by computing their logarithm). Of course, your mileage will vary\n",
            "considerably with each project, but the general ideas are similar.\n",
            "\n",
            "--- Chunk 1833 ---\n",
            "One last thing you may want to do before preparing the data for Machine Learning\n",
            "\n",
            "--- Chunk 1834 ---\n",
            "algorithms is to try out various attribute combinations. For example, the total num‐\n",
            "\n",
            "--- Chunk 1835 ---\n",
            "ber of rooms in a district is not very useful if you don’t know how many households\n",
            "\n",
            "--- Chunk 1836 ---\n",
            "there are. What you really want is the number of rooms per household. Similarly, the\n",
            "\n",
            "--- Chunk 1837 ---\n",
            "total number of bedrooms by itself is not very useful: you probably want to compare\n",
            "\n",
            "--- Chunk 1838 ---\n",
            "it to the number of rooms. And the population per household also seems like an\n",
            "\n",
            "--- Chunk 1839 ---\n",
            "interesting attribute combination to look at. Let’s create these new attributes:\n",
            "\n",
            "--- Chunk 1840 ---\n",
            "Discover and Visualize the Data to Gain Insights | 61\n",
            "\n",
            "--- Chunk 1841 ---\n",
            "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
            "\n",
            "--- Chunk 1842 ---\n",
            "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
            "\n",
            "--- Chunk 1843 ---\n",
            "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]\n",
            "\n",
            "--- Chunk 1844 ---\n",
            "And now let’s look at the correlation matrix again:\n",
            ">>> corr_matrix = housing.corr()\n",
            "\n",
            "--- Chunk 1845 ---\n",
            ">>> corr_matrix[\"median_house_value\"].sort_values(ascending=False)\n",
            "median_house_value          1.000000\n",
            "median_income               0.687160\n",
            "\n",
            "--- Chunk 1846 ---\n",
            "rooms_per_household         0.146285\n",
            "total_rooms                 0.135097\n",
            "housing_median_age          0.114110\n",
            "households                  0.064506\n",
            "\n",
            "--- Chunk 1847 ---\n",
            "total_bedrooms              0.047689\n",
            "population_per_household   -0.021985\n",
            "population                 -0.026920\n",
            "longitude                  -0.047432\n",
            "\n",
            "--- Chunk 1848 ---\n",
            "latitude                   -0.142724\n",
            "bedrooms_per_room          -0.259984\n",
            "Name: median_house_value, dtype: float64\n",
            "\n",
            "--- Chunk 1849 ---\n",
            "Hey, not bad! The new bedrooms_per_room attribute is much more correlated with\n",
            "\n",
            "--- Chunk 1850 ---\n",
            "the median house value than the total number of rooms or bedrooms. Apparently\n",
            "\n",
            "--- Chunk 1851 ---\n",
            "houses with a lower bedroom/room ratio tend to be more expensive. The number of\n",
            "\n",
            "--- Chunk 1852 ---\n",
            "rooms per household is also more informative than the total number of rooms in a\n",
            "\n",
            "--- Chunk 1853 ---\n",
            "district—obviously the larger the houses, the more expensive they are.\n",
            "\n",
            "--- Chunk 1854 ---\n",
            "This round of exploration does not have to be absolutely thorough; the point is to\n",
            "\n",
            "--- Chunk 1855 ---\n",
            "start off on the right foot and quickly gain insights that will help you get a first rea‐\n",
            "\n",
            "--- Chunk 1856 ---\n",
            "sonably good prototype. But this is an iterative process: once you get a prototype up\n",
            "\n",
            "--- Chunk 1857 ---\n",
            "and running, you can analyze its output to gain more insights and come back to this\n",
            "exploration step.\n",
            "\n",
            "--- Chunk 1858 ---\n",
            "Prepare the Data for Machine Learning Algorithms\n",
            "It’s time to prepare the data for your Machine Learning algorithms. Instead of doing\n",
            "\n",
            "--- Chunk 1859 ---\n",
            "this manually, you should write functions for this purpose, for several good reasons:\n",
            "\n",
            "--- Chunk 1860 ---\n",
            "• This will allow you to reproduce these transformations easily on any dataset (e.g.,\n",
            "the next time you get a fresh dataset).\n",
            "\n",
            "--- Chunk 1861 ---\n",
            "• You will gradually build a library of transformation functions that you can reuse\n",
            "in future projects.\n",
            "\n",
            "--- Chunk 1862 ---\n",
            "• You can use these functions in your live system to transform the new data before\n",
            "feeding it to your algorithms.\n",
            "\n",
            "--- Chunk 1863 ---\n",
            "62 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 1864 ---\n",
            "• This will make it possible for you to easily try various transformations and see\n",
            "which combination of transformations works best.\n",
            "\n",
            "--- Chunk 1865 ---\n",
            "But first let’s revert to a clean training set (by copying strat_train_set once again).\n",
            "\n",
            "--- Chunk 1866 ---\n",
            "Let’s also separate the predictors and the labels, since we don’t necessarily want to\n",
            "\n",
            "--- Chunk 1867 ---\n",
            "apply the same transformations to the predictors and the target values (note that\n",
            "\n",
            "--- Chunk 1868 ---\n",
            "drop() creates a copy of the data and does not affect strat_train_set):\n",
            "\n",
            "--- Chunk 1869 ---\n",
            "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
            "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
            "\n",
            "--- Chunk 1870 ---\n",
            "Data Cleaning\n",
            "Most Machine Learning algorithms cannot work with missing features, so let’s create\n",
            "\n",
            "--- Chunk 1871 ---\n",
            "a few functions to take care of them. We saw earlier that the total_bedrooms\n",
            "\n",
            "--- Chunk 1872 ---\n",
            "attribute has some missing values, so let’s fix this. You have three options:\n",
            "\n",
            "--- Chunk 1873 ---\n",
            "1. Get rid of the corresponding districts.\n",
            "2. Get rid of the whole attribute.\n",
            "3. Set the values to some value (zero, the mean, the median, etc.).\n",
            "\n",
            "--- Chunk 1874 ---\n",
            "You can accomplish these easily using DataFrame’s dropna(), drop(), and fillna()\n",
            "methods:\n",
            "\n",
            "--- Chunk 1875 ---\n",
            "housing.dropna(subset=[\"total_bedrooms\"])    # option 1\n",
            "housing.drop(\"total_bedrooms\", axis=1)       # option 2\n",
            "\n",
            "--- Chunk 1876 ---\n",
            "median = housing[\"total_bedrooms\"].median()  # option 3\n",
            "housing[\"total_bedrooms\"].fillna(median, inplace=True)\n",
            "\n",
            "--- Chunk 1877 ---\n",
            "If you choose option 3, you should compute the median value on the training set and\n",
            "\n",
            "--- Chunk 1878 ---\n",
            "use it to fill the missing values in the training set. Don’t forget to save the median\n",
            "\n",
            "--- Chunk 1879 ---\n",
            "value that you have computed. You will need it later to replace missing values in the\n",
            "\n",
            "--- Chunk 1880 ---\n",
            "test set when you want to evaluate your system, and also once the system goes live to\n",
            "replace missing values in new data.\n",
            "\n",
            "--- Chunk 1881 ---\n",
            "Scikit-Learn provides a handy class to take care of missing values: SimpleImputer.\n",
            "\n",
            "--- Chunk 1882 ---\n",
            "Here is how to use it. First, you need to create a SimpleImputer instance, specifying\n",
            "\n",
            "--- Chunk 1883 ---\n",
            "that you want to replace each attribute’s missing values with the median of that\n",
            "attribute:\n",
            "\n",
            "--- Chunk 1884 ---\n",
            "from sklearn.impute import SimpleImputer\n",
            "\n",
            "imputer = SimpleImputer(strategy=\"median\")\n",
            "\n",
            "--- Chunk 1885 ---\n",
            "Since the median can only be computed on numerical attributes, you need to create a\n",
            "copy of the data without the text attribute ocean_proximity:\n",
            "\n",
            "--- Chunk 1886 ---\n",
            "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
            "\n",
            "Prepare the Data for Machine Learning Algorithms | 63\n",
            "\n",
            "--- Chunk 1887 ---\n",
            "Now you can fit the imputer instance to the training data using the fit() method:\n",
            "imputer.fit(housing_num)\n",
            "\n",
            "--- Chunk 1888 ---\n",
            "The imputer has simply computed the median of each attribute and stored the result\n",
            "\n",
            "--- Chunk 1889 ---\n",
            "in its statistics_ instance variable. Only the total_bedrooms attribute had missing\n",
            "\n",
            "--- Chunk 1890 ---\n",
            "values, but we cannot be sure that there won’t be any missing values in new data after\n",
            "\n",
            "--- Chunk 1891 ---\n",
            "the system goes live, so it is safer to apply the imputer to all the numerical attributes:\n",
            "\n",
            "--- Chunk 1892 ---\n",
            ">>> imputer.statistics_\n",
            "array([ -118.51 , 34.26 , 29. , 2119.5 , 433. , 1164. , 408. , 3.5409])\n",
            ">>> housing_num.median().values\n",
            "\n",
            "--- Chunk 1893 ---\n",
            "array([ -118.51 , 34.26 , 29. , 2119.5 , 433. , 1164. , 408. , 3.5409])\n",
            "\n",
            "--- Chunk 1894 ---\n",
            "Now you can use this “trained” imputer to transform the training set by replacing\n",
            "missing values with the learned medians:\n",
            "\n",
            "--- Chunk 1895 ---\n",
            "X = imputer.transform(housing_num)\n",
            "\n",
            "--- Chunk 1896 ---\n",
            "The result is a plain NumPy array containing the transformed features. If you want to\n",
            "put it back into a pandas DataFrame, it’s simple:\n",
            "\n",
            "--- Chunk 1897 ---\n",
            "housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n",
            "                          index=housing_num.index)\n",
            "\n",
            "--- Chunk 1898 ---\n",
            "Scikit-Learn Design\n",
            "Scikit-Learn’s API is remarkably well designed. These are the main design principles:17\n",
            "\n",
            "--- Chunk 1899 ---\n",
            "Consistency\n",
            "All objects share a consistent and simple interface:\n",
            "Estimators\n",
            "\n",
            "--- Chunk 1900 ---\n",
            "Any object that can estimate some parameters based on a dataset is called an\n",
            "\n",
            "--- Chunk 1901 ---\n",
            "estimator (e.g., an imputer is an estimator). The estimation itself is per‐\n",
            "\n",
            "--- Chunk 1902 ---\n",
            "formed by the fit() method, and it takes only a dataset as a parameter (or\n",
            "two for supervised learning algorithms; the second dataset contains the\n",
            "\n",
            "--- Chunk 1903 ---\n",
            "labels). Any other parameter needed to guide the estimation process is con‐\n",
            "sidered a hyperparameter (such as an imputer’s strategy), and it must be\n",
            "\n",
            "--- Chunk 1904 ---\n",
            "set as an instance variable (generally via a constructor parameter).\n",
            "\n",
            "--- Chunk 1905 ---\n",
            "Transformers\n",
            "Some estimators (such as an imputer) can also transform a dataset; these are\n",
            "\n",
            "--- Chunk 1906 ---\n",
            "called transformers. Once again, the API is simple: the transformation is\n",
            "performed by the transform() method with the dataset to transform as a\n",
            "\n",
            "--- Chunk 1907 ---\n",
            "17 For more details on the design principles, see Lars Buitinck et al., “API Design for Machine Learning Software:\n",
            "\n",
            "--- Chunk 1908 ---\n",
            "Experiences from the Scikit-Learn Project” ,” arXiv preprint arXiv:1309.0238 (2013).\n",
            "\n",
            "--- Chunk 1909 ---\n",
            "64 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 1910 ---\n",
            "parameter. It returns the transformed dataset. This transformation generally\n",
            "\n",
            "--- Chunk 1911 ---\n",
            "relies on the learned parameters, as is the case for an imputer. All transform‐\n",
            "\n",
            "--- Chunk 1912 ---\n",
            "ers also have a convenience method called fit_transform() that is equiva‐\n",
            "lent to calling fit() and then transform() (but sometimes\n",
            "\n",
            "--- Chunk 1913 ---\n",
            "fit_transform() is optimized and runs much faster).\n",
            "\n",
            "--- Chunk 1914 ---\n",
            "Predictors\n",
            "Finally, some estimators, given a dataset, are capable of making predictions;\n",
            "\n",
            "--- Chunk 1915 ---\n",
            "they are called predictors. For example, the LinearRegression model in the\n",
            "\n",
            "--- Chunk 1916 ---\n",
            "previous chapter was a predictor: given a country’s GDP per capita, it pre‐\n",
            "dicted life satisfaction. A predictor has a predict() method that takes a\n",
            "\n",
            "--- Chunk 1917 ---\n",
            "dataset of new instances and returns a dataset of corresponding predictions.\n",
            "\n",
            "--- Chunk 1918 ---\n",
            "It also has a score() method that measures the quality of the predictions,\n",
            "\n",
            "--- Chunk 1919 ---\n",
            "given a test set (and the corresponding labels, in the case of supervised learn‐\n",
            "ing algorithms).18\n",
            "\n",
            "--- Chunk 1920 ---\n",
            "Inspection\n",
            "All the estimator’s hyperparameters are accessible directly via public instance\n",
            "\n",
            "--- Chunk 1921 ---\n",
            "variables (e.g., imputer.strategy), and all the estimator’s learned parameters are\n",
            "\n",
            "--- Chunk 1922 ---\n",
            "accessible via public instance variables with an underscore suffix (e.g.,\n",
            "imputer.statistics_).\n",
            "\n",
            "--- Chunk 1923 ---\n",
            "Nonproliferation of classes\n",
            "Datasets are represented as NumPy arrays or SciPy sparse matrices, instead of\n",
            "\n",
            "--- Chunk 1924 ---\n",
            "homemade classes. Hyperparameters are just regular Python strings or numbers.\n",
            "\n",
            "--- Chunk 1925 ---\n",
            "Composition\n",
            "Existing building blocks are reused as much as possible. For example, it is easy to\n",
            "\n",
            "--- Chunk 1926 ---\n",
            "create a Pipeline estimator from an arbitrary sequence of transformers followed\n",
            "by a final estimator, as we will see.\n",
            "\n",
            "--- Chunk 1927 ---\n",
            "Sensible defaults\n",
            "Scikit-Learn provides reasonable default values for most parameters, making it\n",
            "easy to quickly create a baseline working system.\n",
            "\n",
            "--- Chunk 1928 ---\n",
            "Handling Text and Categorical Attributes\n",
            "So far we have only dealt with numerical attributes, but now let’s look at text\n",
            "\n",
            "--- Chunk 1929 ---\n",
            "attributes. In this dataset, there is just one: the ocean_proximity attribute. Let’s look\n",
            "at its value for the first 10 instances:\n",
            "\n",
            "--- Chunk 1930 ---\n",
            "18 Some predictors also provide methods to measure the confidence of their predictions.\n",
            "\n",
            "Prepare the Data for Machine Learning Algorithms | 65\n",
            "\n",
            "--- Chunk 1931 ---\n",
            ">>> housing_cat = housing[[\"ocean_proximity\"]]\n",
            ">>> housing_cat.head(10)\n",
            "      ocean_proximity\n",
            "17606       <1H OCEAN\n",
            "18632       <1H OCEAN\n",
            "\n",
            "--- Chunk 1932 ---\n",
            "14650      NEAR OCEAN\n",
            "3230           INLAND\n",
            "3555        <1H OCEAN\n",
            "19480          INLAND\n",
            "8879        <1H OCEAN\n",
            "13685          INLAND\n",
            "\n",
            "--- Chunk 1933 ---\n",
            "4937        <1H OCEAN\n",
            "4861        <1H OCEAN\n",
            "\n",
            "--- Chunk 1934 ---\n",
            "It’s not arbitrary text: there are a limited number of possible values, each of which\n",
            "\n",
            "--- Chunk 1935 ---\n",
            "represents a category. So this attribute is a categorical attribute. Most Machine Learn‐\n",
            "\n",
            "--- Chunk 1936 ---\n",
            "ing algorithms prefer to work with numbers, so let’s convert these categories from\n",
            "\n",
            "--- Chunk 1937 ---\n",
            "text to numbers. For this, we can use Scikit-Learn’s OrdinalEncoder class:19\n",
            "\n",
            "--- Chunk 1938 ---\n",
            ">>> from sklearn.preprocessing import OrdinalEncoder\n",
            ">>> ordinal_encoder = OrdinalEncoder()\n",
            "\n",
            "--- Chunk 1939 ---\n",
            ">>> housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
            ">>> housing_cat_encoded[:10]\n",
            "array([[0.],\n",
            "       [0.],\n",
            "       [4.],\n",
            "       [1.],\n",
            "\n",
            "--- Chunk 1940 ---\n",
            "[1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.]])\n",
            "\n",
            "--- Chunk 1941 ---\n",
            "You can get the list of categories using the categories_ instance variable. It is a list\n",
            "\n",
            "--- Chunk 1942 ---\n",
            "containing a 1D array of categories for each categorical attribute (in this case, a list\n",
            "\n",
            "--- Chunk 1943 ---\n",
            "containing a single array since there is just one categorical attribute):\n",
            "\n",
            "--- Chunk 1944 ---\n",
            ">>> ordinal_encoder.categories_\n",
            "[array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n",
            "       dtype=object)]\n",
            "\n",
            "--- Chunk 1945 ---\n",
            "One issue with this representation is that ML algorithms will assume that two nearby\n",
            "\n",
            "--- Chunk 1946 ---\n",
            "values are more similar than two distant values. This may be fine in some cases (e.g.,\n",
            "\n",
            "--- Chunk 1947 ---\n",
            "for ordered categories such as “bad,” “average,” “good,” and “excellent”), but it is obvi‐\n",
            "\n",
            "--- Chunk 1948 ---\n",
            "ously not the case for the ocean_proximity column (for example, categories 0 and 4\n",
            "\n",
            "--- Chunk 1949 ---\n",
            "are clearly more similar than categories 0 and 1). To fix this issue, a common solution\n",
            "\n",
            "--- Chunk 1950 ---\n",
            "19 This class is available in Scikit-Learn 0.20 and later. If you use an earlier version, please consider upgrading, or\n",
            "\n",
            "--- Chunk 1951 ---\n",
            "use the pandas Series.factorize() method.\n",
            "\n",
            "--- Chunk 1952 ---\n",
            "66 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 1953 ---\n",
            "is to create one binary attribute per category: one attribute equal to 1 when the cate‐\n",
            "\n",
            "--- Chunk 1954 ---\n",
            "gory is “<1H OCEAN” (and 0 otherwise), another attribute equal to 1 when the cate‐\n",
            "\n",
            "--- Chunk 1955 ---\n",
            "gory is “INLAND” (and 0 otherwise), and so on. This is called one-hot encoding,\n",
            "\n",
            "--- Chunk 1956 ---\n",
            "because only one attribute will be equal to 1 (hot), while the others will be 0 (cold).\n",
            "\n",
            "--- Chunk 1957 ---\n",
            "The new attributes are sometimes called dummy attributes. Scikit-Learn provides a\n",
            "\n",
            "--- Chunk 1958 ---\n",
            "OneHotEncoder class to convert categorical values into one-hot vectors:20\n",
            "\n",
            "--- Chunk 1959 ---\n",
            ">>> from sklearn.preprocessing import OneHotEncoder\n",
            ">>> cat_encoder = OneHotEncoder()\n",
            ">>> housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
            "\n",
            "--- Chunk 1960 ---\n",
            ">>> housing_cat_1hot\n",
            "<16512x5 sparse matrix of type '<class 'numpy.float64'>'\n",
            "  with 16512 stored elements in Compressed Sparse Row format>\n",
            "\n",
            "--- Chunk 1961 ---\n",
            "Notice that the output is a SciPy sparse matrix, instead of a NumPy array. This is very\n",
            "\n",
            "--- Chunk 1962 ---\n",
            "useful when you have categorical attributes with thousands of categories. After one-\n",
            "\n",
            "--- Chunk 1963 ---\n",
            "hot encoding, we get a matrix with thousands of columns, and the matrix is full of 0s\n",
            "\n",
            "--- Chunk 1964 ---\n",
            "except for a single 1 per row. Using up tons of memory mostly to store zeros would\n",
            "\n",
            "--- Chunk 1965 ---\n",
            "be very wasteful, so instead a sparse matrix only stores the location of the nonzero\n",
            "\n",
            "--- Chunk 1966 ---\n",
            "elements. You can use it mostly like a normal 2D array,21 but if you really want to con‐\n",
            "\n",
            "--- Chunk 1967 ---\n",
            "vert it to a (dense) NumPy array, just call the toarray() method:\n",
            "\n",
            "--- Chunk 1968 ---\n",
            ">>> housing_cat_1hot.toarray()\n",
            "array([[1., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 1.],\n",
            "       ...,\n",
            "\n",
            "--- Chunk 1969 ---\n",
            "...,\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.]])\n",
            "\n",
            "--- Chunk 1970 ---\n",
            "Once again, you can get the list of categories using the encoder’s categories_\n",
            "instance variable:\n",
            "\n",
            "--- Chunk 1971 ---\n",
            ">>> cat_encoder.categories_\n",
            "[array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n",
            "       dtype=object)]\n",
            "\n",
            "--- Chunk 1972 ---\n",
            "20 Before Scikit-Learn 0.20, the method could only encode integer categorical values, but since 0.20 it can also\n",
            "\n",
            "--- Chunk 1973 ---\n",
            "handle other types of inputs, including text categorical inputs.\n",
            "\n",
            "--- Chunk 1974 ---\n",
            "21 See SciPy’s documentation for more details.\n",
            "\n",
            "Prepare the Data for Machine Learning Algorithms | 67\n",
            "\n",
            "--- Chunk 1975 ---\n",
            "If a categorical attribute has a large number of possible categories\n",
            "(e.g., country code, profession, species), then one-hot encoding will\n",
            "\n",
            "--- Chunk 1976 ---\n",
            "result in a large number of input features. This may slow down\n",
            "training and degrade performance. If this happens, you may want\n",
            "\n",
            "--- Chunk 1977 ---\n",
            "to replace the categorical input with useful numerical features\n",
            "related to the categories: for example, you could replace the\n",
            "\n",
            "--- Chunk 1978 ---\n",
            "ocean_proximity feature with the distance to the ocean (similarly,\n",
            "a country code could be replaced with the country’s population and\n",
            "\n",
            "--- Chunk 1979 ---\n",
            "GDP per capita). Alternatively, you could replace each category\n",
            "with a learnable, low-dimensional vector called an embedding. Each\n",
            "\n",
            "--- Chunk 1980 ---\n",
            "category’s representation would be learned during training. This is\n",
            "an example of representation learning (see Chapters 13 and 17 for\n",
            "more details).\n",
            "\n",
            "--- Chunk 1981 ---\n",
            "Custom Transformers\n",
            "Although Scikit-Learn provides many useful transformers, you will need to write\n",
            "\n",
            "--- Chunk 1982 ---\n",
            "your own for tasks such as custom cleanup operations or combining specific\n",
            "\n",
            "--- Chunk 1983 ---\n",
            "attributes. You will want your transformer to work seamlessly with Scikit-Learn func‐\n",
            "\n",
            "--- Chunk 1984 ---\n",
            "tionalities (such as pipelines), and since Scikit-Learn relies on duck typing (not inher‐\n",
            "\n",
            "--- Chunk 1985 ---\n",
            "itance), all you need to do is create a class and implement three methods: fit()\n",
            "(returning self), transform(), and fit_transform().\n",
            "\n",
            "--- Chunk 1986 ---\n",
            "You can get the last one for free by simply adding TransformerMixin as a base class.\n",
            "\n",
            "--- Chunk 1987 ---\n",
            "If you add BaseEstimator as a base class (and avoid *args and **kargs in your con‐\n",
            "\n",
            "--- Chunk 1988 ---\n",
            "structor), you will also get two extra methods (get_params() and set_params()) that\n",
            "will be useful for automatic hyperparameter tuning.\n",
            "\n",
            "--- Chunk 1989 ---\n",
            "For example, here is a small transformer class that adds the combined attributes we\n",
            "discussed earlier:\n",
            "\n",
            "--- Chunk 1990 ---\n",
            "from sklearn.base import BaseEstimator, TransformerMixin\n",
            "\n",
            "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
            "\n",
            "--- Chunk 1991 ---\n",
            "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
            "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
            "\n",
            "--- Chunk 1992 ---\n",
            "self.add_bedrooms_per_room = add_bedrooms_per_room\n",
            "    def fit(self, X, y=None):\n",
            "        return self  # nothing else to do\n",
            "\n",
            "--- Chunk 1993 ---\n",
            "def transform(self, X):\n",
            "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
            "\n",
            "--- Chunk 1994 ---\n",
            "population_per_household = X[:, population_ix] / X[:, households_ix]\n",
            "        if self.add_bedrooms_per_room:\n",
            "\n",
            "--- Chunk 1995 ---\n",
            "bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
            "            return np.c_[X, rooms_per_household, population_per_household,\n",
            "\n",
            "--- Chunk 1996 ---\n",
            "bedrooms_per_room]\n",
            "\n",
            "--- Chunk 1997 ---\n",
            "68 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "\n",
            "\n",
            "        else:\n",
            "            return np.c_[X, rooms_per_household, population_per_household]\n",
            "\n",
            "--- Chunk 1998 ---\n",
            "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
            "housing_extra_attribs = attr_adder.transform(housing.values)\n",
            "\n",
            "--- Chunk 1999 ---\n",
            "In this example the transformer has one hyperparameter, add_bedrooms_per_room,\n",
            "\n",
            "--- Chunk 2000 ---\n",
            "set to True by default (it is often helpful to provide sensible defaults). This hyperpara‐\n",
            "\n",
            "--- Chunk 2001 ---\n",
            "meter will allow you to easily find out whether adding this attribute helps the\n",
            "\n",
            "--- Chunk 2002 ---\n",
            "Machine Learning algorithms or not. More generally, you can add a hyperparameter\n",
            "\n",
            "--- Chunk 2003 ---\n",
            "to gate any data preparation step that you are not 100% sure about. The more you\n",
            "\n",
            "--- Chunk 2004 ---\n",
            "automate these data preparation steps, the more combinations you can automatically\n",
            "\n",
            "--- Chunk 2005 ---\n",
            "try out, making it much more likely that you will find a great combination (and sav‐\n",
            "ing you a lot of time).\n",
            "\n",
            "--- Chunk 2006 ---\n",
            "Feature Scaling\n",
            "One of the most important transformations you need to apply to your data is feature\n",
            "\n",
            "--- Chunk 2007 ---\n",
            "scaling. With few exceptions, Machine Learning algorithms don’t perform well when\n",
            "\n",
            "--- Chunk 2008 ---\n",
            "the input numerical attributes have very different scales. This is the case for the hous‐\n",
            "\n",
            "--- Chunk 2009 ---\n",
            "ing data: the total number of rooms ranges from about 6 to 39,320, while the median\n",
            "\n",
            "--- Chunk 2010 ---\n",
            "incomes only range from 0 to 15. Note that scaling the target values is generally not\n",
            "required.\n",
            "\n",
            "--- Chunk 2011 ---\n",
            "required.\n",
            "There are two common ways to get all attributes to have the same scale: min-max\n",
            "scaling and standardization.\n",
            "\n",
            "--- Chunk 2012 ---\n",
            "Min-max scaling (many people call this normalization) is the simplest: values are shif‐\n",
            "\n",
            "--- Chunk 2013 ---\n",
            "ted and rescaled so that they end up ranging from 0 to 1. We do this by subtracting\n",
            "\n",
            "--- Chunk 2014 ---\n",
            "the min value and dividing by the max minus the min. Scikit-Learn provides a trans‐\n",
            "\n",
            "--- Chunk 2015 ---\n",
            "former called MinMaxScaler for this. It has a feature_range hyperparameter that lets\n",
            "you change the range if, for some reason, you don’t want 0–1.\n",
            "\n",
            "--- Chunk 2016 ---\n",
            "Standardization is different: first it subtracts the mean value (so standardized values\n",
            "\n",
            "--- Chunk 2017 ---\n",
            "always have a zero mean), and then it divides by the standard deviation so that the\n",
            "\n",
            "--- Chunk 2018 ---\n",
            "resulting distribution has unit variance. Unlike min-max scaling, standardization\n",
            "\n",
            "--- Chunk 2019 ---\n",
            "does not bound values to a specific range, which may be a problem for some algo‐\n",
            "\n",
            "--- Chunk 2020 ---\n",
            "rithms (e.g., neural networks often expect an input value ranging from 0 to 1). How‐\n",
            "\n",
            "--- Chunk 2021 ---\n",
            "ever, standardization is much less affected by outliers. For example, suppose a district\n",
            "\n",
            "--- Chunk 2022 ---\n",
            "had a median income equal to 100 (by mistake). Min-max scaling would then crush\n",
            "\n",
            "--- Chunk 2023 ---\n",
            "all the other values from 0–15 down to 0–0.15, whereas standardization would not be\n",
            "\n",
            "--- Chunk 2024 ---\n",
            "much affected. Scikit-Learn provides a transformer called StandardScaler for\n",
            "standardization.\n",
            "\n",
            "--- Chunk 2025 ---\n",
            "Prepare the Data for Machine Learning Algorithms | 69\n",
            "\n",
            "--- Chunk 2026 ---\n",
            "As with all the transformations, it is important to fit the scalers to\n",
            "the training data only, not to the full dataset (including the test set).\n",
            "\n",
            "--- Chunk 2027 ---\n",
            "Only then can you use them to transform the training set and the\n",
            "test set (and new data).\n",
            "\n",
            "--- Chunk 2028 ---\n",
            "Transformation Pipelines\n",
            "As you can see, there are many data transformation steps that need to be executed in\n",
            "\n",
            "--- Chunk 2029 ---\n",
            "the right order. Fortunately, Scikit-Learn provides the Pipeline class to help with\n",
            "\n",
            "--- Chunk 2030 ---\n",
            "such sequences of transformations. Here is a small pipeline for the numerical\n",
            "attributes:\n",
            "\n",
            "--- Chunk 2031 ---\n",
            "from sklearn.pipeline import Pipeline\n",
            "from sklearn.preprocessing import StandardScaler\n",
            "\n",
            "--- Chunk 2032 ---\n",
            "num_pipeline = Pipeline([\n",
            "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
            "        ('attribs_adder', CombinedAttributesAdder()),\n",
            "\n",
            "--- Chunk 2033 ---\n",
            "('std_scaler', StandardScaler()),\n",
            "    ])\n",
            "\n",
            "--- Chunk 2034 ---\n",
            "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
            "\n",
            "--- Chunk 2035 ---\n",
            "The Pipeline constructor takes a list of name/estimator pairs defining a sequence of\n",
            "\n",
            "--- Chunk 2036 ---\n",
            "steps. All but the last estimator must be transformers (i.e., they must have a\n",
            "\n",
            "--- Chunk 2037 ---\n",
            "fit_transform() method). The names can be anything you like (as long as they are\n",
            "\n",
            "--- Chunk 2038 ---\n",
            "unique and don’t contain double underscores, __); they will come in handy later for\n",
            "hyperparameter tuning.\n",
            "\n",
            "--- Chunk 2039 ---\n",
            "When you call the pipeline’s fit() method, it calls fit_transform() sequentially on\n",
            "\n",
            "--- Chunk 2040 ---\n",
            "all transformers, passing the output of each call as the parameter to the next call until\n",
            "\n",
            "--- Chunk 2041 ---\n",
            "it reaches the final estimator, for which it calls the fit() method.\n",
            "\n",
            "--- Chunk 2042 ---\n",
            "The pipeline exposes the same methods as the final estimator. In this example, the last\n",
            "\n",
            "--- Chunk 2043 ---\n",
            "estimator is a StandardScaler, which is a transformer, so the pipeline has a trans\n",
            "\n",
            "--- Chunk 2044 ---\n",
            "form() method that applies all the transforms to the data in sequence (and of course\n",
            "also a fit_transform() method, which is the one we used).\n",
            "\n",
            "--- Chunk 2045 ---\n",
            "So far, we have handled the categorical columns and the numerical columns sepa‐\n",
            "\n",
            "--- Chunk 2046 ---\n",
            "rately. It would be more convenient to have a single transformer able to handle all col‐\n",
            "\n",
            "--- Chunk 2047 ---\n",
            "umns, applying the appropriate transformations to each column. In version 0.20,\n",
            "\n",
            "--- Chunk 2048 ---\n",
            "Scikit-Learn introduced the ColumnTransformer for this purpose, and the good news\n",
            "\n",
            "--- Chunk 2049 ---\n",
            "is that it works great with pandas DataFrames. Let’s use it to apply all the transforma‐\n",
            "tions to the housing data:\n",
            "\n",
            "--- Chunk 2050 ---\n",
            "70 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "\n",
            "\n",
            "from sklearn.compose import ColumnTransformer\n",
            "\n",
            "--- Chunk 2051 ---\n",
            "num_attribs = list(housing_num)\n",
            "cat_attribs = [\"ocean_proximity\"]\n",
            "\n",
            "--- Chunk 2052 ---\n",
            "full_pipeline = ColumnTransformer([\n",
            "        (\"num\", num_pipeline, num_attribs),\n",
            "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
            "    ])\n",
            "\n",
            "--- Chunk 2053 ---\n",
            "housing_prepared = full_pipeline.fit_transform(housing)\n",
            "\n",
            "--- Chunk 2054 ---\n",
            "First we import the ColumnTransformer class, next we get the list of numerical col‐\n",
            "\n",
            "--- Chunk 2055 ---\n",
            "umn names and the list of categorical column names, and then we construct a Colum\n",
            "\n",
            "--- Chunk 2056 ---\n",
            "nTransformer. The constructor requires a list of tuples, where each tuple contains a\n",
            "\n",
            "--- Chunk 2057 ---\n",
            "name,22 a transformer, and a list of names (or indices) of columns that the trans‐\n",
            "\n",
            "--- Chunk 2058 ---\n",
            "former should be applied to. In this example, we specify that the numerical columns\n",
            "\n",
            "--- Chunk 2059 ---\n",
            "should be transformed using the num_pipeline that we defined earlier, and the cate‐\n",
            "\n",
            "--- Chunk 2060 ---\n",
            "gorical columns should be transformed using a OneHotEncoder. Finally, we apply this\n",
            "\n",
            "--- Chunk 2061 ---\n",
            "ColumnTransformer to the housing data: it applies each transformer to the appropri‐\n",
            "\n",
            "--- Chunk 2062 ---\n",
            "ate columns and concatenates the outputs along the second axis (the transformers\n",
            "must return the same number of rows).\n",
            "\n",
            "--- Chunk 2063 ---\n",
            "Note that the OneHotEncoder returns a sparse matrix, while the num_pipeline returns\n",
            "\n",
            "--- Chunk 2064 ---\n",
            "a dense matrix. When there is such a mix of sparse and dense matrices, the Colum\n",
            "\n",
            "--- Chunk 2065 ---\n",
            "nTransformer estimates the density of the final matrix (i.e., the ratio of nonzero\n",
            "\n",
            "--- Chunk 2066 ---\n",
            "cells), and it returns a sparse matrix if the density is lower than a given threshold (by\n",
            "\n",
            "--- Chunk 2067 ---\n",
            "default, sparse_threshold=0.3). In this example, it returns a dense matrix. And\n",
            "\n",
            "--- Chunk 2068 ---\n",
            "that’s it! We have a preprocessing pipeline that takes the full housing data and applies\n",
            "the appropriate transformations to each column.\n",
            "\n",
            "--- Chunk 2069 ---\n",
            "Instead of using a transformer, you can specify the string \"drop\" if\n",
            "you want the columns to be dropped, or you can specify \"pass\n",
            "\n",
            "--- Chunk 2070 ---\n",
            "through\" if you want the columns to be left untouched. By default,\n",
            "the remaining columns (i.e., the ones that were not listed) will be\n",
            "\n",
            "--- Chunk 2071 ---\n",
            "dropped, but you can set the remainder hyperparameter to any\n",
            "transformer (or to \"passthrough\") if you want these columns to be\n",
            "handled differently.\n",
            "\n",
            "--- Chunk 2072 ---\n",
            "If you are using Scikit-Learn 0.19 or earlier, you can use a third-party library such as\n",
            "\n",
            "--- Chunk 2073 ---\n",
            "sklearn-pandas, or you can roll out your own custom transformer to get the same\n",
            "\n",
            "--- Chunk 2074 ---\n",
            "functionality as the ColumnTransformer. Alternatively, you can use the FeatureUnion\n",
            "\n",
            "--- Chunk 2075 ---\n",
            "22 Just like for pipelines, the name can be anything as long as it does not contain double underscores.\n",
            "\n",
            "--- Chunk 2076 ---\n",
            "Prepare the Data for Machine Learning Algorithms | 71\n",
            "\n",
            "--- Chunk 2077 ---\n",
            "class, which can apply different transformers and concatenate their outputs. But you\n",
            "\n",
            "--- Chunk 2078 ---\n",
            "cannot specify different columns for each transformer; they all apply to the whole\n",
            "\n",
            "--- Chunk 2079 ---\n",
            "data. It is possible to work around this limitation using a custom transformer for col‐\n",
            "umn selection (see the Jupyter notebook for an example).\n",
            "\n",
            "--- Chunk 2080 ---\n",
            "Select and Train a Model\n",
            "At last! You framed the problem, you got the data and explored it, you sampled a\n",
            "\n",
            "--- Chunk 2081 ---\n",
            "training set and a test set, and you wrote transformation pipelines to clean up and\n",
            "\n",
            "--- Chunk 2082 ---\n",
            "prepare your data for Machine Learning algorithms automatically. You are now ready\n",
            "to select and train a Machine Learning model.\n",
            "\n",
            "--- Chunk 2083 ---\n",
            "Training and Evaluating on the Training Set\n",
            "The good news is that thanks to all these previous steps, things are now going to be\n",
            "\n",
            "--- Chunk 2084 ---\n",
            "much simpler than you might think. Let’s first train a Linear Regression model, like\n",
            "we did in the previous chapter:\n",
            "\n",
            "--- Chunk 2085 ---\n",
            "from sklearn.linear_model import LinearRegression\n",
            "\n",
            "lin_reg = LinearRegression()\n",
            "lin_reg.fit(housing_prepared, housing_labels)\n",
            "\n",
            "--- Chunk 2086 ---\n",
            "Done! You now have a working Linear Regression model. Let’s try it out on a few\n",
            "instances from the training set:\n",
            "\n",
            "--- Chunk 2087 ---\n",
            ">>> some_data = housing.iloc[:5]\n",
            ">>> some_labels = housing_labels.iloc[:5]\n",
            ">>> some_data_prepared = full_pipeline.transform(some_data)\n",
            "\n",
            "--- Chunk 2088 ---\n",
            ">>> print(\"Predictions:\", lin_reg.predict(some_data_prepared))\n",
            "Predictions: [ 210644.6045  317768.8069  210956.4333  59218.9888  189747.5584]\n",
            "\n",
            "--- Chunk 2089 ---\n",
            ">>> print(\"Labels:\", list(some_labels))\n",
            "Labels: [286600.0, 340600.0, 196900.0, 46300.0, 254500.0]\n",
            "\n",
            "--- Chunk 2090 ---\n",
            "It works, although the predictions are not exactly accurate (e.g., the first prediction is\n",
            "\n",
            "--- Chunk 2091 ---\n",
            "off by close to 40%!). Let’s measure this regression model’s RMSE on the whole train‐\n",
            "ing set using Scikit-Learn’s mean_squared_error() function:\n",
            "\n",
            "--- Chunk 2092 ---\n",
            ">>> from sklearn.metrics import mean_squared_error\n",
            ">>> housing_predictions = lin_reg.predict(housing_prepared)\n",
            "\n",
            "--- Chunk 2093 ---\n",
            ">>> lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
            ">>> lin_rmse = np.sqrt(lin_mse)\n",
            ">>> lin_rmse\n",
            "68628.19819848922\n",
            "\n",
            "--- Chunk 2094 ---\n",
            "This is better than nothing, but clearly not a great score: most districts’ median_hous\n",
            "\n",
            "--- Chunk 2095 ---\n",
            "ing_values range between $120,000 and $265,000, so a typical prediction error of\n",
            "\n",
            "--- Chunk 2096 ---\n",
            "$68,628 is not very satisfying. This is an example of a model underfitting the training\n",
            "\n",
            "--- Chunk 2097 ---\n",
            "data. When this happens it can mean that the features do not provide enough\n",
            "\n",
            "--- Chunk 2098 ---\n",
            "72 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 2099 ---\n",
            "information to make good predictions, or that the model is not powerful enough. As\n",
            "\n",
            "--- Chunk 2100 ---\n",
            "we saw in the previous chapter, the main ways to fix underfitting are to select a more\n",
            "\n",
            "--- Chunk 2101 ---\n",
            "powerful model, to feed the training algorithm with better features, or to reduce the\n",
            "\n",
            "--- Chunk 2102 ---\n",
            "constraints on the model. This model is not regularized, which rules out the last\n",
            "\n",
            "--- Chunk 2103 ---\n",
            "option. You could try to add more features (e.g., the log of the population), but first\n",
            "let’s try a more complex model to see how it does.\n",
            "\n",
            "--- Chunk 2104 ---\n",
            "Let’s train a DecisionTreeRegressor. This is a powerful model, capable of finding\n",
            "\n",
            "--- Chunk 2105 ---\n",
            "complex nonlinear relationships in the data (Decision Trees are presented in more\n",
            "detail in Chapter 6). The code should look familiar by now:\n",
            "\n",
            "--- Chunk 2106 ---\n",
            "from sklearn.tree import DecisionTreeRegressor\n",
            "\n",
            "tree_reg = DecisionTreeRegressor()\n",
            "tree_reg.fit(housing_prepared, housing_labels)\n",
            "\n",
            "--- Chunk 2107 ---\n",
            "Now that the model is trained, let’s evaluate it on the training set:\n",
            ">>> housing_predictions = tree_reg.predict(housing_prepared)\n",
            "\n",
            "--- Chunk 2108 ---\n",
            ">>> tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
            ">>> tree_rmse = np.sqrt(tree_mse)\n",
            ">>> tree_rmse\n",
            "0.0\n",
            "\n",
            "--- Chunk 2109 ---\n",
            "Wait, what!? No error at all? Could this model really be absolutely perfect? Of course,\n",
            "\n",
            "--- Chunk 2110 ---\n",
            "it is much more likely that the model has badly overfit the data. How can you be sure?\n",
            "\n",
            "--- Chunk 2111 ---\n",
            "As we saw earlier, you don’t want to touch the test set until you are ready to launch a\n",
            "\n",
            "--- Chunk 2112 ---\n",
            "model you are confident about, so you need to use part of the training set for training\n",
            "and part of it for model validation.\n",
            "\n",
            "--- Chunk 2113 ---\n",
            "Better Evaluation Using Cross-Validation\n",
            "One way to evaluate the Decision Tree model would be to use the\n",
            "\n",
            "--- Chunk 2114 ---\n",
            "train_test_split() function to split the training set into a smaller training set and a\n",
            "\n",
            "--- Chunk 2115 ---\n",
            "validation set, then train your models against the smaller training set and evaluate\n",
            "\n",
            "--- Chunk 2116 ---\n",
            "them against the validation set. It’s a bit of work, but nothing too difficult, and it\n",
            "would work fairly well.\n",
            "\n",
            "--- Chunk 2117 ---\n",
            "A great alternative is to use Scikit-Learn’s K-fold cross-validation feature. The follow‐\n",
            "\n",
            "--- Chunk 2118 ---\n",
            "ing code randomly splits the training set into 10 distinct subsets called folds, then it\n",
            "\n",
            "--- Chunk 2119 ---\n",
            "trains and evaluates the Decision Tree model 10 times, picking a different fold for\n",
            "\n",
            "--- Chunk 2120 ---\n",
            "evaluation every time and training on the other 9 folds. The result is an array con‐\n",
            "taining the 10 evaluation scores:\n",
            "\n",
            "--- Chunk 2121 ---\n",
            "from sklearn.model_selection import cross_val_score\n",
            "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
            "\n",
            "--- Chunk 2122 ---\n",
            "scoring=\"neg_mean_squared_error\", cv=10)\n",
            "tree_rmse_scores = np.sqrt(-scores)\n",
            "\n",
            "--- Chunk 2123 ---\n",
            "Select and Train a Model | 73\n",
            "\n",
            "--- Chunk 2124 ---\n",
            "Scikit-Learn’s cross-validation features expect a utility function\n",
            "(greater is better) rather than a cost function (lower is better), so\n",
            "\n",
            "--- Chunk 2125 ---\n",
            "the scoring function is actually the opposite of the MSE (i.e., a neg‐\n",
            "ative value), which is why the preceding code computes -scores\n",
            "\n",
            "--- Chunk 2126 ---\n",
            "before calculating the square root.\n",
            "\n",
            "--- Chunk 2127 ---\n",
            "Let’s look at the results:\n",
            ">>> def display_scores(scores):\n",
            "...     print(\"Scores:\", scores)\n",
            "...     print(\"Mean:\", scores.mean())\n",
            "\n",
            "--- Chunk 2128 ---\n",
            "...     print(\"Standard deviation:\", scores.std())\n",
            "...\n",
            ">>> display_scores(tree_rmse_scores)\n",
            "\n",
            "--- Chunk 2129 ---\n",
            "Scores: [70194.33680785 66855.16363941 72432.58244769 70758.73896782\n",
            " 71115.88230639 75585.14172901 70262.86139133 70273.6325285\n",
            "\n",
            "--- Chunk 2130 ---\n",
            "75366.87952553 71231.65726027]\n",
            "Mean: 71407.68766037929\n",
            "Standard deviation: 2439.4345041191004\n",
            "\n",
            "--- Chunk 2131 ---\n",
            "Now the Decision Tree doesn’t look as good as it did earlier. In fact, it seems to per‐\n",
            "\n",
            "--- Chunk 2132 ---\n",
            "form worse than the Linear Regression model! Notice that cross-validation allows\n",
            "\n",
            "--- Chunk 2133 ---\n",
            "you to get not only an estimate of the performance of your model, but also a measure\n",
            "\n",
            "--- Chunk 2134 ---\n",
            "of how precise this estimate is (i.e., its standard deviation). The Decision Tree has a\n",
            "\n",
            "--- Chunk 2135 ---\n",
            "score of approximately 71,407, generally ±2,439. You would not have this information\n",
            "\n",
            "--- Chunk 2136 ---\n",
            "if you just used one validation set. But cross-validation comes at the cost of training\n",
            "the model several times, so it is not always possible.\n",
            "\n",
            "--- Chunk 2137 ---\n",
            "Let’s compute the same scores for the Linear Regression model just to be sure:\n",
            "\n",
            "--- Chunk 2138 ---\n",
            ">>> lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
            "\n",
            "--- Chunk 2139 ---\n",
            "...                              scoring=\"neg_mean_squared_error\", cv=10)\n",
            "...\n",
            ">>> lin_rmse_scores = np.sqrt(-lin_scores)\n",
            "\n",
            "--- Chunk 2140 ---\n",
            ">>> display_scores(lin_rmse_scores)\n",
            "Scores: [66782.73843989 66960.118071   70347.95244419 74739.57052552\n",
            "\n",
            "--- Chunk 2141 ---\n",
            "68031.13388938 71193.84183426 64969.63056405 68281.61137997\n",
            " 71552.91566558 67665.10082067]\n",
            "Mean: 69052.46136345083\n",
            "\n",
            "--- Chunk 2142 ---\n",
            "Standard deviation: 2731.674001798348\n",
            "\n",
            "--- Chunk 2143 ---\n",
            "That’s right: the Decision Tree model is overfitting so badly that it performs worse\n",
            "than the Linear Regression model.\n",
            "\n",
            "--- Chunk 2144 ---\n",
            "Let’s try one last model now: the RandomForestRegressor. As we will see in Chap‐\n",
            "\n",
            "--- Chunk 2145 ---\n",
            "ter 7, Random Forests work by training many Decision Trees on random subsets of\n",
            "\n",
            "--- Chunk 2146 ---\n",
            "the features, then averaging out their predictions. Building a model on top of many\n",
            "\n",
            "--- Chunk 2147 ---\n",
            "other models is called Ensemble Learning, and it is often a great way to push ML algo‐\n",
            "\n",
            "--- Chunk 2148 ---\n",
            "rithms even further. We will skip most of the code since it is essentially the same as\n",
            "for the other models:\n",
            "\n",
            "--- Chunk 2149 ---\n",
            "74 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 2150 ---\n",
            ">>> from sklearn.ensemble import RandomForestRegressor\n",
            ">>> forest_reg = RandomForestRegressor()\n",
            ">>> forest_reg.fit(housing_prepared, housing_labels)\n",
            "\n",
            "--- Chunk 2151 ---\n",
            ">>> [...]\n",
            ">>> forest_rmse\n",
            "18603.515021376355\n",
            ">>> display_scores(forest_rmse_scores)\n",
            "\n",
            "--- Chunk 2152 ---\n",
            "Scores: [49519.80364233 47461.9115823  50029.02762854 52325.28068953\n",
            " 49308.39426421 53446.37892622 48634.8036574  47585.73832311\n",
            "\n",
            "--- Chunk 2153 ---\n",
            "53490.10699751 50021.5852922 ]\n",
            "Mean: 50182.303100336096\n",
            "Standard deviation: 2097.0810550985693\n",
            "\n",
            "--- Chunk 2154 ---\n",
            "Wow, this is much better: Random Forests look very promising. However, note that\n",
            "\n",
            "--- Chunk 2155 ---\n",
            "the score on the training set is still much lower than on the validation sets, meaning\n",
            "\n",
            "--- Chunk 2156 ---\n",
            "that the model is still overfitting the training set. Possible solutions for overfitting are\n",
            "\n",
            "--- Chunk 2157 ---\n",
            "to simplify the model, constrain it (i.e., regularize it), or get a lot more training data.\n",
            "\n",
            "--- Chunk 2158 ---\n",
            "Before you dive much deeper into Random Forests, however, you should try out\n",
            "\n",
            "--- Chunk 2159 ---\n",
            "many other models from various categories of Machine Learning algorithms (e.g.,\n",
            "\n",
            "--- Chunk 2160 ---\n",
            "several Support Vector Machines with different kernels, and possibly a neural net‐\n",
            "\n",
            "--- Chunk 2161 ---\n",
            "work), without spending too much time tweaking the hyperparameters. The goal is to\n",
            "shortlist a few (two to five) promising models.\n",
            "\n",
            "--- Chunk 2162 ---\n",
            "You should save every model you experiment with so that you can\n",
            "come back easily to any model you want. Make sure you save both\n",
            "\n",
            "--- Chunk 2163 ---\n",
            "the hyperparameters and the trained parameters, as well as the\n",
            "cross-validation scores and perhaps the actual predictions as well.\n",
            "\n",
            "--- Chunk 2164 ---\n",
            "This will allow you to easily compare scores across model types,\n",
            "and compare the types of errors they make. You can easily save\n",
            "\n",
            "--- Chunk 2165 ---\n",
            "Scikit-Learn models by using Python’s pickle module or by using\n",
            "the joblib library, which is more efficient at serializing large\n",
            "\n",
            "--- Chunk 2166 ---\n",
            "NumPy arrays (you can install this library using pip):\n",
            "\n",
            "--- Chunk 2167 ---\n",
            "import joblib\n",
            "\n",
            "joblib.dump(my_model, \"my_model.pkl\")\n",
            "# and later...\n",
            "my_model_loaded = joblib.load(\"my_model.pkl\")\n",
            "\n",
            "--- Chunk 2168 ---\n",
            "Fine-Tune Your Model\n",
            "Let’s assume that you now have a shortlist of promising models. You now need to\n",
            "\n",
            "--- Chunk 2169 ---\n",
            "fine-tune them. Let’s look at a few ways you can do that.\n",
            "\n",
            "--- Chunk 2170 ---\n",
            "Fine-Tune Your Model | 75\n",
            "\n",
            "--- Chunk 2171 ---\n",
            "Grid Search\n",
            "One option would be to fiddle with the hyperparameters manually, until you find a\n",
            "\n",
            "--- Chunk 2172 ---\n",
            "great combination of hyperparameter values. This would be very tedious work, and\n",
            "you may not have time to explore many combinations.\n",
            "\n",
            "--- Chunk 2173 ---\n",
            "Instead, you should get Scikit-Learn’s GridSearchCV to search for you. All you need\n",
            "\n",
            "--- Chunk 2174 ---\n",
            "to do is tell it which hyperparameters you want it to experiment with and what values\n",
            "\n",
            "--- Chunk 2175 ---\n",
            "to try out, and it will use cross-validation to evaluate all the possible combinations of\n",
            "\n",
            "--- Chunk 2176 ---\n",
            "hyperparameter values. For example, the following code searches for the best combi‐\n",
            "nation of hyperparameter values for the RandomForestRegressor:\n",
            "\n",
            "--- Chunk 2177 ---\n",
            "from sklearn.model_selection import GridSearchCV\n",
            "\n",
            "--- Chunk 2178 ---\n",
            "param_grid = [\n",
            "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
            "\n",
            "--- Chunk 2179 ---\n",
            "{'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
            "  ]\n",
            "\n",
            "--- Chunk 2180 ---\n",
            "forest_reg = RandomForestRegressor()\n",
            "\n",
            "--- Chunk 2181 ---\n",
            "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
            "                           scoring='neg_mean_squared_error',\n",
            "\n",
            "--- Chunk 2182 ---\n",
            "return_train_score=True)\n",
            "\n",
            "--- Chunk 2183 ---\n",
            "grid_search.fit(housing_prepared, housing_labels)\n",
            "\n",
            "--- Chunk 2184 ---\n",
            "When you have no idea what value a hyperparameter should have,\n",
            "a simple approach is to try out consecutive powers of 10 (or a\n",
            "\n",
            "--- Chunk 2185 ---\n",
            "smaller number if you want a more fine-grained search, as shown\n",
            "in this example with the n_estimators hyperparameter).\n",
            "\n",
            "--- Chunk 2186 ---\n",
            "This param_grid tells Scikit-Learn to first evaluate all 3 × 4 = 12 combinations of\n",
            "\n",
            "--- Chunk 2187 ---\n",
            "n_estimators and max_features hyperparameter values specified in the first dict\n",
            "\n",
            "--- Chunk 2188 ---\n",
            "(don’t worry about what these hyperparameters mean for now; they will be explained\n",
            "\n",
            "--- Chunk 2189 ---\n",
            "in Chapter 7), then try all 2 × 3 = 6 combinations of hyperparameter values in the\n",
            "\n",
            "--- Chunk 2190 ---\n",
            "second dict, but this time with the bootstrap hyperparameter set to False instead of\n",
            "True (which is the default value for this hyperparameter).\n",
            "\n",
            "--- Chunk 2191 ---\n",
            "The grid search will explore 12 + 6 = 18 combinations of RandomForestRegressor\n",
            "\n",
            "--- Chunk 2192 ---\n",
            "hyperparameter values, and it will train each model 5 times (since we are using five-\n",
            "\n",
            "--- Chunk 2193 ---\n",
            "fold cross validation). In other words, all in all, there will be 18 × 5 = 90 rounds of\n",
            "\n",
            "--- Chunk 2194 ---\n",
            "training! It may take quite a long time, but when it is done you can get the best com‐\n",
            "bination of parameters like this:\n",
            "\n",
            "--- Chunk 2195 ---\n",
            ">>> grid_search.best_params_\n",
            "{'max_features': 8, 'n_estimators': 30}\n",
            "\n",
            "76 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 2196 ---\n",
            "Since 8 and 30 are the maximum values that were evaluated, you\n",
            "should probably try searching again with higher values; the score\n",
            "\n",
            "--- Chunk 2197 ---\n",
            "may continue to improve.\n",
            "\n",
            "--- Chunk 2198 ---\n",
            "You can also get the best estimator directly:\n",
            ">>> grid_search.best_estimator_\n",
            "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
            "\n",
            "--- Chunk 2199 ---\n",
            "max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "           min_impurity_split=None, min_samples_leaf=1,\n",
            "\n",
            "--- Chunk 2200 ---\n",
            "min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "           n_estimators=30, n_jobs=None, oob_score=False, random_state=None,\n",
            "\n",
            "--- Chunk 2201 ---\n",
            "verbose=0, warm_start=False)\n",
            "\n",
            "--- Chunk 2202 ---\n",
            "If GridSearchCV is initialized with refit=True (which is the\n",
            "default), then once it finds the best estimator using cross-\n",
            "\n",
            "--- Chunk 2203 ---\n",
            "validation, it retrains it on the whole training set. This is usually a\n",
            "good idea, since feeding it more data will likely improve its\n",
            "performance.\n",
            "\n",
            "--- Chunk 2204 ---\n",
            "And of course the evaluation scores are also available:\n",
            ">>> cvres = grid_search.cv_results_\n",
            "\n",
            "--- Chunk 2205 ---\n",
            ">>> for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
            "...     print(np.sqrt(-mean_score), params)\n",
            "...\n",
            "\n",
            "--- Chunk 2206 ---\n",
            "...\n",
            "63669.05791727153 {'max_features': 2, 'n_estimators': 3}\n",
            "55627.16171305252 {'max_features': 2, 'n_estimators': 10}\n",
            "\n",
            "--- Chunk 2207 ---\n",
            "53384.57867637289 {'max_features': 2, 'n_estimators': 30}\n",
            "60965.99185930139 {'max_features': 4, 'n_estimators': 3}\n",
            "\n",
            "--- Chunk 2208 ---\n",
            "52740.98248528835 {'max_features': 4, 'n_estimators': 10}\n",
            "50377.344409590376 {'max_features': 4, 'n_estimators': 30}\n",
            "\n",
            "--- Chunk 2209 ---\n",
            "58663.84733372485 {'max_features': 6, 'n_estimators': 3}\n",
            "52006.15355973719 {'max_features': 6, 'n_estimators': 10}\n",
            "\n",
            "--- Chunk 2210 ---\n",
            "50146.465964159885 {'max_features': 6, 'n_estimators': 30}\n",
            "57869.25504027614 {'max_features': 8, 'n_estimators': 3}\n",
            "\n",
            "--- Chunk 2211 ---\n",
            "51711.09443660957 {'max_features': 8, 'n_estimators': 10}\n",
            "49682.25345942335 {'max_features': 8, 'n_estimators': 30}\n",
            "\n",
            "--- Chunk 2212 ---\n",
            "62895.088889905004 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
            "\n",
            "--- Chunk 2213 ---\n",
            "54658.14484390074 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
            "\n",
            "--- Chunk 2214 ---\n",
            "59470.399594730654 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
            "\n",
            "--- Chunk 2215 ---\n",
            "52725.01091081235 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
            "\n",
            "--- Chunk 2216 ---\n",
            "57490.612956065226 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
            "\n",
            "--- Chunk 2217 ---\n",
            "51009.51445842374 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n",
            "\n",
            "--- Chunk 2218 ---\n",
            "In this example, we obtain the best solution by setting the max_features hyperpara‐\n",
            "\n",
            "--- Chunk 2219 ---\n",
            "meter to 8 and the n_estimators hyperparameter to 30. The RMSE score for this\n",
            "\n",
            "--- Chunk 2220 ---\n",
            "combination is 49,682, which is slightly better than the score you got earlier using the\n",
            "\n",
            "--- Chunk 2221 ---\n",
            "Fine-Tune Your Model | 77\n",
            "\n",
            "\n",
            "\n",
            "default hyperparameter values (which was 50,182). Congratulations, you have suc‐\n",
            "cessfully fine-tuned your best model!\n",
            "\n",
            "--- Chunk 2222 ---\n",
            "Don’t forget that you can treat some of the data preparation steps as\n",
            "hyperparameters. For example, the grid search will automatically\n",
            "\n",
            "--- Chunk 2223 ---\n",
            "find out whether or not to add a feature you were not sure about\n",
            "(e.g., using the add_bedrooms_per_room hyperparameter of your\n",
            "\n",
            "--- Chunk 2224 ---\n",
            "CombinedAttributesAdder transformer). It may similarly be used\n",
            "to automatically find the best way to handle outliers, missing fea‐\n",
            "\n",
            "--- Chunk 2225 ---\n",
            "tures, feature selection, and more.\n",
            "\n",
            "--- Chunk 2226 ---\n",
            "Randomized Search\n",
            "The grid search approach is fine when you are exploring relatively few combinations,\n",
            "\n",
            "--- Chunk 2227 ---\n",
            "like in the previous example, but when the hyperparameter search space is large, it is\n",
            "\n",
            "--- Chunk 2228 ---\n",
            "often preferable to use RandomizedSearchCV instead. This class can be used in much\n",
            "\n",
            "--- Chunk 2229 ---\n",
            "the same way as the GridSearchCV class, but instead of trying out all possible combi‐\n",
            "\n",
            "--- Chunk 2230 ---\n",
            "nations, it evaluates a given number of random combinations by selecting a random\n",
            "\n",
            "--- Chunk 2231 ---\n",
            "value for each hyperparameter at every iteration. This approach has two main\n",
            "benefits:\n",
            "\n",
            "--- Chunk 2232 ---\n",
            "• If you let the randomized search run for, say, 1,000 iterations, this approach will\n",
            "\n",
            "--- Chunk 2233 ---\n",
            "explore 1,000 different values for each hyperparameter (instead of just a few val‐\n",
            "ues per hyperparameter with the grid search approach).\n",
            "\n",
            "--- Chunk 2234 ---\n",
            "• Simply by setting the number of iterations, you have more control over the com‐\n",
            "puting budget you want to allocate to hyperparameter search.\n",
            "\n",
            "--- Chunk 2235 ---\n",
            "Ensemble Methods\n",
            "Another way to fine-tune your system is to try to combine the models that perform\n",
            "\n",
            "--- Chunk 2236 ---\n",
            "best. The group (or “ensemble”) will often perform better than the best individual\n",
            "\n",
            "--- Chunk 2237 ---\n",
            "model (just like Random Forests perform better than the individual Decision Trees\n",
            "\n",
            "--- Chunk 2238 ---\n",
            "they rely on), especially if the individual models make very different types of errors.\n",
            "We will cover this topic in more detail in Chapter 7.\n",
            "\n",
            "--- Chunk 2239 ---\n",
            "Analyze the Best Models and Their Errors\n",
            "You will often gain good insights on the problem by inspecting the best models. For\n",
            "\n",
            "--- Chunk 2240 ---\n",
            "example, the RandomForestRegressor can indicate the relative importance of each\n",
            "attribute for making accurate predictions:\n",
            "\n",
            "--- Chunk 2241 ---\n",
            ">>> feature_importances = grid_search.best_estimator_.feature_importances_\n",
            ">>> feature_importances\n",
            "\n",
            "--- Chunk 2242 ---\n",
            "array([7.33442355e-02, 6.29090705e-02, 4.11437985e-02, 1.46726854e-02,\n",
            "\n",
            "--- Chunk 2243 ---\n",
            "78 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 2244 ---\n",
            "1.41064835e-02, 1.48742809e-02, 1.42575993e-02, 3.66158981e-01,\n",
            "       5.64191792e-02, 1.08792957e-01, 5.33510773e-02, 1.03114883e-02,\n",
            "\n",
            "--- Chunk 2245 ---\n",
            "1.64780994e-01, 6.02803867e-05, 1.96041560e-03, 2.85647464e-03])\n",
            "\n",
            "--- Chunk 2246 ---\n",
            "Let’s display these importance scores next to their corresponding attribute names:\n",
            "\n",
            "--- Chunk 2247 ---\n",
            ">>> extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
            ">>> cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
            "\n",
            "--- Chunk 2248 ---\n",
            ">>> cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
            ">>> attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
            "\n",
            "--- Chunk 2249 ---\n",
            ">>> sorted(zip(feature_importances, attributes), reverse=True)\n",
            "[(0.3661589806181342, 'median_income'),\n",
            " (0.1647809935615905, 'INLAND'),\n",
            "\n",
            "--- Chunk 2250 ---\n",
            "(0.10879295677551573, 'pop_per_hhold'),\n",
            " (0.07334423551601242, 'longitude'),\n",
            " (0.0629090704826203, 'latitude'),\n",
            "\n",
            "--- Chunk 2251 ---\n",
            "(0.05641917918195401, 'rooms_per_hhold'),\n",
            " (0.05335107734767581, 'bedrooms_per_room'),\n",
            " (0.041143798478729635, 'housing_median_age'),\n",
            "\n",
            "--- Chunk 2252 ---\n",
            "(0.014874280890402767, 'population'),\n",
            " (0.014672685420543237, 'total_rooms'),\n",
            " (0.014257599323407807, 'households'),\n",
            "\n",
            "--- Chunk 2253 ---\n",
            "(0.014106483453584102, 'total_bedrooms'),\n",
            " (0.010311488326303787, '<1H OCEAN'),\n",
            " (0.002856474637320158, 'NEAR OCEAN'),\n",
            "\n",
            "--- Chunk 2254 ---\n",
            "(0.00196041559947807, 'NEAR BAY'),\n",
            " (6.028038672736599e-05, 'ISLAND')]\n",
            "\n",
            "--- Chunk 2255 ---\n",
            "With this information, you may want to try dropping some of the less useful features\n",
            "\n",
            "--- Chunk 2256 ---\n",
            "(e.g., apparently only one ocean_proximity category is really useful, so you could try\n",
            "dropping the others).\n",
            "\n",
            "--- Chunk 2257 ---\n",
            "You should also look at the specific errors that your system makes, then try to under‐\n",
            "\n",
            "--- Chunk 2258 ---\n",
            "stand why it makes them and what could fix the problem (adding extra features or\n",
            "getting rid of uninformative ones, cleaning up outliers, etc.).\n",
            "\n",
            "--- Chunk 2259 ---\n",
            "Evaluate Your System on the Test Set\n",
            "After tweaking your models for a while, you eventually have a system that performs\n",
            "\n",
            "--- Chunk 2260 ---\n",
            "sufficiently well. Now is the time to evaluate the final model on the test set. There is\n",
            "\n",
            "--- Chunk 2261 ---\n",
            "nothing special about this process; just get the predictors and the labels from your\n",
            "\n",
            "--- Chunk 2262 ---\n",
            "test set, run your full_pipeline to transform the data (call transform(), not\n",
            "\n",
            "--- Chunk 2263 ---\n",
            "fit_transform()—you do not want to fit the test set!), and evaluate the final model\n",
            "on the test set:\n",
            "\n",
            "--- Chunk 2264 ---\n",
            "final_model = grid_search.best_estimator_\n",
            "\n",
            "--- Chunk 2265 ---\n",
            "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
            "y_test = strat_test_set[\"median_house_value\"].copy()\n",
            "\n",
            "--- Chunk 2266 ---\n",
            "X_test_prepared = full_pipeline.transform(X_test)\n",
            "\n",
            "Fine-Tune Your Model | 79\n",
            "\n",
            "\n",
            "\n",
            "final_predictions = final_model.predict(X_test_prepared)\n",
            "\n",
            "--- Chunk 2267 ---\n",
            "final_mse = mean_squared_error(y_test, final_predictions)\n",
            "final_rmse = np.sqrt(final_mse)   # => evaluates to 47,730.2\n",
            "\n",
            "--- Chunk 2268 ---\n",
            "In some cases, such a point estimate of the generalization error will not be quite\n",
            "\n",
            "--- Chunk 2269 ---\n",
            "enough to convince you to launch: what if it is just 0.1% better than the model cur‐\n",
            "\n",
            "--- Chunk 2270 ---\n",
            "rently in production? You might want to have an idea of how precise this estimate is.\n",
            "\n",
            "--- Chunk 2271 ---\n",
            "For this, you can compute a 95% confidence interval for the generalization error using\n",
            "scipy.stats.t.interval():\n",
            "\n",
            "--- Chunk 2272 ---\n",
            ">>> from scipy import stats\n",
            ">>> confidence = 0.95\n",
            ">>> squared_errors = (final_predictions - y_test) ** 2\n",
            "\n",
            "--- Chunk 2273 ---\n",
            ">>> np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
            "...                          loc=squared_errors.mean(),\n",
            "\n",
            "--- Chunk 2274 ---\n",
            "...                          scale=stats.sem(squared_errors)))\n",
            "...\n",
            "array([45685.10470776, 49691.25001878])\n",
            "\n",
            "--- Chunk 2275 ---\n",
            "If you did a lot of hyperparameter tuning, the performance will usually be slightly\n",
            "\n",
            "--- Chunk 2276 ---\n",
            "worse than what you measured using cross-validation (because your system ends up\n",
            "\n",
            "--- Chunk 2277 ---\n",
            "fine-tuned to perform well on the validation data and will likely not perform as well\n",
            "\n",
            "--- Chunk 2278 ---\n",
            "on unknown datasets). It is not the case in this example, but when this happens you\n",
            "\n",
            "--- Chunk 2279 ---\n",
            "must resist the temptation to tweak the hyperparameters to make the numbers look\n",
            "\n",
            "--- Chunk 2280 ---\n",
            "good on the test set; the improvements would be unlikely to generalize to new data.\n",
            "\n",
            "--- Chunk 2281 ---\n",
            "Now comes the project prelaunch phase: you need to present your solution (high‐\n",
            "\n",
            "--- Chunk 2282 ---\n",
            "lighting what you have learned, what worked and what did not, what assumptions\n",
            "\n",
            "--- Chunk 2283 ---\n",
            "were made, and what your system’s limitations are), document everything, and create\n",
            "\n",
            "--- Chunk 2284 ---\n",
            "nice presentations with clear visualizations and easy-to-remember statements (e.g.,\n",
            "\n",
            "--- Chunk 2285 ---\n",
            "“the median income is the number one predictor of housing prices”). In this Califor‐\n",
            "\n",
            "--- Chunk 2286 ---\n",
            "nia housing example, the final performance of the system is not better than the\n",
            "\n",
            "--- Chunk 2287 ---\n",
            "experts’ price estimates, which were often off by about 20%, but it may still be a good\n",
            "\n",
            "--- Chunk 2288 ---\n",
            "idea to launch it, especially if this frees up some time for the experts so they can work\n",
            "on more interesting and productive tasks.\n",
            "\n",
            "--- Chunk 2289 ---\n",
            "Launch, Monitor, and Maintain Your System\n",
            "Perfect, you got approval to launch! You now need to get your solution ready for pro‐\n",
            "\n",
            "--- Chunk 2290 ---\n",
            "duction (e.g., polish the code, write documentation and tests, and so on). Then you\n",
            "\n",
            "--- Chunk 2291 ---\n",
            "can deploy your model to your production environment. One way to do this is to save\n",
            "\n",
            "--- Chunk 2292 ---\n",
            "the trained Scikit-Learn model (e.g., using joblib), including the full preprocessing\n",
            "\n",
            "--- Chunk 2293 ---\n",
            "and prediction pipeline, then load this trained model within your production envi‐\n",
            "\n",
            "--- Chunk 2294 ---\n",
            "ronment and use it to make predictions by calling its predict() method. For exam‐\n",
            "\n",
            "--- Chunk 2295 ---\n",
            "ple, perhaps the model will be used within a website: the user will type in some data\n",
            "\n",
            "--- Chunk 2296 ---\n",
            "80 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 2297 ---\n",
            "about a new district and click the Estimate Price button. This will send a query con‐\n",
            "\n",
            "--- Chunk 2298 ---\n",
            "taining the data to the web server, which will forward it to your web application, and\n",
            "\n",
            "--- Chunk 2299 ---\n",
            "finally your code will simply call the model’s predict() method (you want to load the\n",
            "\n",
            "--- Chunk 2300 ---\n",
            "model upon server startup, rather than every time the model is used). Alternatively,\n",
            "\n",
            "--- Chunk 2301 ---\n",
            "you can wrap the model within a dedicated web service that your web application can\n",
            "\n",
            "--- Chunk 2302 ---\n",
            "query through a REST API23 (see Figure 2-17). This makes it easier to upgrade your\n",
            "\n",
            "--- Chunk 2303 ---\n",
            "model to new versions without interrupting the main application. It also simplifies\n",
            "\n",
            "--- Chunk 2304 ---\n",
            "scaling, since you can start as many web services as needed and load-balance the\n",
            "\n",
            "--- Chunk 2305 ---\n",
            "requests coming from your web application across these web services. Moreover, it\n",
            "allows your web application to use any language, not just Python.\n",
            "\n",
            "--- Chunk 2306 ---\n",
            "Figure 2-17. A model deployed as a web service and used by a web application\n",
            "\n",
            "--- Chunk 2307 ---\n",
            "Another popular strategy is to deploy your model on the cloud, for example on Goo‐\n",
            "\n",
            "--- Chunk 2308 ---\n",
            "gle Cloud AI Platform (formerly known as Google Cloud ML Engine): just save your\n",
            "\n",
            "--- Chunk 2309 ---\n",
            "model using joblib and upload it to Google Cloud Storage (GCS), then head over to\n",
            "\n",
            "--- Chunk 2310 ---\n",
            "Google Cloud AI Platform and create a new model version, pointing it to the GCS\n",
            "\n",
            "--- Chunk 2311 ---\n",
            "file. That’s it! This gives you a simple web service that takes care of load balancing and\n",
            "\n",
            "--- Chunk 2312 ---\n",
            "scaling for you. It take JSON requests containing the input data (e.g., of a district) and\n",
            "\n",
            "--- Chunk 2313 ---\n",
            "returns JSON responses containing the predictions. You can then use this web service\n",
            "\n",
            "--- Chunk 2314 ---\n",
            "in your website (or whatever production environment you are using). As we will see\n",
            "\n",
            "--- Chunk 2315 ---\n",
            "in Chapter 19, deploying TensorFlow models on AI Platform is not much different\n",
            "from deploying Scikit-Learn models.\n",
            "\n",
            "--- Chunk 2316 ---\n",
            "But deployment is not the end of the story. You also need to write monitoring code to\n",
            "\n",
            "--- Chunk 2317 ---\n",
            "check your system’s live performance at regular intervals and trigger alerts when it\n",
            "\n",
            "--- Chunk 2318 ---\n",
            "drops. This could be a steep drop, likely due to a broken component in your infra‐\n",
            "\n",
            "--- Chunk 2319 ---\n",
            "structure, but be aware that it could also be a gentle decay that could easily go unno‐\n",
            "\n",
            "--- Chunk 2320 ---\n",
            "ticed for a long time. This is quite common because models tend to “rot” over time:\n",
            "\n",
            "--- Chunk 2321 ---\n",
            "indeed, the world changes, so if the model was trained with last year’s data, it may not\n",
            "be adapted to today’s data.\n",
            "\n",
            "--- Chunk 2322 ---\n",
            "23 In a nutshell, a REST (or RESTful) API is an HTTP-based API that follows some conventions, such as using\n",
            "\n",
            "--- Chunk 2323 ---\n",
            "standard HTTP verbs to read, update, create, or delete resources (GET, POST, PUT, and DELETE) and using\n",
            "JSON for the inputs and outputs.\n",
            "\n",
            "--- Chunk 2324 ---\n",
            "Launch, Monitor, and Maintain Your System | 81\n",
            "\n",
            "--- Chunk 2325 ---\n",
            "Even a model trained to classify pictures of cats and dogs may need\n",
            "to be retrained regularly, not because cats and dogs will mutate\n",
            "\n",
            "--- Chunk 2326 ---\n",
            "overnight, but because cameras keep changing, along with image\n",
            "formats, sharpness, brightness, and size ratios. Moreover, people\n",
            "\n",
            "--- Chunk 2327 ---\n",
            "may love different breeds next year, or they may decide to dress\n",
            "their pets with tiny hats—who knows?\n",
            "\n",
            "--- Chunk 2328 ---\n",
            "So you need to monitor your model’s live performance. But how do you that? Well, it\n",
            "\n",
            "--- Chunk 2329 ---\n",
            "depends. In some cases, the model’s performance can be inferred from downstream\n",
            "\n",
            "--- Chunk 2330 ---\n",
            "metrics. For example, if your model is part of a recommender system and it suggests\n",
            "\n",
            "--- Chunk 2331 ---\n",
            "products that the users may be interested in, then it’s easy to monitor the number of\n",
            "\n",
            "--- Chunk 2332 ---\n",
            "recommended products sold each day. If this number drops (compared to non-\n",
            "\n",
            "--- Chunk 2333 ---\n",
            "recommended products), then the prime suspect is the model. This may be because\n",
            "\n",
            "--- Chunk 2334 ---\n",
            "the data pipeline is broken, or perhaps the model needs to be retrained on fresh data\n",
            "(as we will discuss shortly).\n",
            "\n",
            "--- Chunk 2335 ---\n",
            "However, it’s not always possible to determine the model’s performance without any\n",
            "\n",
            "--- Chunk 2336 ---\n",
            "human analysis. For example, suppose you trained an image classification model (see\n",
            "\n",
            "--- Chunk 2337 ---\n",
            "Chapter 3) to detect several product defects on a production line. How can you get an\n",
            "\n",
            "--- Chunk 2338 ---\n",
            "alert if the model’s performance drops, before thousands of defective products get\n",
            "\n",
            "--- Chunk 2339 ---\n",
            "shipped to your clients? One solution is to send to human raters a sample of all the\n",
            "\n",
            "--- Chunk 2340 ---\n",
            "pictures that the model classified (especially pictures that the model wasn’t so sure\n",
            "\n",
            "--- Chunk 2341 ---\n",
            "about). Depending on the task, the raters may need to be experts, or they could be\n",
            "\n",
            "--- Chunk 2342 ---\n",
            "nonspecialists, such as workers on a crowdsourcing platform (e.g., Amazon Mechani‐\n",
            "\n",
            "--- Chunk 2343 ---\n",
            "cal Turk). In some applications they could even be the users themselves, responding\n",
            "for example via surveys or repurposed captchas.24\n",
            "\n",
            "--- Chunk 2344 ---\n",
            "Either way, you need to put in place a monitoring system (with or without human\n",
            "\n",
            "--- Chunk 2345 ---\n",
            "raters to evaluate the live model), as well as all the relevant processes to define what to\n",
            "\n",
            "--- Chunk 2346 ---\n",
            "do in case of failures and how to prepare for them. Unfortunately, this can be a lot of\n",
            "\n",
            "--- Chunk 2347 ---\n",
            "work. In fact, it is often much more work than building and training a model.\n",
            "\n",
            "--- Chunk 2348 ---\n",
            "If the data keeps evolving, you will need to update your datasets and retrain your\n",
            "\n",
            "--- Chunk 2349 ---\n",
            "model regularly. You should probably automate the whole process as much as possi‐\n",
            "ble. Here are a few things you can automate:\n",
            "\n",
            "--- Chunk 2350 ---\n",
            "• Collect fresh data regularly and label it (e.g., using human raters).\n",
            "\n",
            "--- Chunk 2351 ---\n",
            "• Write a script to train the model and fine-tune the hyperparameters automati‐\n",
            "\n",
            "--- Chunk 2352 ---\n",
            "cally. This script could run automatically, for example every day or every week,\n",
            "depending on your needs.\n",
            "\n",
            "--- Chunk 2353 ---\n",
            "24 A captcha is a test to ensure a user is not a robot. These tests have often been used as a cheap way to label\n",
            "training data.\n",
            "\n",
            "--- Chunk 2354 ---\n",
            "82 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "--- Chunk 2355 ---\n",
            "• Write another script that will evaluate both the new model and the previous\n",
            "\n",
            "--- Chunk 2356 ---\n",
            "model on the updated test set, and deploy the model to production if the perfor‐\n",
            "mance has not decreased (if it did, make sure you investigate why).\n",
            "\n",
            "--- Chunk 2357 ---\n",
            "You should also make sure you evaluate the model’s input data quality. Sometimes\n",
            "\n",
            "--- Chunk 2358 ---\n",
            "performance will degrade slightly because of a poor-quality signal (e.g., a malfunc‐\n",
            "\n",
            "--- Chunk 2359 ---\n",
            "tioning sensor sending random values, or another team’s output becoming stale), but\n",
            "\n",
            "--- Chunk 2360 ---\n",
            "it may take a while before your system’s performance degrades enough to trigger an\n",
            "\n",
            "--- Chunk 2361 ---\n",
            "alert. If you monitor your model’s inputs, you may catch this earlier. For example, you\n",
            "\n",
            "--- Chunk 2362 ---\n",
            "could trigger an alert if more and more inputs are missing a feature, or if its mean or\n",
            "\n",
            "--- Chunk 2363 ---\n",
            "standard deviation drifts too far from the training set, or a categorical feature starts\n",
            "containing new categories.\n",
            "\n",
            "--- Chunk 2364 ---\n",
            "Finally, make sure you keep backups of every model you create and have the process\n",
            "\n",
            "--- Chunk 2365 ---\n",
            "and tools in place to roll back to a previous model quickly, in case the new model\n",
            "\n",
            "--- Chunk 2366 ---\n",
            "starts failing badly for some reason. Having backups also makes it possible to easily\n",
            "\n",
            "--- Chunk 2367 ---\n",
            "compare new models with previous ones. Similarly, you should keep backups of every\n",
            "\n",
            "--- Chunk 2368 ---\n",
            "version of your datasets so that you can roll back to a previous dataset if the new one\n",
            "\n",
            "--- Chunk 2369 ---\n",
            "ever gets corrupted (e.g., if the fresh data that gets added to it turns out to be full of\n",
            "\n",
            "--- Chunk 2370 ---\n",
            "outliers). Having backups of your datasets also allows you to evaluate any model\n",
            "against any previous dataset.\n",
            "\n",
            "--- Chunk 2371 ---\n",
            "You may want to create several subsets of the test set in order to\n",
            "evaluate how well your model performs on specific parts of the\n",
            "\n",
            "--- Chunk 2372 ---\n",
            "data. For example, you may want to have a subset containing only\n",
            "the most recent data, or a test set for specific kinds of inputs (e.g.,\n",
            "\n",
            "--- Chunk 2373 ---\n",
            "districts located inland versus districts located near the ocean).\n",
            "This will give you a deeper understanding of your model’s\n",
            "\n",
            "--- Chunk 2374 ---\n",
            "strengths and weaknesses.\n",
            "\n",
            "--- Chunk 2375 ---\n",
            "As you can see, Machine Learning involves quite a lot of infrastructure, so don’t be\n",
            "\n",
            "--- Chunk 2376 ---\n",
            "surprised if your first ML project takes a lot of effort and time to build and deploy to\n",
            "\n",
            "--- Chunk 2377 ---\n",
            "production. Fortunately, once all the infrastructure is in place, going from idea to\n",
            "production will be much faster.\n",
            "\n",
            "--- Chunk 2378 ---\n",
            "Try It Out!\n",
            "Hopefully this chapter gave you a good idea of what a Machine Learning project\n",
            "\n",
            "--- Chunk 2379 ---\n",
            "looks like as well as showing you some of the tools you can use to train a great system.\n",
            "\n",
            "--- Chunk 2380 ---\n",
            "As you can see, much of the work is in the data preparation step: building monitoring\n",
            "\n",
            "--- Chunk 2381 ---\n",
            "tools, setting up human evaluation pipelines, and automating regular model training.\n",
            "\n",
            "--- Chunk 2382 ---\n",
            "The Machine Learning algorithms are important, of course, but it is probably prefera‐\n",
            "\n",
            "--- Chunk 2383 ---\n",
            "Try It Out! | 83\n",
            "\n",
            "--- Chunk 2384 ---\n",
            "ble to be comfortable with the overall process and know three or four algorithms well\n",
            "\n",
            "--- Chunk 2385 ---\n",
            "rather than to spend all your time exploring advanced algorithms.\n",
            "\n",
            "--- Chunk 2386 ---\n",
            "So, if you have not already done so, now is a good time to pick up a laptop, select a\n",
            "\n",
            "--- Chunk 2387 ---\n",
            "dataset that you are interested in, and try to go through the whole process from A to\n",
            "\n",
            "--- Chunk 2388 ---\n",
            "Z. A good place to start is on a competition website such as http://kaggle.com/: you\n",
            "\n",
            "--- Chunk 2389 ---\n",
            "will have a dataset to play with, a clear goal, and people to share the experience with.\n",
            "Have fun!\n",
            "\n",
            "--- Chunk 2390 ---\n",
            "Exercises\n",
            "The following exercises are all based on this chapter’s housing dataset:\n",
            "\n",
            "--- Chunk 2391 ---\n",
            "1. Try a Support Vector Machine regressor (sklearn.svm.SVR) with various hyper‐\n",
            "\n",
            "--- Chunk 2392 ---\n",
            "parameters, such as kernel=\"linear\" (with various values for the C hyperpara‐\n",
            "meter) or kernel=\"rbf\" (with various values for the C and gamma\n",
            "\n",
            "--- Chunk 2393 ---\n",
            "hyperparameters). Don’t worry about what these hyperparameters mean for now.\n",
            "How does the best SVR predictor perform?\n",
            "\n",
            "--- Chunk 2394 ---\n",
            "2. Try replacing GridSearchCV with RandomizedSearchCV.\n",
            "3. Try adding a transformer in the preparation pipeline to select only the most\n",
            "\n",
            "--- Chunk 2395 ---\n",
            "important attributes.\n",
            "4. Try creating a single pipeline that does the full data preparation plus the final\n",
            "\n",
            "--- Chunk 2396 ---\n",
            "prediction.\n",
            "5. Automatically explore some preparation options using GridSearchCV.\n",
            "\n",
            "--- Chunk 2397 ---\n",
            "Solutions to these exercises can be found in the Jupyter notebooks available at https://\n",
            "github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 2398 ---\n",
            "84 | Chapter 2: End-to-End Machine Learning Project\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER 3\n",
            "Classification\n",
            "\n",
            "--- Chunk 2399 ---\n",
            "In Chapter 1 I mentioned that the most common supervised learning tasks are\n",
            "\n",
            "--- Chunk 2400 ---\n",
            "regression (predicting values) and classification (predicting classes). In Chapter 2 we\n",
            "\n",
            "--- Chunk 2401 ---\n",
            "explored a regression task, predicting housing values, using various algorithms such\n",
            "\n",
            "--- Chunk 2402 ---\n",
            "as Linear Regression, Decision Trees, and Random Forests (which will be explained\n",
            "\n",
            "--- Chunk 2403 ---\n",
            "in further detail in later chapters). Now we will turn our attention to classification\n",
            "systems.\n",
            "\n",
            "--- Chunk 2404 ---\n",
            "MNIST\n",
            "In this chapter we will be using the MNIST dataset, which is a set of 70,000 small\n",
            "\n",
            "--- Chunk 2405 ---\n",
            "images of digits handwritten by high school students and employees of the US Cen‐\n",
            "\n",
            "--- Chunk 2406 ---\n",
            "sus Bureau. Each image is labeled with the digit it represents. This set has been stud‐\n",
            "\n",
            "--- Chunk 2407 ---\n",
            "ied so much that it is often called the “hello world” of Machine Learning: whenever\n",
            "\n",
            "--- Chunk 2408 ---\n",
            "people come up with a new classification algorithm they are curious to see how it will\n",
            "\n",
            "--- Chunk 2409 ---\n",
            "perform on MNIST, and anyone who learns Machine Learning tackles this dataset\n",
            "sooner or later.\n",
            "\n",
            "--- Chunk 2410 ---\n",
            "sooner or later.\n",
            "Scikit-Learn provides many helper functions to download popular datasets. MNIST is\n",
            "\n",
            "--- Chunk 2411 ---\n",
            "one of them. The following code fetches the MNIST dataset:1\n",
            "\n",
            "--- Chunk 2412 ---\n",
            ">>> from sklearn.datasets import fetch_openml\n",
            ">>> mnist = fetch_openml('mnist_784', version=1)\n",
            ">>> mnist.keys()\n",
            "\n",
            "--- Chunk 2413 ---\n",
            ">>> mnist.keys()\n",
            "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'details',\n",
            "           'categories', 'url'])\n",
            "\n",
            "--- Chunk 2414 ---\n",
            "1 By default Scikit-Learn caches downloaded datasets in a directory called $HOME/scikit_learn_data.\n",
            "\n",
            "85\n",
            "\n",
            "--- Chunk 2415 ---\n",
            "85\n",
            "\n",
            "\n",
            "\n",
            "Datasets loaded by Scikit-Learn generally have a similar dictionary structure, includ‐\n",
            "ing the following:\n",
            "\n",
            "--- Chunk 2416 ---\n",
            "• A DESCR key describing the dataset\n",
            "• A data key containing an array with one row per instance and one column per\n",
            "\n",
            "--- Chunk 2417 ---\n",
            "feature\n",
            "• A target key containing an array with the labels\n",
            "\n",
            "--- Chunk 2418 ---\n",
            "Let’s look at these arrays:\n",
            ">>> X, y = mnist[\"data\"], mnist[\"target\"]\n",
            ">>> X.shape\n",
            "(70000, 784)\n",
            ">>> y.shape\n",
            "(70000,)\n",
            "\n",
            "--- Chunk 2419 ---\n",
            "There are 70,000 images, and each image has 784 features. This is because each image\n",
            "\n",
            "--- Chunk 2420 ---\n",
            "is 28 × 28 pixels, and each feature simply represents one pixel’s intensity, from 0\n",
            "\n",
            "--- Chunk 2421 ---\n",
            "(white) to 255 (black). Let’s take a peek at one digit from the dataset. All you need to\n",
            "\n",
            "--- Chunk 2422 ---\n",
            "do is grab an instance’s feature vector, reshape it to a 28 × 28 array, and display it\n",
            "using Matplotlib’s imshow() function:\n",
            "\n",
            "--- Chunk 2423 ---\n",
            "import matplotlib as mpl\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "some_digit = X[0]\n",
            "some_digit_image = some_digit.reshape(28, 28)\n",
            "\n",
            "--- Chunk 2424 ---\n",
            "plt.imshow(some_digit_image, cmap=\"binary\")\n",
            "plt.axis(\"off\")\n",
            "plt.show()\n",
            "\n",
            "This looks like a 5, and indeed that’s what the label tells us:\n",
            ">>> y[0]\n",
            "'5'\n",
            "\n",
            "--- Chunk 2425 ---\n",
            "Note that the label is a string. Most ML algorithms expect numbers, so let’s cast y to\n",
            "integer:\n",
            "\n",
            ">>> y = y.astype(np.uint8)\n",
            "\n",
            "--- Chunk 2426 ---\n",
            "86 | Chapter 3: Classification\n",
            "\n",
            "--- Chunk 2427 ---\n",
            "To give you a feel for the complexity of the classification task, Figure 3-1 shows a few\n",
            "more images from the MNIST dataset.\n",
            "\n",
            "--- Chunk 2428 ---\n",
            "Figure 3-1. Digits from the MNIST dataset\n",
            "\n",
            "--- Chunk 2429 ---\n",
            "But wait! You should always create a test set and set it aside before inspecting the data\n",
            "\n",
            "--- Chunk 2430 ---\n",
            "closely. The MNIST dataset is actually already split into a training set (the first 60,000\n",
            "images) and a test set (the last 10,000 images):\n",
            "\n",
            "--- Chunk 2431 ---\n",
            "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
            "\n",
            "--- Chunk 2432 ---\n",
            "The training set is already shuffled for us, which is good because this guarantees that\n",
            "\n",
            "--- Chunk 2433 ---\n",
            "all cross-validation folds will be similar (you don’t want one fold to be missing some\n",
            "\n",
            "--- Chunk 2434 ---\n",
            "digits). Moreover, some learning algorithms are sensitive to the order of the training\n",
            "\n",
            "--- Chunk 2435 ---\n",
            "instances, and they perform poorly if they get many similar instances in a row. Shuf‐\n",
            "fling the dataset ensures that this won’t happen.2\n",
            "\n",
            "--- Chunk 2436 ---\n",
            "2 Shuffling may be a bad idea in some contexts—for example, if you are working on time series data (such as\n",
            "\n",
            "--- Chunk 2437 ---\n",
            "stock market prices or weather conditions). We will explore this in the next chapters.\n",
            "\n",
            "--- Chunk 2438 ---\n",
            "MNIST | 87\n",
            "\n",
            "--- Chunk 2439 ---\n",
            "Training a Binary Classifier\n",
            "Let’s simplify the problem for now and only try to identify one digit—for example,\n",
            "\n",
            "--- Chunk 2440 ---\n",
            "the number 5. This “5-detector” will be an example of a binary classifier, capable of\n",
            "\n",
            "--- Chunk 2441 ---\n",
            "distinguishing between just two classes, 5 and not-5. Let’s create the target vectors for\n",
            "this classification task:\n",
            "\n",
            "--- Chunk 2442 ---\n",
            "y_train_5 = (y_train == 5)  # True for all 5s, False for all other digits\n",
            "y_test_5 = (y_test == 5)\n",
            "\n",
            "--- Chunk 2443 ---\n",
            "Now let’s pick a classifier and train it. A good place to start is with a Stochastic Gradi‐\n",
            "\n",
            "--- Chunk 2444 ---\n",
            "ent Descent (SGD) classifier, using Scikit-Learn’s SGDClassifier class. This classifier\n",
            "\n",
            "--- Chunk 2445 ---\n",
            "has the advantage of being capable of handling very large datasets efficiently. This is\n",
            "\n",
            "--- Chunk 2446 ---\n",
            "in part because SGD deals with training instances independently, one at a time\n",
            "\n",
            "--- Chunk 2447 ---\n",
            "(which also makes SGD well suited for online learning), as we will see later. Let’s cre‐\n",
            "ate an SGDClassifier and train it on the whole training set:\n",
            "\n",
            "--- Chunk 2448 ---\n",
            "from sklearn.linear_model import SGDClassifier\n",
            "\n",
            "sgd_clf = SGDClassifier(random_state=42)\n",
            "sgd_clf.fit(X_train, y_train_5)\n",
            "\n",
            "--- Chunk 2449 ---\n",
            "The SGDClassifier relies on randomness during training (hence\n",
            "the name “stochastic”). If you want reproducible results, you\n",
            "\n",
            "--- Chunk 2450 ---\n",
            "should set the random_state parameter.\n",
            "\n",
            "--- Chunk 2451 ---\n",
            "Now we can use it to detect images of the number 5:\n",
            ">>> sgd_clf.predict([some_digit])\n",
            "array([ True])\n",
            "\n",
            "--- Chunk 2452 ---\n",
            "The classifier guesses that this image represents a 5 (True). Looks like it guessed right\n",
            "\n",
            "--- Chunk 2453 ---\n",
            "in this particular case! Now, let’s evaluate this model’s performance.\n",
            "\n",
            "--- Chunk 2454 ---\n",
            "Performance Measures\n",
            "Evaluating a classifier is often significantly trickier than evaluating a regressor, so we\n",
            "\n",
            "--- Chunk 2455 ---\n",
            "will spend a large part of this chapter on this topic. There are many performance\n",
            "\n",
            "--- Chunk 2456 ---\n",
            "measures available, so grab another coffee and get ready to learn many new concepts\n",
            "and acronyms!\n",
            "\n",
            "--- Chunk 2457 ---\n",
            "88 | Chapter 3: Classification\n",
            "\n",
            "--- Chunk 2458 ---\n",
            "Measuring Accuracy Using Cross-Validation\n",
            "A good way to evaluate a model is to use cross-validation, just as you did in Chap‐\n",
            "ter 2.\n",
            "\n",
            "--- Chunk 2459 ---\n",
            "Implementing Cross-Validation\n",
            "Occasionally you will need more control over the cross-validation process than what\n",
            "\n",
            "--- Chunk 2460 ---\n",
            "Scikit-Learn provides off the shelf. In these cases, you can implement cross-validation\n",
            "\n",
            "--- Chunk 2461 ---\n",
            "yourself. The following code does roughly the same thing as Scikit-Learn’s\n",
            "cross_val_score() function, and it prints the same result:\n",
            "\n",
            "--- Chunk 2462 ---\n",
            "from sklearn.model_selection import StratifiedKFold\n",
            "from sklearn.base import clone\n",
            "\n",
            "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
            "\n",
            "--- Chunk 2463 ---\n",
            "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
            "    clone_clf = clone(sgd_clf)\n",
            "    X_train_folds = X_train[train_index]\n",
            "\n",
            "--- Chunk 2464 ---\n",
            "y_train_folds = y_train_5[train_index]\n",
            "    X_test_fold = X_train[test_index]\n",
            "    y_test_fold = y_train_5[test_index]\n",
            "\n",
            "--- Chunk 2465 ---\n",
            "clone_clf.fit(X_train_folds, y_train_folds)\n",
            "    y_pred = clone_clf.predict(X_test_fold)\n",
            "    n_correct = sum(y_pred == y_test_fold)\n",
            "\n",
            "--- Chunk 2466 ---\n",
            "print(n_correct / len(y_pred))  # prints 0.9502, 0.96565, and 0.96495\n",
            "\n",
            "--- Chunk 2467 ---\n",
            "The StratifiedKFold class performs stratified sampling (as explained in Chapter 2)\n",
            "\n",
            "--- Chunk 2468 ---\n",
            "to produce folds that contain a representative ratio of each class. At each iteration the\n",
            "\n",
            "--- Chunk 2469 ---\n",
            "code creates a clone of the classifier, trains that clone on the training folds, and makes\n",
            "\n",
            "--- Chunk 2470 ---\n",
            "predictions on the test fold. Then it counts the number of correct predictions and\n",
            "outputs the ratio of correct predictions.\n",
            "\n",
            "--- Chunk 2471 ---\n",
            "Let’s use the cross_val_score() function to evaluate our SGDClassifier model,\n",
            "\n",
            "--- Chunk 2472 ---\n",
            "using K-fold cross-validation with three folds. Remember that K-fold cross-validation\n",
            "\n",
            "--- Chunk 2473 ---\n",
            "means splitting the training set into K folds (in this case, three), then making predic‐\n",
            "\n",
            "--- Chunk 2474 ---\n",
            "tions and evaluating them on each fold using a model trained on the remaining folds\n",
            "(see Chapter 2):\n",
            "\n",
            "--- Chunk 2475 ---\n",
            ">>> from sklearn.model_selection import cross_val_score\n",
            ">>> cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
            "\n",
            "--- Chunk 2476 ---\n",
            "array([0.96355, 0.93795, 0.95615])\n",
            "\n",
            "--- Chunk 2477 ---\n",
            "Wow! Above 93% accuracy (ratio of correct predictions) on all cross-validation folds?\n",
            "\n",
            "--- Chunk 2478 ---\n",
            "This looks amazing, doesn’t it? Well, before you get too excited, let’s look at a very\n",
            "\n",
            "--- Chunk 2479 ---\n",
            "dumb classifier that just classifies every single image in the “not-5” class:\n",
            "\n",
            "--- Chunk 2480 ---\n",
            "Performance Measures | 89\n",
            "\n",
            "\n",
            "\n",
            "from sklearn.base import BaseEstimator\n",
            "\n",
            "--- Chunk 2481 ---\n",
            "class Never5Classifier(BaseEstimator):\n",
            "    def fit(self, X, y=None):\n",
            "        return self\n",
            "    def predict(self, X):\n",
            "\n",
            "--- Chunk 2482 ---\n",
            "return np.zeros((len(X), 1), dtype=bool)\n",
            "\n",
            "--- Chunk 2483 ---\n",
            "Can you guess this model’s accuracy? Let’s find out:\n",
            ">>> never_5_clf = Never5Classifier()\n",
            "\n",
            "--- Chunk 2484 ---\n",
            ">>> cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
            "array([0.91125, 0.90855, 0.90915])\n",
            "\n",
            "--- Chunk 2485 ---\n",
            "That’s right, it has over 90% accuracy! This is simply because only about 10% of the\n",
            "\n",
            "--- Chunk 2486 ---\n",
            "images are 5s, so if you always guess that an image is not a 5, you will be right about\n",
            "90% of the time. Beats Nostradamus.\n",
            "\n",
            "--- Chunk 2487 ---\n",
            "This demonstrates why accuracy is generally not the preferred performance measure\n",
            "\n",
            "--- Chunk 2488 ---\n",
            "for classifiers, especially when you are dealing with skewed datasets (i.e., when some\n",
            "classes are much more frequent than others).\n",
            "\n",
            "--- Chunk 2489 ---\n",
            "Confusion Matrix\n",
            "A much better way to evaluate the performance of a classifier is to look at the confu‐\n",
            "\n",
            "--- Chunk 2490 ---\n",
            "sion matrix. The general idea is to count the number of times instances of class A are\n",
            "\n",
            "--- Chunk 2491 ---\n",
            "classified as class B. For example, to know the number of times the classifier confused\n",
            "\n",
            "--- Chunk 2492 ---\n",
            "images of 5s with 3s, you would look in the fifth row and third column of the confu‐\n",
            "sion matrix.\n",
            "\n",
            "--- Chunk 2493 ---\n",
            "sion matrix.\n",
            "To compute the confusion matrix, you first need to have a set of predictions so that\n",
            "\n",
            "--- Chunk 2494 ---\n",
            "they can be compared to the actual targets. You could make predictions on the test\n",
            "\n",
            "--- Chunk 2495 ---\n",
            "set, but let’s keep it untouched for now (remember that you want to use the test set\n",
            "\n",
            "--- Chunk 2496 ---\n",
            "only at the very end of your project, once you have a classifier that you are ready to\n",
            "\n",
            "--- Chunk 2497 ---\n",
            "launch). Instead, you can use the cross_val_predict() function:\n",
            "\n",
            "--- Chunk 2498 ---\n",
            "from sklearn.model_selection import cross_val_predict\n",
            "\n",
            "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
            "\n",
            "--- Chunk 2499 ---\n",
            "Just like the cross_val_score() function, cross_val_predict() performs K-fold\n",
            "\n",
            "--- Chunk 2500 ---\n",
            "cross-validation, but instead of returning the evaluation scores, it returns the predic‐\n",
            "\n",
            "--- Chunk 2501 ---\n",
            "tions made on each test fold. This means that you get a clean prediction for each\n",
            "\n",
            "--- Chunk 2502 ---\n",
            "instance in the training set (“clean” meaning that the prediction is made by a model\n",
            "that never saw the data during training).\n",
            "\n",
            "--- Chunk 2503 ---\n",
            "Now you are ready to get the confusion matrix using the confusion_matrix() func‐\n",
            "\n",
            "--- Chunk 2504 ---\n",
            "tion. Just pass it the target classes (y_train_5) and the predicted classes\n",
            "(y_train_pred):\n",
            "\n",
            "--- Chunk 2505 ---\n",
            "90 | Chapter 3: Classification\n",
            "\n",
            "--- Chunk 2506 ---\n",
            ">>> from sklearn.metrics import confusion_matrix\n",
            ">>> confusion_matrix(y_train_5, y_train_pred)\n",
            "array([[53057,  1522],\n",
            "       [ 1325,  4096]])\n",
            "\n",
            "--- Chunk 2507 ---\n",
            "Each row in a confusion matrix represents an actual class, while each column repre‐\n",
            "\n",
            "--- Chunk 2508 ---\n",
            "sents a predicted class. The first row of this matrix considers non-5 images (the nega‐\n",
            "\n",
            "--- Chunk 2509 ---\n",
            "tive class): 53,057 of them were correctly classified as non-5s (they are called true\n",
            "\n",
            "--- Chunk 2510 ---\n",
            "negatives), while the remaining 1,522 were wrongly classified as 5s (false positives).\n",
            "\n",
            "--- Chunk 2511 ---\n",
            "The second row considers the images of 5s (the positive class): 1,325 were wrongly\n",
            "\n",
            "--- Chunk 2512 ---\n",
            "classified as non-5s (false negatives), while the remaining 4,096 were correctly classi‐\n",
            "\n",
            "--- Chunk 2513 ---\n",
            "fied as 5s (true positives). A perfect classifier would have only true positives and true\n",
            "\n",
            "--- Chunk 2514 ---\n",
            "negatives, so its confusion matrix would have nonzero values only on its main diago‐\n",
            "nal (top left to bottom right):\n",
            "\n",
            "--- Chunk 2515 ---\n",
            ">>> y_train_perfect_predictions = y_train_5  # pretend we reached perfection\n",
            ">>> confusion_matrix(y_train_5, y_train_perfect_predictions)\n",
            "\n",
            "--- Chunk 2516 ---\n",
            "array([[54579,     0],\n",
            "       [    0,  5421]])\n",
            "\n",
            "--- Chunk 2517 ---\n",
            "The confusion matrix gives you a lot of information, but sometimes you may prefer a\n",
            "\n",
            "--- Chunk 2518 ---\n",
            "more concise metric. An interesting one to look at is the accuracy of the positive pre‐\n",
            "\n",
            "--- Chunk 2519 ---\n",
            "dictions; this is called the precision of the classifier (Equation 3-1).\n",
            "\n",
            "--- Chunk 2520 ---\n",
            "Equation 3-1. Precision\n",
            "\n",
            "precision = TP\n",
            "TP + FP\n",
            "\n",
            "--- Chunk 2521 ---\n",
            "TP is the number of true positives, and FP is the number of false positives.\n",
            "\n",
            "--- Chunk 2522 ---\n",
            "A trivial way to have perfect precision is to make one single positive prediction and\n",
            "\n",
            "--- Chunk 2523 ---\n",
            "ensure it is correct (precision = 1/1 = 100%). But this would not be very useful, since\n",
            "\n",
            "--- Chunk 2524 ---\n",
            "the classifier would ignore all but one positive instance. So precision is typically used\n",
            "\n",
            "--- Chunk 2525 ---\n",
            "along with another metric named recall, also called sensitivity or the true positive rate\n",
            "\n",
            "--- Chunk 2526 ---\n",
            "(TPR): this is the ratio of positive instances that are correctly detected by the classifier\n",
            "(Equation 3-2).\n",
            "\n",
            "--- Chunk 2527 ---\n",
            "Equation 3-2. Recall\n",
            "\n",
            "recall = TP\n",
            "TP + FN\n",
            "\n",
            "--- Chunk 2528 ---\n",
            "FN is, of course, the number of false negatives.\n",
            "If you are confused about the confusion matrix, Figure 3-2 may help.\n",
            "\n",
            "Performance Measures | 91\n",
            "\n",
            "--- Chunk 2529 ---\n",
            "Figure 3-2. An illustrated confusion matrix shows examples of true negatives (top left),\n",
            "\n",
            "--- Chunk 2530 ---\n",
            "false positives (top right), false negatives (lower left), and true positives (lower right)\n",
            "\n",
            "--- Chunk 2531 ---\n",
            "Precision and Recall\n",
            "Scikit-Learn provides several functions to compute classifier metrics, including preci‐\n",
            "sion and recall:\n",
            "\n",
            "--- Chunk 2532 ---\n",
            ">>> from sklearn.metrics import precision_score, recall_score\n",
            ">>> precision_score(y_train_5, y_train_pred) # == 4096 / (4096 + 1522)\n",
            "\n",
            "--- Chunk 2533 ---\n",
            "0.7290850836596654\n",
            ">>> recall_score(y_train_5, y_train_pred) # == 4096 / (4096 + 1325)\n",
            "0.7555801512636044\n",
            "\n",
            "--- Chunk 2534 ---\n",
            "Now your 5-detector does not look as shiny as it did when you looked at its accuracy.\n",
            "\n",
            "--- Chunk 2535 ---\n",
            "When it claims an image represents a 5, it is correct only 72.9% of the time. More‐\n",
            "over, it only detects 75.6% of the 5s.\n",
            "\n",
            "--- Chunk 2536 ---\n",
            "It is often convenient to combine precision and recall into a single metric called the F1\n",
            "\n",
            "--- Chunk 2537 ---\n",
            "score, in particular if you need a simple way to compare two classifiers. The F1 score is\n",
            "\n",
            "--- Chunk 2538 ---\n",
            "the harmonic mean of precision and recall (Equation 3-3). Whereas the regular mean\n",
            "\n",
            "--- Chunk 2539 ---\n",
            "treats all values equally, the harmonic mean gives much more weight to low values.\n",
            "\n",
            "--- Chunk 2540 ---\n",
            "As a result, the classifier will only get a high F1 score if both recall and precision are\n",
            "high.\n",
            "\n",
            "--- Chunk 2541 ---\n",
            "Equation 3-3. F1\n",
            "\n",
            "F 2 l TP\n",
            "1 = 1 1 = 2 × precision × recal\n",
            "\n",
            "precision + recall = FN + FP\n",
            "precision + recall TP + 2\n",
            "\n",
            "92 | Chapter 3: Classification\n",
            "\n",
            "--- Chunk 2542 ---\n",
            "To compute the F1 score, simply call the f1_score() function:\n",
            ">>> from sklearn.metrics import f1_score\n",
            ">>> f1_score(y_train_5, y_train_pred)\n",
            "\n",
            "--- Chunk 2543 ---\n",
            "0.7420962043663375\n",
            "\n",
            "--- Chunk 2544 ---\n",
            "The F1 score favors classifiers that have similar precision and recall. This is not always\n",
            "\n",
            "--- Chunk 2545 ---\n",
            "what you want: in some contexts you mostly care about precision, and in other con‐\n",
            "\n",
            "--- Chunk 2546 ---\n",
            "texts you really care about recall. For example, if you trained a classifier to detect vid‐\n",
            "\n",
            "--- Chunk 2547 ---\n",
            "eos that are safe for kids, you would probably prefer a classifier that rejects many\n",
            "\n",
            "--- Chunk 2548 ---\n",
            "good videos (low recall) but keeps only safe ones (high precision), rather than a clas‐\n",
            "\n",
            "--- Chunk 2549 ---\n",
            "sifier that has a much higher recall but lets a few really bad videos show up in your\n",
            "\n",
            "--- Chunk 2550 ---\n",
            "product (in such cases, you may even want to add a human pipeline to check the clas‐\n",
            "\n",
            "--- Chunk 2551 ---\n",
            "sifier’s video selection). On the other hand, suppose you train a classifier to detect\n",
            "\n",
            "--- Chunk 2552 ---\n",
            "shoplifters in surveillance images: it is probably fine if your classifier has only 30%\n",
            "\n",
            "--- Chunk 2553 ---\n",
            "precision as long as it has 99% recall (sure, the security guards will get a few false\n",
            "alerts, but almost all shoplifters will get caught).\n",
            "\n",
            "--- Chunk 2554 ---\n",
            "Unfortunately, you can’t have it both ways: increasing precision reduces recall, and\n",
            "vice versa. This is called the precision/recall trade-off.\n",
            "\n",
            "--- Chunk 2555 ---\n",
            "Precision/Recall Trade-off\n",
            "To understand this trade-off, let’s look at how the SGDClassifier makes its classifica‐\n",
            "\n",
            "--- Chunk 2556 ---\n",
            "tion decisions. For each instance, it computes a score based on a decision function. If\n",
            "\n",
            "--- Chunk 2557 ---\n",
            "that score is greater than a threshold, it assigns the instance to the positive class;\n",
            "\n",
            "--- Chunk 2558 ---\n",
            "otherwise it assigns it to the negative class. Figure 3-3 shows a few digits positioned\n",
            "\n",
            "--- Chunk 2559 ---\n",
            "from the lowest score on the left to the highest score on the right. Suppose the deci‐\n",
            "\n",
            "--- Chunk 2560 ---\n",
            "sion threshold is positioned at the central arrow (between the two 5s): you will find 4\n",
            "\n",
            "--- Chunk 2561 ---\n",
            "true positives (actual 5s) on the right of that threshold, and 1 false positive (actually a\n",
            "\n",
            "--- Chunk 2562 ---\n",
            "6). Therefore, with that threshold, the precision is 80% (4 out of 5). But out of 6\n",
            "\n",
            "--- Chunk 2563 ---\n",
            "actual 5s, the classifier only detects 4, so the recall is 67% (4 out of 6). If you raise the\n",
            "\n",
            "--- Chunk 2564 ---\n",
            "threshold (move it to the arrow on the right), the false positive (the 6) becomes a true\n",
            "\n",
            "--- Chunk 2565 ---\n",
            "negative, thereby increasing the precision (up to 100% in this case), but one true posi‐\n",
            "\n",
            "--- Chunk 2566 ---\n",
            "tive becomes a false negative, decreasing recall down to 50%. Conversely, lowering\n",
            "the threshold increases recall and reduces precision.\n",
            "\n",
            "--- Chunk 2567 ---\n",
            "Performance Measures | 93\n",
            "\n",
            "--- Chunk 2568 ---\n",
            "Figure 3-3. In this precision/recall trade-off, images are ranked by their classifier score,\n",
            "\n",
            "--- Chunk 2569 ---\n",
            "and those above the chosen decision threshold are considered positive; the higher the\n",
            "\n",
            "--- Chunk 2570 ---\n",
            "threshold, the lower the recall, but (in general) the higher the precision\n",
            "\n",
            "--- Chunk 2571 ---\n",
            "Scikit-Learn does not let you set the threshold directly, but it does give you access to\n",
            "\n",
            "--- Chunk 2572 ---\n",
            "the decision scores that it uses to make predictions. Instead of calling the classifier’s\n",
            "\n",
            "--- Chunk 2573 ---\n",
            "predict() method, you can call its decision_function() method, which returns a\n",
            "\n",
            "--- Chunk 2574 ---\n",
            "score for each instance, and then use any threshold you want to make predictions\n",
            "based on those scores:\n",
            "\n",
            "--- Chunk 2575 ---\n",
            ">>> y_scores = sgd_clf.decision_function([some_digit])\n",
            ">>> y_scores\n",
            "array([2412.53175101])\n",
            ">>> threshold = 0\n",
            "\n",
            "--- Chunk 2576 ---\n",
            ">>> threshold = 0\n",
            ">>> y_some_digit_pred = (y_scores > threshold)\n",
            "array([ True])\n",
            "\n",
            "--- Chunk 2577 ---\n",
            "The SGDClassifier uses a threshold equal to 0, so the previous code returns the same\n",
            "\n",
            "--- Chunk 2578 ---\n",
            "result as the predict() method (i.e., True). Let’s raise the threshold:\n",
            "\n",
            "--- Chunk 2579 ---\n",
            ">>> threshold = 8000\n",
            ">>> y_some_digit_pred = (y_scores > threshold)\n",
            ">>> y_some_digit_pred\n",
            "array([False])\n",
            "\n",
            "--- Chunk 2580 ---\n",
            "This confirms that raising the threshold decreases recall. The image actually repre‐\n",
            "\n",
            "--- Chunk 2581 ---\n",
            "sents a 5, and the classifier detects it when the threshold is 0, but it misses it when the\n",
            "threshold is increased to 8,000.\n",
            "\n",
            "--- Chunk 2582 ---\n",
            "How do you decide which threshold to use? First, use the cross_val_predict()\n",
            "\n",
            "--- Chunk 2583 ---\n",
            "function to get the scores of all instances in the training set, but this time specify that\n",
            "\n",
            "--- Chunk 2584 ---\n",
            "you want to return decision scores instead of predictions:\n",
            "\n",
            "--- Chunk 2585 ---\n",
            "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,\n",
            "                             method=\"decision_function\")\n",
            "\n",
            "--- Chunk 2586 ---\n",
            "With these scores, use the precision_recall_curve() function to compute precision\n",
            "and recall for all possible thresholds:\n",
            "\n",
            "--- Chunk 2587 ---\n",
            "94 | Chapter 3: Classification\n",
            "\n",
            "\n",
            "\n",
            "from sklearn.metrics import precision_recall_curve\n",
            "\n",
            "--- Chunk 2588 ---\n",
            "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n",
            "\n",
            "--- Chunk 2589 ---\n",
            "Finally, use Matplotlib to plot precision and recall as functions of the threshold value\n",
            "(Figure 3-4):\n",
            "\n",
            "--- Chunk 2590 ---\n",
            "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
            "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
            "\n",
            "--- Chunk 2591 ---\n",
            "plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
            "    [...] # highlight the threshold and add the legend, axis label, and grid\n",
            "\n",
            "--- Chunk 2592 ---\n",
            "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
            "plt.show()\n",
            "\n",
            "Figure 3-4. Precision and recall versus the decision threshold\n",
            "\n",
            "--- Chunk 2593 ---\n",
            "You may wonder why the precision curve is bumpier than the recall\n",
            "curve in Figure 3-4. The reason is that precision may sometimes go\n",
            "\n",
            "--- Chunk 2594 ---\n",
            "down when you raise the threshold (although in general it will go\n",
            "up). To understand why, look back at Figure 3-3 and notice what\n",
            "\n",
            "--- Chunk 2595 ---\n",
            "happens when you start from the central threshold and move it just\n",
            "one digit to the right: precision goes from 4/5 (80%) down to 3/4\n",
            "\n",
            "--- Chunk 2596 ---\n",
            "(75%). On the other hand, recall can only go down when the thres‐\n",
            "hold is increased, which explains why its curve looks smooth.\n",
            "\n",
            "--- Chunk 2597 ---\n",
            "Another way to select a good precision/recall trade-off is to plot precision directly\n",
            "\n",
            "--- Chunk 2598 ---\n",
            "against recall, as shown in Figure 3-5 (the same threshold as earlier is highlighted).\n",
            "\n",
            "--- Chunk 2599 ---\n",
            "Performance Measures | 95\n",
            "\n",
            "\n",
            "\n",
            "Figure 3-5. Precision versus recall\n",
            "\n",
            "--- Chunk 2600 ---\n",
            "You can see that precision really starts to fall sharply around 80% recall. You will\n",
            "\n",
            "--- Chunk 2601 ---\n",
            "probably want to select a precision/recall trade-off just before that drop—for exam‐\n",
            "\n",
            "--- Chunk 2602 ---\n",
            "ple, at around 60% recall. But of course, the choice depends on your project.\n",
            "\n",
            "--- Chunk 2603 ---\n",
            "Suppose you decide to aim for 90% precision. You look up the first plot and find that\n",
            "\n",
            "--- Chunk 2604 ---\n",
            "you need to use a threshold of about 8,000. To be more precise you can search for the\n",
            "\n",
            "--- Chunk 2605 ---\n",
            "lowest threshold that gives you at least 90% precision (np.argmax() will give you the\n",
            "\n",
            "--- Chunk 2606 ---\n",
            "first index of the maximum value, which in this case means the first True value):\n",
            "\n",
            "--- Chunk 2607 ---\n",
            "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)] # ~7816\n",
            "\n",
            "--- Chunk 2608 ---\n",
            "To make predictions (on the training set for now), instead of calling the classifier’s\n",
            "predict() method, you can run this code:\n",
            "\n",
            "--- Chunk 2609 ---\n",
            "y_train_pred_90 = (y_scores >= threshold_90_precision)\n",
            "\n",
            "--- Chunk 2610 ---\n",
            "Let’s check these predictions’ precision and recall:\n",
            ">>> precision_score(y_train_5, y_train_pred_90)\n",
            "0.9000380083618396\n",
            "\n",
            "--- Chunk 2611 ---\n",
            "0.9000380083618396\n",
            ">>> recall_score(y_train_5, y_train_pred_90)\n",
            "0.4368197749492714\n",
            "\n",
            "--- Chunk 2612 ---\n",
            "Great, you have a 90% precision classifier! As you can see, it is fairly easy to create a\n",
            "\n",
            "--- Chunk 2613 ---\n",
            "classifier with virtually any precision you want: just set a high enough threshold, and\n",
            "\n",
            "--- Chunk 2614 ---\n",
            "you’re done. But wait, not so fast. A high-precision classifier is not very useful if its\n",
            "recall is too low!\n",
            "\n",
            "--- Chunk 2615 ---\n",
            "96 | Chapter 3: Classification\n",
            "\n",
            "\n",
            "\n",
            "If someone says, “Let’s reach 99% precision,” you should ask, “At\n",
            "what recall?”\n",
            "\n",
            "--- Chunk 2616 ---\n",
            "The ROC Curve\n",
            "The receiver operating characteristic (ROC) curve is another common tool used with\n",
            "\n",
            "--- Chunk 2617 ---\n",
            "binary classifiers. It is very similar to the precision/recall curve, but instead of plot‐\n",
            "\n",
            "--- Chunk 2618 ---\n",
            "ting precision versus recall, the ROC curve plots the true positive rate (another name\n",
            "\n",
            "--- Chunk 2619 ---\n",
            "for recall) against the false positive rate (FPR). The FPR is the ratio of negative instan‐\n",
            "\n",
            "--- Chunk 2620 ---\n",
            "ces that are incorrectly classified as positive. It is equal to 1 – the true negative rate\n",
            "\n",
            "--- Chunk 2621 ---\n",
            "(TNR), which is the ratio of negative instances that are correctly classified as negative.\n",
            "\n",
            "--- Chunk 2622 ---\n",
            "The TNR is also called specificity. Hence, the ROC curve plots sensitivity (recall) ver‐\n",
            "sus 1 – specificity.\n",
            "\n",
            "--- Chunk 2623 ---\n",
            "To plot the ROC curve, you first use the roc_curve() function to compute the TPR\n",
            "and FPR for various threshold values:\n",
            "\n",
            "--- Chunk 2624 ---\n",
            "from sklearn.metrics import roc_curve\n",
            "\n",
            "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n",
            "\n",
            "--- Chunk 2625 ---\n",
            "Then you can plot the FPR against the TPR using Matplotlib. This code produces the\n",
            "plot in Figure 3-6:\n",
            "\n",
            "--- Chunk 2626 ---\n",
            "def plot_roc_curve(fpr, tpr, label=None):\n",
            "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
            "    plt.plot([0, 1], [0, 1], 'k--') # Dashed diagonal\n",
            "\n",
            "--- Chunk 2627 ---\n",
            "[...] # Add axis labels and grid\n",
            "\n",
            "--- Chunk 2628 ---\n",
            "plot_roc_curve(fpr, tpr)\n",
            "plt.show()\n",
            "\n",
            "--- Chunk 2629 ---\n",
            "Once again there is a trade-off: the higher the recall (TPR), the more false positives\n",
            "\n",
            "--- Chunk 2630 ---\n",
            "(FPR) the classifier produces. The dotted line represents the ROC curve of a purely\n",
            "\n",
            "--- Chunk 2631 ---\n",
            "random classifier; a good classifier stays as far away from that line as possible (toward\n",
            "the top-left corner).\n",
            "\n",
            "--- Chunk 2632 ---\n",
            "Performance Measures | 97\n",
            "\n",
            "--- Chunk 2633 ---\n",
            "Figure 3-6. This ROC curve plots the false positive rate against the true positive rate for\n",
            "\n",
            "--- Chunk 2634 ---\n",
            "all possible thresholds; the red circle highlights the chosen ratio (at 43.68% recall)\n",
            "\n",
            "--- Chunk 2635 ---\n",
            "One way to compare classifiers is to measure the area under the curve (AUC). A per‐\n",
            "\n",
            "--- Chunk 2636 ---\n",
            "fect classifier will have a ROC AUC equal to 1, whereas a purely random classifier will\n",
            "\n",
            "--- Chunk 2637 ---\n",
            "have a ROC AUC equal to 0.5. Scikit-Learn provides a function to compute the ROC\n",
            "AUC:\n",
            "\n",
            "--- Chunk 2638 ---\n",
            ">>> from sklearn.metrics import roc_auc_score\n",
            ">>> roc_auc_score(y_train_5, y_scores)\n",
            "0.9611778893101814\n",
            "\n",
            "--- Chunk 2639 ---\n",
            "Since the ROC curve is so similar to the precision/recall (PR)\n",
            "curve, you may wonder how to decide which one to use. As a rule\n",
            "\n",
            "--- Chunk 2640 ---\n",
            "of thumb, you should prefer the PR curve whenever the positive\n",
            "class is rare or when you care more about the false positives than\n",
            "\n",
            "--- Chunk 2641 ---\n",
            "the false negatives. Otherwise, use the ROC curve. For example,\n",
            "looking at the previous ROC curve (and the ROC AUC score), you\n",
            "\n",
            "--- Chunk 2642 ---\n",
            "may think that the classifier is really good. But this is mostly\n",
            "because there are few positives (5s) compared to the negatives\n",
            "\n",
            "--- Chunk 2643 ---\n",
            "(non-5s). In contrast, the PR curve makes it clear that the classifier\n",
            "has room for improvement (the curve could be closer to the top-\n",
            "left corner).\n",
            "\n",
            "--- Chunk 2644 ---\n",
            "Let’s now train a RandomForestClassifier and compare its ROC curve and ROC\n",
            "\n",
            "--- Chunk 2645 ---\n",
            "AUC score to those of the SGDClassifier. First, you need to get scores for each\n",
            "\n",
            "--- Chunk 2646 ---\n",
            "instance in the training set. But due to the way it works (see Chapter 7), the Random\n",
            "\n",
            "--- Chunk 2647 ---\n",
            "ForestClassifier class does not have a decision_function() method. Instead, it\n",
            "\n",
            "--- Chunk 2648 ---\n",
            "98 | Chapter 3: Classification\n",
            "\n",
            "--- Chunk 2649 ---\n",
            "has a predict_proba() method. Scikit-Learn classifiers generally have one or the\n",
            "\n",
            "--- Chunk 2650 ---\n",
            "other, or both. The predict_proba() method returns an array containing a row per\n",
            "\n",
            "--- Chunk 2651 ---\n",
            "instance and a column per class, each containing the probability that the given\n",
            "\n",
            "--- Chunk 2652 ---\n",
            "instance belongs to the given class (e.g., 70% chance that the image represents a 5):\n",
            "\n",
            "--- Chunk 2653 ---\n",
            "from sklearn.ensemble import RandomForestClassifier\n",
            "\n",
            "--- Chunk 2654 ---\n",
            "forest_clf = RandomForestClassifier(random_state=42)\n",
            "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3,\n",
            "\n",
            "--- Chunk 2655 ---\n",
            "method=\"predict_proba\")\n",
            "\n",
            "--- Chunk 2656 ---\n",
            "The roc_curve() function expects labels and scores, but instead of scores you can\n",
            "\n",
            "--- Chunk 2657 ---\n",
            "give it class probabilities. Let’s use the positive class’s probability as the score:\n",
            "\n",
            "--- Chunk 2658 ---\n",
            "y_scores_forest = y_probas_forest[:, 1]   # score = proba of positive class\n",
            "\n",
            "--- Chunk 2659 ---\n",
            "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5,y_scores_forest)\n",
            "\n",
            "--- Chunk 2660 ---\n",
            "Now you are ready to plot the ROC curve. It is useful to plot the first ROC curve as\n",
            "well to see how they compare (Figure 3-7):\n",
            "\n",
            "--- Chunk 2661 ---\n",
            "plt.plot(fpr, tpr, \"b:\", label=\"SGD\")\n",
            "plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
            "plt.legend(loc=\"lower right\")\n",
            "plt.show()\n",
            "\n",
            "--- Chunk 2662 ---\n",
            "Figure 3-7. Comparing ROC curves: the Random Forest classifier is superior to the SGD\n",
            "\n",
            "--- Chunk 2663 ---\n",
            "classifier because its ROC curve is much closer to the top-left corner, and it has a greater\n",
            "AUC\n",
            "\n",
            "--- Chunk 2664 ---\n",
            "Performance Measures | 99\n",
            "\n",
            "--- Chunk 2665 ---\n",
            "As you can see in Figure 3-7, the RandomForestClassifier’s ROC curve looks much\n",
            "\n",
            "--- Chunk 2666 ---\n",
            "better than the SGDClassifier’s: it comes much closer to the top-left corner. As a\n",
            "result, its ROC AUC score is also significantly better:\n",
            "\n",
            "--- Chunk 2667 ---\n",
            ">>> roc_auc_score(y_train_5, y_scores_forest)\n",
            "0.9983436731328145\n",
            "\n",
            "--- Chunk 2668 ---\n",
            "Try measuring the precision and recall scores: you should find 99.0% precision and\n",
            "86.6% recall. Not too bad!\n",
            "\n",
            "--- Chunk 2669 ---\n",
            "You now know how to train binary classifiers, choose the appropriate metric for your\n",
            "\n",
            "--- Chunk 2670 ---\n",
            "task, evaluate your classifiers using cross-validation, select the precision/recall trade-\n",
            "\n",
            "--- Chunk 2671 ---\n",
            "off that fits your needs, and use ROC curves and ROC AUC scores to compare vari‐\n",
            "ous models. Now let’s try to detect more than just the 5s.\n",
            "\n",
            "--- Chunk 2672 ---\n",
            "Multiclass Classification\n",
            "Whereas binary classifiers distinguish between two classes, multiclass classifiers (also\n",
            "\n",
            "--- Chunk 2673 ---\n",
            "called multinomial classifiers) can distinguish between more than two classes.\n",
            "\n",
            "--- Chunk 2674 ---\n",
            "Some algorithms (such as SGD classifiers, Random Forest classifiers, and naive Bayes\n",
            "\n",
            "--- Chunk 2675 ---\n",
            "classifiers) are capable of handling multiple classes natively. Others (such as Logistic\n",
            "\n",
            "--- Chunk 2676 ---\n",
            "Regression or Support Vector Machine classifiers) are strictly binary classifiers. How‐\n",
            "\n",
            "--- Chunk 2677 ---\n",
            "ever, there are various strategies that you can use to perform multiclass classification\n",
            "with multiple binary classifiers.\n",
            "\n",
            "--- Chunk 2678 ---\n",
            "One way to create a system that can classify the digit images into 10 classes (from 0 to\n",
            "\n",
            "--- Chunk 2679 ---\n",
            "9) is to train 10 binary classifiers, one for each digit (a 0-detector, a 1-detector, a 2-\n",
            "\n",
            "--- Chunk 2680 ---\n",
            "detector, and so on). Then when you want to classify an image, you get the decision\n",
            "\n",
            "--- Chunk 2681 ---\n",
            "score from each classifier for that image and you select the class whose classifier out‐\n",
            "\n",
            "--- Chunk 2682 ---\n",
            "puts the highest score. This is called the one-versus-the-rest (OvR) strategy (also called\n",
            "one-versus-all).\n",
            "\n",
            "--- Chunk 2683 ---\n",
            "one-versus-all).\n",
            "Another strategy is to train a binary classifier for every pair of digits: one to distin‐\n",
            "\n",
            "--- Chunk 2684 ---\n",
            "guish 0s and 1s, another to distinguish 0s and 2s, another for 1s and 2s, and so on.\n",
            "\n",
            "--- Chunk 2685 ---\n",
            "This is called the one-versus-one (OvO) strategy. If there are N classes, you need to\n",
            "\n",
            "--- Chunk 2686 ---\n",
            "train N × (N – 1) / 2 classifiers. For the MNIST problem, this means training 45\n",
            "\n",
            "--- Chunk 2687 ---\n",
            "binary classifiers! When you want to classify an image, you have to run the image\n",
            "\n",
            "--- Chunk 2688 ---\n",
            "through all 45 classifiers and see which class wins the most duels. The main advan‐\n",
            "\n",
            "--- Chunk 2689 ---\n",
            "tage of OvO is that each classifier only needs to be trained on the part of the training\n",
            "set for the two classes that it must distinguish.\n",
            "\n",
            "--- Chunk 2690 ---\n",
            "Some algorithms (such as Support Vector Machine classifiers) scale poorly with the\n",
            "\n",
            "--- Chunk 2691 ---\n",
            "size of the training set. For these algorithms OvO is preferred because it is faster to\n",
            "\n",
            "--- Chunk 2692 ---\n",
            "train many classifiers on small training sets than to train few classifiers on large train‐\n",
            "\n",
            "--- Chunk 2693 ---\n",
            "ing sets. For most binary classification algorithms, however, OvR is preferred.\n",
            "\n",
            "--- Chunk 2694 ---\n",
            "100 | Chapter 3: Classification\n",
            "\n",
            "--- Chunk 2695 ---\n",
            "Scikit-Learn detects when you try to use a binary classification algorithm for a multi‐\n",
            "\n",
            "--- Chunk 2696 ---\n",
            "class classification task, and it automatically runs OvR or OvO, depending on the\n",
            "\n",
            "--- Chunk 2697 ---\n",
            "algorithm. Let’s try this with a Support Vector Machine classifier (see Chapter 5),\n",
            "using the sklearn.svm.SVC class:\n",
            "\n",
            "--- Chunk 2698 ---\n",
            ">>> from sklearn.svm import SVC\n",
            ">>> svm_clf = SVC()\n",
            ">>> svm_clf.fit(X_train, y_train) # y_train, not y_train_5\n",
            ">>> svm_clf.predict([some_digit])\n",
            "\n",
            "--- Chunk 2699 ---\n",
            "array([5], dtype=uint8)\n",
            "\n",
            "--- Chunk 2700 ---\n",
            "That was easy! This code trains the SVC on the training set using the original target\n",
            "\n",
            "--- Chunk 2701 ---\n",
            "classes from 0 to 9 (y_train), instead of the 5-versus-the-rest target classes\n",
            "\n",
            "--- Chunk 2702 ---\n",
            "(y_train_5). Then it makes a prediction (a correct one in this case). Under the hood,\n",
            "\n",
            "--- Chunk 2703 ---\n",
            "Scikit-Learn actually used the OvO strategy: it trained 45 binary classifiers, got their\n",
            "\n",
            "--- Chunk 2704 ---\n",
            "decision scores for the image, and selected the class that won the most duels.\n",
            "\n",
            "--- Chunk 2705 ---\n",
            "If you call the decision_function() method, you will see that it returns 10 scores\n",
            "per instance (instead of just 1). That’s one score per class:\n",
            "\n",
            "--- Chunk 2706 ---\n",
            ">>> some_digit_scores = svm_clf.decision_function([some_digit])\n",
            ">>> some_digit_scores\n",
            "\n",
            "--- Chunk 2707 ---\n",
            "array([[ 2.92492871,  7.02307409,  3.93648529,  0.90117363,  5.96945908,\n",
            "         9.5       ,  1.90718593,  8.02755089, -0.13202708,  4.94216947]])\n",
            "\n",
            "--- Chunk 2708 ---\n",
            "The highest score is indeed the one corresponding to class 5:\n",
            ">>> np.argmax(some_digit_scores)\n",
            "5\n",
            ">>> svm_clf.classes_\n",
            "\n",
            "--- Chunk 2709 ---\n",
            "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)\n",
            ">>> svm_clf.classes_[5]\n",
            "5\n",
            "\n",
            "--- Chunk 2710 ---\n",
            "When a classifier is trained, it stores the list of target classes in its\n",
            "classes_ attribute, ordered by value. In this case, the index of each\n",
            "\n",
            "--- Chunk 2711 ---\n",
            "class in the classes_ array conveniently matches the class itself\n",
            "(e.g., the class at index 5 happens to be class 5), but in general you\n",
            "\n",
            "--- Chunk 2712 ---\n",
            "won’t be so lucky.\n",
            "\n",
            "--- Chunk 2713 ---\n",
            "If you want to force Scikit-Learn to use one-versus-one or one-versus-the-rest, you\n",
            "\n",
            "--- Chunk 2714 ---\n",
            "can use the OneVsOneClassifier or OneVsRestClassifier classes. Simply create an\n",
            "\n",
            "--- Chunk 2715 ---\n",
            "instance and pass a classifier to its constructor (it does not even have to be a binary\n",
            "\n",
            "--- Chunk 2716 ---\n",
            "classifier). For example, this code creates a multiclass classifier using the OvR strat‐\n",
            "egy, based on an SVC:\n",
            "\n",
            "--- Chunk 2717 ---\n",
            ">>> from sklearn.multiclass import OneVsRestClassifier\n",
            ">>> ovr_clf = OneVsRestClassifier(SVC())\n",
            ">>> ovr_clf.fit(X_train, y_train)\n",
            "\n",
            "--- Chunk 2718 ---\n",
            "Multiclass Classification | 101\n",
            "\n",
            "\n",
            "\n",
            ">>> ovr_clf.predict([some_digit])\n",
            "array([5], dtype=uint8)\n",
            ">>> len(ovr_clf.estimators_)\n",
            "10\n",
            "\n",
            "--- Chunk 2719 ---\n",
            "Training an SGDClassifier (or a RandomForestClassifier) is just as easy:\n",
            ">>> sgd_clf.fit(X_train, y_train)\n",
            ">>> sgd_clf.predict([some_digit])\n",
            "\n",
            "--- Chunk 2720 ---\n",
            "array([5], dtype=uint8)\n",
            "\n",
            "--- Chunk 2721 ---\n",
            "This time Scikit-Learn did not have to run OvR or OvO because SGD classifiers can\n",
            "\n",
            "--- Chunk 2722 ---\n",
            "directly classify instances into multiple classes. The decision_function() method\n",
            "\n",
            "--- Chunk 2723 ---\n",
            "now returns one value per class. Let’s look at the score that the SGD classifier assigned\n",
            "to each class:\n",
            "\n",
            "--- Chunk 2724 ---\n",
            ">>> sgd_clf.decision_function([some_digit])\n",
            "array([[-15955.22628, -38080.96296, -13326.66695,   573.52692, -17680.68466,\n",
            "\n",
            "--- Chunk 2725 ---\n",
            "2412.53175, -25526.86498, -12290.15705, -7946.05205, -10631.35889]])\n",
            "\n",
            "--- Chunk 2726 ---\n",
            "You can see that the classifier is fairly confident about its prediction: almost all scores\n",
            "\n",
            "--- Chunk 2727 ---\n",
            "are largely negative, while class 5 has a score of 2412.5. The model has a slight doubt\n",
            "\n",
            "--- Chunk 2728 ---\n",
            "regarding class 3, which gets a score of 573.5. Now of course you want to evaluate this\n",
            "\n",
            "--- Chunk 2729 ---\n",
            "classifier. As usual, you can use cross-validation. Use the cross_val_score() func‐\n",
            "tion to evaluate the SGDClassifier’s accuracy:\n",
            "\n",
            "--- Chunk 2730 ---\n",
            ">>> cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
            "array([0.8489802 , 0.87129356, 0.86988048])\n",
            "\n",
            "--- Chunk 2731 ---\n",
            "It gets over 84% on all test folds. If you used a random classifier, you would get 10%\n",
            "\n",
            "--- Chunk 2732 ---\n",
            "accuracy, so this is not such a bad score, but you can still do much better. Simply scal‐\n",
            "\n",
            "--- Chunk 2733 ---\n",
            "ing the inputs (as discussed in Chapter 2) increases accuracy above 89%:\n",
            "\n",
            "--- Chunk 2734 ---\n",
            ">>> from sklearn.preprocessing import StandardScaler\n",
            ">>> scaler = StandardScaler()\n",
            "\n",
            "--- Chunk 2735 ---\n",
            ">>> X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
            ">>> cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")\n",
            "\n",
            "--- Chunk 2736 ---\n",
            "array([0.89707059, 0.8960948 , 0.90693604])\n",
            "\n",
            "--- Chunk 2737 ---\n",
            "Error Analysis\n",
            "If this were a real project, you would now follow the steps in your Machine Learning\n",
            "\n",
            "--- Chunk 2738 ---\n",
            "project checklist (see Appendix B). You’d explore data preparation options, try out\n",
            "\n",
            "--- Chunk 2739 ---\n",
            "multiple models (shortlisting the best ones and fine-tuning their hyperparameters\n",
            "\n",
            "--- Chunk 2740 ---\n",
            "using GridSearchCV), and automate as much as possible. Here, we will assume that\n",
            "\n",
            "--- Chunk 2741 ---\n",
            "you have found a promising model and you want to find ways to improve it. One way\n",
            "to do this is to analyze the types of errors it makes.\n",
            "\n",
            "--- Chunk 2742 ---\n",
            "102 | Chapter 3: Classification\n",
            "\n",
            "--- Chunk 2743 ---\n",
            "First, look at the confusion matrix. You need to make predictions using the\n",
            "\n",
            "--- Chunk 2744 ---\n",
            "cross_val_predict() function, then call the confusion_matrix() function, just like\n",
            "you did earlier:\n",
            "\n",
            "--- Chunk 2745 ---\n",
            ">>> y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
            ">>> conf_mx = confusion_matrix(y_train, y_train_pred)\n",
            ">>> conf_mx\n",
            "\n",
            "--- Chunk 2746 ---\n",
            ">>> conf_mx\n",
            "array([[5578,    0,   22,    7,    8,   45,   35,    5,  222,    1],\n",
            "       [   0, 6410,   35,   26,    4,   44,    4,    8,  198,   13],\n",
            "\n",
            "--- Chunk 2747 ---\n",
            "[  28,   27, 5232,  100,   74,   27,   68,   37,  354,   11],\n",
            "       [  23,   18,  115, 5254,    2,  209,   26,   38,  373,   73],\n",
            "\n",
            "--- Chunk 2748 ---\n",
            "[  11,   14,   45,   12, 5219,   11,   33,   26,  299,  172],\n",
            "       [  26,   16,   31,  173,   54, 4484,   76,   14,  482,   65],\n",
            "\n",
            "--- Chunk 2749 ---\n",
            "[  31,   17,   45,    2,   42,   98, 5556,    3,  123,    1],\n",
            "       [  20,   10,   53,   27,   50,   13,    3, 5696,  173,  220],\n",
            "\n",
            "--- Chunk 2750 ---\n",
            "[  17,   64,   47,   91,    3,  125,   24,   11, 5421,   48],\n",
            "       [  24,   18,   29,   67,  116,   39,    1,  174,  329, 5152]])\n",
            "\n",
            "--- Chunk 2751 ---\n",
            "That’s a lot of numbers. It’s often more convenient to look at an image representation\n",
            "\n",
            "--- Chunk 2752 ---\n",
            "of the confusion matrix, using Matplotlib’s matshow() function:\n",
            "\n",
            "--- Chunk 2753 ---\n",
            "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
            "plt.show()\n",
            "\n",
            "--- Chunk 2754 ---\n",
            "This confusion matrix looks pretty good, since most images are on the main diago‐\n",
            "\n",
            "--- Chunk 2755 ---\n",
            "nal, which means that they were classified correctly. The 5s look slightly darker than\n",
            "\n",
            "--- Chunk 2756 ---\n",
            "the other digits, which could mean that there are fewer images of 5s in the dataset or\n",
            "\n",
            "--- Chunk 2757 ---\n",
            "that the classifier does not perform as well on 5s as on other digits. In fact, you can\n",
            "verify that both are the case.\n",
            "\n",
            "--- Chunk 2758 ---\n",
            "Let’s focus the plot on the errors. First, you need to divide each value in the confusion\n",
            "\n",
            "--- Chunk 2759 ---\n",
            "matrix by the number of images in the corresponding class so that you can compare\n",
            "\n",
            "--- Chunk 2760 ---\n",
            "error rates instead of absolute numbers of errors (which would make abundant\n",
            "classes look unfairly bad):\n",
            "\n",
            "--- Chunk 2761 ---\n",
            "Error Analysis | 103\n",
            "\n",
            "\n",
            "\n",
            "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
            "norm_conf_mx = conf_mx / row_sums\n",
            "\n",
            "--- Chunk 2762 ---\n",
            "Fill the diagonal with zeros to keep only the errors, and plot the result:\n",
            "np.fill_diagonal(norm_conf_mx, 0)\n",
            "\n",
            "--- Chunk 2763 ---\n",
            "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
            "plt.show()\n",
            "\n",
            "--- Chunk 2764 ---\n",
            "You can clearly see the kinds of errors the classifier makes. Remember that rows rep‐\n",
            "\n",
            "--- Chunk 2765 ---\n",
            "resent actual classes, while columns represent predicted classes. The column for class\n",
            "\n",
            "--- Chunk 2766 ---\n",
            "8 is quite bright, which tells you that many images get misclassified as 8s. However,\n",
            "\n",
            "--- Chunk 2767 ---\n",
            "the row for class 8 is not that bad, telling you that actual 8s in general get properly\n",
            "\n",
            "--- Chunk 2768 ---\n",
            "classified as 8s. As you can see, the confusion matrix is not necessarily symmetrical.\n",
            "\n",
            "--- Chunk 2769 ---\n",
            "You can also see that 3s and 5s often get confused (in both directions).\n",
            "\n",
            "--- Chunk 2770 ---\n",
            "Analyzing the confusion matrix often gives you insights into ways to improve your\n",
            "\n",
            "--- Chunk 2771 ---\n",
            "classifier. Looking at this plot, it seems that your efforts should be spent on reducing\n",
            "\n",
            "--- Chunk 2772 ---\n",
            "the false 8s. For example, you could try to gather more training data for digits that\n",
            "\n",
            "--- Chunk 2773 ---\n",
            "look like 8s (but are not) so that the classifier can learn to distinguish them from real\n",
            "\n",
            "--- Chunk 2774 ---\n",
            "8s. Or you could engineer new features that would help the classifier—for example,\n",
            "\n",
            "--- Chunk 2775 ---\n",
            "writing an algorithm to count the number of closed loops (e.g., 8 has two, 6 has one, 5\n",
            "\n",
            "--- Chunk 2776 ---\n",
            "has none). Or you could preprocess the images (e.g., using Scikit-Image, Pillow, or\n",
            "\n",
            "--- Chunk 2777 ---\n",
            "OpenCV) to make some patterns, such as closed loops, stand out more.\n",
            "Analyzing individual errors can also be a good way to gain insights on what your\n",
            "\n",
            "--- Chunk 2778 ---\n",
            "classifier is doing and why it is failing, but it is more difficult and time-consuming.\n",
            "\n",
            "--- Chunk 2779 ---\n",
            "For example, let’s plot examples of 3s and 5s (the plot_digits() function just uses\n",
            "\n",
            "--- Chunk 2780 ---\n",
            "Matplotlib’s imshow() function; see this chapter’s Jupyter notebook for details):\n",
            "\n",
            "--- Chunk 2781 ---\n",
            "cl_a, cl_b = 3, 5\n",
            "X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]\n",
            "X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\n",
            "\n",
            "--- Chunk 2782 ---\n",
            "X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\n",
            "X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]\n",
            "\n",
            "--- Chunk 2783 ---\n",
            "104 | Chapter 3: Classification\n",
            "\n",
            "--- Chunk 2784 ---\n",
            "plt.figure(figsize=(8,8))\n",
            "plt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)\n",
            "plt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)\n",
            "\n",
            "--- Chunk 2785 ---\n",
            "plt.subplot(223); plot_digits(X_ba[:25], images_per_row=5)\n",
            "plt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)\n",
            "plt.show()\n",
            "\n",
            "--- Chunk 2786 ---\n",
            "The two 5 × 5 blocks on the left show digits classified as 3s, and the two 5 × 5 blocks\n",
            "\n",
            "--- Chunk 2787 ---\n",
            "on the right show images classified as 5s. Some of the digits that the classifier gets\n",
            "\n",
            "--- Chunk 2788 ---\n",
            "wrong (i.e., in the bottom-left and top-right blocks) are so badly written that even a\n",
            "\n",
            "--- Chunk 2789 ---\n",
            "human would have trouble classifying them (e.g., the 5 in the first row and second\n",
            "\n",
            "--- Chunk 2790 ---\n",
            "column truly looks like a badly written 3). However, most misclassified images seem\n",
            "\n",
            "--- Chunk 2791 ---\n",
            "like obvious errors to us, and it’s hard to understand why the classifier made the mis‐\n",
            "\n",
            "--- Chunk 2792 ---\n",
            "takes it did.3 The reason is that we used a simple SGDClassifier, which is a linear\n",
            "\n",
            "--- Chunk 2793 ---\n",
            "model. All it does is assign a weight per class to each pixel, and when it sees a new\n",
            "\n",
            "--- Chunk 2794 ---\n",
            "image it just sums up the weighted pixel intensities to get a score for each class. So\n",
            "\n",
            "--- Chunk 2795 ---\n",
            "since 3s and 5s differ only by a few pixels, this model will easily confuse them.\n",
            "\n",
            "--- Chunk 2796 ---\n",
            "The main difference between 3s and 5s is the position of the small line that joins the\n",
            "\n",
            "--- Chunk 2797 ---\n",
            "top line to the bottom arc. If you draw a 3 with the junction slightly shifted to the left,\n",
            "\n",
            "--- Chunk 2798 ---\n",
            "the classifier might classify it as a 5, and vice versa. In other words, this classifier is\n",
            "\n",
            "--- Chunk 2799 ---\n",
            "quite sensitive to image shifting and rotation. So one way to reduce the 3/5 confusion\n",
            "\n",
            "--- Chunk 2800 ---\n",
            "would be to preprocess the images to ensure that they are well centered and not too\n",
            "rotated. This will probably help reduce other errors as well.\n",
            "\n",
            "--- Chunk 2801 ---\n",
            "3 But remember that our brain is a fantastic pattern recognition system, and our visual system does a lot of\n",
            "\n",
            "--- Chunk 2802 ---\n",
            "complex preprocessing before any information reaches our consciousness, so the fact that it feels simple does\n",
            "not mean that it is.\n",
            "\n",
            "--- Chunk 2803 ---\n",
            "Error Analysis | 105\n",
            "\n",
            "--- Chunk 2804 ---\n",
            "Multilabel Classification\n",
            "Until now each instance has always been assigned to just one class. In some cases you\n",
            "\n",
            "--- Chunk 2805 ---\n",
            "may want your classifier to output multiple classes for each instance. Consider a face-\n",
            "\n",
            "--- Chunk 2806 ---\n",
            "recognition classifier: what should it do if it recognizes several people in the same\n",
            "\n",
            "--- Chunk 2807 ---\n",
            "picture? It should attach one tag per person it recognizes. Say the classifier has been\n",
            "\n",
            "--- Chunk 2808 ---\n",
            "trained to recognize three faces, Alice, Bob, and Charlie. Then when the classifier is\n",
            "\n",
            "--- Chunk 2809 ---\n",
            "shown a picture of Alice and Charlie, it should output [1, 0, 1] (meaning “Alice yes,\n",
            "\n",
            "--- Chunk 2810 ---\n",
            "Bob no, Charlie yes”). Such a classification system that outputs multiple binary tags is\n",
            "called a multilabel classification system.\n",
            "\n",
            "--- Chunk 2811 ---\n",
            "We won’t go into face recognition just yet, but let’s look at a simpler example, just for\n",
            "illustration purposes:\n",
            "\n",
            "--- Chunk 2812 ---\n",
            "from sklearn.neighbors import KNeighborsClassifier\n",
            "\n",
            "--- Chunk 2813 ---\n",
            "y_train_large = (y_train >= 7)\n",
            "y_train_odd = (y_train % 2 == 1)\n",
            "y_multilabel = np.c_[y_train_large, y_train_odd]\n",
            "\n",
            "--- Chunk 2814 ---\n",
            "knn_clf = KNeighborsClassifier()\n",
            "knn_clf.fit(X_train, y_multilabel)\n",
            "\n",
            "--- Chunk 2815 ---\n",
            "This code creates a y_multilabel array containing two target labels for each digit\n",
            "\n",
            "--- Chunk 2816 ---\n",
            "image: the first indicates whether or not the digit is large (7, 8, or 9), and the second\n",
            "\n",
            "--- Chunk 2817 ---\n",
            "indicates whether or not it is odd. The next lines create a KNeighborsClassifier\n",
            "\n",
            "--- Chunk 2818 ---\n",
            "instance (which supports multilabel classification, though not all classifiers do), and\n",
            "\n",
            "--- Chunk 2819 ---\n",
            "we train it using the multiple targets array. Now you can make a prediction, and\n",
            "notice that it outputs two labels:\n",
            "\n",
            "--- Chunk 2820 ---\n",
            ">>> knn_clf.predict([some_digit])\n",
            "array([[False,  True]])\n",
            "\n",
            "--- Chunk 2821 ---\n",
            "And it gets it right! The digit 5 is indeed not large (False) and odd (True).\n",
            "\n",
            "--- Chunk 2822 ---\n",
            "There are many ways to evaluate a multilabel classifier, and selecting the right metric\n",
            "\n",
            "--- Chunk 2823 ---\n",
            "really depends on your project. One approach is to measure the F1 score for each\n",
            "\n",
            "--- Chunk 2824 ---\n",
            "individual label (or any other binary classifier metric discussed earlier), then simply\n",
            "\n",
            "--- Chunk 2825 ---\n",
            "compute the average score. This code computes the average F1 score across all labels:\n",
            "\n",
            "--- Chunk 2826 ---\n",
            ">>> y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)\n",
            ">>> f1_score(y_multilabel, y_train_knn_pred, average=\"macro\")\n",
            "\n",
            "--- Chunk 2827 ---\n",
            "0.976410265560605\n",
            "\n",
            "--- Chunk 2828 ---\n",
            "This assumes that all labels are equally important, however, which may not be the\n",
            "\n",
            "--- Chunk 2829 ---\n",
            "case. In particular, if you have many more pictures of Alice than of Bob or Charlie,\n",
            "\n",
            "--- Chunk 2830 ---\n",
            "you may want to give more weight to the classifier’s score on pictures of Alice. One\n",
            "\n",
            "--- Chunk 2831 ---\n",
            "simple option is to give each label a weight equal to its support (i.e., the number of\n",
            "\n",
            "--- Chunk 2832 ---\n",
            "106 | Chapter 3: Classification\n",
            "\n",
            "\n",
            "\n",
            "instances with that target label). To do this, simply set average=\"weighted\" in the\n",
            "preceding code.4\n",
            "\n",
            "--- Chunk 2833 ---\n",
            "Multioutput Classification\n",
            "The last type of classification task we are going to discuss here is called multioutput–\n",
            "\n",
            "--- Chunk 2834 ---\n",
            "multiclass classification (or simply multioutput classification). It is simply a generaliza‐\n",
            "\n",
            "--- Chunk 2835 ---\n",
            "tion of multilabel classification where each label can be multiclass (i.e., it can have\n",
            "more than two possible values).\n",
            "\n",
            "--- Chunk 2836 ---\n",
            "To illustrate this, let’s build a system that removes noise from images. It will take as\n",
            "\n",
            "--- Chunk 2837 ---\n",
            "input a noisy digit image, and it will (hopefully) output a clean digit image, repre‐\n",
            "\n",
            "--- Chunk 2838 ---\n",
            "sented as an array of pixel intensities, just like the MNIST images. Notice that the\n",
            "\n",
            "--- Chunk 2839 ---\n",
            "classifier’s output is multilabel (one label per pixel) and each label can have multiple\n",
            "\n",
            "--- Chunk 2840 ---\n",
            "values (pixel intensity ranges from 0 to 255). It is thus an example of a multioutput\n",
            "classification system.\n",
            "\n",
            "--- Chunk 2841 ---\n",
            "The line between classification and regression is sometimes blurry,\n",
            "such as in this example. Arguably, predicting pixel intensity is more\n",
            "\n",
            "--- Chunk 2842 ---\n",
            "akin to regression than to classification. Moreover, multioutput\n",
            "systems are not limited to classification tasks; you could even have\n",
            "\n",
            "--- Chunk 2843 ---\n",
            "a system that outputs multiple labels per instance, including both\n",
            "class labels and value labels.\n",
            "\n",
            "--- Chunk 2844 ---\n",
            "Let’s start by creating the training and test sets by taking the MNIST images and\n",
            "\n",
            "--- Chunk 2845 ---\n",
            "adding noise to their pixel intensities with NumPy’s randint() function. The target\n",
            "images will be the original images:\n",
            "\n",
            "--- Chunk 2846 ---\n",
            "noise = np.random.randint(0, 100, (len(X_train), 784))\n",
            "X_train_mod = X_train + noise\n",
            "noise = np.random.randint(0, 100, (len(X_test), 784))\n",
            "\n",
            "--- Chunk 2847 ---\n",
            "X_test_mod = X_test + noise\n",
            "y_train_mod = X_train\n",
            "y_test_mod = X_test\n",
            "\n",
            "--- Chunk 2848 ---\n",
            "Let’s take a peek at an image from the test set (yes, we’re snooping on the test data, so\n",
            "you should be frowning right now):\n",
            "\n",
            "--- Chunk 2849 ---\n",
            "4 Scikit-Learn offers a few other averaging options and multilabel classifier metrics; see the documentation for\n",
            "more details.\n",
            "\n",
            "--- Chunk 2850 ---\n",
            "Multioutput Classification | 107\n",
            "\n",
            "--- Chunk 2851 ---\n",
            "On the left is the noisy input image, and on the right is the clean target image. Now\n",
            "let’s train the classifier and make it clean this image:\n",
            "\n",
            "--- Chunk 2852 ---\n",
            "knn_clf.fit(X_train_mod, y_train_mod)\n",
            "clean_digit = knn_clf.predict([X_test_mod[some_index]])\n",
            "plot_digit(clean_digit)\n",
            "\n",
            "--- Chunk 2853 ---\n",
            "Looks close enough to the target! This concludes our tour of classification. You\n",
            "\n",
            "--- Chunk 2854 ---\n",
            "should now know how to select good metrics for classification tasks, pick the appro‐\n",
            "\n",
            "--- Chunk 2855 ---\n",
            "priate precision/recall trade-off, compare classifiers, and more generally build good\n",
            "classification systems for a variety of tasks.\n",
            "\n",
            "--- Chunk 2856 ---\n",
            "Exercises\n",
            "1. Try to build a classifier for the MNIST dataset that achieves over 97% accuracy\n",
            "\n",
            "--- Chunk 2857 ---\n",
            "on the test set. Hint: the KNeighborsClassifier works quite well for this task;\n",
            "\n",
            "--- Chunk 2858 ---\n",
            "you just need to find good hyperparameter values (try a grid search on the\n",
            "weights and n_neighbors hyperparameters).\n",
            "\n",
            "--- Chunk 2859 ---\n",
            "2. Write a function that can shift an MNIST image in any direction (left, right, up,\n",
            "\n",
            "--- Chunk 2860 ---\n",
            "or down) by one pixel.5 Then, for each image in the training set, create four shif‐\n",
            "\n",
            "--- Chunk 2861 ---\n",
            "ted copies (one per direction) and add them to the training set. Finally, train your\n",
            "\n",
            "--- Chunk 2862 ---\n",
            "best model on this expanded training set and measure its accuracy on the test set.\n",
            "\n",
            "--- Chunk 2863 ---\n",
            "You should observe that your model performs even better now! This technique of\n",
            "\n",
            "--- Chunk 2864 ---\n",
            "artificially growing the training set is called data augmentation or training set\n",
            "expansion.\n",
            "\n",
            "--- Chunk 2865 ---\n",
            "5 You can use the shift() function from the scipy.ndimage.interpolation module. For example,\n",
            "\n",
            "--- Chunk 2866 ---\n",
            "shift(image, [2, 1], cval=0) shifts the image two pixels down and one pixel to the right.\n",
            "\n",
            "--- Chunk 2867 ---\n",
            "108 | Chapter 3: Classification\n",
            "\n",
            "--- Chunk 2868 ---\n",
            "3. Tackle the Titanic dataset. A great place to start is on Kaggle.\n",
            "4. Build a spam classifier (a more challenging exercise):\n",
            "\n",
            "--- Chunk 2869 ---\n",
            "• Download examples of spam and ham from Apache SpamAssassin’s public\n",
            "datasets.\n",
            "\n",
            "--- Chunk 2870 ---\n",
            "• Unzip the datasets and familiarize yourself with the data format.\n",
            "• Split the datasets into a training set and a test set.\n",
            "\n",
            "--- Chunk 2871 ---\n",
            "• Write a data preparation pipeline to convert each email into a feature vector.\n",
            "\n",
            "--- Chunk 2872 ---\n",
            "Your preparation pipeline should transform an email into a (sparse) vector that\n",
            "\n",
            "--- Chunk 2873 ---\n",
            "indicates the presence or absence of each possible word. For example, if all\n",
            "\n",
            "--- Chunk 2874 ---\n",
            "emails only ever contain four words, “Hello,” “how,” “are,” “you,” then the email\n",
            "\n",
            "--- Chunk 2875 ---\n",
            "“Hello you Hello Hello you” would be converted into a vector [1, 0, 0, 1]\n",
            "(meaning [“Hello” is present, “how” is absent, “are” is absent, “you” is\n",
            "\n",
            "--- Chunk 2876 ---\n",
            "present]), or [3, 0, 0, 2] if you prefer to count the number of occurrences of\n",
            "each word.\n",
            "\n",
            "--- Chunk 2877 ---\n",
            "each word.\n",
            "You may want to add hyperparameters to your preparation pipeline to control\n",
            "\n",
            "--- Chunk 2878 ---\n",
            "whether or not to strip off email headers, convert each email to lowercase,\n",
            "remove punctuation, replace all URLs with “URL,” replace all numbers with\n",
            "\n",
            "--- Chunk 2879 ---\n",
            "“NUMBER,” or even perform stemming (i.e., trim off word endings; there are\n",
            "Python libraries available to do this).\n",
            "\n",
            "--- Chunk 2880 ---\n",
            "Finally, try out several classifiers and see if you can build a great spam classi‐\n",
            "fier, with both high recall and high precision.\n",
            "\n",
            "--- Chunk 2881 ---\n",
            "Solutions to these exercises can be found in the Jupyter notebooks available at https://\n",
            "github.com/ageron/handson-ml2.\n",
            "\n",
            "Exercises | 109\n",
            "\n",
            "--- Chunk 2882 ---\n",
            "CHAPTER 4\n",
            "Training Models\n",
            "\n",
            "--- Chunk 2883 ---\n",
            "So far we have treated Machine Learning models and their training algorithms mostly\n",
            "\n",
            "--- Chunk 2884 ---\n",
            "like black boxes. If you went through some of the exercises in the previous chapters,\n",
            "\n",
            "--- Chunk 2885 ---\n",
            "you may have been surprised by how much you can get done without knowing any‐\n",
            "\n",
            "--- Chunk 2886 ---\n",
            "thing about what’s under the hood: you optimized a regression system, you improved\n",
            "\n",
            "--- Chunk 2887 ---\n",
            "a digit image classifier, and you even built a spam classifier from scratch, all this\n",
            "\n",
            "--- Chunk 2888 ---\n",
            "without knowing how they actually work. Indeed, in many situations you don’t really\n",
            "need to know the implementation details.\n",
            "\n",
            "--- Chunk 2889 ---\n",
            "However, having a good understanding of how things work can help you quickly\n",
            "\n",
            "--- Chunk 2890 ---\n",
            "home in on the appropriate model, the right training algorithm to use, and a good set\n",
            "\n",
            "--- Chunk 2891 ---\n",
            "of hyperparameters for your task. Understanding what’s under the hood will also help\n",
            "\n",
            "--- Chunk 2892 ---\n",
            "you debug issues and perform error analysis more efficiently. Lastly, most of the top‐\n",
            "\n",
            "--- Chunk 2893 ---\n",
            "ics discussed in this chapter will be essential in understanding, building, and training\n",
            "neural networks (discussed in Part II of this book).\n",
            "\n",
            "--- Chunk 2894 ---\n",
            "In this chapter we will start by looking at the Linear Regression model, one of the\n",
            "\n",
            "--- Chunk 2895 ---\n",
            "simplest models there is. We will discuss two very different ways to train it:\n",
            "\n",
            "--- Chunk 2896 ---\n",
            "• Using a direct “closed-form” equation that directly computes the model parame‐\n",
            "\n",
            "--- Chunk 2897 ---\n",
            "ters that best fit the model to the training set (i.e., the model parameters that\n",
            "minimize the cost function over the training set).\n",
            "\n",
            "--- Chunk 2898 ---\n",
            "• Using an iterative optimization approach called Gradient Descent (GD) that\n",
            "\n",
            "--- Chunk 2899 ---\n",
            "gradually tweaks the model parameters to minimize the cost function over the\n",
            "\n",
            "--- Chunk 2900 ---\n",
            "training set, eventually converging to the same set of parameters as the first\n",
            "\n",
            "--- Chunk 2901 ---\n",
            "method. We will look at a few variants of Gradient Descent that we will use again\n",
            "\n",
            "--- Chunk 2902 ---\n",
            "and again when we study neural networks in Part II: Batch GD, Mini-batch GD,\n",
            "and Stochastic GD.\n",
            "\n",
            "--- Chunk 2903 ---\n",
            "111\n",
            "\n",
            "--- Chunk 2904 ---\n",
            "Next we will look at Polynomial Regression, a more complex model that can fit non‐\n",
            "\n",
            "--- Chunk 2905 ---\n",
            "linear datasets. Since this model has more parameters than Linear Regression, it is\n",
            "\n",
            "--- Chunk 2906 ---\n",
            "more prone to overfitting the training data, so we will look at how to detect whether\n",
            "\n",
            "--- Chunk 2907 ---\n",
            "or not this is the case using learning curves, and then we will look at several regulari‐\n",
            "\n",
            "--- Chunk 2908 ---\n",
            "zation techniques that can reduce the risk of overfitting the training set.\n",
            "\n",
            "--- Chunk 2909 ---\n",
            "Finally, we will look at two more models that are commonly used for classification\n",
            "tasks: Logistic Regression and Softmax Regression.\n",
            "\n",
            "--- Chunk 2910 ---\n",
            "There will be quite a few math equations in this chapter, using basic\n",
            "notions of linear algebra and calculus. To understand these equa‐\n",
            "\n",
            "--- Chunk 2911 ---\n",
            "tions, you will need to know what vectors and matrices are; how to\n",
            "transpose them, multiply them, and inverse them; and what partial\n",
            "\n",
            "--- Chunk 2912 ---\n",
            "derivatives are. If you are unfamiliar with these concepts, please go\n",
            "through the linear algebra and calculus introductory tutorials avail‐\n",
            "\n",
            "--- Chunk 2913 ---\n",
            "able as Jupyter notebooks in the online supplemental material. For\n",
            "those who are truly allergic to mathematics, you should still go\n",
            "\n",
            "--- Chunk 2914 ---\n",
            "through this chapter and simply skip the equations; hopefully, the\n",
            "text will be sufficient to help you understand most of the concepts.\n",
            "\n",
            "--- Chunk 2915 ---\n",
            "Linear Regression\n",
            "In Chapter 1 we looked at a simple regression model of life satisfaction: life_satisfac‐\n",
            "tion = θ0 + θ1 × GDP_per_capita.\n",
            "\n",
            "--- Chunk 2916 ---\n",
            "This model is just a linear function of the input feature GDP_per_capita. θ0 and θ1 are\n",
            "the model’s parameters.\n",
            "\n",
            "--- Chunk 2917 ---\n",
            "More generally, a linear model makes a prediction by simply computing a weighted\n",
            "\n",
            "--- Chunk 2918 ---\n",
            "sum of the input features, plus a constant called the bias term (also called the intercept\n",
            "term), as shown in Equation 4-1.\n",
            "\n",
            "--- Chunk 2919 ---\n",
            "Equation 4-1. Linear Regression model prediction\n",
            "y = θ0 + θ1x1 + θ2x2 +⋯ + θnxn\n",
            "\n",
            "In this equation:\n",
            "\n",
            "--- Chunk 2920 ---\n",
            "• ŷ is the predicted value.\n",
            "• n is the number of features.\n",
            "• xi is the ith feature value.\n",
            "\n",
            "--- Chunk 2921 ---\n",
            "• θj is the jth model parameter (including the bias term θ0 and the feature weights\n",
            "\n",
            "--- Chunk 2922 ---\n",
            "θ1, θ2, ⋯, θn).\n",
            "\n",
            "112 | Chapter 4: Training Models\n",
            "\n",
            "\n",
            "\n",
            "This can be written much more concisely using a vectorized form, as shown in Equa‐\n",
            "tion 4-2.\n",
            "\n",
            "--- Chunk 2923 ---\n",
            "Equation 4-2. Linear Regression model prediction (vectorized form)\n",
            "y = hθ x = θ · x\n",
            "\n",
            "In this equation:\n",
            "\n",
            "--- Chunk 2924 ---\n",
            "In this equation:\n",
            "\n",
            "• θ is the model’s parameter vector, containing the bias term θ0 and the feature\n",
            "weights θ1 to θn.\n",
            "\n",
            "--- Chunk 2925 ---\n",
            "• x is the instance’s feature vector, containing x0 to xn, with x0 always equal to 1.\n",
            "\n",
            "--- Chunk 2926 ---\n",
            "• θ · x is the dot product of the vectors θ and x, which is of course equal to θ0x0 +\n",
            "\n",
            "--- Chunk 2927 ---\n",
            "θ1x1 + θ2x2 + ... + θnxn.\n",
            "• hθ is the hypothesis function, using the model parameters θ.\n",
            "\n",
            "--- Chunk 2928 ---\n",
            "In Machine Learning, vectors are often represented as column vec‐\n",
            "tors, which are 2D arrays with a single column. If θ and x are col‐\n",
            "\n",
            "--- Chunk 2929 ---\n",
            "umn vectors, then the prediction is y = θ⊺x, where θ⊺ is the\n",
            "transpose of θ (a row vector instead of a column vector) and θ⊺x is\n",
            "\n",
            "--- Chunk 2930 ---\n",
            "the matrix multiplication of θ⊺ and x. It is of course the same pre‐\n",
            "diction, except that it is now represented as a single-cell matrix\n",
            "\n",
            "--- Chunk 2931 ---\n",
            "rather than a scalar value. In this book I will use this notation to\n",
            "avoid switching between dot products and matrix multiplications.\n",
            "\n",
            "--- Chunk 2932 ---\n",
            "OK, that’s the Linear Regression model—but how do we train it? Well, recall that\n",
            "\n",
            "--- Chunk 2933 ---\n",
            "training a model means setting its parameters so that the model best fits the training\n",
            "\n",
            "--- Chunk 2934 ---\n",
            "set. For this purpose, we first need a measure of how well (or poorly) the model fits\n",
            "\n",
            "--- Chunk 2935 ---\n",
            "the training data. In Chapter 2 we saw that the most common performance measure\n",
            "\n",
            "--- Chunk 2936 ---\n",
            "of a regression model is the Root Mean Square Error (RMSE) (Equation 2-1). There‐\n",
            "\n",
            "--- Chunk 2937 ---\n",
            "fore, to train a Linear Regression model, we need to find the value of θ that minimi‐\n",
            "\n",
            "--- Chunk 2938 ---\n",
            "zes the RMSE. In practice, it is simpler to minimize the mean squared error (MSE)\n",
            "\n",
            "--- Chunk 2939 ---\n",
            "than the RMSE, and it leads to the same result (because the value that minimizes a\n",
            "function also minimizes its square root).1\n",
            "\n",
            "--- Chunk 2940 ---\n",
            "1 It is often the case that a learning algorithm will try to optimize a different function than the performance\n",
            "\n",
            "--- Chunk 2941 ---\n",
            "measure used to evaluate the final model. This is generally because that function is easier to compute, because\n",
            "\n",
            "--- Chunk 2942 ---\n",
            "it has useful differentiation properties that the performance measure lacks, or because we want to constrain\n",
            "\n",
            "--- Chunk 2943 ---\n",
            "the model during training, as you will see when we discuss regularization.\n",
            "\n",
            "--- Chunk 2944 ---\n",
            "Linear Regression | 113\n",
            "\n",
            "\n",
            "\n",
            "The MSE of a Linear Regression hypothesis hθ on a training set X is calculated using\n",
            "Equation 4-3.\n",
            "\n",
            "--- Chunk 2945 ---\n",
            "Equation 4-3. MSE cost function for a Linear Regression model\n",
            "m\n",
            "\n",
            "MSE X, hθ = 1\n",
            "m ∑ θ⊺x i − y i 2\n",
            "\n",
            "i = 1\n",
            "\n",
            "--- Chunk 2946 ---\n",
            "Most of these notations were presented in Chapter 2 (see “Notations” on page 40).\n",
            "\n",
            "--- Chunk 2947 ---\n",
            "The only difference is that we write hθ instead of just h to make it clear that the model\n",
            "\n",
            "--- Chunk 2948 ---\n",
            "is parametrized by the vector θ. To simplify notations, we will just write MSE(θ)\n",
            "instead of MSE(X, hθ).\n",
            "\n",
            "--- Chunk 2949 ---\n",
            "The Normal Equation\n",
            "To find the value of θ that minimizes the cost function, there is a closed-form solution\n",
            "\n",
            "--- Chunk 2950 ---\n",
            "—in other words, a mathematical equation that gives the result directly. This is called\n",
            "the Normal Equation (Equation 4-4).\n",
            "\n",
            "--- Chunk 2951 ---\n",
            "Equation 4-4. Normal Equation\n",
            "\n",
            "θ = X⊺X −1   X⊺   y\n",
            "\n",
            "In this equation:\n",
            "\n",
            "--- Chunk 2952 ---\n",
            "In this equation:\n",
            "\n",
            "• θ is the value of θ that minimizes the cost function.\n",
            "• y is the vector of target values containing y(1) to y(m).\n",
            "\n",
            "--- Chunk 2953 ---\n",
            "Let’s generate some linear-looking data to test this equation on (Figure 4-1):\n",
            "import numpy as np\n",
            "\n",
            "--- Chunk 2954 ---\n",
            "X = 2 * np.random.rand(100, 1)\n",
            "y = 4 + 3 * X + np.random.randn(100, 1)\n",
            "\n",
            "114 | Chapter 4: Training Models\n",
            "\n",
            "--- Chunk 2955 ---\n",
            "Figure 4-1. Randomly generated linear dataset\n",
            "\n",
            "--- Chunk 2956 ---\n",
            "Now let’s compute θ using the Normal Equation. We will use the inv() function from\n",
            "\n",
            "--- Chunk 2957 ---\n",
            "NumPy’s linear algebra module (np.linalg) to compute the inverse of a matrix, and\n",
            "the dot() method for matrix multiplication:\n",
            "\n",
            "--- Chunk 2958 ---\n",
            "X_b = np.c_[np.ones((100, 1)), X]  # add x0 = 1 to each instance\n",
            "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
            "\n",
            "--- Chunk 2959 ---\n",
            "The function that we used to generate the data is y = 4 + 3x1 + Gaussian noise. Let’s\n",
            "see what the equation found:\n",
            "\n",
            "--- Chunk 2960 ---\n",
            ">>> theta_best\n",
            "array([[4.21509616],\n",
            "       [2.77011339]])\n",
            "\n",
            "--- Chunk 2961 ---\n",
            "We would have hoped for θ0 = 4 and θ1 = 3 instead of θ0 = 4.215 and θ1 = 2.770. Close\n",
            "\n",
            "--- Chunk 2962 ---\n",
            "enough, but the noise made it impossible to recover the exact parameters of the origi‐\n",
            "nal function.\n",
            "Now we can make predictions using θ:\n",
            "\n",
            "--- Chunk 2963 ---\n",
            ">>> X_new = np.array([[0], [2]])\n",
            ">>> X_new_b = np.c_[np.ones((2, 1)), X_new] # add x0 = 1 to each instance\n",
            ">>> y_predict = X_new_b.dot(theta_best)\n",
            "\n",
            "--- Chunk 2964 ---\n",
            ">>> y_predict\n",
            "array([[4.21509616],\n",
            "       [9.75532293]])\n",
            "\n",
            "--- Chunk 2965 ---\n",
            "Linear Regression | 115\n",
            "\n",
            "--- Chunk 2966 ---\n",
            "Let’s plot this model’s predictions (Figure 4-2):\n",
            "plt.plot(X_new, y_predict, \"r-\")\n",
            "plt.plot(X, y, \"b.\")\n",
            "plt.axis([0, 2, 0, 15])\n",
            "plt.show()\n",
            "\n",
            "--- Chunk 2967 ---\n",
            "Figure 4-2. Linear Regression model predictions\n",
            "\n",
            "Performing Linear Regression using Scikit-Learn is simple:2\n",
            "\n",
            "--- Chunk 2968 ---\n",
            ">>> from sklearn.linear_model import LinearRegression\n",
            ">>> lin_reg = LinearRegression()\n",
            ">>> lin_reg.fit(X, y)\n",
            ">>> lin_reg.intercept_, lin_reg.coef_\n",
            "\n",
            "--- Chunk 2969 ---\n",
            "(array([4.21509616]), array([[2.77011339]]))\n",
            ">>> lin_reg.predict(X_new)\n",
            "array([[4.21509616],\n",
            "       [9.75532293]])\n",
            "\n",
            "--- Chunk 2970 ---\n",
            "The LinearRegression class is based on the scipy.linalg.lstsq() function (the\n",
            "name stands for “least squares”), which you could call directly:\n",
            "\n",
            "--- Chunk 2971 ---\n",
            ">>> theta_best_svd, residuals, rank, s = np.linalg.lstsq(X_b, y, rcond=1e-6)\n",
            ">>> theta_best_svd\n",
            "array([[4.21509616],\n",
            "       [2.77011339]])\n",
            "\n",
            "--- Chunk 2972 ---\n",
            "This function computes θ = X+y, where �+ is the pseudoinverse of X (specifically,\n",
            "\n",
            "--- Chunk 2973 ---\n",
            "the Moore-Penrose inverse). You can use np.linalg.pinv() to compute the\n",
            "pseudoinverse directly:\n",
            "\n",
            "--- Chunk 2974 ---\n",
            "2 Note that Scikit-Learn separates the bias term (intercept_) from the feature weights (coef_).\n",
            "\n",
            "116 | Chapter 4: Training Models\n",
            "\n",
            "--- Chunk 2975 ---\n",
            ">>> np.linalg.pinv(X_b).dot(y)\n",
            "array([[4.21509616],\n",
            "       [2.77011339]])\n",
            "\n",
            "--- Chunk 2976 ---\n",
            "The pseudoinverse itself is computed using a standard matrix factorization technique\n",
            "\n",
            "--- Chunk 2977 ---\n",
            "called Singular Value Decomposition (SVD) that can decompose the training set\n",
            "matrix X into the matrix multiplication of three matrices U Σ V⊺ (see\n",
            "\n",
            "--- Chunk 2978 ---\n",
            "numpy.linalg.svd()). The pseudoinverse is computed as X+ = VΣ+U⊺. To compute\n",
            "\n",
            "--- Chunk 2979 ---\n",
            "the matrix Σ+, the algorithm takes Σ and sets to zero all values smaller than a tiny\n",
            "\n",
            "--- Chunk 2980 ---\n",
            "threshold value, then it replaces all the nonzero values with their inverse, and finally\n",
            "\n",
            "--- Chunk 2981 ---\n",
            "it transposes the resulting matrix. This approach is more efficient than computing the\n",
            "\n",
            "--- Chunk 2982 ---\n",
            "Normal Equation, plus it handles edge cases nicely: indeed, the Normal Equation may\n",
            "\n",
            "--- Chunk 2983 ---\n",
            "not work if the matrix X⊺X is not invertible (i.e., singular), such as if m < n or if some\n",
            "\n",
            "--- Chunk 2984 ---\n",
            "features are redundant, but the pseudoinverse is always defined.\n",
            "\n",
            "--- Chunk 2985 ---\n",
            "Computational Complexity\n",
            "The Normal Equation computes the inverse of X⊺ X, which is an (n + 1) × (n + 1)\n",
            "\n",
            "--- Chunk 2986 ---\n",
            "matrix (where n is the number of features). The computational complexity of inverting\n",
            "\n",
            "--- Chunk 2987 ---\n",
            "such a matrix is typically about O(n2.4) to O(n3), depending on the implementation. In\n",
            "\n",
            "--- Chunk 2988 ---\n",
            "other words, if you double the number of features, you multiply the computation\n",
            "time by roughly 22.4 = 5.3 to 23 = 8.\n",
            "\n",
            "--- Chunk 2989 ---\n",
            "The SVD approach used by Scikit-Learn’s LinearRegression class is about O(n2). If\n",
            "\n",
            "--- Chunk 2990 ---\n",
            "you double the number of features, you multiply the computation time by roughly 4.\n",
            "\n",
            "--- Chunk 2991 ---\n",
            "Both the Normal Equation and the SVD approach get very slow\n",
            "when the number of features grows large (e.g., 100,000). On the\n",
            "\n",
            "--- Chunk 2992 ---\n",
            "positive side, both are linear with regard to the number of instances\n",
            "in the training set (they are O(m)), so they handle large training\n",
            "\n",
            "--- Chunk 2993 ---\n",
            "sets efficiently, provided they can fit in memory.\n",
            "\n",
            "--- Chunk 2994 ---\n",
            "Also, once you have trained your Linear Regression model (using the Normal Equa‐\n",
            "\n",
            "--- Chunk 2995 ---\n",
            "tion or any other algorithm), predictions are very fast: the computational complexity\n",
            "\n",
            "--- Chunk 2996 ---\n",
            "is linear with regard to both the number of instances you want to make predictions\n",
            "\n",
            "--- Chunk 2997 ---\n",
            "on and the number of features. In other words, making predictions on twice as many\n",
            "\n",
            "--- Chunk 2998 ---\n",
            "instances (or twice as many features) will take roughly twice as much time.\n",
            "\n",
            "--- Chunk 2999 ---\n",
            "Now we will look at a very different way to train a Linear Regression model, which is\n",
            "\n",
            "--- Chunk 3000 ---\n",
            "better suited for cases where there are a large number of features or too many training\n",
            "instances to fit in memory.\n",
            "\n",
            "--- Chunk 3001 ---\n",
            "Linear Regression | 117\n",
            "\n",
            "--- Chunk 3002 ---\n",
            "Gradient Descent\n",
            "Gradient Descent is a generic optimization algorithm capable of finding optimal solu‐\n",
            "\n",
            "--- Chunk 3003 ---\n",
            "tions to a wide range of problems. The general idea of Gradient Descent is to tweak\n",
            "parameters iteratively in order to minimize a cost function.\n",
            "\n",
            "--- Chunk 3004 ---\n",
            "Suppose you are lost in the mountains in a dense fog, and you can only feel the slope\n",
            "\n",
            "--- Chunk 3005 ---\n",
            "of the ground below your feet. A good strategy to get to the bottom of the valley\n",
            "\n",
            "--- Chunk 3006 ---\n",
            "quickly is to go downhill in the direction of the steepest slope. This is exactly what\n",
            "\n",
            "--- Chunk 3007 ---\n",
            "Gradient Descent does: it measures the local gradient of the error function with\n",
            "\n",
            "--- Chunk 3008 ---\n",
            "regard to the parameter vector θ, and it goes in the direction of descending gradient.\n",
            "Once the gradient is zero, you have reached a minimum!\n",
            "\n",
            "--- Chunk 3009 ---\n",
            "Concretely, you start by filling θ with random values (this is called random initializa‐\n",
            "\n",
            "--- Chunk 3010 ---\n",
            "tion). Then you improve it gradually, taking one baby step at a time, each step\n",
            "\n",
            "--- Chunk 3011 ---\n",
            "attempting to decrease the cost function (e.g., the MSE), until the algorithm converges\n",
            "to a minimum (see Figure 4-3).\n",
            "\n",
            "--- Chunk 3012 ---\n",
            "Figure 4-3. In this depiction of Gradient Descent, the model parameters are initialized\n",
            "\n",
            "--- Chunk 3013 ---\n",
            "randomly and get tweaked repeatedly to minimize the cost function; the learning step\n",
            "\n",
            "--- Chunk 3014 ---\n",
            "size is proportional to the slope of the cost function, so the steps gradually get smaller as\n",
            "the parameters approach the minimum\n",
            "\n",
            "--- Chunk 3015 ---\n",
            "An important parameter in Gradient Descent is the size of the steps, determined by\n",
            "\n",
            "--- Chunk 3016 ---\n",
            "the learning rate hyperparameter. If the learning rate is too small, then the algorithm\n",
            "\n",
            "--- Chunk 3017 ---\n",
            "will have to go through many iterations to converge, which will take a long time (see\n",
            "Figure 4-4).\n",
            "\n",
            "--- Chunk 3018 ---\n",
            "118 | Chapter 4: Training Models\n",
            "\n",
            "\n",
            "\n",
            "Figure 4-4. The learning rate is too small\n",
            "\n",
            "--- Chunk 3019 ---\n",
            "On the other hand, if the learning rate is too high, you might jump across the valley\n",
            "\n",
            "--- Chunk 3020 ---\n",
            "and end up on the other side, possibly even higher up than you were before. This\n",
            "\n",
            "--- Chunk 3021 ---\n",
            "might make the algorithm diverge, with larger and larger values, failing to find a good\n",
            "solution (see Figure 4-5).\n",
            "\n",
            "--- Chunk 3022 ---\n",
            "Figure 4-5. The learning rate is too large\n",
            "\n",
            "--- Chunk 3023 ---\n",
            "Finally, not all cost functions look like nice, regular bowls. There may be holes, ridges,\n",
            "\n",
            "--- Chunk 3024 ---\n",
            "plateaus, and all sorts of irregular terrains, making convergence to the minimum dif‐\n",
            "\n",
            "--- Chunk 3025 ---\n",
            "ficult. Figure 4-6 shows the two main challenges with Gradient Descent. If the ran‐\n",
            "\n",
            "--- Chunk 3026 ---\n",
            "dom initialization starts the algorithm on the left, then it will converge to a local\n",
            "\n",
            "--- Chunk 3027 ---\n",
            "minimum, which is not as good as the global minimum. If it starts on the right, then it\n",
            "\n",
            "--- Chunk 3028 ---\n",
            "will take a very long time to cross the plateau. And if you stop too early, you will\n",
            "never reach the global minimum.\n",
            "\n",
            "--- Chunk 3029 ---\n",
            "Gradient Descent | 119\n",
            "\n",
            "\n",
            "\n",
            "Figure 4-6. Gradient Descent pitfalls\n",
            "\n",
            "--- Chunk 3030 ---\n",
            "Fortunately, the MSE cost function for a Linear Regression model happens to be a\n",
            "\n",
            "--- Chunk 3031 ---\n",
            "convex function, which means that if you pick any two points on the curve, the line\n",
            "\n",
            "--- Chunk 3032 ---\n",
            "segment joining them never crosses the curve. This implies that there are no local\n",
            "\n",
            "--- Chunk 3033 ---\n",
            "minima, just one global minimum. It is also a continuous function with a slope that\n",
            "\n",
            "--- Chunk 3034 ---\n",
            "never changes abruptly.3 These two facts have a great consequence: Gradient Descent\n",
            "\n",
            "--- Chunk 3035 ---\n",
            "is guaranteed to approach arbitrarily close the global minimum (if you wait long\n",
            "enough and if the learning rate is not too high).\n",
            "\n",
            "--- Chunk 3036 ---\n",
            "In fact, the cost function has the shape of a bowl, but it can be an elongated bowl if\n",
            "\n",
            "--- Chunk 3037 ---\n",
            "the features have very different scales. Figure 4-7 shows Gradient Descent on a train‐\n",
            "\n",
            "--- Chunk 3038 ---\n",
            "ing set where features 1 and 2 have the same scale (on the left), and on a training set\n",
            "\n",
            "--- Chunk 3039 ---\n",
            "where feature 1 has much smaller values than feature 2 (on the right).4\n",
            "\n",
            "--- Chunk 3040 ---\n",
            "Figure 4-7. Gradient Descent with (left) and without (right) feature scaling\n",
            "\n",
            "--- Chunk 3041 ---\n",
            "3 Technically speaking, its derivative is Lipschitz continuous.\n",
            "\n",
            "--- Chunk 3042 ---\n",
            "4 Since feature 1 is smaller, it takes a larger change in θ1 to affect the cost function, which is why the bowl is\n",
            "\n",
            "--- Chunk 3043 ---\n",
            "elongated along the θ1 axis.\n",
            "\n",
            "120 | Chapter 4: Training Models\n",
            "\n",
            "--- Chunk 3044 ---\n",
            "As you can see, on the left the Gradient Descent algorithm goes straight toward the\n",
            "\n",
            "--- Chunk 3045 ---\n",
            "minimum, thereby reaching it quickly, whereas on the right it first goes in a direction\n",
            "\n",
            "--- Chunk 3046 ---\n",
            "almost orthogonal to the direction of the global minimum, and it ends with a long\n",
            "\n",
            "--- Chunk 3047 ---\n",
            "march down an almost flat valley. It will eventually reach the minimum, but it will\n",
            "take a long time.\n",
            "\n",
            "--- Chunk 3048 ---\n",
            "When using Gradient Descent, you should ensure that all features\n",
            "have a similar scale (e.g., using Scikit-Learn’s StandardScaler\n",
            "\n",
            "--- Chunk 3049 ---\n",
            "class), or else it will take much longer to converge.\n",
            "\n",
            "--- Chunk 3050 ---\n",
            "This diagram also illustrates the fact that training a model means searching for a\n",
            "\n",
            "--- Chunk 3051 ---\n",
            "combination of model parameters that minimizes a cost function (over the training\n",
            "\n",
            "--- Chunk 3052 ---\n",
            "set). It is a search in the model’s parameter space: the more parameters a model has,\n",
            "\n",
            "--- Chunk 3053 ---\n",
            "the more dimensions this space has, and the harder the search is: searching for a nee‐\n",
            "\n",
            "--- Chunk 3054 ---\n",
            "dle in a 300-dimensional haystack is much trickier than in 3 dimensions. Fortunately,\n",
            "\n",
            "--- Chunk 3055 ---\n",
            "since the cost function is convex in the case of Linear Regression, the needle is simply\n",
            "at the bottom of the bowl.\n",
            "\n",
            "--- Chunk 3056 ---\n",
            "Batch Gradient Descent\n",
            "To implement Gradient Descent, you need to compute the gradient of the cost func‐\n",
            "\n",
            "--- Chunk 3057 ---\n",
            "tion with regard to each model parameter θj. In other words, you need to calculate\n",
            "\n",
            "--- Chunk 3058 ---\n",
            "how much the cost function will change if you change θj just a little bit. This is called\n",
            "\n",
            "--- Chunk 3059 ---\n",
            "a partial derivative. It is like asking “What is the slope of the mountain under my feet\n",
            "\n",
            "--- Chunk 3060 ---\n",
            "if I face east?” and then asking the same question facing north (and so on for all other\n",
            "\n",
            "--- Chunk 3061 ---\n",
            "dimensions, if you can imagine a universe with more than three dimensions). Equa‐\n",
            "\n",
            "--- Chunk 3062 ---\n",
            "tion 4-5 computes the partial derivative of the cost function with regard to parameter\n",
            "θj, noted ∂ MSE(θ) / ∂θj.\n",
            "\n",
            "--- Chunk 3063 ---\n",
            "Equation 4-5. Partial derivatives of the cost function\n",
            "∂\n",
            "\n",
            "∂θ MSE θ = 2 m\n",
            "i\n",
            "\n",
            "m ∑ θ⊺x − y i x i\n",
            "j i = 1 j\n",
            "\n",
            "--- Chunk 3064 ---\n",
            "Instead of computing these partial derivatives individually, you can use Equation 4-6\n",
            "\n",
            "--- Chunk 3065 ---\n",
            "to compute them all in one go. The gradient vector, noted ∇θMSE(θ), contains all the\n",
            "\n",
            "--- Chunk 3066 ---\n",
            "partial derivatives of the cost function (one for each model parameter).\n",
            "\n",
            "--- Chunk 3067 ---\n",
            "Gradient Descent | 121\n",
            "\n",
            "\n",
            "\n",
            "Equation 4-6. Gradient vector of the cost function\n",
            "∂\n",
            "\n",
            "∂θ MSE θ\n",
            "0\n",
            "\n",
            "∂\n",
            "∂θ MSE θ\n",
            "\n",
            "∇θ MSE θ = 1 = 2\n",
            "mX⊺ Xθ − y\n",
            "\n",
            "⋮\n",
            "∂\n",
            "\n",
            "∂θ MSE θ\n",
            "n\n",
            "\n",
            "--- Chunk 3068 ---\n",
            "Notice that this formula involves calculations over the full training\n",
            "set X, at each Gradient Descent step! This is why the algorithm is\n",
            "\n",
            "--- Chunk 3069 ---\n",
            "called Batch Gradient Descent: it uses the whole batch of training\n",
            "data at every step (actually, Full Gradient Descent would probably\n",
            "\n",
            "--- Chunk 3070 ---\n",
            "be a better name). As a result it is terribly slow on very large train‐\n",
            "ing sets (but we will see much faster Gradient Descent algorithms\n",
            "\n",
            "--- Chunk 3071 ---\n",
            "shortly). However, Gradient Descent scales well with the number of\n",
            "features; training a Linear Regression model when there are hun‐\n",
            "\n",
            "--- Chunk 3072 ---\n",
            "dreds of thousands of features is much faster using Gradient\n",
            "Descent than using the Normal Equation or SVD decomposition.\n",
            "\n",
            "--- Chunk 3073 ---\n",
            "Once you have the gradient vector, which points uphill, just go in the opposite direc‐\n",
            "\n",
            "--- Chunk 3074 ---\n",
            "tion to go downhill. This means subtracting ∇θMSE(θ) from θ. This is where the\n",
            "\n",
            "--- Chunk 3075 ---\n",
            "learning rate η comes into play:5 multiply the gradient vector by η to determine the\n",
            "size of the downhill step (Equation 4-7).\n",
            "\n",
            "--- Chunk 3076 ---\n",
            "Equation 4-7. Gradient Descent step\n",
            "θ next step = θ − η∇θ MSE θ\n",
            "\n",
            "--- Chunk 3077 ---\n",
            "Let’s look at a quick implementation of this algorithm:\n",
            "eta = 0.1  # learning rate\n",
            "n_iterations = 1000\n",
            "m = 100\n",
            "\n",
            "--- Chunk 3078 ---\n",
            "theta = np.random.randn(2,1)  # random initialization\n",
            "\n",
            "--- Chunk 3079 ---\n",
            "for iteration in range(n_iterations):\n",
            "    gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
            "    theta = theta - eta * gradients\n",
            "\n",
            "--- Chunk 3080 ---\n",
            "5 Eta (η) is the seventh letter of the Greek alphabet.\n",
            "\n",
            "122 | Chapter 4: Training Models\n",
            "\n",
            "--- Chunk 3081 ---\n",
            "That wasn’t too hard! Let’s look at the resulting theta:\n",
            ">>> theta\n",
            "array([[4.21509616],\n",
            "       [2.77011339]])\n",
            "\n",
            "--- Chunk 3082 ---\n",
            "Hey, that’s exactly what the Normal Equation found! Gradient Descent worked per‐\n",
            "\n",
            "--- Chunk 3083 ---\n",
            "fectly. But what if you had used a different learning rate eta? Figure 4-8 shows the\n",
            "\n",
            "--- Chunk 3084 ---\n",
            "first 10 steps of Gradient Descent using three different learning rates (the dashed line\n",
            "represents the starting point).\n",
            "\n",
            "--- Chunk 3085 ---\n",
            "Figure 4-8. Gradient Descent with various learning rates\n",
            "\n",
            "--- Chunk 3086 ---\n",
            "On the left, the learning rate is too low: the algorithm will eventually reach the solu‐\n",
            "\n",
            "--- Chunk 3087 ---\n",
            "tion, but it will take a long time. In the middle, the learning rate looks pretty good: in\n",
            "\n",
            "--- Chunk 3088 ---\n",
            "just a few iterations, it has already converged to the solution. On the right, the learn‐\n",
            "\n",
            "--- Chunk 3089 ---\n",
            "ing rate is too high: the algorithm diverges, jumping all over the place and actually\n",
            "\n",
            "--- Chunk 3090 ---\n",
            "getting further and further away from the solution at every step.\n",
            "To find a good learning rate, you can use grid search (see Chapter 2). However, you\n",
            "\n",
            "--- Chunk 3091 ---\n",
            "may want to limit the number of iterations so that grid search can eliminate models\n",
            "that take too long to converge.\n",
            "\n",
            "--- Chunk 3092 ---\n",
            "You may wonder how to set the number of iterations. If it is too low, you will still be\n",
            "\n",
            "--- Chunk 3093 ---\n",
            "far away from the optimal solution when the algorithm stops; but if it is too high, you\n",
            "\n",
            "--- Chunk 3094 ---\n",
            "will waste time while the model parameters do not change anymore. A simple solu‐\n",
            "\n",
            "--- Chunk 3095 ---\n",
            "tion is to set a very large number of iterations but to interrupt the algorithm when the\n",
            "\n",
            "--- Chunk 3096 ---\n",
            "gradient vector becomes tiny—that is, when its norm becomes smaller than a tiny\n",
            "\n",
            "--- Chunk 3097 ---\n",
            "number ϵ (called the tolerance)—because this happens when Gradient Descent has\n",
            "(almost) reached the minimum.\n",
            "\n",
            "--- Chunk 3098 ---\n",
            "Gradient Descent | 123\n",
            "\n",
            "--- Chunk 3099 ---\n",
            "Convergence Rate\n",
            "When the cost function is convex and its slope does not change abruptly (as is the\n",
            "\n",
            "--- Chunk 3100 ---\n",
            "case for the MSE cost function), Batch Gradient Descent with a fixed learning rate\n",
            "\n",
            "--- Chunk 3101 ---\n",
            "will eventually converge to the optimal solution, but you may have to wait a while: it\n",
            "\n",
            "--- Chunk 3102 ---\n",
            "can take O(1/ϵ) iterations to reach the optimum within a range of ϵ, depending on the\n",
            "\n",
            "--- Chunk 3103 ---\n",
            "shape of the cost function. If you divide the tolerance by 10 to have a more precise\n",
            "\n",
            "--- Chunk 3104 ---\n",
            "solution, then the algorithm may have to run about 10 times longer.\n",
            "\n",
            "--- Chunk 3105 ---\n",
            "Stochastic Gradient Descent\n",
            "The main problem with Batch Gradient Descent is the fact that it uses the whole\n",
            "\n",
            "--- Chunk 3106 ---\n",
            "training set to compute the gradients at every step, which makes it very slow when\n",
            "\n",
            "--- Chunk 3107 ---\n",
            "the training set is large. At the opposite extreme, Stochastic Gradient Descent picks a\n",
            "\n",
            "--- Chunk 3108 ---\n",
            "random instance in the training set at every step and computes the gradients based\n",
            "\n",
            "--- Chunk 3109 ---\n",
            "only on that single instance. Obviously, working on a single instance at a time makes\n",
            "\n",
            "--- Chunk 3110 ---\n",
            "the algorithm much faster because it has very little data to manipulate at every itera‐\n",
            "\n",
            "--- Chunk 3111 ---\n",
            "tion. It also makes it possible to train on huge training sets, since only one instance\n",
            "\n",
            "--- Chunk 3112 ---\n",
            "needs to be in memory at each iteration (Stochastic GD can be implemented as an\n",
            "out-of-core algorithm; see Chapter 1).\n",
            "\n",
            "--- Chunk 3113 ---\n",
            "On the other hand, due to its stochastic (i.e., random) nature, this algorithm is much\n",
            "\n",
            "--- Chunk 3114 ---\n",
            "less regular than Batch Gradient Descent: instead of gently decreasing until it reaches\n",
            "\n",
            "--- Chunk 3115 ---\n",
            "the minimum, the cost function will bounce up and down, decreasing only on aver‐\n",
            "\n",
            "--- Chunk 3116 ---\n",
            "age. Over time it will end up very close to the minimum, but once it gets there it will\n",
            "\n",
            "--- Chunk 3117 ---\n",
            "continue to bounce around, never settling down (see Figure 4-9). So once the algo‐\n",
            "rithm stops, the final parameter values are good, but not optimal.\n",
            "\n",
            "--- Chunk 3118 ---\n",
            "Figure 4-9. With Stochastic Gradient Descent, each training step is much faster but also\n",
            "much more stochastic than when using Batch Gradient Descent\n",
            "\n",
            "--- Chunk 3119 ---\n",
            "124 | Chapter 4: Training Models\n",
            "\n",
            "--- Chunk 3120 ---\n",
            "When the cost function is very irregular (as in Figure 4-6), this can actually help the\n",
            "\n",
            "--- Chunk 3121 ---\n",
            "algorithm jump out of local minima, so Stochastic Gradient Descent has a better\n",
            "\n",
            "--- Chunk 3122 ---\n",
            "chance of finding the global minimum than Batch Gradient Descent does.\n",
            "\n",
            "--- Chunk 3123 ---\n",
            "Therefore, randomness is good to escape from local optima, but bad because it means\n",
            "\n",
            "--- Chunk 3124 ---\n",
            "that the algorithm can never settle at the minimum. One solution to this dilemma is\n",
            "\n",
            "--- Chunk 3125 ---\n",
            "to gradually reduce the learning rate. The steps start out large (which helps make\n",
            "\n",
            "--- Chunk 3126 ---\n",
            "quick progress and escape local minima), then get smaller and smaller, allowing the\n",
            "\n",
            "--- Chunk 3127 ---\n",
            "algorithm to settle at the global minimum. This process is akin to simulated anneal‐\n",
            "\n",
            "--- Chunk 3128 ---\n",
            "ing, an algorithm inspired from the process in metallurgy of annealing, where molten\n",
            "\n",
            "--- Chunk 3129 ---\n",
            "metal is slowly cooled down. The function that determines the learning rate at each\n",
            "\n",
            "--- Chunk 3130 ---\n",
            "iteration is called the learning schedule. If the learning rate is reduced too quickly, you\n",
            "\n",
            "--- Chunk 3131 ---\n",
            "may get stuck in a local minimum, or even end up frozen halfway to the minimum. If\n",
            "\n",
            "--- Chunk 3132 ---\n",
            "the learning rate is reduced too slowly, you may jump around the minimum for a\n",
            "\n",
            "--- Chunk 3133 ---\n",
            "long time and end up with a suboptimal solution if you halt training too early.\n",
            "\n",
            "--- Chunk 3134 ---\n",
            "This code implements Stochastic Gradient Descent using a simple learning schedule:\n",
            "\n",
            "--- Chunk 3135 ---\n",
            "n_epochs = 50\n",
            "t0, t1 = 5, 50  # learning schedule hyperparameters\n",
            "\n",
            "def learning_schedule(t):\n",
            "    return t0 / (t + t1)\n",
            "\n",
            "--- Chunk 3136 ---\n",
            "theta = np.random.randn(2,1)  # random initialization\n",
            "\n",
            "--- Chunk 3137 ---\n",
            "for epoch in range(n_epochs):\n",
            "    for i in range(m):\n",
            "        random_index = np.random.randint(m)\n",
            "        xi = X_b[random_index:random_index+1]\n",
            "\n",
            "--- Chunk 3138 ---\n",
            "yi = y[random_index:random_index+1]\n",
            "        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
            "        eta = learning_schedule(epoch * m + i)\n",
            "\n",
            "--- Chunk 3139 ---\n",
            "theta = theta - eta * gradients\n",
            "\n",
            "--- Chunk 3140 ---\n",
            "By convention we iterate by rounds of m iterations; each round is called an epoch.\n",
            "\n",
            "--- Chunk 3141 ---\n",
            "While the Batch Gradient Descent code iterated 1,000 times through the whole train‐\n",
            "\n",
            "--- Chunk 3142 ---\n",
            "ing set, this code goes through the training set only 50 times and reaches a pretty\n",
            "good solution:\n",
            "\n",
            "--- Chunk 3143 ---\n",
            ">>> theta\n",
            "array([[4.21076011],\n",
            "       [2.74856079]])\n",
            "\n",
            "Figure 4-10 shows the first 20 steps of training (notice how irregular the steps are).\n",
            "\n",
            "--- Chunk 3144 ---\n",
            "Gradient Descent | 125\n",
            "\n",
            "\n",
            "\n",
            "Figure 4-10. The first 20 steps of Stochastic Gradient Descent\n",
            "\n",
            "--- Chunk 3145 ---\n",
            "Note that since instances are picked randomly, some instances may be picked several\n",
            "\n",
            "--- Chunk 3146 ---\n",
            "times per epoch, while others may not be picked at all. If you want to be sure that the\n",
            "\n",
            "--- Chunk 3147 ---\n",
            "algorithm goes through every instance at each epoch, another approach is to shuffle\n",
            "\n",
            "--- Chunk 3148 ---\n",
            "the training set (making sure to shuffle the input features and the labels jointly), then\n",
            "\n",
            "--- Chunk 3149 ---\n",
            "go through it instance by instance, then shuffle it again, and so on. However, this\n",
            "approach generally converges more slowly.\n",
            "\n",
            "--- Chunk 3150 ---\n",
            "When using Stochastic Gradient Descent, the training instances\n",
            "must be independent and identically distributed (IID) to ensure\n",
            "\n",
            "--- Chunk 3151 ---\n",
            "that the parameters get pulled toward the global optimum, on aver‐\n",
            "age. A simple way to ensure this is to shuffle the instances during\n",
            "\n",
            "--- Chunk 3152 ---\n",
            "training (e.g., pick each instance randomly, or shuffle the training\n",
            "set at the beginning of each epoch). If you do not shuffle the\n",
            "\n",
            "--- Chunk 3153 ---\n",
            "instances—for example, if the instances are sorted by label—then\n",
            "SGD will start by optimizing for one label, then the next, and so on,\n",
            "\n",
            "--- Chunk 3154 ---\n",
            "and it will not settle close to the global minimum.\n",
            "\n",
            "--- Chunk 3155 ---\n",
            "To perform Linear Regression using Stochastic GD with Scikit-Learn, you can use the\n",
            "\n",
            "--- Chunk 3156 ---\n",
            "SGDRegressor class, which defaults to optimizing the squared error cost function.\n",
            "\n",
            "--- Chunk 3157 ---\n",
            "The following code runs for maximum 1,000 epochs or until the loss drops by less\n",
            "\n",
            "--- Chunk 3158 ---\n",
            "than 0.001 during one epoch (max_iter=1000, tol=1e-3). It starts with a learning rate\n",
            "\n",
            "--- Chunk 3159 ---\n",
            "of 0.1 (eta0=0.1), using the default learning schedule (different from the preceding\n",
            "\n",
            "--- Chunk 3160 ---\n",
            "one). Lastly, it does not use any regularization (penalty=None; more details on this\n",
            "shortly):\n",
            "\n",
            "--- Chunk 3161 ---\n",
            "126 | Chapter 4: Training Models\n",
            "\n",
            "--- Chunk 3162 ---\n",
            "from sklearn.linear_model import SGDRegressor\n",
            "sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.1)\n",
            "sgd_reg.fit(X, y.ravel())\n",
            "\n",
            "--- Chunk 3163 ---\n",
            "Once again, you find a solution quite close to the one returned by the Normal\n",
            "Equation:\n",
            "\n",
            "--- Chunk 3164 ---\n",
            ">>> sgd_reg.intercept_, sgd_reg.coef_\n",
            "(array([4.24365286]), array([2.8250878]))\n",
            "\n",
            "--- Chunk 3165 ---\n",
            "Mini-batch Gradient Descent\n",
            "The last Gradient Descent algorithm we will look at is called Mini-batch Gradient\n",
            "\n",
            "--- Chunk 3166 ---\n",
            "Descent. It is simple to understand once you know Batch and Stochastic Gradient\n",
            "\n",
            "--- Chunk 3167 ---\n",
            "Descent: at each step, instead of computing the gradients based on the full training set\n",
            "\n",
            "--- Chunk 3168 ---\n",
            "(as in Batch GD) or based on just one instance (as in Stochastic GD), Mini-batch GD\n",
            "\n",
            "--- Chunk 3169 ---\n",
            "computes the gradients on small random sets of instances called mini-batches. The\n",
            "\n",
            "--- Chunk 3170 ---\n",
            "main advantage of Mini-batch GD over Stochastic GD is that you can get a perfor‐\n",
            "\n",
            "--- Chunk 3171 ---\n",
            "mance boost from hardware optimization of matrix operations, especially when using\n",
            "GPUs.\n",
            "\n",
            "--- Chunk 3172 ---\n",
            "GPUs.\n",
            "The algorithm’s progress in parameter space is less erratic than with Stochastic GD,\n",
            "\n",
            "--- Chunk 3173 ---\n",
            "especially with fairly large mini-batches. As a result, Mini-batch GD will end up walk‐\n",
            "\n",
            "--- Chunk 3174 ---\n",
            "ing around a bit closer to the minimum than Stochastic GD—but it may be harder for\n",
            "\n",
            "--- Chunk 3175 ---\n",
            "it to escape from local minima (in the case of problems that suffer from local minima,\n",
            "\n",
            "--- Chunk 3176 ---\n",
            "unlike Linear Regression). Figure 4-11 shows the paths taken by the three Gradient\n",
            "\n",
            "--- Chunk 3177 ---\n",
            "Descent algorithms in parameter space during training. They all end up near the\n",
            "\n",
            "--- Chunk 3178 ---\n",
            "minimum, but Batch GD’s path actually stops at the minimum, while both Stochastic\n",
            "\n",
            "--- Chunk 3179 ---\n",
            "GD and Mini-batch GD continue to walk around. However, don’t forget that Batch\n",
            "\n",
            "--- Chunk 3180 ---\n",
            "GD takes a lot of time to take each step, and Stochastic GD and Mini-batch GD\n",
            "would also reach the minimum if you used a good learning schedule.\n",
            "\n",
            "--- Chunk 3181 ---\n",
            "Figure 4-11. Gradient Descent paths in parameter space\n",
            "\n",
            "Gradient Descent | 127\n",
            "\n",
            "--- Chunk 3182 ---\n",
            "Let’s compare the algorithms we’ve discussed so far for Linear Regression6 (recall that\n",
            "\n",
            "--- Chunk 3183 ---\n",
            "m is the number of training instances and n is the number of features); see Table 4-1.\n",
            "\n",
            "--- Chunk 3184 ---\n",
            "Table 4-1. Comparison of algorithms for Linear Regression\n",
            "Algorithm Large m Out-of-core support Large n Hyperparams Scaling required Scikit-Learn\n",
            "\n",
            "--- Chunk 3185 ---\n",
            "Normal Equation Fast No Slow 0 No N/A\n",
            "SVD Fast No Slow 0 No LinearRegression\n",
            "\n",
            "--- Chunk 3186 ---\n",
            "Batch GD Slow No Fast 2 Yes SGDRegressor\n",
            "\n",
            "Stochastic GD Fast Yes Fast ≥2 Yes SGDRegressor\n",
            "\n",
            "Mini-batch GD Fast Yes Fast ≥2 Yes SGDRegressor\n",
            "\n",
            "--- Chunk 3187 ---\n",
            "There is almost no difference after training: all these algorithms\n",
            "end up with very similar models and make predictions in exactly\n",
            "the same way.\n",
            "\n",
            "--- Chunk 3188 ---\n",
            "Polynomial Regression\n",
            "What if your data is more complex than a straight line? Surprisingly, you can use a\n",
            "\n",
            "--- Chunk 3189 ---\n",
            "linear model to fit nonlinear data. A simple way to do this is to add powers of each\n",
            "\n",
            "--- Chunk 3190 ---\n",
            "feature as new features, then train a linear model on this extended set of features. This\n",
            "technique is called Polynomial Regression.\n",
            "\n",
            "--- Chunk 3191 ---\n",
            "Let’s look at an example. First, let’s generate some nonlinear data, based on a simple\n",
            "quadratic equation7 (plus some noise; see Figure 4-12):\n",
            "\n",
            "--- Chunk 3192 ---\n",
            "m = 100\n",
            "X = 6 * np.random.rand(m, 1) - 3\n",
            "y = 0.5 * X**2 + X + 2 + np.random.randn(m, 1)\n",
            "\n",
            "--- Chunk 3193 ---\n",
            "6 While the Normal Equation can only perform Linear Regression, the Gradient Descent algorithms can be\n",
            "\n",
            "--- Chunk 3194 ---\n",
            "used to train many other models, as we will see.\n",
            "\n",
            "--- Chunk 3195 ---\n",
            "7 A quadratic equation is of the form y = ax2 + bx + c.\n",
            "\n",
            "128 | Chapter 4: Training Models\n",
            "\n",
            "\n",
            "\n",
            "Figure 4-12. Generated nonlinear and noisy dataset\n",
            "\n",
            "--- Chunk 3196 ---\n",
            "Clearly, a straight line will never fit this data properly. So let’s use Scikit-Learn’s Poly\n",
            "\n",
            "--- Chunk 3197 ---\n",
            "nomialFeatures class to transform our training data, adding the square (second-\n",
            "\n",
            "--- Chunk 3198 ---\n",
            "degree polynomial) of each feature in the training set as a new feature (in this case\n",
            "there is just one feature):\n",
            "\n",
            "--- Chunk 3199 ---\n",
            ">>> from sklearn.preprocessing import PolynomialFeatures\n",
            ">>> poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
            "\n",
            "--- Chunk 3200 ---\n",
            ">>> X_poly = poly_features.fit_transform(X)\n",
            ">>> X[0]\n",
            "array([-0.75275929])\n",
            ">>> X_poly[0]\n",
            "array([-0.75275929, 0.56664654])\n",
            "\n",
            "--- Chunk 3201 ---\n",
            "X_poly now contains the original feature of X plus the square of this feature. Now you\n",
            "\n",
            "--- Chunk 3202 ---\n",
            "can fit a LinearRegression model to this extended training data (Figure 4-13):\n",
            "\n",
            "--- Chunk 3203 ---\n",
            ">>> lin_reg = LinearRegression()\n",
            ">>> lin_reg.fit(X_poly, y)\n",
            ">>> lin_reg.intercept_, lin_reg.coef_\n",
            "\n",
            "--- Chunk 3204 ---\n",
            "(array([1.78134581]), array([[0.93366893, 0.56456263]]))\n",
            "\n",
            "--- Chunk 3205 ---\n",
            "Polynomial Regression | 129\n",
            "\n",
            "\n",
            "\n",
            "Figure 4-13. Polynomial Regression model predictions\n",
            "\n",
            "--- Chunk 3206 ---\n",
            "Not bad: the model estimates y = 0.56x 2\n",
            "1 + 0.93x1 + 1.78 when in fact the original\n",
            "\n",
            "function was y = 0.5x 2\n",
            "1 + 1.0x1 + 2.0 + Gaussian noise.\n",
            "\n",
            "--- Chunk 3207 ---\n",
            "Note that when there are multiple features, Polynomial Regression is capable of find‐\n",
            "\n",
            "--- Chunk 3208 ---\n",
            "ing relationships between features (which is something a plain Linear Regression\n",
            "\n",
            "--- Chunk 3209 ---\n",
            "model cannot do). This is made possible by the fact that PolynomialFeatures also\n",
            "\n",
            "--- Chunk 3210 ---\n",
            "adds all combinations of features up to the given degree. For example, if there were\n",
            "\n",
            "--- Chunk 3211 ---\n",
            "two features a and b, PolynomialFeatures with degree=3 would not only add the\n",
            "\n",
            "--- Chunk 3212 ---\n",
            "features a2, a3, b2, and b3, but also the combinations ab, a2b, and ab2.\n",
            "\n",
            "--- Chunk 3213 ---\n",
            "PolynomialFeatures(degree=d) transforms an array containing n\n",
            "features into an array containing (n + d)! / d!n! features, where n! is\n",
            "\n",
            "--- Chunk 3214 ---\n",
            "the factorial of n, equal to 1 × 2 × 3 × ⋯ × n. Beware of the combi‐\n",
            "natorial explosion of the number of features!\n",
            "\n",
            "--- Chunk 3215 ---\n",
            "Learning Curves\n",
            "If you perform high-degree Polynomial Regression, you will likely fit the training\n",
            "\n",
            "--- Chunk 3216 ---\n",
            "data much better than with plain Linear Regression. For example, Figure 4-14 applies\n",
            "\n",
            "--- Chunk 3217 ---\n",
            "a 300-degree polynomial model to the preceding training data, and compares the\n",
            "\n",
            "--- Chunk 3218 ---\n",
            "result with a pure linear model and a quadratic model (second-degree polynomial).\n",
            "\n",
            "--- Chunk 3219 ---\n",
            "Notice how the 300-degree polynomial model wiggles around to get as close as possi‐\n",
            "ble to the training instances.\n",
            "\n",
            "--- Chunk 3220 ---\n",
            "130 | Chapter 4: Training Models\n",
            "\n",
            "\n",
            "\n",
            "Figure 4-14. High-degree Polynomial Regression\n",
            "\n",
            "--- Chunk 3221 ---\n",
            "This high-degree Polynomial Regression model is severely overfitting the training\n",
            "\n",
            "--- Chunk 3222 ---\n",
            "data, while the linear model is underfitting it. The model that will generalize best in\n",
            "\n",
            "--- Chunk 3223 ---\n",
            "this case is the quadratic model, which makes sense because the data was generated\n",
            "\n",
            "--- Chunk 3224 ---\n",
            "using a quadratic model. But in general you won’t know what function generated the\n",
            "\n",
            "--- Chunk 3225 ---\n",
            "data, so how can you decide how complex your model should be? How can you tell\n",
            "that your model is overfitting or underfitting the data?\n",
            "\n",
            "--- Chunk 3226 ---\n",
            "In Chapter 2 you used cross-validation to get an estimate of a model’s generalization\n",
            "\n",
            "--- Chunk 3227 ---\n",
            "performance. If a model performs well on the training data but generalizes poorly\n",
            "\n",
            "--- Chunk 3228 ---\n",
            "according to the cross-validation metrics, then your model is overfitting. If it per‐\n",
            "\n",
            "--- Chunk 3229 ---\n",
            "forms poorly on both, then it is underfitting. This is one way to tell when a model is\n",
            "too simple or too complex.\n",
            "\n",
            "--- Chunk 3230 ---\n",
            "Another way to tell is to look at the learning curves: these are plots of the model’s per‐\n",
            "\n",
            "--- Chunk 3231 ---\n",
            "formance on the training set and the validation set as a function of the training set\n",
            "\n",
            "--- Chunk 3232 ---\n",
            "size (or the training iteration). To generate the plots, train the model several times on\n",
            "\n",
            "--- Chunk 3233 ---\n",
            "different sized subsets of the training set. The following code defines a function that,\n",
            "\n",
            "--- Chunk 3234 ---\n",
            "given some training data, plots the learning curves of a model:\n",
            "\n",
            "--- Chunk 3235 ---\n",
            "Learning Curves | 131\n",
            "\n",
            "\n",
            "\n",
            "from sklearn.metrics import mean_squared_error\n",
            "from sklearn.model_selection import train_test_split\n",
            "\n",
            "--- Chunk 3236 ---\n",
            "def plot_learning_curves(model, X, y):\n",
            "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
            "\n",
            "--- Chunk 3237 ---\n",
            "train_errors, val_errors = [], []\n",
            "    for m in range(1, len(X_train)):\n",
            "        model.fit(X_train[:m], y_train[:m])\n",
            "\n",
            "--- Chunk 3238 ---\n",
            "y_train_predict = model.predict(X_train[:m])\n",
            "        y_val_predict = model.predict(X_val)\n",
            "\n",
            "--- Chunk 3239 ---\n",
            "train_errors.append(mean_squared_error(y_train[:m], y_train_predict))\n",
            "        val_errors.append(mean_squared_error(y_val, y_val_predict))\n",
            "\n",
            "--- Chunk 3240 ---\n",
            "plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
            "    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")\n",
            "\n",
            "--- Chunk 3241 ---\n",
            "Let’s look at the learning curves of the plain Linear Regression model (a straight line;\n",
            "see Figure 4-15):\n",
            "\n",
            "--- Chunk 3242 ---\n",
            "lin_reg = LinearRegression()\n",
            "plot_learning_curves(lin_reg, X, y)\n",
            "\n",
            "Figure 4-15. Learning curves\n",
            "\n",
            "--- Chunk 3243 ---\n",
            "This model that’s underfitting deserves a bit of explanation. First, let’s look at the per‐\n",
            "\n",
            "--- Chunk 3244 ---\n",
            "formance on the training data: when there are just one or two instances in the train‐\n",
            "\n",
            "--- Chunk 3245 ---\n",
            "ing set, the model can fit them perfectly, which is why the curve starts at zero. But as\n",
            "\n",
            "--- Chunk 3246 ---\n",
            "new instances are added to the training set, it becomes impossible for the model to fit\n",
            "\n",
            "--- Chunk 3247 ---\n",
            "the training data perfectly, both because the data is noisy and because it is not linear\n",
            "\n",
            "--- Chunk 3248 ---\n",
            "at all. So the error on the training data goes up until it reaches a plateau, at which\n",
            "\n",
            "--- Chunk 3249 ---\n",
            "point adding new instances to the training set doesn’t make the average error much\n",
            "\n",
            "--- Chunk 3250 ---\n",
            "better or worse. Now let’s look at the performance of the model on the validation\n",
            "\n",
            "--- Chunk 3251 ---\n",
            "data. When the model is trained on very few training instances, it is incapable of gen‐\n",
            "\n",
            "--- Chunk 3252 ---\n",
            "eralizing properly, which is why the validation error is initially quite big. Then, as the\n",
            "\n",
            "--- Chunk 3253 ---\n",
            "132 | Chapter 4: Training Models\n",
            "\n",
            "--- Chunk 3254 ---\n",
            "model is shown more training examples, it learns, and thus the validation error\n",
            "\n",
            "--- Chunk 3255 ---\n",
            "slowly goes down. However, once again a straight line cannot do a good job modeling\n",
            "\n",
            "--- Chunk 3256 ---\n",
            "the data, so the error ends up at a plateau, very close to the other curve.\n",
            "\n",
            "--- Chunk 3257 ---\n",
            "These learning curves are typical of a model that’s underfitting. Both curves have\n",
            "reached a plateau; they are close and fairly high.\n",
            "\n",
            "--- Chunk 3258 ---\n",
            "If your model is underfitting the training data, adding more train‐\n",
            "ing examples will not help. You need to use a more complex model\n",
            "\n",
            "--- Chunk 3259 ---\n",
            "or come up with better features.\n",
            "\n",
            "--- Chunk 3260 ---\n",
            "Now let’s look at the learning curves of a 10th-degree polynomial model on the same\n",
            "data (Figure 4-16):\n",
            "\n",
            "from sklearn.pipeline import Pipeline\n",
            "\n",
            "--- Chunk 3261 ---\n",
            "polynomial_regression = Pipeline([\n",
            "        (\"poly_features\", PolynomialFeatures(degree=10, include_bias=False)),\n",
            "\n",
            "--- Chunk 3262 ---\n",
            "(\"lin_reg\", LinearRegression()),\n",
            "    ])\n",
            "\n",
            "--- Chunk 3263 ---\n",
            "plot_learning_curves(polynomial_regression, X, y)\n",
            "\n",
            "Figure 4-16. Learning curves for the 10th-degree polynomial model\n",
            "\n",
            "--- Chunk 3264 ---\n",
            "These learning curves look a bit like the previous ones, but there are two very impor‐\n",
            "tant differences:\n",
            "\n",
            "--- Chunk 3265 ---\n",
            "• The error on the training data is much lower than with the Linear Regression\n",
            "model.\n",
            "\n",
            "Learning Curves | 133\n",
            "\n",
            "--- Chunk 3266 ---\n",
            "• There is a gap between the curves. This means that the model performs signifi‐\n",
            "\n",
            "--- Chunk 3267 ---\n",
            "cantly better on the training data than on the validation data, which is the hall‐\n",
            "\n",
            "--- Chunk 3268 ---\n",
            "mark of an overfitting model. If you used a much larger training set, however, the\n",
            "two curves would continue to get closer.\n",
            "\n",
            "--- Chunk 3269 ---\n",
            "One way to improve an overfitting model is to feed it more training\n",
            "data until the validation error reaches the training error.\n",
            "\n",
            "--- Chunk 3270 ---\n",
            "The Bias/Variance Trade-off\n",
            "An important theoretical result of statistics and Machine Learning is the fact that a\n",
            "\n",
            "--- Chunk 3271 ---\n",
            "model’s generalization error can be expressed as the sum of three very different\n",
            "errors:\n",
            "Bias\n",
            "\n",
            "--- Chunk 3272 ---\n",
            "This part of the generalization error is due to wrong assumptions, such as assum‐\n",
            "\n",
            "--- Chunk 3273 ---\n",
            "ing that the data is linear when it is actually quadratic. A high-bias model is most\n",
            "likely to underfit the training data.8\n",
            "\n",
            "--- Chunk 3274 ---\n",
            "Variance\n",
            "This part is due to the model’s excessive sensitivity to small variations in the\n",
            "\n",
            "--- Chunk 3275 ---\n",
            "training data. A model with many degrees of freedom (such as a high-degree pol‐\n",
            "\n",
            "--- Chunk 3276 ---\n",
            "ynomial model) is likely to have high variance and thus overfit the training data.\n",
            "\n",
            "--- Chunk 3277 ---\n",
            "Irreducible error\n",
            "This part is due to the noisiness of the data itself. The only way to reduce this\n",
            "\n",
            "--- Chunk 3278 ---\n",
            "part of the error is to clean up the data (e.g., fix the data sources, such as broken\n",
            "sensors, or detect and remove outliers).\n",
            "\n",
            "--- Chunk 3279 ---\n",
            "Increasing a model’s complexity will typically increase its variance and reduce its bias.\n",
            "\n",
            "--- Chunk 3280 ---\n",
            "Conversely, reducing a model’s complexity increases its bias and reduces its variance.\n",
            "This is why it is called a trade-off.\n",
            "\n",
            "--- Chunk 3281 ---\n",
            "Regularized Linear Models\n",
            "As we saw in Chapters 1 and 2, a good way to reduce overfitting is to regularize the\n",
            "\n",
            "--- Chunk 3282 ---\n",
            "model (i.e., to constrain it): the fewer degrees of freedom it has, the harder it will be\n",
            "\n",
            "--- Chunk 3283 ---\n",
            "8 This notion of bias is not to be confused with the bias term of linear models.\n",
            "\n",
            "134 | Chapter 4: Training Models\n",
            "\n",
            "--- Chunk 3284 ---\n",
            "for it to overfit the data. A simple way to regularize a polynomial model is to reduce\n",
            "the number of polynomial degrees.\n",
            "\n",
            "--- Chunk 3285 ---\n",
            "For a linear model, regularization is typically achieved by constraining the weights of\n",
            "\n",
            "--- Chunk 3286 ---\n",
            "the model. We will now look at Ridge Regression, Lasso Regression, and Elastic Net,\n",
            "which implement three different ways to constrain the weights.\n",
            "\n",
            "--- Chunk 3287 ---\n",
            "Ridge Regression\n",
            "Ridge Regression (also called Tikhonov regularization) is a regularized version of Lin‐\n",
            "\n",
            "--- Chunk 3288 ---\n",
            "ear Regression: a regularization term equal to α∑n\n",
            "\n",
            "--- Chunk 3289 ---\n",
            "i = 1 θ 2\n",
            "i  is added to the cost function.\n",
            "\n",
            "--- Chunk 3290 ---\n",
            "This forces the learning algorithm to not only fit the data but also keep the model\n",
            "\n",
            "--- Chunk 3291 ---\n",
            "weights as small as possible. Note that the regularization term should only be added\n",
            "\n",
            "--- Chunk 3292 ---\n",
            "to the cost function during training. Once the model is trained, you want to use the\n",
            "\n",
            "--- Chunk 3293 ---\n",
            "unregularized performance measure to evaluate the model’s performance.\n",
            "\n",
            "--- Chunk 3294 ---\n",
            "It is quite common for the cost function used during training to be\n",
            "different from the performance measure used for testing. Apart\n",
            "\n",
            "--- Chunk 3295 ---\n",
            "from regularization, another reason they might be different is that a\n",
            "good training cost function should have optimization-friendly\n",
            "\n",
            "--- Chunk 3296 ---\n",
            "derivatives, while the performance measure used for testing should\n",
            "be as close as possible to the final objective. For example, classifiers\n",
            "\n",
            "--- Chunk 3297 ---\n",
            "are often trained using a cost function such as the log loss (dis‐\n",
            "cussed in a moment) but evaluated using precision/recall.\n",
            "\n",
            "--- Chunk 3298 ---\n",
            "The hyperparameter α controls how much you want to regularize the model. If α = 0,\n",
            "\n",
            "--- Chunk 3299 ---\n",
            "then Ridge Regression is just Linear Regression. If α is very large, then all weights end\n",
            "\n",
            "--- Chunk 3300 ---\n",
            "up very close to zero and the result is a flat line going through the data’s mean. Equa‐\n",
            "tion 4-8 presents the Ridge Regression cost function.9\n",
            "\n",
            "--- Chunk 3301 ---\n",
            "Equation 4-8. Ridge Regression cost function\n",
            "\n",
            "J θ = MSE θ + α 1\n",
            "2 ∑n θ 2\n",
            "\n",
            "i = 1 i\n",
            "\n",
            "--- Chunk 3302 ---\n",
            "Note that the bias term θ0 is not regularized (the sum starts at i = 1, not 0). If we\n",
            "\n",
            "--- Chunk 3303 ---\n",
            "define w as the vector of feature weights (θ1 to θn), then the regularization term is\n",
            "\n",
            "--- Chunk 3304 ---\n",
            "9 It is common to use the notation J(θ) for cost functions that don’t have a short name; we will often use this\n",
            "\n",
            "--- Chunk 3305 ---\n",
            "notation throughout the rest of this book. The context will make it clear which cost function is being dis‐\n",
            "cussed.\n",
            "\n",
            "--- Chunk 3306 ---\n",
            "Regularized Linear Models | 135\n",
            "\n",
            "--- Chunk 3307 ---\n",
            "equal to ½(∥ w ∥2)2, where ∥ w ∥2 represents the ℓ2 norm of the weight vector.10 For\n",
            "\n",
            "--- Chunk 3308 ---\n",
            "Gradient Descent, just add αw to the MSE gradient vector (Equation 4-6).\n",
            "\n",
            "--- Chunk 3309 ---\n",
            "It is important to scale the data (e.g., using a StandardScaler)\n",
            "before performing Ridge Regression, as it is sensitive to the scale of\n",
            "\n",
            "--- Chunk 3310 ---\n",
            "the input features. This is true of most regularized models.\n",
            "\n",
            "--- Chunk 3311 ---\n",
            "Figure 4-17 shows several Ridge models trained on some linear data using different α\n",
            "\n",
            "--- Chunk 3312 ---\n",
            "values. On the left, plain Ridge models are used, leading to linear predictions. On the\n",
            "\n",
            "--- Chunk 3313 ---\n",
            "right, the data is first expanded using PolynomialFeatures(degree=10), then it is\n",
            "\n",
            "--- Chunk 3314 ---\n",
            "scaled using a StandardScaler, and finally the Ridge models are applied to the result‐\n",
            "\n",
            "--- Chunk 3315 ---\n",
            "ing features: this is Polynomial Regression with Ridge regularization. Note how\n",
            "\n",
            "--- Chunk 3316 ---\n",
            "increasing α leads to flatter (i.e., less extreme, more reasonable) predictions, thus\n",
            "reducing the model’s variance but increasing its bias.\n",
            "\n",
            "--- Chunk 3317 ---\n",
            "Figure 4-17. A linear model (left) and a polynomial model (right), both with various lev‐\n",
            "els of Ridge regularization\n",
            "\n",
            "--- Chunk 3318 ---\n",
            "As with Linear Regression, we can perform Ridge Regression either by computing a\n",
            "\n",
            "--- Chunk 3319 ---\n",
            "closed-form equation or by performing Gradient Descent. The pros and cons are the\n",
            "\n",
            "--- Chunk 3320 ---\n",
            "10 Norms are discussed in Chapter 2.\n",
            "\n",
            "136 | Chapter 4: Training Models\n",
            "\n",
            "--- Chunk 3321 ---\n",
            "same. Equation 4-9 shows the closed-form solution, where A is the (n + 1) × (n + 1)\n",
            "\n",
            "--- Chunk 3322 ---\n",
            "identity matrix,11 except with a 0 in the top-left cell, corresponding to the bias term.\n",
            "\n",
            "--- Chunk 3323 ---\n",
            "Equation 4-9. Ridge Regression closed-form solution\n",
            "\n",
            "θ = X⊺X + αA −1   X⊺   y\n",
            "\n",
            "--- Chunk 3324 ---\n",
            "Here is how to perform Ridge Regression with Scikit-Learn using a closed-form solu‐\n",
            "\n",
            "--- Chunk 3325 ---\n",
            "tion (a variant of Equation 4-9 that uses a matrix factorization technique by André-\n",
            "Louis Cholesky):\n",
            "\n",
            "--- Chunk 3326 ---\n",
            ">>> from sklearn.linear_model import Ridge\n",
            ">>> ridge_reg = Ridge(alpha=1, solver=\"cholesky\")\n",
            ">>> ridge_reg.fit(X, y)\n",
            ">>> ridge_reg.predict([[1.5]])\n",
            "\n",
            "--- Chunk 3327 ---\n",
            "array([[1.55071465]])\n",
            "\n",
            "--- Chunk 3328 ---\n",
            "And using Stochastic Gradient Descent:12\n",
            "\n",
            "--- Chunk 3329 ---\n",
            ">>> sgd_reg = SGDRegressor(penalty=\"l2\")\n",
            ">>> sgd_reg.fit(X, y.ravel())\n",
            ">>> sgd_reg.predict([[1.5]])\n",
            "array([1.47012588])\n",
            "\n",
            "--- Chunk 3330 ---\n",
            "The penalty hyperparameter sets the type of regularization term to use. Specifying\n",
            "\n",
            "--- Chunk 3331 ---\n",
            "\"l2\" indicates that you want SGD to add a regularization term to the cost function\n",
            "\n",
            "--- Chunk 3332 ---\n",
            "equal to half the square of the ℓ2 norm of the weight vector: this is simply Ridge\n",
            "Regression.\n",
            "\n",
            "--- Chunk 3333 ---\n",
            "Lasso Regression\n",
            "Least Absolute Shrinkage and Selection Operator Regression (usually simply called\n",
            "\n",
            "--- Chunk 3334 ---\n",
            "Lasso Regression) is another regularized version of Linear Regression: just like Ridge\n",
            "\n",
            "--- Chunk 3335 ---\n",
            "Regression, it adds a regularization term to the cost function, but it uses the ℓ1 norm\n",
            "\n",
            "--- Chunk 3336 ---\n",
            "of the weight vector instead of half the square of the ℓ2 norm (see Equation 4-10).\n",
            "\n",
            "--- Chunk 3337 ---\n",
            "Equation 4-10. Lasso Regression cost function\n",
            "J θ = MSE θ + α∑n\n",
            "\n",
            "i = 1 θi\n",
            "\n",
            "--- Chunk 3338 ---\n",
            "11 A square matrix full of 0s except for 1s on the main diagonal (top left to bottom right).\n",
            "\n",
            "--- Chunk 3339 ---\n",
            "12 Alternatively you can use the Ridge class with the \"sag\" solver. Stochastic Average GD is a variant of Stochas‐\n",
            "\n",
            "--- Chunk 3340 ---\n",
            "tic GD. For more details, see the presentation “Minimizing Finite Sums with the Stochastic Average Gradient\n",
            "\n",
            "--- Chunk 3341 ---\n",
            "Algorithm” by Mark Schmidt et al. from the University of British Columbia.\n",
            "\n",
            "--- Chunk 3342 ---\n",
            "Regularized Linear Models | 137\n",
            "\n",
            "--- Chunk 3343 ---\n",
            "Figure 4-18 shows the same thing as Figure 4-17 but replaces Ridge models with\n",
            "Lasso models and uses smaller α values.\n",
            "\n",
            "--- Chunk 3344 ---\n",
            "Figure 4-18. A linear model (left) and a polynomial model (right), both using various\n",
            "levels of Lasso regularization\n",
            "\n",
            "--- Chunk 3345 ---\n",
            "An important characteristic of Lasso Regression is that it tends to eliminate the\n",
            "\n",
            "--- Chunk 3346 ---\n",
            "weights of the least important features (i.e., set them to zero). For example, the\n",
            "\n",
            "--- Chunk 3347 ---\n",
            "dashed line in the righthand plot in Figure 4-18 (with α = 10-7) looks quadratic,\n",
            "\n",
            "--- Chunk 3348 ---\n",
            "almost linear: all the weights for the high-degree polynomial features are equal to\n",
            "\n",
            "--- Chunk 3349 ---\n",
            "zero. In other words, Lasso Regression automatically performs feature selection and\n",
            "outputs a sparse model (i.e., with few nonzero feature weights).\n",
            "\n",
            "--- Chunk 3350 ---\n",
            "You can get a sense of why this is the case by looking at Figure 4-19: the axes repre‐\n",
            "\n",
            "--- Chunk 3351 ---\n",
            "sent two model parameters, and the background contours represent different loss\n",
            "\n",
            "--- Chunk 3352 ---\n",
            "functions. In the top-left plot, the contours represent the ℓ1 loss (|θ1| + |θ2|), which\n",
            "\n",
            "--- Chunk 3353 ---\n",
            "drops linearly as you get closer to any axis. For example, if you initialize the model\n",
            "\n",
            "--- Chunk 3354 ---\n",
            "parameters to θ1 = 2 and θ2 = 0.5, running Gradient Descent will decrement both\n",
            "\n",
            "--- Chunk 3355 ---\n",
            "parameters equally (as represented by the dashed yellow line); therefore θ2 will reach\n",
            "\n",
            "--- Chunk 3356 ---\n",
            "0 first (since it was closer to 0 to begin with). After that, Gradient Descent will roll\n",
            "\n",
            "--- Chunk 3357 ---\n",
            "down the gutter until it reaches θ1 = 0 (with a bit of bouncing around, since the gradi‐\n",
            "\n",
            "--- Chunk 3358 ---\n",
            "ents of ℓ1 never get close to 0: they are either –1 or 1 for each parameter). In the top-\n",
            "\n",
            "--- Chunk 3359 ---\n",
            "right plot, the contours represent Lasso’s cost function (i.e., an MSE cost function plus\n",
            "\n",
            "--- Chunk 3360 ---\n",
            "an ℓ1 loss). The small white circles show the path that Gradient Descent takes to opti‐\n",
            "\n",
            "--- Chunk 3361 ---\n",
            "mize some model parameters that were initialized around θ1 = 0.25 and θ2 = –1:\n",
            "\n",
            "--- Chunk 3362 ---\n",
            "notice once again how the path quickly reaches θ2 = 0, then rolls down the gutter and\n",
            "\n",
            "--- Chunk 3363 ---\n",
            "ends up bouncing around the global optimum (represented by the red square). If we\n",
            "\n",
            "--- Chunk 3364 ---\n",
            "increased α, the global optimum would move left along the dashed yellow line, while\n",
            "\n",
            "--- Chunk 3365 ---\n",
            "138 | Chapter 4: Training Models\n",
            "\n",
            "--- Chunk 3366 ---\n",
            "if we decreased α, the global optimum would move right (in this example, the optimal\n",
            "parameters for the unregularized MSE are θ1 = 2 and θ2 = 0.5).\n",
            "\n",
            "--- Chunk 3367 ---\n",
            "Figure 4-19. Lasso versus Ridge regularization\n",
            "\n",
            "--- Chunk 3368 ---\n",
            "The two bottom plots show the same thing but with an ℓ2 penalty instead. In the\n",
            "\n",
            "--- Chunk 3369 ---\n",
            "bottom-left plot, you can see that the ℓ2 loss decreases with the distance to the origin,\n",
            "\n",
            "--- Chunk 3370 ---\n",
            "so Gradient Descent just takes a straight path toward that point. In the bottom-right\n",
            "\n",
            "--- Chunk 3371 ---\n",
            "plot, the contours represent Ridge Regression’s cost function (i.e., an MSE cost func‐\n",
            "\n",
            "--- Chunk 3372 ---\n",
            "tion plus an ℓ2 loss). There are two main differences with Lasso. First, the gradients\n",
            "\n",
            "--- Chunk 3373 ---\n",
            "get smaller as the parameters approach the global optimum, so Gradient Descent nat‐\n",
            "\n",
            "--- Chunk 3374 ---\n",
            "urally slows down, which helps convergence (as there is no bouncing around). Sec‐\n",
            "\n",
            "--- Chunk 3375 ---\n",
            "ond, the optimal parameters (represented by the red square) get closer and closer to\n",
            "\n",
            "--- Chunk 3376 ---\n",
            "the origin when you increase α, but they never get eliminated entirely.\n",
            "\n",
            "--- Chunk 3377 ---\n",
            "To avoid Gradient Descent from bouncing around the optimum at\n",
            "the end when using Lasso, you need to gradually reduce the learn‐\n",
            "\n",
            "--- Chunk 3378 ---\n",
            "ing rate during training (it will still bounce around the optimum,\n",
            "but the steps will get smaller and smaller, so it will converge).\n",
            "\n",
            "--- Chunk 3379 ---\n",
            "Regularized Linear Models | 139\n",
            "\n",
            "--- Chunk 3380 ---\n",
            "The Lasso cost function is not differentiable at θi = 0 (for i = 1, 2, ⋯, n), but Gradient\n",
            "\n",
            "--- Chunk 3381 ---\n",
            "Descent still works fine if you use a subgradient vector g13 instead when any θi = 0.\n",
            "\n",
            "--- Chunk 3382 ---\n",
            "Equation 4-11 shows a subgradient vector equation you can use for Gradient Descent\n",
            "with the Lasso cost function.\n",
            "\n",
            "--- Chunk 3383 ---\n",
            "Equation 4-11. Lasso Regression subgradient vector\n",
            "sign θ1 −1 if θi < 0\n",
            "sign θ\n",
            "\n",
            "g θ, J = ∇θ MSE θ + α 2    where  sign θi = 0 if θi = 0\n",
            "⋮ +1 if θ\n",
            "\n",
            "--- Chunk 3384 ---\n",
            "sign θ i > 0\n",
            "n\n",
            "\n",
            "--- Chunk 3385 ---\n",
            "Here is a small Scikit-Learn example using the Lasso class:\n",
            ">>> from sklearn.linear_model import Lasso\n",
            ">>> lasso_reg = Lasso(alpha=0.1)\n",
            "\n",
            "--- Chunk 3386 ---\n",
            ">>> lasso_reg.fit(X, y)\n",
            ">>> lasso_reg.predict([[1.5]])\n",
            "array([1.53788174])\n",
            "\n",
            "--- Chunk 3387 ---\n",
            "Note that you could instead use SGDRegressor(penalty=\"l1\").\n",
            "\n",
            "--- Chunk 3388 ---\n",
            "Elastic Net\n",
            "Elastic Net is a middle ground between Ridge Regression and Lasso Regression. The\n",
            "\n",
            "--- Chunk 3389 ---\n",
            "regularization term is a simple mix of both Ridge and Lasso’s regularization terms,\n",
            "\n",
            "--- Chunk 3390 ---\n",
            "and you can control the mix ratio r. When r = 0, Elastic Net is equivalent to Ridge\n",
            "\n",
            "--- Chunk 3391 ---\n",
            "Regression, and when r = 1, it is equivalent to Lasso Regression (see Equation 4-12).\n",
            "\n",
            "--- Chunk 3392 ---\n",
            "Equation 4-12. Elastic Net cost function\n",
            "\n",
            "J θ = MSE θ + rα∑n\n",
            "i = 1 θi + 1 − r\n",
            "\n",
            "2 α∑n 2\n",
            "i = 1 θi\n",
            "\n",
            "--- Chunk 3393 ---\n",
            "So when should you use plain Linear Regression (i.e., without any regularization),\n",
            "\n",
            "--- Chunk 3394 ---\n",
            "Ridge, Lasso, or Elastic Net? It is almost always preferable to have at least a little bit of\n",
            "\n",
            "--- Chunk 3395 ---\n",
            "regularization, so generally you should avoid plain Linear Regression. Ridge is a good\n",
            "\n",
            "--- Chunk 3396 ---\n",
            "default, but if you suspect that only a few features are useful, you should prefer Lasso\n",
            "\n",
            "--- Chunk 3397 ---\n",
            "or Elastic Net because they tend to reduce the useless features’ weights down to zero,\n",
            "\n",
            "--- Chunk 3398 ---\n",
            "as we have discussed. In general, Elastic Net is preferred over Lasso because Lasso\n",
            "\n",
            "--- Chunk 3399 ---\n",
            "13 You can think of a subgradient vector at a nondifferentiable point as an intermediate vector between the gra‐\n",
            "dient vectors around that point.\n",
            "\n",
            "--- Chunk 3400 ---\n",
            "140 | Chapter 4: Training Models\n",
            "\n",
            "--- Chunk 3401 ---\n",
            "may behave erratically when the number of features is greater than the number of\n",
            "\n",
            "--- Chunk 3402 ---\n",
            "training instances or when several features are strongly correlated.\n",
            "\n",
            "--- Chunk 3403 ---\n",
            "Here is a short example that uses Scikit-Learn’s ElasticNet (l1_ratio corresponds to\n",
            "the mix ratio r):\n",
            "\n",
            "--- Chunk 3404 ---\n",
            ">>> from sklearn.linear_model import ElasticNet\n",
            ">>> elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
            ">>> elastic_net.fit(X, y)\n",
            "\n",
            "--- Chunk 3405 ---\n",
            ">>> elastic_net.predict([[1.5]])\n",
            "array([1.54333232])\n",
            "\n",
            "--- Chunk 3406 ---\n",
            "Early Stopping\n",
            "A very different way to regularize iterative learning algorithms such as Gradient\n",
            "\n",
            "--- Chunk 3407 ---\n",
            "Descent is to stop training as soon as the validation error reaches a minimum. This is\n",
            "\n",
            "--- Chunk 3408 ---\n",
            "called early stopping. Figure 4-20 shows a complex model (in this case, a high-degree\n",
            "\n",
            "--- Chunk 3409 ---\n",
            "Polynomial Regression model) being trained with Batch Gradient Descent. As the\n",
            "\n",
            "--- Chunk 3410 ---\n",
            "epochs go by the algorithm learns, and its prediction error (RMSE) on the training\n",
            "\n",
            "--- Chunk 3411 ---\n",
            "set goes down, along with its prediction error on the validation set. After a while\n",
            "\n",
            "--- Chunk 3412 ---\n",
            "though, the validation error stops decreasing and starts to go back up. This indicates\n",
            "\n",
            "--- Chunk 3413 ---\n",
            "that the model has started to overfit the training data. With early stopping you just\n",
            "\n",
            "--- Chunk 3414 ---\n",
            "stop training as soon as the validation error reaches the minimum. It is such a simple\n",
            "\n",
            "--- Chunk 3415 ---\n",
            "and efficient regularization technique that Geoffrey Hinton called it a “beautiful free\n",
            "lunch.”\n",
            "\n",
            "--- Chunk 3416 ---\n",
            "Figure 4-20. Early stopping regularization\n",
            "\n",
            "Regularized Linear Models | 141\n",
            "\n",
            "--- Chunk 3417 ---\n",
            "With Stochastic and Mini-batch Gradient Descent, the curves are\n",
            "not so smooth, and it may be hard to know whether you have\n",
            "\n",
            "--- Chunk 3418 ---\n",
            "reached the minimum or not. One solution is to stop only after the\n",
            "validation error has been above the minimum for some time (when\n",
            "\n",
            "--- Chunk 3419 ---\n",
            "you are confident that the model will not do any better), then roll\n",
            "back the model parameters to the point where the validation error\n",
            "\n",
            "--- Chunk 3420 ---\n",
            "was at a minimum.\n",
            "\n",
            "--- Chunk 3421 ---\n",
            "Here is a basic implementation of early stopping:\n",
            "from sklearn.base import clone\n",
            "\n",
            "--- Chunk 3422 ---\n",
            "# prepare the data\n",
            "poly_scaler = Pipeline([\n",
            "        (\"poly_features\", PolynomialFeatures(degree=90, include_bias=False)),\n",
            "\n",
            "--- Chunk 3423 ---\n",
            "(\"std_scaler\", StandardScaler())\n",
            "    ])\n",
            "X_train_poly_scaled = poly_scaler.fit_transform(X_train)\n",
            "\n",
            "--- Chunk 3424 ---\n",
            "X_val_poly_scaled = poly_scaler.transform(X_val)\n",
            "\n",
            "--- Chunk 3425 ---\n",
            "sgd_reg = SGDRegressor(max_iter=1, tol=-np.infty, warm_start=True,\n",
            "                       penalty=None, learning_rate=\"constant\", eta0=0.0005)\n",
            "\n",
            "--- Chunk 3426 ---\n",
            "minimum_val_error = float(\"inf\")\n",
            "best_epoch = None\n",
            "best_model = None\n",
            "for epoch in range(1000):\n",
            "\n",
            "--- Chunk 3427 ---\n",
            "sgd_reg.fit(X_train_poly_scaled, y_train)  # continues where it left off\n",
            "    y_val_predict = sgd_reg.predict(X_val_poly_scaled)\n",
            "\n",
            "--- Chunk 3428 ---\n",
            "val_error = mean_squared_error(y_val, y_val_predict)\n",
            "    if val_error < minimum_val_error:\n",
            "        minimum_val_error = val_error\n",
            "\n",
            "--- Chunk 3429 ---\n",
            "best_epoch = epoch\n",
            "        best_model = clone(sgd_reg)\n",
            "\n",
            "--- Chunk 3430 ---\n",
            "Note that with warm_start=True, when the fit() method is called it continues train‐\n",
            "ing where it left off, instead of restarting from scratch.\n",
            "\n",
            "--- Chunk 3431 ---\n",
            "Logistic Regression\n",
            "As we discussed in Chapter 1, some regression algorithms can be used for classifica‐\n",
            "\n",
            "--- Chunk 3432 ---\n",
            "tion (and vice versa). Logistic Regression (also called Logit Regression) is commonly\n",
            "\n",
            "--- Chunk 3433 ---\n",
            "used to estimate the probability that an instance belongs to a particular class (e.g.,\n",
            "\n",
            "--- Chunk 3434 ---\n",
            "what is the probability that this email is spam?). If the estimated probability is greater\n",
            "\n",
            "--- Chunk 3435 ---\n",
            "than 50%, then the model predicts that the instance belongs to that class (called the\n",
            "\n",
            "--- Chunk 3436 ---\n",
            "positive class, labeled “1”), and otherwise it predicts that it does not (i.e., it belongs to\n",
            "\n",
            "--- Chunk 3437 ---\n",
            "the negative class, labeled “0”). This makes it a binary classifier.\n",
            "\n",
            "--- Chunk 3438 ---\n",
            "142 | Chapter 4: Training Models\n",
            "\n",
            "--- Chunk 3439 ---\n",
            "Estimating Probabilities\n",
            "So how does Logistic Regression work? Just like a Linear Regression model, a Logistic\n",
            "\n",
            "--- Chunk 3440 ---\n",
            "Regression model computes a weighted sum of the input features (plus a bias term),\n",
            "\n",
            "--- Chunk 3441 ---\n",
            "but instead of outputting the result directly like the Linear Regression model does, it\n",
            "outputs the logistic of this result (see Equation 4-13).\n",
            "\n",
            "--- Chunk 3442 ---\n",
            "Equation 4-13. Logistic Regression model estimated probability (vectorized form)\n",
            "p = hθ x = σ x⊺θ\n",
            "\n",
            "--- Chunk 3443 ---\n",
            "The logistic—noted σ(·)—is a sigmoid function (i.e., S-shaped) that outputs a number\n",
            "\n",
            "--- Chunk 3444 ---\n",
            "between 0 and 1. It is defined as shown in Equation 4-14 and Figure 4-21.\n",
            "\n",
            "--- Chunk 3445 ---\n",
            "Equation 4-14. Logistic function\n",
            "\n",
            "σ t = 1\n",
            "1 + exp − t\n",
            "\n",
            "Figure 4-21. Logistic function\n",
            "\n",
            "--- Chunk 3446 ---\n",
            "Once the Logistic Regression model has estimated the probability p = hθ(x) that an\n",
            "\n",
            "--- Chunk 3447 ---\n",
            "instance x belongs to the positive class, it can make its prediction ŷ easily (see Equa‐\n",
            "tion 4-15).\n",
            "\n",
            "--- Chunk 3448 ---\n",
            "Equation 4-15. Logistic Regression model prediction\n",
            "0 if p < 0.5\n",
            "\n",
            "y =\n",
            "1 if p ≥ 0.5\n",
            "\n",
            "--- Chunk 3449 ---\n",
            "Notice that σ(t) < 0.5 when t < 0, and σ(t) ≥ 0.5 when t ≥ 0, so a Logistic Regression\n",
            "model predicts 1 if x⊺ θ is positive and 0 if it is negative.\n",
            "\n",
            "--- Chunk 3450 ---\n",
            "Logistic Regression | 143\n",
            "\n",
            "--- Chunk 3451 ---\n",
            "The score t is often called the logit. The name comes from the fact\n",
            "that the logit function, defined as logit(p) = log(p / (1 – p)), is the\n",
            "\n",
            "--- Chunk 3452 ---\n",
            "inverse of the logistic function. Indeed, if you compute the logit of\n",
            "the estimated probability p, you will find that the result is t. The\n",
            "\n",
            "--- Chunk 3453 ---\n",
            "logit is also called the log-odds, since it is the log of the ratio\n",
            "between the estimated probability for the positive class and the\n",
            "\n",
            "--- Chunk 3454 ---\n",
            "estimated probability for the negative class.\n",
            "\n",
            "--- Chunk 3455 ---\n",
            "Training and Cost Function\n",
            "Now you know how a Logistic Regression model estimates probabilities and makes\n",
            "\n",
            "--- Chunk 3456 ---\n",
            "predictions. But how is it trained? The objective of training is to set the parameter\n",
            "\n",
            "--- Chunk 3457 ---\n",
            "vector θ so that the model estimates high probabilities for positive instances (y = 1)\n",
            "\n",
            "--- Chunk 3458 ---\n",
            "and low probabilities for negative instances (y = 0). This idea is captured by the cost\n",
            "\n",
            "--- Chunk 3459 ---\n",
            "function shown in Equation 4-16 for a single training instance x.\n",
            "\n",
            "--- Chunk 3460 ---\n",
            "Equation 4-16. Cost function of a single training instance\n",
            "−log p if y = 1\n",
            "\n",
            "c θ =\n",
            "−log 1 − p if y = 0\n",
            "\n",
            "--- Chunk 3461 ---\n",
            "This cost function makes sense because –log(t) grows very large when t approaches 0,\n",
            "\n",
            "--- Chunk 3462 ---\n",
            "so the cost will be large if the model estimates a probability close to 0 for a positive\n",
            "\n",
            "--- Chunk 3463 ---\n",
            "instance, and it will also be very large if the model estimates a probability close to 1\n",
            "\n",
            "--- Chunk 3464 ---\n",
            "for a negative instance. On the other hand, –log(t) is close to 0 when t is close to 1, so\n",
            "\n",
            "--- Chunk 3465 ---\n",
            "the cost will be close to 0 if the estimated probability is close to 0 for a negative\n",
            "\n",
            "--- Chunk 3466 ---\n",
            "instance or close to 1 for a positive instance, which is precisely what we want.\n",
            "\n",
            "--- Chunk 3467 ---\n",
            "The cost function over the whole training set is the average cost over all training\n",
            "\n",
            "--- Chunk 3468 ---\n",
            "instances. It can be written in a single expression called the log loss, shown in Equa‐\n",
            "tion 4-17.\n",
            "\n",
            "--- Chunk 3469 ---\n",
            "Equation 4-17. Logistic Regression cost function (log loss)\n",
            "\n",
            "J θ = − 1\n",
            "m ∑m\n",
            "\n",
            "i = y i\n",
            "1 log p i + 1 − y i log 1 − p i\n",
            "\n",
            "--- Chunk 3470 ---\n",
            "The bad news is that there is no known closed-form equation to compute the value of\n",
            "\n",
            "--- Chunk 3471 ---\n",
            "θ that minimizes this cost function (there is no equivalent of the Normal Equation).\n",
            "\n",
            "--- Chunk 3472 ---\n",
            "The good news is that this cost function is convex, so Gradient Descent (or any other\n",
            "\n",
            "--- Chunk 3473 ---\n",
            "optimization algorithm) is guaranteed to find the global minimum (if the learning\n",
            "\n",
            "--- Chunk 3474 ---\n",
            "144 | Chapter 4: Training Models\n",
            "\n",
            "--- Chunk 3475 ---\n",
            "rate is not too large and you wait long enough). The partial derivatives of the cost\n",
            "\n",
            "--- Chunk 3476 ---\n",
            "function with regard to the jth model parameter θj are given by Equation 4-18.\n",
            "\n",
            "--- Chunk 3477 ---\n",
            "Equation 4-18. Logistic cost function partial derivatives\n",
            "∂ m\n",
            "\n",
            "∂θ J θ = 1\n",
            "m ∑ σ θ⊺x i − y i x i\n",
            "\n",
            "i = 1 j\n",
            "j\n",
            "\n",
            "--- Chunk 3478 ---\n",
            "This equation looks very much like Equation 4-5: for each instance it computes the\n",
            "\n",
            "--- Chunk 3479 ---\n",
            "prediction error and multiplies it by the jth feature value, and then it computes the\n",
            "\n",
            "--- Chunk 3480 ---\n",
            "average over all training instances. Once you have the gradient vector containing all\n",
            "\n",
            "--- Chunk 3481 ---\n",
            "the partial derivatives, you can use it in the Batch Gradient Descent algorithm. That’s\n",
            "\n",
            "--- Chunk 3482 ---\n",
            "it: you now know how to train a Logistic Regression model. For Stochastic GD you\n",
            "\n",
            "--- Chunk 3483 ---\n",
            "would take one instance at a time, and for Mini-batch GD you would use a mini-\n",
            "batch at a time.\n",
            "\n",
            "--- Chunk 3484 ---\n",
            "Decision Boundaries\n",
            "Let’s use the iris dataset to illustrate Logistic Regression. This is a famous dataset that\n",
            "\n",
            "--- Chunk 3485 ---\n",
            "contains the sepal and petal length and width of 150 iris flowers of three different\n",
            "\n",
            "--- Chunk 3486 ---\n",
            "species: Iris setosa, Iris versicolor, and Iris virginica (see Figure 4-22).\n",
            "\n",
            "--- Chunk 3487 ---\n",
            "Figure 4-22. Flowers of three iris plant species14\n",
            "\n",
            "--- Chunk 3488 ---\n",
            "14 Photos reproduced from the corresponding Wikipedia pages. Iris virginica photo by Frank Mayfield (Creative\n",
            "\n",
            "--- Chunk 3489 ---\n",
            "Commons BY-SA 2.0), Iris versicolor photo by D. Gordon E. Robertson (Creative Commons BY-SA 3.0), Iris\n",
            "setosa photo public domain.\n",
            "\n",
            "--- Chunk 3490 ---\n",
            "Logistic Regression | 145\n",
            "\n",
            "--- Chunk 3491 ---\n",
            "Let’s try to build a classifier to detect the Iris virginica type based only on the petal\n",
            "width feature. First let’s load the data:\n",
            "\n",
            "--- Chunk 3492 ---\n",
            ">>> from sklearn import datasets\n",
            ">>> iris = datasets.load_iris()\n",
            ">>> list(iris.keys())\n",
            "\n",
            "--- Chunk 3493 ---\n",
            "['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename']\n",
            ">>> X = iris[\"data\"][:, 3:]  # petal width\n",
            "\n",
            "--- Chunk 3494 ---\n",
            ">>> y = (iris[\"target\"] == 2).astype(np.int)  # 1 if Iris virginica, else 0\n",
            "\n",
            "--- Chunk 3495 ---\n",
            "Now let’s train a Logistic Regression model:\n",
            "from sklearn.linear_model import LogisticRegression\n",
            "\n",
            "log_reg = LogisticRegression()\n",
            "log_reg.fit(X, y)\n",
            "\n",
            "--- Chunk 3496 ---\n",
            "Let’s look at the model’s estimated probabilities for flowers with petal widths varying\n",
            "from 0 cm to 3 cm (Figure 4-23):15\n",
            "\n",
            "--- Chunk 3497 ---\n",
            "X_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
            "y_proba = log_reg.predict_proba(X_new)\n",
            "plt.plot(X_new, y_proba[:, 1], \"g-\", label=\"Iris virginica\")\n",
            "\n",
            "--- Chunk 3498 ---\n",
            "plt.plot(X_new, y_proba[:, 0], \"b--\", label=\"Not Iris virginica\")\n",
            "# + more Matplotlib code to make the image look pretty\n",
            "\n",
            "--- Chunk 3499 ---\n",
            "Figure 4-23. Estimated probabilities and decision boundary\n",
            "\n",
            "--- Chunk 3500 ---\n",
            "The petal width of Iris virginica flowers (represented by triangles) ranges from 1.4 cm\n",
            "\n",
            "--- Chunk 3501 ---\n",
            "to 2.5 cm, while the other iris flowers (represented by squares) generally have a\n",
            "\n",
            "--- Chunk 3502 ---\n",
            "smaller petal width, ranging from 0.1 cm to 1.8 cm. Notice that there is a bit of over‐\n",
            "\n",
            "--- Chunk 3503 ---\n",
            "lap. Above about 2 cm the classifier is highly confident that the flower is an Iris virgin‐\n",
            "\n",
            "--- Chunk 3504 ---\n",
            "ica (it outputs a high probability for that class), while below 1 cm it is highly\n",
            "\n",
            "--- Chunk 3505 ---\n",
            "confident that it is not an Iris virginica (high probability for the “Not Iris virginica”\n",
            "\n",
            "--- Chunk 3506 ---\n",
            "15 NumPy’s reshape() function allows one dimension to be –1, which means “unspecified”: the value is inferred\n",
            "\n",
            "--- Chunk 3507 ---\n",
            "from the length of the array and the remaining dimensions.\n",
            "\n",
            "--- Chunk 3508 ---\n",
            "146 | Chapter 4: Training Models\n",
            "\n",
            "--- Chunk 3509 ---\n",
            "class). In between these extremes, the classifier is unsure. However, if you ask it to\n",
            "\n",
            "--- Chunk 3510 ---\n",
            "predict the class (using the predict() method rather than the predict_proba()\n",
            "\n",
            "--- Chunk 3511 ---\n",
            "method), it will return whichever class is the most likely. Therefore, there is a decision\n",
            "\n",
            "--- Chunk 3512 ---\n",
            "boundary at around 1.6 cm where both probabilities are equal to 50%: if the petal\n",
            "\n",
            "--- Chunk 3513 ---\n",
            "width is higher than 1.6 cm, the classifier will predict that the flower is an Iris virgin‐\n",
            "\n",
            "--- Chunk 3514 ---\n",
            "ica, and otherwise it will predict that it is not (even if it is not very confident):\n",
            "\n",
            "--- Chunk 3515 ---\n",
            ">>> log_reg.predict([[1.7], [1.5]])\n",
            "array([1, 0])\n",
            "\n",
            "--- Chunk 3516 ---\n",
            "Figure 4-24 shows the same dataset, but this time displaying two features: petal width\n",
            "\n",
            "--- Chunk 3517 ---\n",
            "and length. Once trained, the Logistic Regression classifier can, based on these two\n",
            "\n",
            "--- Chunk 3518 ---\n",
            "features, estimate the probability that a new flower is an Iris virginica. The dashed line\n",
            "\n",
            "--- Chunk 3519 ---\n",
            "represents the points where the model estimates a 50% probability: this is the model’s\n",
            "\n",
            "--- Chunk 3520 ---\n",
            "decision boundary. Note that it is a linear boundary.16 Each parallel line represents the\n",
            "\n",
            "--- Chunk 3521 ---\n",
            "points where the model outputs a specific probability, from 15% (bottom left) to 90%\n",
            "\n",
            "--- Chunk 3522 ---\n",
            "(top right). All the flowers beyond the top-right line have an over 90% chance of\n",
            "being Iris virginica, according to the model.\n",
            "\n",
            "--- Chunk 3523 ---\n",
            "Figure 4-24. Linear decision boundary\n",
            "\n",
            "--- Chunk 3524 ---\n",
            "Just like the other linear models, Logistic Regression models can be regularized using\n",
            "\n",
            "--- Chunk 3525 ---\n",
            "ℓ1 or ℓ2 penalties. Scikit-Learn actually adds an ℓ2 penalty by default.\n",
            "\n",
            "--- Chunk 3526 ---\n",
            "The hyperparameter controlling the regularization strength of a\n",
            "Scikit-Learn LogisticRegression model is not alpha (as in other\n",
            "\n",
            "--- Chunk 3527 ---\n",
            "linear models), but its inverse: C. The higher the value of C, the less\n",
            "the model is regularized.\n",
            "\n",
            "--- Chunk 3528 ---\n",
            "16 It is the the set of points x such that θ0 + θ1x1 + θ2x2 = 0, which defines a straight line.\n",
            "\n",
            "Logistic Regression | 147\n",
            "\n",
            "--- Chunk 3529 ---\n",
            "Softmax Regression\n",
            "The Logistic Regression model can be generalized to support multiple classes directly,\n",
            "\n",
            "--- Chunk 3530 ---\n",
            "without having to train and combine multiple binary classifiers (as discussed in\n",
            "\n",
            "--- Chunk 3531 ---\n",
            "Chapter 3). This is called Softmax Regression, or Multinomial Logistic Regression.\n",
            "\n",
            "--- Chunk 3532 ---\n",
            "The idea is simple: when given an instance x, the Softmax Regression model first\n",
            "\n",
            "--- Chunk 3533 ---\n",
            "computes a score sk(x) for each class k, then estimates the probability of each class by\n",
            "\n",
            "--- Chunk 3534 ---\n",
            "applying the softmax function (also called the normalized exponential) to the scores.\n",
            "\n",
            "--- Chunk 3535 ---\n",
            "The equation to compute sk(x) should look familiar, as it is just like the equation for\n",
            "Linear Regression prediction (see Equation 4-19).\n",
            "\n",
            "--- Chunk 3536 ---\n",
            "Equation 4-19. Softmax score for class k\n",
            "sk x = x⊺θ k\n",
            "\n",
            "--- Chunk 3537 ---\n",
            "Note that each class has its own dedicated parameter vector θ(k). All these vectors are\n",
            "typically stored as rows in a parameter matrix Θ.\n",
            "\n",
            "--- Chunk 3538 ---\n",
            "Once you have computed the score of every class for the instance x, you can estimate\n",
            "\n",
            "--- Chunk 3539 ---\n",
            "the probability pk that the instance belongs to class k by running the scores through\n",
            "\n",
            "--- Chunk 3540 ---\n",
            "the softmax function (Equation 4-20). The function computes the exponential of\n",
            "\n",
            "--- Chunk 3541 ---\n",
            "every score, then normalizes them (dividing by the sum of all the exponentials). The\n",
            "\n",
            "--- Chunk 3542 ---\n",
            "scores are generally called logits or log-odds (although they are actually unnormal‐\n",
            "ized log-odds).\n",
            "\n",
            "--- Chunk 3543 ---\n",
            "Equation 4-20. Softmax function\n",
            "exp s\n",
            "\n",
            "pk = σ s x k = k x\n",
            "∑K\n",
            "\n",
            "j = 1 exp s j x\n",
            "\n",
            "In this equation:\n",
            "\n",
            "--- Chunk 3544 ---\n",
            "• K is the number of classes.\n",
            "• s(x) is a vector containing the scores of each class for the instance x.\n",
            "\n",
            "--- Chunk 3545 ---\n",
            "• σ(s(x))k is the estimated probability that the instance x belongs to class k, given\n",
            "\n",
            "--- Chunk 3546 ---\n",
            "the scores of each class for that instance.\n",
            "\n",
            "148 | Chapter 4: Training Models\n",
            "\n",
            "--- Chunk 3547 ---\n",
            "Just like the Logistic Regression classifier, the Softmax Regression classifier predicts\n",
            "\n",
            "--- Chunk 3548 ---\n",
            "the class with the highest estimated probability (which is simply the class with the\n",
            "highest score), as shown in Equation 4-21.\n",
            "\n",
            "--- Chunk 3549 ---\n",
            "Equation 4-21. Softmax Regression classifier prediction\n",
            "\n",
            "y = argmax σ s x k = argmax s arg ax θ k ⊺x\n",
            "k k x = m\n",
            "\n",
            "k k\n",
            "\n",
            "--- Chunk 3550 ---\n",
            "The argmax operator returns the value of a variable that maximizes a function. In this\n",
            "\n",
            "--- Chunk 3551 ---\n",
            "equation, it returns the value of k that maximizes the estimated probability σ(s(x))k.\n",
            "\n",
            "--- Chunk 3552 ---\n",
            "The Softmax Regression classifier predicts only one class at a time\n",
            "(i.e., it is multiclass, not multioutput), so it should be used only\n",
            "\n",
            "--- Chunk 3553 ---\n",
            "with mutually exclusive classes, such as different types of plants.\n",
            "You cannot use it to recognize multiple people in one picture.\n",
            "\n",
            "--- Chunk 3554 ---\n",
            "Now that you know how the model estimates probabilities and makes predictions,\n",
            "\n",
            "--- Chunk 3555 ---\n",
            "let’s take a look at training. The objective is to have a model that estimates a high\n",
            "\n",
            "--- Chunk 3556 ---\n",
            "probability for the target class (and consequently a low probability for the other\n",
            "\n",
            "--- Chunk 3557 ---\n",
            "classes). Minimizing the cost function shown in Equation 4-22, called the cross\n",
            "\n",
            "--- Chunk 3558 ---\n",
            "entropy, should lead to this objective because it penalizes the model when it estimates\n",
            "\n",
            "--- Chunk 3559 ---\n",
            "a low probability for a target class. Cross entropy is frequently used to measure how\n",
            "\n",
            "--- Chunk 3560 ---\n",
            "well a set of estimated class probabilities matches the target classes.\n",
            "\n",
            "--- Chunk 3561 ---\n",
            "Equation 4-22. Cross entropy cost function\n",
            "\n",
            "J Θ = − 1 m\n",
            "m ∑ ∑K i\n",
            "\n",
            "i = 1 k = 1 yk log p i\n",
            "k\n",
            "\n",
            "In this equation:\n",
            "\n",
            "--- Chunk 3562 ---\n",
            "In this equation:\n",
            "\n",
            "• y i\n",
            "k  is the target probability that the ith instance belongs to class k. In general, it is\n",
            "\n",
            "--- Chunk 3563 ---\n",
            "either equal to 1 or 0, depending on whether the instance belongs to the class or\n",
            "not.\n",
            "\n",
            "--- Chunk 3564 ---\n",
            "Notice that when there are just two classes (K = 2), this cost function is equivalent to\n",
            "\n",
            "--- Chunk 3565 ---\n",
            "the Logistic Regression’s cost function (log loss; see Equation 4-17).\n",
            "\n",
            "--- Chunk 3566 ---\n",
            "Logistic Regression | 149\n",
            "\n",
            "--- Chunk 3567 ---\n",
            "Cross Entropy\n",
            "Cross entropy originated from information theory. Suppose you want to efficiently\n",
            "\n",
            "--- Chunk 3568 ---\n",
            "transmit information about the weather every day. If there are eight options (sunny,\n",
            "\n",
            "--- Chunk 3569 ---\n",
            "rainy, etc.), you could encode each option using three bits because 23 = 8. However, if\n",
            "\n",
            "--- Chunk 3570 ---\n",
            "you think it will be sunny almost every day, it would be much more efficient to code\n",
            "\n",
            "--- Chunk 3571 ---\n",
            "“sunny” on just one bit (0) and the other seven options on four bits (starting with a\n",
            "\n",
            "--- Chunk 3572 ---\n",
            "1). Cross entropy measures the average number of bits you actually send per option.\n",
            "\n",
            "--- Chunk 3573 ---\n",
            "If your assumption about the weather is perfect, cross entropy will be equal to the\n",
            "\n",
            "--- Chunk 3574 ---\n",
            "entropy of the weather itself (i.e., its intrinsic unpredictability). But if your assump‐\n",
            "\n",
            "--- Chunk 3575 ---\n",
            "tions are wrong (e.g., if it rains often), cross entropy will be greater by an amount\n",
            "called the Kullback–Leibler (KL) divergence.\n",
            "\n",
            "--- Chunk 3576 ---\n",
            "The cross entropy between two probability distributions p and q is defined as H(p,q)\n",
            "\n",
            "--- Chunk 3577 ---\n",
            "= —Σx p(x) log q(x) (at least when the distributions are discrete). For more details,\n",
            "check out my video on the subject.\n",
            "\n",
            "--- Chunk 3578 ---\n",
            "The gradient vector of this cost function with regard to θ(k) is given by Equation 4-23.\n",
            "\n",
            "Equation 4-23. Cross entropy gradient vector for class k\n",
            "m\n",
            "\n",
            "--- Chunk 3579 ---\n",
            "∇\n",
            "θ k J Θ = 1\n",
            "\n",
            "m ∑ p i i i\n",
            "k − yk x\n",
            "\n",
            "i = 1\n",
            "\n",
            "--- Chunk 3580 ---\n",
            "Now you can compute the gradient vector for every class, then use Gradient Descent\n",
            "\n",
            "--- Chunk 3581 ---\n",
            "(or any other optimization algorithm) to find the parameter matrix Θ that minimizes\n",
            "the cost function.\n",
            "\n",
            "--- Chunk 3582 ---\n",
            "the cost function.\n",
            "Let’s use Softmax Regression to classify the iris flowers into all three classes. Scikit-\n",
            "\n",
            "--- Chunk 3583 ---\n",
            "Learn’s LogisticRegression uses one-versus-the-rest by default when you train it on\n",
            "\n",
            "--- Chunk 3584 ---\n",
            "more than two classes, but you can set the multi_class hyperparameter to \"multino\n",
            "\n",
            "--- Chunk 3585 ---\n",
            "mial\" to switch it to Softmax Regression. You must also specify a solver that supports\n",
            "\n",
            "--- Chunk 3586 ---\n",
            "Softmax Regression, such as the \"lbfgs\" solver (see Scikit-Learn’s documentation for\n",
            "\n",
            "--- Chunk 3587 ---\n",
            "more details). It also applies ℓ2 regularization by default, which you can control using\n",
            "the hyperparameter C:\n",
            "\n",
            "--- Chunk 3588 ---\n",
            "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
            "y = iris[\"target\"]\n",
            "\n",
            "--- Chunk 3589 ---\n",
            "softmax_reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", C=10)\n",
            "softmax_reg.fit(X, y)\n",
            "\n",
            "--- Chunk 3590 ---\n",
            "So the next time you find an iris with petals that are 5 cm long and 2 cm wide, you\n",
            "\n",
            "--- Chunk 3591 ---\n",
            "can ask your model to tell you what type of iris it is, and it will answer Iris virginica\n",
            "\n",
            "--- Chunk 3592 ---\n",
            "(class 2) with 94.2% probability (or Iris versicolor with 5.8% probability):\n",
            "\n",
            "--- Chunk 3593 ---\n",
            "150 | Chapter 4: Training Models\n",
            "\n",
            "--- Chunk 3594 ---\n",
            ">>> softmax_reg.predict([[5, 2]])\n",
            "array([2])\n",
            ">>> softmax_reg.predict_proba([[5, 2]])\n",
            "array([[6.38014896e-07, 5.74929995e-02, 9.42506362e-01]])\n",
            "\n",
            "--- Chunk 3595 ---\n",
            "Figure 4-25 shows the resulting decision boundaries, represented by the background\n",
            "\n",
            "--- Chunk 3596 ---\n",
            "colors. Notice that the decision boundaries between any two classes are linear. The\n",
            "\n",
            "--- Chunk 3597 ---\n",
            "figure also shows the probabilities for the Iris versicolor class, represented by the\n",
            "\n",
            "--- Chunk 3598 ---\n",
            "curved lines (e.g., the line labeled with 0.450 represents the 45% probability bound‐\n",
            "\n",
            "--- Chunk 3599 ---\n",
            "ary). Notice that the model can predict a class that has an estimated probability below\n",
            "\n",
            "--- Chunk 3600 ---\n",
            "50%. For example, at the point where all decision boundaries meet, all classes have an\n",
            "equal estimated probability of 33%.\n",
            "\n",
            "--- Chunk 3601 ---\n",
            "Figure 4-25. Softmax Regression decision boundaries\n",
            "\n",
            "Exercises\n",
            "1. Which Linear Regression training algorithm can you use if you have a training\n",
            "\n",
            "--- Chunk 3602 ---\n",
            "set with millions of features?\n",
            "2. Suppose the features in your training set have very different scales. Which algo‐\n",
            "\n",
            "--- Chunk 3603 ---\n",
            "rithms might suffer from this, and how? What can you do about it?\n",
            "3. Can Gradient Descent get stuck in a local minimum when training a Logistic\n",
            "\n",
            "--- Chunk 3604 ---\n",
            "Regression model?\n",
            "4. Do all Gradient Descent algorithms lead to the same model, provided you let\n",
            "\n",
            "--- Chunk 3605 ---\n",
            "them run long enough?\n",
            "5. Suppose you use Batch Gradient Descent and you plot the validation error at\n",
            "\n",
            "--- Chunk 3606 ---\n",
            "every epoch. If you notice that the validation error consistently goes up, what is\n",
            "likely going on? How can you fix this?\n",
            "\n",
            "--- Chunk 3607 ---\n",
            "6. Is it a good idea to stop Mini-batch Gradient Descent immediately when the vali‐\n",
            "dation error goes up?\n",
            "\n",
            "Exercises | 151\n",
            "\n",
            "--- Chunk 3608 ---\n",
            "7. Which Gradient Descent algorithm (among those we discussed) will reach the\n",
            "\n",
            "--- Chunk 3609 ---\n",
            "vicinity of the optimal solution the fastest? Which will actually converge? How\n",
            "can you make the others converge as well?\n",
            "\n",
            "--- Chunk 3610 ---\n",
            "8. Suppose you are using Polynomial Regression. You plot the learning curves and\n",
            "\n",
            "--- Chunk 3611 ---\n",
            "you notice that there is a large gap between the training error and the validation\n",
            "error. What is happening? What are three ways to solve this?\n",
            "\n",
            "--- Chunk 3612 ---\n",
            "9. Suppose you are using Ridge Regression and you notice that the training error\n",
            "\n",
            "--- Chunk 3613 ---\n",
            "and the validation error are almost equal and fairly high. Would you say that the\n",
            "\n",
            "--- Chunk 3614 ---\n",
            "model suffers from high bias or high variance? Should you increase the regulari‐\n",
            "zation hyperparameter α or reduce it?\n",
            "\n",
            "--- Chunk 3615 ---\n",
            "10. Why would you want to use:\n",
            "a. Ridge Regression instead of plain Linear Regression (i.e., without any regula‐\n",
            "\n",
            "--- Chunk 3616 ---\n",
            "rization)?\n",
            "b. Lasso instead of Ridge Regression?\n",
            "c. Elastic Net instead of Lasso?\n",
            "\n",
            "--- Chunk 3617 ---\n",
            "11. Suppose you want to classify pictures as outdoor/indoor and daytime/nighttime.\n",
            "\n",
            "--- Chunk 3618 ---\n",
            "Should you implement two Logistic Regression classifiers or one Softmax Regres‐\n",
            "sion classifier?\n",
            "\n",
            "--- Chunk 3619 ---\n",
            "12. Implement Batch Gradient Descent with early stopping for Softmax Regression\n",
            "(without using Scikit-Learn).\n",
            "\n",
            "--- Chunk 3620 ---\n",
            "Solutions to these exercises are available in Appendix A.\n",
            "\n",
            "152 | Chapter 4: Training Models\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER 5\n",
            "Support Vector Machines\n",
            "\n",
            "--- Chunk 3621 ---\n",
            "A Support Vector Machine (SVM) is a powerful and versatile Machine Learning\n",
            "\n",
            "--- Chunk 3622 ---\n",
            "model, capable of performing linear or nonlinear classification, regression, and even\n",
            "\n",
            "--- Chunk 3623 ---\n",
            "outlier detection. It is one of the most popular models in Machine Learning, and any‐\n",
            "\n",
            "--- Chunk 3624 ---\n",
            "one interested in Machine Learning should have it in their toolbox. SVMs are partic‐\n",
            "\n",
            "--- Chunk 3625 ---\n",
            "ularly well suited for classification of complex small- or medium-sized datasets.\n",
            "\n",
            "--- Chunk 3626 ---\n",
            "This chapter will explain the core concepts of SVMs, how to use them, and how they\n",
            "work.\n",
            "\n",
            "--- Chunk 3627 ---\n",
            "Linear SVM Classification\n",
            "The fundamental idea behind SVMs is best explained with some pictures. Figure 5-1\n",
            "\n",
            "--- Chunk 3628 ---\n",
            "shows part of the iris dataset that was introduced at the end of Chapter 4. The two\n",
            "\n",
            "--- Chunk 3629 ---\n",
            "classes can clearly be separated easily with a straight line (they are linearly separable).\n",
            "\n",
            "--- Chunk 3630 ---\n",
            "The left plot shows the decision boundaries of three possible linear classifiers. The\n",
            "\n",
            "--- Chunk 3631 ---\n",
            "model whose decision boundary is represented by the dashed line is so bad that it\n",
            "\n",
            "--- Chunk 3632 ---\n",
            "does not even separate the classes properly. The other two models work perfectly on\n",
            "\n",
            "--- Chunk 3633 ---\n",
            "this training set, but their decision boundaries come so close to the instances that\n",
            "\n",
            "--- Chunk 3634 ---\n",
            "these models will probably not perform as well on new instances. In contrast, the\n",
            "\n",
            "--- Chunk 3635 ---\n",
            "solid line in the plot on the right represents the decision boundary of an SVM classi‐\n",
            "\n",
            "--- Chunk 3636 ---\n",
            "fier; this line not only separates the two classes but also stays as far away from the\n",
            "\n",
            "--- Chunk 3637 ---\n",
            "closest training instances as possible. You can think of an SVM classifier as fitting the\n",
            "\n",
            "--- Chunk 3638 ---\n",
            "widest possible street (represented by the parallel dashed lines) between the classes.\n",
            "This is called large margin classification.\n",
            "\n",
            "--- Chunk 3639 ---\n",
            "153\n",
            "\n",
            "\n",
            "\n",
            "Figure 5-1. Large margin classification\n",
            "\n",
            "--- Chunk 3640 ---\n",
            "Notice that adding more training instances “off the street” will not affect the decision\n",
            "\n",
            "--- Chunk 3641 ---\n",
            "boundary at all: it is fully determined (or “supported”) by the instances located on the\n",
            "\n",
            "--- Chunk 3642 ---\n",
            "edge of the street. These instances are called the support vectors (they are circled in\n",
            "Figure 5-1).\n",
            "\n",
            "--- Chunk 3643 ---\n",
            "Figure 5-2. Sensitivity to feature scales\n",
            "\n",
            "--- Chunk 3644 ---\n",
            "SVMs are sensitive to the feature scales, as you can see in\n",
            "Figure 5-2: in the left plot, the vertical scale is much larger than the\n",
            "\n",
            "--- Chunk 3645 ---\n",
            "horizontal scale, so the widest possible street is close to horizontal.\n",
            "After feature scaling (e.g., using Scikit-Learn’s StandardScaler),\n",
            "\n",
            "--- Chunk 3646 ---\n",
            "the decision boundary in the right plot looks much better.\n",
            "\n",
            "--- Chunk 3647 ---\n",
            "Soft Margin Classification\n",
            "If we strictly impose that all instances must be off the street and on the right side, this\n",
            "\n",
            "--- Chunk 3648 ---\n",
            "is called hard margin classification. There are two main issues with hard margin clas‐\n",
            "\n",
            "--- Chunk 3649 ---\n",
            "sification. First, it only works if the data is linearly separable. Second, it is sensitive to\n",
            "\n",
            "--- Chunk 3650 ---\n",
            "outliers. Figure 5-3 shows the iris dataset with just one additional outlier: on the left,\n",
            "\n",
            "--- Chunk 3651 ---\n",
            "it is impossible to find a hard margin; on the right, the decision boundary ends up\n",
            "\n",
            "--- Chunk 3652 ---\n",
            "very different from the one we saw in Figure 5-1 without the outlier, and it will prob‐\n",
            "ably not generalize as well.\n",
            "\n",
            "--- Chunk 3653 ---\n",
            "154 | Chapter 5: Support Vector Machines\n",
            "\n",
            "\n",
            "\n",
            "Figure 5-3. Hard margin sensitivity to outliers\n",
            "\n",
            "--- Chunk 3654 ---\n",
            "To avoid these issues, use a more flexible model. The objective is to find a good bal‐\n",
            "\n",
            "--- Chunk 3655 ---\n",
            "ance between keeping the street as large as possible and limiting the margin violations\n",
            "\n",
            "--- Chunk 3656 ---\n",
            "(i.e., instances that end up in the middle of the street or even on the wrong side). This\n",
            "is called soft margin classification.\n",
            "\n",
            "--- Chunk 3657 ---\n",
            "When creating an SVM model using Scikit-Learn, we can specify a number of hyper‐\n",
            "\n",
            "--- Chunk 3658 ---\n",
            "parameters. C is one of those hyperparameters. If we set it to a low value, then we end\n",
            "\n",
            "--- Chunk 3659 ---\n",
            "up with the model on the left of Figure 5-4. With a high value, we get the model on\n",
            "\n",
            "--- Chunk 3660 ---\n",
            "the right. Margin violations are bad. It’s usually better to have few of them. However,\n",
            "\n",
            "--- Chunk 3661 ---\n",
            "in this case the model on the left has a lot of margin violations but will probably gen‐\n",
            "eralize better.\n",
            "\n",
            "--- Chunk 3662 ---\n",
            "Figure 5-4. Large margin (left) versus fewer margin violations (right)\n",
            "\n",
            "If your SVM model is overfitting, you can try regularizing it by\n",
            "reducing C.\n",
            "\n",
            "--- Chunk 3663 ---\n",
            "The following Scikit-Learn code loads the iris dataset, scales the features, and then\n",
            "\n",
            "--- Chunk 3664 ---\n",
            "trains a linear SVM model (using the LinearSVC class with C=1 and the hinge loss\n",
            "function, described shortly) to detect Iris virginica flowers:\n",
            "\n",
            "--- Chunk 3665 ---\n",
            "import numpy as np\n",
            "from sklearn import datasets\n",
            "from sklearn.pipeline import Pipeline\n",
            "\n",
            "Linear SVM Classification | 155\n",
            "\n",
            "--- Chunk 3666 ---\n",
            "from sklearn.preprocessing import StandardScaler\n",
            "from sklearn.svm import LinearSVC\n",
            "\n",
            "--- Chunk 3667 ---\n",
            "iris = datasets.load_iris()\n",
            "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
            "y = (iris[\"target\"] == 2).astype(np.float64)  # Iris virginica\n",
            "\n",
            "--- Chunk 3668 ---\n",
            "svm_clf = Pipeline([\n",
            "        (\"scaler\", StandardScaler()),\n",
            "        (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\")),\n",
            "    ])\n",
            "\n",
            "svm_clf.fit(X, y)\n",
            "\n",
            "--- Chunk 3669 ---\n",
            "svm_clf.fit(X, y)\n",
            "\n",
            "The resulting model is represented on the left in Figure 5-4.\n",
            "Then, as usual, you can use the model to make predictions:\n",
            "\n",
            "--- Chunk 3670 ---\n",
            ">>> svm_clf.predict([[5.5, 1.7]])\n",
            "array([1.])\n",
            "\n",
            "Unlike Logistic Regression classifiers, SVM classifiers do not out‐\n",
            "put probabilities for each class.\n",
            "\n",
            "--- Chunk 3671 ---\n",
            "Instead of using the LinearSVC class, we could use the SVC class with a linear kernel.\n",
            "\n",
            "--- Chunk 3672 ---\n",
            "When creating the SVC model, we would write SVC(kernel=\"linear\", C=1). Or we\n",
            "\n",
            "--- Chunk 3673 ---\n",
            "could use the SGDClassifier class, with SGDClassifier(loss=\"hinge\", alpha=1/\n",
            "\n",
            "--- Chunk 3674 ---\n",
            "(m*C)). This applies regular Stochastic Gradient Descent (see Chapter 4) to train a\n",
            "\n",
            "--- Chunk 3675 ---\n",
            "linear SVM classifier. It does not converge as fast as the LinearSVC class, but it can be\n",
            "\n",
            "--- Chunk 3676 ---\n",
            "useful to handle online classification tasks or huge datasets that do not fit in memory\n",
            "(out-of-core training).\n",
            "\n",
            "--- Chunk 3677 ---\n",
            "The LinearSVC class regularizes the bias term, so you should center\n",
            "the training set first by subtracting its mean. This is automatic if\n",
            "\n",
            "--- Chunk 3678 ---\n",
            "you scale the data using the StandardScaler. Also make sure you\n",
            "set the loss hyperparameter to \"hinge\", as it is not the default\n",
            "\n",
            "--- Chunk 3679 ---\n",
            "value. Finally, for better performance, you should set the dual\n",
            "hyperparameter to False, unless there are more features than\n",
            "\n",
            "--- Chunk 3680 ---\n",
            "training instances (we will discuss duality later in the chapter).\n",
            "\n",
            "--- Chunk 3681 ---\n",
            "156 | Chapter 5: Support Vector Machines\n",
            "\n",
            "--- Chunk 3682 ---\n",
            "Nonlinear SVM Classification\n",
            "Although linear SVM classifiers are efficient and work surprisingly well in many\n",
            "\n",
            "--- Chunk 3683 ---\n",
            "cases, many datasets are not even close to being linearly separable. One approach to\n",
            "\n",
            "--- Chunk 3684 ---\n",
            "handling nonlinear datasets is to add more features, such as polynomial features (as\n",
            "\n",
            "--- Chunk 3685 ---\n",
            "you did in Chapter 4); in some cases this can result in a linearly separable dataset.\n",
            "\n",
            "--- Chunk 3686 ---\n",
            "Consider the left plot in Figure 5-5: it represents a simple dataset with just one fea‐\n",
            "\n",
            "--- Chunk 3687 ---\n",
            "ture, x1. This dataset is not linearly separable, as you can see. But if you add a second\n",
            "\n",
            "--- Chunk 3688 ---\n",
            "feature x2 = (x1)2, the resulting 2D dataset is perfectly linearly separable.\n",
            "\n",
            "--- Chunk 3689 ---\n",
            "Figure 5-5. Adding features to make a dataset linearly separable\n",
            "\n",
            "--- Chunk 3690 ---\n",
            "To implement this idea using Scikit-Learn, create a Pipeline containing a Polyno\n",
            "\n",
            "--- Chunk 3691 ---\n",
            "mialFeatures transformer (discussed in “Polynomial Regression” on page 128), fol‐\n",
            "\n",
            "--- Chunk 3692 ---\n",
            "lowed by a StandardScaler and a LinearSVC. Let’s test this on the moons dataset: this\n",
            "\n",
            "--- Chunk 3693 ---\n",
            "is a toy dataset for binary classification in which the data points are shaped as two\n",
            "\n",
            "--- Chunk 3694 ---\n",
            "interleaving half circles (see Figure 5-6). You can generate this dataset using the\n",
            "make_moons() function:\n",
            "\n",
            "--- Chunk 3695 ---\n",
            "from sklearn.datasets import make_moons\n",
            "from sklearn.pipeline import Pipeline\n",
            "from sklearn.preprocessing import PolynomialFeatures\n",
            "\n",
            "--- Chunk 3696 ---\n",
            "X, y = make_moons(n_samples=100, noise=0.15)\n",
            "polynomial_svm_clf = Pipeline([\n",
            "        (\"poly_features\", PolynomialFeatures(degree=3)),\n",
            "\n",
            "--- Chunk 3697 ---\n",
            "(\"scaler\", StandardScaler()),\n",
            "        (\"svm_clf\", LinearSVC(C=10, loss=\"hinge\"))\n",
            "    ])\n",
            "\n",
            "--- Chunk 3698 ---\n",
            "polynomial_svm_clf.fit(X, y)\n",
            "\n",
            "Nonlinear SVM Classification | 157\n",
            "\n",
            "\n",
            "\n",
            "Figure 5-6. Linear SVM classifier using polynomial features\n",
            "\n",
            "--- Chunk 3699 ---\n",
            "Polynomial Kernel\n",
            "Adding polynomial features is simple to implement and can work great with all sorts\n",
            "\n",
            "--- Chunk 3700 ---\n",
            "of Machine Learning algorithms (not just SVMs). That said, at a low polynomial\n",
            "\n",
            "--- Chunk 3701 ---\n",
            "degree, this method cannot deal with very complex datasets, and with a high polyno‐\n",
            "\n",
            "--- Chunk 3702 ---\n",
            "mial degree it creates a huge number of features, making the model too slow.\n",
            "\n",
            "--- Chunk 3703 ---\n",
            "Fortunately, when using SVMs you can apply an almost miraculous mathematical\n",
            "\n",
            "--- Chunk 3704 ---\n",
            "technique called the kernel trick (explained in a moment). The kernel trick makes it\n",
            "\n",
            "--- Chunk 3705 ---\n",
            "possible to get the same result as if you had added many polynomial features, even\n",
            "\n",
            "--- Chunk 3706 ---\n",
            "with very high-degree polynomials, without actually having to add them. So there is\n",
            "\n",
            "--- Chunk 3707 ---\n",
            "no combinatorial explosion of the number of features because you don’t actually add\n",
            "\n",
            "--- Chunk 3708 ---\n",
            "any features. This trick is implemented by the SVC class. Let’s test it on the moons\n",
            "dataset:\n",
            "\n",
            "--- Chunk 3709 ---\n",
            "from sklearn.svm import SVC\n",
            "poly_kernel_svm_clf = Pipeline([\n",
            "        (\"scaler\", StandardScaler()),\n",
            "\n",
            "--- Chunk 3710 ---\n",
            "(\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=5))\n",
            "    ])\n",
            "poly_kernel_svm_clf.fit(X, y)\n",
            "\n",
            "--- Chunk 3711 ---\n",
            "This code trains an SVM classifier using a third-degree polynomial kernel. It is repre‐\n",
            "\n",
            "--- Chunk 3712 ---\n",
            "sented on the left in Figure 5-7. On the right is another SVM classifier using a 10th-\n",
            "\n",
            "--- Chunk 3713 ---\n",
            "degree polynomial kernel. Obviously, if your model is overfitting, you might want to\n",
            "\n",
            "--- Chunk 3714 ---\n",
            "reduce the polynomial degree. Conversely, if it is underfitting, you can try increasing\n",
            "\n",
            "--- Chunk 3715 ---\n",
            "it. The hyperparameter coef0 controls how much the model is influenced by high-\n",
            "degree polynomials versus low-degree polynomials.\n",
            "\n",
            "--- Chunk 3716 ---\n",
            "158 | Chapter 5: Support Vector Machines\n",
            "\n",
            "\n",
            "\n",
            "Figure 5-7. SVM classifiers with a polynomial kernel\n",
            "\n",
            "--- Chunk 3717 ---\n",
            "A common approach to finding the right hyperparameter values is\n",
            "to use grid search (see Chapter 2). It is often faster to first do a very\n",
            "\n",
            "--- Chunk 3718 ---\n",
            "coarse grid search, then a finer grid search around the best values\n",
            "found. Having a good sense of what each hyperparameter actually\n",
            "\n",
            "--- Chunk 3719 ---\n",
            "does can also help you search in the right part of the hyperparame‐\n",
            "ter space.\n",
            "\n",
            "--- Chunk 3720 ---\n",
            "Similarity Features\n",
            "Another technique to tackle nonlinear problems is to add features computed using a\n",
            "\n",
            "--- Chunk 3721 ---\n",
            "similarity function, which measures how much each instance resembles a particular\n",
            "\n",
            "--- Chunk 3722 ---\n",
            "landmark. For example, let’s take the 1D dataset discussed earlier and add two land‐\n",
            "\n",
            "--- Chunk 3723 ---\n",
            "marks to it at x1 = –2 and x1 = 1 (see the left plot in Figure 5-8). Next, let’s define the\n",
            "\n",
            "--- Chunk 3724 ---\n",
            "similarity function to be the Gaussian Radial Basis Function (RBF) with γ = 0.3 (see\n",
            "Equation 5-1).\n",
            "\n",
            "--- Chunk 3725 ---\n",
            "Equation 5-1. Gaussian RBF\n",
            "ϕγ x, ℓ = exp −γ 2\n",
            "\n",
            "∥ x − ℓ ∥\n",
            "\n",
            "--- Chunk 3726 ---\n",
            "This is a bell-shaped function varying from 0 (very far away from the landmark) to 1\n",
            "\n",
            "--- Chunk 3727 ---\n",
            "(at the landmark). Now we are ready to compute the new features. For example, let’s\n",
            "\n",
            "--- Chunk 3728 ---\n",
            "look at the instance x1 = –1: it is located at a distance of 1 from the first landmark and\n",
            "\n",
            "--- Chunk 3729 ---\n",
            "2 from the second landmark. Therefore its new features are x2 = exp(–0.3 × 12) ≈ 0.74\n",
            "\n",
            "--- Chunk 3730 ---\n",
            "and x3 = exp(–0.3 × 22) ≈ 0.30. The plot on the right in Figure 5-8 shows the trans‐\n",
            "\n",
            "--- Chunk 3731 ---\n",
            "formed dataset (dropping the original features). As you can see, it is now linearly\n",
            "separable.\n",
            "\n",
            "--- Chunk 3732 ---\n",
            "Nonlinear SVM Classification | 159\n",
            "\n",
            "\n",
            "\n",
            "Figure 5-8. Similarity features using the Gaussian RBF\n",
            "\n",
            "--- Chunk 3733 ---\n",
            "You may wonder how to select the landmarks. The simplest approach is to create a\n",
            "\n",
            "--- Chunk 3734 ---\n",
            "landmark at the location of each and every instance in the dataset. Doing that creates\n",
            "\n",
            "--- Chunk 3735 ---\n",
            "many dimensions and thus increases the chances that the transformed training set\n",
            "\n",
            "--- Chunk 3736 ---\n",
            "will be linearly separable. The downside is that a training set with m instances and n\n",
            "\n",
            "--- Chunk 3737 ---\n",
            "features gets transformed into a training set with m instances and m features (assum‐\n",
            "\n",
            "--- Chunk 3738 ---\n",
            "ing you drop the original features). If your training set is very large, you end up with\n",
            "an equally large number of features.\n",
            "\n",
            "--- Chunk 3739 ---\n",
            "Gaussian RBF Kernel\n",
            "Just like the polynomial features method, the similarity features method can be useful\n",
            "\n",
            "--- Chunk 3740 ---\n",
            "with any Machine Learning algorithm, but it may be computationally expensive to\n",
            "\n",
            "--- Chunk 3741 ---\n",
            "compute all the additional features, especially on large training sets. Once again the\n",
            "\n",
            "--- Chunk 3742 ---\n",
            "kernel trick does its SVM magic, making it possible to obtain a similar result as if you\n",
            "\n",
            "--- Chunk 3743 ---\n",
            "had added many similarity features. Let’s try the SVC class with the Gaussian RBF\n",
            "kernel:\n",
            "\n",
            "--- Chunk 3744 ---\n",
            "rbf_kernel_svm_clf = Pipeline([\n",
            "        (\"scaler\", StandardScaler()),\n",
            "        (\"svm_clf\", SVC(kernel=\"rbf\", gamma=5, C=0.001))\n",
            "    ])\n",
            "\n",
            "--- Chunk 3745 ---\n",
            "])\n",
            "rbf_kernel_svm_clf.fit(X, y)\n",
            "\n",
            "--- Chunk 3746 ---\n",
            "This model is represented at the bottom left in Figure 5-9. The other plots show mod‐\n",
            "\n",
            "--- Chunk 3747 ---\n",
            "els trained with different values of hyperparameters gamma (γ) and C. Increasing gamma\n",
            "\n",
            "--- Chunk 3748 ---\n",
            "makes the bell-shaped curve narrower (see the lefthand plots in Figure 5-8). As a\n",
            "\n",
            "--- Chunk 3749 ---\n",
            "result, each instance’s range of influence is smaller: the decision boundary ends up\n",
            "\n",
            "--- Chunk 3750 ---\n",
            "being more irregular, wiggling around individual instances. Conversely, a small gamma\n",
            "\n",
            "--- Chunk 3751 ---\n",
            "value makes the bell-shaped curve wider: instances have a larger range of influence,\n",
            "\n",
            "--- Chunk 3752 ---\n",
            "and the decision boundary ends up smoother. So γ acts like a regularization\n",
            "\n",
            "--- Chunk 3753 ---\n",
            "160 | Chapter 5: Support Vector Machines\n",
            "\n",
            "--- Chunk 3754 ---\n",
            "hyperparameter: if your model is overfitting, you should reduce it; if it is underfitting,\n",
            "you should increase it (similar to the C hyperparameter).\n",
            "\n",
            "--- Chunk 3755 ---\n",
            "Figure 5-9. SVM classifiers using an RBF kernel\n",
            "\n",
            "--- Chunk 3756 ---\n",
            "Other kernels exist but are used much more rarely. Some kernels are specialized for\n",
            "\n",
            "--- Chunk 3757 ---\n",
            "specific data structures. String kernels are sometimes used when classifying text docu‐\n",
            "\n",
            "--- Chunk 3758 ---\n",
            "ments or DNA sequences (e.g., using the string subsequence kernel or kernels based on\n",
            "the Levenshtein distance).\n",
            "\n",
            "--- Chunk 3759 ---\n",
            "With so many kernels to choose from, how can you decide which\n",
            "one to use? As a rule of thumb, you should always try the linear\n",
            "\n",
            "--- Chunk 3760 ---\n",
            "kernel first (remember that LinearSVC is much faster than SVC(ker\n",
            "nel=\"linear\")), especially if the training set is very large or if it\n",
            "\n",
            "--- Chunk 3761 ---\n",
            "has plenty of features. If the training set is not too large, you should\n",
            "also try the Gaussian RBF kernel; it works well in most cases. Then\n",
            "\n",
            "--- Chunk 3762 ---\n",
            "if you have spare time and computing power, you can experiment\n",
            "with a few other kernels, using cross-validation and grid search.\n",
            "\n",
            "--- Chunk 3763 ---\n",
            "You’d want to experiment like that especially if there are kernels\n",
            "specialized for your training set’s data structure.\n",
            "\n",
            "--- Chunk 3764 ---\n",
            "Nonlinear SVM Classification | 161\n",
            "\n",
            "--- Chunk 3765 ---\n",
            "Computational Complexity\n",
            "The LinearSVC class is based on the liblinear library, which implements an opti‐\n",
            "\n",
            "--- Chunk 3766 ---\n",
            "mized algorithm for linear SVMs.1 It does not support the kernel trick, but it scales\n",
            "\n",
            "--- Chunk 3767 ---\n",
            "almost linearly with the number of training instances and the number of features. Its\n",
            "training time complexity is roughly O(m × n).\n",
            "\n",
            "--- Chunk 3768 ---\n",
            "The algorithm takes longer if you require very high precision. This is controlled by\n",
            "\n",
            "--- Chunk 3769 ---\n",
            "the tolerance hyperparameter ϵ (called tol in Scikit-Learn). In most classification\n",
            "tasks, the default tolerance is fine.\n",
            "\n",
            "--- Chunk 3770 ---\n",
            "The SVC class is based on the libsvm library, which implements an algorithm that\n",
            "\n",
            "--- Chunk 3771 ---\n",
            "supports the kernel trick.2 The training time complexity is usually between O(m2 × n)\n",
            "\n",
            "--- Chunk 3772 ---\n",
            "and O(m3 × n). Unfortunately, this means that it gets dreadfully slow when the num‐\n",
            "\n",
            "--- Chunk 3773 ---\n",
            "ber of training instances gets large (e.g., hundreds of thousands of instances). This\n",
            "\n",
            "--- Chunk 3774 ---\n",
            "algorithm is perfect for complex small or medium-sized training sets. It scales well\n",
            "\n",
            "--- Chunk 3775 ---\n",
            "with the number of features, especially with sparse features (i.e., when each instance\n",
            "\n",
            "--- Chunk 3776 ---\n",
            "has few nonzero features). In this case, the algorithm scales roughly with the average\n",
            "\n",
            "--- Chunk 3777 ---\n",
            "number of nonzero features per instance. Table 5-1 compares Scikit-Learn’s SVM\n",
            "classification classes.\n",
            "\n",
            "--- Chunk 3778 ---\n",
            "Table 5-1. Comparison of Scikit-Learn classes for SVM classification\n",
            "Class Time complexity Out-of-core support Scaling required Kernel trick\n",
            "\n",
            "--- Chunk 3779 ---\n",
            "LinearSVC O(m × n) No Yes No\n",
            "SGDClassifier O(m × n) Yes Yes No\n",
            "SVC O(m² × n) to O(m³ × n) No Yes Yes\n",
            "\n",
            "--- Chunk 3780 ---\n",
            "SVM Regression\n",
            "As mentioned earlier, the SVM algorithm is versatile: not only does it support linear\n",
            "\n",
            "--- Chunk 3781 ---\n",
            "and nonlinear classification, but it also supports linear and nonlinear regression. To\n",
            "\n",
            "--- Chunk 3782 ---\n",
            "use SVMs for regression instead of classification, the trick is to reverse the objective:\n",
            "\n",
            "--- Chunk 3783 ---\n",
            "instead of trying to fit the largest possible street between two classes while limiting\n",
            "\n",
            "--- Chunk 3784 ---\n",
            "margin violations, SVM Regression tries to fit as many instances as possible on the\n",
            "\n",
            "--- Chunk 3785 ---\n",
            "street while limiting margin violations (i.e., instances off the street). The width of the\n",
            "\n",
            "--- Chunk 3786 ---\n",
            "street is controlled by a hyperparameter, ϵ. Figure 5-10 shows two linear SVM\n",
            "\n",
            "--- Chunk 3787 ---\n",
            "1 Chih-Jen Lin et al., “A Dual Coordinate Descent Method for Large-Scale Linear SVM,” Proceedings of the 25th\n",
            "\n",
            "--- Chunk 3788 ---\n",
            "International Conference on Machine Learning (2008): 408–415.\n",
            "\n",
            "--- Chunk 3789 ---\n",
            "2 John Platt, “Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines”\n",
            "\n",
            "--- Chunk 3790 ---\n",
            "(Microsoft Research technical report, April 21, 1998), https://www.microsoft.com/en-us/research/wp-content/\n",
            "uploads/2016/02/tr-98-14.pdf.\n",
            "\n",
            "--- Chunk 3791 ---\n",
            "162 | Chapter 5: Support Vector Machines\n",
            "\n",
            "--- Chunk 3792 ---\n",
            "Regression models trained on some random linear data, one with a large margin (ϵ =\n",
            "1.5) and the other with a small margin (ϵ = 0.5).\n",
            "\n",
            "--- Chunk 3793 ---\n",
            "Figure 5-10. SVM Regression\n",
            "\n",
            "--- Chunk 3794 ---\n",
            "Adding more training instances within the margin does not affect the model’s predic‐\n",
            "tions; thus, the model is said to be ϵ-insensitive.\n",
            "\n",
            "--- Chunk 3795 ---\n",
            "You can use Scikit-Learn’s LinearSVR class to perform linear SVM Regression. The\n",
            "\n",
            "--- Chunk 3796 ---\n",
            "following code produces the model represented on the left in Figure 5-10 (the train‐\n",
            "ing data should be scaled and centered first):\n",
            "\n",
            "--- Chunk 3797 ---\n",
            "from sklearn.svm import LinearSVR\n",
            "\n",
            "svm_reg = LinearSVR(epsilon=1.5)\n",
            "svm_reg.fit(X, y)\n",
            "\n",
            "--- Chunk 3798 ---\n",
            "To tackle nonlinear regression tasks, you can use a kernelized SVM model.\n",
            "\n",
            "--- Chunk 3799 ---\n",
            "Figure 5-11 shows SVM Regression on a random quadratic training set, using a\n",
            "\n",
            "--- Chunk 3800 ---\n",
            "second-degree polynomial kernel. There is little regularization in the left plot (i.e., a\n",
            "\n",
            "--- Chunk 3801 ---\n",
            "large C value), and much more regularization in the right plot (i.e., a small C value).\n",
            "\n",
            "--- Chunk 3802 ---\n",
            "SVM Regression | 163\n",
            "\n",
            "\n",
            "\n",
            "Figure 5-11. SVM Regression using a second-degree polynomial kernel\n",
            "\n",
            "--- Chunk 3803 ---\n",
            "The following code uses Scikit-Learn’s SVR class (which supports the kernel trick) to\n",
            "produce the model represented on the left in Figure 5-11:\n",
            "\n",
            "--- Chunk 3804 ---\n",
            "from sklearn.svm import SVR\n",
            "\n",
            "svm_poly_reg = SVR(kernel=\"poly\", degree=2, C=100, epsilon=0.1)\n",
            "svm_poly_reg.fit(X, y)\n",
            "\n",
            "--- Chunk 3805 ---\n",
            "The SVR class is the regression equivalent of the SVC class, and the LinearSVR class is\n",
            "\n",
            "--- Chunk 3806 ---\n",
            "the regression equivalent of the LinearSVC class. The LinearSVR class scales linearly\n",
            "\n",
            "--- Chunk 3807 ---\n",
            "with the size of the training set (just like the LinearSVC class), while the SVR class gets\n",
            "\n",
            "--- Chunk 3808 ---\n",
            "much too slow when the training set grows large (just like the SVC class).\n",
            "\n",
            "--- Chunk 3809 ---\n",
            "SVMs can also be used for outlier detection; see Scikit-Learn’s doc‐\n",
            "umentation for more details.\n",
            "\n",
            "--- Chunk 3810 ---\n",
            "Under the Hood\n",
            "This section explains how SVMs make predictions and how their training algorithms\n",
            "\n",
            "--- Chunk 3811 ---\n",
            "work, starting with linear SVM classifiers. If you are just getting started with Machine\n",
            "\n",
            "--- Chunk 3812 ---\n",
            "Learning, you can safely skip it and go straight to the exercises at the end of this chap‐\n",
            "\n",
            "--- Chunk 3813 ---\n",
            "ter, and come back later when you want to get a deeper understanding of SVMs.\n",
            "\n",
            "--- Chunk 3814 ---\n",
            "First, a word about notations. In Chapter 4 we used the convention of putting all the\n",
            "\n",
            "--- Chunk 3815 ---\n",
            "model parameters in one vector θ, including the bias term θ0 and the input feature\n",
            "\n",
            "--- Chunk 3816 ---\n",
            "weights θ1 to θn, and adding a bias input x0 = 1 to all instances. In this chapter we will\n",
            "\n",
            "--- Chunk 3817 ---\n",
            "use a convention that is more convenient (and more common) when dealing with\n",
            "\n",
            "--- Chunk 3818 ---\n",
            "164 | Chapter 5: Support Vector Machines\n",
            "\n",
            "--- Chunk 3819 ---\n",
            "SVMs: the bias term will be called b, and the feature weights vector will be called w.\n",
            "No bias feature will be added to the input feature vectors.\n",
            "\n",
            "--- Chunk 3820 ---\n",
            "Decision Function and Predictions\n",
            "The linear SVM classifier model predicts the class of a new instance x by simply com‐\n",
            "\n",
            "--- Chunk 3821 ---\n",
            "puting the decision function w⊺ x + b = w1 x1 + ⋯ + wn xn + b. If the result is positive,\n",
            "\n",
            "--- Chunk 3822 ---\n",
            "the predicted class ŷ is the positive class (1), and otherwise it is the negative class (0);\n",
            "see Equation 5-2.\n",
            "\n",
            "--- Chunk 3823 ---\n",
            "Equation 5-2. Linear SVM classifier prediction\n",
            "0 if w⊺x + b < 0,\n",
            "\n",
            "y =\n",
            "1 if w⊺x + b ≥ 0\n",
            "\n",
            "--- Chunk 3824 ---\n",
            "Figure 5-12 shows the decision function that corresponds to the model in the left in\n",
            "\n",
            "--- Chunk 3825 ---\n",
            "Figure 5-4: it is a 2D plane because this dataset has two features (petal width and petal\n",
            "\n",
            "--- Chunk 3826 ---\n",
            "length). The decision boundary is the set of points where the decision function is\n",
            "\n",
            "--- Chunk 3827 ---\n",
            "equal to 0: it is the intersection of two planes, which is a straight line (represented by\n",
            "the thick solid line).3\n",
            "\n",
            "--- Chunk 3828 ---\n",
            "Figure 5-12. Decision function for the iris dataset\n",
            "\n",
            "--- Chunk 3829 ---\n",
            "3 More generally, when there are n features, the decision function is an n-dimensional hyperplane, and the deci‐\n",
            "\n",
            "--- Chunk 3830 ---\n",
            "sion boundary is an (n – 1)-dimensional hyperplane.\n",
            "\n",
            "--- Chunk 3831 ---\n",
            "Under the Hood | 165\n",
            "\n",
            "--- Chunk 3832 ---\n",
            "The dashed lines represent the points where the decision function is equal to 1 or –1:\n",
            "\n",
            "--- Chunk 3833 ---\n",
            "they are parallel and at equal distance to the decision boundary, and they form a mar‐\n",
            "\n",
            "--- Chunk 3834 ---\n",
            "gin around it. Training a linear SVM classifier means finding the values of w and b\n",
            "\n",
            "--- Chunk 3835 ---\n",
            "that make this margin as wide as possible while avoiding margin violations (hard\n",
            "margin) or limiting them (soft margin).\n",
            "\n",
            "--- Chunk 3836 ---\n",
            "Training Objective\n",
            "Consider the slope of the decision function: it is equal to the norm of the weight vec‐\n",
            "\n",
            "--- Chunk 3837 ---\n",
            "tor, ∥ w ∥. If we divide this slope by 2, the points where the decision function is equal\n",
            "\n",
            "--- Chunk 3838 ---\n",
            "to ±1 are going to be twice as far away from the decision boundary. In other words,\n",
            "\n",
            "--- Chunk 3839 ---\n",
            "dividing the slope by 2 will multiply the margin by 2. This may be easier to visualize\n",
            "\n",
            "--- Chunk 3840 ---\n",
            "in 2D, as shown in Figure 5-13. The smaller the weight vector w, the larger the\n",
            "margin.\n",
            "\n",
            "--- Chunk 3841 ---\n",
            "Figure 5-13. A smaller weight vector results in a larger margin\n",
            "\n",
            "--- Chunk 3842 ---\n",
            "So we want to minimize ∥ w ∥ to get a large margin. If we also want to avoid any\n",
            "\n",
            "--- Chunk 3843 ---\n",
            "margin violations (hard margin), then we need the decision function to be greater\n",
            "\n",
            "--- Chunk 3844 ---\n",
            "than 1 for all positive training instances and lower than –1 for negative training\n",
            "\n",
            "--- Chunk 3845 ---\n",
            "instances. If we define t(i) = –1 for negative instances (if y(i) = 0) and t(i) = 1 for positive\n",
            "\n",
            "--- Chunk 3846 ---\n",
            "instances (if y(i) = 1), then we can express this constraint as t(i)(w⊺ x(i) + b) ≥ 1 for all\n",
            "instances.\n",
            "\n",
            "--- Chunk 3847 ---\n",
            "instances.\n",
            "We can therefore express the hard margin linear SVM classifier objective as the con‐\n",
            "strained optimization problem in Equation 5-3.\n",
            "\n",
            "--- Chunk 3848 ---\n",
            "Equation 5-3. Hard margin linear SVM classifier objective\n",
            "\n",
            "minimize 1\n",
            "w, 2w⊺w\n",
            "\n",
            "b\n",
            "\n",
            "subject to t i w⊺x i + b ≥ 1 for i = 1, 2,⋯, m\n",
            "\n",
            "--- Chunk 3849 ---\n",
            "166 | Chapter 5: Support Vector Machines\n",
            "\n",
            "--- Chunk 3850 ---\n",
            "We are minimizing ½ w⊺ w, which is equal to ½∥ w ∥2, rather than\n",
            "minimizing ∥ w ∥. Indeed, ½∥ w ∥2 has a nice, simple derivative (it\n",
            "\n",
            "--- Chunk 3851 ---\n",
            "is just w), while ∥ w ∥ is not differentiable at w = 0. Optimization\n",
            "algorithms work much better on differentiable functions.\n",
            "\n",
            "--- Chunk 3852 ---\n",
            "To get the soft margin objective, we need to introduce a slack variable ζ(i) ≥ 0 for each\n",
            "\n",
            "--- Chunk 3853 ---\n",
            "instance:4 ζ(i) measures how much the ith instance is allowed to violate the margin. We\n",
            "\n",
            "--- Chunk 3854 ---\n",
            "now have two conflicting objectives: make the slack variables as small as possible to\n",
            "\n",
            "--- Chunk 3855 ---\n",
            "reduce the margin violations, and make ½ w⊺ w as small as possible to increase the\n",
            "\n",
            "--- Chunk 3856 ---\n",
            "margin. This is where the C hyperparameter comes in: it allows us to define the trade‐\n",
            "\n",
            "--- Chunk 3857 ---\n",
            "off between these two objectives. This gives us the constrained optimization problem\n",
            "in Equation 5-4.\n",
            "\n",
            "--- Chunk 3858 ---\n",
            "Equation 5-4. Soft margin linear SVM classifier objective\n",
            "\n",
            "minimize 1 m\n",
            "\n",
            "w, b, ζ 2w⊺w + C ∑ ζ i\n",
            "i = 1\n",
            "\n",
            "--- Chunk 3859 ---\n",
            "subject to t i w⊺x i + b ≥ 1 − ζ i and ζ i ≥ 0 for i = 1, 2,⋯, m\n",
            "\n",
            "--- Chunk 3860 ---\n",
            "Quadratic Programming\n",
            "The hard margin and soft margin problems are both convex quadratic optimization\n",
            "\n",
            "--- Chunk 3861 ---\n",
            "problems with linear constraints. Such problems are known as Quadratic Program‐\n",
            "\n",
            "--- Chunk 3862 ---\n",
            "ming (QP) problems. Many off-the-shelf solvers are available to solve QP problems\n",
            "\n",
            "--- Chunk 3863 ---\n",
            "by using a variety of techniques that are outside the scope of this book.5\n",
            "\n",
            "--- Chunk 3864 ---\n",
            "4 Zeta (ζ) is the sixth letter of the Greek alphabet.\n",
            "\n",
            "--- Chunk 3865 ---\n",
            "5 To learn more about Quadratic Programming, you can start by reading Stephen Boyd and Lieven Vandenber‐\n",
            "\n",
            "--- Chunk 3866 ---\n",
            "ghe’s book Convex Optimization (Cambridge University Press, 2004) or watch Richard Brown’s series of video\n",
            "lectures.\n",
            "\n",
            "Under the Hood | 167\n",
            "\n",
            "--- Chunk 3867 ---\n",
            "The general problem formulation is given by Equation 5-5.\n",
            "\n",
            "Equation 5-5. Quadratic Programming problem\n",
            "\n",
            "Minimize 1\n",
            "2p⊺Hp + f⊺p\n",
            "\n",
            "--- Chunk 3868 ---\n",
            "p\n",
            "subject to Ap ≤ b\n",
            "\n",
            "p is an np‐dimensional vector (np = number of parameters),\n",
            "H is an np × np matrix,\n",
            "\n",
            "--- Chunk 3869 ---\n",
            "where f is an np‐dimensional vector,\n",
            "A is an nc × np matrix (nc = number of constraints),\n",
            "b is an nc‐dimensional vector.\n",
            "\n",
            "--- Chunk 3870 ---\n",
            "Note that the expression A p ≤ b defines nc constraints: p⊺ a(i) ≤ b(i) for i = 1, 2, ⋯, nc,\n",
            "\n",
            "--- Chunk 3871 ---\n",
            "where a(i) is the vector containing the elements of the ith row of A and b(i) is the ith\n",
            "\n",
            "--- Chunk 3872 ---\n",
            "element of b.\n",
            "You can easily verify that if you set the QP parameters in the following way, you get\n",
            "the hard margin linear SVM classifier objective:\n",
            "\n",
            "--- Chunk 3873 ---\n",
            "• np = n + 1, where n is the number of features (the +1 is for the bias term).\n",
            "• nc = m, where m is the number of training instances.\n",
            "\n",
            "--- Chunk 3874 ---\n",
            "• H is the np × np identity matrix, except with a zero in the top-left cell (to ignore\n",
            "\n",
            "--- Chunk 3875 ---\n",
            "the bias term).\n",
            "• f = 0, an np-dimensional vector full of 0s.\n",
            "• b = –1, an nc-dimensional vector full of –1s.\n",
            "\n",
            "--- Chunk 3876 ---\n",
            "• a(i) = –t(i) ẋ(i), where ẋ(i) is equal to x(i) with an extra bias feature ẋ0 = 1.\n",
            "\n",
            "--- Chunk 3877 ---\n",
            "One way to train a hard margin linear SVM classifier is to use an off-the-shelf QP\n",
            "\n",
            "--- Chunk 3878 ---\n",
            "solver and pass it the preceding parameters. The resulting vector p will contain the\n",
            "\n",
            "--- Chunk 3879 ---\n",
            "bias term b = p0 and the feature weights wi = pi for i = 1, 2, ⋯, n. Similarly, you can\n",
            "\n",
            "--- Chunk 3880 ---\n",
            "use a QP solver to solve the soft margin problem (see the exercises at the end of the\n",
            "chapter).\n",
            "\n",
            "--- Chunk 3881 ---\n",
            "chapter).\n",
            "To use the kernel trick, we are going to look at a different constrained optimization\n",
            "problem.\n",
            "\n",
            "--- Chunk 3882 ---\n",
            "The Dual Problem\n",
            "Given a constrained optimization problem, known as the primal problem, it is possi‐\n",
            "\n",
            "--- Chunk 3883 ---\n",
            "ble to express a different but closely related problem, called its dual problem. The\n",
            "\n",
            "--- Chunk 3884 ---\n",
            "168 | Chapter 5: Support Vector Machines\n",
            "\n",
            "--- Chunk 3885 ---\n",
            "solution to the dual problem typically gives a lower bound to the solution of the pri‐\n",
            "\n",
            "--- Chunk 3886 ---\n",
            "mal problem, but under some conditions it can have the same solution as the primal\n",
            "\n",
            "--- Chunk 3887 ---\n",
            "problem. Luckily, the SVM problem happens to meet these conditions,6 so you can\n",
            "\n",
            "--- Chunk 3888 ---\n",
            "choose to solve the primal problem or the dual problem; both will have the same sol‐\n",
            "\n",
            "--- Chunk 3889 ---\n",
            "ution. Equation 5-6 shows the dual form of the linear SVM objective (if you are inter‐\n",
            "\n",
            "--- Chunk 3890 ---\n",
            "ested in knowing how to derive the dual problem from the primal problem, see\n",
            "Appendix C).\n",
            "\n",
            "--- Chunk 3891 ---\n",
            "Equation 5-6. Dual form of the linear SVM objective\n",
            "\n",
            "minimize 1 m m m\n",
            "\n",
            "α 2 ∑ ∑ α i α j t i t j x i ⊺x j − ∑ α i\n",
            "i = 1 j = 1 i = 1\n",
            "\n",
            "--- Chunk 3892 ---\n",
            "subject to α i ≥ 0 for i = 1, 2,⋯, m\n",
            "\n",
            "--- Chunk 3893 ---\n",
            "Once you find the vector α that minimizes this equation (using a QP solver), use\n",
            "Equation 5-7 to compute w and b  that minimize the primal problem.\n",
            "\n",
            "--- Chunk 3894 ---\n",
            "Equation 5-7. From the dual solution to the primal solution\n",
            "m\n",
            "\n",
            "w = ∑ α i t i x i\n",
            "i = 1\n",
            "\n",
            "m\n",
            "b = 1 i\n",
            "\n",
            "n ∑ t − w⊺x i\n",
            "s i = 1\n",
            "\n",
            "α i > 0\n",
            "\n",
            "--- Chunk 3895 ---\n",
            "The dual problem is faster to solve than the primal one when the number of training\n",
            "\n",
            "--- Chunk 3896 ---\n",
            "instances is smaller than the number of features. More importantly, the dual problem\n",
            "\n",
            "--- Chunk 3897 ---\n",
            "makes the kernel trick possible, while the primal does not. So what is this kernel trick,\n",
            "anyway?\n",
            "\n",
            "--- Chunk 3898 ---\n",
            "Kernelized SVMs\n",
            "Suppose you want to apply a second-degree polynomial transformation to a two-\n",
            "\n",
            "--- Chunk 3899 ---\n",
            "dimensional training set (such as the moons training set), then train a linear SVM\n",
            "\n",
            "--- Chunk 3900 ---\n",
            "classifier on the transformed training set. Equation 5-8 shows the second-degree pol‐\n",
            "ynomial mapping function ϕ that you want to apply.\n",
            "\n",
            "--- Chunk 3901 ---\n",
            "6 The objective function is convex, and the inequality constraints are continuously differentiable and convex\n",
            "functions.\n",
            "\n",
            "Under the Hood | 169\n",
            "\n",
            "--- Chunk 3902 ---\n",
            "Equation 5-8. Second-degree polynomial mapping\n",
            "x 2\n",
            "\n",
            "x 1\n",
            "ϕ x = ϕ 1 = 2 x x\n",
            "\n",
            "x 1 2\n",
            "2\n",
            "\n",
            "x 2\n",
            "2\n",
            "\n",
            "--- Chunk 3903 ---\n",
            "Notice that the transformed vector is 3D instead of 2D. Now let’s look at what hap‐\n",
            "\n",
            "--- Chunk 3904 ---\n",
            "pens to a couple of 2D vectors, a and b, if we apply this second-degree polynomial\n",
            "\n",
            "--- Chunk 3905 ---\n",
            "mapping and then compute the dot product7 of the transformed vectors (See Equa‐\n",
            "tion 5-9).\n",
            "\n",
            "--- Chunk 3906 ---\n",
            "Equation 5-9. Kernel trick for a second-degree polynomial mapping\n",
            "\n",
            "a 2 ⊺ 2\n",
            "1 b1\n",
            "\n",
            "ϕ a ⊺ϕ b = 2 a 2\n",
            "1a2 2 b1b2 = a 2\n",
            "\n",
            "1 b1 + 2a1b1a2b2 + a 2\n",
            "2 b 2\n",
            "\n",
            "--- Chunk 3907 ---\n",
            "2\n",
            "a 2\n",
            "\n",
            "2 b 2\n",
            "2\n",
            "\n",
            "a ⊺\n",
            "1 b 2\n",
            "\n",
            "= a1b1 + a 2\n",
            "2b2 = 1 = a⊺b 2\n",
            "\n",
            "a2 b2\n",
            "\n",
            "--- Chunk 3908 ---\n",
            "How about that? The dot product of the transformed vectors is equal to the square of\n",
            "the dot product of the original vectors: ϕ(a)⊺ ϕ(b) = (a⊺ b)2.\n",
            "\n",
            "--- Chunk 3909 ---\n",
            "Here is the key insight: if you apply the transformation ϕ to all training instances,\n",
            "\n",
            "--- Chunk 3910 ---\n",
            "then the dual problem (see Equation 5-6) will contain the dot product ϕ(x(i))⊺ ϕ(x(j)).\n",
            "\n",
            "--- Chunk 3911 ---\n",
            "But if ϕ is the second-degree polynomial transformation defined in Equation 5-8,\n",
            "\n",
            "--- Chunk 3912 ---\n",
            "then you can replace this dot product of transformed vectors simply by x i ⊺x j 2\n",
            "\n",
            "--- Chunk 3913 ---\n",
            ". So,\n",
            "you don’t need to transform the training instances at all; just replace the dot product\n",
            "\n",
            "--- Chunk 3914 ---\n",
            "by its square in Equation 5-6. The result will be strictly the same as if you had gone\n",
            "\n",
            "--- Chunk 3915 ---\n",
            "through the trouble of transforming the training set then fitting a linear SVM algo‐\n",
            "\n",
            "--- Chunk 3916 ---\n",
            "rithm, but this trick makes the whole process much more computationally efficient.\n",
            "\n",
            "--- Chunk 3917 ---\n",
            "The function K(a, b) = (a⊺ b)2 is a second-degree polynomial kernel. In Machine\n",
            "\n",
            "--- Chunk 3918 ---\n",
            "Learning, a kernel is a function capable of computing the dot product ϕ(a)⊺ ϕ(b),\n",
            "\n",
            "--- Chunk 3919 ---\n",
            "7 As explained in Chapter 4, the dot product of two vectors a and b is normally noted a · b. However, in\n",
            "\n",
            "--- Chunk 3920 ---\n",
            "Machine Learning, vectors are frequently represented as column vectors (i.e., single-column matrices), so the\n",
            "\n",
            "--- Chunk 3921 ---\n",
            "dot product is achieved by computing a⊺b. To remain consistent with the rest of the book, we will use this\n",
            "\n",
            "--- Chunk 3922 ---\n",
            "notation here, ignoring the fact that this technically results in a single-cell matrix rather than a scalar value.\n",
            "\n",
            "--- Chunk 3923 ---\n",
            "170 | Chapter 5: Support Vector Machines\n",
            "\n",
            "--- Chunk 3924 ---\n",
            "based only on the original vectors a and b, without having to compute (or even to\n",
            "\n",
            "--- Chunk 3925 ---\n",
            "know about) the transformation ϕ. Equation 5-10 lists some of the most commonly\n",
            "used kernels.\n",
            "\n",
            "--- Chunk 3926 ---\n",
            "Equation 5-10. Common kernels\n",
            "Linear: K a, b = a⊺b\n",
            "\n",
            "Polynomial: K a, b = γa⊺b + r d\n",
            "\n",
            "Gaussian RBF: K a, b = exp −γ∥ a − b 2\n",
            "∥\n",
            "\n",
            "--- Chunk 3927 ---\n",
            "Sigmoid: K a, b = tanh γa⊺b + r\n",
            "\n",
            "--- Chunk 3928 ---\n",
            "Mercer’s Theorem\n",
            "According to Mercer’s theorem, if a function K(a, b) respects a few mathematical con‐\n",
            "\n",
            "--- Chunk 3929 ---\n",
            "ditions called Mercer’s conditions (e.g., K must be continuous and symmetric in its\n",
            "\n",
            "--- Chunk 3930 ---\n",
            "arguments so that K(a, b) = K(b, a), etc.), then there exists a function ϕ that maps a\n",
            "\n",
            "--- Chunk 3931 ---\n",
            "and b into another space (possibly with much higher dimensions) such that K(a, b) =\n",
            "\n",
            "--- Chunk 3932 ---\n",
            "ϕ(a)⊺ ϕ(b). You can use K as a kernel because you know ϕ exists, even if you don’t\n",
            "\n",
            "--- Chunk 3933 ---\n",
            "know what ϕ is. In the case of the Gaussian RBF kernel, it can be shown that ϕ maps\n",
            "\n",
            "--- Chunk 3934 ---\n",
            "each training instance to an infinite-dimensional space, so it’s a good thing you don’t\n",
            "need to actually perform the mapping!\n",
            "\n",
            "--- Chunk 3935 ---\n",
            "Note that some frequently used kernels (such as the sigmoid kernel) don’t respect all\n",
            "\n",
            "--- Chunk 3936 ---\n",
            "of Mercer’s conditions, yet they generally work well in practice.\n",
            "\n",
            "--- Chunk 3937 ---\n",
            "There is still one loose end we must tie up. Equation 5-7 shows how to go from the\n",
            "\n",
            "--- Chunk 3938 ---\n",
            "dual solution to the primal solution in the case of a linear SVM classifier. But if you\n",
            "\n",
            "--- Chunk 3939 ---\n",
            "apply the kernel trick, you end up with equations that include ϕ(x(i)). In fact, w must\n",
            "\n",
            "--- Chunk 3940 ---\n",
            "have the same number of dimensions as ϕ(x(i)), which may be huge or even infinite,\n",
            "\n",
            "--- Chunk 3941 ---\n",
            "so you can’t compute it. But how can you make predictions without knowing w? Well,\n",
            "\n",
            "--- Chunk 3942 ---\n",
            "the good news is that you can plug the formula for w from Equation 5-7 into the deci‐\n",
            "\n",
            "--- Chunk 3943 ---\n",
            "sion function for a new instance x(n), and you get an equation with only dot products\n",
            "\n",
            "--- Chunk 3944 ---\n",
            "between input vectors. This makes it possible to use the kernel trick (Equation 5-11).\n",
            "\n",
            "--- Chunk 3945 ---\n",
            "Under the Hood | 171\n",
            "\n",
            "\n",
            "\n",
            "Equation 5-11. Making predictions with a kernelized SVM\n",
            "m ⊺\n",
            "\n",
            "h ϕ x n = w⊺ϕ x n + b = ∑ α i t i ϕ x i ϕ x n + b\n",
            "w, b i = 1\n",
            "\n",
            "--- Chunk 3946 ---\n",
            "m\n",
            "= ∑ α i t i ϕ x i ⊺ϕ x n + b\n",
            "\n",
            "i = 1\n",
            "m\n",
            "\n",
            "= ∑ α i t i K x i , x n + b\n",
            "i = 1\n",
            "\n",
            "α i > 0\n",
            "\n",
            "--- Chunk 3947 ---\n",
            "Note that since α(i) ≠ 0 only for support vectors, making predictions involves comput‐\n",
            "\n",
            "--- Chunk 3948 ---\n",
            "ing the dot product of the new input vector x(n) with only the support vectors, not all\n",
            "\n",
            "--- Chunk 3949 ---\n",
            "the training instances. Of course, you need to use the same trick to compute the bias\n",
            "term b  (Equation 5-12).\n",
            "\n",
            "--- Chunk 3950 ---\n",
            "Equation 5-12. Using the kernel trick to compute the bias term\n",
            "m m m ⊺\n",
            "\n",
            "b = 1\n",
            "n ∑ t i − w⊺ϕ x i = 1 α j t j ϕ x j ϕ x i\n",
            "\n",
            "--- Chunk 3951 ---\n",
            "s n ∑ t i − ∑\n",
            "i = 1 s i = 1 j = 1\n",
            "\n",
            "α i > 0 α i > 0\n",
            "\n",
            "m\n",
            "= 1 m\n",
            "\n",
            "n ∑ t i − ∑ α j t j K x i , x j\n",
            "s i = 1 j = 1\n",
            "\n",
            "α i > 0 α j > 0\n",
            "\n",
            "--- Chunk 3952 ---\n",
            "α i > 0 α j > 0\n",
            "\n",
            "If you are starting to get a headache, it’s perfectly normal: it’s an unfortunate side\n",
            "effect of the kernel trick.\n",
            "\n",
            "--- Chunk 3953 ---\n",
            "Online SVMs\n",
            "Before concluding this chapter, let’s take a quick look at online SVM classifiers (recall\n",
            "\n",
            "--- Chunk 3954 ---\n",
            "that online learning means learning incrementally, typically as new instances arrive).\n",
            "\n",
            "--- Chunk 3955 ---\n",
            "For linear SVM classifiers, one method for implementing an online SVM classifier is\n",
            "\n",
            "--- Chunk 3956 ---\n",
            "to use Gradient Descent (e.g., using SGDClassifier) to minimize the cost function in\n",
            "\n",
            "--- Chunk 3957 ---\n",
            "Equation 5-13, which is derived from the primal problem. Unfortunately, Gradient\n",
            "Descent converges much more slowly than the methods based on QP.\n",
            "\n",
            "--- Chunk 3958 ---\n",
            "172 | Chapter 5: Support Vector Machines\n",
            "\n",
            "\n",
            "\n",
            "Equation 5-13. Linear SVM classifier cost function\n",
            "m\n",
            "\n",
            "J w, b = 1\n",
            "2w⊺w + C ∑ max 0, 1 − t i w⊺x i + b\n",
            "\n",
            "--- Chunk 3959 ---\n",
            "i = 1\n",
            "\n",
            "--- Chunk 3960 ---\n",
            "The first sum in the cost function will push the model to have a small weight vector\n",
            "\n",
            "--- Chunk 3961 ---\n",
            "w, leading to a larger margin. The second sum computes the total of all margin viola‐\n",
            "\n",
            "--- Chunk 3962 ---\n",
            "tions. An instance’s margin violation is equal to 0 if it is located off the street and on\n",
            "\n",
            "--- Chunk 3963 ---\n",
            "the correct side, or else it is proportional to the distance to the correct side of the\n",
            "\n",
            "--- Chunk 3964 ---\n",
            "street. Minimizing this term ensures that the model makes the margin violations as\n",
            "small and as few as possible.\n",
            "\n",
            "--- Chunk 3965 ---\n",
            "Hinge Loss\n",
            "The function max(0, 1 – t) is called the hinge loss function (see the following image).\n",
            "\n",
            "--- Chunk 3966 ---\n",
            "It is equal to 0 when t ≥ 1. Its derivative (slope) is equal to –1 if t < 1 and 0 if t > 1. It is\n",
            "\n",
            "--- Chunk 3967 ---\n",
            "not differentiable at t = 1, but just like for Lasso Regression (see “Lasso Regression”\n",
            "\n",
            "--- Chunk 3968 ---\n",
            "on page 137), you can still use Gradient Descent using any subderivative at t = 1 (i.e.,\n",
            "any value between –1 and 0).\n",
            "\n",
            "--- Chunk 3969 ---\n",
            "It is also possible to implement online kernelized SVMs, as described in the papers\n",
            "\n",
            "--- Chunk 3970 ---\n",
            "“Incremental and Decremental Support Vector Machine Learning”8 and “Fast Kernel\n",
            "\n",
            "--- Chunk 3971 ---\n",
            "Classifiers with Online and Active Learning”.9 These kernelized SVMs are imple‐\n",
            "\n",
            "--- Chunk 3972 ---\n",
            "8 Gert Cauwenberghs and Tomaso Poggio, “Incremental and Decremental Support Vector Machine Learning,”\n",
            "\n",
            "--- Chunk 3973 ---\n",
            "Proceedings of the 13th International Conference on Neural Information Processing Systems (2000): 388–394.\n",
            "\n",
            "--- Chunk 3974 ---\n",
            "9 Antoine Bordes et al., “Fast Kernel Classifiers with Online and Active Learning,” Journal of Machine Learning\n",
            "Research 6 (2005): 1579–1619.\n",
            "\n",
            "--- Chunk 3975 ---\n",
            "Under the Hood | 173\n",
            "\n",
            "--- Chunk 3976 ---\n",
            "mented in Matlab and C++. For large-scale nonlinear problems, you may want to\n",
            "consider using neural networks instead (see Part II).\n",
            "\n",
            "--- Chunk 3977 ---\n",
            "Exercises\n",
            "1. What is the fundamental idea behind Support Vector Machines?\n",
            "2. What is a support vector?\n",
            "\n",
            "--- Chunk 3978 ---\n",
            "3. Why is it important to scale the inputs when using SVMs?\n",
            "4. Can an SVM classifier output a confidence score when it classifies an instance?\n",
            "\n",
            "--- Chunk 3979 ---\n",
            "What about a probability?\n",
            "5. Should you use the primal or the dual form of the SVM problem to train a model\n",
            "\n",
            "--- Chunk 3980 ---\n",
            "on a training set with millions of instances and hundreds of features?\n",
            "\n",
            "--- Chunk 3981 ---\n",
            "6. Say you’ve trained an SVM classifier with an RBF kernel, but it seems to underfit\n",
            "\n",
            "--- Chunk 3982 ---\n",
            "the training set. Should you increase or decrease γ (gamma)? What about C?\n",
            "\n",
            "--- Chunk 3983 ---\n",
            "7. How should you set the QP parameters (H, f, A, and b) to solve the soft margin\n",
            "\n",
            "--- Chunk 3984 ---\n",
            "linear SVM classifier problem using an off-the-shelf QP solver?\n",
            "8. Train a LinearSVC on a linearly separable dataset. Then train an SVC and a\n",
            "\n",
            "--- Chunk 3985 ---\n",
            "SGDClassifier on the same dataset. See if you can get them to produce roughly\n",
            "the same model.\n",
            "\n",
            "--- Chunk 3986 ---\n",
            "9. Train an SVM classifier on the MNIST dataset. Since SVM classifiers are binary\n",
            "\n",
            "--- Chunk 3987 ---\n",
            "classifiers, you will need to use one-versus-the-rest to classify all 10 digits. You\n",
            "\n",
            "--- Chunk 3988 ---\n",
            "may want to tune the hyperparameters using small validation sets to speed up the\n",
            "process. What accuracy can you reach?\n",
            "\n",
            "--- Chunk 3989 ---\n",
            "10. Train an SVM regressor on the California housing dataset.\n",
            "\n",
            "Solutions to these exercises are available in Appendix A.\n",
            "\n",
            "--- Chunk 3990 ---\n",
            "174 | Chapter 5: Support Vector Machines\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER 6\n",
            "Decision Trees\n",
            "\n",
            "--- Chunk 3991 ---\n",
            "Like SVMs, Decision Trees are versatile Machine Learning algorithms that can per‐\n",
            "\n",
            "--- Chunk 3992 ---\n",
            "form both classification and regression tasks, and even multioutput tasks. They are\n",
            "\n",
            "--- Chunk 3993 ---\n",
            "powerful algorithms, capable of fitting complex datasets. For example, in Chapter 2\n",
            "\n",
            "--- Chunk 3994 ---\n",
            "you trained a DecisionTreeRegressor model on the California housing dataset, fit‐\n",
            "ting it perfectly (actually, overfitting it).\n",
            "\n",
            "--- Chunk 3995 ---\n",
            "Decision Trees are also the fundamental components of Random Forests (see Chap‐\n",
            "\n",
            "--- Chunk 3996 ---\n",
            "ter 7), which are among the most powerful Machine Learning algorithms available\n",
            "today.\n",
            "\n",
            "--- Chunk 3997 ---\n",
            "today.\n",
            "In this chapter we will start by discussing how to train, visualize, and make predic‐\n",
            "\n",
            "--- Chunk 3998 ---\n",
            "tions with Decision Trees. Then we will go through the CART training algorithm\n",
            "\n",
            "--- Chunk 3999 ---\n",
            "used by Scikit-Learn, and we will discuss how to regularize trees and use them for\n",
            "\n",
            "--- Chunk 4000 ---\n",
            "regression tasks. Finally, we will discuss some of the limitations of Decision Trees.\n",
            "\n",
            "--- Chunk 4001 ---\n",
            "Training and Visualizing a Decision Tree\n",
            "To understand Decision Trees, let’s build one and take a look at how it makes predic‐\n",
            "\n",
            "--- Chunk 4002 ---\n",
            "tions. The following code trains a DecisionTreeClassifier on the iris dataset (see\n",
            "Chapter 4):\n",
            "\n",
            "--- Chunk 4003 ---\n",
            "from sklearn.datasets import load_iris\n",
            "from sklearn.tree import DecisionTreeClassifier\n",
            "\n",
            "--- Chunk 4004 ---\n",
            "iris = load_iris()\n",
            "X = iris.data[:, 2:] # petal length and width\n",
            "y = iris.target\n",
            "\n",
            "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
            "tree_clf.fit(X, y)\n",
            "\n",
            "--- Chunk 4005 ---\n",
            "175\n",
            "\n",
            "--- Chunk 4006 ---\n",
            "You can visualize the trained Decision Tree by first using the export_graphviz()\n",
            "method to output a graph definition file called iris_tree.dot:\n",
            "\n",
            "--- Chunk 4007 ---\n",
            "from sklearn.tree import export_graphviz\n",
            "\n",
            "--- Chunk 4008 ---\n",
            "export_graphviz(\n",
            "        tree_clf,\n",
            "        out_file=image_path(\"iris_tree.dot\"),\n",
            "        feature_names=iris.feature_names[2:],\n",
            "\n",
            "--- Chunk 4009 ---\n",
            "class_names=iris.target_names,\n",
            "        rounded=True,\n",
            "        filled=True\n",
            "    )\n",
            "\n",
            "--- Chunk 4010 ---\n",
            "Then you can use the dot command-line tool from the Graphviz package to convert\n",
            "\n",
            "--- Chunk 4011 ---\n",
            "this .dot file to a variety of formats, such as PDF or PNG.1 This command line con‐\n",
            "verts the .dot file to a .png image file:\n",
            "\n",
            "--- Chunk 4012 ---\n",
            "$ dot -Tpng iris_tree.dot -o iris_tree.png\n",
            "\n",
            "Your first Decision Tree looks like Figure 6-1.\n",
            "\n",
            "Figure 6-1. Iris Decision Tree\n",
            "\n",
            "--- Chunk 4013 ---\n",
            "Making Predictions\n",
            "Let’s see how the tree represented in Figure 6-1 makes predictions. Suppose you find\n",
            "\n",
            "--- Chunk 4014 ---\n",
            "an iris flower and you want to classify it. You start at the root node (depth 0, at the\n",
            "\n",
            "--- Chunk 4015 ---\n",
            "top): this node asks whether the flower’s petal length is smaller than 2.45 cm. If it is,\n",
            "\n",
            "--- Chunk 4016 ---\n",
            "then you move down to the root’s left child node (depth 1, left). In this case, it is a leaf\n",
            "\n",
            "--- Chunk 4017 ---\n",
            "1 Graphviz is an open source graph visualization software package, available at http://www.graphviz.org/.\n",
            "\n",
            "176 | Chapter 6: Decision Trees\n",
            "\n",
            "--- Chunk 4018 ---\n",
            "node (i.e., it does not have any child nodes), so it does not ask any questions: simply\n",
            "\n",
            "--- Chunk 4019 ---\n",
            "look at the predicted class for that node, and the Decision Tree predicts that your\n",
            "flower is an Iris setosa (class=setosa).\n",
            "\n",
            "--- Chunk 4020 ---\n",
            "Now suppose you find another flower, and this time the petal length is greater than\n",
            "\n",
            "--- Chunk 4021 ---\n",
            "2.45 cm. You must move down to the root’s right child node (depth 1, right), which is\n",
            "\n",
            "--- Chunk 4022 ---\n",
            "not a leaf node, so the node asks another question: is the petal width smaller than\n",
            "\n",
            "--- Chunk 4023 ---\n",
            "1.75 cm? If it is, then your flower is most likely an Iris versicolor (depth 2, left). If not,\n",
            "\n",
            "--- Chunk 4024 ---\n",
            "it is likely an Iris virginica (depth 2, right). It’s really that simple.\n",
            "\n",
            "--- Chunk 4025 ---\n",
            "One of the many qualities of Decision Trees is that they require\n",
            "very little data preparation. In fact, they don’t require feature scal‐\n",
            "\n",
            "--- Chunk 4026 ---\n",
            "ing or centering at all.\n",
            "\n",
            "--- Chunk 4027 ---\n",
            "A node’s samples attribute counts how many training instances it applies to. For\n",
            "\n",
            "--- Chunk 4028 ---\n",
            "example, 100 training instances have a petal length greater than 2.45 cm (depth 1,\n",
            "\n",
            "--- Chunk 4029 ---\n",
            "right), and of those 100, 54 have a petal width smaller than 1.75 cm (depth 2, left). A\n",
            "\n",
            "--- Chunk 4030 ---\n",
            "node’s value attribute tells you how many training instances of each class this node\n",
            "\n",
            "--- Chunk 4031 ---\n",
            "applies to: for example, the bottom-right node applies to 0 Iris setosa, 1 Iris versicolor,\n",
            "\n",
            "--- Chunk 4032 ---\n",
            "and 45 Iris virginica. Finally, a node’s gini attribute measures its impurity: a node is\n",
            "\n",
            "--- Chunk 4033 ---\n",
            "“pure” (gini=0) if all training instances it applies to belong to the same class. For\n",
            "\n",
            "--- Chunk 4034 ---\n",
            "example, since the depth-1 left node applies only to Iris setosa training instances, it is\n",
            "\n",
            "--- Chunk 4035 ---\n",
            "pure and its gini score is 0. Equation 6-1 shows how the training algorithm com‐\n",
            "\n",
            "--- Chunk 4036 ---\n",
            "putes the gini score Gi of the ith node. The depth-2 left node has a gini score equal to\n",
            "1 – (0/54)2 – (49/54)2 – (5/54)2 ≈ 0.168.\n",
            "\n",
            "--- Chunk 4037 ---\n",
            "Equation 6-1. Gini impurity\n",
            "n\n",
            "\n",
            "Gi = 1 − ∑ p 2\n",
            "k = 1 i, k\n",
            "\n",
            "In this equation:\n",
            "\n",
            "--- Chunk 4038 ---\n",
            "In this equation:\n",
            "\n",
            "• pi,k is the ratio of class k instances among the training instances in the ith node.\n",
            "\n",
            "--- Chunk 4039 ---\n",
            "Scikit-Learn uses the CART algorithm, which produces only binary\n",
            "trees: nonleaf nodes always have two children (i.e., questions only\n",
            "\n",
            "--- Chunk 4040 ---\n",
            "have yes/no answers). However, other algorithms such as ID3 can\n",
            "produce Decision Trees with nodes that have more than two\n",
            "children.\n",
            "\n",
            "--- Chunk 4041 ---\n",
            "Making Predictions | 177\n",
            "\n",
            "--- Chunk 4042 ---\n",
            "Figure 6-2 shows this Decision Tree’s decision boundaries. The thick vertical line rep‐\n",
            "\n",
            "--- Chunk 4043 ---\n",
            "resents the decision boundary of the root node (depth 0): petal length = 2.45 cm.\n",
            "\n",
            "--- Chunk 4044 ---\n",
            "Since the lefthand area is pure (only Iris setosa), it cannot be split any further. How‐\n",
            "\n",
            "--- Chunk 4045 ---\n",
            "ever, the righthand area is impure, so the depth-1 right node splits it at petal width =\n",
            "\n",
            "--- Chunk 4046 ---\n",
            "1.75 cm (represented by the dashed line). Since max_depth was set to 2, the Decision\n",
            "\n",
            "--- Chunk 4047 ---\n",
            "Tree stops right there. If you set max_depth to 3, then the two depth-2 nodes would\n",
            "\n",
            "--- Chunk 4048 ---\n",
            "each add another decision boundary (represented by the dotted lines).\n",
            "\n",
            "--- Chunk 4049 ---\n",
            "Figure 6-2. Decision Tree decision boundaries\n",
            "\n",
            "--- Chunk 4050 ---\n",
            "Model Interpretation: White Box Versus Black Box\n",
            "Decision Trees are intuitive, and their decisions are easy to interpret. Such models are\n",
            "\n",
            "--- Chunk 4051 ---\n",
            "often called white box models. In contrast, as we will see, Random Forests or neural\n",
            "\n",
            "--- Chunk 4052 ---\n",
            "networks are generally considered black box models. They make great predictions,\n",
            "\n",
            "--- Chunk 4053 ---\n",
            "and you can easily check the calculations that they performed to make these predic‐\n",
            "\n",
            "--- Chunk 4054 ---\n",
            "tions; nevertheless, it is usually hard to explain in simple terms why the predictions\n",
            "\n",
            "--- Chunk 4055 ---\n",
            "were made. For example, if a neural network says that a particular person appears on\n",
            "\n",
            "--- Chunk 4056 ---\n",
            "a picture, it is hard to know what contributed to this prediction: did the model recog‐\n",
            "\n",
            "--- Chunk 4057 ---\n",
            "nize that person’s eyes? Their mouth? Their nose? Their shoes? Or even the couch\n",
            "\n",
            "--- Chunk 4058 ---\n",
            "that they were sitting on? Conversely, Decision Trees provide nice, simple classifica‐\n",
            "\n",
            "--- Chunk 4059 ---\n",
            "tion rules that can even be applied manually if need be (e.g., for flower classification).\n",
            "\n",
            "--- Chunk 4060 ---\n",
            "Estimating Class Probabilities\n",
            "A Decision Tree can also estimate the probability that an instance belongs to a partic‐\n",
            "\n",
            "--- Chunk 4061 ---\n",
            "ular class k. First it traverses the tree to find the leaf node for this instance, and then it\n",
            "\n",
            "--- Chunk 4062 ---\n",
            "returns the ratio of training instances of class k in this node. For example, suppose\n",
            "\n",
            "--- Chunk 4063 ---\n",
            "you have found a flower whose petals are 5 cm long and 1.5 cm wide. The\n",
            "\n",
            "--- Chunk 4064 ---\n",
            "178 | Chapter 6: Decision Trees\n",
            "\n",
            "--- Chunk 4065 ---\n",
            "corresponding leaf node is the depth-2 left node, so the Decision Tree should output\n",
            "\n",
            "--- Chunk 4066 ---\n",
            "the following probabilities: 0% for Iris setosa (0/54), 90.7% for Iris versicolor (49/54),\n",
            "\n",
            "--- Chunk 4067 ---\n",
            "and 9.3% for Iris virginica (5/54). And if you ask it to predict the class, it should out‐\n",
            "\n",
            "--- Chunk 4068 ---\n",
            "put Iris versicolor (class 1) because it has the highest probability. Let’s check this:\n",
            "\n",
            "--- Chunk 4069 ---\n",
            ">>> tree_clf.predict_proba([[5, 1.5]])\n",
            "array([[0.        , 0.90740741, 0.09259259]])\n",
            ">>> tree_clf.predict([[5, 1.5]])\n",
            "array([1])\n",
            "\n",
            "--- Chunk 4070 ---\n",
            "Perfect! Notice that the estimated probabilities would be identical anywhere else in\n",
            "\n",
            "--- Chunk 4071 ---\n",
            "the bottom-right rectangle of Figure 6-2—for example, if the petals were 6 cm long\n",
            "\n",
            "--- Chunk 4072 ---\n",
            "and 1.5 cm wide (even though it seems obvious that it would most likely be an Iris\n",
            "virginica in this case).\n",
            "\n",
            "--- Chunk 4073 ---\n",
            "The CART Training Algorithm\n",
            "Scikit-Learn uses the Classification and Regression Tree (CART) algorithm to train\n",
            "\n",
            "--- Chunk 4074 ---\n",
            "Decision Trees (also called “growing” trees). The algorithm works by first splitting the\n",
            "\n",
            "--- Chunk 4075 ---\n",
            "training set into two subsets using a single feature k and a threshold tk (e.g., “petal\n",
            "\n",
            "--- Chunk 4076 ---\n",
            "length ≤ 2.45 cm”). How does it choose k and tk? It searches for the pair (k, tk) that\n",
            "\n",
            "--- Chunk 4077 ---\n",
            "produces the purest subsets (weighted by their size). Equation 6-2 gives the cost func‐\n",
            "tion that the algorithm tries to minimize.\n",
            "\n",
            "--- Chunk 4078 ---\n",
            "Equation 6-2. CART cost function for classification\n",
            "m\n",
            "\n",
            "J k, tk = left mri h\n",
            "m G g t\n",
            "\n",
            "left + m Gright\n",
            "\n",
            "--- Chunk 4079 ---\n",
            "left + m Gright\n",
            "\n",
            "G\n",
            "where left/right measures the impurity of the left/right subset,\n",
            "\n",
            "--- Chunk 4080 ---\n",
            "mleft/right is the number of instances in the left/right subset.\n",
            "\n",
            "--- Chunk 4081 ---\n",
            "Once the CART algorithm has successfully split the training set in two, it splits the\n",
            "\n",
            "--- Chunk 4082 ---\n",
            "subsets using the same logic, then the sub-subsets, and so on, recursively. It stops\n",
            "\n",
            "--- Chunk 4083 ---\n",
            "recursing once it reaches the maximum depth (defined by the max_depth hyperpara‐\n",
            "\n",
            "--- Chunk 4084 ---\n",
            "meter), or if it cannot find a split that will reduce impurity. A few other hyperparame‐\n",
            "\n",
            "--- Chunk 4085 ---\n",
            "ters (described in a moment) control additional stopping conditions\n",
            "(min_samples_split, min_samples_leaf, min_weight_fraction_leaf, and\n",
            "\n",
            "--- Chunk 4086 ---\n",
            "max_leaf_nodes).\n",
            "\n",
            "--- Chunk 4087 ---\n",
            "The CART Training Algorithm | 179\n",
            "\n",
            "--- Chunk 4088 ---\n",
            "As you can see, the CART algorithm is a greedy algorithm: it greed‐\n",
            "ily searches for an optimum split at the top level, then repeats the\n",
            "\n",
            "--- Chunk 4089 ---\n",
            "process at each subsequent level. It does not check whether or not\n",
            "the split will lead to the lowest possible impurity several levels\n",
            "\n",
            "--- Chunk 4090 ---\n",
            "down. A greedy algorithm often produces a solution that’s reasona‐\n",
            "bly good but not guaranteed to be optimal.\n",
            "\n",
            "--- Chunk 4091 ---\n",
            "Unfortunately, finding the optimal tree is known to be an NP-\n",
            "Complete problem:2 it requires O(exp(m)) time, making the prob‐\n",
            "\n",
            "--- Chunk 4092 ---\n",
            "lem intractable even for small training sets. This is why we must\n",
            "settle for a “reasonably good” solution.\n",
            "\n",
            "--- Chunk 4093 ---\n",
            "Computational Complexity\n",
            "Making predictions requires traversing the Decision Tree from the root to a leaf.\n",
            "\n",
            "--- Chunk 4094 ---\n",
            "Decision Trees generally are approximately balanced, so traversing the Decision Tree\n",
            "\n",
            "--- Chunk 4095 ---\n",
            "requires going through roughly O(log2(m)) nodes.3 Since each node only requires\n",
            "\n",
            "--- Chunk 4096 ---\n",
            "checking the value of one feature, the overall prediction complexity is O(log2(m)),\n",
            "\n",
            "--- Chunk 4097 ---\n",
            "independent of the number of features. So predictions are very fast, even when deal‐\n",
            "ing with large training sets.\n",
            "\n",
            "--- Chunk 4098 ---\n",
            "The training algorithm compares all features (or less if max_features is set) on all\n",
            "\n",
            "--- Chunk 4099 ---\n",
            "samples at each node. Comparing all features on all samples at each node results in a\n",
            "\n",
            "--- Chunk 4100 ---\n",
            "training complexity of O(n × m log2(m)). For small training sets (less than a few thou‐\n",
            "\n",
            "--- Chunk 4101 ---\n",
            "sand instances), Scikit-Learn can speed up training by presorting the data (set pre\n",
            "\n",
            "--- Chunk 4102 ---\n",
            "sort=True), but doing that slows down training considerably for larger training sets.\n",
            "\n",
            "--- Chunk 4103 ---\n",
            "Gini Impurity or Entropy?\n",
            "By default, the Gini impurity measure is used, but you can select the entropy impurity\n",
            "\n",
            "--- Chunk 4104 ---\n",
            "measure instead by setting the criterion hyperparameter to \"entropy\". The concept\n",
            "\n",
            "--- Chunk 4105 ---\n",
            "of entropy originated in thermodynamics as a measure of molecular disorder:\n",
            "\n",
            "--- Chunk 4106 ---\n",
            "entropy approaches zero when molecules are still and well ordered. Entropy later\n",
            "\n",
            "--- Chunk 4107 ---\n",
            "spread to a wide variety of domains, including Shannon’s information theory, where it\n",
            "\n",
            "--- Chunk 4108 ---\n",
            "measures the average information content of a message:4 entropy is zero when all\n",
            "\n",
            "--- Chunk 4109 ---\n",
            "messages are identical. In Machine Learning, entropy is frequently used as an\n",
            "\n",
            "--- Chunk 4110 ---\n",
            "2 P is the set of problems that can be solved in polynomial time. NP is the set of problems whose solutions can\n",
            "\n",
            "--- Chunk 4111 ---\n",
            "be verified in polynomial time. An NP-Hard problem is a problem to which any NP problem can be reduced\n",
            "\n",
            "--- Chunk 4112 ---\n",
            "in polynomial time. An NP-Complete problem is both NP and NP-Hard. A major open mathematical ques‐\n",
            "\n",
            "--- Chunk 4113 ---\n",
            "tion is whether or not P = NP. If P ≠ NP (which seems likely), then no polynomial algorithm will ever be\n",
            "\n",
            "--- Chunk 4114 ---\n",
            "found for any NP-Complete problem (except perhaps on a quantum computer).\n",
            "\n",
            "--- Chunk 4115 ---\n",
            "3 log2 is the binary logarithm. It is equal to log2(m) = log(m) / log(2).\n",
            "4 A reduction of entropy is often called an information gain.\n",
            "\n",
            "--- Chunk 4116 ---\n",
            "180 | Chapter 6: Decision Trees\n",
            "\n",
            "--- Chunk 4117 ---\n",
            "impurity measure: a set’s entropy is zero when it contains instances of only one class.\n",
            "\n",
            "--- Chunk 4118 ---\n",
            "Equation 6-3 shows the definition of the entropy of the ith node. For example, the\n",
            "\n",
            "--- Chunk 4119 ---\n",
            "depth-2 left node in Figure 6-1 has an entropy equal to –(49/54) log2 (49/54) – (5/54)\n",
            "log2 (5/54) ≈ 0.445.\n",
            "\n",
            "--- Chunk 4120 ---\n",
            "Equation 6-3. Entropy\n",
            "n\n",
            "\n",
            "Hi = − ∑ p\n",
            "k = 1 i, k log2 pi, k\n",
            "\n",
            "pi, k ≠ 0\n",
            "\n",
            "--- Chunk 4121 ---\n",
            "So, should you use Gini impurity or entropy? The truth is, most of the time it does\n",
            "\n",
            "--- Chunk 4122 ---\n",
            "not make a big difference: they lead to similar trees. Gini impurity is slightly faster to\n",
            "\n",
            "--- Chunk 4123 ---\n",
            "compute, so it is a good default. However, when they differ, Gini impurity tends to\n",
            "\n",
            "--- Chunk 4124 ---\n",
            "isolate the most frequent class in its own branch of the tree, while entropy tends to\n",
            "produce slightly more balanced trees.5\n",
            "\n",
            "--- Chunk 4125 ---\n",
            "Regularization Hyperparameters\n",
            "Decision Trees make very few assumptions about the training data (as opposed to lin‐\n",
            "\n",
            "--- Chunk 4126 ---\n",
            "ear models, which assume that the data is linear, for example). If left unconstrained,\n",
            "\n",
            "--- Chunk 4127 ---\n",
            "the tree structure will adapt itself to the training data, fitting it very closely—indeed,\n",
            "\n",
            "--- Chunk 4128 ---\n",
            "most likely overfitting it. Such a model is often called a nonparametric model, not\n",
            "\n",
            "--- Chunk 4129 ---\n",
            "because it does not have any parameters (it often has a lot) but because the number of\n",
            "\n",
            "--- Chunk 4130 ---\n",
            "parameters is not determined prior to training, so the model structure is free to stick\n",
            "\n",
            "--- Chunk 4131 ---\n",
            "closely to the data. In contrast, a parametric model, such as a linear model, has a pre‐\n",
            "\n",
            "--- Chunk 4132 ---\n",
            "determined number of parameters, so its degree of freedom is limited, reducing the\n",
            "risk of overfitting (but increasing the risk of underfitting).\n",
            "\n",
            "--- Chunk 4133 ---\n",
            "To avoid overfitting the training data, you need to restrict the Decision Tree’s freedom\n",
            "\n",
            "--- Chunk 4134 ---\n",
            "during training. As you know by now, this is called regularization. The regularization\n",
            "\n",
            "--- Chunk 4135 ---\n",
            "hyperparameters depend on the algorithm used, but generally you can at least restrict\n",
            "\n",
            "--- Chunk 4136 ---\n",
            "the maximum depth of the Decision Tree. In Scikit-Learn, this is controlled by the\n",
            "\n",
            "--- Chunk 4137 ---\n",
            "max_depth hyperparameter (the default value is None, which means unlimited).\n",
            "\n",
            "--- Chunk 4138 ---\n",
            "Reducing max_depth will regularize the model and thus reduce the risk of overfitting.\n",
            "\n",
            "--- Chunk 4139 ---\n",
            "The DecisionTreeClassifier class has a few other parameters that similarly restrict\n",
            "\n",
            "--- Chunk 4140 ---\n",
            "the shape of the Decision Tree: min_samples_split (the minimum number of sam‐\n",
            "\n",
            "--- Chunk 4141 ---\n",
            "ples a node must have before it can be split), min_samples_leaf (the minimum num‐\n",
            "\n",
            "--- Chunk 4142 ---\n",
            "ber of samples a leaf node must have), min_weight_fraction_leaf (same as\n",
            "\n",
            "--- Chunk 4143 ---\n",
            "5 See Sebastian Raschka’s interesting analysis for more details.\n",
            "\n",
            "Regularization Hyperparameters | 181\n",
            "\n",
            "--- Chunk 4144 ---\n",
            "min_samples_leaf but expressed as a fraction of the total number of weighted\n",
            "\n",
            "--- Chunk 4145 ---\n",
            "instances), max_leaf_nodes (the maximum number of leaf nodes), and max_features\n",
            "\n",
            "--- Chunk 4146 ---\n",
            "(the maximum number of features that are evaluated for splitting at each node).\n",
            "\n",
            "--- Chunk 4147 ---\n",
            "Increasing min_* hyperparameters or reducing max_* hyperparameters will regularize\n",
            "the model.\n",
            "\n",
            "--- Chunk 4148 ---\n",
            "Other algorithms work by first training the Decision Tree without\n",
            "restrictions, then pruning (deleting) unnecessary nodes. A node\n",
            "\n",
            "--- Chunk 4149 ---\n",
            "whose children are all leaf nodes is considered unnecessary if the\n",
            "purity improvement it provides is not statistically significant. Stan‐\n",
            "\n",
            "--- Chunk 4150 ---\n",
            "dard statistical tests, such as the χ2 test (chi-squared test), are used\n",
            "to estimate the probability that the improvement is purely the\n",
            "\n",
            "--- Chunk 4151 ---\n",
            "result of chance (which is called the null hypothesis). If this proba‐\n",
            "bility, called the p-value, is higher than a given threshold (typically\n",
            "\n",
            "--- Chunk 4152 ---\n",
            "5%, controlled by a hyperparameter), then the node is considered\n",
            "unnecessary and its children are deleted. The pruning continues\n",
            "\n",
            "--- Chunk 4153 ---\n",
            "until all unnecessary nodes have been pruned.\n",
            "\n",
            "--- Chunk 4154 ---\n",
            "Figure 6-3 shows two Decision Trees trained on the moons dataset (introduced in\n",
            "\n",
            "--- Chunk 4155 ---\n",
            "Chapter 5). On the left the Decision Tree is trained with the default hyperparameters\n",
            "\n",
            "--- Chunk 4156 ---\n",
            "(i.e., no restrictions), and on the right it’s trained with min_samples_leaf=4. It is\n",
            "\n",
            "--- Chunk 4157 ---\n",
            "quite obvious that the model on the left is overfitting, and the model on the right will\n",
            "probably generalize better.\n",
            "\n",
            "--- Chunk 4158 ---\n",
            "Figure 6-3. Regularization using min_samples_leaf\n",
            "\n",
            "182 | Chapter 6: Decision Trees\n",
            "\n",
            "--- Chunk 4159 ---\n",
            "Regression\n",
            "Decision Trees are also capable of performing regression tasks. Let’s build a regres‐\n",
            "\n",
            "--- Chunk 4160 ---\n",
            "sion tree using Scikit-Learn’s DecisionTreeRegressor class, training it on a noisy\n",
            "quadratic dataset with max_depth=2:\n",
            "\n",
            "--- Chunk 4161 ---\n",
            "from sklearn.tree import DecisionTreeRegressor\n",
            "\n",
            "tree_reg = DecisionTreeRegressor(max_depth=2)\n",
            "tree_reg.fit(X, y)\n",
            "\n",
            "--- Chunk 4162 ---\n",
            "The resulting tree is represented in Figure 6-4.\n",
            "\n",
            "Figure 6-4. A Decision Tree for regression\n",
            "\n",
            "--- Chunk 4163 ---\n",
            "This tree looks very similar to the classification tree you built earlier. The main differ‐\n",
            "\n",
            "--- Chunk 4164 ---\n",
            "ence is that instead of predicting a class in each node, it predicts a value. For example,\n",
            "\n",
            "--- Chunk 4165 ---\n",
            "suppose you want to make a prediction for a new instance with x1 = 0.6. You traverse\n",
            "\n",
            "--- Chunk 4166 ---\n",
            "the tree starting at the root, and you eventually reach the leaf node that predicts\n",
            "\n",
            "--- Chunk 4167 ---\n",
            "value=0.111. This prediction is the average target value of the 110 training instances\n",
            "\n",
            "--- Chunk 4168 ---\n",
            "associated with this leaf node, and it results in a mean squared error equal to 0.015\n",
            "over these 110 instances.\n",
            "\n",
            "--- Chunk 4169 ---\n",
            "This model’s predictions are represented on the left in Figure 6-5. If you set\n",
            "\n",
            "--- Chunk 4170 ---\n",
            "max_depth=3, you get the predictions represented on the right. Notice how the pre‐\n",
            "\n",
            "--- Chunk 4171 ---\n",
            "dicted value for each region is always the average target value of the instances in that\n",
            "\n",
            "--- Chunk 4172 ---\n",
            "region. The algorithm splits each region in a way that makes most training instances\n",
            "as close as possible to that predicted value.\n",
            "\n",
            "--- Chunk 4173 ---\n",
            "Regression | 183\n",
            "\n",
            "\n",
            "\n",
            "Figure 6-5. Predictions of two Decision Tree regression models\n",
            "\n",
            "--- Chunk 4174 ---\n",
            "The CART algorithm works mostly the same way as earlier, except that instead of try‐\n",
            "\n",
            "--- Chunk 4175 ---\n",
            "ing to split the training set in a way that minimizes impurity, it now tries to split the\n",
            "\n",
            "--- Chunk 4176 ---\n",
            "training set in a way that minimizes the MSE. Equation 6-4 shows the cost function\n",
            "that the algorithm tries to minimize.\n",
            "\n",
            "--- Chunk 4177 ---\n",
            "Equation 6-4. CART cost function for regression\n",
            "\n",
            "MSEnode = ∑ y\n",
            "i e y i 2\n",
            "∈ node nod −\n",
            "\n",
            "m\n",
            "J k, t left m\n",
            "\n",
            "k = m MSE right\n",
            "left + m MSEright where\n",
            "\n",
            "--- Chunk 4178 ---\n",
            "ynode = 1\n",
            "m ∑ y i\n",
            "\n",
            "node i ∈ node\n",
            "\n",
            "--- Chunk 4179 ---\n",
            "Just like for classification tasks, Decision Trees are prone to overfitting when dealing\n",
            "\n",
            "--- Chunk 4180 ---\n",
            "with regression tasks. Without any regularization (i.e., using the default hyperpara‐\n",
            "\n",
            "--- Chunk 4181 ---\n",
            "meters), you get the predictions on the left in Figure 6-6. These predictions are obvi‐\n",
            "\n",
            "--- Chunk 4182 ---\n",
            "ously overfitting the training set very badly. Just setting min_samples_leaf=10 results\n",
            "\n",
            "--- Chunk 4183 ---\n",
            "in a much more reasonable model, represented on the right in Figure 6-6.\n",
            "\n",
            "--- Chunk 4184 ---\n",
            "Figure 6-6. Regularizing a Decision Tree regressor\n",
            "\n",
            "184 | Chapter 6: Decision Trees\n",
            "\n",
            "--- Chunk 4185 ---\n",
            "Instability\n",
            "Hopefully by now you are convinced that Decision Trees have a lot going for them:\n",
            "\n",
            "--- Chunk 4186 ---\n",
            "they are simple to understand and interpret, easy to use, versatile, and powerful.\n",
            "\n",
            "--- Chunk 4187 ---\n",
            "However, they do have a few limitations. First, as you may have noticed, Decision\n",
            "\n",
            "--- Chunk 4188 ---\n",
            "Trees love orthogonal decision boundaries (all splits are perpendicular to an axis),\n",
            "\n",
            "--- Chunk 4189 ---\n",
            "which makes them sensitive to training set rotation. For example, Figure 6-7 shows a\n",
            "\n",
            "--- Chunk 4190 ---\n",
            "simple linearly separable dataset: on the left, a Decision Tree can split it easily, while\n",
            "\n",
            "--- Chunk 4191 ---\n",
            "on the right, after the dataset is rotated by 45°, the decision boundary looks unneces‐\n",
            "\n",
            "--- Chunk 4192 ---\n",
            "sarily convoluted. Although both Decision Trees fit the training set perfectly, it is very\n",
            "\n",
            "--- Chunk 4193 ---\n",
            "likely that the model on the right will not generalize well. One way to limit this prob‐\n",
            "\n",
            "--- Chunk 4194 ---\n",
            "lem is to use Principal Component Analysis (see Chapter 8), which often results in a\n",
            "better orientation of the training data.\n",
            "\n",
            "--- Chunk 4195 ---\n",
            "Figure 6-7. Sensitivity to training set rotation\n",
            "\n",
            "--- Chunk 4196 ---\n",
            "More generally, the main issue with Decision Trees is that they are very sensitive to\n",
            "\n",
            "--- Chunk 4197 ---\n",
            "small variations in the training data. For example, if you just remove the widest Iris\n",
            "\n",
            "--- Chunk 4198 ---\n",
            "versicolor from the iris training set (the one with petals 4.8 cm long and 1.8 cm wide)\n",
            "\n",
            "--- Chunk 4199 ---\n",
            "and train a new Decision Tree, you may get the model represented in Figure 6-8. As\n",
            "\n",
            "--- Chunk 4200 ---\n",
            "you can see, it looks very different from the previous Decision Tree (Figure 6-2).\n",
            "\n",
            "--- Chunk 4201 ---\n",
            "Actually, since the training algorithm used by Scikit-Learn is stochastic,6 you may\n",
            "\n",
            "--- Chunk 4202 ---\n",
            "get very different models even on the same training data (unless you set the\n",
            "random_state hyperparameter).\n",
            "\n",
            "--- Chunk 4203 ---\n",
            "6 It randomly selects the set of features to evaluate at each node.\n",
            "\n",
            "Instability | 185\n",
            "\n",
            "\n",
            "\n",
            "Figure 6-8. Sensitivity to training set details\n",
            "\n",
            "--- Chunk 4204 ---\n",
            "Random Forests can limit this instability by averaging predictions over many trees, as\n",
            "we will see in the next chapter.\n",
            "\n",
            "--- Chunk 4205 ---\n",
            "Exercises\n",
            "1. What is the approximate depth of a Decision Tree trained (without restrictions)\n",
            "\n",
            "--- Chunk 4206 ---\n",
            "on a training set with one million instances?\n",
            "2. Is a node’s Gini impurity generally lower or greater than its parent’s? Is it gener‐\n",
            "\n",
            "--- Chunk 4207 ---\n",
            "ally lower/greater, or always lower/greater?\n",
            "3. If a Decision Tree is overfitting the training set, is it a good idea to try decreasing\n",
            "\n",
            "--- Chunk 4208 ---\n",
            "max_depth?\n",
            "4. If a Decision Tree is underfitting the training set, is it a good idea to try scaling\n",
            "\n",
            "--- Chunk 4209 ---\n",
            "the input features?\n",
            "5. If it takes one hour to train a Decision Tree on a training set containing 1 million\n",
            "\n",
            "--- Chunk 4210 ---\n",
            "instances, roughly how much time will it take to train another Decision Tree on a\n",
            "training set containing 10 million instances?\n",
            "\n",
            "--- Chunk 4211 ---\n",
            "6. If your training set contains 100,000 instances, will setting presort=True speed\n",
            "up training?\n",
            "\n",
            "--- Chunk 4212 ---\n",
            "7. Train and fine-tune a Decision Tree for the moons dataset by following these\n",
            "steps:\n",
            "\n",
            "--- Chunk 4213 ---\n",
            "steps:\n",
            "a. Use make_moons(n_samples=10000, noise=0.4) to generate a moons dataset.\n",
            "\n",
            "--- Chunk 4214 ---\n",
            "b. Use train_test_split() to split the dataset into a training set and a test set.\n",
            "\n",
            "--- Chunk 4215 ---\n",
            "186 | Chapter 6: Decision Trees\n",
            "\n",
            "--- Chunk 4216 ---\n",
            "c. Use grid search with cross-validation (with the help of the GridSearchCV\n",
            "class) to find good hyperparameter values for a DecisionTreeClassifier.\n",
            "\n",
            "--- Chunk 4217 ---\n",
            "Hint: try various values for max_leaf_nodes.\n",
            "\n",
            "--- Chunk 4218 ---\n",
            "d. Train it on the full training set using these hyperparameters, and measure\n",
            "\n",
            "--- Chunk 4219 ---\n",
            "your model’s performance on the test set. You should get roughly 85% to 87%\n",
            "accuracy.\n",
            "\n",
            "--- Chunk 4220 ---\n",
            "8. Grow a forest by following these steps:\n",
            "a. Continuing the previous exercise, generate 1,000 subsets of the training set,\n",
            "\n",
            "--- Chunk 4221 ---\n",
            "each containing 100 instances selected randomly. Hint: you can use Scikit-\n",
            "Learn’s ShuffleSplit class for this.\n",
            "\n",
            "--- Chunk 4222 ---\n",
            "b. Train one Decision Tree on each subset, using the best hyperparameter values\n",
            "\n",
            "--- Chunk 4223 ---\n",
            "found in the previous exercise. Evaluate these 1,000 Decision Trees on the test\n",
            "\n",
            "--- Chunk 4224 ---\n",
            "set. Since they were trained on smaller sets, these Decision Trees will likely\n",
            "perform worse than the first Decision Tree, achieving only about 80%\n",
            "\n",
            "--- Chunk 4225 ---\n",
            "accuracy.\n",
            "\n",
            "--- Chunk 4226 ---\n",
            "c. Now comes the magic. For each test set instance, generate the predictions of\n",
            "\n",
            "--- Chunk 4227 ---\n",
            "the 1,000 Decision Trees, and keep only the most frequent prediction (you can\n",
            "\n",
            "--- Chunk 4228 ---\n",
            "use SciPy’s mode() function for this). This approach gives you majority-vote\n",
            "predictions over the test set.\n",
            "\n",
            "--- Chunk 4229 ---\n",
            "d. Evaluate these predictions on the test set: you should obtain a slightly higher\n",
            "\n",
            "--- Chunk 4230 ---\n",
            "accuracy than your first model (about 0.5 to 1.5% higher). Congratulations,\n",
            "you have trained a Random Forest classifier!\n",
            "\n",
            "--- Chunk 4231 ---\n",
            "Solutions to these exercises are available in Appendix A.\n",
            "\n",
            "Exercises | 187\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER 7\n",
            "Ensemble Learning and Random Forests\n",
            "\n",
            "--- Chunk 4232 ---\n",
            "Suppose you pose a complex question to thousands of random people, then aggregate\n",
            "\n",
            "--- Chunk 4233 ---\n",
            "their answers. In many cases you will find that this aggregated answer is better than\n",
            "\n",
            "--- Chunk 4234 ---\n",
            "an expert’s answer. This is called the wisdom of the crowd. Similarly, if you aggregate\n",
            "\n",
            "--- Chunk 4235 ---\n",
            "the predictions of a group of predictors (such as classifiers or regressors), you will\n",
            "\n",
            "--- Chunk 4236 ---\n",
            "often get better predictions than with the best individual predictor. A group of pre‐\n",
            "\n",
            "--- Chunk 4237 ---\n",
            "dictors is called an ensemble; thus, this technique is called Ensemble Learning, and an\n",
            "Ensemble Learning algorithm is called an Ensemble method.\n",
            "\n",
            "--- Chunk 4238 ---\n",
            "As an example of an Ensemble method, you can train a group of Decision Tree classi‐\n",
            "\n",
            "--- Chunk 4239 ---\n",
            "fiers, each on a different random subset of the training set. To make predictions, you\n",
            "\n",
            "--- Chunk 4240 ---\n",
            "obtain the predictions of all the individual trees, then predict the class that gets the\n",
            "\n",
            "--- Chunk 4241 ---\n",
            "most votes (see the last exercise in Chapter 6). Such an ensemble of Decision Trees is\n",
            "\n",
            "--- Chunk 4242 ---\n",
            "called a Random Forest, and despite its simplicity, this is one of the most powerful\n",
            "Machine Learning algorithms available today.\n",
            "\n",
            "--- Chunk 4243 ---\n",
            "As discussed in Chapter 2, you will often use Ensemble methods near the end of a\n",
            "\n",
            "--- Chunk 4244 ---\n",
            "project, once you have already built a few good predictors, to combine them into an\n",
            "\n",
            "--- Chunk 4245 ---\n",
            "even better predictor. In fact, the winning solutions in Machine Learning competi‐\n",
            "\n",
            "--- Chunk 4246 ---\n",
            "tions often involve several Ensemble methods (most famously in the Netflix Prize\n",
            "competition).\n",
            "\n",
            "--- Chunk 4247 ---\n",
            "competition).\n",
            "In this chapter we will discuss the most popular Ensemble methods, including bag‐\n",
            "\n",
            "--- Chunk 4248 ---\n",
            "ging, boosting, and stacking. We will also explore Random Forests.\n",
            "\n",
            "--- Chunk 4249 ---\n",
            "Voting Classifiers\n",
            "Suppose you have trained a few classifiers, each one achieving about 80% accuracy.\n",
            "\n",
            "--- Chunk 4250 ---\n",
            "You may have a Logistic Regression classifier, an SVM classifier, a Random Forest\n",
            "\n",
            "--- Chunk 4251 ---\n",
            "classifier, a K-Nearest Neighbors classifier, and perhaps a few more (see Figure 7-1).\n",
            "\n",
            "--- Chunk 4252 ---\n",
            "189\n",
            "\n",
            "\n",
            "\n",
            "Figure 7-1. Training diverse classifiers\n",
            "\n",
            "--- Chunk 4253 ---\n",
            "A very simple way to create an even better classifier is to aggregate the predictions of\n",
            "\n",
            "--- Chunk 4254 ---\n",
            "each classifier and predict the class that gets the most votes. This majority-vote classi‐\n",
            "fier is called a hard voting classifier (see Figure 7-2).\n",
            "\n",
            "--- Chunk 4255 ---\n",
            "Figure 7-2. Hard voting classifier predictions\n",
            "\n",
            "--- Chunk 4256 ---\n",
            "Somewhat surprisingly, this voting classifier often achieves a higher accuracy than the\n",
            "\n",
            "--- Chunk 4257 ---\n",
            "best classifier in the ensemble. In fact, even if each classifier is a weak learner (mean‐\n",
            "\n",
            "--- Chunk 4258 ---\n",
            "ing it does only slightly better than random guessing), the ensemble can still be a\n",
            "\n",
            "--- Chunk 4259 ---\n",
            "strong learner (achieving high accuracy), provided there are a sufficient number of\n",
            "weak learners and they are sufficiently diverse.\n",
            "\n",
            "--- Chunk 4260 ---\n",
            "190 | Chapter 7: Ensemble Learning and Random Forests\n",
            "\n",
            "--- Chunk 4261 ---\n",
            "How is this possible? The following analogy can help shed some light on this mystery.\n",
            "\n",
            "--- Chunk 4262 ---\n",
            "Suppose you have a slightly biased coin that has a 51% chance of coming up heads\n",
            "\n",
            "--- Chunk 4263 ---\n",
            "and 49% chance of coming up tails. If you toss it 1,000 times, you will generally get\n",
            "\n",
            "--- Chunk 4264 ---\n",
            "more or less 510 heads and 490 tails, and hence a majority of heads. If you do the\n",
            "\n",
            "--- Chunk 4265 ---\n",
            "math, you will find that the probability of obtaining a majority of heads after 1,000\n",
            "\n",
            "--- Chunk 4266 ---\n",
            "tosses is close to 75%. The more you toss the coin, the higher the probability (e.g.,\n",
            "\n",
            "--- Chunk 4267 ---\n",
            "with 10,000 tosses, the probability climbs over 97%). This is due to the law of large\n",
            "\n",
            "--- Chunk 4268 ---\n",
            "numbers: as you keep tossing the coin, the ratio of heads gets closer and closer to the\n",
            "\n",
            "--- Chunk 4269 ---\n",
            "probability of heads (51%). Figure 7-3 shows 10 series of biased coin tosses. You can\n",
            "\n",
            "--- Chunk 4270 ---\n",
            "see that as the number of tosses increases, the ratio of heads approaches 51%. Eventu‐\n",
            "\n",
            "--- Chunk 4271 ---\n",
            "ally all 10 series end up so close to 51% that they are consistently above 50%.\n",
            "\n",
            "--- Chunk 4272 ---\n",
            "Figure 7-3. The law of large numbers\n",
            "\n",
            "--- Chunk 4273 ---\n",
            "Similarly, suppose you build an ensemble containing 1,000 classifiers that are individ‐\n",
            "\n",
            "--- Chunk 4274 ---\n",
            "ually correct only 51% of the time (barely better than random guessing). If you pre‐\n",
            "\n",
            "--- Chunk 4275 ---\n",
            "dict the majority voted class, you can hope for up to 75% accuracy! However, this is\n",
            "\n",
            "--- Chunk 4276 ---\n",
            "only true if all classifiers are perfectly independent, making uncorrelated errors,\n",
            "\n",
            "--- Chunk 4277 ---\n",
            "which is clearly not the case because they are trained on the same data. They are likely\n",
            "\n",
            "--- Chunk 4278 ---\n",
            "to make the same types of errors, so there will be many majority votes for the wrong\n",
            "class, reducing the ensemble’s accuracy.\n",
            "\n",
            "--- Chunk 4279 ---\n",
            "Ensemble methods work best when the predictors are as independ‐\n",
            "ent from one another as possible. One way to get diverse classifiers\n",
            "\n",
            "--- Chunk 4280 ---\n",
            "is to train them using very different algorithms. This increases the\n",
            "chance that they will make very different types of errors, improving\n",
            "\n",
            "--- Chunk 4281 ---\n",
            "the ensemble’s accuracy.\n",
            "\n",
            "--- Chunk 4282 ---\n",
            "The following code creates and trains a voting classifier in Scikit-Learn, composed of\n",
            "\n",
            "--- Chunk 4283 ---\n",
            "three diverse classifiers (the training set is the moons dataset, introduced in Chap‐\n",
            "ter 5):\n",
            "\n",
            "--- Chunk 4284 ---\n",
            "Voting Classifiers | 191\n",
            "\n",
            "--- Chunk 4285 ---\n",
            "from sklearn.ensemble import RandomForestClassifier\n",
            "from sklearn.ensemble import VotingClassifier\n",
            "\n",
            "--- Chunk 4286 ---\n",
            "from sklearn.linear_model import LogisticRegression\n",
            "from sklearn.svm import SVC\n",
            "\n",
            "--- Chunk 4287 ---\n",
            "log_clf = LogisticRegression()\n",
            "rnd_clf = RandomForestClassifier()\n",
            "svm_clf = SVC()\n",
            "\n",
            "--- Chunk 4288 ---\n",
            "voting_clf = VotingClassifier(\n",
            "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
            "    voting='hard')\n",
            "\n",
            "--- Chunk 4289 ---\n",
            "voting='hard')\n",
            "voting_clf.fit(X_train, y_train)\n",
            "\n",
            "--- Chunk 4290 ---\n",
            "Let’s look at each classifier’s accuracy on the test set:\n",
            ">>> from sklearn.metrics import accuracy_score\n",
            "\n",
            "--- Chunk 4291 ---\n",
            ">>> for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
            "...     clf.fit(X_train, y_train)\n",
            "...     y_pred = clf.predict(X_test)\n",
            "\n",
            "--- Chunk 4292 ---\n",
            "...     print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
            "...\n",
            "LogisticRegression 0.864\n",
            "RandomForestClassifier 0.896\n",
            "SVC 0.888\n",
            "\n",
            "--- Chunk 4293 ---\n",
            "SVC 0.888\n",
            "VotingClassifier 0.904\n",
            "\n",
            "--- Chunk 4294 ---\n",
            "There you have it! The voting classifier slightly outperforms all the individual\n",
            "classifiers.\n",
            "\n",
            "--- Chunk 4295 ---\n",
            "classifiers.\n",
            "If all classifiers are able to estimate class probabilities (i.e., they all have a pre\n",
            "\n",
            "--- Chunk 4296 ---\n",
            "dict_proba() method), then you can tell Scikit-Learn to predict the class with the\n",
            "\n",
            "--- Chunk 4297 ---\n",
            "highest class probability, averaged over all the individual classifiers. This is called soft\n",
            "\n",
            "--- Chunk 4298 ---\n",
            "voting. It often achieves higher performance than hard voting because it gives more\n",
            "\n",
            "--- Chunk 4299 ---\n",
            "weight to highly confident votes. All you need to do is replace voting=\"hard\" with\n",
            "\n",
            "--- Chunk 4300 ---\n",
            "voting=\"soft\" and ensure that all classifiers can estimate class probabilities. This is\n",
            "\n",
            "--- Chunk 4301 ---\n",
            "not the case for the SVC class by default, so you need to set its probability hyper‐\n",
            "\n",
            "--- Chunk 4302 ---\n",
            "parameter to True (this will make the SVC class use cross-validation to estimate class\n",
            "\n",
            "--- Chunk 4303 ---\n",
            "probabilities, slowing down training, and it will add a predict_proba() method). If\n",
            "\n",
            "--- Chunk 4304 ---\n",
            "you modify the preceding code to use soft voting, you will find that the voting classi‐\n",
            "fier achieves over 91.2% accuracy!\n",
            "\n",
            "--- Chunk 4305 ---\n",
            "Bagging and Pasting\n",
            "One way to get a diverse set of classifiers is to use very different training algorithms,\n",
            "\n",
            "--- Chunk 4306 ---\n",
            "as just discussed. Another approach is to use the same training algorithm for every\n",
            "\n",
            "--- Chunk 4307 ---\n",
            "predictor and train them on different random subsets of the training set. When sam‐\n",
            "\n",
            "--- Chunk 4308 ---\n",
            "192 | Chapter 7: Ensemble Learning and Random Forests\n",
            "\n",
            "--- Chunk 4309 ---\n",
            "pling is performed with replacement, this method is called bagging1 (short for boot‐\n",
            "\n",
            "--- Chunk 4310 ---\n",
            "strap aggregating2). When sampling is performed without replacement, it is called\n",
            "pasting.3\n",
            "\n",
            "--- Chunk 4311 ---\n",
            "In other words, both bagging and pasting allow training instances to be sampled sev‐\n",
            "\n",
            "--- Chunk 4312 ---\n",
            "eral times across multiple predictors, but only bagging allows training instances to be\n",
            "\n",
            "--- Chunk 4313 ---\n",
            "sampled several times for the same predictor. This sampling and training process is\n",
            "represented in Figure 7-4.\n",
            "\n",
            "--- Chunk 4314 ---\n",
            "Figure 7-4. Bagging and pasting involves training several predictors on different random\n",
            "samples of the training set\n",
            "\n",
            "--- Chunk 4315 ---\n",
            "Once all predictors are trained, the ensemble can make a prediction for a new\n",
            "\n",
            "--- Chunk 4316 ---\n",
            "instance by simply aggregating the predictions of all predictors. The aggregation\n",
            "\n",
            "--- Chunk 4317 ---\n",
            "function is typically the statistical mode (i.e., the most frequent prediction, just like a\n",
            "\n",
            "--- Chunk 4318 ---\n",
            "hard voting classifier) for classification, or the average for regression. Each individual\n",
            "\n",
            "--- Chunk 4319 ---\n",
            "predictor has a higher bias than if it were trained on the original training set, but\n",
            "\n",
            "--- Chunk 4320 ---\n",
            "aggregation reduces both bias and variance.4 Generally, the net result is that the\n",
            "\n",
            "--- Chunk 4321 ---\n",
            "ensemble has a similar bias but a lower variance than a single predictor trained on the\n",
            "original training set.\n",
            "\n",
            "--- Chunk 4322 ---\n",
            "1 Leo Breiman, “Bagging Predictors,” Machine Learning 24, no. 2 (1996): 123–140.\n",
            "\n",
            "--- Chunk 4323 ---\n",
            "2 In statistics, resampling with replacement is called bootstrapping.\n",
            "\n",
            "--- Chunk 4324 ---\n",
            "3 Leo Breiman, “Pasting Small Votes for Classification in Large Databases and On-Line,” Machine Learning 36,\n",
            "\n",
            "--- Chunk 4325 ---\n",
            "no. 1–2 (1999): 85–103.\n",
            "4 Bias and variance were introduced in Chapter 4.\n",
            "\n",
            "Bagging and Pasting | 193\n",
            "\n",
            "--- Chunk 4326 ---\n",
            "As you can see in Figure 7-4, predictors can all be trained in parallel, via different\n",
            "\n",
            "--- Chunk 4327 ---\n",
            "CPU cores or even different servers. Similarly, predictions can be made in parallel.\n",
            "\n",
            "--- Chunk 4328 ---\n",
            "This is one of the reasons bagging and pasting are such popular methods: they scale\n",
            "very well.\n",
            "\n",
            "--- Chunk 4329 ---\n",
            "Bagging and Pasting in Scikit-Learn\n",
            "Scikit-Learn offers a simple API for both bagging and pasting with the BaggingClas\n",
            "\n",
            "--- Chunk 4330 ---\n",
            "sifier class (or BaggingRegressor for regression). The following code trains an\n",
            "\n",
            "--- Chunk 4331 ---\n",
            "ensemble of 500 Decision Tree classifiers:5 each is trained on 100 training instances\n",
            "\n",
            "--- Chunk 4332 ---\n",
            "randomly sampled from the training set with replacement (this is an example of bag‐\n",
            "\n",
            "--- Chunk 4333 ---\n",
            "ging, but if you want to use pasting instead, just set bootstrap=False). The n_jobs\n",
            "\n",
            "--- Chunk 4334 ---\n",
            "parameter tells Scikit-Learn the number of CPU cores to use for training and predic‐\n",
            "tions (–1 tells Scikit-Learn to use all available cores):\n",
            "\n",
            "--- Chunk 4335 ---\n",
            "from sklearn.ensemble import BaggingClassifier\n",
            "from sklearn.tree import DecisionTreeClassifier\n",
            "\n",
            "--- Chunk 4336 ---\n",
            "bag_clf = BaggingClassifier(\n",
            "    DecisionTreeClassifier(), n_estimators=500,\n",
            "    max_samples=100, bootstrap=True, n_jobs=-1)\n",
            "\n",
            "--- Chunk 4337 ---\n",
            "bag_clf.fit(X_train, y_train)\n",
            "y_pred = bag_clf.predict(X_test)\n",
            "\n",
            "--- Chunk 4338 ---\n",
            "The BaggingClassifier automatically performs soft voting\n",
            "instead of hard voting if the base classifier can estimate class proba‐\n",
            "\n",
            "--- Chunk 4339 ---\n",
            "bilities (i.e., if it has a predict_proba() method), which is the case\n",
            "with Decision Tree classifiers.\n",
            "\n",
            "--- Chunk 4340 ---\n",
            "Figure 7-5 compares the decision boundary of a single Decision Tree with the deci‐\n",
            "\n",
            "--- Chunk 4341 ---\n",
            "sion boundary of a bagging ensemble of 500 trees (from the preceding code), both\n",
            "\n",
            "--- Chunk 4342 ---\n",
            "trained on the moons dataset. As you can see, the ensemble’s predictions will likely\n",
            "\n",
            "--- Chunk 4343 ---\n",
            "generalize much better than the single Decision Tree’s predictions: the ensemble has a\n",
            "\n",
            "--- Chunk 4344 ---\n",
            "comparable bias but a smaller variance (it makes roughly the same number of errors\n",
            "on the training set, but the decision boundary is less irregular).\n",
            "\n",
            "--- Chunk 4345 ---\n",
            "5 max_samples can alternatively be set to a float between 0.0 and 1.0, in which case the max number of instances\n",
            "\n",
            "--- Chunk 4346 ---\n",
            "to sample is equal to the size of the training set times max_samples.\n",
            "\n",
            "--- Chunk 4347 ---\n",
            "194 | Chapter 7: Ensemble Learning and Random Forests\n",
            "\n",
            "\n",
            "\n",
            "Figure 7-5. A single Decision Tree (left) versus a bagging ensemble of 500 trees (right)\n",
            "\n",
            "--- Chunk 4348 ---\n",
            "Bootstrapping introduces a bit more diversity in the subsets that each predictor is\n",
            "\n",
            "--- Chunk 4349 ---\n",
            "trained on, so bagging ends up with a slightly higher bias than pasting; but the extra\n",
            "\n",
            "--- Chunk 4350 ---\n",
            "diversity also means that the predictors end up being less correlated, so the ensemble’s\n",
            "\n",
            "--- Chunk 4351 ---\n",
            "variance is reduced. Overall, bagging often results in better models, which explains\n",
            "\n",
            "--- Chunk 4352 ---\n",
            "why it is generally preferred. However, if you have spare time and CPU power, you\n",
            "\n",
            "--- Chunk 4353 ---\n",
            "can use cross-validation to evaluate both bagging and pasting and select the one that\n",
            "works best.\n",
            "\n",
            "--- Chunk 4354 ---\n",
            "Out-of-Bag Evaluation\n",
            "With bagging, some instances may be sampled several times for any given predictor,\n",
            "\n",
            "--- Chunk 4355 ---\n",
            "while others may not be sampled at all. By default a BaggingClassifier samples m\n",
            "\n",
            "--- Chunk 4356 ---\n",
            "training instances with replacement (bootstrap=True), where m is the size of the\n",
            "\n",
            "--- Chunk 4357 ---\n",
            "training set. This means that only about 63% of the training instances are sampled on\n",
            "\n",
            "--- Chunk 4358 ---\n",
            "average for each predictor.6 The remaining 37% of the training instances that are not\n",
            "\n",
            "--- Chunk 4359 ---\n",
            "sampled are called out-of-bag (oob) instances. Note that they are not the same 37%\n",
            "for all predictors.\n",
            "\n",
            "--- Chunk 4360 ---\n",
            "for all predictors.\n",
            "Since a predictor never sees the oob instances during training, it can be evaluated on\n",
            "\n",
            "--- Chunk 4361 ---\n",
            "these instances, without the need for a separate validation set. You can evaluate the\n",
            "\n",
            "--- Chunk 4362 ---\n",
            "ensemble itself by averaging out the oob evaluations of each predictor.\n",
            "\n",
            "--- Chunk 4363 ---\n",
            "In Scikit-Learn, you can set oob_score=True when creating a BaggingClassifier to\n",
            "\n",
            "--- Chunk 4364 ---\n",
            "request an automatic oob evaluation after training. The following code demonstrates\n",
            "\n",
            "--- Chunk 4365 ---\n",
            "this. The resulting evaluation score is available through the oob_score_ variable:\n",
            "\n",
            "--- Chunk 4366 ---\n",
            "6 As m grows, this ratio approaches 1 – exp(–1) ≈ 63.212%.\n",
            "\n",
            "Bagging and Pasting | 195\n",
            "\n",
            "--- Chunk 4367 ---\n",
            ">>> bag_clf = BaggingClassifier(\n",
            "...     DecisionTreeClassifier(), n_estimators=500,\n",
            "...     bootstrap=True, n_jobs=-1, oob_score=True)\n",
            "...\n",
            "\n",
            "--- Chunk 4368 ---\n",
            "...\n",
            ">>> bag_clf.fit(X_train, y_train)\n",
            ">>> bag_clf.oob_score_\n",
            "0.90133333333333332\n",
            "\n",
            "--- Chunk 4369 ---\n",
            "According to this oob evaluation, this BaggingClassifier is likely to achieve about\n",
            "90.1% accuracy on the test set. Let’s verify this:\n",
            "\n",
            "--- Chunk 4370 ---\n",
            ">>> from sklearn.metrics import accuracy_score\n",
            ">>> y_pred = bag_clf.predict(X_test)\n",
            ">>> accuracy_score(y_test, y_pred)\n",
            "0.91200000000000003\n",
            "\n",
            "--- Chunk 4371 ---\n",
            "We get 91.2% accuracy on the test set—close enough!\n",
            "The oob decision function for each training instance is also available through the\n",
            "\n",
            "--- Chunk 4372 ---\n",
            "oob_decision_function_ variable. In this case (since the base estimator has a pre\n",
            "\n",
            "--- Chunk 4373 ---\n",
            "dict_proba() method), the decision function returns the class probabilities for each\n",
            "\n",
            "--- Chunk 4374 ---\n",
            "training instance. For example, the oob evaluation estimates that the first training\n",
            "\n",
            "--- Chunk 4375 ---\n",
            "instance has a 68.25% probability of belonging to the positive class (and 31.75% of\n",
            "belonging to the negative class):\n",
            "\n",
            "--- Chunk 4376 ---\n",
            ">>> bag_clf.oob_decision_function_\n",
            "array([[0.31746032, 0.68253968],\n",
            "       [0.34117647, 0.65882353],\n",
            "       [1.        , 0.        ],\n",
            "       ...\n",
            "\n",
            "--- Chunk 4377 ---\n",
            "...\n",
            "       [1.        , 0.        ],\n",
            "       [0.03108808, 0.96891192],\n",
            "       [0.57291667, 0.42708333]])\n",
            "\n",
            "--- Chunk 4378 ---\n",
            "Random Patches and Random Subspaces\n",
            "The BaggingClassifier class supports sampling the features as well. Sampling is\n",
            "\n",
            "--- Chunk 4379 ---\n",
            "controlled by two hyperparameters: max_features and bootstrap_features. They\n",
            "\n",
            "--- Chunk 4380 ---\n",
            "work the same way as max_samples and bootstrap, but for feature sampling instead\n",
            "\n",
            "--- Chunk 4381 ---\n",
            "of instance sampling. Thus, each predictor will be trained on a random subset of the\n",
            "input features.\n",
            "\n",
            "--- Chunk 4382 ---\n",
            "input features.\n",
            "This technique is particularly useful when you are dealing with high-dimensional\n",
            "\n",
            "--- Chunk 4383 ---\n",
            "inputs (such as images). Sampling both training instances and features is called the\n",
            "\n",
            "--- Chunk 4384 ---\n",
            "Random Patches method.7 Keeping all training instances (by setting bootstrap=False\n",
            "\n",
            "--- Chunk 4385 ---\n",
            "7 Gilles Louppe and Pierre Geurts, “Ensembles on Random Patches,” Lecture Notes in Computer Science 7523\n",
            "(2012): 346–361.\n",
            "\n",
            "--- Chunk 4386 ---\n",
            "196 | Chapter 7: Ensemble Learning and Random Forests\n",
            "\n",
            "--- Chunk 4387 ---\n",
            "and max_samples=1.0) but sampling features (by setting bootstrap_features to\n",
            "\n",
            "--- Chunk 4388 ---\n",
            "True and/or max_features to a value smaller than 1.0) is called the Random Subspa‐\n",
            "ces method.8\n",
            "\n",
            "--- Chunk 4389 ---\n",
            "Sampling features results in even more predictor diversity, trading a bit more bias for\n",
            "a lower variance.\n",
            "\n",
            "--- Chunk 4390 ---\n",
            "Random Forests\n",
            "As we have discussed, a Random Forest9 is an ensemble of Decision Trees, generally\n",
            "\n",
            "--- Chunk 4391 ---\n",
            "trained via the bagging method (or sometimes pasting), typically with max_samples\n",
            "\n",
            "--- Chunk 4392 ---\n",
            "set to the size of the training set. Instead of building a BaggingClassifier and pass‐\n",
            "\n",
            "--- Chunk 4393 ---\n",
            "ing it a DecisionTreeClassifier, you can instead use the RandomForestClassifier\n",
            "\n",
            "--- Chunk 4394 ---\n",
            "class, which is more convenient and optimized for Decision Trees10 (similarly, there is\n",
            "\n",
            "--- Chunk 4395 ---\n",
            "a RandomForestRegressor class for regression tasks). The following code uses all\n",
            "\n",
            "--- Chunk 4396 ---\n",
            "available CPU cores to train a Random Forest classifier with 500 trees (each limited\n",
            "to maximum 16 nodes):\n",
            "\n",
            "--- Chunk 4397 ---\n",
            "from sklearn.ensemble import RandomForestClassifier\n",
            "\n",
            "--- Chunk 4398 ---\n",
            "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
            "rnd_clf.fit(X_train, y_train)\n",
            "\n",
            "y_pred_rf = rnd_clf.predict(X_test)\n",
            "\n",
            "--- Chunk 4399 ---\n",
            "With a few exceptions, a RandomForestClassifier has all the hyperparameters of a\n",
            "\n",
            "--- Chunk 4400 ---\n",
            "DecisionTreeClassifier (to control how trees are grown), plus all the hyperpara‐\n",
            "meters of a BaggingClassifier to control the ensemble itself.11\n",
            "\n",
            "--- Chunk 4401 ---\n",
            "The Random Forest algorithm introduces extra randomness when growing trees;\n",
            "\n",
            "--- Chunk 4402 ---\n",
            "instead of searching for the very best feature when splitting a node (see Chapter 6), it\n",
            "\n",
            "--- Chunk 4403 ---\n",
            "searches for the best feature among a random subset of features. The algorithm\n",
            "\n",
            "--- Chunk 4404 ---\n",
            "results in greater tree diversity, which (again) trades a higher bias for a lower var‐\n",
            "\n",
            "--- Chunk 4405 ---\n",
            "iance, generally yielding an overall better model. The following BaggingClassifier\n",
            "is roughly equivalent to the previous RandomForestClassifier:\n",
            "\n",
            "--- Chunk 4406 ---\n",
            "8 Tin Kam Ho, “The Random Subspace Method for Constructing Decision Forests,” IEEE Transactions on Pat‐\n",
            "\n",
            "--- Chunk 4407 ---\n",
            "tern Analysis and Machine Intelligence 20, no. 8 (1998): 832–844.\n",
            "\n",
            "--- Chunk 4408 ---\n",
            "9 Tin Kam Ho, “Random Decision Forests,” Proceedings of the Third International Conference on Document\n",
            "Analysis and Recognition 1 (1995): 278.\n",
            "\n",
            "--- Chunk 4409 ---\n",
            "10 The BaggingClassifier class remains useful if you want a bag of something other than Decision Trees.\n",
            "\n",
            "--- Chunk 4410 ---\n",
            "11 There are a few notable exceptions: splitter is absent (forced to \"random\"), presort is absent (forced to\n",
            "\n",
            "--- Chunk 4411 ---\n",
            "False), max_samples is absent (forced to 1.0), and base_estimator is absent (forced to DecisionTreeClassi\n",
            "fier with the provided hyperparameters).\n",
            "\n",
            "--- Chunk 4412 ---\n",
            "Random Forests | 197\n",
            "\n",
            "--- Chunk 4413 ---\n",
            "bag_clf = BaggingClassifier(\n",
            "    DecisionTreeClassifier(splitter=\"random\", max_leaf_nodes=16),\n",
            "\n",
            "--- Chunk 4414 ---\n",
            "n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1)\n",
            "\n",
            "--- Chunk 4415 ---\n",
            "Extra-Trees\n",
            "When you are growing a tree in a Random Forest, at each node only a random subset\n",
            "\n",
            "--- Chunk 4416 ---\n",
            "of the features is considered for splitting (as discussed earlier). It is possible to make\n",
            "\n",
            "--- Chunk 4417 ---\n",
            "trees even more random by also using random thresholds for each feature rather than\n",
            "\n",
            "--- Chunk 4418 ---\n",
            "searching for the best possible thresholds (like regular Decision Trees do).\n",
            "\n",
            "--- Chunk 4419 ---\n",
            "A forest of such extremely random trees is called an Extremely Randomized Trees\n",
            "\n",
            "--- Chunk 4420 ---\n",
            "ensemble12 (or Extra-Trees for short). Once again, this technique trades more bias for\n",
            "\n",
            "--- Chunk 4421 ---\n",
            "a lower variance. It also makes Extra-Trees much faster to train than regular Random\n",
            "\n",
            "--- Chunk 4422 ---\n",
            "Forests, because finding the best possible threshold for each feature at every node is\n",
            "one of the most time-consuming tasks of growing a tree.\n",
            "\n",
            "--- Chunk 4423 ---\n",
            "You can create an Extra-Trees classifier using Scikit-Learn’s ExtraTreesClassifier\n",
            "\n",
            "--- Chunk 4424 ---\n",
            "class. Its API is identical to the RandomForestClassifier class. Similarly, the Extra\n",
            "\n",
            "--- Chunk 4425 ---\n",
            "TreesRegressor class has the same API as the RandomForestRegressor class.\n",
            "\n",
            "--- Chunk 4426 ---\n",
            "It is hard to tell in advance whether a RandomForestClassifier\n",
            "will perform better or worse than an ExtraTreesClassifier. Gen‐\n",
            "\n",
            "--- Chunk 4427 ---\n",
            "erally, the only way to know is to try both and compare them using\n",
            "cross-validation (tuning the hyperparameters using grid search).\n",
            "\n",
            "--- Chunk 4428 ---\n",
            "Feature Importance\n",
            "Yet another great quality of Random Forests is that they make it easy to measure the\n",
            "\n",
            "--- Chunk 4429 ---\n",
            "relative importance of each feature. Scikit-Learn measures a feature’s importance by\n",
            "\n",
            "--- Chunk 4430 ---\n",
            "looking at how much the tree nodes that use that feature reduce impurity on average\n",
            "\n",
            "--- Chunk 4431 ---\n",
            "(across all trees in the forest). More precisely, it is a weighted average, where each\n",
            "\n",
            "--- Chunk 4432 ---\n",
            "node’s weight is equal to the number of training samples that are associated with it\n",
            "(see Chapter 6).\n",
            "\n",
            "--- Chunk 4433 ---\n",
            "(see Chapter 6).\n",
            "Scikit-Learn computes this score automatically for each feature after training, then it\n",
            "\n",
            "--- Chunk 4434 ---\n",
            "scales the results so that the sum of all importances is equal to 1. You can access the\n",
            "\n",
            "--- Chunk 4435 ---\n",
            "result using the feature_importances_ variable. For example, the following code\n",
            "\n",
            "--- Chunk 4436 ---\n",
            "trains a RandomForestClassifier on the iris dataset (introduced in Chapter 4) and\n",
            "\n",
            "--- Chunk 4437 ---\n",
            "outputs each feature’s importance. It seems that the most important features are the\n",
            "\n",
            "--- Chunk 4438 ---\n",
            "petal length (44%) and width (42%), while sepal length and width are rather unim‐\n",
            "portant in comparison (11% and 2%, respectively):\n",
            "\n",
            "--- Chunk 4439 ---\n",
            "12 Pierre Geurts et al., “Extremely Randomized Trees,” Machine Learning 63, no. 1 (2006): 3–42.\n",
            "\n",
            "--- Chunk 4440 ---\n",
            "198 | Chapter 7: Ensemble Learning and Random Forests\n",
            "\n",
            "--- Chunk 4441 ---\n",
            ">>> from sklearn.datasets import load_iris\n",
            ">>> iris = load_iris()\n",
            ">>> rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
            "\n",
            "--- Chunk 4442 ---\n",
            ">>> rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
            ">>> for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
            "\n",
            "--- Chunk 4443 ---\n",
            "...     print(name, score)\n",
            "...\n",
            "sepal length (cm) 0.112492250999\n",
            "sepal width (cm) 0.0231192882825\n",
            "petal length (cm) 0.441030464364\n",
            "\n",
            "--- Chunk 4444 ---\n",
            "petal width (cm) 0.423357996355\n",
            "\n",
            "--- Chunk 4445 ---\n",
            "Similarly, if you train a Random Forest classifier on the MNIST dataset (introduced\n",
            "\n",
            "--- Chunk 4446 ---\n",
            "in Chapter 3) and plot each pixel’s importance, you get the image represented in\n",
            "Figure 7-6.\n",
            "\n",
            "--- Chunk 4447 ---\n",
            "Figure 7-6. MNIST pixel importance (according to a Random Forest classifier)\n",
            "\n",
            "--- Chunk 4448 ---\n",
            "Random Forests are very handy to get a quick understanding of what features\n",
            "actually matter, in particular if you need to perform feature selection.\n",
            "\n",
            "--- Chunk 4449 ---\n",
            "Boosting\n",
            "Boosting (originally called hypothesis boosting) refers to any Ensemble method that\n",
            "\n",
            "--- Chunk 4450 ---\n",
            "can combine several weak learners into a strong learner. The general idea of most\n",
            "\n",
            "--- Chunk 4451 ---\n",
            "boosting methods is to train predictors sequentially, each trying to correct its prede‐\n",
            "\n",
            "--- Chunk 4452 ---\n",
            "cessor. There are many boosting methods available, but by far the most popular are\n",
            "\n",
            "--- Chunk 4453 ---\n",
            "Boosting | 199\n",
            "\n",
            "\n",
            "\n",
            "AdaBoost13 (short for Adaptive Boosting) and Gradient Boosting. Let’s start with Ada‐\n",
            "Boost.\n",
            "\n",
            "--- Chunk 4454 ---\n",
            "AdaBoost\n",
            "One way for a new predictor to correct its predecessor is to pay a bit more attention\n",
            "\n",
            "--- Chunk 4455 ---\n",
            "to the training instances that the predecessor underfitted. This results in new predic‐\n",
            "\n",
            "--- Chunk 4456 ---\n",
            "tors focusing more and more on the hard cases. This is the technique used by\n",
            "AdaBoost.\n",
            "\n",
            "--- Chunk 4457 ---\n",
            "AdaBoost.\n",
            "For example, when training an AdaBoost classifier, the algorithm first trains a base\n",
            "\n",
            "--- Chunk 4458 ---\n",
            "classifier (such as a Decision Tree) and uses it to make predictions on the training set.\n",
            "\n",
            "--- Chunk 4459 ---\n",
            "The algorithm then increases the relative weight of misclassified training instances.\n",
            "\n",
            "--- Chunk 4460 ---\n",
            "Then it trains a second classifier, using the updated weights, and again makes predic‐\n",
            "\n",
            "--- Chunk 4461 ---\n",
            "tions on the training set, updates the instance weights, and so on (see Figure 7-7).\n",
            "\n",
            "--- Chunk 4462 ---\n",
            "Figure 7-7. AdaBoost sequential training with instance weight updates\n",
            "\n",
            "--- Chunk 4463 ---\n",
            "Figure 7-8 shows the decision boundaries of five consecutive predictors on the\n",
            "\n",
            "--- Chunk 4464 ---\n",
            "moons dataset (in this example, each predictor is a highly regularized SVM classifier\n",
            "\n",
            "--- Chunk 4465 ---\n",
            "with an RBF kernel14). The first classifier gets many instances wrong, so their weights\n",
            "\n",
            "--- Chunk 4466 ---\n",
            "13 Yoav Freund and Robert E. Schapire, “A Decision-Theoretic Generalization of On-Line Learning and an\n",
            "\n",
            "--- Chunk 4467 ---\n",
            "Application to Boosting,” Journal of Computer and System Sciences 55, no. 1 (1997): 119–139.\n",
            "\n",
            "--- Chunk 4468 ---\n",
            "14 This is just for illustrative purposes. SVMs are generally not good base predictors for AdaBoost; they are slow\n",
            "and tend to be unstable with it.\n",
            "\n",
            "--- Chunk 4469 ---\n",
            "200 | Chapter 7: Ensemble Learning and Random Forests\n",
            "\n",
            "--- Chunk 4470 ---\n",
            "get boosted. The second classifier therefore does a better job on these instances, and\n",
            "\n",
            "--- Chunk 4471 ---\n",
            "so on. The plot on the right represents the same sequence of predictors, except that\n",
            "\n",
            "--- Chunk 4472 ---\n",
            "the learning rate is halved (i.e., the misclassified instance weights are boosted half as\n",
            "\n",
            "--- Chunk 4473 ---\n",
            "much at every iteration). As you can see, this sequential learning technique has some\n",
            "\n",
            "--- Chunk 4474 ---\n",
            "similarities with Gradient Descent, except that instead of tweaking a single predictor’s\n",
            "\n",
            "--- Chunk 4475 ---\n",
            "parameters to minimize a cost function, AdaBoost adds predictors to the ensemble,\n",
            "gradually making it better.\n",
            "\n",
            "--- Chunk 4476 ---\n",
            "Figure 7-8. Decision boundaries of consecutive predictors\n",
            "\n",
            "--- Chunk 4477 ---\n",
            "Once all predictors are trained, the ensemble makes predictions very much like bag‐\n",
            "\n",
            "--- Chunk 4478 ---\n",
            "ging or pasting, except that predictors have different weights depending on their\n",
            "overall accuracy on the weighted training set.\n",
            "\n",
            "--- Chunk 4479 ---\n",
            "There is one important drawback to this sequential learning techni‐\n",
            "que: it cannot be parallelized (or only partially), since each predic‐\n",
            "\n",
            "--- Chunk 4480 ---\n",
            "tor can only be trained after the previous predictor has been\n",
            "trained and evaluated. As a result, it does not scale as well as bag‐\n",
            "ging or pasting.\n",
            "\n",
            "--- Chunk 4481 ---\n",
            "Let’s take a closer look at the AdaBoost algorithm. Each instance weight w(i) is initially\n",
            "\n",
            "--- Chunk 4482 ---\n",
            "set to 1/m. A first predictor is trained, and its weighted error rate r1 is computed on\n",
            "the training set; see Equation 7-1.\n",
            "\n",
            "--- Chunk 4483 ---\n",
            "Equation 7-1. Weighted error rate of the jth predictor\n",
            "m\n",
            "∑ w i\n",
            "\n",
            "i = 1\n",
            "y i\n",
            "\n",
            "r j ≠ y i\n",
            "\n",
            "--- Chunk 4484 ---\n",
            "r j ≠ y i\n",
            "\n",
            "j = m where y i\n",
            "j is the jth predictor’s prediction for the ith instance.\n",
            "\n",
            "∑ w i\n",
            "i = 1\n",
            "\n",
            "Boosting | 201\n",
            "\n",
            "--- Chunk 4485 ---\n",
            "The predictor’s weight αj is then computed using Equation 7-2, where η is the learn‐\n",
            "\n",
            "--- Chunk 4486 ---\n",
            "ing rate hyperparameter (defaults to 1).15 The more accurate the predictor is, the\n",
            "\n",
            "--- Chunk 4487 ---\n",
            "higher its weight will be. If it is just guessing randomly, then its weight will be close to\n",
            "\n",
            "--- Chunk 4488 ---\n",
            "zero. However, if it is most often wrong (i.e., less accurate than random guessing),\n",
            "then its weight will be negative.\n",
            "\n",
            "--- Chunk 4489 ---\n",
            "Equation 7-2. Predictor weight\n",
            "1 − r\n",
            "\n",
            "α η log j\n",
            "j = r j\n",
            "\n",
            "--- Chunk 4490 ---\n",
            "Next, the AdaBoost algorithm updates the instance weights, using Equation 7-3,\n",
            "which boosts the weights of the misclassified instances.\n",
            "\n",
            "--- Chunk 4491 ---\n",
            "Equation 7-3. Weight update rule\n",
            "for i = 1, 2,⋯, m\n",
            "\n",
            "w i if y i = y i\n",
            "w i j\n",
            "\n",
            "w i exp α if y i\n",
            "j j ≠ y i\n",
            "\n",
            "--- Chunk 4492 ---\n",
            "Then all the instance weights are normalized (i.e., divided by ∑m\n",
            "i = 1 w i ).\n",
            "\n",
            "--- Chunk 4493 ---\n",
            "Finally, a new predictor is trained using the updated weights, and the whole process is\n",
            "\n",
            "--- Chunk 4494 ---\n",
            "repeated (the new predictor’s weight is computed, the instance weights are updated,\n",
            "\n",
            "--- Chunk 4495 ---\n",
            "then another predictor is trained, and so on). The algorithm stops when the desired\n",
            "\n",
            "--- Chunk 4496 ---\n",
            "number of predictors is reached, or when a perfect predictor is found.\n",
            "\n",
            "--- Chunk 4497 ---\n",
            "To make predictions, AdaBoost simply computes the predictions of all the predictors\n",
            "\n",
            "--- Chunk 4498 ---\n",
            "and weighs them using the predictor weights αj. The predicted class is the one that\n",
            "receives the majority of weighted votes (see Equation 7-4).\n",
            "\n",
            "--- Chunk 4499 ---\n",
            "Equation 7-4. AdaBoost predictions\n",
            "N\n",
            "\n",
            "y x = argmax ∑ α where N is the number of predictors.\n",
            "k j = 1 j\n",
            "\n",
            "y j x = k\n",
            "\n",
            "--- Chunk 4500 ---\n",
            "y j x = k\n",
            "\n",
            "15 The original AdaBoost algorithm does not use a learning rate hyperparameter.\n",
            "\n",
            "202 | Chapter 7: Ensemble Learning and Random Forests\n",
            "\n",
            "--- Chunk 4501 ---\n",
            "Scikit-Learn uses a multiclass version of AdaBoost called SAMME16 (which stands for\n",
            "\n",
            "--- Chunk 4502 ---\n",
            "Stagewise Additive Modeling using a Multiclass Exponential loss function). When there\n",
            "\n",
            "--- Chunk 4503 ---\n",
            "are just two classes, SAMME is equivalent to AdaBoost. If the predictors can estimate\n",
            "\n",
            "--- Chunk 4504 ---\n",
            "class probabilities (i.e., if they have a predict_proba() method), Scikit-Learn can use\n",
            "\n",
            "--- Chunk 4505 ---\n",
            "a variant of SAMME called SAMME.R (the R stands for “Real”), which relies on class\n",
            "\n",
            "--- Chunk 4506 ---\n",
            "probabilities rather than predictions and generally performs better.\n",
            "\n",
            "--- Chunk 4507 ---\n",
            "The following code trains an AdaBoost classifier based on 200 Decision Stumps using\n",
            "\n",
            "--- Chunk 4508 ---\n",
            "Scikit-Learn’s AdaBoostClassifier class (as you might expect, there is also an Ada\n",
            "\n",
            "--- Chunk 4509 ---\n",
            "BoostRegressor class). A Decision Stump is a Decision Tree with max_depth=1—in\n",
            "\n",
            "--- Chunk 4510 ---\n",
            "other words, a tree composed of a single decision node plus two leaf nodes. This is\n",
            "the default base estimator for the AdaBoostClassifier class:\n",
            "\n",
            "--- Chunk 4511 ---\n",
            "from sklearn.ensemble import AdaBoostClassifier\n",
            "\n",
            "--- Chunk 4512 ---\n",
            "ada_clf = AdaBoostClassifier(\n",
            "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
            "    algorithm=\"SAMME.R\", learning_rate=0.5)\n",
            "\n",
            "--- Chunk 4513 ---\n",
            "ada_clf.fit(X_train, y_train)\n",
            "\n",
            "--- Chunk 4514 ---\n",
            "If your AdaBoost ensemble is overfitting the training set, you can\n",
            "try reducing the number of estimators or more strongly regulariz‐\n",
            "\n",
            "--- Chunk 4515 ---\n",
            "ing the base estimator.\n",
            "\n",
            "--- Chunk 4516 ---\n",
            "Gradient Boosting\n",
            "Another very popular boosting algorithm is Gradient Boosting.17 Just like AdaBoost,\n",
            "\n",
            "--- Chunk 4517 ---\n",
            "Gradient Boosting works by sequentially adding predictors to an ensemble, each one\n",
            "\n",
            "--- Chunk 4518 ---\n",
            "correcting its predecessor. However, instead of tweaking the instance weights at every\n",
            "\n",
            "--- Chunk 4519 ---\n",
            "iteration like AdaBoost does, this method tries to fit the new predictor to the residual\n",
            "errors made by the previous predictor.\n",
            "\n",
            "--- Chunk 4520 ---\n",
            "Let’s go through a simple regression example, using Decision Trees as the base predic‐\n",
            "\n",
            "--- Chunk 4521 ---\n",
            "tors (of course, Gradient Boosting also works great with regression tasks). This is\n",
            "\n",
            "--- Chunk 4522 ---\n",
            "called Gradient Tree Boosting, or Gradient Boosted Regression Trees (GBRT). First, let’s\n",
            "\n",
            "--- Chunk 4523 ---\n",
            "fit a DecisionTreeRegressor to the training set (for example, a noisy quadratic train‐\n",
            "ing set):\n",
            "\n",
            "--- Chunk 4524 ---\n",
            "16 For more details, see Ji Zhu et al., “Multi-Class AdaBoost,” Statistics and Its Interface 2, no. 3 (2009): 349–360.\n",
            "\n",
            "--- Chunk 4525 ---\n",
            "17 Gradient Boosting was first introduced in Leo Breiman’s 1997 paper “Arcing the Edge” and was further devel‐\n",
            "\n",
            "--- Chunk 4526 ---\n",
            "oped in the 1999 paper “Greedy Function Approximation: A Gradient Boosting Machine” by Jerome H. Fried‐\n",
            "man.\n",
            "\n",
            "Boosting | 203\n",
            "\n",
            "--- Chunk 4527 ---\n",
            "Boosting | 203\n",
            "\n",
            "\n",
            "\n",
            "from sklearn.tree import DecisionTreeRegressor\n",
            "\n",
            "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
            "tree_reg1.fit(X, y)\n",
            "\n",
            "--- Chunk 4528 ---\n",
            "Next, we’ll train a second DecisionTreeRegressor on the residual errors made by the\n",
            "first predictor:\n",
            "\n",
            "--- Chunk 4529 ---\n",
            "y2 = y - tree_reg1.predict(X)\n",
            "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
            "tree_reg2.fit(X, y2)\n",
            "\n",
            "--- Chunk 4530 ---\n",
            "Then we train a third regressor on the residual errors made by the second predictor:\n",
            "y3 = y2 - tree_reg2.predict(X)\n",
            "\n",
            "--- Chunk 4531 ---\n",
            "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
            "tree_reg3.fit(X, y3)\n",
            "\n",
            "--- Chunk 4532 ---\n",
            "Now we have an ensemble containing three trees. It can make predictions on a new\n",
            "instance simply by adding up the predictions of all the trees:\n",
            "\n",
            "--- Chunk 4533 ---\n",
            "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))\n",
            "\n",
            "--- Chunk 4534 ---\n",
            "Figure 7-9 represents the predictions of these three trees in the left column, and the\n",
            "\n",
            "--- Chunk 4535 ---\n",
            "ensemble’s predictions in the right column. In the first row, the ensemble has just one\n",
            "\n",
            "--- Chunk 4536 ---\n",
            "tree, so its predictions are exactly the same as the first tree’s predictions. In the second\n",
            "\n",
            "--- Chunk 4537 ---\n",
            "row, a new tree is trained on the residual errors of the first tree. On the right you can\n",
            "\n",
            "--- Chunk 4538 ---\n",
            "see that the ensemble’s predictions are equal to the sum of the predictions of the first\n",
            "\n",
            "--- Chunk 4539 ---\n",
            "two trees. Similarly, in the third row another tree is trained on the residual errors of\n",
            "\n",
            "--- Chunk 4540 ---\n",
            "the second tree. You can see that the ensemble’s predictions gradually get better as\n",
            "trees are added to the ensemble.\n",
            "\n",
            "--- Chunk 4541 ---\n",
            "A simpler way to train GBRT ensembles is to use Scikit-Learn’s GradientBoostingRe\n",
            "\n",
            "--- Chunk 4542 ---\n",
            "gressor class. Much like the RandomForestRegressor class, it has hyperparameters to\n",
            "\n",
            "--- Chunk 4543 ---\n",
            "control the growth of Decision Trees (e.g., max_depth, min_samples_leaf), as well as\n",
            "\n",
            "--- Chunk 4544 ---\n",
            "hyperparameters to control the ensemble training, such as the number of trees\n",
            "\n",
            "--- Chunk 4545 ---\n",
            "(n_estimators). The following code creates the same ensemble as the previous one:\n",
            "\n",
            "--- Chunk 4546 ---\n",
            "from sklearn.ensemble import GradientBoostingRegressor\n",
            "\n",
            "--- Chunk 4547 ---\n",
            "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
            "gbrt.fit(X, y)\n",
            "\n",
            "--- Chunk 4548 ---\n",
            "204 | Chapter 7: Ensemble Learning and Random Forests\n",
            "\n",
            "--- Chunk 4549 ---\n",
            "Figure 7-9. In this depiction of Gradient Boosting, the first predictor (top left) is trained\n",
            "\n",
            "--- Chunk 4550 ---\n",
            "normally, then each consecutive predictor (middle left and lower left) is trained on the\n",
            "\n",
            "--- Chunk 4551 ---\n",
            "previous predictor’s residuals; the right column shows the resulting ensemble’s predictions\n",
            "\n",
            "--- Chunk 4552 ---\n",
            "The learning_rate hyperparameter scales the contribution of each tree. If you set it\n",
            "\n",
            "--- Chunk 4553 ---\n",
            "to a low value, such as 0.1, you will need more trees in the ensemble to fit the train‐\n",
            "\n",
            "--- Chunk 4554 ---\n",
            "ing set, but the predictions will usually generalize better. This is a regularization tech‐\n",
            "\n",
            "--- Chunk 4555 ---\n",
            "nique called shrinkage. Figure 7-10 shows two GBRT ensembles trained with a low\n",
            "\n",
            "--- Chunk 4556 ---\n",
            "learning rate: the one on the left does not have enough trees to fit the training set,\n",
            "\n",
            "--- Chunk 4557 ---\n",
            "while the one on the right has too many trees and overfits the training set.\n",
            "\n",
            "--- Chunk 4558 ---\n",
            "Boosting | 205\n",
            "\n",
            "\n",
            "\n",
            "Figure 7-10. GBRT ensembles with not enough predictors (left) and too many (right)\n",
            "\n",
            "--- Chunk 4559 ---\n",
            "In order to find the optimal number of trees, you can use early stopping (see Chap‐\n",
            "\n",
            "--- Chunk 4560 ---\n",
            "ter 4). A simple way to implement this is to use the staged_predict() method: it\n",
            "\n",
            "--- Chunk 4561 ---\n",
            "returns an iterator over the predictions made by the ensemble at each stage of train‐\n",
            "\n",
            "--- Chunk 4562 ---\n",
            "ing (with one tree, two trees, etc.). The following code trains a GBRT ensemble with\n",
            "\n",
            "--- Chunk 4563 ---\n",
            "120 trees, then measures the validation error at each stage of training to find the opti‐\n",
            "\n",
            "--- Chunk 4564 ---\n",
            "mal number of trees, and finally trains another GBRT ensemble using the optimal\n",
            "number of trees:\n",
            "\n",
            "--- Chunk 4565 ---\n",
            "import numpy as np\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.metrics import mean_squared_error\n",
            "\n",
            "--- Chunk 4566 ---\n",
            "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
            "\n",
            "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120)\n",
            "gbrt.fit(X_train, y_train)\n",
            "\n",
            "--- Chunk 4567 ---\n",
            "errors = [mean_squared_error(y_val, y_pred)\n",
            "          for y_pred in gbrt.staged_predict(X_val)]\n",
            "bst_n_estimators = np.argmin(errors) + 1\n",
            "\n",
            "--- Chunk 4568 ---\n",
            "gbrt_best = GradientBoostingRegressor(max_depth=2,n_estimators=bst_n_estimators)\n",
            "gbrt_best.fit(X_train, y_train)\n",
            "\n",
            "--- Chunk 4569 ---\n",
            "The validation errors are represented on the left of Figure 7-11, and the best model’s\n",
            "predictions are represented on the right.\n",
            "\n",
            "--- Chunk 4570 ---\n",
            "206 | Chapter 7: Ensemble Learning and Random Forests\n",
            "\n",
            "\n",
            "\n",
            "Figure 7-11. Tuning the number of trees using early stopping\n",
            "\n",
            "--- Chunk 4571 ---\n",
            "It is also possible to implement early stopping by actually stopping training early\n",
            "\n",
            "--- Chunk 4572 ---\n",
            "(instead of training a large number of trees first and then looking back to find the\n",
            "\n",
            "--- Chunk 4573 ---\n",
            "optimal number). You can do so by setting warm_start=True, which makes Scikit-\n",
            "\n",
            "--- Chunk 4574 ---\n",
            "Learn keep existing trees when the fit() method is called, allowing incremental\n",
            "\n",
            "--- Chunk 4575 ---\n",
            "training. The following code stops training when the validation error does not\n",
            "improve for five iterations in a row:\n",
            "\n",
            "--- Chunk 4576 ---\n",
            "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True)\n",
            "\n",
            "--- Chunk 4577 ---\n",
            "min_val_error = float(\"inf\")\n",
            "error_going_up = 0\n",
            "for n_estimators in range(1, 120):\n",
            "    gbrt.n_estimators = n_estimators\n",
            "\n",
            "--- Chunk 4578 ---\n",
            "gbrt.fit(X_train, y_train)\n",
            "    y_pred = gbrt.predict(X_val)\n",
            "    val_error = mean_squared_error(y_val, y_pred)\n",
            "    if val_error < min_val_error:\n",
            "\n",
            "--- Chunk 4579 ---\n",
            "min_val_error = val_error\n",
            "        error_going_up = 0\n",
            "    else:\n",
            "        error_going_up += 1\n",
            "        if error_going_up == 5:\n",
            "\n",
            "--- Chunk 4580 ---\n",
            "break  # early stopping\n",
            "\n",
            "--- Chunk 4581 ---\n",
            "The GradientBoostingRegressor class also supports a subsample hyperparameter,\n",
            "\n",
            "--- Chunk 4582 ---\n",
            "which specifies the fraction of training instances to be used for training each tree. For\n",
            "\n",
            "--- Chunk 4583 ---\n",
            "example, if subsample=0.25, then each tree is trained on 25% of the training instan‐\n",
            "\n",
            "--- Chunk 4584 ---\n",
            "ces, selected randomly. As you can probably guess by now, this technique trades a\n",
            "\n",
            "--- Chunk 4585 ---\n",
            "higher bias for a lower variance. It also speeds up training considerably. This is called\n",
            "Stochastic Gradient Boosting.\n",
            "\n",
            "--- Chunk 4586 ---\n",
            "Boosting | 207\n",
            "\n",
            "--- Chunk 4587 ---\n",
            "It is possible to use Gradient Boosting with other cost functions.\n",
            "This is controlled by the loss hyperparameter (see Scikit-Learn’s\n",
            "\n",
            "--- Chunk 4588 ---\n",
            "documentation for more details).\n",
            "\n",
            "--- Chunk 4589 ---\n",
            "It is worth noting that an optimized implementation of Gradient Boosting is available\n",
            "\n",
            "--- Chunk 4590 ---\n",
            "in the popular Python library XGBoost, which stands for Extreme Gradient Boosting.\n",
            "\n",
            "--- Chunk 4591 ---\n",
            "This package was initially developed by Tianqi Chen as part of the Distributed (Deep)\n",
            "\n",
            "--- Chunk 4592 ---\n",
            "Machine Learning Community (DMLC), and it aims to be extremely fast, scalable,\n",
            "\n",
            "--- Chunk 4593 ---\n",
            "and portable. In fact, XGBoost is often an important component of the winning\n",
            "\n",
            "--- Chunk 4594 ---\n",
            "entries in ML competitions. XGBoost’s API is quite similar to Scikit-Learn’s:\n",
            "\n",
            "--- Chunk 4595 ---\n",
            "import xgboost\n",
            "\n",
            "xgb_reg = xgboost.XGBRegressor()\n",
            "xgb_reg.fit(X_train, y_train)\n",
            "y_pred = xgb_reg.predict(X_val)\n",
            "\n",
            "--- Chunk 4596 ---\n",
            "XGBoost also offers several nice features, such as automatically taking care of early\n",
            "stopping:\n",
            "\n",
            "--- Chunk 4597 ---\n",
            "xgb_reg.fit(X_train, y_train,\n",
            "            eval_set=[(X_val, y_val)], early_stopping_rounds=2)\n",
            "y_pred = xgb_reg.predict(X_val)\n",
            "\n",
            "--- Chunk 4598 ---\n",
            "You should definitely check it out!\n",
            "\n",
            "--- Chunk 4599 ---\n",
            "Stacking\n",
            "The last Ensemble method we will discuss in this chapter is called stacking (short for\n",
            "\n",
            "--- Chunk 4600 ---\n",
            "stacked generalization).18 It is based on a simple idea: instead of using trivial functions\n",
            "\n",
            "--- Chunk 4601 ---\n",
            "(such as hard voting) to aggregate the predictions of all predictors in an ensemble,\n",
            "\n",
            "--- Chunk 4602 ---\n",
            "why don’t we train a model to perform this aggregation? Figure 7-12 shows such an\n",
            "\n",
            "--- Chunk 4603 ---\n",
            "ensemble performing a regression task on a new instance. Each of the bottom three\n",
            "\n",
            "--- Chunk 4604 ---\n",
            "predictors predicts a different value (3.1, 2.7, and 2.9), and then the final predictor\n",
            "\n",
            "--- Chunk 4605 ---\n",
            "(called a blender, or a meta learner) takes these predictions as inputs and makes the\n",
            "final prediction (3.0).\n",
            "\n",
            "--- Chunk 4606 ---\n",
            "18 David H. Wolpert, “Stacked Generalization,” Neural Networks 5, no. 2 (1992): 241–259.\n",
            "\n",
            "208 | Chapter 7: Ensemble Learning and Random Forests\n",
            "\n",
            "--- Chunk 4607 ---\n",
            "Figure 7-12. Aggregating predictions using a blending predictor\n",
            "\n",
            "--- Chunk 4608 ---\n",
            "To train the blender, a common approach is to use a hold-out set.19 Let’s see how it\n",
            "\n",
            "--- Chunk 4609 ---\n",
            "works. First, the training set is split into two subsets. The first subset is used to train\n",
            "the predictors in the first layer (see Figure 7-13).\n",
            "\n",
            "--- Chunk 4610 ---\n",
            "Figure 7-13. Training the first layer\n",
            "\n",
            "--- Chunk 4611 ---\n",
            "Next, the first layer’s predictors are used to make predictions on the second (held-\n",
            "\n",
            "--- Chunk 4612 ---\n",
            "out) set (see Figure 7-14). This ensures that the predictions are “clean,” since the pre‐\n",
            "\n",
            "--- Chunk 4613 ---\n",
            "dictors never saw these instances during training. For each instance in the hold-out\n",
            "\n",
            "--- Chunk 4614 ---\n",
            "19 Alternatively, it is possible to use out-of-fold predictions. In some contexts this is called stacking, while using a\n",
            "\n",
            "--- Chunk 4615 ---\n",
            "hold-out set is called blending. For many people these terms are synonymous.\n",
            "\n",
            "--- Chunk 4616 ---\n",
            "Stacking | 209\n",
            "\n",
            "--- Chunk 4617 ---\n",
            "set, there are three predicted values. We can create a new training set using these pre‐\n",
            "\n",
            "--- Chunk 4618 ---\n",
            "dicted values as input features (which makes this new training set 3D), and keeping\n",
            "\n",
            "--- Chunk 4619 ---\n",
            "the target values. The blender is trained on this new training set, so it learns to pre‐\n",
            "dict the target value, given the first layer’s predictions.\n",
            "\n",
            "--- Chunk 4620 ---\n",
            "Figure 7-14. Training the blender\n",
            "\n",
            "--- Chunk 4621 ---\n",
            "It is actually possible to train several different blenders this way (e.g., one using Lin‐\n",
            "\n",
            "--- Chunk 4622 ---\n",
            "ear Regression, another using Random Forest Regression), to get a whole layer of\n",
            "\n",
            "--- Chunk 4623 ---\n",
            "blenders. The trick is to split the training set into three subsets: the first one is used to\n",
            "\n",
            "--- Chunk 4624 ---\n",
            "train the first layer, the second one is used to create the training set used to train the\n",
            "\n",
            "--- Chunk 4625 ---\n",
            "second layer (using predictions made by the predictors of the first layer), and the\n",
            "\n",
            "--- Chunk 4626 ---\n",
            "third one is used to create the training set to train the third layer (using predictions\n",
            "\n",
            "--- Chunk 4627 ---\n",
            "made by the predictors of the second layer). Once this is done, we can make a predic‐\n",
            "\n",
            "--- Chunk 4628 ---\n",
            "tion for a new instance by going through each layer sequentially, as shown in\n",
            "Figure 7-15.\n",
            "\n",
            "--- Chunk 4629 ---\n",
            "210 | Chapter 7: Ensemble Learning and Random Forests\n",
            "\n",
            "\n",
            "\n",
            "Figure 7-15. Predictions in a multilayer stacking ensemble\n",
            "\n",
            "--- Chunk 4630 ---\n",
            "Unfortunately, Scikit-Learn does not support stacking directly, but it is not too hard\n",
            "\n",
            "--- Chunk 4631 ---\n",
            "to roll out your own implementation (see the following exercises). Alternatively, you\n",
            "can use an open source implementation such as DESlib.\n",
            "\n",
            "--- Chunk 4632 ---\n",
            "Exercises\n",
            "1. If you have trained five different models on the exact same training data, and\n",
            "\n",
            "--- Chunk 4633 ---\n",
            "they all achieve 95% precision, is there any chance that you can combine these\n",
            "models to get better results? If so, how? If not, why?\n",
            "\n",
            "--- Chunk 4634 ---\n",
            "2. What is the difference between hard and soft voting classifiers?\n",
            "\n",
            "--- Chunk 4635 ---\n",
            "3. Is it possible to speed up training of a bagging ensemble by distributing it across\n",
            "\n",
            "--- Chunk 4636 ---\n",
            "multiple servers? What about pasting ensembles, boosting ensembles, Random\n",
            "Forests, or stacking ensembles?\n",
            "\n",
            "--- Chunk 4637 ---\n",
            "4. What is the benefit of out-of-bag evaluation?\n",
            "5. What makes Extra-Trees more random than regular Random Forests? How can\n",
            "\n",
            "--- Chunk 4638 ---\n",
            "this extra randomness help? Are Extra-Trees slower or faster than regular Ran‐\n",
            "dom Forests?\n",
            "\n",
            "--- Chunk 4639 ---\n",
            "6. If your AdaBoost ensemble underfits the training data, which hyperparameters\n",
            "should you tweak and how?\n",
            "\n",
            "Exercises | 211\n",
            "\n",
            "--- Chunk 4640 ---\n",
            "Exercises | 211\n",
            "\n",
            "\n",
            "\n",
            "7. If your Gradient Boosting ensemble overfits the training set, should you increase\n",
            "or decrease the learning rate?\n",
            "\n",
            "--- Chunk 4641 ---\n",
            "8. Load the MNIST data (introduced in Chapter 3), and split it into a training set, a\n",
            "\n",
            "--- Chunk 4642 ---\n",
            "validation set, and a test set (e.g., use 50,000 instances for training, 10,000 for val‐\n",
            "\n",
            "--- Chunk 4643 ---\n",
            "idation, and 10,000 for testing). Then train various classifiers, such as a Random\n",
            "\n",
            "--- Chunk 4644 ---\n",
            "Forest classifier, an Extra-Trees classifier, and an SVM classifier. Next, try to com‐\n",
            "\n",
            "--- Chunk 4645 ---\n",
            "bine them into an ensemble that outperforms each individual classifier on the\n",
            "\n",
            "--- Chunk 4646 ---\n",
            "validation set, using soft or hard voting. Once you have found one, try it on the\n",
            "\n",
            "--- Chunk 4647 ---\n",
            "test set. How much better does it perform compared to the individual classifiers?\n",
            "\n",
            "--- Chunk 4648 ---\n",
            "9. Run the individual classifiers from the previous exercise to make predictions on\n",
            "\n",
            "--- Chunk 4649 ---\n",
            "the validation set, and create a new training set with the resulting predictions:\n",
            "\n",
            "--- Chunk 4650 ---\n",
            "each training instance is a vector containing the set of predictions from all your\n",
            "\n",
            "--- Chunk 4651 ---\n",
            "classifiers for an image, and the target is the image’s class. Train a classifier on\n",
            "\n",
            "--- Chunk 4652 ---\n",
            "this new training set. Congratulations, you have just trained a blender, and\n",
            "\n",
            "--- Chunk 4653 ---\n",
            "together with the classifiers it forms a stacking ensemble! Now evaluate the\n",
            "\n",
            "--- Chunk 4654 ---\n",
            "ensemble on the test set. For each image in the test set, make predictions with all\n",
            "\n",
            "--- Chunk 4655 ---\n",
            "your classifiers, then feed the predictions to the blender to get the ensemble’s pre‐\n",
            "\n",
            "--- Chunk 4656 ---\n",
            "dictions. How does it compare to the voting classifier you trained earlier?\n",
            "\n",
            "--- Chunk 4657 ---\n",
            "Solutions to these exercises are available in Appendix A.\n",
            "\n",
            "212 | Chapter 7: Ensemble Learning and Random Forests\n",
            "\n",
            "--- Chunk 4658 ---\n",
            "CHAPTER 8\n",
            "Dimensionality Reduction\n",
            "\n",
            "--- Chunk 4659 ---\n",
            "Many Machine Learning problems involve thousands or even millions of features for\n",
            "\n",
            "--- Chunk 4660 ---\n",
            "each training instance. Not only do all these features make training extremely slow,\n",
            "\n",
            "--- Chunk 4661 ---\n",
            "but they can also make it much harder to find a good solution, as we will see. This\n",
            "problem is often referred to as the curse of dimensionality.\n",
            "\n",
            "--- Chunk 4662 ---\n",
            "Fortunately, in real-world problems, it is often possible to reduce the number of fea‐\n",
            "\n",
            "--- Chunk 4663 ---\n",
            "tures considerably, turning an intractable problem into a tractable one. For example,\n",
            "\n",
            "--- Chunk 4664 ---\n",
            "consider the MNIST images (introduced in Chapter 3): the pixels on the image bor‐\n",
            "\n",
            "--- Chunk 4665 ---\n",
            "ders are almost always white, so you could completely drop these pixels from the\n",
            "\n",
            "--- Chunk 4666 ---\n",
            "training set without losing much information. Figure 7-6 confirms that these pixels\n",
            "\n",
            "--- Chunk 4667 ---\n",
            "are utterly unimportant for the classification task. Additionally, two neighboring pix‐\n",
            "\n",
            "--- Chunk 4668 ---\n",
            "els are often highly correlated: if you merge them into a single pixel (e.g., by taking\n",
            "\n",
            "--- Chunk 4669 ---\n",
            "the mean of the two pixel intensities), you will not lose much information.\n",
            "\n",
            "--- Chunk 4670 ---\n",
            "Reducing dimensionality does cause some information loss (just\n",
            "like compressing an image to JPEG can degrade its quality), so\n",
            "\n",
            "--- Chunk 4671 ---\n",
            "even though it will speed up training, it may make your system\n",
            "perform slightly worse. It also makes your pipelines a bit more\n",
            "\n",
            "--- Chunk 4672 ---\n",
            "complex and thus harder to maintain. So, if training is too slow,\n",
            "you should first try to train your system with the original data\n",
            "\n",
            "--- Chunk 4673 ---\n",
            "before considering using dimensionality reduction. In some cases,\n",
            "reducing the dimensionality of the training data may filter out\n",
            "\n",
            "--- Chunk 4674 ---\n",
            "some noise and unnecessary details and thus result in higher per‐\n",
            "formance, but in general it won’t; it will just speed up training.\n",
            "\n",
            "--- Chunk 4675 ---\n",
            "Apart from speeding up training, dimensionality reduction is also extremely useful\n",
            "\n",
            "--- Chunk 4676 ---\n",
            "for data visualization (or DataViz). Reducing the number of dimensions down to two\n",
            "\n",
            "--- Chunk 4677 ---\n",
            "(or three) makes it possible to plot a condensed view of a high-dimensional training\n",
            "\n",
            "--- Chunk 4678 ---\n",
            "213\n",
            "\n",
            "--- Chunk 4679 ---\n",
            "set on a graph and often gain some important insights by visually detecting patterns,\n",
            "\n",
            "--- Chunk 4680 ---\n",
            "such as clusters. Moreover, DataViz is essential to communicate your conclusions to\n",
            "\n",
            "--- Chunk 4681 ---\n",
            "people who are not data scientists—in particular, decision makers who will use your\n",
            "results.\n",
            "\n",
            "--- Chunk 4682 ---\n",
            "results.\n",
            "In this chapter we will discuss the curse of dimensionality and get a sense of what\n",
            "\n",
            "--- Chunk 4683 ---\n",
            "goes on in high-dimensional space. Then, we will consider the two main approaches\n",
            "\n",
            "--- Chunk 4684 ---\n",
            "to dimensionality reduction (projection and Manifold Learning), and we will go\n",
            "\n",
            "--- Chunk 4685 ---\n",
            "through three of the most popular dimensionality reduction techniques: PCA, Kernel\n",
            "PCA, and LLE.\n",
            "\n",
            "--- Chunk 4686 ---\n",
            "The Curse of Dimensionality\n",
            "We are so used to living in three dimensions1 that our intuition fails us when we try\n",
            "\n",
            "--- Chunk 4687 ---\n",
            "to imagine a high-dimensional space. Even a basic 4D hypercube is incredibly hard to\n",
            "\n",
            "--- Chunk 4688 ---\n",
            "picture in our minds (see Figure 8-1), let alone a 200-dimensional ellipsoid bent in a\n",
            "1,000-dimensional space.\n",
            "\n",
            "--- Chunk 4689 ---\n",
            "Figure 8-1. Point, segment, square, cube, and tesseract (0D to 4D hypercubes)2\n",
            "\n",
            "--- Chunk 4690 ---\n",
            "It turns out that many things behave very differently in high-dimensional space. For\n",
            "\n",
            "--- Chunk 4691 ---\n",
            "example, if you pick a random point in a unit square (a 1 × 1 square), it will have only\n",
            "\n",
            "--- Chunk 4692 ---\n",
            "about a 0.4% chance of being located less than 0.001 from a border (in other words, it\n",
            "\n",
            "--- Chunk 4693 ---\n",
            "is very unlikely that a random point will be “extreme” along any dimension). But in a\n",
            "\n",
            "--- Chunk 4694 ---\n",
            "10,000-dimensional unit hypercube, this probability is greater than 99.999999%. Most\n",
            "\n",
            "--- Chunk 4695 ---\n",
            "points in a high-dimensional hypercube are very close to the border.3\n",
            "\n",
            "--- Chunk 4696 ---\n",
            "1 Well, four dimensions if you count time, and a few more if you are a string theorist.\n",
            "\n",
            "--- Chunk 4697 ---\n",
            "2 Watch a rotating tesseract projected into 3D space at https://homl.info/30. Image by Wikipedia user Nerd‐\n",
            "\n",
            "--- Chunk 4698 ---\n",
            "Boy1392 (Creative Commons BY-SA 3.0). Reproduced from https://en.wikipedia.org/wiki/Tesseract.\n",
            "\n",
            "--- Chunk 4699 ---\n",
            "3 Fun fact: anyone you know is probably an extremist in at least one dimension (e.g., how much sugar they put\n",
            "\n",
            "--- Chunk 4700 ---\n",
            "in their coffee), if you consider enough dimensions.\n",
            "\n",
            "214 | Chapter 8: Dimensionality Reduction\n",
            "\n",
            "--- Chunk 4701 ---\n",
            "Here is a more troublesome difference: if you pick two points randomly in a unit\n",
            "\n",
            "--- Chunk 4702 ---\n",
            "square, the distance between these two points will be, on average, roughly 0.52. If you\n",
            "\n",
            "--- Chunk 4703 ---\n",
            "pick two random points in a unit 3D cube, the average distance will be roughly 0.66.\n",
            "\n",
            "--- Chunk 4704 ---\n",
            "But what about two points picked randomly in a 1,000,000-dimensional hypercube?\n",
            "\n",
            "--- Chunk 4705 ---\n",
            "The average distance, believe it or not, will be about 408.25 (roughly 1, 000, 000/6)!\n",
            "\n",
            "--- Chunk 4706 ---\n",
            "This is counterintuitive: how can two points be so far apart when they both lie within\n",
            "\n",
            "--- Chunk 4707 ---\n",
            "the same unit hypercube? Well, there’s just plenty of space in high dimensions. As a\n",
            "\n",
            "--- Chunk 4708 ---\n",
            "result, high-dimensional datasets are at risk of being very sparse: most training\n",
            "\n",
            "--- Chunk 4709 ---\n",
            "instances are likely to be far away from each other. This also means that a new\n",
            "\n",
            "--- Chunk 4710 ---\n",
            "instance will likely be far away from any training instance, making predictions much\n",
            "\n",
            "--- Chunk 4711 ---\n",
            "less reliable than in lower dimensions, since they will be based on much larger extrap‐\n",
            "\n",
            "--- Chunk 4712 ---\n",
            "olations. In short, the more dimensions the training set has, the greater the risk of\n",
            "overfitting it.\n",
            "\n",
            "--- Chunk 4713 ---\n",
            "overfitting it.\n",
            "In theory, one solution to the curse of dimensionality could be to increase the size of\n",
            "\n",
            "--- Chunk 4714 ---\n",
            "the training set to reach a sufficient density of training instances. Unfortunately, in\n",
            "\n",
            "--- Chunk 4715 ---\n",
            "practice, the number of training instances required to reach a given density grows\n",
            "\n",
            "--- Chunk 4716 ---\n",
            "exponentially with the number of dimensions. With just 100 features (significantly\n",
            "\n",
            "--- Chunk 4717 ---\n",
            "fewer than in the MNIST problem), you would need more training instances than\n",
            "\n",
            "--- Chunk 4718 ---\n",
            "atoms in the observable universe in order for training instances to be within 0.1 of\n",
            "\n",
            "--- Chunk 4719 ---\n",
            "each other on average, assuming they were spread out uniformly across all dimen‐\n",
            "sions.\n",
            "\n",
            "--- Chunk 4720 ---\n",
            "Main Approaches for Dimensionality Reduction\n",
            "Before we dive into specific dimensionality reduction algorithms, let’s take a look at\n",
            "\n",
            "--- Chunk 4721 ---\n",
            "the two main approaches to reducing dimensionality: projection and Manifold\n",
            "Learning.\n",
            "\n",
            "--- Chunk 4722 ---\n",
            "Projection\n",
            "In most real-world problems, training instances are not spread out uniformly across\n",
            "\n",
            "--- Chunk 4723 ---\n",
            "all dimensions. Many features are almost constant, while others are highly correlated\n",
            "\n",
            "--- Chunk 4724 ---\n",
            "(as discussed earlier for MNIST). As a result, all training instances lie within (or close\n",
            "\n",
            "--- Chunk 4725 ---\n",
            "to) a much lower-dimensional subspace of the high-dimensional space. This sounds\n",
            "\n",
            "--- Chunk 4726 ---\n",
            "very abstract, so let’s look at an example. In Figure 8-2 you can see a 3D dataset repre‐\n",
            "sented by circles.\n",
            "\n",
            "--- Chunk 4727 ---\n",
            "Main Approaches for Dimensionality Reduction | 215\n",
            "\n",
            "\n",
            "\n",
            "Figure 8-2. A 3D dataset lying close to a 2D subspace\n",
            "\n",
            "--- Chunk 4728 ---\n",
            "Notice that all training instances lie close to a plane: this is a lower-dimensional (2D)\n",
            "\n",
            "--- Chunk 4729 ---\n",
            "subspace of the high-dimensional (3D) space. If we project every training instance\n",
            "\n",
            "--- Chunk 4730 ---\n",
            "perpendicularly onto this subspace (as represented by the short lines connecting the\n",
            "\n",
            "--- Chunk 4731 ---\n",
            "instances to the plane), we get the new 2D dataset shown in Figure 8-3. Ta-da! We\n",
            "\n",
            "--- Chunk 4732 ---\n",
            "have just reduced the dataset’s dimensionality from 3D to 2D. Note that the axes cor‐\n",
            "\n",
            "--- Chunk 4733 ---\n",
            "respond to new features z1 and z2 (the coordinates of the projections on the plane).\n",
            "\n",
            "--- Chunk 4734 ---\n",
            "Figure 8-3. The new 2D dataset after projection\n",
            "\n",
            "216 | Chapter 8: Dimensionality Reduction\n",
            "\n",
            "--- Chunk 4735 ---\n",
            "However, projection is not always the best approach to dimensionality reduction. In\n",
            "\n",
            "--- Chunk 4736 ---\n",
            "many cases the subspace may twist and turn, such as in the famous Swiss roll toy data‐\n",
            "set represented in Figure 8-4.\n",
            "\n",
            "--- Chunk 4737 ---\n",
            "Figure 8-4. Swiss roll dataset\n",
            "\n",
            "--- Chunk 4738 ---\n",
            "Simply projecting onto a plane (e.g., by dropping x3) would squash different layers of\n",
            "\n",
            "--- Chunk 4739 ---\n",
            "the Swiss roll together, as shown on the left side of Figure 8-5. What you really want is\n",
            "\n",
            "--- Chunk 4740 ---\n",
            "to unroll the Swiss roll to obtain the 2D dataset on the right side of Figure 8-5.\n",
            "\n",
            "--- Chunk 4741 ---\n",
            "Figure 8-5. Squashing by projecting onto a plane (left) versus unrolling the Swiss roll\n",
            "(right)\n",
            "\n",
            "Main Approaches for Dimensionality Reduction | 217\n",
            "\n",
            "--- Chunk 4742 ---\n",
            "Manifold Learning\n",
            "The Swiss roll is an example of a 2D manifold. Put simply, a 2D manifold is a 2D\n",
            "\n",
            "--- Chunk 4743 ---\n",
            "shape that can be bent and twisted in a higher-dimensional space. More generally, a\n",
            "\n",
            "--- Chunk 4744 ---\n",
            "d-dimensional manifold is a part of an n-dimensional space (where d < n) that locally\n",
            "\n",
            "--- Chunk 4745 ---\n",
            "resembles a d-dimensional hyperplane. In the case of the Swiss roll, d = 2 and n = 3: it\n",
            "\n",
            "--- Chunk 4746 ---\n",
            "locally resembles a 2D plane, but it is rolled in the third dimension.\n",
            "\n",
            "--- Chunk 4747 ---\n",
            "Many dimensionality reduction algorithms work by modeling the manifold on which\n",
            "\n",
            "--- Chunk 4748 ---\n",
            "the training instances lie; this is called Manifold Learning. It relies on the manifold\n",
            "\n",
            "--- Chunk 4749 ---\n",
            "assumption, also called the manifold hypothesis, which holds that most real-world\n",
            "\n",
            "--- Chunk 4750 ---\n",
            "high-dimensional datasets lie close to a much lower-dimensional manifold. This\n",
            "assumption is very often empirically observed.\n",
            "\n",
            "--- Chunk 4751 ---\n",
            "Once again, think about the MNIST dataset: all handwritten digit images have some\n",
            "\n",
            "--- Chunk 4752 ---\n",
            "similarities. They are made of connected lines, the borders are white, and they are\n",
            "\n",
            "--- Chunk 4753 ---\n",
            "more or less centered. If you randomly generated images, only a ridiculously tiny\n",
            "\n",
            "--- Chunk 4754 ---\n",
            "fraction of them would look like handwritten digits. In other words, the degrees of\n",
            "\n",
            "--- Chunk 4755 ---\n",
            "freedom available to you if you try to create a digit image are dramatically lower than\n",
            "\n",
            "--- Chunk 4756 ---\n",
            "the degrees of freedom you would have if you were allowed to generate any image\n",
            "\n",
            "--- Chunk 4757 ---\n",
            "you wanted. These constraints tend to squeeze the dataset into a lower-dimensional\n",
            "manifold.\n",
            "\n",
            "--- Chunk 4758 ---\n",
            "manifold.\n",
            "The manifold assumption is often accompanied by another implicit assumption: that\n",
            "\n",
            "--- Chunk 4759 ---\n",
            "the task at hand (e.g., classification or regression) will be simpler if expressed in the\n",
            "\n",
            "--- Chunk 4760 ---\n",
            "lower-dimensional space of the manifold. For example, in the top row of Figure 8-6\n",
            "\n",
            "--- Chunk 4761 ---\n",
            "the Swiss roll is split into two classes: in the 3D space (on the left), the decision\n",
            "\n",
            "--- Chunk 4762 ---\n",
            "boundary would be fairly complex, but in the 2D unrolled manifold space (on the\n",
            "right), the decision boundary is a straight line.\n",
            "\n",
            "--- Chunk 4763 ---\n",
            "However, this implicit assumption does not always hold. For example, in the bottom\n",
            "\n",
            "--- Chunk 4764 ---\n",
            "row of Figure 8-6, the decision boundary is located at x1 = 5. This decision boundary\n",
            "\n",
            "--- Chunk 4765 ---\n",
            "looks very simple in the original 3D space (a vertical plane), but it looks more com‐\n",
            "\n",
            "--- Chunk 4766 ---\n",
            "plex in the unrolled manifold (a collection of four independent line segments).\n",
            "\n",
            "--- Chunk 4767 ---\n",
            "In short, reducing the dimensionality of your training set before training a model will\n",
            "\n",
            "--- Chunk 4768 ---\n",
            "usually speed up training, but it may not always lead to a better or simpler solution; it\n",
            "all depends on the dataset.\n",
            "\n",
            "--- Chunk 4769 ---\n",
            "Hopefully you now have a good sense of what the curse of dimensionality is and how\n",
            "\n",
            "--- Chunk 4770 ---\n",
            "dimensionality reduction algorithms can fight it, especially when the manifold\n",
            "\n",
            "--- Chunk 4771 ---\n",
            "assumption holds. The rest of this chapter will go through some of the most popular\n",
            "algorithms.\n",
            "\n",
            "--- Chunk 4772 ---\n",
            "218 | Chapter 8: Dimensionality Reduction\n",
            "\n",
            "\n",
            "\n",
            "Figure 8-6. The decision boundary may not always be simpler with lower dimensions\n",
            "\n",
            "--- Chunk 4773 ---\n",
            "PCA\n",
            "Principal Component Analysis (PCA) is by far the most popular dimensionality reduc‐\n",
            "\n",
            "--- Chunk 4774 ---\n",
            "tion algorithm. First it identifies the hyperplane that lies closest to the data, and then\n",
            "it projects the data onto it, just like in Figure 8-2.\n",
            "\n",
            "--- Chunk 4775 ---\n",
            "Preserving the Variance\n",
            "Before you can project the training set onto a lower-dimensional hyperplane, you\n",
            "\n",
            "--- Chunk 4776 ---\n",
            "first need to choose the right hyperplane. For example, a simple 2D dataset is repre‐\n",
            "\n",
            "--- Chunk 4777 ---\n",
            "sented on the left in Figure 8-7, along with three different axes (i.e., 1D hyperplanes).\n",
            "\n",
            "--- Chunk 4778 ---\n",
            "On the right is the result of the projection of the dataset onto each of these axes. As\n",
            "\n",
            "--- Chunk 4779 ---\n",
            "you can see, the projection onto the solid line preserves the maximum variance, while\n",
            "\n",
            "--- Chunk 4780 ---\n",
            "the projection onto the dotted line preserves very little variance and the projection\n",
            "\n",
            "--- Chunk 4781 ---\n",
            "onto the dashed line preserves an intermediate amount of variance.\n",
            "\n",
            "--- Chunk 4782 ---\n",
            "PCA | 219\n",
            "\n",
            "\n",
            "\n",
            "Figure 8-7. Selecting the subspace to project on\n",
            "\n",
            "--- Chunk 4783 ---\n",
            "It seems reasonable to select the axis that preserves the maximum amount of var‐\n",
            "\n",
            "--- Chunk 4784 ---\n",
            "iance, as it will most likely lose less information than the other projections. Another\n",
            "\n",
            "--- Chunk 4785 ---\n",
            "way to justify this choice is that it is the axis that minimizes the mean squared dis‐\n",
            "\n",
            "--- Chunk 4786 ---\n",
            "tance between the original dataset and its projection onto that axis. This is the rather\n",
            "simple idea behind PCA.4\n",
            "\n",
            "--- Chunk 4787 ---\n",
            "Principal Components\n",
            "PCA identifies the axis that accounts for the largest amount of variance in the train‐\n",
            "\n",
            "--- Chunk 4788 ---\n",
            "ing set. In Figure 8-7, it is the solid line. It also finds a second axis, orthogonal to the\n",
            "\n",
            "--- Chunk 4789 ---\n",
            "first one, that accounts for the largest amount of remaining variance. In this 2D\n",
            "\n",
            "--- Chunk 4790 ---\n",
            "example there is no choice: it is the dotted line. If it were a higher-dimensional data‐\n",
            "\n",
            "--- Chunk 4791 ---\n",
            "set, PCA would also find a third axis, orthogonal to both previous axes, and a fourth,\n",
            "\n",
            "--- Chunk 4792 ---\n",
            "a fifth, and so on—as many axes as the number of dimensions in the dataset.\n",
            "\n",
            "--- Chunk 4793 ---\n",
            "The ith axis is called the ith principal component (PC) of the data. In Figure 8-7, the\n",
            "\n",
            "--- Chunk 4794 ---\n",
            "first PC is the axis on which vector c1 lies, and the second PC is the axis on which\n",
            "\n",
            "--- Chunk 4795 ---\n",
            "vector c2 lies. In Figure 8-2 the first two PCs are the orthogonal axes on which the\n",
            "\n",
            "--- Chunk 4796 ---\n",
            "two arrows lie, on the plane, and the third PC is the axis orthogonal to that plane.\n",
            "\n",
            "--- Chunk 4797 ---\n",
            "4 Karl Pearson, “On Lines and Planes of Closest Fit to Systems of Points in Space,” The London, Edinburgh, and\n",
            "\n",
            "--- Chunk 4798 ---\n",
            "Dublin Philosophical Magazine and Journal of Science 2, no. 11 (1901): 559-572, https://homl.info/pca.\n",
            "\n",
            "--- Chunk 4799 ---\n",
            "220 | Chapter 8: Dimensionality Reduction\n",
            "\n",
            "--- Chunk 4800 ---\n",
            "For each principal component, PCA finds a zero-centered unit vec‐\n",
            "tor pointing in the direction of the PC. Since two opposing unit\n",
            "\n",
            "--- Chunk 4801 ---\n",
            "vectors lie on the same axis, the direction of the unit vectors\n",
            "returned by PCA is not stable: if you perturb the training set\n",
            "\n",
            "--- Chunk 4802 ---\n",
            "slightly and run PCA again, the unit vectors may point in the oppo‐\n",
            "site direction as the original vectors. However, they will generally\n",
            "\n",
            "--- Chunk 4803 ---\n",
            "still lie on the same axes. In some cases, a pair of unit vectors may\n",
            "even rotate or swap (if the variances along these two axes are close),\n",
            "\n",
            "--- Chunk 4804 ---\n",
            "but the plane they define will generally remain the same.\n",
            "\n",
            "--- Chunk 4805 ---\n",
            "So how can you find the principal components of a training set? Luckily, there is a\n",
            "\n",
            "--- Chunk 4806 ---\n",
            "standard matrix factorization technique called Singular Value Decomposition (SVD)\n",
            "\n",
            "--- Chunk 4807 ---\n",
            "that can decompose the training set matrix X into the matrix multiplication of three\n",
            "\n",
            "--- Chunk 4808 ---\n",
            "matrices U Σ V⊺, where V contains the unit vectors that define all the principal com‐\n",
            "ponents that we are looking for, as shown in Equation 8-1.\n",
            "\n",
            "--- Chunk 4809 ---\n",
            "Equation 8-1. Principal components matrix\n",
            "∣ ∣ ∣\n",
            "\n",
            "V = c1 c2 ⋯ cn\n",
            "∣ ∣ ∣\n",
            "\n",
            "--- Chunk 4810 ---\n",
            "The following Python code uses NumPy’s svd() function to obtain all the principal\n",
            "\n",
            "--- Chunk 4811 ---\n",
            "components of the training set, then extracts the two unit vectors that define the first\n",
            "two PCs:\n",
            "\n",
            "--- Chunk 4812 ---\n",
            "X_centered = X - X.mean(axis=0)\n",
            "U, s, Vt = np.linalg.svd(X_centered)\n",
            "c1 = Vt.T[:, 0]\n",
            "c2 = Vt.T[:, 1]\n",
            "\n",
            "--- Chunk 4813 ---\n",
            "PCA assumes that the dataset is centered around the origin. As we\n",
            "will see, Scikit-Learn’s PCA classes take care of centering the data\n",
            "\n",
            "--- Chunk 4814 ---\n",
            "for you. If you implement PCA yourself (as in the preceding exam‐\n",
            "ple), or if you use other libraries, don’t forget to center the data\n",
            "first.\n",
            "\n",
            "--- Chunk 4815 ---\n",
            "Projecting Down to d Dimensions\n",
            "Once you have identified all the principal components, you can reduce the dimen‐\n",
            "\n",
            "--- Chunk 4816 ---\n",
            "sionality of the dataset down to d dimensions by projecting it onto the hyperplane\n",
            "\n",
            "--- Chunk 4817 ---\n",
            "defined by the first d principal components. Selecting this hyperplane ensures that the\n",
            "\n",
            "--- Chunk 4818 ---\n",
            "projection will preserve as much variance as possible. For example, in Figure 8-2 the\n",
            "\n",
            "--- Chunk 4819 ---\n",
            "3D dataset is projected down to the 2D plane defined by the first two principal\n",
            "\n",
            "--- Chunk 4820 ---\n",
            "PCA | 221\n",
            "\n",
            "--- Chunk 4821 ---\n",
            "components, preserving a large part of the dataset’s variance. As a result, the 2D pro‐\n",
            "jection looks very much like the original 3D dataset.\n",
            "\n",
            "--- Chunk 4822 ---\n",
            "To project the training set onto the hyperplane and obtain a reduced dataset Xd-proj of\n",
            "\n",
            "--- Chunk 4823 ---\n",
            "dimensionality d, compute the matrix multiplication of the training set matrix X by\n",
            "\n",
            "--- Chunk 4824 ---\n",
            "the matrix Wd, defined as the matrix containing the first d columns of V, as shown in\n",
            "Equation 8-2.\n",
            "\n",
            "--- Chunk 4825 ---\n",
            "Equation 8-2. Projecting the training set down to d dimensions\n",
            "Xd‐proj = XWd\n",
            "\n",
            "--- Chunk 4826 ---\n",
            "The following Python code projects the training set onto the plane defined by the first\n",
            "two principal components:\n",
            "\n",
            "--- Chunk 4827 ---\n",
            "W2 = Vt.T[:, :2]\n",
            "X2D = X_centered.dot(W2)\n",
            "\n",
            "--- Chunk 4828 ---\n",
            "There you have it! You now know how to reduce the dimensionality of any dataset\n",
            "\n",
            "--- Chunk 4829 ---\n",
            "down to any number of dimensions, while preserving as much variance as possible.\n",
            "\n",
            "--- Chunk 4830 ---\n",
            "Using Scikit-Learn\n",
            "Scikit-Learn’s PCA class uses SVD decomposition to implement PCA, just like we did\n",
            "\n",
            "--- Chunk 4831 ---\n",
            "earlier in this chapter. The following code applies PCA to reduce the dimensionality\n",
            "\n",
            "--- Chunk 4832 ---\n",
            "of the dataset down to two dimensions (note that it automatically takes care of center‐\n",
            "ing the data):\n",
            "\n",
            "--- Chunk 4833 ---\n",
            "from sklearn.decomposition import PCA\n",
            "\n",
            "pca = PCA(n_components = 2)\n",
            "X2D = pca.fit_transform(X)\n",
            "\n",
            "--- Chunk 4834 ---\n",
            "After fitting the PCA transformer to the dataset, its components_ attribute holds the\n",
            "\n",
            "--- Chunk 4835 ---\n",
            "transpose of Wd (e.g., the unit vector that defines the first principal component is\n",
            "equal to pca.components_.T[:, 0]).\n",
            "\n",
            "--- Chunk 4836 ---\n",
            "Explained Variance Ratio\n",
            "Another useful piece of information is the explained variance ratio of each principal\n",
            "\n",
            "--- Chunk 4837 ---\n",
            "component, available via the explained_variance_ratio_ variable. The ratio indi‐\n",
            "\n",
            "--- Chunk 4838 ---\n",
            "cates the proportion of the dataset’s variance that lies along each principal compo‐\n",
            "\n",
            "--- Chunk 4839 ---\n",
            "nent. For example, let’s look at the explained variance ratios of the first two\n",
            "components of the 3D dataset represented in Figure 8-2:\n",
            "\n",
            "--- Chunk 4840 ---\n",
            ">>> pca.explained_variance_ratio_\n",
            "array([0.84248607, 0.14631839])\n",
            "\n",
            "222 | Chapter 8: Dimensionality Reduction\n",
            "\n",
            "--- Chunk 4841 ---\n",
            "This output tells you that 84.2% of the dataset’s variance lies along the first PC, and\n",
            "\n",
            "--- Chunk 4842 ---\n",
            "14.6% lies along the second PC. This leaves less than 1.2% for the third PC, so it is\n",
            "\n",
            "--- Chunk 4843 ---\n",
            "reasonable to assume that the third PC probably carries little information.\n",
            "\n",
            "--- Chunk 4844 ---\n",
            "Choosing the Right Number of Dimensions\n",
            "Instead of arbitrarily choosing the number of dimensions to reduce down to, it is\n",
            "\n",
            "--- Chunk 4845 ---\n",
            "simpler to choose the number of dimensions that add up to a sufficiently large por‐\n",
            "\n",
            "--- Chunk 4846 ---\n",
            "tion of the variance (e.g., 95%). Unless, of course, you are reducing dimensionality for\n",
            "\n",
            "--- Chunk 4847 ---\n",
            "data visualization—in that case you will want to reduce the dimensionality down to 2\n",
            "or 3.\n",
            "\n",
            "--- Chunk 4848 ---\n",
            "or 3.\n",
            "The following code performs PCA without reducing dimensionality, then computes\n",
            "\n",
            "--- Chunk 4849 ---\n",
            "the minimum number of dimensions required to preserve 95% of the training set’s\n",
            "variance:\n",
            "\n",
            "--- Chunk 4850 ---\n",
            "pca = PCA()\n",
            "pca.fit(X_train)\n",
            "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
            "d = np.argmax(cumsum >= 0.95) + 1\n",
            "\n",
            "--- Chunk 4851 ---\n",
            "You could then set n_components=d and run PCA again. But there is a much better\n",
            "\n",
            "--- Chunk 4852 ---\n",
            "option: instead of specifying the number of principal components you want to pre‐\n",
            "\n",
            "--- Chunk 4853 ---\n",
            "serve, you can set n_components to be a float between 0.0 and 1.0, indicating the ratio\n",
            "of variance you wish to preserve:\n",
            "\n",
            "--- Chunk 4854 ---\n",
            "pca = PCA(n_components=0.95)\n",
            "X_reduced = pca.fit_transform(X_train)\n",
            "\n",
            "--- Chunk 4855 ---\n",
            "Yet another option is to plot the explained variance as a function of the number of\n",
            "\n",
            "--- Chunk 4856 ---\n",
            "dimensions (simply plot cumsum; see Figure 8-8). There will usually be an elbow in the\n",
            "\n",
            "--- Chunk 4857 ---\n",
            "curve, where the explained variance stops growing fast. In this case, you can see that\n",
            "\n",
            "--- Chunk 4858 ---\n",
            "reducing the dimensionality down to about 100 dimensions wouldn’t lose too much\n",
            "explained variance.\n",
            "\n",
            "--- Chunk 4859 ---\n",
            "PCA | 223\n",
            "\n",
            "\n",
            "\n",
            "Figure 8-8. Explained variance as a function of the number of dimensions\n",
            "\n",
            "--- Chunk 4860 ---\n",
            "PCA for Compression\n",
            "After dimensionality reduction, the training set takes up much less space. As an\n",
            "\n",
            "--- Chunk 4861 ---\n",
            "example, try applying PCA to the MNIST dataset while preserving 95% of its var‐\n",
            "\n",
            "--- Chunk 4862 ---\n",
            "iance. You should find that each instance will have just over 150 features, instead of\n",
            "\n",
            "--- Chunk 4863 ---\n",
            "the original 784 features. So, while most of the variance is preserved, the dataset is\n",
            "\n",
            "--- Chunk 4864 ---\n",
            "now less than 20% of its original size! This is a reasonable compression ratio, and you\n",
            "\n",
            "--- Chunk 4865 ---\n",
            "can see how this size reduction can speed up a classification algorithm (such as an\n",
            "SVM classifier) tremendously.\n",
            "\n",
            "--- Chunk 4866 ---\n",
            "It is also possible to decompress the reduced dataset back to 784 dimensions by\n",
            "\n",
            "--- Chunk 4867 ---\n",
            "applying the inverse transformation of the PCA projection. This won’t give you back\n",
            "\n",
            "--- Chunk 4868 ---\n",
            "the original data, since the projection lost a bit of information (within the 5% var‐\n",
            "\n",
            "--- Chunk 4869 ---\n",
            "iance that was dropped), but it will likely be close to the original data. The mean\n",
            "\n",
            "--- Chunk 4870 ---\n",
            "squared distance between the original data and the reconstructed data (compressed\n",
            "and then decompressed) is called the reconstruction error.\n",
            "\n",
            "--- Chunk 4871 ---\n",
            "The following code compresses the MNIST dataset down to 154 dimensions, then\n",
            "\n",
            "--- Chunk 4872 ---\n",
            "uses the inverse_transform() method to decompress it back to 784 dimensions:\n",
            "\n",
            "--- Chunk 4873 ---\n",
            "pca = PCA(n_components = 154)\n",
            "X_reduced = pca.fit_transform(X_train)\n",
            "X_recovered = pca.inverse_transform(X_reduced)\n",
            "\n",
            "--- Chunk 4874 ---\n",
            "Figure 8-9 shows a few digits from the original training set (on the left), and the cor‐\n",
            "\n",
            "--- Chunk 4875 ---\n",
            "responding digits after compression and decompression. You can see that there is a\n",
            "slight image quality loss, but the digits are still mostly intact.\n",
            "\n",
            "--- Chunk 4876 ---\n",
            "224 | Chapter 8: Dimensionality Reduction\n",
            "\n",
            "\n",
            "\n",
            "Figure 8-9. MNIST compression that preserves 95% of the variance\n",
            "\n",
            "--- Chunk 4877 ---\n",
            "The equation of the inverse transformation is shown in Equation 8-3.\n",
            "\n",
            "--- Chunk 4878 ---\n",
            "Equation 8-3. PCA inverse transformation, back to the original number of\n",
            "dimensions\n",
            "X ⊺\n",
            "\n",
            "recovered = Xd‐projWd\n",
            "\n",
            "--- Chunk 4879 ---\n",
            "Randomized PCA\n",
            "If you set the svd_solver hyperparameter to \"randomized\", Scikit-Learn uses a sto‐\n",
            "\n",
            "--- Chunk 4880 ---\n",
            "chastic algorithm called Randomized PCA that quickly finds an approximation of the\n",
            "\n",
            "--- Chunk 4881 ---\n",
            "first d principal components. Its computational complexity is O(m × d2) + O(d3),\n",
            "\n",
            "--- Chunk 4882 ---\n",
            "instead of O(m × n2) + O(n3) for the full SVD approach, so it is dramatically faster\n",
            "than full SVD when d is much smaller than n:\n",
            "\n",
            "--- Chunk 4883 ---\n",
            "rnd_pca = PCA(n_components=154, svd_solver=\"randomized\")\n",
            "X_reduced = rnd_pca.fit_transform(X_train)\n",
            "\n",
            "--- Chunk 4884 ---\n",
            "By default, svd_solver is actually set to \"auto\": Scikit-Learn automatically uses the\n",
            "\n",
            "--- Chunk 4885 ---\n",
            "randomized PCA algorithm if m or n is greater than 500 and d is less than 80% of m\n",
            "\n",
            "--- Chunk 4886 ---\n",
            "or n, or else it uses the full SVD approach. If you want to force Scikit-Learn to use full\n",
            "SVD, you can set the svd_solver hyperparameter to \"full\".\n",
            "\n",
            "--- Chunk 4887 ---\n",
            "Incremental PCA\n",
            "One problem with the preceding implementations of PCA is that they require the\n",
            "\n",
            "--- Chunk 4888 ---\n",
            "whole training set to fit in memory in order for the algorithm to run. Fortunately,\n",
            "\n",
            "--- Chunk 4889 ---\n",
            "Incremental PCA (IPCA) algorithms have been developed. They allow you to split the\n",
            "\n",
            "--- Chunk 4890 ---\n",
            "training set into mini-batches and feed an IPCA algorithm one mini-batch at a time.\n",
            "\n",
            "--- Chunk 4891 ---\n",
            "PCA | 225\n",
            "\n",
            "--- Chunk 4892 ---\n",
            "This is useful for large training sets and for applying PCA online (i.e., on the fly, as\n",
            "new instances arrive).\n",
            "\n",
            "--- Chunk 4893 ---\n",
            "The following code splits the MNIST dataset into 100 mini-batches (using NumPy’s\n",
            "\n",
            "--- Chunk 4894 ---\n",
            "array_split() function) and feeds them to Scikit-Learn’s IncrementalPCA class5 to\n",
            "\n",
            "--- Chunk 4895 ---\n",
            "reduce the dimensionality of the MNIST dataset down to 154 dimensions (just like\n",
            "\n",
            "--- Chunk 4896 ---\n",
            "before). Note that you must call the partial_fit() method with each mini-batch,\n",
            "rather than the fit() method with the whole training set:\n",
            "\n",
            "--- Chunk 4897 ---\n",
            "from sklearn.decomposition import IncrementalPCA\n",
            "\n",
            "--- Chunk 4898 ---\n",
            "n_batches = 100\n",
            "inc_pca = IncrementalPCA(n_components=154)\n",
            "for X_batch in np.array_split(X_train, n_batches):\n",
            "    inc_pca.partial_fit(X_batch)\n",
            "\n",
            "--- Chunk 4899 ---\n",
            "X_reduced = inc_pca.transform(X_train)\n",
            "\n",
            "--- Chunk 4900 ---\n",
            "Alternatively, you can use NumPy’s memmap class, which allows you to manipulate a\n",
            "\n",
            "--- Chunk 4901 ---\n",
            "large array stored in a binary file on disk as if it were entirely in memory; the class\n",
            "\n",
            "--- Chunk 4902 ---\n",
            "loads only the data it needs in memory, when it needs it. Since the IncrementalPCA\n",
            "\n",
            "--- Chunk 4903 ---\n",
            "class uses only a small part of the array at any given time, the memory usage remains\n",
            "\n",
            "--- Chunk 4904 ---\n",
            "under control. This makes it possible to call the usual fit() method, as you can see\n",
            "in the following code:\n",
            "\n",
            "--- Chunk 4905 ---\n",
            "X_mm = np.memmap(filename, dtype=\"float32\", mode=\"readonly\", shape=(m, n))\n",
            "\n",
            "--- Chunk 4906 ---\n",
            "batch_size = m // n_batches\n",
            "inc_pca = IncrementalPCA(n_components=154, batch_size=batch_size)\n",
            "inc_pca.fit(X_mm)\n",
            "\n",
            "--- Chunk 4907 ---\n",
            "Kernel PCA\n",
            "In Chapter 5 we discussed the kernel trick, a mathematical technique that implicitly\n",
            "\n",
            "--- Chunk 4908 ---\n",
            "maps instances into a very high-dimensional space (called the feature space), enabling\n",
            "\n",
            "--- Chunk 4909 ---\n",
            "nonlinear classification and regression with Support Vector Machines. Recall that a\n",
            "\n",
            "--- Chunk 4910 ---\n",
            "linear decision boundary in the high-dimensional feature space corresponds to a\n",
            "complex nonlinear decision boundary in the original space.\n",
            "\n",
            "--- Chunk 4911 ---\n",
            "It turns out that the same trick can be applied to PCA, making it possible to perform\n",
            "\n",
            "--- Chunk 4912 ---\n",
            "complex nonlinear projections for dimensionality reduction. This is called Kernel\n",
            "\n",
            "--- Chunk 4913 ---\n",
            "5 Scikit-Learn uses the algorithm described in David A. Ross et al., “Incremental Learning for Robust Visual\n",
            "\n",
            "--- Chunk 4914 ---\n",
            "Tracking,” International Journal of Computer Vision 77, no. 1–3 (2008): 125–141.\n",
            "\n",
            "--- Chunk 4915 ---\n",
            "226 | Chapter 8: Dimensionality Reduction\n",
            "\n",
            "--- Chunk 4916 ---\n",
            "PCA (kPCA).6 It is often good at preserving clusters of instances after projection, or\n",
            "\n",
            "--- Chunk 4917 ---\n",
            "sometimes even unrolling datasets that lie close to a twisted manifold.\n",
            "\n",
            "--- Chunk 4918 ---\n",
            "The following code uses Scikit-Learn’s KernelPCA class to perform kPCA with an RBF\n",
            "\n",
            "--- Chunk 4919 ---\n",
            "kernel (see Chapter 5 for more details about the RBF kernel and other kernels):\n",
            "\n",
            "--- Chunk 4920 ---\n",
            "from sklearn.decomposition import KernelPCA\n",
            "\n",
            "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.04)\n",
            "X_reduced = rbf_pca.fit_transform(X)\n",
            "\n",
            "--- Chunk 4921 ---\n",
            "Figure 8-10 shows the Swiss roll, reduced to two dimensions using a linear kernel\n",
            "\n",
            "--- Chunk 4922 ---\n",
            "(equivalent to simply using the PCA class), an RBF kernel, and a sigmoid kernel.\n",
            "\n",
            "--- Chunk 4923 ---\n",
            "Figure 8-10. Swiss roll reduced to 2D using kPCA with various kernels\n",
            "\n",
            "--- Chunk 4924 ---\n",
            "Selecting a Kernel and Tuning Hyperparameters\n",
            "As kPCA is an unsupervised learning algorithm, there is no obvious performance\n",
            "\n",
            "--- Chunk 4925 ---\n",
            "measure to help you select the best kernel and hyperparameter values. That said,\n",
            "\n",
            "--- Chunk 4926 ---\n",
            "dimensionality reduction is often a preparation step for a supervised learning task\n",
            "\n",
            "--- Chunk 4927 ---\n",
            "(e.g., classification), so you can use grid search to select the kernel and hyperparame‐\n",
            "\n",
            "--- Chunk 4928 ---\n",
            "ters that lead to the best performance on that task. The following code creates a two-\n",
            "\n",
            "--- Chunk 4929 ---\n",
            "step pipeline, first reducing dimensionality to two dimensions using kPCA, then\n",
            "\n",
            "--- Chunk 4930 ---\n",
            "applying Logistic Regression for classification. Then it uses GridSearchCV to find the\n",
            "\n",
            "--- Chunk 4931 ---\n",
            "best kernel and gamma value for kPCA in order to get the best classification accuracy\n",
            "at the end of the pipeline:\n",
            "\n",
            "--- Chunk 4932 ---\n",
            "from sklearn.model_selection import GridSearchCV\n",
            "from sklearn.linear_model import LogisticRegression\n",
            "from sklearn.pipeline import Pipeline\n",
            "\n",
            "--- Chunk 4933 ---\n",
            "6 Bernhard Schölkopf et al., “Kernel Principal Component Analysis,” in Lecture Notes in Computer Science 1327\n",
            "(Berlin: Springer, 1997): 583–588.\n",
            "\n",
            "--- Chunk 4934 ---\n",
            "Kernel PCA | 227\n",
            "\n",
            "\n",
            "\n",
            "clf = Pipeline([\n",
            "        (\"kpca\", KernelPCA(n_components=2)),\n",
            "        (\"log_reg\", LogisticRegression())\n",
            "    ])\n",
            "\n",
            "--- Chunk 4935 ---\n",
            "param_grid = [{\n",
            "        \"kpca__gamma\": np.linspace(0.03, 0.05, 10),\n",
            "        \"kpca__kernel\": [\"rbf\", \"sigmoid\"]\n",
            "    }]\n",
            "\n",
            "--- Chunk 4936 ---\n",
            "grid_search = GridSearchCV(clf, param_grid, cv=3)\n",
            "grid_search.fit(X, y)\n",
            "\n",
            "--- Chunk 4937 ---\n",
            "The best kernel and hyperparameters are then available through the best_params_\n",
            "variable:\n",
            "\n",
            "--- Chunk 4938 ---\n",
            ">>> print(grid_search.best_params_)\n",
            "{'kpca__gamma': 0.043333333333333335, 'kpca__kernel': 'rbf'}\n",
            "\n",
            "--- Chunk 4939 ---\n",
            "Another approach, this time entirely unsupervised, is to select the kernel and hyper‐\n",
            "\n",
            "--- Chunk 4940 ---\n",
            "parameters that yield the lowest reconstruction error. Note that reconstruction is not\n",
            "\n",
            "--- Chunk 4941 ---\n",
            "as easy as with linear PCA. Here’s why. Figure 8-11 shows the original Swiss roll 3D\n",
            "\n",
            "--- Chunk 4942 ---\n",
            "dataset (top left) and the resulting 2D dataset after kPCA is applied using an RBF ker‐\n",
            "\n",
            "--- Chunk 4943 ---\n",
            "nel (top right). Thanks to the kernel trick, this transformation is mathematically\n",
            "\n",
            "--- Chunk 4944 ---\n",
            "equivalent to using the feature map φ to map the training set to an infinite-\n",
            "\n",
            "--- Chunk 4945 ---\n",
            "dimensional feature space (bottom right), then projecting the transformed training\n",
            "set down to 2D using linear PCA.\n",
            "\n",
            "--- Chunk 4946 ---\n",
            "Notice that if we could invert the linear PCA step for a given instance in the reduced\n",
            "\n",
            "--- Chunk 4947 ---\n",
            "space, the reconstructed point would lie in feature space, not in the original space\n",
            "\n",
            "--- Chunk 4948 ---\n",
            "(e.g., like the one represented by an X in the diagram). Since the feature space is\n",
            "\n",
            "--- Chunk 4949 ---\n",
            "infinite-dimensional, we cannot compute the reconstructed point, and therefore we\n",
            "\n",
            "--- Chunk 4950 ---\n",
            "cannot compute the true reconstruction error. Fortunately, it is possible to find a\n",
            "\n",
            "--- Chunk 4951 ---\n",
            "point in the original space that would map close to the reconstructed point. This\n",
            "\n",
            "--- Chunk 4952 ---\n",
            "point is called the reconstruction pre-image. Once you have this pre-image, you can\n",
            "\n",
            "--- Chunk 4953 ---\n",
            "measure its squared distance to the original instance. You can then select the kernel\n",
            "\n",
            "--- Chunk 4954 ---\n",
            "and hyperparameters that minimize this reconstruction pre-image error.\n",
            "\n",
            "--- Chunk 4955 ---\n",
            "228 | Chapter 8: Dimensionality Reduction\n",
            "\n",
            "\n",
            "\n",
            "Figure 8-11. Kernel PCA and the reconstruction pre-image error\n",
            "\n",
            "--- Chunk 4956 ---\n",
            "You may be wondering how to perform this reconstruction. One solution is to train a\n",
            "\n",
            "--- Chunk 4957 ---\n",
            "supervised regression model, with the projected instances as the training set and the\n",
            "\n",
            "--- Chunk 4958 ---\n",
            "original instances as the targets. Scikit-Learn will do this automatically if you set\n",
            "fit_inverse_transform=True, as shown in the following code:7\n",
            "\n",
            "--- Chunk 4959 ---\n",
            "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.0433,\n",
            "                    fit_inverse_transform=True)\n",
            "\n",
            "--- Chunk 4960 ---\n",
            "X_reduced = rbf_pca.fit_transform(X)\n",
            "X_preimage = rbf_pca.inverse_transform(X_reduced)\n",
            "\n",
            "--- Chunk 4961 ---\n",
            "By default, fit_inverse_transform=False and KernelPCA has no\n",
            "inverse_transform() method. This method only gets created\n",
            "\n",
            "--- Chunk 4962 ---\n",
            "when you set fit_inverse_transform=True.\n",
            "\n",
            "--- Chunk 4963 ---\n",
            "7 If you set fit_inverse_transform=True, Scikit-Learn will use the algorithm (based on Kernel Ridge Regres‐\n",
            "\n",
            "--- Chunk 4964 ---\n",
            "sion) described in Gokhan H. Bakır et al., “Learning to Find Pre-Images”, Proceedings of the 16th International\n",
            "\n",
            "--- Chunk 4965 ---\n",
            "Conference on Neural Information Processing Systems (2004): 449–456.\n",
            "\n",
            "--- Chunk 4966 ---\n",
            "Kernel PCA | 229\n",
            "\n",
            "--- Chunk 4967 ---\n",
            "You can then compute the reconstruction pre-image error:\n",
            ">>> from sklearn.metrics import mean_squared_error\n",
            ">>> mean_squared_error(X, X_preimage)\n",
            "\n",
            "--- Chunk 4968 ---\n",
            "32.786308795766132\n",
            "\n",
            "--- Chunk 4969 ---\n",
            "Now you can use grid search with cross-validation to find the kernel and hyperpara‐\n",
            "meters that minimize this error.\n",
            "\n",
            "--- Chunk 4970 ---\n",
            "LLE\n",
            "Locally Linear Embedding (LLE)8 is another powerful nonlinear dimensionality reduc‐\n",
            "\n",
            "--- Chunk 4971 ---\n",
            "tion (NLDR) technique. It is a Manifold Learning technique that does not rely on\n",
            "\n",
            "--- Chunk 4972 ---\n",
            "projections, like the previous algorithms do. In a nutshell, LLE works by first measur‐\n",
            "\n",
            "--- Chunk 4973 ---\n",
            "ing how each training instance linearly relates to its closest neighbors (c.n.), and then\n",
            "\n",
            "--- Chunk 4974 ---\n",
            "looking for a low-dimensional representation of the training set where these local\n",
            "\n",
            "--- Chunk 4975 ---\n",
            "relationships are best preserved (more details shortly). This approach makes it partic‐\n",
            "\n",
            "--- Chunk 4976 ---\n",
            "ularly good at unrolling twisted manifolds, especially when there is not too much\n",
            "noise.\n",
            "\n",
            "--- Chunk 4977 ---\n",
            "noise.\n",
            "The following code uses Scikit-Learn’s LocallyLinearEmbedding class to unroll the\n",
            "Swiss roll:\n",
            "\n",
            "--- Chunk 4978 ---\n",
            "from sklearn.manifold import LocallyLinearEmbedding\n",
            "\n",
            "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=10)\n",
            "X_reduced = lle.fit_transform(X)\n",
            "\n",
            "--- Chunk 4979 ---\n",
            "The resulting 2D dataset is shown in Figure 8-12. As you can see, the Swiss roll is\n",
            "\n",
            "--- Chunk 4980 ---\n",
            "completely unrolled, and the distances between instances are locally well preserved.\n",
            "\n",
            "--- Chunk 4981 ---\n",
            "However, distances are not preserved on a larger scale: the left part of the unrolled\n",
            "\n",
            "--- Chunk 4982 ---\n",
            "Swiss roll is stretched, while the right part is squeezed. Nevertheless, LLE did a pretty\n",
            "good job at modeling the manifold.\n",
            "\n",
            "--- Chunk 4983 ---\n",
            "8 Sam T. Roweis and Lawrence K. Saul, “Nonlinear Dimensionality Reduction by Locally Linear Embedding,”\n",
            "Science 290, no. 5500 (2000): 2323–2326.\n",
            "\n",
            "--- Chunk 4984 ---\n",
            "230 | Chapter 8: Dimensionality Reduction\n",
            "\n",
            "\n",
            "\n",
            "Figure 8-12. Unrolled Swiss roll using LLE\n",
            "\n",
            "--- Chunk 4985 ---\n",
            "Here’s how LLE works: for each training instance x(i), the algorithm identifies its k\n",
            "\n",
            "--- Chunk 4986 ---\n",
            "closest neighbors (in the preceding code k = 10), then tries to reconstruct x(i) as a lin‐\n",
            "\n",
            "--- Chunk 4987 ---\n",
            "ear function of these neighbors. More specifically, it finds the weights wi,j such that\n",
            "the squared distance between x(i) and ∑m\n",
            "\n",
            "--- Chunk 4988 ---\n",
            "j = 1 wi, jx\n",
            "j  is as small as possible, assuming wi,j\n",
            "\n",
            "--- Chunk 4989 ---\n",
            "= 0 if x(j) is not one of the k closest neighbors of x(i). Thus the first step of LLE is the\n",
            "\n",
            "--- Chunk 4990 ---\n",
            "constrained optimization problem described in Equation 8-4, where W is the weight\n",
            "\n",
            "--- Chunk 4991 ---\n",
            "matrix containing all the weights wi,j. The second constraint simply normalizes the\n",
            "weights for each training instance x(i).\n",
            "\n",
            "--- Chunk 4992 ---\n",
            "Equation 8-4. LLE step one: linearly modeling local relationships\n",
            "m m 2\n",
            "\n",
            "W = argmin ∑ x i − ∑ w x j\n",
            "W i = 1 j = 1 i, j\n",
            "\n",
            "--- Chunk 4993 ---\n",
            "w j\n",
            "i, j = 0 if x is not one of the k c.n. of x i\n",
            "\n",
            "subject to m\n",
            "∑ w\n",
            "\n",
            "j = i, j = 1 for i = 1, 2,⋯, m\n",
            "1\n",
            "\n",
            "--- Chunk 4994 ---\n",
            "After this step, the weight matrix W (containing the weights wi, j) encodes the local\n",
            "\n",
            "--- Chunk 4995 ---\n",
            "linear relationships between the training instances. The second step is to map the\n",
            "\n",
            "--- Chunk 4996 ---\n",
            "training instances into a d-dimensional space (where d < n) while preserving these\n",
            "\n",
            "--- Chunk 4997 ---\n",
            "local relationships as much as possible. If z(i) is the image of x(i) in this d-dimensional\n",
            "\n",
            "--- Chunk 4998 ---\n",
            "LLE | 231\n",
            "\n",
            "\n",
            "\n",
            "space, then we want the squared distance between z(i) and ∑m\n",
            "j = 1 wi, jz\n",
            "\n",
            "--- Chunk 4999 ---\n",
            "j  to be as small\n",
            "as possible. This idea leads to the unconstrained optimization problem described in\n",
            "\n",
            "--- Chunk 5000 ---\n",
            "Equation 8-5. It looks very similar to the first step, but instead of keeping the instan‐\n",
            "\n",
            "--- Chunk 5001 ---\n",
            "ces fixed and finding the optimal weights, we are doing the reverse: keeping the\n",
            "\n",
            "--- Chunk 5002 ---\n",
            "weights fixed and finding the optimal position of the instances’ images in the low-\n",
            "dimensional space. Note that Z is the matrix containing all z(i).\n",
            "\n",
            "--- Chunk 5003 ---\n",
            "Equation 8-5. LLE step two: reducing dimensionality while preserving relationships\n",
            "m m 2\n",
            "\n",
            "Z = argmin ∑ z i − ∑ w z j\n",
            "Z i = 1 j = 1 i, j\n",
            "\n",
            "--- Chunk 5004 ---\n",
            "Scikit-Learn’s LLE implementation has the following computational complexity:\n",
            "\n",
            "--- Chunk 5005 ---\n",
            "O(m log(m)n log(k)) for finding the k nearest neighbors, O(mnk3) for optimizing the\n",
            "\n",
            "--- Chunk 5006 ---\n",
            "weights, and O(dm2) for constructing the low-dimensional representations. Unfortu‐\n",
            "\n",
            "--- Chunk 5007 ---\n",
            "nately, the m2 in the last term makes this algorithm scale poorly to very large datasets.\n",
            "\n",
            "--- Chunk 5008 ---\n",
            "Other Dimensionality Reduction Techniques\n",
            "There are many other dimensionality reduction techniques, several of which are\n",
            "\n",
            "--- Chunk 5009 ---\n",
            "available in Scikit-Learn. Here are some of the most popular ones:\n",
            "Random Projections\n",
            "\n",
            "--- Chunk 5010 ---\n",
            "As its name suggests, projects the data to a lower-dimensional space using a ran‐\n",
            "\n",
            "--- Chunk 5011 ---\n",
            "dom linear projection. This may sound crazy, but it turns out that such a random\n",
            "\n",
            "--- Chunk 5012 ---\n",
            "projection is actually very likely to preserve distances well, as was demonstrated\n",
            "\n",
            "--- Chunk 5013 ---\n",
            "mathematically by William B. Johnson and Joram Lindenstrauss in a famous\n",
            "lemma. The quality of the dimensionality reduction depends on the number of\n",
            "\n",
            "--- Chunk 5014 ---\n",
            "instances and the target dimensionality, but surprisingly not on the initial dimen‐\n",
            "\n",
            "--- Chunk 5015 ---\n",
            "sionality. Check out the documentation for the sklearn.random_projection\n",
            "package for more details.\n",
            "\n",
            "--- Chunk 5016 ---\n",
            "Multidimensional Scaling (MDS)\n",
            "Reduces dimensionality while trying to preserve the distances between the\n",
            "instances.\n",
            "\n",
            "--- Chunk 5017 ---\n",
            "232 | Chapter 8: Dimensionality Reduction\n",
            "\n",
            "--- Chunk 5018 ---\n",
            "Isomap\n",
            "Creates a graph by connecting each instance to its nearest neighbors, then\n",
            "\n",
            "--- Chunk 5019 ---\n",
            "reduces dimensionality while trying to preserve the geodesic distances9 between\n",
            "the instances.\n",
            "\n",
            "--- Chunk 5020 ---\n",
            "t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
            "Reduces dimensionality while trying to keep similar instances close and dissimi‐\n",
            "\n",
            "--- Chunk 5021 ---\n",
            "lar instances apart. It is mostly used for visualization, in particular to visualize\n",
            "\n",
            "--- Chunk 5022 ---\n",
            "clusters of instances in high-dimensional space (e.g., to visualize the MNIST\n",
            "images in 2D).\n",
            "\n",
            "--- Chunk 5023 ---\n",
            "Linear Discriminant Analysis (LDA)\n",
            "Is a classification algorithm, but during training it learns the most discriminative\n",
            "\n",
            "--- Chunk 5024 ---\n",
            "axes between the classes, and these axes can then be used to define a hyperplane\n",
            "\n",
            "--- Chunk 5025 ---\n",
            "onto which to project the data. The benefit of this approach is that the projection\n",
            "\n",
            "--- Chunk 5026 ---\n",
            "will keep classes as far apart as possible, so LDA is a good technique to reduce\n",
            "\n",
            "--- Chunk 5027 ---\n",
            "dimensionality before running another classification algorithm such as an SVM\n",
            "classifier.\n",
            "\n",
            "--- Chunk 5028 ---\n",
            "Figure 8-13 shows the results of a few of these techniques.\n",
            "\n",
            "Figure 8-13. Using various techniques to reduce the Swill roll to 2D\n",
            "\n",
            "--- Chunk 5029 ---\n",
            "Exercises\n",
            "1. What are the main motivations for reducing a dataset’s dimensionality? What are\n",
            "\n",
            "--- Chunk 5030 ---\n",
            "the main drawbacks?\n",
            "2. What is the curse of dimensionality?\n",
            "\n",
            "--- Chunk 5031 ---\n",
            "9 The geodesic distance between two nodes in a graph is the number of nodes on the shortest path between\n",
            "these nodes.\n",
            "\n",
            "Exercises | 233\n",
            "\n",
            "--- Chunk 5032 ---\n",
            "Exercises | 233\n",
            "\n",
            "\n",
            "\n",
            "3. Once a dataset’s dimensionality has been reduced, is it possible to reverse the\n",
            "operation? If so, how? If not, why?\n",
            "\n",
            "--- Chunk 5033 ---\n",
            "4. Can PCA be used to reduce the dimensionality of a highly nonlinear dataset?\n",
            "\n",
            "--- Chunk 5034 ---\n",
            "5. Suppose you perform PCA on a 1,000-dimensional dataset, setting the explained\n",
            "\n",
            "--- Chunk 5035 ---\n",
            "variance ratio to 95%. How many dimensions will the resulting dataset have?\n",
            "\n",
            "--- Chunk 5036 ---\n",
            "6. In what cases would you use vanilla PCA, Incremental PCA, Randomized PCA,\n",
            "\n",
            "--- Chunk 5037 ---\n",
            "or Kernel PCA?\n",
            "7. How can you evaluate the performance of a dimensionality reduction algorithm\n",
            "\n",
            "--- Chunk 5038 ---\n",
            "on your dataset?\n",
            "8. Does it make any sense to chain two different dimensionality reduction algo‐\n",
            "\n",
            "--- Chunk 5039 ---\n",
            "rithms?\n",
            "9. Load the MNIST dataset (introduced in Chapter 3) and split it into a training set\n",
            "\n",
            "--- Chunk 5040 ---\n",
            "and a test set (take the first 60,000 instances for training, and the remaining\n",
            "\n",
            "--- Chunk 5041 ---\n",
            "10,000 for testing). Train a Random Forest classifier on the dataset and time how\n",
            "\n",
            "--- Chunk 5042 ---\n",
            "long it takes, then evaluate the resulting model on the test set. Next, use PCA to\n",
            "\n",
            "--- Chunk 5043 ---\n",
            "reduce the dataset’s dimensionality, with an explained variance ratio of 95%.\n",
            "\n",
            "--- Chunk 5044 ---\n",
            "Train a new Random Forest classifier on the reduced dataset and see how long it\n",
            "\n",
            "--- Chunk 5045 ---\n",
            "takes. Was training much faster? Next, evaluate the classifier on the test set. How\n",
            "does it compare to the previous classifier?\n",
            "\n",
            "--- Chunk 5046 ---\n",
            "10. Use t-SNE to reduce the MNIST dataset down to two dimensions and plot the\n",
            "\n",
            "--- Chunk 5047 ---\n",
            "result using Matplotlib. You can use a scatterplot using 10 different colors to rep‐\n",
            "\n",
            "--- Chunk 5048 ---\n",
            "resent each image’s target class. Alternatively, you can replace each dot in the\n",
            "\n",
            "--- Chunk 5049 ---\n",
            "scatterplot with the corresponding instance’s class (a digit from 0 to 9), or even\n",
            "\n",
            "--- Chunk 5050 ---\n",
            "plot scaled-down versions of the digit images themselves (if you plot all digits,\n",
            "\n",
            "--- Chunk 5051 ---\n",
            "the visualization will be too cluttered, so you should either draw a random sam‐\n",
            "\n",
            "--- Chunk 5052 ---\n",
            "ple or plot an instance only if no other instance has already been plotted at a\n",
            "\n",
            "--- Chunk 5053 ---\n",
            "close distance). You should get a nice visualization with well-separated clusters of\n",
            "\n",
            "--- Chunk 5054 ---\n",
            "digits. Try using other dimensionality reduction algorithms such as PCA, LLE, or\n",
            "MDS and compare the resulting visualizations.\n",
            "\n",
            "--- Chunk 5055 ---\n",
            "Solutions to these exercises are available in Appendix A.\n",
            "\n",
            "234 | Chapter 8: Dimensionality Reduction\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER 9\n",
            "Unsupervised Learning Techniques\n",
            "\n",
            "--- Chunk 5056 ---\n",
            "Although most of the applications of Machine Learning today are based on super‐\n",
            "\n",
            "--- Chunk 5057 ---\n",
            "vised learning (and as a result, this is where most of the investments go to), the vast\n",
            "\n",
            "--- Chunk 5058 ---\n",
            "majority of the available data is unlabeled: we have the input features X, but we do\n",
            "\n",
            "--- Chunk 5059 ---\n",
            "not have the labels y. The computer scientist Yann LeCun famously said that “if intel‐\n",
            "\n",
            "--- Chunk 5060 ---\n",
            "ligence was a cake, unsupervised learning would be the cake, supervised learning\n",
            "\n",
            "--- Chunk 5061 ---\n",
            "would be the icing on the cake, and reinforcement learning would be the cherry on\n",
            "\n",
            "--- Chunk 5062 ---\n",
            "the cake.” In other words, there is a huge potential in unsupervised learning that we\n",
            "have only barely started to sink our teeth into.\n",
            "\n",
            "--- Chunk 5063 ---\n",
            "Say you want to create a system that will take a few pictures of each item on a manu‐\n",
            "\n",
            "--- Chunk 5064 ---\n",
            "facturing production line and detect which items are defective. You can fairly easily\n",
            "\n",
            "--- Chunk 5065 ---\n",
            "create a system that will take pictures automatically, and this might give you thou‐\n",
            "\n",
            "--- Chunk 5066 ---\n",
            "sands of pictures every day. You can then build a reasonably large dataset in just a few\n",
            "\n",
            "--- Chunk 5067 ---\n",
            "weeks. But wait, there are no labels! If you want to train a regular binary classifier that\n",
            "\n",
            "--- Chunk 5068 ---\n",
            "will predict whether an item is defective or not, you will need to label every single\n",
            "\n",
            "--- Chunk 5069 ---\n",
            "picture as “defective” or “normal.” This will generally require human experts to sit\n",
            "\n",
            "--- Chunk 5070 ---\n",
            "down and manually go through all the pictures. This is a long, costly, and tedious\n",
            "\n",
            "--- Chunk 5071 ---\n",
            "task, so it will usually only be done on a small subset of the available pictures. As a\n",
            "\n",
            "--- Chunk 5072 ---\n",
            "result, the labeled dataset will be quite small, and the classifier’s performance will be\n",
            "\n",
            "--- Chunk 5073 ---\n",
            "disappointing. Moreover, every time the company makes any change to its products,\n",
            "\n",
            "--- Chunk 5074 ---\n",
            "the whole process will need to be started over from scratch. Wouldn’t it be great if the\n",
            "\n",
            "--- Chunk 5075 ---\n",
            "algorithm could just exploit the unlabeled data without needing humans to label\n",
            "every picture? Enter unsupervised learning.\n",
            "\n",
            "--- Chunk 5076 ---\n",
            "In Chapter 8 we looked at the most common unsupervised learning task: dimension‐\n",
            "\n",
            "--- Chunk 5077 ---\n",
            "ality reduction. In this chapter we will look at a few more unsupervised learning tasks\n",
            "and algorithms:\n",
            "\n",
            "--- Chunk 5078 ---\n",
            "235\n",
            "\n",
            "--- Chunk 5079 ---\n",
            "Clustering\n",
            "The goal is to group similar instances together into clusters. Clustering is a great\n",
            "\n",
            "--- Chunk 5080 ---\n",
            "tool for data analysis, customer segmentation, recommender systems, search\n",
            "\n",
            "--- Chunk 5081 ---\n",
            "engines, image segmentation, semi-supervised learning, dimensionality reduc‐\n",
            "tion, and more.\n",
            "\n",
            "--- Chunk 5082 ---\n",
            "Anomaly detection\n",
            "The objective is to learn what “normal” data looks like, and then use that to\n",
            "\n",
            "--- Chunk 5083 ---\n",
            "detect abnormal instances, such as defective items on a production line or a new\n",
            "trend in a time series.\n",
            "\n",
            "--- Chunk 5084 ---\n",
            "Density estimation\n",
            "This is the task of estimating the probability density function (PDF) of the random\n",
            "\n",
            "--- Chunk 5085 ---\n",
            "process that generated the dataset. Density estimation is commonly used for\n",
            "\n",
            "--- Chunk 5086 ---\n",
            "anomaly detection: instances located in very low-density regions are likely to be\n",
            "anomalies. It is also useful for data analysis and visualization.\n",
            "\n",
            "--- Chunk 5087 ---\n",
            "Ready for some cake? We will start with clustering, using K-Means and DBSCAN,\n",
            "\n",
            "--- Chunk 5088 ---\n",
            "and then we will discuss Gaussian mixture models and see how they can be used for\n",
            "density estimation, clustering, and anomaly detection.\n",
            "\n",
            "--- Chunk 5089 ---\n",
            "Clustering\n",
            "As you enjoy a hike in the mountains, you stumble upon a plant you have never seen\n",
            "\n",
            "--- Chunk 5090 ---\n",
            "before. You look around and you notice a few more. They are not identical, yet they\n",
            "\n",
            "--- Chunk 5091 ---\n",
            "are sufficiently similar for you to know that they most likely belong to the same spe‐\n",
            "\n",
            "--- Chunk 5092 ---\n",
            "cies (or at least the same genus). You may need a botanist to tell you what species that\n",
            "\n",
            "--- Chunk 5093 ---\n",
            "is, but you certainly don’t need an expert to identify groups of similar-looking objects.\n",
            "\n",
            "--- Chunk 5094 ---\n",
            "This is called clustering: it is the task of identifying similar instances and assigning\n",
            "them to clusters, or groups of similar instances.\n",
            "\n",
            "--- Chunk 5095 ---\n",
            "Just like in classification, each instance gets assigned to a group. However, unlike clas‐\n",
            "\n",
            "--- Chunk 5096 ---\n",
            "sification, clustering is an unsupervised task. Consider Figure 9-1: on the left is the\n",
            "\n",
            "--- Chunk 5097 ---\n",
            "iris dataset (introduced in Chapter 4), where each instance’s species (i.e., its class) is\n",
            "\n",
            "--- Chunk 5098 ---\n",
            "represented with a different marker. It is a labeled dataset, for which classification\n",
            "\n",
            "--- Chunk 5099 ---\n",
            "algorithms such as Logistic Regression, SVMs, or Random Forest classifiers are well\n",
            "\n",
            "--- Chunk 5100 ---\n",
            "suited. On the right is the same dataset, but without the labels, so you cannot use a\n",
            "\n",
            "--- Chunk 5101 ---\n",
            "classification algorithm anymore. This is where clustering algorithms step in: many of\n",
            "\n",
            "--- Chunk 5102 ---\n",
            "them can easily detect the lower-left cluster. It is also quite easy to see with our own\n",
            "\n",
            "--- Chunk 5103 ---\n",
            "eyes, but it is not so obvious that the upper-right cluster is composed of two distinct\n",
            "\n",
            "--- Chunk 5104 ---\n",
            "sub-clusters. That said, the dataset has two additional features (sepal length and\n",
            "\n",
            "--- Chunk 5105 ---\n",
            "width), not represented here, and clustering algorithms can make good use of all fea‐\n",
            "\n",
            "--- Chunk 5106 ---\n",
            "tures, so in fact they identify the three clusters fairly well (e.g., using a Gaussian mix‐\n",
            "\n",
            "--- Chunk 5107 ---\n",
            "ture model, only 5 instances out of 150 are assigned to the wrong cluster).\n",
            "\n",
            "--- Chunk 5108 ---\n",
            "236 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "\n",
            "\n",
            "Figure 9-1. Classification (left) versus clustering (right)\n",
            "\n",
            "--- Chunk 5109 ---\n",
            "Clustering is used in a wide variety of applications, including these:\n",
            "For customer segmentation\n",
            "\n",
            "--- Chunk 5110 ---\n",
            "You can cluster your customers based on their purchases and their activity on\n",
            "\n",
            "--- Chunk 5111 ---\n",
            "your website. This is useful to understand who your customers are and what they\n",
            "\n",
            "--- Chunk 5112 ---\n",
            "need, so you can adapt your products and marketing campaigns to each segment.\n",
            "\n",
            "--- Chunk 5113 ---\n",
            "For example, customer segmentation can be useful in recommender systems to\n",
            "suggest content that other users in the same cluster enjoyed.\n",
            "\n",
            "--- Chunk 5114 ---\n",
            "For data analysis\n",
            "When you analyze a new dataset, it can be helpful to run a clustering algorithm,\n",
            "and then analyze each cluster separately.\n",
            "\n",
            "--- Chunk 5115 ---\n",
            "As a dimensionality reduction technique\n",
            "Once a dataset has been clustered, it is usually possible to measure each instance’s\n",
            "\n",
            "--- Chunk 5116 ---\n",
            "affinity with each cluster (affinity is any measure of how well an instance fits into\n",
            "\n",
            "--- Chunk 5117 ---\n",
            "a cluster). Each instance’s feature vector x can then be replaced with the vector of\n",
            "\n",
            "--- Chunk 5118 ---\n",
            "its cluster affinities. If there are k clusters, then this vector is k-dimensional. This\n",
            "\n",
            "--- Chunk 5119 ---\n",
            "vector is typically much lower-dimensional than the original feature vector, but it\n",
            "can preserve enough information for further processing.\n",
            "\n",
            "--- Chunk 5120 ---\n",
            "For anomaly detection (also called outlier detection)\n",
            "Any instance that has a low affinity to all the clusters is likely to be an anomaly.\n",
            "\n",
            "--- Chunk 5121 ---\n",
            "For example, if you have clustered the users of your website based on their\n",
            "\n",
            "--- Chunk 5122 ---\n",
            "behavior, you can detect users with unusual behavior, such as an unusual number\n",
            "\n",
            "--- Chunk 5123 ---\n",
            "of requests per second. Anomaly detection is particularly useful in detecting\n",
            "defects in manufacturing, or for fraud detection.\n",
            "\n",
            "--- Chunk 5124 ---\n",
            "For semi-supervised learning\n",
            "If you only have a few labels, you could perform clustering and propagate the\n",
            "\n",
            "--- Chunk 5125 ---\n",
            "labels to all the instances in the same cluster. This technique can greatly increase\n",
            "\n",
            "--- Chunk 5126 ---\n",
            "Clustering | 237\n",
            "\n",
            "\n",
            "\n",
            "the number of labels available for a subsequent supervised learning algorithm,\n",
            "and thus improve its performance.\n",
            "\n",
            "--- Chunk 5127 ---\n",
            "For search engines\n",
            "Some search engines let you search for images that are similar to a reference\n",
            "\n",
            "--- Chunk 5128 ---\n",
            "image. To build such a system, you would first apply a clustering algorithm to all\n",
            "\n",
            "--- Chunk 5129 ---\n",
            "the images in your database; similar images would end up in the same cluster.\n",
            "\n",
            "--- Chunk 5130 ---\n",
            "Then when a user provides a reference image, all you need to do is use the\n",
            "\n",
            "--- Chunk 5131 ---\n",
            "trained clustering model to find this image’s cluster, and you can then simply\n",
            "return all the images from this cluster.\n",
            "\n",
            "--- Chunk 5132 ---\n",
            "To segment an image\n",
            "By clustering pixels according to their color, then replacing each pixel’s color\n",
            "\n",
            "--- Chunk 5133 ---\n",
            "with the mean color of its cluster, it is possible to considerably reduce the num‐\n",
            "\n",
            "--- Chunk 5134 ---\n",
            "ber of different colors in the image. Image segmentation is used in many object\n",
            "\n",
            "--- Chunk 5135 ---\n",
            "detection and tracking systems, as it makes it easier to detect the contour of each\n",
            "object.\n",
            "\n",
            "--- Chunk 5136 ---\n",
            "There is no universal definition of what a cluster is: it really depends on the context,\n",
            "\n",
            "--- Chunk 5137 ---\n",
            "and different algorithms will capture different kinds of clusters. Some algorithms\n",
            "\n",
            "--- Chunk 5138 ---\n",
            "look for instances centered around a particular point, called a centroid. Others look\n",
            "\n",
            "--- Chunk 5139 ---\n",
            "for continuous regions of densely packed instances: these clusters can take on any\n",
            "\n",
            "--- Chunk 5140 ---\n",
            "shape. Some algorithms are hierarchical, looking for clusters of clusters. And the list\n",
            "goes on.\n",
            "\n",
            "--- Chunk 5141 ---\n",
            "goes on.\n",
            "In this section, we will look at two popular clustering algorithms, K-Means and\n",
            "\n",
            "--- Chunk 5142 ---\n",
            "DBSCAN, and explore some of their applications, such as nonlinear dimensionality\n",
            "reduction, semi-supervised learning, and anomaly detection.\n",
            "\n",
            "--- Chunk 5143 ---\n",
            "K-Means\n",
            "Consider the unlabeled dataset represented in Figure 9-2: you can clearly see five\n",
            "\n",
            "--- Chunk 5144 ---\n",
            "blobs of instances. The K-Means algorithm is a simple algorithm capable of clustering\n",
            "\n",
            "--- Chunk 5145 ---\n",
            "this kind of dataset very quickly and efficiently, often in just a few iterations. It was\n",
            "\n",
            "--- Chunk 5146 ---\n",
            "proposed by Stuart Lloyd at Bell Labs in 1957 as a technique for pulse-code modula‐\n",
            "\n",
            "--- Chunk 5147 ---\n",
            "tion, but it was only published outside of the company in 1982.1 In 1965, Edward W.\n",
            "\n",
            "--- Chunk 5148 ---\n",
            "Forgy had published virtually the same algorithm, so K-Means is sometimes referred\n",
            "to as Lloyd–Forgy.\n",
            "\n",
            "--- Chunk 5149 ---\n",
            "1 Stuart P. Lloyd, “Least Squares Quantization in PCM,” IEEE Transactions on Information Theory 28, no. 2\n",
            "(1982): 129–137.\n",
            "\n",
            "--- Chunk 5150 ---\n",
            "238 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "\n",
            "\n",
            "Figure 9-2. An unlabeled dataset composed of five blobs of instances\n",
            "\n",
            "--- Chunk 5151 ---\n",
            "Let’s train a K-Means clusterer on this dataset. It will try to find each blob’s center and\n",
            "assign each instance to the closest blob:\n",
            "\n",
            "--- Chunk 5152 ---\n",
            "from sklearn.cluster import KMeans\n",
            "k = 5\n",
            "kmeans = KMeans(n_clusters=k)\n",
            "y_pred = kmeans.fit_predict(X)\n",
            "\n",
            "--- Chunk 5153 ---\n",
            "Note that you have to specify the number of clusters k that the algorithm must find.\n",
            "\n",
            "--- Chunk 5154 ---\n",
            "In this example, it is pretty obvious from looking at the data that k should be set to 5,\n",
            "\n",
            "--- Chunk 5155 ---\n",
            "but in general it is not that easy. We will discuss this shortly.\n",
            "\n",
            "--- Chunk 5156 ---\n",
            "Each instance was assigned to one of the five clusters. In the context of clustering, an\n",
            "\n",
            "--- Chunk 5157 ---\n",
            "instance’s label is the index of the cluster that this instance gets assigned to by the\n",
            "\n",
            "--- Chunk 5158 ---\n",
            "algorithm: this is not to be confused with the class labels in classification (remember\n",
            "\n",
            "--- Chunk 5159 ---\n",
            "that clustering is an unsupervised learning task). The KMeans instance preserves a\n",
            "\n",
            "--- Chunk 5160 ---\n",
            "copy of the labels of the instances it was trained on, available via the labels_ instance\n",
            "variable:\n",
            "\n",
            "--- Chunk 5161 ---\n",
            ">>> y_pred\n",
            "array([4, 0, 1, ..., 2, 1, 0], dtype=int32)\n",
            ">>> y_pred is kmeans.labels_\n",
            "True\n",
            "\n",
            "--- Chunk 5162 ---\n",
            "We can also take a look at the five centroids that the algorithm found:\n",
            ">>> kmeans.cluster_centers_\n",
            "array([[-2.80389616,  1.80117999],\n",
            "\n",
            "--- Chunk 5163 ---\n",
            "[ 0.20876306,  2.25551336],\n",
            "       [-2.79290307,  2.79641063],\n",
            "       [-1.46679593,  2.28585348],\n",
            "       [-2.80037642,  1.30082566]])\n",
            "\n",
            "--- Chunk 5164 ---\n",
            "Clustering | 239\n",
            "\n",
            "--- Chunk 5165 ---\n",
            "You can easily assign new instances to the cluster whose centroid is closest:\n",
            ">>> X_new = np.array([[0, 2], [3, 2], [-3, 3], [-3, 2.5]])\n",
            "\n",
            "--- Chunk 5166 ---\n",
            ">>> kmeans.predict(X_new)\n",
            "array([1, 1, 2, 2], dtype=int32)\n",
            "\n",
            "--- Chunk 5167 ---\n",
            "If you plot the cluster’s decision boundaries, you get a Voronoi tessellation (see\n",
            "Figure 9-3, where each centroid is represented with an X).\n",
            "\n",
            "--- Chunk 5168 ---\n",
            "Figure 9-3. K-Means decision boundaries (Voronoi tessellation)\n",
            "\n",
            "--- Chunk 5169 ---\n",
            "The vast majority of the instances were clearly assigned to the appropriate cluster, but\n",
            "\n",
            "--- Chunk 5170 ---\n",
            "a few instances were probably mislabeled (especially near the boundary between the\n",
            "\n",
            "--- Chunk 5171 ---\n",
            "top-left cluster and the central cluster). Indeed, the K-Means algorithm does not\n",
            "\n",
            "--- Chunk 5172 ---\n",
            "behave very well when the blobs have very different diameters because all it cares\n",
            "\n",
            "--- Chunk 5173 ---\n",
            "about when assigning an instance to a cluster is the distance to the centroid.\n",
            "\n",
            "--- Chunk 5174 ---\n",
            "Instead of assigning each instance to a single cluster, which is called hard clustering, it\n",
            "\n",
            "--- Chunk 5175 ---\n",
            "can be useful to give each instance a score per cluster, which is called soft clustering.\n",
            "\n",
            "--- Chunk 5176 ---\n",
            "The score can be the distance between the instance and the centroid; conversely, it\n",
            "\n",
            "--- Chunk 5177 ---\n",
            "can be a similarity score (or affinity), such as the Gaussian Radial Basis Function\n",
            "\n",
            "--- Chunk 5178 ---\n",
            "(introduced in Chapter 5). In the KMeans class, the transform() method measures\n",
            "the distance from each instance to every centroid:\n",
            "\n",
            "--- Chunk 5179 ---\n",
            ">>> kmeans.transform(X_new)\n",
            "array([[2.81093633, 0.32995317, 2.9042344 , 1.49439034, 2.88633901],\n",
            "\n",
            "--- Chunk 5180 ---\n",
            "[5.80730058, 2.80290755, 5.84739223, 4.4759332 , 5.84236351],\n",
            "       [1.21475352, 3.29399768, 0.29040966, 1.69136631, 1.71086031],\n",
            "\n",
            "--- Chunk 5181 ---\n",
            "[0.72581411, 3.21806371, 0.36159148, 1.54808703, 1.21567622]])\n",
            "\n",
            "--- Chunk 5182 ---\n",
            "In this example, the first instance in X_new is located at a distance of 2.81 from the\n",
            "\n",
            "--- Chunk 5183 ---\n",
            "first centroid, 0.33 from the second centroid, 2.90 from the third centroid, 1.49 from\n",
            "\n",
            "--- Chunk 5184 ---\n",
            "the fourth centroid, and 2.89 from the fifth centroid. If you have a high-dimensional\n",
            "\n",
            "--- Chunk 5185 ---\n",
            "dataset and you transform it this way, you end up with a k-dimensional dataset: this\n",
            "\n",
            "--- Chunk 5186 ---\n",
            "transformation can be a very efficient nonlinear dimensionality reduction technique.\n",
            "\n",
            "--- Chunk 5187 ---\n",
            "240 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "--- Chunk 5188 ---\n",
            "The K-Means algorithm\n",
            "So, how does the algorithm work? Well, suppose you were given the centroids. You\n",
            "\n",
            "--- Chunk 5189 ---\n",
            "could easily label all the instances in the dataset by assigning each of them to the clus‐\n",
            "\n",
            "--- Chunk 5190 ---\n",
            "ter whose centroid is closest. Conversely, if you were given all the instance labels, you\n",
            "\n",
            "--- Chunk 5191 ---\n",
            "could easily locate all the centroids by computing the mean of the instances for each\n",
            "\n",
            "--- Chunk 5192 ---\n",
            "cluster. But you are given neither the labels nor the centroids, so how can you pro‐\n",
            "\n",
            "--- Chunk 5193 ---\n",
            "ceed? Well, just start by placing the centroids randomly (e.g., by picking k instances at\n",
            "\n",
            "--- Chunk 5194 ---\n",
            "random and using their locations as centroids). Then label the instances, update the\n",
            "\n",
            "--- Chunk 5195 ---\n",
            "centroids, label the instances, update the centroids, and so on until the centroids stop\n",
            "\n",
            "--- Chunk 5196 ---\n",
            "moving. The algorithm is guaranteed to converge in a finite number of steps (usually\n",
            "quite small); it will not oscillate forever.2\n",
            "\n",
            "--- Chunk 5197 ---\n",
            "You can see the algorithm in action in Figure 9-4: the centroids are initialized ran‐\n",
            "\n",
            "--- Chunk 5198 ---\n",
            "domly (top left), then the instances are labeled (top right), then the centroids are\n",
            "\n",
            "--- Chunk 5199 ---\n",
            "updated (center left), the instances are relabeled (center right), and so on. As you can\n",
            "\n",
            "--- Chunk 5200 ---\n",
            "see, in just three iterations, the algorithm has reached a clustering that seems close to\n",
            "optimal.\n",
            "\n",
            "--- Chunk 5201 ---\n",
            "The computational complexity of the algorithm is generally linear\n",
            "with regard to the number of instances m, the number of clusters k,\n",
            "\n",
            "--- Chunk 5202 ---\n",
            "and the number of dimensions n. However, this is only true when\n",
            "the data has a clustering structure. If it does not, then in the worst-\n",
            "\n",
            "--- Chunk 5203 ---\n",
            "case scenario the complexity can increase exponentially with the\n",
            "number of instances. In practice, this rarely happens, and K-Means\n",
            "\n",
            "--- Chunk 5204 ---\n",
            "is generally one of the fastest clustering algorithms.\n",
            "\n",
            "--- Chunk 5205 ---\n",
            "2 That’s because the mean squared distance between the instances and their closest centroid can only go down\n",
            "at each step.\n",
            "\n",
            "Clustering | 241\n",
            "\n",
            "--- Chunk 5206 ---\n",
            "Clustering | 241\n",
            "\n",
            "\n",
            "\n",
            "Figure 9-4. The K-Means algorithm\n",
            "\n",
            "--- Chunk 5207 ---\n",
            "Although the algorithm is guaranteed to converge, it may not converge to the right\n",
            "\n",
            "--- Chunk 5208 ---\n",
            "solution (i.e., it may converge to a local optimum): whether it does or not depends on\n",
            "\n",
            "--- Chunk 5209 ---\n",
            "the centroid initialization. Figure 9-5 shows two suboptimal solutions that the algo‐\n",
            "\n",
            "--- Chunk 5210 ---\n",
            "rithm can converge to if you are not lucky with the random initialization step.\n",
            "\n",
            "--- Chunk 5211 ---\n",
            "Figure 9-5. Suboptimal solutions due to unlucky centroid initializations\n",
            "\n",
            "--- Chunk 5212 ---\n",
            "Let’s look at a few ways you can mitigate this risk by improving the centroid\n",
            "initialization.\n",
            "\n",
            "242 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "--- Chunk 5213 ---\n",
            "Centroid initialization methods\n",
            "If you happen to know approximately where the centroids should be (e.g., if you ran\n",
            "\n",
            "--- Chunk 5214 ---\n",
            "another clustering algorithm earlier), then you can set the init hyperparameter to a\n",
            "\n",
            "--- Chunk 5215 ---\n",
            "NumPy array containing the list of centroids, and set n_init to 1:\n",
            "\n",
            "--- Chunk 5216 ---\n",
            "good_init = np.array([[-3, 3], [-3, 2], [-3, 1], [-1, 2], [0, 2]])\n",
            "kmeans = KMeans(n_clusters=5, init=good_init, n_init=1)\n",
            "\n",
            "--- Chunk 5217 ---\n",
            "Another solution is to run the algorithm multiple times with different random initial‐\n",
            "\n",
            "--- Chunk 5218 ---\n",
            "izations and keep the best solution. The number of random initializations is con‐\n",
            "\n",
            "--- Chunk 5219 ---\n",
            "trolled by the n_init hyperparameter: by default, it is equal to 10, which means that\n",
            "\n",
            "--- Chunk 5220 ---\n",
            "the whole algorithm described earlier runs 10 times when you call fit(), and Scikit-\n",
            "\n",
            "--- Chunk 5221 ---\n",
            "Learn keeps the best solution. But how exactly does it know which solution is the\n",
            "\n",
            "--- Chunk 5222 ---\n",
            "best? It uses a performance metric! That metric is called the model’s inertia, which is\n",
            "\n",
            "--- Chunk 5223 ---\n",
            "the mean squared distance between each instance and its closest centroid. It is\n",
            "\n",
            "--- Chunk 5224 ---\n",
            "roughly equal to 223.3 for the model on the left in Figure 9-5, 237.5 for the model on\n",
            "\n",
            "--- Chunk 5225 ---\n",
            "the right in Figure 9-5, and 211.6 for the model in Figure 9-3. The KMeans class runs\n",
            "\n",
            "--- Chunk 5226 ---\n",
            "the algorithm n_init times and keeps the model with the lowest inertia. In this\n",
            "\n",
            "--- Chunk 5227 ---\n",
            "example, the model in Figure 9-3 will be selected (unless we are very unlucky with\n",
            "\n",
            "--- Chunk 5228 ---\n",
            "n_init consecutive random initializations). If you are curious, a model’s inertia is\n",
            "accessible via the inertia_ instance variable:\n",
            "\n",
            "--- Chunk 5229 ---\n",
            ">>> kmeans.inertia_\n",
            "211.59853725816856\n",
            "\n",
            "--- Chunk 5230 ---\n",
            "The score() method returns the negative inertia. Why negative? Because a predic‐\n",
            "\n",
            "--- Chunk 5231 ---\n",
            "tor’s score() method must always respect Scikit-Learn’s “greater is better” rule: if a\n",
            "\n",
            "--- Chunk 5232 ---\n",
            "predictor is better than another, its score() method should return a greater score.\n",
            "\n",
            "--- Chunk 5233 ---\n",
            ">>> kmeans.score(X)\n",
            "-211.59853725816856\n",
            "\n",
            "--- Chunk 5234 ---\n",
            "An important improvement to the K-Means algorithm, K-Means++, was proposed in\n",
            "\n",
            "--- Chunk 5235 ---\n",
            "a 2006 paper by David Arthur and Sergei Vassilvitskii.3 They introduced a smarter\n",
            "\n",
            "--- Chunk 5236 ---\n",
            "initialization step that tends to select centroids that are distant from one another, and\n",
            "\n",
            "--- Chunk 5237 ---\n",
            "this improvement makes the K-Means algorithm much less likely to converge to a\n",
            "\n",
            "--- Chunk 5238 ---\n",
            "suboptimal solution. They showed that the additional computation required for the\n",
            "\n",
            "--- Chunk 5239 ---\n",
            "smarter initialization step is well worth it because it makes it possible to drastically\n",
            "\n",
            "--- Chunk 5240 ---\n",
            "reduce the number of times the algorithm needs to be run to find the optimal solu‐\n",
            "tion. Here is the K-Means++ initialization algorithm:\n",
            "\n",
            "--- Chunk 5241 ---\n",
            "1. Take one centroid c(1), chosen uniformly at random from the dataset.\n",
            "\n",
            "--- Chunk 5242 ---\n",
            "3 David Arthur and Sergei Vassilvitskii, “k-Means++: The Advantages of Careful Seeding,” Proceedings of the\n",
            "\n",
            "--- Chunk 5243 ---\n",
            "18th Annual ACM-SIAM Symposium on Discrete Algorithms (2007): 1027–1035.\n",
            "\n",
            "--- Chunk 5244 ---\n",
            "Clustering | 243\n",
            "\n",
            "\n",
            "\n",
            "2. Take a new centroid c(i), choosing an instance x(i) with probability D � i 2\n",
            " /\n",
            "\n",
            "∑m\n",
            "j = 1 D � j 2\n",
            "\n",
            "--- Chunk 5245 ---\n",
            ", where D(x(i)) is the distance between the instance x(i) and the clos‐\n",
            "\n",
            "--- Chunk 5246 ---\n",
            "est centroid that was already chosen. This probability distribution ensures that\n",
            "\n",
            "--- Chunk 5247 ---\n",
            "instances farther away from already chosen centroids are much more likely be\n",
            "selected as centroids.\n",
            "\n",
            "--- Chunk 5248 ---\n",
            "3. Repeat the previous step until all k centroids have been chosen.\n",
            "\n",
            "--- Chunk 5249 ---\n",
            "The KMeans class uses this initialization method by default. If you want to force it to\n",
            "\n",
            "--- Chunk 5250 ---\n",
            "use the original method (i.e., picking k instances randomly to define the initial cent‐\n",
            "\n",
            "--- Chunk 5251 ---\n",
            "roids), then you can set the init hyperparameter to \"random\". You will rarely need to\n",
            "do this.\n",
            "\n",
            "--- Chunk 5252 ---\n",
            "Accelerated K-Means and mini-batch K-Means\n",
            "Another important improvement to the K-Means algorithm was proposed in a 2003\n",
            "\n",
            "--- Chunk 5253 ---\n",
            "paper by Charles Elkan.4 It considerably accelerates the algorithm by avoiding many\n",
            "\n",
            "--- Chunk 5254 ---\n",
            "unnecessary distance calculations. Elkan achieved this by exploiting the triangle\n",
            "\n",
            "--- Chunk 5255 ---\n",
            "inequality (i.e., that a straight line is always the shortest distance between two points5)\n",
            "\n",
            "--- Chunk 5256 ---\n",
            "and by keeping track of lower and upper bounds for distances between instances and\n",
            "\n",
            "--- Chunk 5257 ---\n",
            "centroids. This is the algorithm the KMeans class uses by default (you can force it to\n",
            "\n",
            "--- Chunk 5258 ---\n",
            "use the original algorithm by setting the algorithm hyperparameter to \"full\",\n",
            "although you probably will never need to).\n",
            "\n",
            "--- Chunk 5259 ---\n",
            "Yet another important variant of the K-Means algorithm was proposed in a 2010\n",
            "\n",
            "--- Chunk 5260 ---\n",
            "paper by David Sculley.6 Instead of using the full dataset at each iteration, the algo‐\n",
            "\n",
            "--- Chunk 5261 ---\n",
            "rithm is capable of using mini-batches, moving the centroids just slightly at each iter‐\n",
            "\n",
            "--- Chunk 5262 ---\n",
            "ation. This speeds up the algorithm typically by a factor of three or four and makes it\n",
            "\n",
            "--- Chunk 5263 ---\n",
            "possible to cluster huge datasets that do not fit in memory. Scikit-Learn implements\n",
            "\n",
            "--- Chunk 5264 ---\n",
            "this algorithm in the MiniBatchKMeans class. You can just use this class like the\n",
            "KMeans class:\n",
            "\n",
            "--- Chunk 5265 ---\n",
            "from sklearn.cluster import MiniBatchKMeans\n",
            "\n",
            "minibatch_kmeans = MiniBatchKMeans(n_clusters=5)\n",
            "minibatch_kmeans.fit(X)\n",
            "\n",
            "--- Chunk 5266 ---\n",
            "4 Charles Elkan, “Using the Triangle Inequality to Accelerate k-Means,” Proceedings of the 20th International\n",
            "\n",
            "--- Chunk 5267 ---\n",
            "Conference on Machine Learning (2003): 147–153.\n",
            "\n",
            "--- Chunk 5268 ---\n",
            "5 The triangle inequality is AC ≤ AB + BC where A, B and C are three points and AB, AC, and BC are the\n",
            "distances between these points.\n",
            "\n",
            "--- Chunk 5269 ---\n",
            "6 David Sculley, “Web-Scale K-Means Clustering,” Proceedings of the 19th International Conference on World\n",
            "Wide Web (2010): 1177–1178.\n",
            "\n",
            "--- Chunk 5270 ---\n",
            "244 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "--- Chunk 5271 ---\n",
            "If the dataset does not fit in memory, the simplest option is to use the memmap class, as\n",
            "\n",
            "--- Chunk 5272 ---\n",
            "we did for incremental PCA in Chapter 8. Alternatively, you can pass one mini-batch\n",
            "\n",
            "--- Chunk 5273 ---\n",
            "at a time to the partial_fit() method, but this will require much more work, since\n",
            "\n",
            "--- Chunk 5274 ---\n",
            "you will need to perform multiple initializations and select the best one yourself (see\n",
            "\n",
            "--- Chunk 5275 ---\n",
            "the mini-batch K-Means section of the notebook for an example).\n",
            "Although the Mini-batch K-Means algorithm is much faster than the regular K-\n",
            "\n",
            "--- Chunk 5276 ---\n",
            "Means algorithm, its inertia is generally slightly worse, especially as the number of\n",
            "\n",
            "--- Chunk 5277 ---\n",
            "clusters increases. You can see this in Figure 9-6: the plot on the left compares the\n",
            "\n",
            "--- Chunk 5278 ---\n",
            "inertias of Mini-batch K-Means and regular K-Means models trained on the previous\n",
            "\n",
            "--- Chunk 5279 ---\n",
            "dataset using various numbers of clusters k. The difference between the two curves\n",
            "\n",
            "--- Chunk 5280 ---\n",
            "remains fairly constant, but this difference becomes more and more significant as k\n",
            "\n",
            "--- Chunk 5281 ---\n",
            "increases, since the inertia becomes smaller and smaller. In the plot on the right, you\n",
            "\n",
            "--- Chunk 5282 ---\n",
            "can see that Mini-batch K-Means is much faster than regular K-Means, and this dif‐\n",
            "ference increases with k.\n",
            "\n",
            "--- Chunk 5283 ---\n",
            "Figure 9-6. Mini-batch K-Means has a higher inertia than K-Means (left) but it is much\n",
            "faster (right), especially as k increases\n",
            "\n",
            "--- Chunk 5284 ---\n",
            "Finding the optimal number of clusters\n",
            "So far, we have set the number of clusters k to 5 because it was obvious by looking at\n",
            "\n",
            "--- Chunk 5285 ---\n",
            "the data that this was the correct number of clusters. But in general, it will not be so\n",
            "\n",
            "--- Chunk 5286 ---\n",
            "easy to know how to set k, and the result might be quite bad if you set it to the wrong\n",
            "\n",
            "--- Chunk 5287 ---\n",
            "value. As you can see in Figure 9-7, setting k to 3 or 8 results in fairly bad models.\n",
            "\n",
            "--- Chunk 5288 ---\n",
            "Clustering | 245\n",
            "\n",
            "--- Chunk 5289 ---\n",
            "Figure 9-7. Bad choices for the number of clusters: when k is too small, separate clusters\n",
            "\n",
            "--- Chunk 5290 ---\n",
            "get merged (left), and when k is too large, some clusters get chopped into multiple pieces\n",
            "(right)\n",
            "\n",
            "--- Chunk 5291 ---\n",
            "You might be thinking that we could just pick the model with the lowest inertia,\n",
            "\n",
            "--- Chunk 5292 ---\n",
            "right? Unfortunately, it is not that simple. The inertia for k=3 is 653.2, which is much\n",
            "\n",
            "--- Chunk 5293 ---\n",
            "higher than for k=5 (which was 211.6). But with k=8, the inertia is just 119.1. The\n",
            "\n",
            "--- Chunk 5294 ---\n",
            "inertia is not a good performance metric when trying to choose k because it keeps\n",
            "\n",
            "--- Chunk 5295 ---\n",
            "getting lower as we increase k. Indeed, the more clusters there are, the closer each\n",
            "\n",
            "--- Chunk 5296 ---\n",
            "instance will be to its closest centroid, and therefore the lower the inertia will be. Let’s\n",
            "plot the inertia as a function of k (see Figure 9-8).\n",
            "\n",
            "--- Chunk 5297 ---\n",
            "Figure 9-8. When plotting the inertia as a function of the number of clusters k, the curve\n",
            "often contains an inflexion point called the “elbow”\n",
            "\n",
            "--- Chunk 5298 ---\n",
            "As you can see, the inertia drops very quickly as we increase k up to 4, but then it\n",
            "\n",
            "--- Chunk 5299 ---\n",
            "decreases much more slowly as we keep increasing k. This curve has roughly the\n",
            "\n",
            "--- Chunk 5300 ---\n",
            "shape of an arm, and there is an “elbow” at k = 4. So, if we did not know better, 4\n",
            "\n",
            "--- Chunk 5301 ---\n",
            "would be a good choice: any lower value would be dramatic, while any higher value\n",
            "\n",
            "--- Chunk 5302 ---\n",
            "would not help much, and we might just be splitting perfectly good clusters in half for\n",
            "no good reason.\n",
            "\n",
            "--- Chunk 5303 ---\n",
            "no good reason.\n",
            "This technique for choosing the best value for the number of clusters is rather coarse.\n",
            "\n",
            "--- Chunk 5304 ---\n",
            "A more precise approach (but also more computationally expensive) is to use the\n",
            "\n",
            "--- Chunk 5305 ---\n",
            "silhouette score, which is the mean silhouette coefficient over all the instances. An\n",
            "\n",
            "--- Chunk 5306 ---\n",
            "246 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "--- Chunk 5307 ---\n",
            "instance’s silhouette coefficient is equal to (b – a) / max(a, b), where a is the mean\n",
            "\n",
            "--- Chunk 5308 ---\n",
            "distance to the other instances in the same cluster (i.e., the mean intra-cluster dis‐\n",
            "\n",
            "--- Chunk 5309 ---\n",
            "tance) and b is the mean nearest-cluster distance (i.e., the mean distance to the\n",
            "\n",
            "--- Chunk 5310 ---\n",
            "instances of the next closest cluster, defined as the one that minimizes b, excluding\n",
            "\n",
            "--- Chunk 5311 ---\n",
            "the instance’s own cluster). The silhouette coefficient can vary between –1 and +1. A\n",
            "\n",
            "--- Chunk 5312 ---\n",
            "coefficient close to +1 means that the instance is well inside its own cluster and far\n",
            "\n",
            "--- Chunk 5313 ---\n",
            "from other clusters, while a coefficient close to 0 means that it is close to a cluster\n",
            "\n",
            "--- Chunk 5314 ---\n",
            "boundary, and finally a coefficient close to –1 means that the instance may have been\n",
            "assigned to the wrong cluster.\n",
            "\n",
            "--- Chunk 5315 ---\n",
            "To compute the silhouette score, you can use Scikit-Learn’s silhouette_score()\n",
            "\n",
            "--- Chunk 5316 ---\n",
            "function, giving it all the instances in the dataset and the labels they were assigned:\n",
            "\n",
            "--- Chunk 5317 ---\n",
            ">>> from sklearn.metrics import silhouette_score\n",
            ">>> silhouette_score(X, kmeans.labels_)\n",
            "0.655517642572828\n",
            "\n",
            "--- Chunk 5318 ---\n",
            "Let’s compare the silhouette scores for different numbers of clusters (see Figure 9-9).\n",
            "\n",
            "--- Chunk 5319 ---\n",
            "Figure 9-9. Selecting the number of clusters k using the silhouette score\n",
            "\n",
            "--- Chunk 5320 ---\n",
            "As you can see, this visualization is much richer than the previous one: although it\n",
            "\n",
            "--- Chunk 5321 ---\n",
            "confirms that k = 4 is a very good choice, it also underlines the fact that k = 5 is quite\n",
            "\n",
            "--- Chunk 5322 ---\n",
            "good as well, and much better than k = 6 or 7. This was not visible when comparing\n",
            "inertias.\n",
            "\n",
            "--- Chunk 5323 ---\n",
            "inertias.\n",
            "An even more informative visualization is obtained when you plot every instance’s\n",
            "\n",
            "--- Chunk 5324 ---\n",
            "silhouette coefficient, sorted by the cluster they are assigned to and by the value of the\n",
            "\n",
            "--- Chunk 5325 ---\n",
            "coefficient. This is called a silhouette diagram (see Figure 9-10). Each diagram con‐\n",
            "\n",
            "--- Chunk 5326 ---\n",
            "tains one knife shape per cluster. The shape’s height indicates the number of instances\n",
            "\n",
            "--- Chunk 5327 ---\n",
            "the cluster contains, and its width represents the sorted silhouette coefficients of the\n",
            "\n",
            "--- Chunk 5328 ---\n",
            "instances in the cluster (wider is better). The dashed line indicates the mean silhou‐\n",
            "ette coefficient.\n",
            "\n",
            "--- Chunk 5329 ---\n",
            "Clustering | 247\n",
            "\n",
            "\n",
            "\n",
            "Figure 9-10. Analyzing the silhouette diagrams for various values of k\n",
            "\n",
            "--- Chunk 5330 ---\n",
            "The vertical dashed lines represent the silhouette score for each number of clusters.\n",
            "\n",
            "--- Chunk 5331 ---\n",
            "When most of the instances in a cluster have a lower coefficient than this score (i.e., if\n",
            "\n",
            "--- Chunk 5332 ---\n",
            "many of the instances stop short of the dashed line, ending to the left of it), then the\n",
            "\n",
            "--- Chunk 5333 ---\n",
            "cluster is rather bad since this means its instances are much too close to other clus‐\n",
            "\n",
            "--- Chunk 5334 ---\n",
            "ters. We can see that when k = 3 and when k = 6, we get bad clusters. But when k = 4\n",
            "\n",
            "--- Chunk 5335 ---\n",
            "or k = 5, the clusters look pretty good: most instances extend beyond the dashed line,\n",
            "\n",
            "--- Chunk 5336 ---\n",
            "to the right and closer to 1.0. When k = 4, the cluster at index 1 (the third from the\n",
            "\n",
            "--- Chunk 5337 ---\n",
            "top) is rather big. When k = 5, all clusters have similar sizes. So, even though the\n",
            "\n",
            "--- Chunk 5338 ---\n",
            "overall silhouette score from k = 4 is slightly greater than for k = 5, it seems like a\n",
            "good idea to use k = 5 to get clusters of similar sizes.\n",
            "\n",
            "--- Chunk 5339 ---\n",
            "Limits of K-Means\n",
            "Despite its many merits, most notably being fast and scalable, K-Means is not perfect.\n",
            "\n",
            "--- Chunk 5340 ---\n",
            "As we saw, it is necessary to run the algorithm several times to avoid suboptimal solu‐\n",
            "\n",
            "--- Chunk 5341 ---\n",
            "tions, plus you need to specify the number of clusters, which can be quite a hassle.\n",
            "\n",
            "--- Chunk 5342 ---\n",
            "Moreover, K-Means does not behave very well when the clusters have varying sizes,\n",
            "\n",
            "--- Chunk 5343 ---\n",
            "248 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "--- Chunk 5344 ---\n",
            "different densities, or nonspherical shapes. For example, Figure 9-11 shows how K-\n",
            "\n",
            "--- Chunk 5345 ---\n",
            "Means clusters a dataset containing three ellipsoidal clusters of different dimensions,\n",
            "densities, and orientations.\n",
            "\n",
            "--- Chunk 5346 ---\n",
            "Figure 9-11. K-Means fails to cluster these ellipsoidal blobs properly\n",
            "\n",
            "--- Chunk 5347 ---\n",
            "As you can see, neither of these solutions is any good. The solution on the left is bet‐\n",
            "\n",
            "--- Chunk 5348 ---\n",
            "ter, but it still chops off 25% of the middle cluster and assigns it to the cluster on the\n",
            "\n",
            "--- Chunk 5349 ---\n",
            "right. The solution on the right is just terrible, even though its inertia is lower. So,\n",
            "\n",
            "--- Chunk 5350 ---\n",
            "depending on the data, different clustering algorithms may perform better. On these\n",
            "types of elliptical clusters, Gaussian mixture models work great.\n",
            "\n",
            "--- Chunk 5351 ---\n",
            "It is important to scale the input features before you run K-Means,\n",
            "or the clusters may be very stretched and K-Means will perform\n",
            "\n",
            "--- Chunk 5352 ---\n",
            "poorly. Scaling the features does not guarantee that all the clusters\n",
            "will be nice and spherical, but it generally improves things.\n",
            "\n",
            "--- Chunk 5353 ---\n",
            "Now let’s look at a few ways we can benefit from clustering. We will use K-Means, but\n",
            "feel free to experiment with other clustering algorithms.\n",
            "\n",
            "--- Chunk 5354 ---\n",
            "Using Clustering for Image Segmentation\n",
            "Image segmentation is the task of partitioning an image into multiple segments. In\n",
            "\n",
            "--- Chunk 5355 ---\n",
            "semantic segmentation, all pixels that are part of the same object type get assigned to\n",
            "\n",
            "--- Chunk 5356 ---\n",
            "the same segment. For example, in a self-driving car’s vision system, all pixels that are\n",
            "\n",
            "--- Chunk 5357 ---\n",
            "part of a pedestrian’s image might be assigned to the “pedestrian” segment (there\n",
            "\n",
            "--- Chunk 5358 ---\n",
            "would be one segment containing all the pedestrians). In instance segmentation, all\n",
            "\n",
            "--- Chunk 5359 ---\n",
            "pixels that are part of the same individual object are assigned to the same segment. In\n",
            "\n",
            "--- Chunk 5360 ---\n",
            "this case there would be a different segment for each pedestrian. The state of the art\n",
            "\n",
            "--- Chunk 5361 ---\n",
            "in semantic or instance segmentation today is achieved using complex architectures\n",
            "\n",
            "--- Chunk 5362 ---\n",
            "based on convolutional neural networks (see Chapter 14). Here, we are going to do\n",
            "\n",
            "--- Chunk 5363 ---\n",
            "something much simpler: color segmentation. We will simply assign pixels to the same\n",
            "\n",
            "--- Chunk 5364 ---\n",
            "segment if they have a similar color. In some applications, this may be sufficient. For\n",
            "\n",
            "--- Chunk 5365 ---\n",
            "Clustering | 249\n",
            "\n",
            "--- Chunk 5366 ---\n",
            "example, if you want to analyze satellite images to measure how much total forest\n",
            "area there is in a region, color segmentation may be just fine.\n",
            "\n",
            "--- Chunk 5367 ---\n",
            "First, use Matplotlib’s imread() function to load the image (see the upper-left image\n",
            "in Figure 9-12):\n",
            "\n",
            "--- Chunk 5368 ---\n",
            ">>> from matplotlib.image import imread  # or `from imageio import imread`\n",
            "\n",
            "--- Chunk 5369 ---\n",
            ">>> image = imread(os.path.join(\"images\",\"unsupervised_learning\",\"ladybug.png\"))\n",
            ">>> image.shape\n",
            "(533, 800, 3)\n",
            "\n",
            "--- Chunk 5370 ---\n",
            "The image is represented as a 3D array. The first dimension’s size is the height; the\n",
            "\n",
            "--- Chunk 5371 ---\n",
            "second is the width; and the third is the number of color channels, in this case red,\n",
            "\n",
            "--- Chunk 5372 ---\n",
            "green, and blue (RGB). In other words, for each pixel there is a 3D vector containing\n",
            "\n",
            "--- Chunk 5373 ---\n",
            "the intensities of red, green, and blue, each between 0.0 and 1.0 (or between 0 and\n",
            "\n",
            "--- Chunk 5374 ---\n",
            "255, if you use imageio.imread()). Some images may have fewer channels, such as\n",
            "\n",
            "--- Chunk 5375 ---\n",
            "grayscale images (one channel). And some images may have more channels, such as\n",
            "\n",
            "--- Chunk 5376 ---\n",
            "images with an additional alpha channel for transparency or satellite images, which\n",
            "\n",
            "--- Chunk 5377 ---\n",
            "often contain channels for many light frequencies (e.g., infrared). The following code\n",
            "\n",
            "--- Chunk 5378 ---\n",
            "reshapes the array to get a long list of RGB colors, then it clusters these colors using\n",
            "K-Means:\n",
            "\n",
            "--- Chunk 5379 ---\n",
            "X = image.reshape(-1, 3)\n",
            "kmeans = KMeans(n_clusters=8).fit(X)\n",
            "segmented_img = kmeans.cluster_centers_[kmeans.labels_]\n",
            "\n",
            "--- Chunk 5380 ---\n",
            "segmented_img = segmented_img.reshape(image.shape)\n",
            "\n",
            "--- Chunk 5381 ---\n",
            "For example, it may identify a color cluster for all shades of green. Next, for each\n",
            "\n",
            "--- Chunk 5382 ---\n",
            "color (e.g., dark green), it looks for the mean color of the pixel’s color cluster. For\n",
            "\n",
            "--- Chunk 5383 ---\n",
            "example, all shades of green may be replaced with the same light green color (assum‐\n",
            "\n",
            "--- Chunk 5384 ---\n",
            "ing the mean color of the green cluster is light green). Finally, it reshapes this long list\n",
            "\n",
            "--- Chunk 5385 ---\n",
            "of colors to get the same shape as the original image. And we’re done!\n",
            "\n",
            "--- Chunk 5386 ---\n",
            "This outputs the image shown in the upper right of Figure 9-12. You can experiment\n",
            "\n",
            "--- Chunk 5387 ---\n",
            "with various numbers of clusters, as shown in the figure. When you use fewer than\n",
            "\n",
            "--- Chunk 5388 ---\n",
            "eight clusters, notice that the ladybug’s flashy red color fails to get a cluster of its own:\n",
            "\n",
            "--- Chunk 5389 ---\n",
            "it gets merged with colors from the environment. This is because K-Means prefers\n",
            "\n",
            "--- Chunk 5390 ---\n",
            "clusters of similar sizes. The ladybug is small—much smaller than the rest of the\n",
            "\n",
            "--- Chunk 5391 ---\n",
            "image—so even though its color is flashy, K-Means fails to dedicate a cluster to it.\n",
            "\n",
            "--- Chunk 5392 ---\n",
            "250 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "\n",
            "\n",
            "Figure 9-12. Image segmentation using K-Means with various numbers of color clusters\n",
            "\n",
            "--- Chunk 5393 ---\n",
            "That wasn’t too hard, was it? Now let’s look at another application of clustering: pre‐\n",
            "processing.\n",
            "\n",
            "--- Chunk 5394 ---\n",
            "Using Clustering for Preprocessing\n",
            "Clustering can be an efficient approach to dimensionality reduction, in particular as a\n",
            "\n",
            "--- Chunk 5395 ---\n",
            "preprocessing step before a supervised learning algorithm. As an example of using\n",
            "\n",
            "--- Chunk 5396 ---\n",
            "clustering for dimensionality reduction, let’s tackle the digits dataset, which is a sim‐\n",
            "\n",
            "--- Chunk 5397 ---\n",
            "ple MNIST-like dataset containing 1,797 grayscale 8 × 8 images representing the dig‐\n",
            "its 0 to 9. First, load the dataset:\n",
            "\n",
            "--- Chunk 5398 ---\n",
            "from sklearn.datasets import load_digits\n",
            "\n",
            "X_digits, y_digits = load_digits(return_X_y=True)\n",
            "\n",
            "--- Chunk 5399 ---\n",
            "Now, split it into a training set and a test set:\n",
            "from sklearn.model_selection import train_test_split\n",
            "\n",
            "--- Chunk 5400 ---\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits)\n",
            "\n",
            "--- Chunk 5401 ---\n",
            "Next, fit a Logistic Regression model:\n",
            "from sklearn.linear_model import LogisticRegression\n",
            "\n",
            "--- Chunk 5402 ---\n",
            "log_reg = LogisticRegression()\n",
            "log_reg.fit(X_train, y_train)\n",
            "\n",
            "--- Chunk 5403 ---\n",
            "Let’s evaluate its accuracy on the test set:\n",
            ">>> log_reg.score(X_test, y_test)\n",
            "0.9688888888888889\n",
            "\n",
            "Clustering | 251\n",
            "\n",
            "--- Chunk 5404 ---\n",
            "OK, that’s our baseline: 96.9% accuracy. Let’s see if we can do better by using K-Means\n",
            "\n",
            "--- Chunk 5405 ---\n",
            "as a preprocessing step. We will create a pipeline that will first cluster the training set\n",
            "\n",
            "--- Chunk 5406 ---\n",
            "into 50 clusters and replace the images with their distances to these 50 clusters, then\n",
            "apply a Logistic Regression model:\n",
            "\n",
            "--- Chunk 5407 ---\n",
            "from sklearn.pipeline import Pipeline\n",
            "\n",
            "--- Chunk 5408 ---\n",
            "pipeline = Pipeline([\n",
            "    (\"kmeans\", KMeans(n_clusters=50)),\n",
            "    (\"log_reg\", LogisticRegression()),\n",
            "])\n",
            "pipeline.fit(X_train, y_train)\n",
            "\n",
            "--- Chunk 5409 ---\n",
            "Since there are 10 different digits, it is tempting to set the number\n",
            "of clusters to 10. However, each digit can be written several differ‐\n",
            "\n",
            "--- Chunk 5410 ---\n",
            "ent ways, so it is preferable to use a larger number of clusters, such\n",
            "as 50.\n",
            "\n",
            "--- Chunk 5411 ---\n",
            "Now let’s evaluate this classification pipeline:\n",
            ">>> pipeline.score(X_test, y_test)\n",
            "0.9777777777777777\n",
            "\n",
            "--- Chunk 5412 ---\n",
            "How about that? We reduced the error rate by almost 30% (from about 3.1% to about\n",
            "2.2%)!\n",
            "\n",
            "--- Chunk 5413 ---\n",
            "2.2%)!\n",
            "But we chose the number of clusters k arbitrarily; we can surely do better. Since K-\n",
            "\n",
            "--- Chunk 5414 ---\n",
            "Means is just a preprocessing step in a classification pipeline, finding a good value for\n",
            "\n",
            "--- Chunk 5415 ---\n",
            "k is much simpler than earlier. There’s no need to perform silhouette analysis or mini‐\n",
            "\n",
            "--- Chunk 5416 ---\n",
            "mize the inertia; the best value of k is simply the one that results in the best classifica‐\n",
            "\n",
            "--- Chunk 5417 ---\n",
            "tion performance during cross-validation. We can use GridSearchCV to find the\n",
            "optimal number of clusters:\n",
            "\n",
            "--- Chunk 5418 ---\n",
            "from sklearn.model_selection import GridSearchCV\n",
            "\n",
            "--- Chunk 5419 ---\n",
            "param_grid = dict(kmeans__n_clusters=range(2, 100))\n",
            "grid_clf = GridSearchCV(pipeline, param_grid, cv=3, verbose=2)\n",
            "grid_clf.fit(X_train, y_train)\n",
            "\n",
            "--- Chunk 5420 ---\n",
            "Let’s look at the best value for k and the performance of the resulting pipeline:\n",
            ">>> grid_clf.best_params_\n",
            "{'kmeans__n_clusters': 99}\n",
            "\n",
            "--- Chunk 5421 ---\n",
            ">>> grid_clf.score(X_test, y_test)\n",
            "0.9822222222222222\n",
            "\n",
            "--- Chunk 5422 ---\n",
            "With k = 99 clusters, we get a significant accuracy boost, reaching 98.22% accuracy\n",
            "\n",
            "--- Chunk 5423 ---\n",
            "on the test set. Cool! You may want to keep exploring higher values for k, since 99\n",
            "was the largest value in the range we explored.\n",
            "\n",
            "--- Chunk 5424 ---\n",
            "252 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "--- Chunk 5425 ---\n",
            "Using Clustering for Semi-Supervised Learning\n",
            "Another use case for clustering is in semi-supervised learning, when we have plenty\n",
            "\n",
            "--- Chunk 5426 ---\n",
            "of unlabeled instances and very few labeled instances. Let’s train a Logistic Regression\n",
            "\n",
            "--- Chunk 5427 ---\n",
            "model on a sample of 50 labeled instances from the digits dataset:\n",
            "\n",
            "--- Chunk 5428 ---\n",
            "n_labeled = 50\n",
            "log_reg = LogisticRegression()\n",
            "log_reg.fit(X_train[:n_labeled], y_train[:n_labeled])\n",
            "\n",
            "--- Chunk 5429 ---\n",
            "What is the performance of this model on the test set?\n",
            ">>> log_reg.score(X_test, y_test)\n",
            "0.8333333333333334\n",
            "\n",
            "--- Chunk 5430 ---\n",
            "The accuracy is just 83.3%. It should come as no surprise that this is much lower than\n",
            "\n",
            "--- Chunk 5431 ---\n",
            "earlier, when we trained the model on the full training set. Let’s see how we can do\n",
            "\n",
            "--- Chunk 5432 ---\n",
            "better. First, let’s cluster the training set into 50 clusters. Then for each cluster, let’s\n",
            "\n",
            "--- Chunk 5433 ---\n",
            "find the image closest to the centroid. We will call these images the representative\n",
            "images:\n",
            "\n",
            "--- Chunk 5434 ---\n",
            "k = 50\n",
            "kmeans = KMeans(n_clusters=k)\n",
            "X_digits_dist = kmeans.fit_transform(X_train)\n",
            "representative_digit_idx = np.argmin(X_digits_dist, axis=0)\n",
            "\n",
            "--- Chunk 5435 ---\n",
            "X_representative_digits = X_train[representative_digit_idx]\n",
            "\n",
            "--- Chunk 5436 ---\n",
            "Figure 9-13 shows these 50 representative images.\n",
            "\n",
            "Figure 9-13. Fifty representative digit images (one per cluster)\n",
            "\n",
            "--- Chunk 5437 ---\n",
            "Let’s look at each image and manually label it:\n",
            "y_representative_digits = np.array([4, 8, 0, 6, 8, 3, ..., 7, 6, 2, 3, 1, 1])\n",
            "\n",
            "--- Chunk 5438 ---\n",
            "Now we have a dataset with just 50 labeled instances, but instead of being random\n",
            "\n",
            "--- Chunk 5439 ---\n",
            "instances, each of them is a representative image of its cluster. Let’s see if the perfor‐\n",
            "mance is any better:\n",
            "\n",
            "--- Chunk 5440 ---\n",
            ">>> log_reg = LogisticRegression()\n",
            ">>> log_reg.fit(X_representative_digits, y_representative_digits)\n",
            ">>> log_reg.score(X_test, y_test)\n",
            "\n",
            "--- Chunk 5441 ---\n",
            "0.9222222222222223\n",
            "\n",
            "--- Chunk 5442 ---\n",
            "Clustering | 253\n",
            "\n",
            "--- Chunk 5443 ---\n",
            "Wow! We jumped from 83.3% accuracy to 92.2%, although we are still only training\n",
            "\n",
            "--- Chunk 5444 ---\n",
            "the model on 50 instances. Since it is often costly and painful to label instances, espe‐\n",
            "\n",
            "--- Chunk 5445 ---\n",
            "cially when it has to be done manually by experts, it is a good idea to label representa‐\n",
            "tive instances rather than just random instances.\n",
            "\n",
            "--- Chunk 5446 ---\n",
            "But perhaps we can go one step further: what if we propagated the labels to all the\n",
            "\n",
            "--- Chunk 5447 ---\n",
            "other instances in the same cluster? This is called label propagation:\n",
            "\n",
            "--- Chunk 5448 ---\n",
            "y_train_propagated = np.empty(len(X_train), dtype=np.int32)\n",
            "for i in range(k):\n",
            "\n",
            "--- Chunk 5449 ---\n",
            "for i in range(k):\n",
            "    y_train_propagated[kmeans.labels_==i] = y_representative_digits[i]\n",
            "\n",
            "--- Chunk 5450 ---\n",
            "Now let’s train the model again and look at its performance:\n",
            ">>> log_reg = LogisticRegression()\n",
            ">>> log_reg.fit(X_train, y_train_propagated)\n",
            "\n",
            "--- Chunk 5451 ---\n",
            ">>> log_reg.score(X_test, y_test)\n",
            "0.9333333333333333\n",
            "\n",
            "--- Chunk 5452 ---\n",
            "We got a reasonable accuracy boost, but nothing absolutely astounding. The problem\n",
            "\n",
            "--- Chunk 5453 ---\n",
            "is that we propagated each representative instance’s label to all the instances in the\n",
            "\n",
            "--- Chunk 5454 ---\n",
            "same cluster, including the instances located close to the cluster boundaries, which\n",
            "\n",
            "--- Chunk 5455 ---\n",
            "are more likely to be mislabeled. Let’s see what happens if we only propagate the\n",
            "\n",
            "--- Chunk 5456 ---\n",
            "labels to the 20% of the instances that are closest to the centroids:\n",
            "\n",
            "--- Chunk 5457 ---\n",
            "percentile_closest = 20\n",
            "\n",
            "--- Chunk 5458 ---\n",
            "X_cluster_dist = X_digits_dist[np.arange(len(X_train)), kmeans.labels_]\n",
            "for i in range(k):\n",
            "    in_cluster = (kmeans.labels_ == i)\n",
            "\n",
            "--- Chunk 5459 ---\n",
            "cluster_dist = X_cluster_dist[in_cluster]\n",
            "    cutoff_distance = np.percentile(cluster_dist, percentile_closest)\n",
            "\n",
            "--- Chunk 5460 ---\n",
            "above_cutoff = (X_cluster_dist > cutoff_distance)\n",
            "    X_cluster_dist[in_cluster & above_cutoff] = -1\n",
            "\n",
            "--- Chunk 5461 ---\n",
            "partially_propagated = (X_cluster_dist != -1)\n",
            "X_train_partially_propagated = X_train[partially_propagated]\n",
            "\n",
            "--- Chunk 5462 ---\n",
            "y_train_partially_propagated = y_train_propagated[partially_propagated]\n",
            "\n",
            "--- Chunk 5463 ---\n",
            "Now let’s train the model again on this partially propagated dataset:\n",
            ">>> log_reg = LogisticRegression()\n",
            "\n",
            "--- Chunk 5464 ---\n",
            ">>> log_reg.fit(X_train_partially_propagated, y_train_partially_propagated)\n",
            ">>> log_reg.score(X_test, y_test)\n",
            "0.94\n",
            "\n",
            "--- Chunk 5465 ---\n",
            "Nice! With just 50 labeled instances (only 5 examples per class on average!), we got\n",
            "\n",
            "--- Chunk 5466 ---\n",
            "94.0% accuracy, which is pretty close to the performance of Logistic Regression on\n",
            "\n",
            "--- Chunk 5467 ---\n",
            "the fully labeled digits dataset (which was 96.9%). This good performance is due to\n",
            "\n",
            "--- Chunk 5468 ---\n",
            "the fact that the propagated labels are actually pretty good—their accuracy is very\n",
            "close to 99%, as the following code shows:\n",
            "\n",
            "--- Chunk 5469 ---\n",
            "254 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "\n",
            "\n",
            ">>> np.mean(y_train_partially_propagated == y_train[partially_propagated])\n",
            "0.9896907216494846\n",
            "\n",
            "--- Chunk 5470 ---\n",
            "Active Learning\n",
            "To continue improving your model and your training set, the next step could be to do\n",
            "\n",
            "--- Chunk 5471 ---\n",
            "a few rounds of active learning, which is when a human expert interacts with the\n",
            "\n",
            "--- Chunk 5472 ---\n",
            "learning algorithm, providing labels for specific instances when the algorithm\n",
            "\n",
            "--- Chunk 5473 ---\n",
            "requests them. There are many different strategies for active learning, but one of the\n",
            "\n",
            "--- Chunk 5474 ---\n",
            "most common ones is called uncertainty sampling. Here is how it works:\n",
            "\n",
            "--- Chunk 5475 ---\n",
            "1. The model is trained on the labeled instances gathered so far, and this model is\n",
            "used to make predictions on all the unlabeled instances.\n",
            "\n",
            "--- Chunk 5476 ---\n",
            "2. The instances for which the model is most uncertain (i.e., when its estimated\n",
            "probability is lowest) are given to the expert to be labeled.\n",
            "\n",
            "--- Chunk 5477 ---\n",
            "3. You iterate this process until the performance improvement stops being worth\n",
            "the labeling effort.\n",
            "\n",
            "--- Chunk 5478 ---\n",
            "Other strategies include labeling the instances that would result in the largest model\n",
            "\n",
            "--- Chunk 5479 ---\n",
            "change, or the largest drop in the model’s validation error, or the instances that differ‐\n",
            "ent models disagree on (e.g., an SVM or a Random Forest).\n",
            "\n",
            "--- Chunk 5480 ---\n",
            "Before we move on to Gaussian mixture models, let’s take a look at DBSCAN,\n",
            "\n",
            "--- Chunk 5481 ---\n",
            "another popular clustering algorithm that illustrates a very different approach based\n",
            "\n",
            "--- Chunk 5482 ---\n",
            "on local density estimation. This approach allows the algorithm to identify clusters of\n",
            "arbitrary shapes.\n",
            "\n",
            "--- Chunk 5483 ---\n",
            "DBSCAN\n",
            "This algorithm defines clusters as continuous regions of high density. Here is how it\n",
            "works:\n",
            "\n",
            "--- Chunk 5484 ---\n",
            "• For each instance, the algorithm counts how many instances are located within a\n",
            "\n",
            "--- Chunk 5485 ---\n",
            "small distance ε (epsilon) from it. This region is called the instance’s ε-\n",
            "neighborhood.\n",
            "\n",
            "--- Chunk 5486 ---\n",
            "• If an instance has at least min_samples instances in its ε-neighborhood (includ‐\n",
            "\n",
            "--- Chunk 5487 ---\n",
            "ing itself), then it is considered a core instance. In other words, core instances are\n",
            "those that are located in dense regions.\n",
            "\n",
            "--- Chunk 5488 ---\n",
            "• All instances in the neighborhood of a core instance belong to the same cluster.\n",
            "\n",
            "--- Chunk 5489 ---\n",
            "This neighborhood may include other core instances; therefore, a long sequence\n",
            "of neighboring core instances forms a single cluster.\n",
            "\n",
            "--- Chunk 5490 ---\n",
            "Clustering | 255\n",
            "\n",
            "\n",
            "\n",
            "• Any instance that is not a core instance and does not have one in its neighbor‐\n",
            "hood is considered an anomaly.\n",
            "\n",
            "--- Chunk 5491 ---\n",
            "This algorithm works well if all the clusters are dense enough and if they are well sep‐\n",
            "\n",
            "--- Chunk 5492 ---\n",
            "arated by low-density regions. The DBSCAN class in Scikit-Learn is as simple to use as\n",
            "\n",
            "--- Chunk 5493 ---\n",
            "you might expect. Let’s test it on the moons dataset, introduced in Chapter 5:\n",
            "\n",
            "--- Chunk 5494 ---\n",
            "from sklearn.cluster import DBSCAN\n",
            "from sklearn.datasets import make_moons\n",
            "\n",
            "--- Chunk 5495 ---\n",
            "X, y = make_moons(n_samples=1000, noise=0.05)\n",
            "dbscan = DBSCAN(eps=0.05, min_samples=5)\n",
            "dbscan.fit(X)\n",
            "\n",
            "--- Chunk 5496 ---\n",
            "The labels of all the instances are now available in the labels_ instance variable:\n",
            ">>> dbscan.labels_\n",
            "\n",
            "--- Chunk 5497 ---\n",
            ">>> dbscan.labels_\n",
            "array([ 0,  2, -1, -1,  1,  0,  0,  0, ...,  3,  2,  3,  3,  4,  2,  6,  3])\n",
            "\n",
            "--- Chunk 5498 ---\n",
            "Notice that some instances have a cluster index equal to –1, which means that they\n",
            "\n",
            "--- Chunk 5499 ---\n",
            "are considered as anomalies by the algorithm. The indices of the core instances are\n",
            "\n",
            "--- Chunk 5500 ---\n",
            "available in the core_sample_indices_ instance variable, and the core instances\n",
            "themselves are available in the components_ instance variable:\n",
            "\n",
            "--- Chunk 5501 ---\n",
            ">>> len(dbscan.core_sample_indices_)\n",
            "808\n",
            ">>> dbscan.core_sample_indices_\n",
            "array([ 0,  4,  5,  6,  7,  8, 10, 11, ..., 992, 993, 995, 997, 998, 999])\n",
            "\n",
            "--- Chunk 5502 ---\n",
            ">>> dbscan.components_\n",
            "array([[-0.02137124,  0.40618608],\n",
            "       [-0.84192557,  0.53058695],\n",
            "                  ...\n",
            "       [-0.94355873,  0.3278936 ],\n",
            "\n",
            "--- Chunk 5503 ---\n",
            "[ 0.79419406,  0.60777171]])\n",
            "\n",
            "--- Chunk 5504 ---\n",
            "This clustering is represented in the lefthand plot of Figure 9-14. As you can see, it\n",
            "\n",
            "--- Chunk 5505 ---\n",
            "identified quite a lot of anomalies, plus seven different clusters. How disappointing!\n",
            "\n",
            "--- Chunk 5506 ---\n",
            "Fortunately, if we widen each instance’s neighborhood by increasing eps to 0.2, we get\n",
            "\n",
            "--- Chunk 5507 ---\n",
            "the clustering on the right, which looks perfect. Let’s continue with this model.\n",
            "\n",
            "--- Chunk 5508 ---\n",
            "256 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "\n",
            "\n",
            "Figure 9-14. DBSCAN clustering using two different neighborhood radiuses\n",
            "\n",
            "--- Chunk 5509 ---\n",
            "Somewhat surprisingly, the DBSCAN class does not have a predict() method, although\n",
            "\n",
            "--- Chunk 5510 ---\n",
            "it has a fit_predict() method. In other words, it cannot predict which cluster a new\n",
            "\n",
            "--- Chunk 5511 ---\n",
            "instance belongs to. This implementation decision was made because different classi‐\n",
            "\n",
            "--- Chunk 5512 ---\n",
            "fication algorithms can be better for different tasks, so the authors decided to let the\n",
            "\n",
            "--- Chunk 5513 ---\n",
            "user choose which one to use. Moreover, it’s not hard to implement. For example, let’s\n",
            "train a KNeighborsClassifier:\n",
            "\n",
            "--- Chunk 5514 ---\n",
            "from sklearn.neighbors import KNeighborsClassifier\n",
            "\n",
            "--- Chunk 5515 ---\n",
            "knn = KNeighborsClassifier(n_neighbors=50)\n",
            "knn.fit(dbscan.components_, dbscan.labels_[dbscan.core_sample_indices_])\n",
            "\n",
            "--- Chunk 5516 ---\n",
            "Now, given a few new instances, we can predict which cluster they most likely belong\n",
            "to and even estimate a probability for each cluster:\n",
            "\n",
            "--- Chunk 5517 ---\n",
            ">>> X_new = np.array([[-0.5, 0], [0, 0.5], [1, -0.1], [2, 1]])\n",
            ">>> knn.predict(X_new)\n",
            "array([1, 0, 1, 0])\n",
            ">>> knn.predict_proba(X_new)\n",
            "\n",
            "--- Chunk 5518 ---\n",
            "array([[0.18, 0.82],\n",
            "       [1.  , 0.  ],\n",
            "       [0.12, 0.88],\n",
            "       [1.  , 0.  ]])\n",
            "\n",
            "--- Chunk 5519 ---\n",
            "Note that we only trained the classifier on the core instances, but we could also have\n",
            "\n",
            "--- Chunk 5520 ---\n",
            "chosen to train it on all the instances, or all but the anomalies: this choice depends on\n",
            "the final task.\n",
            "\n",
            "--- Chunk 5521 ---\n",
            "the final task.\n",
            "The decision boundary is represented in Figure 9-15 (the crosses represent the four\n",
            "\n",
            "--- Chunk 5522 ---\n",
            "instances in X_new). Notice that since there is no anomaly in the training set, the clas‐\n",
            "\n",
            "--- Chunk 5523 ---\n",
            "sifier always chooses a cluster, even when that cluster is far away. It is fairly straight‐\n",
            "\n",
            "--- Chunk 5524 ---\n",
            "forward to introduce a maximum distance, in which case the two instances that are\n",
            "\n",
            "--- Chunk 5525 ---\n",
            "far away from both clusters are classified as anomalies. To do this, use the kneigh\n",
            "\n",
            "--- Chunk 5526 ---\n",
            "bors() method of the KNeighborsClassifier. Given a set of instances, it returns the\n",
            "\n",
            "--- Chunk 5527 ---\n",
            "Clustering | 257\n",
            "\n",
            "\n",
            "\n",
            "distances and the indices of the k nearest neighbors in the training set (two matrices,\n",
            "each with k columns):\n",
            "\n",
            "--- Chunk 5528 ---\n",
            ">>> y_dist, y_pred_idx = knn.kneighbors(X_new, n_neighbors=1)\n",
            ">>> y_pred = dbscan.labels_[dbscan.core_sample_indices_][y_pred_idx]\n",
            "\n",
            "--- Chunk 5529 ---\n",
            ">>> y_pred[y_dist > 0.2] = -1\n",
            ">>> y_pred.ravel()\n",
            "array([-1,  0,  1, -1])\n",
            "\n",
            "--- Chunk 5530 ---\n",
            "Figure 9-15. Decision boundary between two clusters\n",
            "\n",
            "--- Chunk 5531 ---\n",
            "In short, DBSCAN is a very simple yet powerful algorithm capable of identifying any\n",
            "\n",
            "--- Chunk 5532 ---\n",
            "number of clusters of any shape. It is robust to outliers, and it has just two hyperpara‐\n",
            "\n",
            "--- Chunk 5533 ---\n",
            "meters (eps and min_samples). If the density varies significantly across the clusters,\n",
            "\n",
            "--- Chunk 5534 ---\n",
            "however, it can be impossible for it to capture all the clusters properly. Its computa‐\n",
            "\n",
            "--- Chunk 5535 ---\n",
            "tional complexity is roughly O(m log m), making it pretty close to linear with regard\n",
            "\n",
            "--- Chunk 5536 ---\n",
            "to the number of instances, but Scikit-Learn’s implementation can require up to\n",
            "O(m2) memory if eps is large.\n",
            "\n",
            "--- Chunk 5537 ---\n",
            "You may also want to try Hierarchical DBSCAN (HDBSCAN),\n",
            "which is implemented in the scikit-learn-contrib project.\n",
            "\n",
            "--- Chunk 5538 ---\n",
            "Other Clustering Algorithms\n",
            "Scikit-Learn implements several more clustering algorithms that you should take a\n",
            "\n",
            "--- Chunk 5539 ---\n",
            "look at. We cannot cover them all in detail here, but here is a brief overview:\n",
            "Agglomerative clustering\n",
            "\n",
            "--- Chunk 5540 ---\n",
            "A hierarchy of clusters is built from the bottom up. Think of many tiny bubbles\n",
            "\n",
            "--- Chunk 5541 ---\n",
            "floating on water and gradually attaching to each other until there’s one big group\n",
            "\n",
            "--- Chunk 5542 ---\n",
            "of bubbles. Similarly, at each iteration, agglomerative clustering connects the\n",
            "\n",
            "--- Chunk 5543 ---\n",
            "nearest pair of clusters (starting with individual instances). If you drew a tree\n",
            "\n",
            "--- Chunk 5544 ---\n",
            "258 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "--- Chunk 5545 ---\n",
            "with a branch for every pair of clusters that merged, you would get a binary tree\n",
            "\n",
            "--- Chunk 5546 ---\n",
            "of clusters, where the leaves are the individual instances. This approach scales\n",
            "\n",
            "--- Chunk 5547 ---\n",
            "very well to large numbers of instances or clusters. It can capture clusters of vari‐\n",
            "\n",
            "--- Chunk 5548 ---\n",
            "ous shapes, it produces a flexible and informative cluster tree instead of forcing\n",
            "\n",
            "--- Chunk 5549 ---\n",
            "you to choose a particular cluster scale, and it can be used with any pairwise dis‐\n",
            "\n",
            "--- Chunk 5550 ---\n",
            "tance. It can scale nicely to large numbers of instances if you provide a connectiv‐\n",
            "\n",
            "--- Chunk 5551 ---\n",
            "ity matrix, which is a sparse m × m matrix that indicates which pairs of instances\n",
            "\n",
            "--- Chunk 5552 ---\n",
            "are neighbors (e.g., returned by sklearn.neighbors.kneighbors_graph()).\n",
            "\n",
            "--- Chunk 5553 ---\n",
            "Without a connectivity matrix, the algorithm does not scale well to large datasets.\n",
            "\n",
            "--- Chunk 5554 ---\n",
            "BIRCH\n",
            "The BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies)\n",
            "\n",
            "--- Chunk 5555 ---\n",
            "algorithm was designed specifically for very large datasets, and it can be faster\n",
            "\n",
            "--- Chunk 5556 ---\n",
            "than batch K-Means, with similar results, as long as the number of features is not\n",
            "\n",
            "--- Chunk 5557 ---\n",
            "too large (<20). During training, it builds a tree structure containing just enough\n",
            "\n",
            "--- Chunk 5558 ---\n",
            "information to quickly assign each new instance to a cluster, without having to\n",
            "\n",
            "--- Chunk 5559 ---\n",
            "store all the instances in the tree: this approach allows it to use limited memory,\n",
            "while handling huge datasets.\n",
            "\n",
            "--- Chunk 5560 ---\n",
            "Mean-Shift\n",
            "This algorithm starts by placing a circle centered on each instance; then for each\n",
            "\n",
            "--- Chunk 5561 ---\n",
            "circle it computes the mean of all the instances located within it, and it shifts the\n",
            "\n",
            "--- Chunk 5562 ---\n",
            "circle so that it is centered on the mean. Next, it iterates this mean-shifting step\n",
            "\n",
            "--- Chunk 5563 ---\n",
            "until all the circles stop moving (i.e., until each of them is centered on the mean\n",
            "\n",
            "--- Chunk 5564 ---\n",
            "of the instances it contains). Mean-Shift shifts the circles in the direction of\n",
            "\n",
            "--- Chunk 5565 ---\n",
            "higher density, until each of them has found a local density maximum. Finally, all\n",
            "\n",
            "--- Chunk 5566 ---\n",
            "the instances whose circles have settled in the same place (or close enough) are\n",
            "\n",
            "--- Chunk 5567 ---\n",
            "assigned to the same cluster. Mean-Shift has some of the same features as\n",
            "\n",
            "--- Chunk 5568 ---\n",
            "DBSCAN, like how it can find any number of clusters of any shape, it has very\n",
            "\n",
            "--- Chunk 5569 ---\n",
            "few hyperparameters (just one—the radius of the circles, called the bandwidth),\n",
            "\n",
            "--- Chunk 5570 ---\n",
            "and it relies on local density estimation. But unlike DBSCAN, Mean-Shift tends\n",
            "\n",
            "--- Chunk 5571 ---\n",
            "to chop clusters into pieces when they have internal density variations. Unfortu‐\n",
            "\n",
            "--- Chunk 5572 ---\n",
            "nately, its computational complexity is O(m2), so it is not suited for large datasets.\n",
            "\n",
            "--- Chunk 5573 ---\n",
            "Affinity propagation\n",
            "This algorithm uses a voting system, where instances vote for similar instances to\n",
            "\n",
            "--- Chunk 5574 ---\n",
            "be their representatives, and once the algorithm converges, each representative\n",
            "\n",
            "--- Chunk 5575 ---\n",
            "and its voters form a cluster. Affinity propagation can detect any number of clus‐\n",
            "\n",
            "--- Chunk 5576 ---\n",
            "ters of different sizes. Unfortunately, this algorithm has a computational com‐\n",
            "plexity of O(m2), so it too is not suited for large datasets.\n",
            "\n",
            "--- Chunk 5577 ---\n",
            "Spectral clustering\n",
            "This algorithm takes a similarity matrix between the instances and creates a low-\n",
            "\n",
            "--- Chunk 5578 ---\n",
            "dimensional embedding from it (i.e., it reduces its dimensionality), then it uses\n",
            "\n",
            "--- Chunk 5579 ---\n",
            "Clustering | 259\n",
            "\n",
            "--- Chunk 5580 ---\n",
            "another clustering algorithm in this low-dimensional space (Scikit-Learn’s imple‐\n",
            "\n",
            "--- Chunk 5581 ---\n",
            "mentation uses K-Means.) Spectral clustering can capture complex cluster struc‐\n",
            "\n",
            "--- Chunk 5582 ---\n",
            "tures, and it can also be used to cut graphs (e.g., to identify clusters of friends on\n",
            "\n",
            "--- Chunk 5583 ---\n",
            "a social network). It does not scale well to large numbers of instances, and it does\n",
            "not behave well when the clusters have very different sizes.\n",
            "\n",
            "--- Chunk 5584 ---\n",
            "Now let’s dive into Gaussian mixture models, which can be used for density estima‐\n",
            "tion, clustering, and anomaly detection.\n",
            "\n",
            "--- Chunk 5585 ---\n",
            "Gaussian Mixtures\n",
            "A Gaussian mixture model (GMM) is a probabilistic model that assumes that the\n",
            "\n",
            "--- Chunk 5586 ---\n",
            "instances were generated from a mixture of several Gaussian distributions whose\n",
            "\n",
            "--- Chunk 5587 ---\n",
            "parameters are unknown. All the instances generated from a single Gaussian distri‐\n",
            "\n",
            "--- Chunk 5588 ---\n",
            "bution form a cluster that typically looks like an ellipsoid. Each cluster can have a dif‐\n",
            "\n",
            "--- Chunk 5589 ---\n",
            "ferent ellipsoidal shape, size, density, and orientation, just like in Figure 9-11. When\n",
            "\n",
            "--- Chunk 5590 ---\n",
            "you observe an instance, you know it was generated from one of the Gaussian distri‐\n",
            "\n",
            "--- Chunk 5591 ---\n",
            "butions, but you are not told which one, and you do not know what the parameters of\n",
            "these distributions are.\n",
            "\n",
            "--- Chunk 5592 ---\n",
            "There are several GMM variants. In the simplest variant, implemented in the Gaus\n",
            "\n",
            "--- Chunk 5593 ---\n",
            "sianMixture class, you must know in advance the number k of Gaussian distribu‐\n",
            "\n",
            "--- Chunk 5594 ---\n",
            "tions. The dataset X is assumed to have been generated through the following\n",
            "probabilistic process:\n",
            "\n",
            "--- Chunk 5595 ---\n",
            "• For each instance, a cluster is picked randomly from among k clusters. The prob‐\n",
            "\n",
            "--- Chunk 5596 ---\n",
            "ability of choosing the jth cluster is defined by the cluster’s weight, ϕ(j).7 The index\n",
            "of the cluster chosen for the ith instance is noted z(i).\n",
            "\n",
            "--- Chunk 5597 ---\n",
            "• If z(i)=j, meaning the ith instance has been assigned to the jth cluster, the location\n",
            "\n",
            "--- Chunk 5598 ---\n",
            "x(i) of this instance is sampled randomly from the Gaussian distribution with\n",
            "mean μ(j) and covariance matrix Σ(j). This is noted x i ∼ � μ j , Σ j .\n",
            "\n",
            "--- Chunk 5599 ---\n",
            "This generative process can be represented as a graphical model. Figure 9-16 repre‐\n",
            "\n",
            "--- Chunk 5600 ---\n",
            "sents the structure of the conditional dependencies between random variables.\n",
            "\n",
            "--- Chunk 5601 ---\n",
            "7 Phi (ϕ or φ) is the 21st letter of the Greek alphabet.\n",
            "\n",
            "260 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "--- Chunk 5602 ---\n",
            "Figure 9-16. A graphical representation of a Gaussian mixture model, including its\n",
            "\n",
            "--- Chunk 5603 ---\n",
            "parameters (squares), random variables (circles), and their conditional dependencies\n",
            "(solid arrows)\n",
            "\n",
            "--- Chunk 5604 ---\n",
            "Here is how to interpret the figure:8\n",
            "\n",
            "--- Chunk 5605 ---\n",
            "• The circles represent random variables.\n",
            "• The squares represent fixed values (i.e., parameters of the model).\n",
            "\n",
            "--- Chunk 5606 ---\n",
            "• The large rectangles are called plates. They indicate that their content is repeated\n",
            "\n",
            "--- Chunk 5607 ---\n",
            "several times.\n",
            "• The number at the bottom right of each plate indicates how many times its con‐\n",
            "\n",
            "--- Chunk 5608 ---\n",
            "tent is repeated. So, there are m random variables z(i) (from z(1) to z(m)) and m\n",
            "\n",
            "--- Chunk 5609 ---\n",
            "random variables x(i). There are also k means μ(j) and k covariance matrices Σ(j).\n",
            "\n",
            "--- Chunk 5610 ---\n",
            "Lastly, there is just one weight vector ϕ (containing all the weights ϕ(1) to ϕ(k)).\n",
            "\n",
            "--- Chunk 5611 ---\n",
            "• Each variable z(i) is drawn from the categorical distribution with weights ϕ. Each\n",
            "\n",
            "--- Chunk 5612 ---\n",
            "variable x(i) is drawn from the normal distribution, with the mean and covariance\n",
            "matrix defined by its cluster z(i).\n",
            "\n",
            "--- Chunk 5613 ---\n",
            "• The solid arrows represent conditional dependencies. For example, the probabil‐\n",
            "\n",
            "--- Chunk 5614 ---\n",
            "ity distribution for each random variable z(i) depends on the weight vector ϕ.\n",
            "\n",
            "--- Chunk 5615 ---\n",
            "Note that when an arrow crosses a plate boundary, it means that it applies to all\n",
            "\n",
            "--- Chunk 5616 ---\n",
            "the repetitions of that plate. For example, the weight vector ϕ conditions the\n",
            "probability distributions of all the random variables x(1) to x(m).\n",
            "\n",
            "--- Chunk 5617 ---\n",
            "• The squiggly arrow from z(i) to x(i) represents a switch: depending on the value of\n",
            "\n",
            "--- Chunk 5618 ---\n",
            "z(i), the instance x(i) will be sampled from a different Gaussian distribution. For\n",
            "example, if z(i)=j, then x i ∼ � μ j , Σ j .\n",
            "\n",
            "--- Chunk 5619 ---\n",
            "8 Most of these notations are standard, but a few additional notations were taken from the Wikipedia article on\n",
            "plate notation.\n",
            "\n",
            "--- Chunk 5620 ---\n",
            "Gaussian Mixtures | 261\n",
            "\n",
            "--- Chunk 5621 ---\n",
            "• Shaded nodes indicate that the value is known. So, in this case, only the random\n",
            "\n",
            "--- Chunk 5622 ---\n",
            "variables x(i) have known values: they are called observed variables. The unknown\n",
            "random variables z(i) are called latent variables.\n",
            "\n",
            "--- Chunk 5623 ---\n",
            "So, what can you do with such a model? Well, given the dataset X, you typically want\n",
            "\n",
            "--- Chunk 5624 ---\n",
            "to start by estimating the weights ϕ and all the distribution parameters μ(1) to μ(k) and\n",
            "\n",
            "--- Chunk 5625 ---\n",
            "Σ(1) to Σ(k). Scikit-Learn’s GaussianMixture class makes this super easy:\n",
            "\n",
            "--- Chunk 5626 ---\n",
            "from sklearn.mixture import GaussianMixture\n",
            "\n",
            "gm = GaussianMixture(n_components=3, n_init=10)\n",
            "gm.fit(X)\n",
            "\n",
            "--- Chunk 5627 ---\n",
            "Let’s look at the parameters that the algorithm estimated:\n",
            ">>> gm.weights_\n",
            "array([0.20965228, 0.4000662 , 0.39028152])\n",
            ">>> gm.means_\n",
            "\n",
            "--- Chunk 5628 ---\n",
            ">>> gm.means_\n",
            "array([[ 3.39909717,  1.05933727],\n",
            "       [-1.40763984,  1.42710194],\n",
            "       [ 0.05135313,  0.07524095]])\n",
            ">>> gm.covariances_\n",
            "\n",
            "--- Chunk 5629 ---\n",
            ">>> gm.covariances_\n",
            "array([[[ 1.14807234, -0.03270354],\n",
            "        [-0.03270354,  0.95496237]],\n",
            "\n",
            "--- Chunk 5630 ---\n",
            "[[ 0.63478101,  0.72969804],\n",
            "        [ 0.72969804,  1.1609872 ]],\n",
            "\n",
            "       [[ 0.68809572,  0.79608475],\n",
            "        [ 0.79608475,  1.21234145]]])\n",
            "\n",
            "--- Chunk 5631 ---\n",
            "Great, it worked fine! Indeed, the weights that were used to generate the data were\n",
            "\n",
            "--- Chunk 5632 ---\n",
            "0.2, 0.4, and 0.4; and similarly, the means and covariance matrices were very close to\n",
            "\n",
            "--- Chunk 5633 ---\n",
            "those found by the algorithm. But how? This class relies on the Expectation-\n",
            "\n",
            "--- Chunk 5634 ---\n",
            "Maximization (EM) algorithm, which has many similarities with the K-Means algo‐\n",
            "\n",
            "--- Chunk 5635 ---\n",
            "rithm: it also initializes the cluster parameters randomly, then it repeats two steps\n",
            "\n",
            "--- Chunk 5636 ---\n",
            "until convergence, first assigning instances to clusters (this is called the expectation\n",
            "\n",
            "--- Chunk 5637 ---\n",
            "step) and then updating the clusters (this is called the maximization step). Sounds\n",
            "\n",
            "--- Chunk 5638 ---\n",
            "familiar, right? In the context of clustering, you can think of EM as a generalization of\n",
            "\n",
            "--- Chunk 5639 ---\n",
            "K-Means that not only finds the cluster centers (μ(1) to μ(k)), but also their size, shape,\n",
            "\n",
            "--- Chunk 5640 ---\n",
            "and orientation (Σ(1) to Σ(k)), as well as their relative weights (ϕ(1) to ϕ(k)). Unlike K-\n",
            "\n",
            "--- Chunk 5641 ---\n",
            "Means, though, EM uses soft cluster assignments, not hard assignments. For each\n",
            "\n",
            "--- Chunk 5642 ---\n",
            "instance, during the expectation step, the algorithm estimates the probability that it\n",
            "\n",
            "--- Chunk 5643 ---\n",
            "belongs to each cluster (based on the current cluster parameters). Then, during the\n",
            "\n",
            "--- Chunk 5644 ---\n",
            "maximization step, each cluster is updated using all the instances in the dataset, with\n",
            "\n",
            "--- Chunk 5645 ---\n",
            "each instance weighted by the estimated probability that it belongs to that cluster.\n",
            "\n",
            "--- Chunk 5646 ---\n",
            "These probabilities are called the responsibilities of the clusters for the instances.\n",
            "\n",
            "--- Chunk 5647 ---\n",
            "262 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "--- Chunk 5648 ---\n",
            "During the maximization step, each cluster’s update will mostly be impacted by the\n",
            "instances it is most responsible for.\n",
            "\n",
            "--- Chunk 5649 ---\n",
            "Unfortunately, just like K-Means, EM can end up converging to\n",
            "poor solutions, so it needs to be run several times, keeping only the\n",
            "\n",
            "--- Chunk 5650 ---\n",
            "best solution. This is why we set n_init to 10. Be careful: by default\n",
            "n_init is set to 1.\n",
            "\n",
            "--- Chunk 5651 ---\n",
            "You can check whether or not the algorithm converged and how many iterations it\n",
            "took:\n",
            "\n",
            ">>> gm.converged_\n",
            "True\n",
            ">>> gm.n_iter_\n",
            "3\n",
            "\n",
            "--- Chunk 5652 ---\n",
            "Now that you have an estimate of the location, size, shape, orientation, and relative\n",
            "\n",
            "--- Chunk 5653 ---\n",
            "weight of each cluster, the model can easily assign each instance to the most likely\n",
            "\n",
            "--- Chunk 5654 ---\n",
            "cluster (hard clustering) or estimate the probability that it belongs to a particular\n",
            "\n",
            "--- Chunk 5655 ---\n",
            "cluster (soft clustering). Just use the predict() method for hard clustering, or the\n",
            "predict_proba() method for soft clustering:\n",
            "\n",
            "--- Chunk 5656 ---\n",
            ">>> gm.predict(X)\n",
            "array([2, 2, 1, ..., 0, 0, 0])\n",
            ">>> gm.predict_proba(X)\n",
            "array([[2.32389467e-02, 6.77397850e-07, 9.76760376e-01],\n",
            "\n",
            "--- Chunk 5657 ---\n",
            "[1.64685609e-02, 6.75361303e-04, 9.82856078e-01],\n",
            "       [2.01535333e-06, 9.99923053e-01, 7.49319577e-05],\n",
            "       ...,\n",
            "\n",
            "--- Chunk 5658 ---\n",
            "...,\n",
            "       [9.99999571e-01, 2.13946075e-26, 4.28788333e-07],\n",
            "       [1.00000000e+00, 1.46454409e-41, 5.12459171e-16],\n",
            "\n",
            "--- Chunk 5659 ---\n",
            "[1.00000000e+00, 8.02006365e-41, 2.27626238e-15]])\n",
            "\n",
            "--- Chunk 5660 ---\n",
            "A Gaussian mixture model is a generative model, meaning you can sample new\n",
            "instances from it (note that they are ordered by cluster index):\n",
            "\n",
            "--- Chunk 5661 ---\n",
            ">>> X_new, y_new = gm.sample(6)\n",
            ">>> X_new\n",
            "array([[ 2.95400315,  2.63680992],\n",
            "       [-1.16654575,  1.62792705],\n",
            "       [-1.39477712, -1.48511338],\n",
            "\n",
            "--- Chunk 5662 ---\n",
            "[ 0.27221525,  0.690366  ],\n",
            "       [ 0.54095936,  0.48591934],\n",
            "       [ 0.38064009, -0.56240465]])\n",
            "\n",
            "--- Chunk 5663 ---\n",
            ">>> y_new\n",
            "array([0, 1, 2, 2, 2, 2])\n",
            "\n",
            "--- Chunk 5664 ---\n",
            "It is also possible to estimate the density of the model at any given location. This is\n",
            "\n",
            "--- Chunk 5665 ---\n",
            "achieved using the score_samples() method: for each instance it is given, this\n",
            "\n",
            "--- Chunk 5666 ---\n",
            "Gaussian Mixtures | 263\n",
            "\n",
            "--- Chunk 5667 ---\n",
            "method estimates the log of the probability density function (PDF) at that location.\n",
            "The greater the score, the higher the density:\n",
            "\n",
            "--- Chunk 5668 ---\n",
            ">>> gm.score_samples(X)\n",
            "array([-2.60782346, -3.57106041, -3.33003479, ..., -3.51352783,\n",
            "       -4.39802535, -3.80743859])\n",
            "\n",
            "--- Chunk 5669 ---\n",
            "If you compute the exponential of these scores, you get the value of the PDF at the\n",
            "\n",
            "--- Chunk 5670 ---\n",
            "location of the given instances. These are not probabilities, but probability densities:\n",
            "\n",
            "--- Chunk 5671 ---\n",
            "they can take on any positive value, not just a value between 0 and 1. To estimate the\n",
            "\n",
            "--- Chunk 5672 ---\n",
            "probability that an instance will fall within a particular region, you would have to\n",
            "\n",
            "--- Chunk 5673 ---\n",
            "integrate the PDF over that region (if you do so over the entire space of possible\n",
            "instance locations, the result will be 1).\n",
            "\n",
            "--- Chunk 5674 ---\n",
            "Figure 9-17 shows the cluster means, the decision boundaries (dashed lines), and the\n",
            "density contours of this model.\n",
            "\n",
            "--- Chunk 5675 ---\n",
            "Figure 9-17. Cluster means, decision boundaries, and density contours of a trained\n",
            "Gaussian mixture model\n",
            "\n",
            "--- Chunk 5676 ---\n",
            "Nice! The algorithm clearly found an excellent solution. Of course, we made its task\n",
            "\n",
            "--- Chunk 5677 ---\n",
            "easy by generating the data using a set of 2D Gaussian distributions (unfortunately,\n",
            "\n",
            "--- Chunk 5678 ---\n",
            "real-life data is not always so Gaussian and low-dimensional). We also gave the algo‐\n",
            "\n",
            "--- Chunk 5679 ---\n",
            "rithm the correct number of clusters. When there are many dimensions, or many\n",
            "\n",
            "--- Chunk 5680 ---\n",
            "clusters, or few instances, EM can struggle to converge to the optimal solution. You\n",
            "\n",
            "--- Chunk 5681 ---\n",
            "might need to reduce the difficulty of the task by limiting the number of parameters\n",
            "\n",
            "--- Chunk 5682 ---\n",
            "that the algorithm has to learn. One way to do this is to limit the range of shapes and\n",
            "\n",
            "--- Chunk 5683 ---\n",
            "orientations that the clusters can have. This can be achieved by imposing constraints\n",
            "\n",
            "--- Chunk 5684 ---\n",
            "on the covariance matrices. To do this, set the covariance_type hyperparameter to\n",
            "one of the following values:\n",
            "\n",
            "--- Chunk 5685 ---\n",
            "264 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "--- Chunk 5686 ---\n",
            "\"spherical\"\n",
            "All clusters must be spherical, but they can have different diameters (i.e., differ‐\n",
            "ent variances).\n",
            "\n",
            "--- Chunk 5687 ---\n",
            "\"diag\"\n",
            "Clusters can take on any ellipsoidal shape of any size, but the ellipsoid’s axes must\n",
            "\n",
            "--- Chunk 5688 ---\n",
            "be parallel to the coordinate axes (i.e., the covariance matrices must be diagonal).\n",
            "\n",
            "--- Chunk 5689 ---\n",
            "\"tied\"\n",
            "All clusters must have the same ellipsoidal shape, size, and orientation (i.e., all\n",
            "clusters share the same covariance matrix).\n",
            "\n",
            "--- Chunk 5690 ---\n",
            "By default, covariance_type is equal to \"full\", which means that each cluster can\n",
            "\n",
            "--- Chunk 5691 ---\n",
            "take on any shape, size, and orientation (it has its own unconstrained covariance\n",
            "\n",
            "--- Chunk 5692 ---\n",
            "matrix). Figure 9-18 plots the solutions found by the EM algorithm when cova\n",
            "riance_type is set to \"tied\" or \"spherical.”\n",
            "\n",
            "--- Chunk 5693 ---\n",
            "Figure 9-18. Gaussian mixtures for tied clusters (left) and spherical clusters (right)\n",
            "\n",
            "--- Chunk 5694 ---\n",
            "The computational complexity of training a GaussianMixture\n",
            "model depends on the number of instances m, the number of\n",
            "\n",
            "--- Chunk 5695 ---\n",
            "dimensions n, the number of clusters k, and the constraints on the\n",
            "covariance matrices. If covariance_type is \"spherical or \"diag\",\n",
            "\n",
            "--- Chunk 5696 ---\n",
            "it is O(kmn), assuming the data has a clustering structure. If cova\n",
            "riance_type is \"tied\" or \"full\", it is O(kmn2 + kn3), so it will not\n",
            "\n",
            "--- Chunk 5697 ---\n",
            "scale to large numbers of features.\n",
            "\n",
            "--- Chunk 5698 ---\n",
            "Gaussian mixture models can also be used for anomaly detection. Let’s see how.\n",
            "\n",
            "Gaussian Mixtures | 265\n",
            "\n",
            "--- Chunk 5699 ---\n",
            "Anomaly Detection Using Gaussian Mixtures\n",
            "Anomaly detection (also called outlier detection) is the task of detecting instances that\n",
            "\n",
            "--- Chunk 5700 ---\n",
            "deviate strongly from the norm. These instances are called anomalies, or outliers,\n",
            "\n",
            "--- Chunk 5701 ---\n",
            "while the normal instances are called inliers. Anomaly detection is useful in a wide\n",
            "\n",
            "--- Chunk 5702 ---\n",
            "variety of applications, such as fraud detection, detecting defective products in manu‐\n",
            "\n",
            "--- Chunk 5703 ---\n",
            "facturing, or removing outliers from a dataset before training another model (which\n",
            "\n",
            "--- Chunk 5704 ---\n",
            "can significantly improve the performance of the resulting model).\n",
            "Using a Gaussian mixture model for anomaly detection is quite simple: any instance\n",
            "\n",
            "--- Chunk 5705 ---\n",
            "located in a low-density region can be considered an anomaly. You must define what\n",
            "\n",
            "--- Chunk 5706 ---\n",
            "density threshold you want to use. For example, in a manufacturing company that\n",
            "\n",
            "--- Chunk 5707 ---\n",
            "tries to detect defective products, the ratio of defective products is usually well\n",
            "\n",
            "--- Chunk 5708 ---\n",
            "known. Say it is equal to 4%. You then set the density threshold to be the value that\n",
            "\n",
            "--- Chunk 5709 ---\n",
            "results in having 4% of the instances located in areas below that threshold density. If\n",
            "\n",
            "--- Chunk 5710 ---\n",
            "you notice that you get too many false positives (i.e., perfectly good products that are\n",
            "\n",
            "--- Chunk 5711 ---\n",
            "flagged as defective), you can lower the threshold. Conversely, if you have too many\n",
            "\n",
            "--- Chunk 5712 ---\n",
            "false negatives (i.e., defective products that the system does not flag as defective), you\n",
            "\n",
            "--- Chunk 5713 ---\n",
            "can increase the threshold. This is the usual precision/recall trade-off (see Chapter 3).\n",
            "\n",
            "--- Chunk 5714 ---\n",
            "Here is how you would identify the outliers using the fourth percentile lowest density\n",
            "\n",
            "--- Chunk 5715 ---\n",
            "as the threshold (i.e., approximately 4% of the instances will be flagged as anomalies):\n",
            "\n",
            "--- Chunk 5716 ---\n",
            "densities = gm.score_samples(X)\n",
            "density_threshold = np.percentile(densities, 4)\n",
            "anomalies = X[densities < density_threshold]\n",
            "\n",
            "--- Chunk 5717 ---\n",
            "Figure 9-19 represents these anomalies as stars.\n",
            "\n",
            "Figure 9-19. Anomaly detection using a Gaussian mixture model\n",
            "\n",
            "--- Chunk 5718 ---\n",
            "266 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "--- Chunk 5719 ---\n",
            "A closely related task is novelty detection: it differs from anomaly detection in that the\n",
            "\n",
            "--- Chunk 5720 ---\n",
            "algorithm is assumed to be trained on a “clean” dataset, uncontaminated by outliers,\n",
            "\n",
            "--- Chunk 5721 ---\n",
            "whereas anomaly detection does not make this assumption. Indeed, outlier detection\n",
            "is often used to clean up a dataset.\n",
            "\n",
            "--- Chunk 5722 ---\n",
            "Gaussian mixture models try to fit all the data, including the outli‐\n",
            "ers, so if you have too many of them, this will bias the model’s view\n",
            "\n",
            "--- Chunk 5723 ---\n",
            "of “normality,” and some outliers may wrongly be considered as\n",
            "normal. If this happens, you can try to fit the model once, use it to\n",
            "\n",
            "--- Chunk 5724 ---\n",
            "detect and remove the most extreme outliers, then fit the model\n",
            "again on the cleaned-up dataset. Another approach is to use robust\n",
            "\n",
            "--- Chunk 5725 ---\n",
            "covariance estimation methods (see the EllipticEnvelope class).\n",
            "\n",
            "--- Chunk 5726 ---\n",
            "Just like K-Means, the GaussianMixture algorithm requires you to specify the num‐\n",
            "ber of clusters. So, how can you find it?\n",
            "\n",
            "--- Chunk 5727 ---\n",
            "Selecting the Number of Clusters\n",
            "With K-Means, you could use the inertia or the silhouette score to select the appro‐\n",
            "\n",
            "--- Chunk 5728 ---\n",
            "priate number of clusters. But with Gaussian mixtures, it is not possible to use these\n",
            "\n",
            "--- Chunk 5729 ---\n",
            "metrics because they are not reliable when the clusters are not spherical or have dif‐\n",
            "\n",
            "--- Chunk 5730 ---\n",
            "ferent sizes. Instead, you can try to find the model that minimizes a theoretical infor‐\n",
            "\n",
            "--- Chunk 5731 ---\n",
            "mation criterion, such as the Bayesian information criterion (BIC) or the Akaike\n",
            "information criterion (AIC), defined in Equation 9-1.\n",
            "\n",
            "--- Chunk 5732 ---\n",
            "Equation 9-1. Bayesian information criterion (BIC) and Akaike information\n",
            "criterion (AIC)\n",
            "BIC = log m p − 2 log L\n",
            "AIC = 2p − 2 log L\n",
            "\n",
            "--- Chunk 5733 ---\n",
            "In these equations:\n",
            "\n",
            "--- Chunk 5734 ---\n",
            "• m is the number of instances, as always.\n",
            "• p is the number of parameters learned by the model.\n",
            "\n",
            "--- Chunk 5735 ---\n",
            "• L is the maximized value of the likelihood function of the model.\n",
            "\n",
            "--- Chunk 5736 ---\n",
            "Both the BIC and the AIC penalize models that have more parameters to learn (e.g.,\n",
            "\n",
            "--- Chunk 5737 ---\n",
            "more clusters) and reward models that fit the data well. They often end up selecting\n",
            "\n",
            "--- Chunk 5738 ---\n",
            "the same model. When they differ, the model selected by the BIC tends to be simpler\n",
            "\n",
            "--- Chunk 5739 ---\n",
            "Gaussian Mixtures | 267\n",
            "\n",
            "--- Chunk 5740 ---\n",
            "(fewer parameters) than the one selected by the AIC, but tends to not fit the data\n",
            "quite as well (this is especially true for larger datasets).\n",
            "\n",
            "--- Chunk 5741 ---\n",
            "Likelihood Function\n",
            "The terms “probability” and “likelihood” are often used interchangeably in the\n",
            "\n",
            "--- Chunk 5742 ---\n",
            "English language, but they have very different meanings in statistics. Given a statisti‐\n",
            "\n",
            "--- Chunk 5743 ---\n",
            "cal model with some parameters θ, the word “probability” is used to describe how\n",
            "\n",
            "--- Chunk 5744 ---\n",
            "plausible a future outcome x is (knowing the parameter values θ), while the word\n",
            "\n",
            "--- Chunk 5745 ---\n",
            "“likelihood” is used to describe how plausible a particular set of parameter values θ\n",
            "are, after the outcome x is known.\n",
            "\n",
            "--- Chunk 5746 ---\n",
            "Consider a 1D mixture model of two Gaussian distributions centered at –4 and +1.\n",
            "\n",
            "--- Chunk 5747 ---\n",
            "For simplicity, this toy model has a single parameter θ that controls the standard devi‐\n",
            "\n",
            "--- Chunk 5748 ---\n",
            "ations of both distributions. The top-left contour plot in Figure 9-20 shows the entire\n",
            "\n",
            "--- Chunk 5749 ---\n",
            "model f(x; θ) as a function of both x and θ. To estimate the probability distribution of\n",
            "\n",
            "--- Chunk 5750 ---\n",
            "a future outcome x, you need to set the model parameter θ. For example, if you set θ\n",
            "\n",
            "--- Chunk 5751 ---\n",
            "to 1.3 (the horizontal line), you get the probability density function f(x; θ=1.3) shown\n",
            "\n",
            "--- Chunk 5752 ---\n",
            "in the lower-left plot. Say you want to estimate the probability that x will fall between\n",
            "\n",
            "--- Chunk 5753 ---\n",
            "–2 and +2. You must calculate the integral of the PDF on this range (i.e., the surface of\n",
            "\n",
            "--- Chunk 5754 ---\n",
            "the shaded region). But what if you don’t know θ, and instead if you have observed a\n",
            "\n",
            "--- Chunk 5755 ---\n",
            "single instance x=2.5 (the vertical line in the upper-left plot)? In this case, you get the\n",
            "\n",
            "--- Chunk 5756 ---\n",
            "likelihood function ℒ(θ|x=2.5)=f(x=2.5; θ), represented in the upper-right plot.\n",
            "\n",
            "--- Chunk 5757 ---\n",
            "Figure 9-20. A model’s parametric function (top left), and some derived functions: a PDF\n",
            "\n",
            "--- Chunk 5758 ---\n",
            "(lower left), a likelihood function (top right), and a log likelihood function (lower right)\n",
            "\n",
            "--- Chunk 5759 ---\n",
            "268 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "--- Chunk 5760 ---\n",
            "In short, the PDF is a function of x (with θ fixed), while the likelihood function is a\n",
            "\n",
            "--- Chunk 5761 ---\n",
            "function of θ (with x fixed). It is important to understand that the likelihood function\n",
            "\n",
            "--- Chunk 5762 ---\n",
            "is not a probability distribution: if you integrate a probability distribution over all\n",
            "\n",
            "--- Chunk 5763 ---\n",
            "possible values of x, you always get 1; but if you integrate the likelihood function over\n",
            "\n",
            "--- Chunk 5764 ---\n",
            "all possible values of θ, the result can be any positive value.\n",
            "Given a dataset X, a common task is to try to estimate the most likely values for the\n",
            "\n",
            "--- Chunk 5765 ---\n",
            "model parameters. To do this, you must find the values that maximize the likelihood\n",
            "\n",
            "--- Chunk 5766 ---\n",
            "function, given X. In this example, if you have observed a single instance x=2.5, the\n",
            "\n",
            "--- Chunk 5767 ---\n",
            "maximum likelihood estimate (MLE) of θ is θ=1.5. If a prior probability distribution g\n",
            "\n",
            "--- Chunk 5768 ---\n",
            "over θ exists, it is possible to take it into account by maximizing ℒ(θ|x)g(θ) rather\n",
            "\n",
            "--- Chunk 5769 ---\n",
            "than just maximizing ℒ(θ|x). This is called maximum a-posteriori (MAP) estimation.\n",
            "\n",
            "--- Chunk 5770 ---\n",
            "Since MAP constrains the parameter values, you can think of it as a regularized ver‐\n",
            "sion of MLE.\n",
            "\n",
            "--- Chunk 5771 ---\n",
            "sion of MLE.\n",
            "Notice that maximizing the likelihood function is equivalent to maximizing its loga‐\n",
            "\n",
            "--- Chunk 5772 ---\n",
            "rithm (represented in the lower-righthand plot in Figure 9-20). Indeed the logarithm\n",
            "\n",
            "--- Chunk 5773 ---\n",
            "is a strictly increasing function, so if θ maximizes the log likelihood, it also maximizes\n",
            "\n",
            "--- Chunk 5774 ---\n",
            "the likelihood. It turns out that it is generally easier to maximize the log likelihood.\n",
            "\n",
            "--- Chunk 5775 ---\n",
            "For example, if you observed several independent instances x(1) to x(m), you would\n",
            "\n",
            "--- Chunk 5776 ---\n",
            "need to find the value of θ that maximizes the product of the individual likelihood\n",
            "\n",
            "--- Chunk 5777 ---\n",
            "functions. But it is equivalent, and much simpler, to maximize the sum (not the prod‐\n",
            "\n",
            "--- Chunk 5778 ---\n",
            "uct) of the log likelihood functions, thanks to the magic of the logarithm which con‐\n",
            "verts products into sums: log(ab)=log(a)+log(b).\n",
            "\n",
            "--- Chunk 5779 ---\n",
            "Once you have estimated θ , the value of θ that maximizes the likelihood function,\n",
            "\n",
            "--- Chunk 5780 ---\n",
            "then you are ready to compute L = ℒ θ ,� , which is the value used to compute the\n",
            "\n",
            "--- Chunk 5781 ---\n",
            "AIC and BIC; you can think of it as a measure of how well the model fits the data.\n",
            "\n",
            "--- Chunk 5782 ---\n",
            "To compute the BIC and AIC, call the bic() and aic() methods:\n",
            ">>> gm.bic(X)\n",
            "8189.74345832983\n",
            ">>> gm.aic(X)\n",
            "8102.518178214792\n",
            "\n",
            "--- Chunk 5783 ---\n",
            "Figure 9-21 shows the BIC for different numbers of clusters k. As you can see, both\n",
            "\n",
            "--- Chunk 5784 ---\n",
            "the BIC and the AIC are lowest when k=3, so it is most likely the best choice. Note\n",
            "\n",
            "--- Chunk 5785 ---\n",
            "that we could also search for the best value for the covariance_type hyperparameter.\n",
            "\n",
            "--- Chunk 5786 ---\n",
            "For example, if it is \"spherical\" rather than \"full\", then the model has significantly\n",
            "\n",
            "--- Chunk 5787 ---\n",
            "fewer parameters to learn, but it does not fit the data as well.\n",
            "\n",
            "--- Chunk 5788 ---\n",
            "Gaussian Mixtures | 269\n",
            "\n",
            "\n",
            "\n",
            "Figure 9-21. AIC and BIC for different numbers of clusters k\n",
            "\n",
            "--- Chunk 5789 ---\n",
            "Bayesian Gaussian Mixture Models\n",
            "Rather than manually searching for the optimal number of clusters, you can use the\n",
            "\n",
            "--- Chunk 5790 ---\n",
            "BayesianGaussianMixture class, which is capable of giving weights equal (or close)\n",
            "\n",
            "--- Chunk 5791 ---\n",
            "to zero to unnecessary clusters. Set the number of clusters n_components to a value\n",
            "\n",
            "--- Chunk 5792 ---\n",
            "that you have good reason to believe is greater than the optimal number of clusters\n",
            "\n",
            "--- Chunk 5793 ---\n",
            "(this assumes some minimal knowledge about the problem at hand), and the algo‐\n",
            "\n",
            "--- Chunk 5794 ---\n",
            "rithm will eliminate the unnecessary clusters automatically. For example, let’s set the\n",
            "number of clusters to 10 and see what happens:\n",
            "\n",
            "--- Chunk 5795 ---\n",
            ">>> from sklearn.mixture import BayesianGaussianMixture\n",
            ">>> bgm = BayesianGaussianMixture(n_components=10, n_init=10)\n",
            ">>> bgm.fit(X)\n",
            "\n",
            "--- Chunk 5796 ---\n",
            ">>> bgm.fit(X)\n",
            ">>> np.round(bgm.weights_, 2)\n",
            "array([0.4 , 0.21, 0.4 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ])\n",
            "\n",
            "--- Chunk 5797 ---\n",
            "Perfect: the algorithm automatically detected that only three clusters are needed, and\n",
            "\n",
            "--- Chunk 5798 ---\n",
            "the resulting clusters are almost identical to the ones in Figure 9-17.\n",
            "\n",
            "--- Chunk 5799 ---\n",
            "In this model, the cluster parameters (including the weights, means, and covariance\n",
            "\n",
            "--- Chunk 5800 ---\n",
            "matrices) are not treated as fixed model parameters anymore, but as latent random\n",
            "\n",
            "--- Chunk 5801 ---\n",
            "variables, like the cluster assignments (see Figure 9-22). So z now includes both the\n",
            "cluster parameters and the cluster assignments.\n",
            "\n",
            "--- Chunk 5802 ---\n",
            "The Beta distribution is commonly used to model random variables whose values lie\n",
            "\n",
            "--- Chunk 5803 ---\n",
            "within a fixed range. In this case, the range is from 0 to 1. The Stick-Breaking Process\n",
            "\n",
            "--- Chunk 5804 ---\n",
            "(SBP) is best explained through an example: suppose Φ=[0.3, 0.6, 0.5,…], then 30% of\n",
            "\n",
            "--- Chunk 5805 ---\n",
            "the instances will be assigned to cluster 0, then 60% of the remaining instances will be\n",
            "\n",
            "--- Chunk 5806 ---\n",
            "assigned to cluster 1, then 50% of the remaining instances will be assigned to cluster\n",
            "\n",
            "--- Chunk 5807 ---\n",
            "2, and so on. This process is a good model for datasets where new instances are more\n",
            "\n",
            "--- Chunk 5808 ---\n",
            "likely to join large clusters than small clusters (e.g., people are more likely to move to\n",
            "\n",
            "--- Chunk 5809 ---\n",
            "larger cities). If the concentration α is high, then Φ values will likely be close to 0, and\n",
            "\n",
            "--- Chunk 5810 ---\n",
            "the SBP generate many clusters. Conversely, if the concentration is low, then Φ values\n",
            "\n",
            "--- Chunk 5811 ---\n",
            "270 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "--- Chunk 5812 ---\n",
            "will likely be close to 1, and there will be few clusters. Finally, the Wishart distribution\n",
            "\n",
            "--- Chunk 5813 ---\n",
            "is used to sample covariance matrices: the parameters d and V control the distribu‐\n",
            "tion of cluster shapes.\n",
            "\n",
            "--- Chunk 5814 ---\n",
            "Figure 9-22. Bayesian Gaussian mixture model\n",
            "\n",
            "--- Chunk 5815 ---\n",
            "Prior knowledge about the latent variables z can be encoded in a probability distribu‐\n",
            "\n",
            "--- Chunk 5816 ---\n",
            "tion p(z) called the prior. For example, we may have a prior belief that the clusters are\n",
            "\n",
            "--- Chunk 5817 ---\n",
            "likely to be few (low concentration), or conversely, that they are likely to be plentiful\n",
            "\n",
            "--- Chunk 5818 ---\n",
            "(high concentration). This prior belief about the number of clusters can be adjusted\n",
            "\n",
            "--- Chunk 5819 ---\n",
            "using the weight_concentration_prior hyperparameter. Setting it to 0.01 or 10,000\n",
            "\n",
            "--- Chunk 5820 ---\n",
            "gives very different clusterings (see Figure 9-23). The more data we have, however,\n",
            "\n",
            "--- Chunk 5821 ---\n",
            "the less the priors matter. In fact, to plot diagrams with such large differences, you\n",
            "must use very strong priors and little data.\n",
            "\n",
            "--- Chunk 5822 ---\n",
            "Figure 9-23. Using different concentration priors on the same data results in different\n",
            "numbers of clusters\n",
            "\n",
            "Gaussian Mixtures | 271\n",
            "\n",
            "--- Chunk 5823 ---\n",
            "Bayes’ theorem (Equation 9-2) tells us how to update the probability distribution over\n",
            "\n",
            "--- Chunk 5824 ---\n",
            "the latent variables after we observe some data X. It computes the posterior distribu‐\n",
            "\n",
            "--- Chunk 5825 ---\n",
            "tion p(z|X), which is the conditional probability of z given X.\n",
            "\n",
            "--- Chunk 5826 ---\n",
            "Equation 9-2. Bayes’ theorem\n",
            "\n",
            "p z X = posterior = likelihood × prior\n",
            "evidence = p X z p z\n",
            "\n",
            "p X\n",
            "\n",
            "--- Chunk 5827 ---\n",
            "Unfortunately, in a Gaussian mixture model (and many other problems), the denomi‐\n",
            "\n",
            "--- Chunk 5828 ---\n",
            "nator p(x) is intractable, as it requires integrating over all the possible values of z\n",
            "\n",
            "--- Chunk 5829 ---\n",
            "(Equation 9-3), which would require considering all possible combinations of cluster\n",
            "parameters and cluster assignments.\n",
            "\n",
            "--- Chunk 5830 ---\n",
            "Equation 9-3. The evidence p(X) is often intractable\n",
            "\n",
            "p X = ∫p X z p z dz\n",
            "\n",
            "--- Chunk 5831 ---\n",
            "This intractability is one of the central problems in Bayesian statistics, and there are\n",
            "\n",
            "--- Chunk 5832 ---\n",
            "several approaches to solving it. One of them is variational inference, which picks a\n",
            "\n",
            "--- Chunk 5833 ---\n",
            "family of distributions q(z; λ) with its own variational parameters λ (lambda), then\n",
            "\n",
            "--- Chunk 5834 ---\n",
            "optimizes these parameters to make q(z) a good approximation of p(z|X). This is\n",
            "\n",
            "--- Chunk 5835 ---\n",
            "achieved by finding the value of λ that minimizes the KL divergence from q(z) to\n",
            "\n",
            "--- Chunk 5836 ---\n",
            "p(z|X), noted DKL(q‖p). The KL divergence equation is shown in Equation 9-4, and it\n",
            "\n",
            "--- Chunk 5837 ---\n",
            "can be rewritten as the log of the evidence (log p(X)) minus the evidence lower bound\n",
            "\n",
            "--- Chunk 5838 ---\n",
            "(ELBO). Since the log of the evidence does not depend on q, it is a constant term, so\n",
            "minimizing the KL divergence just requires maximizing the ELBO.\n",
            "\n",
            "--- Chunk 5839 ---\n",
            "Equation 9-4. KL divergence from q(z) to p(z|X)\n",
            "\n",
            "DKL q ∥ p = �q log q z\n",
            "p z X\n",
            "\n",
            "= �q log q z − log p z X\n",
            "\n",
            "= �q log q z − log p z, X\n",
            "p X\n",
            "\n",
            "--- Chunk 5840 ---\n",
            "= �q log q z − log p z, X + log p X\n",
            "= �q log q z − �q log p z, X + �q log p X\n",
            "= �q log p X − �q log p z, X − �q log q z\n",
            "= log p X − ELBO\n",
            "\n",
            "--- Chunk 5841 ---\n",
            "where ELBO = �q log p z, X − �q log q z\n",
            "\n",
            "272 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "--- Chunk 5842 ---\n",
            "In practice, there are different techniques to maximize the ELBO. In mean field varia‐\n",
            "\n",
            "--- Chunk 5843 ---\n",
            "tional inference, it is necessary to pick the family of distributions q(z; λ) and the prior\n",
            "\n",
            "--- Chunk 5844 ---\n",
            "p(z) very carefully to ensure that the equation for the ELBO simplifies to a form that\n",
            "\n",
            "--- Chunk 5845 ---\n",
            "can be computed. Unfortunately, there is no general way to do this. Picking the right\n",
            "\n",
            "--- Chunk 5846 ---\n",
            "family of distributions and the right prior depends on the task and requires some\n",
            "\n",
            "--- Chunk 5847 ---\n",
            "mathematical skills. For example, the distributions and lower-bound equations used\n",
            "\n",
            "--- Chunk 5848 ---\n",
            "in Scikit-Learn’s BayesianGaussianMixture class are presented in the documenta‐\n",
            "\n",
            "--- Chunk 5849 ---\n",
            "tion. From these equations it is possible to derive update equations for the cluster\n",
            "\n",
            "--- Chunk 5850 ---\n",
            "parameters and assignment variables: these are then used very much like in the\n",
            "\n",
            "--- Chunk 5851 ---\n",
            "Expectation-Maximization algorithm. In fact, the computational complexity of the\n",
            "\n",
            "--- Chunk 5852 ---\n",
            "BayesianGaussianMixture class is similar to that of the GaussianMixture class (but\n",
            "\n",
            "--- Chunk 5853 ---\n",
            "generally significantly slower). A simpler approach to maximizing the ELBO is called\n",
            "\n",
            "--- Chunk 5854 ---\n",
            "black box stochastic variational inference (BBSVI): at each iteration, a few samples are\n",
            "\n",
            "--- Chunk 5855 ---\n",
            "drawn from q, and they are used to estimate the gradients of the ELBO with regard to\n",
            "\n",
            "--- Chunk 5856 ---\n",
            "the variational parameters λ, which are then used in a gradient ascent step. This\n",
            "\n",
            "--- Chunk 5857 ---\n",
            "approach makes it possible to use Bayesian inference with any kind of model (pro‐\n",
            "\n",
            "--- Chunk 5858 ---\n",
            "vided it is differentiable), even deep neural networks; using Bayesian inference with\n",
            "deep neural networks is called Bayesian Deep Learning.\n",
            "\n",
            "--- Chunk 5859 ---\n",
            "If you want to dive deeper into Bayesian statistics, check out the\n",
            "book Bayesian Data Analysis by Andrew Gelman et al. (Chapman\n",
            "& Hall).\n",
            "\n",
            "--- Chunk 5860 ---\n",
            "Gaussian mixture models work great on clusters with ellipsoidal shapes, but if you try\n",
            "\n",
            "--- Chunk 5861 ---\n",
            "to fit a dataset with different shapes, you may have bad surprises. For example, let’s\n",
            "\n",
            "--- Chunk 5862 ---\n",
            "see what happens if we use a Bayesian Gaussian mixture model to cluster the moons\n",
            "dataset (see Figure 9-24).\n",
            "\n",
            "--- Chunk 5863 ---\n",
            "Figure 9-24. Fitting a Gaussian mixture to nonellipsoidal clusters\n",
            "\n",
            "Gaussian Mixtures | 273\n",
            "\n",
            "--- Chunk 5864 ---\n",
            "Oops! The algorithm desperately searched for ellipsoids, so it found eight different\n",
            "\n",
            "--- Chunk 5865 ---\n",
            "clusters instead of two. The density estimation is not too bad, so this model could\n",
            "\n",
            "--- Chunk 5866 ---\n",
            "perhaps be used for anomaly detection, but it failed to identify the two moons. Let’s\n",
            "\n",
            "--- Chunk 5867 ---\n",
            "now look at a few clustering algorithms capable of dealing with arbitrarily shaped\n",
            "clusters.\n",
            "\n",
            "--- Chunk 5868 ---\n",
            "Other Algorithms for Anomaly and Novelty Detection\n",
            "Scikit-Learn implements other algorithms dedicated to anomaly detection or novelty\n",
            "detection:\n",
            "\n",
            "--- Chunk 5869 ---\n",
            "detection:\n",
            "PCA (and other dimensionality reduction techniques with an inverse_transform()\n",
            "method)\n",
            "\n",
            "--- Chunk 5870 ---\n",
            "If you compare the reconstruction error of a normal instance with the recon‐\n",
            "\n",
            "--- Chunk 5871 ---\n",
            "struction error of an anomaly, the latter will usually be much larger. This is a sim‐\n",
            "\n",
            "--- Chunk 5872 ---\n",
            "ple and often quite efficient anomaly detection approach (see this chapter’s\n",
            "exercises for an application of this approach).\n",
            "\n",
            "--- Chunk 5873 ---\n",
            "Fast-MCD (minimum covariance determinant)\n",
            "Implemented by the EllipticEnvelope class, this algorithm is useful for outlier\n",
            "\n",
            "--- Chunk 5874 ---\n",
            "detection, in particular to clean up a dataset. It assumes that the normal instances\n",
            "\n",
            "--- Chunk 5875 ---\n",
            "(inliers) are generated from a single Gaussian distribution (not a mixture). It also\n",
            "\n",
            "--- Chunk 5876 ---\n",
            "assumes that the dataset is contaminated with outliers that were not generated\n",
            "\n",
            "--- Chunk 5877 ---\n",
            "from this Gaussian distribution. When the algorithm estimates the parameters of\n",
            "\n",
            "--- Chunk 5878 ---\n",
            "the Gaussian distribution (i.e., the shape of the elliptic envelope around the inli‐\n",
            "\n",
            "--- Chunk 5879 ---\n",
            "ers), it is careful to ignore the instances that are most likely outliers. This techni‐\n",
            "\n",
            "--- Chunk 5880 ---\n",
            "que gives a better estimation of the elliptic envelope and thus makes the\n",
            "algorithm better at identifying the outliers.\n",
            "\n",
            "--- Chunk 5881 ---\n",
            "Isolation Forest\n",
            "This is an efficient algorithm for outlier detection, especially in high-dimensional\n",
            "\n",
            "--- Chunk 5882 ---\n",
            "datasets. The algorithm builds a Random Forest in which each Decision Tree is\n",
            "\n",
            "--- Chunk 5883 ---\n",
            "grown randomly: at each node, it picks a feature randomly, then it picks a ran‐\n",
            "\n",
            "--- Chunk 5884 ---\n",
            "dom threshold value (between the min and max values) to split the dataset in\n",
            "\n",
            "--- Chunk 5885 ---\n",
            "two. The dataset gradually gets chopped into pieces this way, until all instances\n",
            "\n",
            "--- Chunk 5886 ---\n",
            "end up isolated from the other instances. Anomalies are usually far from other\n",
            "\n",
            "--- Chunk 5887 ---\n",
            "instances, so on average (across all the Decision Trees) they tend to get isolated in\n",
            "fewer steps than normal instances.\n",
            "\n",
            "--- Chunk 5888 ---\n",
            "Local Outlier Factor (LOF)\n",
            "This algorithm is also good for outlier detection. It compares the density of\n",
            "\n",
            "--- Chunk 5889 ---\n",
            "instances around a given instance to the density around its neighbors. An anom‐\n",
            "aly is often more isolated than its k nearest neighbors.\n",
            "\n",
            "--- Chunk 5890 ---\n",
            "274 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "--- Chunk 5891 ---\n",
            "One-class SVM\n",
            "This algorithm is better suited for novelty detection. Recall that a kernelized\n",
            "\n",
            "--- Chunk 5892 ---\n",
            "SVM classifier separates two classes by first (implicitly) mapping all the instances\n",
            "\n",
            "--- Chunk 5893 ---\n",
            "to a high-dimensional space, then separating the two classes using a linear SVM\n",
            "\n",
            "--- Chunk 5894 ---\n",
            "classifier within this high-dimensional space (see Chapter 5). Since we just have\n",
            "\n",
            "--- Chunk 5895 ---\n",
            "one class of instances, the one-class SVM algorithm instead tries to separate the\n",
            "\n",
            "--- Chunk 5896 ---\n",
            "instances in high-dimensional space from the origin. In the original space, this\n",
            "\n",
            "--- Chunk 5897 ---\n",
            "will correspond to finding a small region that encompasses all the instances. If a\n",
            "\n",
            "--- Chunk 5898 ---\n",
            "new instance does not fall within this region, it is an anomaly. There are a few\n",
            "\n",
            "--- Chunk 5899 ---\n",
            "hyperparameters to tweak: the usual ones for a kernelized SVM, plus a margin\n",
            "\n",
            "--- Chunk 5900 ---\n",
            "hyperparameter that corresponds to the probability of a new instance being mis‐\n",
            "\n",
            "--- Chunk 5901 ---\n",
            "takenly considered as novel when it is in fact normal. It works great, especially\n",
            "\n",
            "--- Chunk 5902 ---\n",
            "with high-dimensional datasets, but like all SVMs it does not scale to large\n",
            "datasets.\n",
            "\n",
            "--- Chunk 5903 ---\n",
            "Exercises\n",
            "1. How would you define clustering? Can you name a few clustering algorithms?\n",
            "\n",
            "--- Chunk 5904 ---\n",
            "2. What are some of the main applications of clustering algorithms?\n",
            "3. Describe two techniques to select the right number of clusters when using\n",
            "\n",
            "--- Chunk 5905 ---\n",
            "K-Means.\n",
            "4. What is label propagation? Why would you implement it, and how?\n",
            "\n",
            "--- Chunk 5906 ---\n",
            "5. Can you name two clustering algorithms that can scale to large datasets? And\n",
            "\n",
            "--- Chunk 5907 ---\n",
            "two that look for regions of high density?\n",
            "6. Can you think of a use case where active learning would be useful? How would\n",
            "\n",
            "--- Chunk 5908 ---\n",
            "you implement it?\n",
            "7. What is the difference between anomaly detection and novelty detection?\n",
            "\n",
            "--- Chunk 5909 ---\n",
            "8. What is a Gaussian mixture? What tasks can you use it for?\n",
            "9. Can you name two techniques to find the right number of clusters when using a\n",
            "\n",
            "--- Chunk 5910 ---\n",
            "Gaussian mixture model?\n",
            "10. The classic Olivetti faces dataset contains 400 grayscale 64 × 64–pixel images of\n",
            "\n",
            "--- Chunk 5911 ---\n",
            "faces. Each image is flattened to a 1D vector of size 4,096. 40 different people\n",
            "\n",
            "--- Chunk 5912 ---\n",
            "were photographed (10 times each), and the usual task is to train a model that\n",
            "\n",
            "--- Chunk 5913 ---\n",
            "can predict which person is represented in each picture. Load the dataset using\n",
            "\n",
            "--- Chunk 5914 ---\n",
            "the sklearn.datasets.fetch_olivetti_faces() function, then split it into a\n",
            "\n",
            "--- Chunk 5915 ---\n",
            "training set, a validation set, and a test set (note that the dataset is already scaled\n",
            "\n",
            "--- Chunk 5916 ---\n",
            "between 0 and 1). Since the dataset is quite small, you probably want to use strati‐\n",
            "\n",
            "--- Chunk 5917 ---\n",
            "fied sampling to ensure that there are the same number of images per person in\n",
            "\n",
            "--- Chunk 5918 ---\n",
            "each set. Next, cluster the images using K-Means, and ensure that you have a\n",
            "\n",
            "--- Chunk 5919 ---\n",
            "Exercises | 275\n",
            "\n",
            "--- Chunk 5920 ---\n",
            "good number of clusters (using one of the techniques discussed in this chapter).\n",
            "Visualize the clusters: do you see similar faces in each cluster?\n",
            "\n",
            "--- Chunk 5921 ---\n",
            "11. Continuing with the Olivetti faces dataset, train a classifier to predict which per‐\n",
            "\n",
            "--- Chunk 5922 ---\n",
            "son is represented in each picture, and evaluate it on the validation set. Next, use\n",
            "\n",
            "--- Chunk 5923 ---\n",
            "K-Means as a dimensionality reduction tool, and train a classifier on the reduced\n",
            "\n",
            "--- Chunk 5924 ---\n",
            "set. Search for the number of clusters that allows the classifier to get the best per‐\n",
            "\n",
            "--- Chunk 5925 ---\n",
            "formance: what performance can you reach? What if you append the features\n",
            "\n",
            "--- Chunk 5926 ---\n",
            "from the reduced set to the original features (again, searching for the best num‐\n",
            "ber of clusters)?\n",
            "\n",
            "--- Chunk 5927 ---\n",
            "12. Train a Gaussian mixture model on the Olivetti faces dataset. To speed up the\n",
            "\n",
            "--- Chunk 5928 ---\n",
            "algorithm, you should probably reduce the dataset’s dimensionality (e.g., use\n",
            "\n",
            "--- Chunk 5929 ---\n",
            "PCA, preserving 99% of the variance). Use the model to generate some new faces\n",
            "\n",
            "--- Chunk 5930 ---\n",
            "(using the sample() method), and visualize them (if you used PCA, you will need\n",
            "\n",
            "--- Chunk 5931 ---\n",
            "to use its inverse_transform() method). Try to modify some images (e.g.,\n",
            "\n",
            "--- Chunk 5932 ---\n",
            "rotate, flip, darken) and see if the model can detect the anomalies (i.e., compare\n",
            "\n",
            "--- Chunk 5933 ---\n",
            "the output of the score_samples() method for normal images and for anoma‐\n",
            "lies).\n",
            "\n",
            "--- Chunk 5934 ---\n",
            "13. Some dimensionality reduction techniques can also be used for anomaly detec‐\n",
            "\n",
            "--- Chunk 5935 ---\n",
            "tion. For example, take the Olivetti faces dataset and reduce it with PCA, preserv‐\n",
            "\n",
            "--- Chunk 5936 ---\n",
            "ing 99% of the variance. Then compute the reconstruction error for each image.\n",
            "\n",
            "--- Chunk 5937 ---\n",
            "Next, take some of the modified images you built in the previous exercise, and\n",
            "\n",
            "--- Chunk 5938 ---\n",
            "look at their reconstruction error: notice how much larger the reconstruction\n",
            "\n",
            "--- Chunk 5939 ---\n",
            "error is. If you plot a reconstructed image, you will see why: it tries to reconstruct\n",
            "a normal face.\n",
            "\n",
            "--- Chunk 5940 ---\n",
            "Solutions to these exercises are available in Appendix A.\n",
            "\n",
            "276 | Chapter 9: Unsupervised Learning Techniques\n",
            "\n",
            "--- Chunk 5941 ---\n",
            "PART II\n",
            "Neural Networks and Deep Learning\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER 10\n",
            "Introduction to Artificial Neural Networks\n",
            "\n",
            "with Keras\n",
            "\n",
            "--- Chunk 5942 ---\n",
            "Birds inspired us to fly, burdock plants inspired Velcro, and nature has inspired\n",
            "\n",
            "--- Chunk 5943 ---\n",
            "countless more inventions. It seems only logical, then, to look at the brain’s architec‐\n",
            "\n",
            "--- Chunk 5944 ---\n",
            "ture for inspiration on how to build an intelligent machine. This is the logic that\n",
            "\n",
            "--- Chunk 5945 ---\n",
            "sparked artificial neural networks (ANNs): an ANN is a Machine Learning model\n",
            "\n",
            "--- Chunk 5946 ---\n",
            "inspired by the networks of biological neurons found in our brains. However,\n",
            "\n",
            "--- Chunk 5947 ---\n",
            "although planes were inspired by birds, they don’t have to flap their wings. Similarly,\n",
            "\n",
            "--- Chunk 5948 ---\n",
            "ANNs have gradually become quite different from their biological cousins. Some\n",
            "\n",
            "--- Chunk 5949 ---\n",
            "researchers even argue that we should drop the biological analogy altogether (e.g., by\n",
            "\n",
            "--- Chunk 5950 ---\n",
            "saying “units” rather than “neurons”), lest we restrict our creativity to biologically\n",
            "plausible systems.1\n",
            "\n",
            "--- Chunk 5951 ---\n",
            "ANNs are at the very core of Deep Learning. They are versatile, powerful, and scala‐\n",
            "\n",
            "--- Chunk 5952 ---\n",
            "ble, making them ideal to tackle large and highly complex Machine Learning tasks\n",
            "\n",
            "--- Chunk 5953 ---\n",
            "such as classifying billions of images (e.g., Google Images), powering speech recogni‐\n",
            "\n",
            "--- Chunk 5954 ---\n",
            "tion services (e.g., Apple’s Siri), recommending the best videos to watch to hundreds\n",
            "\n",
            "--- Chunk 5955 ---\n",
            "of millions of users every day (e.g., YouTube), or learning to beat the world champion\n",
            "at the game of Go (DeepMind’s AlphaGo).\n",
            "\n",
            "--- Chunk 5956 ---\n",
            "The first part of this chapter introduces artificial neural networks, starting with a\n",
            "\n",
            "--- Chunk 5957 ---\n",
            "quick tour of the very first ANN architectures and leading up to Multilayer Percep‐\n",
            "\n",
            "--- Chunk 5958 ---\n",
            "trons (MLPs), which are heavily used today (other architectures will be explored in\n",
            "\n",
            "--- Chunk 5959 ---\n",
            "the next chapters). In the second part, we will look at how to implement neural net‐\n",
            "\n",
            "--- Chunk 5960 ---\n",
            "works using the popular Keras API. This is a beautifully designed and simple high-\n",
            "\n",
            "--- Chunk 5961 ---\n",
            "1 You can get the best of both worlds by being open to biological inspirations without being afraid to create\n",
            "\n",
            "--- Chunk 5962 ---\n",
            "biologically unrealistic models, as long as they work well.\n",
            "\n",
            "--- Chunk 5963 ---\n",
            "279\n",
            "\n",
            "--- Chunk 5964 ---\n",
            "level API for building, training, evaluating, and running neural networks. But don’t\n",
            "\n",
            "--- Chunk 5965 ---\n",
            "be fooled by its simplicity: it is expressive and flexible enough to let you build a wide\n",
            "\n",
            "--- Chunk 5966 ---\n",
            "variety of neural network architectures. In fact, it will probably be sufficient for most\n",
            "\n",
            "--- Chunk 5967 ---\n",
            "of your use cases. And should you ever need extra flexibility, you can always write\n",
            "\n",
            "--- Chunk 5968 ---\n",
            "custom Keras components using its lower-level API, as we will see in Chapter 12.\n",
            "\n",
            "--- Chunk 5969 ---\n",
            "But first, let’s go back in time to see how artificial neural networks came to be!\n",
            "\n",
            "--- Chunk 5970 ---\n",
            "From Biological to Artificial Neurons\n",
            "Surprisingly, ANNs have been around for quite a while: they were first introduced\n",
            "\n",
            "--- Chunk 5971 ---\n",
            "back in 1943 by the neurophysiologist Warren McCulloch and the mathematician\n",
            "\n",
            "--- Chunk 5972 ---\n",
            "Walter Pitts. In their landmark paper2 “A Logical Calculus of Ideas Immanent in\n",
            "\n",
            "--- Chunk 5973 ---\n",
            "Nervous Activity,” McCulloch and Pitts presented a simplified computational model\n",
            "\n",
            "--- Chunk 5974 ---\n",
            "of how biological neurons might work together in animal brains to perform complex\n",
            "\n",
            "--- Chunk 5975 ---\n",
            "computations using propositional logic. This was the first artificial neural network\n",
            "\n",
            "--- Chunk 5976 ---\n",
            "architecture. Since then many other architectures have been invented, as we will see.\n",
            "\n",
            "--- Chunk 5977 ---\n",
            "The early successes of ANNs led to the widespread belief that we would soon be con‐\n",
            "\n",
            "--- Chunk 5978 ---\n",
            "versing with truly intelligent machines. When it became clear in the 1960s that this\n",
            "\n",
            "--- Chunk 5979 ---\n",
            "promise would go unfulfilled (at least for quite a while), funding flew elsewhere, and\n",
            "\n",
            "--- Chunk 5980 ---\n",
            "ANNs entered a long winter. In the early 1980s, new architectures were invented and\n",
            "\n",
            "--- Chunk 5981 ---\n",
            "better training techniques were developed, sparking a revival of interest in connec‐\n",
            "\n",
            "--- Chunk 5982 ---\n",
            "tionism (the study of neural networks). But progress was slow, and by the 1990s other\n",
            "\n",
            "--- Chunk 5983 ---\n",
            "powerful Machine Learning techniques were invented, such as Support Vector\n",
            "\n",
            "--- Chunk 5984 ---\n",
            "Machines (see Chapter 5). These techniques seemed to offer better results and stron‐\n",
            "\n",
            "--- Chunk 5985 ---\n",
            "ger theoretical foundations than ANNs, so once again the study of neural networks\n",
            "was put on hold.\n",
            "\n",
            "--- Chunk 5986 ---\n",
            "was put on hold.\n",
            "We are now witnessing yet another wave of interest in ANNs. Will this wave die out\n",
            "\n",
            "--- Chunk 5987 ---\n",
            "like the previous ones did? Well, here are a few good reasons to believe that this time\n",
            "\n",
            "--- Chunk 5988 ---\n",
            "is different and that the renewed interest in ANNs will have a much more profound\n",
            "impact on our lives:\n",
            "\n",
            "--- Chunk 5989 ---\n",
            "• There is now a huge quantity of data available to train neural networks, and\n",
            "\n",
            "--- Chunk 5990 ---\n",
            "ANNs frequently outperform other ML techniques on very large and complex\n",
            "problems.\n",
            "\n",
            "--- Chunk 5991 ---\n",
            "• The tremendous increase in computing power since the 1990s now makes it pos‐\n",
            "\n",
            "--- Chunk 5992 ---\n",
            "sible to train large neural networks in a reasonable amount of time. This is in\n",
            "\n",
            "--- Chunk 5993 ---\n",
            "part due to Moore’s law (the number of components in integrated circuits has\n",
            "\n",
            "--- Chunk 5994 ---\n",
            "2 Warren S. McCulloch and Walter Pitts, “A Logical Calculus of the Ideas Immanent in Nervous Activity,” The\n",
            "\n",
            "--- Chunk 5995 ---\n",
            "Bulletin of Mathematical Biology 5, no. 4 (1943): 115–113.\n",
            "\n",
            "--- Chunk 5996 ---\n",
            "280 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 5997 ---\n",
            "doubled about every 2 years over the last 50 years), but also thanks to the gaming\n",
            "\n",
            "--- Chunk 5998 ---\n",
            "industry, which has stimulated the production of powerful GPU cards by the mil‐\n",
            "\n",
            "--- Chunk 5999 ---\n",
            "lions. Moreover, cloud platforms have made this power accessible to everyone.\n",
            "\n",
            "--- Chunk 6000 ---\n",
            "• The training algorithms have been improved. To be fair they are only slightly dif‐\n",
            "\n",
            "--- Chunk 6001 ---\n",
            "ferent from the ones used in the 1990s, but these relatively small tweaks have had\n",
            "a huge positive impact.\n",
            "\n",
            "--- Chunk 6002 ---\n",
            "• Some theoretical limitations of ANNs have turned out to be benign in practice.\n",
            "\n",
            "--- Chunk 6003 ---\n",
            "For example, many people thought that ANN training algorithms were doomed\n",
            "\n",
            "--- Chunk 6004 ---\n",
            "because they were likely to get stuck in local optima, but it turns out that this is\n",
            "\n",
            "--- Chunk 6005 ---\n",
            "rather rare in practice (and when it is the case, they are usually fairly close to the\n",
            "global optimum).\n",
            "\n",
            "--- Chunk 6006 ---\n",
            "• ANNs seem to have entered a virtuous circle of funding and progress. Amazing\n",
            "\n",
            "--- Chunk 6007 ---\n",
            "products based on ANNs regularly make the headline news, which pulls more\n",
            "and more attention and funding toward them, resulting in more and more pro‐\n",
            "\n",
            "--- Chunk 6008 ---\n",
            "gress and even more amazing products.\n",
            "\n",
            "--- Chunk 6009 ---\n",
            "Biological Neurons\n",
            "Before we discuss artificial neurons, let’s take a quick look at a biological neuron (rep‐\n",
            "\n",
            "--- Chunk 6010 ---\n",
            "resented in Figure 10-1). It is an unusual-looking cell mostly found in animal brains.\n",
            "\n",
            "--- Chunk 6011 ---\n",
            "It’s composed of a cell body containing the nucleus and most of the cell’s complex\n",
            "\n",
            "--- Chunk 6012 ---\n",
            "components, many branching extensions called dendrites, plus one very long exten‐\n",
            "\n",
            "--- Chunk 6013 ---\n",
            "sion called the axon. The axon’s length may be just a few times longer than the cell\n",
            "\n",
            "--- Chunk 6014 ---\n",
            "body, or up to tens of thousands of times longer. Near its extremity the axon splits off\n",
            "\n",
            "--- Chunk 6015 ---\n",
            "into many branches called telodendria, and at the tip of these branches are minuscule\n",
            "\n",
            "--- Chunk 6016 ---\n",
            "structures called synaptic terminals (or simply synapses), which are connected to the\n",
            "\n",
            "--- Chunk 6017 ---\n",
            "dendrites or cell bodies of other neurons.3 Biological neurons produce short electrical\n",
            "\n",
            "--- Chunk 6018 ---\n",
            "impulses called action potentials (APs, or just signals) which travel along the axons\n",
            "\n",
            "--- Chunk 6019 ---\n",
            "and make the synapses release chemical signals called neurotransmitters. When a neu‐\n",
            "\n",
            "--- Chunk 6020 ---\n",
            "ron receives a sufficient amount of these neurotransmitters within a few milliseconds,\n",
            "\n",
            "--- Chunk 6021 ---\n",
            "it fires its own electrical impulses (actually, it depends on the neurotransmitters, as\n",
            "some of them inhibit the neuron from firing).\n",
            "\n",
            "--- Chunk 6022 ---\n",
            "3 They are not actually attached, just so close that they can very quickly exchange chemical signals.\n",
            "\n",
            "From Biological to Artificial Neurons | 281\n",
            "\n",
            "--- Chunk 6023 ---\n",
            "Figure 10-1. Biological neuron4\n",
            "\n",
            "--- Chunk 6024 ---\n",
            "Thus, individual biological neurons seem to behave in a rather simple way, but they\n",
            "\n",
            "--- Chunk 6025 ---\n",
            "are organized in a vast network of billions, with each neuron typically connected to\n",
            "\n",
            "--- Chunk 6026 ---\n",
            "thousands of other neurons. Highly complex computations can be performed by a\n",
            "\n",
            "--- Chunk 6027 ---\n",
            "network of fairly simple neurons, much like a complex anthill can emerge from the\n",
            "\n",
            "--- Chunk 6028 ---\n",
            "combined efforts of simple ants. The architecture of biological neural networks\n",
            "\n",
            "--- Chunk 6029 ---\n",
            "(BNNs)5 is still the subject of active research, but some parts of the brain have been\n",
            "\n",
            "--- Chunk 6030 ---\n",
            "mapped, and it seems that neurons are often organized in consecutive layers, espe‐\n",
            "\n",
            "--- Chunk 6031 ---\n",
            "cially in the cerebral cortex (i.e., the outer layer of your brain), as shown in\n",
            "Figure 10-2.\n",
            "\n",
            "--- Chunk 6032 ---\n",
            "4 Image by Bruce Blaus (Creative Commons 3.0). Reproduced from https://en.wikipedia.org/wiki/Neuron.\n",
            "\n",
            "--- Chunk 6033 ---\n",
            "5 In the context of Machine Learning, the phrase “neural networks” generally refers to ANNs, not BNNs.\n",
            "\n",
            "--- Chunk 6034 ---\n",
            "282 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 6035 ---\n",
            "Figure 10-2. Multiple layers in a biological neural network (human cortex)6\n",
            "\n",
            "--- Chunk 6036 ---\n",
            "Logical Computations with Neurons\n",
            "McCulloch and Pitts proposed a very simple model of the biological neuron, which\n",
            "\n",
            "--- Chunk 6037 ---\n",
            "later became known as an artificial neuron: it has one or more binary (on/off) inputs\n",
            "\n",
            "--- Chunk 6038 ---\n",
            "and one binary output. The artificial neuron activates its output when more than a\n",
            "\n",
            "--- Chunk 6039 ---\n",
            "certain number of its inputs are active. In their paper, they showed that even with\n",
            "\n",
            "--- Chunk 6040 ---\n",
            "such a simplified model it is possible to build a network of artificial neurons that\n",
            "\n",
            "--- Chunk 6041 ---\n",
            "computes any logical proposition you want. To see how such a network works, let’s\n",
            "\n",
            "--- Chunk 6042 ---\n",
            "build a few ANNs that perform various logical computations (see Figure 10-3),\n",
            "\n",
            "--- Chunk 6043 ---\n",
            "assuming that a neuron is activated when at least two of its inputs are active.\n",
            "\n",
            "--- Chunk 6044 ---\n",
            "Figure 10-3. ANNs performing simple logical computations\n",
            "\n",
            "--- Chunk 6045 ---\n",
            "6 Drawing of a cortical lamination by S. Ramon y Cajal (public domain). Reproduced from https://en.wikipe\n",
            "dia.org/wiki/Cerebral_cortex.\n",
            "\n",
            "--- Chunk 6046 ---\n",
            "From Biological to Artificial Neurons | 283\n",
            "\n",
            "\n",
            "\n",
            "Let’s see what these networks do:\n",
            "\n",
            "--- Chunk 6047 ---\n",
            "• The first network on the left is the identity function: if neuron A is activated,\n",
            "\n",
            "--- Chunk 6048 ---\n",
            "then neuron C gets activated as well (since it receives two input signals from neu‐\n",
            "ron A); but if neuron A is off, then neuron C is off as well.\n",
            "\n",
            "--- Chunk 6049 ---\n",
            "• The second network performs a logical AND: neuron C is activated only when\n",
            "\n",
            "--- Chunk 6050 ---\n",
            "both neurons A and B are activated (a single input signal is not enough to acti‐\n",
            "vate neuron C).\n",
            "\n",
            "--- Chunk 6051 ---\n",
            "• The third network performs a logical OR: neuron C gets activated if either neu‐\n",
            "ron A or neuron B is activated (or both).\n",
            "\n",
            "--- Chunk 6052 ---\n",
            "• Finally, if we suppose that an input connection can inhibit the neuron’s activity\n",
            "\n",
            "--- Chunk 6053 ---\n",
            "(which is the case with biological neurons), then the fourth network computes a\n",
            "\n",
            "--- Chunk 6054 ---\n",
            "slightly more complex logical proposition: neuron C is activated only if neuron A\n",
            "\n",
            "--- Chunk 6055 ---\n",
            "is active and neuron B is off. If neuron A is active all the time, then you get a\n",
            "\n",
            "--- Chunk 6056 ---\n",
            "logical NOT: neuron C is active when neuron B is off, and vice versa.\n",
            "\n",
            "--- Chunk 6057 ---\n",
            "You can imagine how these networks can be combined to compute complex logical\n",
            "\n",
            "--- Chunk 6058 ---\n",
            "expressions (see the exercises at the end of the chapter for an example).\n",
            "\n",
            "--- Chunk 6059 ---\n",
            "The Perceptron\n",
            "The Perceptron is one of the simplest ANN architectures, invented in 1957 by Frank\n",
            "\n",
            "--- Chunk 6060 ---\n",
            "Rosenblatt. It is based on a slightly different artificial neuron (see Figure 10-4) called\n",
            "\n",
            "--- Chunk 6061 ---\n",
            "a threshold logic unit (TLU), or sometimes a linear threshold unit (LTU). The inputs\n",
            "\n",
            "--- Chunk 6062 ---\n",
            "and output are numbers (instead of binary on/off values), and each input connection\n",
            "\n",
            "--- Chunk 6063 ---\n",
            "is associated with a weight. The TLU computes a weighted sum of its inputs (z = w1 x1\n",
            "\n",
            "--- Chunk 6064 ---\n",
            "+ w2 x2 + ⋯ + wn xn = x⊺ w), then applies a step function to that sum and outputs the\n",
            "result: hw(x) = step(z), where z = x⊺ w.\n",
            "\n",
            "--- Chunk 6065 ---\n",
            "Figure 10-4. Threshold logic unit: an artificial neuron which computes a weighted sum\n",
            "of its inputs then applies a step function\n",
            "\n",
            "--- Chunk 6066 ---\n",
            "284 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 6067 ---\n",
            "The most common step function used in Perceptrons is the Heaviside step function\n",
            "(see Equation 10-1). Sometimes the sign function is used instead.\n",
            "\n",
            "--- Chunk 6068 ---\n",
            "Equation 10-1. Common step functions used in Perceptrons (assuming threshold =\n",
            "0)\n",
            "\n",
            "−1 if z < 0\n",
            "0 if z < 0\n",
            "\n",
            "--- Chunk 6069 ---\n",
            "heaviside z = sgn z = 0 if z = 0\n",
            "1 if z ≥ 0\n",
            "\n",
            "+1 if z > 0\n",
            "\n",
            "--- Chunk 6070 ---\n",
            "A single TLU can be used for simple linear binary classification. It computes a linear\n",
            "\n",
            "--- Chunk 6071 ---\n",
            "combination of the inputs, and if the result exceeds a threshold, it outputs the posi‐\n",
            "\n",
            "--- Chunk 6072 ---\n",
            "tive class. Otherwise it outputs the negative class (just like a Logistic Regression or\n",
            "\n",
            "--- Chunk 6073 ---\n",
            "linear SVM classifier). You could, for example, use a single TLU to classify iris flowers\n",
            "\n",
            "--- Chunk 6074 ---\n",
            "based on petal length and width (also adding an extra bias feature x0 = 1, just like we\n",
            "\n",
            "--- Chunk 6075 ---\n",
            "did in previous chapters). Training a TLU in this case means finding the right values\n",
            "\n",
            "--- Chunk 6076 ---\n",
            "for w0, w1, and w2 (the training algorithm is discussed shortly).\n",
            "A Perceptron is simply composed of a single layer of TLUs,7 with each TLU connected\n",
            "\n",
            "--- Chunk 6077 ---\n",
            "to all the inputs. When all the neurons in a layer are connected to every neuron in the\n",
            "\n",
            "--- Chunk 6078 ---\n",
            "previous layer (i.e., its input neurons), the layer is called a fully connected layer, or a\n",
            "\n",
            "--- Chunk 6079 ---\n",
            "dense layer. The inputs of the Perceptron are fed to special passthrough neurons\n",
            "\n",
            "--- Chunk 6080 ---\n",
            "called input neurons: they output whatever input they are fed. All the input neurons\n",
            "\n",
            "--- Chunk 6081 ---\n",
            "form the input layer. Moreover, an extra bias feature is generally added (x0 = 1): it is\n",
            "\n",
            "--- Chunk 6082 ---\n",
            "typically represented using a special type of neuron called a bias neuron, which out‐\n",
            "\n",
            "--- Chunk 6083 ---\n",
            "puts 1 all the time. A Perceptron with two inputs and three outputs is represented in\n",
            "\n",
            "--- Chunk 6084 ---\n",
            "Figure 10-5. This Perceptron can classify instances simultaneously into three different\n",
            "binary classes, which makes it a multioutput classifier.\n",
            "\n",
            "--- Chunk 6085 ---\n",
            "7 The name Perceptron is sometimes used to mean a tiny network with a single TLU.\n",
            "\n",
            "From Biological to Artificial Neurons | 285\n",
            "\n",
            "--- Chunk 6086 ---\n",
            "Figure 10-5. Architecture of a Perceptron with two input neurons, one bias neuron, and\n",
            "three output neurons\n",
            "\n",
            "--- Chunk 6087 ---\n",
            "Thanks to the magic of linear algebra, Equation 10-2 makes it possible to efficiently\n",
            "\n",
            "--- Chunk 6088 ---\n",
            "compute the outputs of a layer of artificial neurons for several instances at once.\n",
            "\n",
            "--- Chunk 6089 ---\n",
            "Equation 10-2. Computing the outputs of a fully connected layer\n",
            "hW, b X = ϕ XW + b\n",
            "\n",
            "In this equation:\n",
            "\n",
            "--- Chunk 6090 ---\n",
            "In this equation:\n",
            "\n",
            "• As always, X represents the matrix of input features. It has one row per instance\n",
            "and one column per feature.\n",
            "\n",
            "--- Chunk 6091 ---\n",
            "• The weight matrix W contains all the connection weights except for the ones\n",
            "\n",
            "--- Chunk 6092 ---\n",
            "from the bias neuron. It has one row per input neuron and one column per artifi‐\n",
            "cial neuron in the layer.\n",
            "\n",
            "--- Chunk 6093 ---\n",
            "• The bias vector b contains all the connection weights between the bias neuron\n",
            "\n",
            "--- Chunk 6094 ---\n",
            "and the artificial neurons. It has one bias term per artificial neuron.\n",
            "\n",
            "--- Chunk 6095 ---\n",
            "• The function ϕ is called the activation function: when the artificial neurons are\n",
            "\n",
            "--- Chunk 6096 ---\n",
            "TLUs, it is a step function (but we will discuss other activation functions shortly).\n",
            "\n",
            "--- Chunk 6097 ---\n",
            "So, how is a Perceptron trained? The Perceptron training algorithm proposed by\n",
            "\n",
            "--- Chunk 6098 ---\n",
            "Rosenblatt was largely inspired by Hebb’s rule. In his 1949 book The Organization of\n",
            "\n",
            "--- Chunk 6099 ---\n",
            "Behavior (Wiley), Donald Hebb suggested that when a biological neuron triggers\n",
            "\n",
            "--- Chunk 6100 ---\n",
            "another neuron often, the connection between these two neurons grows stronger. Sie‐\n",
            "\n",
            "--- Chunk 6101 ---\n",
            "grid Löwel later summarized Hebb’s idea in the catchy phrase, “Cells that fire\n",
            "\n",
            "--- Chunk 6102 ---\n",
            "together, wire together”; that is, the connection weight between two neurons tends to\n",
            "\n",
            "--- Chunk 6103 ---\n",
            "increase when they fire simultaneously. This rule later became known as Hebb’s rule\n",
            "\n",
            "--- Chunk 6104 ---\n",
            "(or Hebbian learning). Perceptrons are trained using a variant of this rule that takes\n",
            "\n",
            "--- Chunk 6105 ---\n",
            "into account the error made by the network when it makes a prediction; the\n",
            "\n",
            "--- Chunk 6106 ---\n",
            "286 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 6107 ---\n",
            "Perceptron learning rule reinforces connections that help reduce the error. More\n",
            "\n",
            "--- Chunk 6108 ---\n",
            "specifically, the Perceptron is fed one training instance at a time, and for each\n",
            "\n",
            "--- Chunk 6109 ---\n",
            "instance it makes its predictions. For every output neuron that produced a wrong\n",
            "\n",
            "--- Chunk 6110 ---\n",
            "prediction, it reinforces the connection weights from the inputs that would have con‐\n",
            "\n",
            "--- Chunk 6111 ---\n",
            "tributed to the correct prediction. The rule is shown in Equation 10-3.\n",
            "\n",
            "--- Chunk 6112 ---\n",
            "Equation 10-3. Perceptron learning rule (weight update)\n",
            "w next step\n",
            "\n",
            "i, j = wi, j + η y j − y j xi\n",
            "\n",
            "In this equation:\n",
            "\n",
            "--- Chunk 6113 ---\n",
            "In this equation:\n",
            "\n",
            "• wi, j is the connection weight between the ith input neuron and the jth output\n",
            "neuron.\n",
            "\n",
            "--- Chunk 6114 ---\n",
            "• xi is the ith input value of the current training instance.\n",
            "• y j is the output of the jth output neuron for the current training instance.\n",
            "\n",
            "--- Chunk 6115 ---\n",
            "• yj is the target output of the jth output neuron for the current training instance.\n",
            "• η is the learning rate.\n",
            "\n",
            "--- Chunk 6116 ---\n",
            "The decision boundary of each output neuron is linear, so Perceptrons are incapable\n",
            "\n",
            "--- Chunk 6117 ---\n",
            "of learning complex patterns (just like Logistic Regression classifiers). However, if the\n",
            "\n",
            "--- Chunk 6118 ---\n",
            "training instances are linearly separable, Rosenblatt demonstrated that this algorithm\n",
            "\n",
            "--- Chunk 6119 ---\n",
            "would converge to a solution.8 This is called the Perceptron convergence theorem.\n",
            "\n",
            "--- Chunk 6120 ---\n",
            "Scikit-Learn provides a Perceptron class that implements a single-TLU network. It\n",
            "\n",
            "--- Chunk 6121 ---\n",
            "can be used pretty much as you would expect—for example, on the iris dataset (intro‐\n",
            "duced in Chapter 4):\n",
            "\n",
            "--- Chunk 6122 ---\n",
            "import numpy as np\n",
            "from sklearn.datasets import load_iris\n",
            "from sklearn.linear_model import Perceptron\n",
            "\n",
            "--- Chunk 6123 ---\n",
            "iris = load_iris()\n",
            "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
            "y = (iris.target == 0).astype(np.int)  # Iris setosa?\n",
            "\n",
            "--- Chunk 6124 ---\n",
            "per_clf = Perceptron()\n",
            "per_clf.fit(X, y)\n",
            "\n",
            "y_pred = per_clf.predict([[2, 0.5]])\n",
            "\n",
            "--- Chunk 6125 ---\n",
            "8 Note that this solution is not unique: when data points are linearly separable, there is an infinity of hyper‐\n",
            "planes that can separate them.\n",
            "\n",
            "--- Chunk 6126 ---\n",
            "From Biological to Artificial Neurons | 287\n",
            "\n",
            "--- Chunk 6127 ---\n",
            "You may have noticed that the Perceptron learning algorithm strongly resembles Sto‐\n",
            "\n",
            "--- Chunk 6128 ---\n",
            "chastic Gradient Descent. In fact, Scikit-Learn’s Perceptron class is equivalent to\n",
            "\n",
            "--- Chunk 6129 ---\n",
            "using an SGDClassifier with the following hyperparameters: loss=\"perceptron\",\n",
            "\n",
            "--- Chunk 6130 ---\n",
            "learning_rate=\"constant\", eta0=1 (the learning rate), and penalty=None (no\n",
            "regularization).\n",
            "\n",
            "--- Chunk 6131 ---\n",
            "regularization).\n",
            "Note that contrary to Logistic Regression classifiers, Perceptrons do not output a class\n",
            "\n",
            "--- Chunk 6132 ---\n",
            "probability; rather, they make predictions based on a hard threshold. This is one rea‐\n",
            "son to prefer Logistic Regression over Perceptrons.\n",
            "\n",
            "--- Chunk 6133 ---\n",
            "In their 1969 monograph Perceptrons, Marvin Minsky and Seymour Papert highligh‐\n",
            "\n",
            "--- Chunk 6134 ---\n",
            "ted a number of serious weaknesses of Perceptrons—in particular, the fact that they\n",
            "\n",
            "--- Chunk 6135 ---\n",
            "are incapable of solving some trivial problems (e.g., the Exclusive OR (XOR) classifi‐\n",
            "\n",
            "--- Chunk 6136 ---\n",
            "cation problem; see the left side of Figure 10-6). This is true of any other linear classi‐\n",
            "\n",
            "--- Chunk 6137 ---\n",
            "fication model (such as Logistic Regression classifiers), but researchers had expected\n",
            "\n",
            "--- Chunk 6138 ---\n",
            "much more from Perceptrons, and some were so disappointed that they dropped\n",
            "\n",
            "--- Chunk 6139 ---\n",
            "neural networks altogether in favor of higher-level problems such as logic, problem\n",
            "solving, and search.\n",
            "\n",
            "--- Chunk 6140 ---\n",
            "It turns out that some of the limitations of Perceptrons can be eliminated by stacking\n",
            "\n",
            "--- Chunk 6141 ---\n",
            "multiple Perceptrons. The resulting ANN is called a Multilayer Perceptron (MLP). An\n",
            "\n",
            "--- Chunk 6142 ---\n",
            "MLP can solve the XOR problem, as you can verify by computing the output of the\n",
            "\n",
            "--- Chunk 6143 ---\n",
            "MLP represented on the right side of Figure 10-6: with inputs (0, 0) or (1, 1), the net‐\n",
            "\n",
            "--- Chunk 6144 ---\n",
            "work outputs 0, and with inputs (0, 1) or (1, 0) it outputs 1. All connections have a\n",
            "\n",
            "--- Chunk 6145 ---\n",
            "weight equal to 1, except the four connections where the weight is shown. Try verify‐\n",
            "ing that this network indeed solves the XOR problem!\n",
            "\n",
            "--- Chunk 6146 ---\n",
            "Figure 10-6. XOR classification problem and an MLP that solves it\n",
            "\n",
            "288 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 6147 ---\n",
            "The Multilayer Perceptron and Backpropagation\n",
            "An MLP is composed of one (passthrough) input layer, one or more layers of TLUs,\n",
            "\n",
            "--- Chunk 6148 ---\n",
            "called hidden layers, and one final layer of TLUs called the output layer (see\n",
            "\n",
            "--- Chunk 6149 ---\n",
            "Figure 10-7). The layers close to the input layer are usually called the lower layers, and\n",
            "\n",
            "--- Chunk 6150 ---\n",
            "the ones close to the outputs are usually called the upper layers. Every layer except the\n",
            "\n",
            "--- Chunk 6151 ---\n",
            "output layer includes a bias neuron and is fully connected to the next layer.\n",
            "\n",
            "--- Chunk 6152 ---\n",
            "Figure 10-7. Architecture of a Multilayer Perceptron with two inputs, one hidden layer of\n",
            "\n",
            "--- Chunk 6153 ---\n",
            "four neurons, and three output neurons (the bias neurons are shown here, but usually\n",
            "they are implicit)\n",
            "\n",
            "--- Chunk 6154 ---\n",
            "The signal flows only in one direction (from the inputs to the out‐\n",
            "puts), so this architecture is an example of a feedforward neural net‐\n",
            "\n",
            "--- Chunk 6155 ---\n",
            "work (FNN).\n",
            "\n",
            "--- Chunk 6156 ---\n",
            "When an ANN contains a deep stack of hidden layers,9 it is called a deep neural net‐\n",
            "\n",
            "--- Chunk 6157 ---\n",
            "work (DNN). The field of Deep Learning studies DNNs, and more generally models\n",
            "\n",
            "--- Chunk 6158 ---\n",
            "containing deep stacks of computations. Even so, many people talk about Deep\n",
            "Learning whenever neural networks are involved (even shallow ones).\n",
            "\n",
            "--- Chunk 6159 ---\n",
            "For many years researchers struggled to find a way to train MLPs, without success.\n",
            "\n",
            "--- Chunk 6160 ---\n",
            "But in 1986, David Rumelhart, Geoffrey Hinton, and Ronald Williams published a\n",
            "\n",
            "--- Chunk 6161 ---\n",
            "9 In the 1990s, an ANN with more than two hidden layers was considered deep. Nowadays, it is common to see\n",
            "\n",
            "--- Chunk 6162 ---\n",
            "ANNs with dozens of layers, or even hundreds, so the definition of “deep” is quite fuzzy.\n",
            "\n",
            "--- Chunk 6163 ---\n",
            "From Biological to Artificial Neurons | 289\n",
            "\n",
            "--- Chunk 6164 ---\n",
            "groundbreaking paper10 that introduced the backpropagation training algorithm,\n",
            "\n",
            "--- Chunk 6165 ---\n",
            "which is still used today. In short, it is Gradient Descent (introduced in Chapter 4)\n",
            "\n",
            "--- Chunk 6166 ---\n",
            "using an efficient technique for computing the gradients automatically:11 in just two\n",
            "\n",
            "--- Chunk 6167 ---\n",
            "passes through the network (one forward, one backward), the backpropagation algo‐\n",
            "\n",
            "--- Chunk 6168 ---\n",
            "rithm is able to compute the gradient of the network’s error with regard to every sin‐\n",
            "\n",
            "--- Chunk 6169 ---\n",
            "gle model parameter. In other words, it can find out how each connection weight and\n",
            "\n",
            "--- Chunk 6170 ---\n",
            "each bias term should be tweaked in order to reduce the error. Once it has these gra‐\n",
            "\n",
            "--- Chunk 6171 ---\n",
            "dients, it just performs a regular Gradient Descent step, and the whole process is\n",
            "repeated until the network converges to the solution.\n",
            "\n",
            "--- Chunk 6172 ---\n",
            "Automatically computing gradients is called automatic differentia‐\n",
            "tion, or autodiff. There are various autodiff techniques, with differ‐\n",
            "\n",
            "--- Chunk 6173 ---\n",
            "ent pros and cons. The one used by backpropagation is called\n",
            "reverse-mode autodiff. It is fast and precise, and is well suited when\n",
            "\n",
            "--- Chunk 6174 ---\n",
            "the function to differentiate has many variables (e.g., connection\n",
            "weights) and few outputs (e.g., one loss). If you want to learn more\n",
            "\n",
            "--- Chunk 6175 ---\n",
            "about autodiff, check out Appendix D.\n",
            "\n",
            "--- Chunk 6176 ---\n",
            "Let’s run through this algorithm in a bit more detail:\n",
            "\n",
            "--- Chunk 6177 ---\n",
            "• It handles one mini-batch at a time (for example, containing 32 instances each),\n",
            "\n",
            "--- Chunk 6178 ---\n",
            "and it goes through the full training set multiple times. Each pass is called an\n",
            "epoch.\n",
            "\n",
            "--- Chunk 6179 ---\n",
            "• Each mini-batch is passed to the network’s input layer, which sends it to the first\n",
            "\n",
            "--- Chunk 6180 ---\n",
            "hidden layer. The algorithm then computes the output of all the neurons in this\n",
            "\n",
            "--- Chunk 6181 ---\n",
            "layer (for every instance in the mini-batch). The result is passed on to the next\n",
            "\n",
            "--- Chunk 6182 ---\n",
            "layer, its output is computed and passed to the next layer, and so on until we get\n",
            "\n",
            "--- Chunk 6183 ---\n",
            "the output of the last layer, the output layer. This is the forward pass: it is exactly\n",
            "\n",
            "--- Chunk 6184 ---\n",
            "like making predictions, except all intermediate results are preserved since they\n",
            "are needed for the backward pass.\n",
            "\n",
            "--- Chunk 6185 ---\n",
            "• Next, the algorithm measures the network’s output error (i.e., it uses a loss func‐\n",
            "\n",
            "--- Chunk 6186 ---\n",
            "tion that compares the desired output and the actual output of the network, and\n",
            "returns some measure of the error).\n",
            "\n",
            "--- Chunk 6187 ---\n",
            "• Then it computes how much each output connection contributed to the error.\n",
            "\n",
            "--- Chunk 6188 ---\n",
            "This is done analytically by applying the chain rule (perhaps the most fundamen‐\n",
            "tal rule in calculus), which makes this step fast and precise.\n",
            "\n",
            "--- Chunk 6189 ---\n",
            "10 David Rumelhart et al. “Learning Internal Representations by Error Propagation,” (Defense Technical Infor‐\n",
            "\n",
            "--- Chunk 6190 ---\n",
            "mation Center technical report, September 1985).\n",
            "\n",
            "--- Chunk 6191 ---\n",
            "11 This technique was actually independently invented several times by various researchers in different fields,\n",
            "starting with Paul Werbos in 1974.\n",
            "\n",
            "--- Chunk 6192 ---\n",
            "290 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 6193 ---\n",
            "• The algorithm then measures how much of these error contributions came from\n",
            "\n",
            "--- Chunk 6194 ---\n",
            "each connection in the layer below, again using the chain rule, working backward\n",
            "\n",
            "--- Chunk 6195 ---\n",
            "until the algorithm reaches the input layer. As explained earlier, this reverse pass\n",
            "\n",
            "--- Chunk 6196 ---\n",
            "efficiently measures the error gradient across all the connection weights in the\n",
            "\n",
            "--- Chunk 6197 ---\n",
            "network by propagating the error gradient backward through the network (hence\n",
            "the name of the algorithm).\n",
            "\n",
            "--- Chunk 6198 ---\n",
            "• Finally, the algorithm performs a Gradient Descent step to tweak all the connec‐\n",
            "\n",
            "--- Chunk 6199 ---\n",
            "tion weights in the network, using the error gradients it just computed.\n",
            "\n",
            "--- Chunk 6200 ---\n",
            "This algorithm is so important that it’s worth summarizing it again: for each training\n",
            "\n",
            "--- Chunk 6201 ---\n",
            "instance, the backpropagation algorithm first makes a prediction (forward pass) and\n",
            "\n",
            "--- Chunk 6202 ---\n",
            "measures the error, then goes through each layer in reverse to measure the error con‐\n",
            "\n",
            "--- Chunk 6203 ---\n",
            "tribution from each connection (reverse pass), and finally tweaks the connection\n",
            "weights to reduce the error (Gradient Descent step).\n",
            "\n",
            "--- Chunk 6204 ---\n",
            "It is important to initialize all the hidden layers’ connection weights\n",
            "randomly, or else training will fail. For example, if you initialize all\n",
            "\n",
            "--- Chunk 6205 ---\n",
            "weights and biases to zero, then all neurons in a given layer will be\n",
            "perfectly identical, and thus backpropagation will affect them in\n",
            "\n",
            "--- Chunk 6206 ---\n",
            "exactly the same way, so they will remain identical. In other words,\n",
            "despite having hundreds of neurons per layer, your model will act\n",
            "\n",
            "--- Chunk 6207 ---\n",
            "as if it had only one neuron per layer: it won’t be too smart. If\n",
            "instead you randomly initialize the weights, you break the symme‐\n",
            "\n",
            "--- Chunk 6208 ---\n",
            "try and allow backpropagation to train a diverse team of neurons.\n",
            "\n",
            "--- Chunk 6209 ---\n",
            "In order for this algorithm to work properly, its authors made a key change to the\n",
            "\n",
            "--- Chunk 6210 ---\n",
            "MLP’s architecture: they replaced the step function with the logistic (sigmoid) func‐\n",
            "\n",
            "--- Chunk 6211 ---\n",
            "tion, σ(z) = 1 / (1 + exp(–z)). This was essential because the step function contains\n",
            "\n",
            "--- Chunk 6212 ---\n",
            "only flat segments, so there is no gradient to work with (Gradient Descent cannot\n",
            "\n",
            "--- Chunk 6213 ---\n",
            "move on a flat surface), while the logistic function has a well-defined nonzero deriva‐\n",
            "\n",
            "--- Chunk 6214 ---\n",
            "tive everywhere, allowing Gradient Descent to make some progress at every step. In\n",
            "\n",
            "--- Chunk 6215 ---\n",
            "fact, the backpropagation algorithm works well with many other activation functions,\n",
            "\n",
            "--- Chunk 6216 ---\n",
            "not just the logistic function. Here are two other popular choices:\n",
            "The hyperbolic tangent function: tanh(z) = 2σ(2z) – 1\n",
            "\n",
            "--- Chunk 6217 ---\n",
            "Just like the logistic function, this activation function is S-shaped, continuous,\n",
            "\n",
            "--- Chunk 6218 ---\n",
            "and differentiable, but its output value ranges from –1 to 1 (instead of 0 to 1 in\n",
            "\n",
            "--- Chunk 6219 ---\n",
            "the case of the logistic function). That range tends to make each layer’s output\n",
            "\n",
            "--- Chunk 6220 ---\n",
            "more or less centered around 0 at the beginning of training, which often helps\n",
            "speed up convergence.\n",
            "\n",
            "--- Chunk 6221 ---\n",
            "From Biological to Artificial Neurons | 291\n",
            "\n",
            "--- Chunk 6222 ---\n",
            "The Rectified Linear Unit function: ReLU(z) = max(0, z)\n",
            "The ReLU function is continuous but unfortunately not differentiable at z = 0\n",
            "\n",
            "--- Chunk 6223 ---\n",
            "(the slope changes abruptly, which can make Gradient Descent bounce around),\n",
            "\n",
            "--- Chunk 6224 ---\n",
            "and its derivative is 0 for z < 0. In practice, however, it works very well and has\n",
            "\n",
            "--- Chunk 6225 ---\n",
            "the advantage of being fast to compute, so it has become the default.12 Most\n",
            "\n",
            "--- Chunk 6226 ---\n",
            "importantly, the fact that it does not have a maximum output value helps reduce\n",
            "\n",
            "--- Chunk 6227 ---\n",
            "some issues during Gradient Descent (we will come back to this in Chapter 11).\n",
            "\n",
            "--- Chunk 6228 ---\n",
            "These popular activation functions and their derivatives are represented in\n",
            "\n",
            "--- Chunk 6229 ---\n",
            "Figure 10-8. But wait! Why do we need activation functions in the first place? Well, if\n",
            "\n",
            "--- Chunk 6230 ---\n",
            "you chain several linear transformations, all you get is a linear transformation. For\n",
            "\n",
            "--- Chunk 6231 ---\n",
            "example, if f(x) = 2x + 3 and g(x) = 5x – 1, then chaining these two linear functions\n",
            "\n",
            "--- Chunk 6232 ---\n",
            "gives you another linear function: f(g(x)) = 2(5x – 1) + 3 = 10x + 1. So if you don’t\n",
            "\n",
            "--- Chunk 6233 ---\n",
            "have some nonlinearity between layers, then even a deep stack of layers is equivalent\n",
            "\n",
            "--- Chunk 6234 ---\n",
            "to a single layer, and you can’t solve very complex problems with that. Conversely, a\n",
            "\n",
            "--- Chunk 6235 ---\n",
            "large enough DNN with nonlinear activations can theoretically approximate any con‐\n",
            "tinuous function.\n",
            "\n",
            "--- Chunk 6236 ---\n",
            "Figure 10-8. Activation functions and their derivatives\n",
            "\n",
            "--- Chunk 6237 ---\n",
            "OK! You know where neural nets came from, what their architecture is, and how to\n",
            "\n",
            "--- Chunk 6238 ---\n",
            "compute their outputs. You’ve also learned about the backpropagation algorithm. But\n",
            "what exactly can you do with them?\n",
            "\n",
            "--- Chunk 6239 ---\n",
            "Regression MLPs\n",
            "First, MLPs can be used for regression tasks. If you want to predict a single value (e.g.,\n",
            "\n",
            "--- Chunk 6240 ---\n",
            "the price of a house, given many of its features), then you just need a single output\n",
            "\n",
            "--- Chunk 6241 ---\n",
            "neuron: its output is the predicted value. For multivariate regression (i.e., to predict\n",
            "\n",
            "--- Chunk 6242 ---\n",
            "12 Biological neurons seem to implement a roughly sigmoid (S-shaped) activation function, so researchers stuck\n",
            "\n",
            "--- Chunk 6243 ---\n",
            "to sigmoid functions for a very long time. But it turns out that ReLU generally works better in ANNs. This is\n",
            "\n",
            "--- Chunk 6244 ---\n",
            "one of the cases where the biological analogy was misleading.\n",
            "\n",
            "--- Chunk 6245 ---\n",
            "292 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 6246 ---\n",
            "multiple values at once), you need one output neuron per output dimension. For\n",
            "\n",
            "--- Chunk 6247 ---\n",
            "example, to locate the center of an object in an image, you need to predict 2D coordi‐\n",
            "\n",
            "--- Chunk 6248 ---\n",
            "nates, so you need two output neurons. If you also want to place a bounding box\n",
            "\n",
            "--- Chunk 6249 ---\n",
            "around the object, then you need two more numbers: the width and the height of the\n",
            "object. So, you end up with four output neurons.\n",
            "\n",
            "--- Chunk 6250 ---\n",
            "In general, when building an MLP for regression, you do not want to use any activa‐\n",
            "\n",
            "--- Chunk 6251 ---\n",
            "tion function for the output neurons, so they are free to output any range of values. If\n",
            "\n",
            "--- Chunk 6252 ---\n",
            "you want to guarantee that the output will always be positive, then you can use the\n",
            "\n",
            "--- Chunk 6253 ---\n",
            "ReLU activation function in the output layer. Alternatively, you can use the softplus\n",
            "\n",
            "--- Chunk 6254 ---\n",
            "activation function, which is a smooth variant of ReLU: softplus(z) = log(1 + exp(z)).\n",
            "\n",
            "--- Chunk 6255 ---\n",
            "It is close to 0 when z is negative, and close to z when z is positive. Finally, if you want\n",
            "\n",
            "--- Chunk 6256 ---\n",
            "to guarantee that the predictions will fall within a given range of values, then you can\n",
            "\n",
            "--- Chunk 6257 ---\n",
            "use the logistic function or the hyperbolic tangent, and then scale the labels to the\n",
            "\n",
            "--- Chunk 6258 ---\n",
            "appropriate range: 0 to 1 for the logistic function and –1 to 1 for the hyperbolic\n",
            "tangent.\n",
            "\n",
            "--- Chunk 6259 ---\n",
            "tangent.\n",
            "The loss function to use during training is typically the mean squared error, but if you\n",
            "\n",
            "--- Chunk 6260 ---\n",
            "have a lot of outliers in the training set, you may prefer to use the mean absolute\n",
            "\n",
            "--- Chunk 6261 ---\n",
            "error instead. Alternatively, you can use the Huber loss, which is a combination of\n",
            "both.\n",
            "\n",
            "--- Chunk 6262 ---\n",
            "The Huber loss is quadratic when the error is smaller than a thres‐\n",
            "hold δ (typically 1) but linear when the error is larger than δ. The\n",
            "\n",
            "--- Chunk 6263 ---\n",
            "linear part makes it less sensitive to outliers than the mean squared\n",
            "error, and the quadratic part allows it to converge faster and be\n",
            "\n",
            "--- Chunk 6264 ---\n",
            "more precise than the mean absolute error.\n",
            "\n",
            "--- Chunk 6265 ---\n",
            "Table 10-1 summarizes the typical architecture of a regression MLP.\n",
            "\n",
            "--- Chunk 6266 ---\n",
            "Table 10-1. Typical regression MLP architecture\n",
            "Hyperparameter Typical value\n",
            "# input neurons One per input feature (e.g., 28 x 28 = 784 for MNIST)\n",
            "\n",
            "--- Chunk 6267 ---\n",
            "# hidden layers Depends on the problem, but typically 1 to 5\n",
            "# neurons per hidden layer Depends on the problem, but typically 10 to 100\n",
            "\n",
            "--- Chunk 6268 ---\n",
            "# output neurons 1 per prediction dimension\n",
            "Hidden activation ReLU (or SELU, see Chapter 11)\n",
            "\n",
            "--- Chunk 6269 ---\n",
            "Output activation None, or ReLU/softplus (if positive outputs) or logistic/tanh (if bounded outputs)\n",
            "Loss function MSE or MAE/Huber (if outliers)\n",
            "\n",
            "--- Chunk 6270 ---\n",
            "From Biological to Artificial Neurons | 293\n",
            "\n",
            "--- Chunk 6271 ---\n",
            "Classification MLPs\n",
            "MLPs can also be used for classification tasks. For a binary classification problem,\n",
            "\n",
            "--- Chunk 6272 ---\n",
            "you just need a single output neuron using the logistic activation function: the output\n",
            "\n",
            "--- Chunk 6273 ---\n",
            "will be a number between 0 and 1, which you can interpret as the estimated probabil‐\n",
            "\n",
            "--- Chunk 6274 ---\n",
            "ity of the positive class. The estimated probability of the negative class is equal to one\n",
            "minus that number.\n",
            "\n",
            "--- Chunk 6275 ---\n",
            "minus that number.\n",
            "MLPs can also easily handle multilabel binary classification tasks (see Chapter 3). For\n",
            "\n",
            "--- Chunk 6276 ---\n",
            "example, you could have an email classification system that predicts whether each\n",
            "\n",
            "--- Chunk 6277 ---\n",
            "incoming email is ham or spam, and simultaneously predicts whether it is an urgent\n",
            "\n",
            "--- Chunk 6278 ---\n",
            "or nonurgent email. In this case, you would need two output neurons, both using the\n",
            "\n",
            "--- Chunk 6279 ---\n",
            "logistic activation function: the first would output the probability that the email is\n",
            "\n",
            "--- Chunk 6280 ---\n",
            "spam, and the second would output the probability that it is urgent. More generally,\n",
            "\n",
            "--- Chunk 6281 ---\n",
            "you would dedicate one output neuron for each positive class. Note that the output\n",
            "\n",
            "--- Chunk 6282 ---\n",
            "probabilities do not necessarily add up to 1. This lets the model output any combina‐\n",
            "\n",
            "--- Chunk 6283 ---\n",
            "tion of labels: you can have nonurgent ham, urgent ham, nonurgent spam, and per‐\n",
            "haps even urgent spam (although that would probably be an error).\n",
            "\n",
            "--- Chunk 6284 ---\n",
            "If each instance can belong only to a single class, out of three or more possible classes\n",
            "\n",
            "--- Chunk 6285 ---\n",
            "(e.g., classes 0 through 9 for digit image classification), then you need to have one\n",
            "\n",
            "--- Chunk 6286 ---\n",
            "output neuron per class, and you should use the softmax activation function for the\n",
            "\n",
            "--- Chunk 6287 ---\n",
            "whole output layer (see Figure 10-9). The softmax function (introduced in Chapter 4)\n",
            "\n",
            "--- Chunk 6288 ---\n",
            "will ensure that all the estimated probabilities are between 0 and 1 and that they add\n",
            "\n",
            "--- Chunk 6289 ---\n",
            "up to 1 (which is required if the classes are exclusive). This is called multiclass\n",
            "classification.\n",
            "\n",
            "--- Chunk 6290 ---\n",
            "Figure 10-9. A modern MLP (including ReLU and softmax) for classification\n",
            "\n",
            "294 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 6291 ---\n",
            "Regarding the loss function, since we are predicting probability distributions, the\n",
            "\n",
            "--- Chunk 6292 ---\n",
            "cross-entropy loss (also called the log loss, see Chapter 4) is generally a good choice.\n",
            "\n",
            "--- Chunk 6293 ---\n",
            "Table 10-2 summarizes the typical architecture of a classification MLP.\n",
            "\n",
            "--- Chunk 6294 ---\n",
            "Table 10-2. Typical classification MLP architecture\n",
            "Hyperparameter Binary classification Multilabel binary classification Multiclass classification\n",
            "\n",
            "--- Chunk 6295 ---\n",
            "Input and hidden layers Same as regression Same as regression Same as regression\n",
            "# output neurons 1 1 per label 1 per class\n",
            "\n",
            "--- Chunk 6296 ---\n",
            "Output layer activation Logistic Logistic Softmax\n",
            "Loss function Cross entropy Cross entropy Cross entropy\n",
            "\n",
            "--- Chunk 6297 ---\n",
            "Before we go on, I recommend you go through exercise 1 at the\n",
            "end of this chapter. You will play with various neural network\n",
            "\n",
            "--- Chunk 6298 ---\n",
            "architectures and visualize their outputs using the TensorFlow Play‐\n",
            "ground. This will be very useful to better understand MLPs, includ‐\n",
            "\n",
            "--- Chunk 6299 ---\n",
            "ing the effects of all the hyperparameters (number of layers and\n",
            "neurons, activation functions, and more).\n",
            "\n",
            "--- Chunk 6300 ---\n",
            "Now you have all the concepts you need to start implementing MLPs with Keras!\n",
            "\n",
            "--- Chunk 6301 ---\n",
            "Implementing MLPs with Keras\n",
            "Keras is a high-level Deep Learning API that allows you to easily build, train, evalu‐\n",
            "\n",
            "--- Chunk 6302 ---\n",
            "ate, and execute all sorts of neural networks. Its documentation (or specification) is\n",
            "\n",
            "--- Chunk 6303 ---\n",
            "available at https://keras.io/. The reference implementation, also called Keras, was\n",
            "\n",
            "--- Chunk 6304 ---\n",
            "developed by François Chollet as part of a research project13 and was released as an\n",
            "\n",
            "--- Chunk 6305 ---\n",
            "open source project in March 2015. It quickly gained popularity, owing to its ease of\n",
            "\n",
            "--- Chunk 6306 ---\n",
            "use, flexibility, and beautiful design. To perform the heavy computations required by\n",
            "\n",
            "--- Chunk 6307 ---\n",
            "neural networks, this reference implementation relies on a computation backend. At\n",
            "\n",
            "--- Chunk 6308 ---\n",
            "present, you can choose from three popular open source Deep Learning libraries:\n",
            "\n",
            "--- Chunk 6309 ---\n",
            "TensorFlow, Microsoft Cognitive Toolkit (CNTK), and Theano. Therefore, to avoid\n",
            "\n",
            "--- Chunk 6310 ---\n",
            "any confusion, we will refer to this reference implementation as multibackend Keras.\n",
            "\n",
            "--- Chunk 6311 ---\n",
            "Since late 2016, other implementations have been released. You can now run Keras on\n",
            "\n",
            "--- Chunk 6312 ---\n",
            "Apache MXNet, Apple’s Core ML, JavaScript or TypeScript (to run Keras code in a\n",
            "\n",
            "--- Chunk 6313 ---\n",
            "web browser), and PlaidML (which can run on all sorts of GPU devices, not just Nvi‐\n",
            "\n",
            "--- Chunk 6314 ---\n",
            "dia). Moreover, TensorFlow itself now comes bundled with its own Keras implemen‐\n",
            "\n",
            "--- Chunk 6315 ---\n",
            "tation, tf.keras. It only supports TensorFlow as the backend, but it has the advantage\n",
            "\n",
            "--- Chunk 6316 ---\n",
            "of offering some very useful extra features (see Figure 10-10): for example, it supports\n",
            "\n",
            "--- Chunk 6317 ---\n",
            "13 Project ONEIROS (Open-ended Neuro-Electronic Intelligent Robot Operating System).\n",
            "\n",
            "Implementing MLPs with Keras | 295\n",
            "\n",
            "--- Chunk 6318 ---\n",
            "TensorFlow’s Data API, which makes it easy to load and preprocess data efficiently.\n",
            "\n",
            "--- Chunk 6319 ---\n",
            "For this reason, we will use tf.keras in this book. However, in this chapter we will not\n",
            "\n",
            "--- Chunk 6320 ---\n",
            "use any of the TensorFlow-specific features, so the code should run fine on other\n",
            "\n",
            "--- Chunk 6321 ---\n",
            "Keras implementations as well (at least in Python), with only minor modifications,\n",
            "such as changing the imports.\n",
            "\n",
            "--- Chunk 6322 ---\n",
            "Figure 10-10. Two implementations of the Keras API: multibackend Keras (left) and\n",
            "tf.keras (right)\n",
            "\n",
            "--- Chunk 6323 ---\n",
            "The most popular Deep Learning library, after Keras and TensorFlow, is Facebook’s\n",
            "\n",
            "--- Chunk 6324 ---\n",
            "PyTorch library. The good news is that its API is quite similar to Keras’s (in part\n",
            "\n",
            "--- Chunk 6325 ---\n",
            "because both APIs were inspired by Scikit-Learn and Chainer), so once you know\n",
            "\n",
            "--- Chunk 6326 ---\n",
            "Keras, it is not difficult to switch to PyTorch, if you ever want to. PyTorch’s popularity\n",
            "\n",
            "--- Chunk 6327 ---\n",
            "grew exponentially in 2018, largely thanks to its simplicity and excellent documenta‐\n",
            "\n",
            "--- Chunk 6328 ---\n",
            "tion, which were not TensorFlow 1.x’s main strengths. However, TensorFlow 2 is\n",
            "\n",
            "--- Chunk 6329 ---\n",
            "arguably just as simple as PyTorch, as it has adopted Keras as its official high-level\n",
            "\n",
            "--- Chunk 6330 ---\n",
            "API and its developers have greatly simplified and cleaned up the rest of the API. The\n",
            "\n",
            "--- Chunk 6331 ---\n",
            "documentation has also been completely reorganized, and it is much easier to find\n",
            "\n",
            "--- Chunk 6332 ---\n",
            "what you need now. Similarly, PyTorch’s main weaknesses (e.g., limited portability\n",
            "\n",
            "--- Chunk 6333 ---\n",
            "and no computation graph analysis) have been largely addressed in PyTorch 1.0.\n",
            "Healthy competition is beneficial to everyone.\n",
            "\n",
            "--- Chunk 6334 ---\n",
            "All right, it’s time to code! As tf.keras is bundled with TensorFlow, let’s start by instal‐\n",
            "ling TensorFlow.\n",
            "\n",
            "--- Chunk 6335 ---\n",
            "Installing TensorFlow 2\n",
            "Assuming you installed Jupyter and Scikit-Learn by following the installation instruc‐\n",
            "\n",
            "--- Chunk 6336 ---\n",
            "tions in Chapter 2, use pip to install TensorFlow. If you created an isolated environ‐\n",
            "ment using virtualenv, you first need to activate it:\n",
            "\n",
            "--- Chunk 6337 ---\n",
            "296 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 6338 ---\n",
            "$ cd $ML_PATH                 # Your ML working directory (e.g., $HOME/ml)\n",
            "$ source my_env/bin/activate  # on Linux or macOS\n",
            "\n",
            "--- Chunk 6339 ---\n",
            "$ .\\my_env\\Scripts\\activate   # on Windows\n",
            "\n",
            "--- Chunk 6340 ---\n",
            "Next, install TensorFlow 2 (if you are not using a virtualenv, you will need adminis‐\n",
            "trator rights, or to add the --user option):\n",
            "\n",
            "--- Chunk 6341 ---\n",
            "$ python3 -m pip install -U tensorflow\n",
            "\n",
            "--- Chunk 6342 ---\n",
            "For GPU support, at the time of this writing you need to install\n",
            "tensorflow-gpu instead of tensorflow, but the TensorFlow team\n",
            "\n",
            "--- Chunk 6343 ---\n",
            "is working on having a single library that will support both CPU-\n",
            "only and GPU-equipped systems. You will still need to install extra\n",
            "\n",
            "--- Chunk 6344 ---\n",
            "libraries for GPU support (see https://tensorflow.org/install for\n",
            "more details). We will look at GPUs in more depth in Chapter 19.\n",
            "\n",
            "--- Chunk 6345 ---\n",
            "To test your installation, open a Python shell or a Jupyter notebook, then import\n",
            "TensorFlow and tf.keras and print their versions:\n",
            "\n",
            "--- Chunk 6346 ---\n",
            ">>> import tensorflow as tf\n",
            ">>> from tensorflow import keras\n",
            ">>> tf.__version__\n",
            "'2.0.0'\n",
            ">>> keras.__version__\n",
            "'2.2.4-tf'\n",
            "\n",
            "--- Chunk 6347 ---\n",
            "The second version is the version of the Keras API implemented by tf.keras. Note that\n",
            "\n",
            "--- Chunk 6348 ---\n",
            "it ends with -tf, highlighting the fact that tf.keras implements the Keras API, plus\n",
            "some extra TensorFlow-specific features.\n",
            "\n",
            "--- Chunk 6349 ---\n",
            "Now let’s use tf.keras! We’ll start by building a simple image classifier.\n",
            "\n",
            "--- Chunk 6350 ---\n",
            "Building an Image Classifier Using the Sequential API\n",
            "First, we need to load a dataset. In this chapter we will tackle Fashion MNIST, which\n",
            "\n",
            "--- Chunk 6351 ---\n",
            "is a drop-in replacement of MNIST (introduced in Chapter 3). It has the exact same\n",
            "\n",
            "--- Chunk 6352 ---\n",
            "format as MNIST (70,000 grayscale images of 28 × 28 pixels each, with 10 classes),\n",
            "\n",
            "--- Chunk 6353 ---\n",
            "but the images represent fashion items rather than handwritten digits, so each class is\n",
            "\n",
            "--- Chunk 6354 ---\n",
            "more diverse, and the problem turns out to be significantly more challenging than\n",
            "\n",
            "--- Chunk 6355 ---\n",
            "MNIST. For example, a simple linear model reaches about 92% accuracy on MNIST,\n",
            "but only about 83% on Fashion MNIST.\n",
            "\n",
            "--- Chunk 6356 ---\n",
            "Using Keras to load the dataset\n",
            "Keras provides some utility functions to fetch and load common datasets, including\n",
            "\n",
            "--- Chunk 6357 ---\n",
            "MNIST, Fashion MNIST, and the California housing dataset we used in Chapter 2.\n",
            "Let’s load Fashion MNIST:\n",
            "\n",
            "--- Chunk 6358 ---\n",
            "Implementing MLPs with Keras | 297\n",
            "\n",
            "--- Chunk 6359 ---\n",
            "fashion_mnist = keras.datasets.fashion_mnist\n",
            "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
            "\n",
            "--- Chunk 6360 ---\n",
            "When loading MNIST or Fashion MNIST using Keras rather than Scikit-Learn, one\n",
            "\n",
            "--- Chunk 6361 ---\n",
            "important difference is that every image is represented as a 28 × 28 array rather than\n",
            "\n",
            "--- Chunk 6362 ---\n",
            "a 1D array of size 784. Moreover, the pixel intensities are represented as integers\n",
            "\n",
            "--- Chunk 6363 ---\n",
            "(from 0 to 255) rather than floats (from 0.0 to 255.0). Let’s take a look at the shape\n",
            "and data type of the training set:\n",
            "\n",
            "--- Chunk 6364 ---\n",
            ">>> X_train_full.shape\n",
            "(60000, 28, 28)\n",
            ">>> X_train_full.dtype\n",
            "dtype('uint8')\n",
            "\n",
            "--- Chunk 6365 ---\n",
            "Note that the dataset is already split into a training set and a test set, but there is no\n",
            "\n",
            "--- Chunk 6366 ---\n",
            "validation set, so we’ll create one now. Additionally, since we are going to train the\n",
            "\n",
            "--- Chunk 6367 ---\n",
            "neural network using Gradient Descent, we must scale the input features. For simplic‐\n",
            "\n",
            "--- Chunk 6368 ---\n",
            "ity, we’ll scale the pixel intensities down to the 0–1 range by dividing them by 255.0\n",
            "(this also converts them to floats):\n",
            "\n",
            "--- Chunk 6369 ---\n",
            "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
            "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
            "\n",
            "--- Chunk 6370 ---\n",
            "With MNIST, when the label is equal to 5, it means that the image represents the\n",
            "\n",
            "--- Chunk 6371 ---\n",
            "handwritten digit 5. Easy. For Fashion MNIST, however, we need the list of class\n",
            "names to know what we are dealing with:\n",
            "\n",
            "--- Chunk 6372 ---\n",
            "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
            "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
            "\n",
            "--- Chunk 6373 ---\n",
            "For example, the first image in the training set represents a coat:\n",
            ">>> class_names[y_train[0]]\n",
            "'Coat'\n",
            "\n",
            "--- Chunk 6374 ---\n",
            "Figure 10-11 shows some samples from the Fashion MNIST dataset.\n",
            "\n",
            "Figure 10-11. Samples from Fashion MNIST\n",
            "\n",
            "--- Chunk 6375 ---\n",
            "298 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 6376 ---\n",
            "Creating the model using the Sequential API\n",
            "Now let’s build the neural network! Here is a classification MLP with two hidden\n",
            "layers:\n",
            "\n",
            "--- Chunk 6377 ---\n",
            "model = keras.models.Sequential()\n",
            "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
            "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
            "\n",
            "--- Chunk 6378 ---\n",
            "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
            "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
            "\n",
            "--- Chunk 6379 ---\n",
            "Let’s go through this code line by line:\n",
            "\n",
            "--- Chunk 6380 ---\n",
            "• The first line creates a Sequential model. This is the simplest kind of Keras\n",
            "\n",
            "--- Chunk 6381 ---\n",
            "model for neural networks that are just composed of a single stack of layers con‐\n",
            "nected sequentially. This is called the Sequential API.\n",
            "\n",
            "--- Chunk 6382 ---\n",
            "• Next, we build the first layer and add it to the model. It is a Flatten layer whose\n",
            "\n",
            "--- Chunk 6383 ---\n",
            "role is to convert each input image into a 1D array: if it receives input data X, it\n",
            "\n",
            "--- Chunk 6384 ---\n",
            "computes X.reshape(-1, 1). This layer does not have any parameters; it is just\n",
            "\n",
            "--- Chunk 6385 ---\n",
            "there to do some simple preprocessing. Since it is the first layer in the model, you\n",
            "\n",
            "--- Chunk 6386 ---\n",
            "should specify the input_shape, which doesn’t include the batch size, only the\n",
            "\n",
            "--- Chunk 6387 ---\n",
            "shape of the instances. Alternatively, you could add a keras.layers.InputLayer\n",
            "as the first layer, setting input_shape=[28,28].\n",
            "\n",
            "--- Chunk 6388 ---\n",
            "• Next we add a Dense hidden layer with 300 neurons. It will use the ReLU activa‐\n",
            "\n",
            "--- Chunk 6389 ---\n",
            "tion function. Each Dense layer manages its own weight matrix, containing all the\n",
            "\n",
            "--- Chunk 6390 ---\n",
            "connection weights between the neurons and their inputs. It also manages a vec‐\n",
            "\n",
            "--- Chunk 6391 ---\n",
            "tor of bias terms (one per neuron). When it receives some input data, it computes\n",
            "Equation 10-2.\n",
            "\n",
            "--- Chunk 6392 ---\n",
            "• Then we add a second Dense hidden layer with 100 neurons, also using the ReLU\n",
            "activation function.\n",
            "\n",
            "--- Chunk 6393 ---\n",
            "• Finally, we add a Dense output layer with 10 neurons (one per class), using the\n",
            "softmax activation function (because the classes are exclusive).\n",
            "\n",
            "--- Chunk 6394 ---\n",
            "Specifying activation=\"relu\" is equivalent to specifying activa\n",
            "tion=keras.activations.relu. Other activation functions are\n",
            "\n",
            "--- Chunk 6395 ---\n",
            "available in the keras.activations package, we will use many of\n",
            "them in this book. See https://keras.io/activations/ for the full list.\n",
            "\n",
            "--- Chunk 6396 ---\n",
            "Instead of adding the layers one by one as we just did, you can pass a list of layers\n",
            "when creating the Sequential model:\n",
            "\n",
            "--- Chunk 6397 ---\n",
            "Implementing MLPs with Keras | 299\n",
            "\n",
            "--- Chunk 6398 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.Flatten(input_shape=[28, 28]),\n",
            "    keras.layers.Dense(300, activation=\"relu\"),\n",
            "\n",
            "--- Chunk 6399 ---\n",
            "keras.layers.Dense(100, activation=\"relu\"),\n",
            "    keras.layers.Dense(10, activation=\"softmax\")\n",
            "])\n",
            "\n",
            "--- Chunk 6400 ---\n",
            "Using Code Examples from keras.io\n",
            "Code examples documented on keras.io will work fine with tf.keras, but you need to\n",
            "\n",
            "--- Chunk 6401 ---\n",
            "change the imports. For example, consider this keras.io code:\n",
            "\n",
            "--- Chunk 6402 ---\n",
            "from keras.layers import Dense\n",
            "output_layer = Dense(10)\n",
            "\n",
            "--- Chunk 6403 ---\n",
            "You must change the imports like this:\n",
            "from tensorflow.keras.layers import Dense\n",
            "output_layer = Dense(10)\n",
            "\n",
            "--- Chunk 6404 ---\n",
            "Or simply use full paths, if you prefer:\n",
            "from tensorflow import keras\n",
            "output_layer = keras.layers.Dense(10)\n",
            "\n",
            "--- Chunk 6405 ---\n",
            "This approach is more verbose, but I use it in this book so you can easily see which\n",
            "\n",
            "--- Chunk 6406 ---\n",
            "packages to use, and to avoid confusion between standard classes and custom classes.\n",
            "\n",
            "--- Chunk 6407 ---\n",
            "In production code, I prefer the previous approach. Many people also use from ten\n",
            "sorflow.keras import layers followed by layers.Dense(10).\n",
            "\n",
            "--- Chunk 6408 ---\n",
            "The model’s summary() method displays all the model’s layers,14 including each layer’s\n",
            "\n",
            "--- Chunk 6409 ---\n",
            "name (which is automatically generated unless you set it when creating the layer), its\n",
            "\n",
            "--- Chunk 6410 ---\n",
            "output shape (None means the batch size can be anything), and its number of parame‐\n",
            "\n",
            "--- Chunk 6411 ---\n",
            "ters. The summary ends with the total number of parameters, including trainable and\n",
            "\n",
            "--- Chunk 6412 ---\n",
            "non-trainable parameters. Here we only have trainable parameters (we will see exam‐\n",
            "ples of non-trainable parameters in Chapter 11):\n",
            "\n",
            "--- Chunk 6413 ---\n",
            ">>> model.summary()\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "\n",
            "--- Chunk 6414 ---\n",
            "Layer (type)                 Output Shape              Param #\n",
            "=================================================================\n",
            "\n",
            "--- Chunk 6415 ---\n",
            "flatten (Flatten)            (None, 784)               0\n",
            "_________________________________________________________________\n",
            "\n",
            "--- Chunk 6416 ---\n",
            "dense (Dense)                (None, 300)               235500\n",
            "_________________________________________________________________\n",
            "\n",
            "--- Chunk 6417 ---\n",
            "14 You can use keras.utils.plot_model() to generate an image of your model.\n",
            "\n",
            "300 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 6418 ---\n",
            "dense_1 (Dense)              (None, 100)               30100\n",
            "_________________________________________________________________\n",
            "\n",
            "--- Chunk 6419 ---\n",
            "dense_2 (Dense)              (None, 10)                1010\n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "\n",
            "--- Chunk 6420 ---\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "--- Chunk 6421 ---\n",
            "Note that Dense layers often have a lot of parameters. For example, the first hidden\n",
            "\n",
            "--- Chunk 6422 ---\n",
            "layer has 784 × 300 connection weights, plus 300 bias terms, which adds up to\n",
            "\n",
            "--- Chunk 6423 ---\n",
            "235,500 parameters! This gives the model quite a lot of flexibility to fit the training\n",
            "\n",
            "--- Chunk 6424 ---\n",
            "data, but it also means that the model runs the risk of overfitting, especially when you\n",
            "\n",
            "--- Chunk 6425 ---\n",
            "do not have a lot of training data. We will come back to this later.\n",
            "\n",
            "--- Chunk 6426 ---\n",
            "You can easily get a model’s list of layers, to fetch a layer by its index, or you can fetch\n",
            "it by name:\n",
            "\n",
            "--- Chunk 6427 ---\n",
            ">>> model.layers\n",
            "[<tensorflow.python.keras.layers.core.Flatten at 0x132414e48>,\n",
            " <tensorflow.python.keras.layers.core.Dense at 0x1324149b0>,\n",
            "\n",
            "--- Chunk 6428 ---\n",
            "<tensorflow.python.keras.layers.core.Dense at 0x1356ba8d0>,\n",
            " <tensorflow.python.keras.layers.core.Dense at 0x13240d240>]\n",
            "\n",
            "--- Chunk 6429 ---\n",
            ">>> hidden1 = model.layers[1]\n",
            ">>> hidden1.name\n",
            "'dense'\n",
            ">>> model.get_layer('dense') is hidden1\n",
            "True\n",
            "\n",
            "--- Chunk 6430 ---\n",
            "All the parameters of a layer can be accessed using its get_weights() and\n",
            "\n",
            "--- Chunk 6431 ---\n",
            "set_weights() methods. For a Dense layer, this includes both the connection weights\n",
            "and the bias terms:\n",
            "\n",
            "--- Chunk 6432 ---\n",
            ">>> weights, biases = hidden1.get_weights()\n",
            ">>> weights\n",
            "array([[ 0.02448617, -0.00877795, -0.02189048, ..., -0.02766046,\n",
            "\n",
            "--- Chunk 6433 ---\n",
            "0.03859074, -0.06889391],\n",
            "       ...,\n",
            "       [-0.06022581,  0.01577859, -0.02585464, ..., -0.00527829,\n",
            "\n",
            "--- Chunk 6434 ---\n",
            "0.00272203, -0.06793761]], dtype=float32)\n",
            ">>> weights.shape\n",
            "(784, 300)\n",
            ">>> biases\n",
            "\n",
            "--- Chunk 6435 ---\n",
            ">>> biases\n",
            "array([0., 0., 0., 0., 0., 0., 0., 0., 0., ...,  0., 0., 0.], dtype=float32)\n",
            ">>> biases.shape\n",
            "(300,)\n",
            "\n",
            "--- Chunk 6436 ---\n",
            "Notice that the Dense layer initialized the connection weights randomly (which is\n",
            "\n",
            "--- Chunk 6437 ---\n",
            "needed to break symmetry, as we discussed earlier), and the biases were initialized to\n",
            "\n",
            "--- Chunk 6438 ---\n",
            "zeros, which is fine. If you ever want to use a different initialization method, you can\n",
            "\n",
            "--- Chunk 6439 ---\n",
            "set kernel_initializer (kernel is another name for the matrix of connection\n",
            "\n",
            "--- Chunk 6440 ---\n",
            "Implementing MLPs with Keras | 301\n",
            "\n",
            "--- Chunk 6441 ---\n",
            "weights) or bias_initializer when creating the layer. We will discuss initializers\n",
            "\n",
            "--- Chunk 6442 ---\n",
            "further in Chapter 11, but if you want the full list, see https://keras.io/initializers/.\n",
            "\n",
            "--- Chunk 6443 ---\n",
            "The shape of the weight matrix depends on the number of inputs.\n",
            "This is why it is recommended to specify the input_shape when\n",
            "\n",
            "--- Chunk 6444 ---\n",
            "creating the first layer in a Sequential model. However, if you do\n",
            "not specify the input shape, it’s OK: Keras will simply wait until it\n",
            "\n",
            "--- Chunk 6445 ---\n",
            "knows the input shape before it actually builds the model. This will\n",
            "happen either when you feed it actual data (e.g., during training),\n",
            "\n",
            "--- Chunk 6446 ---\n",
            "or when you call its build() method. Until the model is really\n",
            "built, the layers will not have any weights, and you will not be able\n",
            "\n",
            "--- Chunk 6447 ---\n",
            "to do certain things (such as print the model summary or save the\n",
            "model). So, if you know the input shape when creating the model,\n",
            "\n",
            "--- Chunk 6448 ---\n",
            "it is best to specify it.\n",
            "\n",
            "--- Chunk 6449 ---\n",
            "Compiling the model\n",
            "After a model is created, you must call its compile() method to specify the loss func‐\n",
            "\n",
            "--- Chunk 6450 ---\n",
            "tion and the optimizer to use. Optionally, you can specify a list of extra metrics to\n",
            "compute during training and evaluation:\n",
            "\n",
            "--- Chunk 6451 ---\n",
            "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
            "              optimizer=\"sgd\",\n",
            "              metrics=[\"accuracy\"])\n",
            "\n",
            "--- Chunk 6452 ---\n",
            "Using loss=\"sparse_categorical_crossentropy\" is equivalent to\n",
            "using loss=keras.losses.sparse_categorical_crossentropy.\n",
            "\n",
            "--- Chunk 6453 ---\n",
            "Similarly, specifying optimizer=\"sgd\" is equivalent to specifying\n",
            "optimizer=keras.optimizers.SGD(), and metrics=[\"accuracy\"]\n",
            "\n",
            "--- Chunk 6454 ---\n",
            "is equivalent to metrics=[keras.metrics.sparse_categori\n",
            "cal_accuracy] (when using this loss). We will use many other los‐\n",
            "\n",
            "--- Chunk 6455 ---\n",
            "ses, optimizers, and metrics in this book; for the full lists, see\n",
            "https://keras.io/losses, https://keras.io/optimizers, and https://\n",
            "\n",
            "--- Chunk 6456 ---\n",
            "keras.io/metrics.\n",
            "\n",
            "--- Chunk 6457 ---\n",
            "This code requires some explanation. First, we use the \"sparse_categorical_cross\n",
            "\n",
            "--- Chunk 6458 ---\n",
            "entropy\" loss because we have sparse labels (i.e., for each instance, there is just a tar‐\n",
            "\n",
            "--- Chunk 6459 ---\n",
            "get class index, from 0 to 9 in this case), and the classes are exclusive. If instead we\n",
            "\n",
            "--- Chunk 6460 ---\n",
            "had one target probability per class for each instance (such as one-hot vectors, e.g.\n",
            "\n",
            "--- Chunk 6461 ---\n",
            "[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.] to represent class 3), then we would\n",
            "\n",
            "--- Chunk 6462 ---\n",
            "need to use the \"categorical_crossentropy\" loss instead. If we were doing binary\n",
            "\n",
            "--- Chunk 6463 ---\n",
            "classification (with one or more binary labels), then we would use the \"sigmoid\" (i.e.,\n",
            "\n",
            "--- Chunk 6464 ---\n",
            "logistic) activation function in the output layer instead of the \"softmax\" activation\n",
            "function, and we would use the \"binary_crossentropy\" loss.\n",
            "\n",
            "--- Chunk 6465 ---\n",
            "302 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 6466 ---\n",
            "If you want to convert sparse labels (i.e., class indices) to one-hot\n",
            "vector labels, use the keras.utils.to_categorical() function. To\n",
            "\n",
            "--- Chunk 6467 ---\n",
            "go the other way round, use the np.argmax() function with\n",
            "axis=1.\n",
            "\n",
            "--- Chunk 6468 ---\n",
            "Regarding the optimizer, \"sgd\" means that we will train the model using simple Sto‐\n",
            "\n",
            "--- Chunk 6469 ---\n",
            "chastic Gradient Descent. In other words, Keras will perform the backpropagation\n",
            "\n",
            "--- Chunk 6470 ---\n",
            "algorithm described earlier (i.e., reverse-mode autodiff plus Gradient Descent). We\n",
            "\n",
            "--- Chunk 6471 ---\n",
            "will discuss more efficient optimizers in Chapter 11 (they improve the Gradient\n",
            "Descent part, not the autodiff).\n",
            "\n",
            "--- Chunk 6472 ---\n",
            "When using the SGD optimizer, it is important to tune the learning\n",
            "rate. So, you will generally want to use optimizer=keras.optimiz\n",
            "\n",
            "--- Chunk 6473 ---\n",
            "ers.SGD(lr=???) to set the learning rate, rather than opti\n",
            "mizer=\"sgd\", which defaults to lr=0.01.\n",
            "\n",
            "--- Chunk 6474 ---\n",
            "Finally, since this is a classifier, it’s useful to measure its \"accuracy\" during training\n",
            "and evaluation.\n",
            "\n",
            "--- Chunk 6475 ---\n",
            "Training and evaluating the model\n",
            "Now the model is ready to be trained. For this we simply need to call its fit()\n",
            "method:\n",
            "\n",
            "--- Chunk 6476 ---\n",
            ">>> history = model.fit(X_train, y_train, epochs=30,\n",
            "...                     validation_data=(X_valid, y_valid))\n",
            "...\n",
            "\n",
            "--- Chunk 6477 ---\n",
            "...\n",
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "55000/55000 [======] - 3s 49us/sample - loss: 0.7218     - accuracy: 0.7660\n",
            "\n",
            "--- Chunk 6478 ---\n",
            "- val_loss: 0.4973 - val_accuracy: 0.8366\n",
            "Epoch 2/30\n",
            "\n",
            "--- Chunk 6479 ---\n",
            "Epoch 2/30\n",
            "55000/55000 [======] - 2s 45us/sample - loss: 0.4840     - accuracy: 0.8327\n",
            "\n",
            "--- Chunk 6480 ---\n",
            "- val_loss: 0.4456 - val_accuracy: 0.8480\n",
            "[...]\n",
            "Epoch 30/30\n",
            "\n",
            "--- Chunk 6481 ---\n",
            "[...]\n",
            "Epoch 30/30\n",
            "55000/55000 [======] - 3s 53us/sample - loss: 0.2252     - accuracy: 0.9192\n",
            "\n",
            "--- Chunk 6482 ---\n",
            "- val_loss: 0.2999 - val_accuracy: 0.8926\n",
            "\n",
            "--- Chunk 6483 ---\n",
            "We pass it the input features (X_train) and the target classes (y_train), as well as the\n",
            "\n",
            "--- Chunk 6484 ---\n",
            "number of epochs to train (or else it would default to just 1, which would definitely\n",
            "\n",
            "--- Chunk 6485 ---\n",
            "not be enough to converge to a good solution). We also pass a validation set (this is\n",
            "\n",
            "--- Chunk 6486 ---\n",
            "optional). Keras will measure the loss and the extra metrics on this set at the end of\n",
            "\n",
            "--- Chunk 6487 ---\n",
            "each epoch, which is very useful to see how well the model really performs. If the per‐\n",
            "\n",
            "--- Chunk 6488 ---\n",
            "formance on the training set is much better than on the validation set, your model is\n",
            "\n",
            "--- Chunk 6489 ---\n",
            "Implementing MLPs with Keras | 303\n",
            "\n",
            "--- Chunk 6490 ---\n",
            "probably overfitting the training set (or there is a bug, such as a data mismatch\n",
            "between the training set and the validation set).\n",
            "\n",
            "--- Chunk 6491 ---\n",
            "And that’s it! The neural network is trained.15 At each epoch during training, Keras\n",
            "\n",
            "--- Chunk 6492 ---\n",
            "displays the number of instances processed so far (along with a progress bar), the\n",
            "\n",
            "--- Chunk 6493 ---\n",
            "mean training time per sample, and the loss and accuracy (or any other extra metrics\n",
            "\n",
            "--- Chunk 6494 ---\n",
            "you asked for) on both the training set and the validation set. You can see that the\n",
            "\n",
            "--- Chunk 6495 ---\n",
            "training loss went down, which is a good sign, and the validation accuracy reached\n",
            "\n",
            "--- Chunk 6496 ---\n",
            "89.26% after 30 epochs. That’s not too far from the training accuracy, so there does\n",
            "not seem to be much overfitting going on.\n",
            "\n",
            "--- Chunk 6497 ---\n",
            "Instead of passing a validation set using the validation_data\n",
            "argument, you could set validation_split to the ratio of the\n",
            "\n",
            "--- Chunk 6498 ---\n",
            "training set that you want Keras to use for validation. For example,\n",
            "validation_split=0.1 tells Keras to use the last 10% of the data\n",
            "\n",
            "--- Chunk 6499 ---\n",
            "(before shuffling) for validation.\n",
            "\n",
            "--- Chunk 6500 ---\n",
            "If the training set was very skewed, with some classes being overrepresented and oth‐\n",
            "\n",
            "--- Chunk 6501 ---\n",
            "ers underrepresented, it would be useful to set the class_weight argument when\n",
            "\n",
            "--- Chunk 6502 ---\n",
            "calling the fit() method, which would give a larger weight to underrepresented\n",
            "\n",
            "--- Chunk 6503 ---\n",
            "classes and a lower weight to overrepresented classes. These weights would be used by\n",
            "\n",
            "--- Chunk 6504 ---\n",
            "Keras when computing the loss. If you need per-instance weights, set the sam\n",
            "\n",
            "--- Chunk 6505 ---\n",
            "ple_weight argument (if both class_weight and sample_weight are provided, Keras\n",
            "\n",
            "--- Chunk 6506 ---\n",
            "multiplies them). Per-instance weights could be useful if some instances were labeled\n",
            "\n",
            "--- Chunk 6507 ---\n",
            "by experts while others were labeled using a crowdsourcing platform: you might want\n",
            "\n",
            "--- Chunk 6508 ---\n",
            "to give more weight to the former. You can also provide sample weights (but not class\n",
            "\n",
            "--- Chunk 6509 ---\n",
            "weights) for the validation set by adding them as a third item in the validation_data\n",
            "tuple.\n",
            "\n",
            "--- Chunk 6510 ---\n",
            "tuple.\n",
            "The fit() method returns a History object containing the training parameters\n",
            "\n",
            "--- Chunk 6511 ---\n",
            "(history.params), the list of epochs it went through (history.epoch), and most\n",
            "\n",
            "--- Chunk 6512 ---\n",
            "importantly a dictionary (history.history) containing the loss and extra metrics it\n",
            "\n",
            "--- Chunk 6513 ---\n",
            "measured at the end of each epoch on the training set and on the validation set (if\n",
            "\n",
            "--- Chunk 6514 ---\n",
            "any). If you use this dictionary to create a pandas DataFrame and call its plot()\n",
            "method, you get the learning curves shown in Figure 10-12:\n",
            "\n",
            "--- Chunk 6515 ---\n",
            "15 If your training or validation data does not match the expected shape, you will get an exception. This is per‐\n",
            "\n",
            "--- Chunk 6516 ---\n",
            "haps the most common error, so you should get familiar with the error message. The message is actually quite\n",
            "\n",
            "--- Chunk 6517 ---\n",
            "clear: for example, if you try to train this model with an array containing flattened images\n",
            "\n",
            "--- Chunk 6518 ---\n",
            "(X_train.reshape(-1, 784)), then you will get the following exception: “ValueError: Error when checking\n",
            "\n",
            "--- Chunk 6519 ---\n",
            "input: expected flatten_input to have 3 dimensions, but got array with shape (60000, 784).”\n",
            "\n",
            "--- Chunk 6520 ---\n",
            "304 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "\n",
            "\n",
            "import pandas as pd\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "--- Chunk 6521 ---\n",
            "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
            "plt.grid(True)\n",
            "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
            "plt.show()\n",
            "\n",
            "--- Chunk 6522 ---\n",
            "Figure 10-12. Learning curves: the mean training loss and accuracy measured over each\n",
            "\n",
            "--- Chunk 6523 ---\n",
            "epoch, and the mean validation loss and accuracy measured at the end of each epoch\n",
            "\n",
            "--- Chunk 6524 ---\n",
            "You can see that both the training accuracy and the validation accuracy steadily\n",
            "\n",
            "--- Chunk 6525 ---\n",
            "increase during training, while the training loss and the validation loss decrease.\n",
            "\n",
            "--- Chunk 6526 ---\n",
            "Good! Moreover, the validation curves are close to the training curves, which means\n",
            "\n",
            "--- Chunk 6527 ---\n",
            "that there is not too much overfitting. In this particular case, the model looks like it\n",
            "\n",
            "--- Chunk 6528 ---\n",
            "performed better on the validation set than on the training set at the beginning of\n",
            "\n",
            "--- Chunk 6529 ---\n",
            "training. But that’s not the case: indeed, the validation error is computed at the end of\n",
            "\n",
            "--- Chunk 6530 ---\n",
            "each epoch, while the training error is computed using a running mean during each\n",
            "\n",
            "--- Chunk 6531 ---\n",
            "epoch. So the training curve should be shifted by half an epoch to the left. If you do\n",
            "\n",
            "--- Chunk 6532 ---\n",
            "that, you will see that the training and validation curves overlap almost perfectly at\n",
            "the beginning of training.\n",
            "\n",
            "--- Chunk 6533 ---\n",
            "When plotting the training curve, it should be shifted by half an\n",
            "epoch to the left.\n",
            "\n",
            "Implementing MLPs with Keras | 305\n",
            "\n",
            "--- Chunk 6534 ---\n",
            "The training set performance ends up beating the validation performance, as is gen‐\n",
            "\n",
            "--- Chunk 6535 ---\n",
            "erally the case when you train for long enough. You can tell that the model has not\n",
            "\n",
            "--- Chunk 6536 ---\n",
            "quite converged yet, as the validation loss is still going down, so you should probably\n",
            "\n",
            "--- Chunk 6537 ---\n",
            "continue training. It’s as simple as calling the fit() method again, since Keras just\n",
            "\n",
            "--- Chunk 6538 ---\n",
            "continues training where it left off (you should be able to reach close to 89% valida‐\n",
            "tion accuracy).\n",
            "\n",
            "--- Chunk 6539 ---\n",
            "tion accuracy).\n",
            "If you are not satisfied with the performance of your model, you should go back and\n",
            "\n",
            "--- Chunk 6540 ---\n",
            "tune the hyperparameters. The first one to check is the learning rate. If that doesn’t\n",
            "\n",
            "--- Chunk 6541 ---\n",
            "help, try another optimizer (and always retune the learning rate after changing any\n",
            "\n",
            "--- Chunk 6542 ---\n",
            "hyperparameter). If the performance is still not great, then try tuning model hyper‐\n",
            "\n",
            "--- Chunk 6543 ---\n",
            "parameters such as the number of layers, the number of neurons per layer, and the\n",
            "\n",
            "--- Chunk 6544 ---\n",
            "types of activation functions to use for each hidden layer. You can also try tuning\n",
            "\n",
            "--- Chunk 6545 ---\n",
            "other hyperparameters, such as the batch size (it can be set in the fit() method using\n",
            "\n",
            "--- Chunk 6546 ---\n",
            "the batch_size argument, which defaults to 32). We will get back to hyperparameter\n",
            "\n",
            "--- Chunk 6547 ---\n",
            "tuning at the end of this chapter. Once you are satisfied with your model’s validation\n",
            "\n",
            "--- Chunk 6548 ---\n",
            "accuracy, you should evaluate it on the test set to estimate the generalization error\n",
            "\n",
            "--- Chunk 6549 ---\n",
            "before you deploy the model to production. You can easily do this using the evalu\n",
            "\n",
            "--- Chunk 6550 ---\n",
            "ate() method (it also supports several other arguments, such as batch_size and\n",
            "sample_weight; please check the documentation for more details):\n",
            "\n",
            "--- Chunk 6551 ---\n",
            ">>> model.evaluate(X_test, y_test)\n",
            "10000/10000 [==========] - 0s 29us/sample - loss: 0.3340 - accuracy: 0.8851\n",
            "[0.3339798209667206, 0.8851]\n",
            "\n",
            "--- Chunk 6552 ---\n",
            "As we saw in Chapter 2, it is common to get slightly lower performance on the test set\n",
            "\n",
            "--- Chunk 6553 ---\n",
            "than on the validation set, because the hyperparameters are tuned on the validation\n",
            "\n",
            "--- Chunk 6554 ---\n",
            "set, not the test set (however, in this example, we did not do any hyperparameter tun‐\n",
            "\n",
            "--- Chunk 6555 ---\n",
            "ing, so the lower accuracy is just bad luck). Remember to resist the temptation to\n",
            "\n",
            "--- Chunk 6556 ---\n",
            "tweak the hyperparameters on the test set, or else your estimate of the generalization\n",
            "error will be too optimistic.\n",
            "\n",
            "--- Chunk 6557 ---\n",
            "Using the model to make predictions\n",
            "Next, we can use the model’s predict() method to make predictions on new instan‐\n",
            "\n",
            "--- Chunk 6558 ---\n",
            "ces. Since we don’t have actual new instances, we will just use the first three instances\n",
            "of the test set:\n",
            "\n",
            "--- Chunk 6559 ---\n",
            ">>> X_new = X_test[:3]\n",
            ">>> y_proba = model.predict(X_new)\n",
            ">>> y_proba.round(2)\n",
            "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.01, 0.  , 0.96],\n",
            "\n",
            "--- Chunk 6560 ---\n",
            "[0.  , 0.  , 0.98, 0.  , 0.02, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
            "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
            "\n",
            "--- Chunk 6561 ---\n",
            "dtype=float32)\n",
            "\n",
            "--- Chunk 6562 ---\n",
            "306 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 6563 ---\n",
            "As you can see, for each instance the model estimates one probability per class, from\n",
            "\n",
            "--- Chunk 6564 ---\n",
            "class 0 to class 9. For example, for the first image it estimates that the probability of\n",
            "\n",
            "--- Chunk 6565 ---\n",
            "class 9 (ankle boot) is 96%, the probability of class 5 (sandal) is 3%, the probability of\n",
            "\n",
            "--- Chunk 6566 ---\n",
            "class 7 (sneaker) is 1%, and the probabilities of the other classes are negligible. In\n",
            "\n",
            "--- Chunk 6567 ---\n",
            "other words, it “believes” the first image is footwear, most likely ankle boots but pos‐\n",
            "\n",
            "--- Chunk 6568 ---\n",
            "sibly sandals or sneakers. If you only care about the class with the highest estimated\n",
            "\n",
            "--- Chunk 6569 ---\n",
            "probability (even if that probability is quite low), then you can use the pre\n",
            "dict_classes() method instead:\n",
            "\n",
            "--- Chunk 6570 ---\n",
            ">>> y_pred = model.predict_classes(X_new)\n",
            ">>> y_pred\n",
            "array([9, 2, 1])\n",
            ">>> np.array(class_names)[y_pred]\n",
            "\n",
            "--- Chunk 6571 ---\n",
            "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')\n",
            "\n",
            "--- Chunk 6572 ---\n",
            "Here, the classifier actually classified all three images correctly (these images are\n",
            "shown in Figure 10-13):\n",
            "\n",
            "--- Chunk 6573 ---\n",
            ">>> y_new = y_test[:3]\n",
            ">>> y_new\n",
            "array([9, 2, 1])\n",
            "\n",
            "Figure 10-13. Correctly classified Fashion MNIST images\n",
            "\n",
            "--- Chunk 6574 ---\n",
            "Now you know how to use the Sequential API to build, train, evaluate, and use a clas‐\n",
            "sification MLP. But what about regression?\n",
            "\n",
            "--- Chunk 6575 ---\n",
            "Building a Regression MLP Using the Sequential API\n",
            "Let’s switch to the California housing problem and tackle it using a regression neural\n",
            "\n",
            "--- Chunk 6576 ---\n",
            "network. For simplicity, we will use Scikit-Learn’s fetch_california_housing()\n",
            "\n",
            "--- Chunk 6577 ---\n",
            "function to load the data. This dataset is simpler than the one we used in Chapter 2,\n",
            "\n",
            "--- Chunk 6578 ---\n",
            "since it contains only numerical features (there is no ocean_proximity feature), and\n",
            "\n",
            "--- Chunk 6579 ---\n",
            "there is no missing value. After loading the data, we split it into a training set, a vali‐\n",
            "\n",
            "--- Chunk 6580 ---\n",
            "dation set, and a test set, and we scale all the features:\n",
            "\n",
            "--- Chunk 6581 ---\n",
            "from sklearn.datasets import fetch_california_housing\n",
            "from sklearn.model_selection import train_test_split\n",
            "\n",
            "--- Chunk 6582 ---\n",
            "from sklearn.preprocessing import StandardScaler\n",
            "\n",
            "--- Chunk 6583 ---\n",
            "Implementing MLPs with Keras | 307\n",
            "\n",
            "\n",
            "\n",
            "housing = fetch_california_housing()\n",
            "\n",
            "--- Chunk 6584 ---\n",
            "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
            "    housing.data, housing.target)\n",
            "\n",
            "--- Chunk 6585 ---\n",
            "X_train, X_valid, y_train, y_valid = train_test_split(\n",
            "    X_train_full, y_train_full)\n",
            "\n",
            "--- Chunk 6586 ---\n",
            "scaler = StandardScaler()\n",
            "X_train = scaler.fit_transform(X_train)\n",
            "X_valid = scaler.transform(X_valid)\n",
            "X_test = scaler.transform(X_test)\n",
            "\n",
            "--- Chunk 6587 ---\n",
            "Using the Sequential API to build, train, evaluate, and use a regression MLP to make\n",
            "\n",
            "--- Chunk 6588 ---\n",
            "predictions is quite similar to what we did for classification. The main differences are\n",
            "\n",
            "--- Chunk 6589 ---\n",
            "the fact that the output layer has a single neuron (since we only want to predict a sin‐\n",
            "\n",
            "--- Chunk 6590 ---\n",
            "gle value) and uses no activation function, and the loss function is the mean squared\n",
            "\n",
            "--- Chunk 6591 ---\n",
            "error. Since the dataset is quite noisy, we just use a single hidden layer with fewer\n",
            "neurons than before, to avoid overfitting:\n",
            "\n",
            "--- Chunk 6592 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
            "    keras.layers.Dense(1)\n",
            "])\n",
            "\n",
            "--- Chunk 6593 ---\n",
            "])\n",
            "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
            "history = model.fit(X_train, y_train, epochs=20,\n",
            "\n",
            "--- Chunk 6594 ---\n",
            "validation_data=(X_valid, y_valid))\n",
            "mse_test = model.evaluate(X_test, y_test)\n",
            "\n",
            "--- Chunk 6595 ---\n",
            "X_new = X_test[:3] # pretend these are new instances\n",
            "y_pred = model.predict(X_new)\n",
            "\n",
            "--- Chunk 6596 ---\n",
            "As you can see, the Sequential API is quite easy to use. However, although Sequen\n",
            "\n",
            "--- Chunk 6597 ---\n",
            "tial models are extremely common, it is sometimes useful to build neural networks\n",
            "\n",
            "--- Chunk 6598 ---\n",
            "with more complex topologies, or with multiple inputs or outputs. For this purpose,\n",
            "Keras offers the Functional API.\n",
            "\n",
            "--- Chunk 6599 ---\n",
            "Building Complex Models Using the Functional API\n",
            "One example of a nonsequential neural network is a Wide & Deep neural network.\n",
            "\n",
            "--- Chunk 6600 ---\n",
            "This neural network architecture was introduced in a 2016 paper by Heng-Tze Cheng\n",
            "\n",
            "--- Chunk 6601 ---\n",
            "et al.16 It connects all or part of the inputs directly to the output layer, as shown in\n",
            "\n",
            "--- Chunk 6602 ---\n",
            "Figure 10-14. This architecture makes it possible for the neural network to learn both\n",
            "\n",
            "--- Chunk 6603 ---\n",
            "deep patterns (using the deep path) and simple rules (through the short path).17 In\n",
            "\n",
            "--- Chunk 6604 ---\n",
            "contrast, a regular MLP forces all the data to flow through the full stack of layers;\n",
            "\n",
            "--- Chunk 6605 ---\n",
            "16 Heng-Tze Cheng et al., “Wide & Deep Learning for Recommender Systems,” Proceedings of the First Workshop\n",
            "\n",
            "--- Chunk 6606 ---\n",
            "on Deep Learning for Recommender Systems (2016): 7–10.\n",
            "\n",
            "--- Chunk 6607 ---\n",
            "17 The short path can also be used to provide manually engineered features to the neural network.\n",
            "\n",
            "--- Chunk 6608 ---\n",
            "308 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 6609 ---\n",
            "thus, simple patterns in the data may end up being distorted by this sequence of\n",
            "transformations.\n",
            "\n",
            "Figure 10-14. Wide & Deep neural network\n",
            "\n",
            "--- Chunk 6610 ---\n",
            "Let’s build such a neural network to tackle the California housing problem:\n",
            "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
            "\n",
            "--- Chunk 6611 ---\n",
            "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
            "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
            "\n",
            "--- Chunk 6612 ---\n",
            "concat = keras.layers.Concatenate()([input_, hidden2])\n",
            "output = keras.layers.Dense(1)(concat)\n",
            "model = keras.Model(inputs=[input_], outputs=[output])\n",
            "\n",
            "--- Chunk 6613 ---\n",
            "Let’s go through each line of this code:\n",
            "\n",
            "--- Chunk 6614 ---\n",
            "• First, we need to create an Input object.18 This is a specification of the kind of\n",
            "\n",
            "--- Chunk 6615 ---\n",
            "input the model will get, including its shape and dtype. A model may actually\n",
            "have multiple inputs, as we will see shortly.\n",
            "\n",
            "--- Chunk 6616 ---\n",
            "• Next, we create a Dense layer with 30 neurons, using the ReLU activation func‐\n",
            "\n",
            "--- Chunk 6617 ---\n",
            "tion. As soon as it is created, notice that we call it like a function, passing it the\n",
            "\n",
            "--- Chunk 6618 ---\n",
            "input. This is why this is called the Functional API. Note that we are just telling\n",
            "\n",
            "--- Chunk 6619 ---\n",
            "Keras how it should connect the layers together; no actual data is being processed\n",
            "yet.\n",
            "\n",
            "--- Chunk 6620 ---\n",
            "• We then create a second hidden layer, and again we use it as a function. Note that\n",
            "we pass it the output of the first hidden layer.\n",
            "\n",
            "--- Chunk 6621 ---\n",
            "18 The name input_ is used to avoid overshadowing Python’s built-in input() function.\n",
            "\n",
            "Implementing MLPs with Keras | 309\n",
            "\n",
            "--- Chunk 6622 ---\n",
            "• Next, we create a Concatenate layer, and once again we immediately use it like a\n",
            "\n",
            "--- Chunk 6623 ---\n",
            "function, to concatenate the input and the output of the second hidden layer. You\n",
            "may prefer the keras.layers.concatenate() function, which creates a\n",
            "\n",
            "--- Chunk 6624 ---\n",
            "Concatenate layer and immediately calls it with the given inputs.\n",
            "\n",
            "--- Chunk 6625 ---\n",
            "• Then we create the output layer, with a single neuron and no activation function,\n",
            "\n",
            "--- Chunk 6626 ---\n",
            "and we call it like a function, passing it the result of the concatenation.\n",
            "\n",
            "--- Chunk 6627 ---\n",
            "• Lastly, we create a Keras Model, specifying which inputs and outputs to use.\n",
            "\n",
            "--- Chunk 6628 ---\n",
            "Once you have built the Keras model, everything is exactly like earlier, so there’s no\n",
            "\n",
            "--- Chunk 6629 ---\n",
            "need to repeat it here: you must compile the model, train it, evaluate it, and use it to\n",
            "make predictions.\n",
            "\n",
            "--- Chunk 6630 ---\n",
            "make predictions.\n",
            "But what if you want to send a subset of the features through the wide path and a\n",
            "\n",
            "--- Chunk 6631 ---\n",
            "different subset (possibly overlapping) through the deep path (see Figure 10-15)? In\n",
            "\n",
            "--- Chunk 6632 ---\n",
            "this case, one solution is to use multiple inputs. For example, suppose we want to\n",
            "\n",
            "--- Chunk 6633 ---\n",
            "send five features through the wide path (features 0 to 4), and six features through the\n",
            "deep path (features 2 to 7):\n",
            "\n",
            "--- Chunk 6634 ---\n",
            "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
            "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
            "\n",
            "--- Chunk 6635 ---\n",
            "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
            "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
            "\n",
            "--- Chunk 6636 ---\n",
            "concat = keras.layers.concatenate([input_A, hidden2])\n",
            "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
            "\n",
            "--- Chunk 6637 ---\n",
            "model = keras.Model(inputs=[input_A, input_B], outputs=[output])\n",
            "\n",
            "--- Chunk 6638 ---\n",
            "Figure 10-15. Handling multiple inputs\n",
            "\n",
            "310 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 6639 ---\n",
            "The code is self-explanatory. You should name at least the most important layers,\n",
            "\n",
            "--- Chunk 6640 ---\n",
            "especially when the model gets a bit complex like this. Note that we specified\n",
            "\n",
            "--- Chunk 6641 ---\n",
            "inputs=[input_A, input_B] when creating the model. Now we can compile the\n",
            "\n",
            "--- Chunk 6642 ---\n",
            "model as usual, but when we call the fit() method, instead of passing a single input\n",
            "\n",
            "--- Chunk 6643 ---\n",
            "matrix X_train, we must pass a pair of matrices (X_train_A, X_train_B): one per\n",
            "\n",
            "--- Chunk 6644 ---\n",
            "input.19 The same is true for X_valid, and also for X_test and X_new when you call\n",
            "evaluate() or predict():\n",
            "\n",
            "--- Chunk 6645 ---\n",
            "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
            "\n",
            "--- Chunk 6646 ---\n",
            "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
            "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
            "\n",
            "--- Chunk 6647 ---\n",
            "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
            "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
            "\n",
            "--- Chunk 6648 ---\n",
            "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
            "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
            "\n",
            "--- Chunk 6649 ---\n",
            "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
            "y_pred = model.predict((X_new_A, X_new_B))\n",
            "\n",
            "--- Chunk 6650 ---\n",
            "There are many use cases in which you may want to have multiple outputs:\n",
            "\n",
            "--- Chunk 6651 ---\n",
            "• The task may demand it. For instance, you may want to locate and classify the\n",
            "\n",
            "--- Chunk 6652 ---\n",
            "main object in a picture. This is both a regression task (finding the coordinates of\n",
            "\n",
            "--- Chunk 6653 ---\n",
            "the object’s center, as well as its width and height) and a classification task.\n",
            "\n",
            "--- Chunk 6654 ---\n",
            "• Similarly, you may have multiple independent tasks based on the same data. Sure,\n",
            "\n",
            "--- Chunk 6655 ---\n",
            "you could train one neural network per task, but in many cases you will get better\n",
            "\n",
            "--- Chunk 6656 ---\n",
            "results on all tasks by training a single neural network with one output per task.\n",
            "\n",
            "--- Chunk 6657 ---\n",
            "This is because the neural network can learn features in the data that are useful\n",
            "\n",
            "--- Chunk 6658 ---\n",
            "across tasks. For example, you could perform multitask classification on pictures\n",
            "\n",
            "--- Chunk 6659 ---\n",
            "of faces, using one output to classify the person’s facial expression (smiling, sur‐\n",
            "\n",
            "--- Chunk 6660 ---\n",
            "prised, etc.) and another output to identify whether they are wearing glasses or\n",
            "not.\n",
            "\n",
            "--- Chunk 6661 ---\n",
            "• Another use case is as a regularization technique (i.e., a training constraint whose\n",
            "\n",
            "--- Chunk 6662 ---\n",
            "objective is to reduce overfitting and thus improve the model’s ability to general‐\n",
            "\n",
            "--- Chunk 6663 ---\n",
            "ize). For example, you may want to add some auxiliary outputs in a neural net‐\n",
            "\n",
            "--- Chunk 6664 ---\n",
            "work architecture (see Figure 10-16) to ensure that the underlying part of the\n",
            "\n",
            "--- Chunk 6665 ---\n",
            "network learns something useful on its own, without relying on the rest of the\n",
            "network.\n",
            "\n",
            "--- Chunk 6666 ---\n",
            "19 Alternatively, you can pass a dictionary mapping the input names to the input values, like {\"wide_input\":\n",
            "\n",
            "--- Chunk 6667 ---\n",
            "X_train_A, \"deep_input\": X_train_B}. This is especially useful when there are many inputs, to avoid get‐\n",
            "ting the order wrong.\n",
            "\n",
            "--- Chunk 6668 ---\n",
            "Implementing MLPs with Keras | 311\n",
            "\n",
            "\n",
            "\n",
            "Figure 10-16. Handling multiple outputs, in this example to add an auxiliary output for\n",
            "regularization\n",
            "\n",
            "--- Chunk 6669 ---\n",
            "Adding extra outputs is quite easy: just connect them to the appropriate layers and\n",
            "\n",
            "--- Chunk 6670 ---\n",
            "add them to your model’s list of outputs. For example, the following code builds the\n",
            "network represented in Figure 10-16:\n",
            "\n",
            "--- Chunk 6671 ---\n",
            "[...] # Same as above, up to the main output layer\n",
            "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
            "\n",
            "--- Chunk 6672 ---\n",
            "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
            "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])\n",
            "\n",
            "--- Chunk 6673 ---\n",
            "Each output will need its own loss function. Therefore, when we compile the model,\n",
            "\n",
            "--- Chunk 6674 ---\n",
            "we should pass a list of losses20 (if we pass a single loss, Keras will assume that the\n",
            "\n",
            "--- Chunk 6675 ---\n",
            "same loss must be used for all outputs). By default, Keras will compute all these losses\n",
            "\n",
            "--- Chunk 6676 ---\n",
            "and simply add them up to get the final loss used for training. We care much more\n",
            "\n",
            "--- Chunk 6677 ---\n",
            "about the main output than about the auxiliary output (as it is just used for regulari‐\n",
            "\n",
            "--- Chunk 6678 ---\n",
            "zation), so we want to give the main output’s loss a much greater weight. Fortunately,\n",
            "\n",
            "--- Chunk 6679 ---\n",
            "it is possible to set all the loss weights when compiling the model:\n",
            "\n",
            "--- Chunk 6680 ---\n",
            "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")\n",
            "\n",
            "--- Chunk 6681 ---\n",
            "Now when we train the model, we need to provide labels for each output. In this\n",
            "\n",
            "--- Chunk 6682 ---\n",
            "example, the main output and the auxiliary output should try to predict the same\n",
            "\n",
            "--- Chunk 6683 ---\n",
            "thing, so they should use the same labels. So instead of passing y_train, we need to\n",
            "\n",
            "--- Chunk 6684 ---\n",
            "pass (y_train, y_train) (and the same goes for y_valid and y_test):\n",
            "\n",
            "--- Chunk 6685 ---\n",
            "history = model.fit(\n",
            "    [X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
            "    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))\n",
            "\n",
            "--- Chunk 6686 ---\n",
            "20 Alternatively, you can pass a dictionary that maps each output name to the corresponding loss. Just like for\n",
            "\n",
            "--- Chunk 6687 ---\n",
            "the inputs, this is useful when there are multiple outputs, to avoid getting the order wrong. The loss weights\n",
            "\n",
            "--- Chunk 6688 ---\n",
            "and metrics (discussed shortly) can also be set using dictionaries.\n",
            "\n",
            "--- Chunk 6689 ---\n",
            "312 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 6690 ---\n",
            "When we evaluate the model, Keras will return the total loss, as well as all the individ‐\n",
            "ual losses:\n",
            "\n",
            "--- Chunk 6691 ---\n",
            "total_loss, main_loss, aux_loss = model.evaluate(\n",
            "    [X_test_A, X_test_B], [y_test, y_test])\n",
            "\n",
            "--- Chunk 6692 ---\n",
            "Similarly, the predict() method will return predictions for each output:\n",
            "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])\n",
            "\n",
            "--- Chunk 6693 ---\n",
            "As you can see, you can build any sort of architecture you want quite easily with the\n",
            "\n",
            "--- Chunk 6694 ---\n",
            "Functional API. Let’s look at one last way you can build Keras models.\n",
            "\n",
            "--- Chunk 6695 ---\n",
            "Using the Subclassing API to Build Dynamic Models\n",
            "Both the Sequential API and the Functional API are declarative: you start by declar‐\n",
            "\n",
            "--- Chunk 6696 ---\n",
            "ing which layers you want to use and how they should be connected, and only then\n",
            "\n",
            "--- Chunk 6697 ---\n",
            "can you start feeding the model some data for training or inference. This has many\n",
            "\n",
            "--- Chunk 6698 ---\n",
            "advantages: the model can easily be saved, cloned, and shared; its structure can be\n",
            "\n",
            "--- Chunk 6699 ---\n",
            "displayed and analyzed; the framework can infer shapes and check types, so errors\n",
            "\n",
            "--- Chunk 6700 ---\n",
            "can be caught early (i.e., before any data ever goes through the model). It’s also fairly\n",
            "\n",
            "--- Chunk 6701 ---\n",
            "easy to debug, since the whole model is a static graph of layers. But the flip side is just\n",
            "\n",
            "--- Chunk 6702 ---\n",
            "that: it’s static. Some models involve loops, varying shapes, conditional branching,\n",
            "\n",
            "--- Chunk 6703 ---\n",
            "and other dynamic behaviors. For such cases, or simply if you prefer a more impera‐\n",
            "tive programming style, the Subclassing API is for you.\n",
            "\n",
            "--- Chunk 6704 ---\n",
            "Simply subclass the Model class, create the layers you need in the constructor, and use\n",
            "\n",
            "--- Chunk 6705 ---\n",
            "them to perform the computations you want in the call() method. For example, cre‐\n",
            "\n",
            "--- Chunk 6706 ---\n",
            "ating an instance of the following WideAndDeepModel class gives us an equivalent\n",
            "\n",
            "--- Chunk 6707 ---\n",
            "model to the one we just built with the Functional API. You can then compile it, eval‐\n",
            "\n",
            "--- Chunk 6708 ---\n",
            "uate it, and use it to make predictions, exactly like we just did:\n",
            "\n",
            "--- Chunk 6709 ---\n",
            "class WideAndDeepModel(keras.Model):\n",
            "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
            "\n",
            "--- Chunk 6710 ---\n",
            "super().__init__(**kwargs) # handles standard args (e.g., name)\n",
            "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
            "\n",
            "--- Chunk 6711 ---\n",
            "self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
            "        self.main_output = keras.layers.Dense(1)\n",
            "\n",
            "--- Chunk 6712 ---\n",
            "self.aux_output = keras.layers.Dense(1)\n",
            "\n",
            "--- Chunk 6713 ---\n",
            "def call(self, inputs):\n",
            "        input_A, input_B = inputs\n",
            "        hidden1 = self.hidden1(input_B)\n",
            "        hidden2 = self.hidden2(hidden1)\n",
            "\n",
            "--- Chunk 6714 ---\n",
            "concat = keras.layers.concatenate([input_A, hidden2])\n",
            "        main_output = self.main_output(concat)\n",
            "\n",
            "--- Chunk 6715 ---\n",
            "aux_output = self.aux_output(hidden2)\n",
            "        return main_output, aux_output\n",
            "\n",
            "--- Chunk 6716 ---\n",
            "model = WideAndDeepModel()\n",
            "\n",
            "Implementing MLPs with Keras | 313\n",
            "\n",
            "--- Chunk 6717 ---\n",
            "This example looks very much like the Functional API, except we do not need to cre‐\n",
            "\n",
            "--- Chunk 6718 ---\n",
            "ate the inputs; we just use the input argument to the call() method, and we separate\n",
            "\n",
            "--- Chunk 6719 ---\n",
            "the creation of the layers21 in the constructor from their usage in the call() method.\n",
            "\n",
            "--- Chunk 6720 ---\n",
            "The big difference is that you can do pretty much anything you want in the call()\n",
            "\n",
            "--- Chunk 6721 ---\n",
            "method: for loops, if statements, low-level TensorFlow operations—your imagina‐\n",
            "\n",
            "--- Chunk 6722 ---\n",
            "tion is the limit (see Chapter 12)! This makes it a great API for researchers experi‐\n",
            "menting with new ideas.\n",
            "\n",
            "--- Chunk 6723 ---\n",
            "This extra flexibility does come at a cost: your model’s architecture is hidden within\n",
            "\n",
            "--- Chunk 6724 ---\n",
            "the call() method, so Keras cannot easily inspect it; it cannot save or clone it; and\n",
            "\n",
            "--- Chunk 6725 ---\n",
            "when you call the summary() method, you only get a list of layers, without any infor‐\n",
            "\n",
            "--- Chunk 6726 ---\n",
            "mation on how they are connected to each other. Moreover, Keras cannot check types\n",
            "\n",
            "--- Chunk 6727 ---\n",
            "and shapes ahead of time, and it is easier to make mistakes. So unless you really need\n",
            "\n",
            "--- Chunk 6728 ---\n",
            "that extra flexibility, you should probably stick to the Sequential API or the Func‐\n",
            "tional API.\n",
            "\n",
            "--- Chunk 6729 ---\n",
            "Keras models can be used just like regular layers, so you can easily\n",
            "combine them to build complex architectures.\n",
            "\n",
            "--- Chunk 6730 ---\n",
            "Now that you know how to build and train neural nets using Keras, you will want to\n",
            "save them!\n",
            "\n",
            "--- Chunk 6731 ---\n",
            "Saving and Restoring a Model\n",
            "When using the Sequential API or the Functional API, saving a trained Keras model\n",
            "is as simple as it gets:\n",
            "\n",
            "--- Chunk 6732 ---\n",
            "model = keras.models.Sequential([...]) # or keras.Model([...])\n",
            "model.compile([...])\n",
            "model.fit([...])\n",
            "model.save(\"my_keras_model.h5\")\n",
            "\n",
            "--- Chunk 6733 ---\n",
            "Keras will use the HDF5 format to save both the model’s architecture (including every\n",
            "\n",
            "--- Chunk 6734 ---\n",
            "layer’s hyperparameters) and the values of all the model parameters for every layer\n",
            "\n",
            "--- Chunk 6735 ---\n",
            "(e.g., connection weights and biases). It also saves the optimizer (including its hyper‐\n",
            "\n",
            "--- Chunk 6736 ---\n",
            "parameters and any state it may have). In Chapter 19, we will see how to save a\n",
            "tf.keras model using TensorFlow’s SavedModel format instead.\n",
            "\n",
            "--- Chunk 6737 ---\n",
            "21 Keras models have an output attribute, so we cannot use that name for the main output layer, which is why\n",
            "we renamed it to main_output.\n",
            "\n",
            "--- Chunk 6738 ---\n",
            "314 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 6739 ---\n",
            "You will typically have a script that trains a model and saves it, and one or more\n",
            "\n",
            "--- Chunk 6740 ---\n",
            "scripts (or web services) that load the model and use it to make predictions. Loading\n",
            "the model is just as easy:\n",
            "\n",
            "--- Chunk 6741 ---\n",
            "model = keras.models.load_model(\"my_keras_model.h5\")\n",
            "\n",
            "--- Chunk 6742 ---\n",
            "This will work when using the Sequential API or the Functional\n",
            "API, but unfortunately not when using model subclassing. You can\n",
            "\n",
            "--- Chunk 6743 ---\n",
            "use save_weights() and load_weights() to at least save and\n",
            "restore the model parameters, but you will need to save and restore\n",
            "\n",
            "--- Chunk 6744 ---\n",
            "everything else yourself.\n",
            "\n",
            "--- Chunk 6745 ---\n",
            "But what if training lasts several hours? This is quite common, especially when train‐\n",
            "\n",
            "--- Chunk 6746 ---\n",
            "ing on large datasets. In this case, you should not only save your model at the end of\n",
            "\n",
            "--- Chunk 6747 ---\n",
            "training, but also save checkpoints at regular intervals during training, to avoid losing\n",
            "\n",
            "--- Chunk 6748 ---\n",
            "everything if your computer crashes. But how can you tell the fit() method to save\n",
            "checkpoints? Use callbacks.\n",
            "\n",
            "--- Chunk 6749 ---\n",
            "Using Callbacks\n",
            "The fit() method accepts a callbacks argument that lets you specify a list of objects\n",
            "\n",
            "--- Chunk 6750 ---\n",
            "that Keras will call at the start and end of training, at the start and end of each epoch,\n",
            "\n",
            "--- Chunk 6751 ---\n",
            "and even before and after processing each batch. For example, the ModelCheckpoint\n",
            "\n",
            "--- Chunk 6752 ---\n",
            "callback saves checkpoints of your model at regular intervals during training, by\n",
            "default at the end of each epoch:\n",
            "\n",
            "--- Chunk 6753 ---\n",
            "[...] # build and compile the model\n",
            "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
            "\n",
            "--- Chunk 6754 ---\n",
            "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])\n",
            "\n",
            "--- Chunk 6755 ---\n",
            "Moreover, if you use a validation set during training, you can set\n",
            "save_best_only=True when creating the ModelCheckpoint. In this case, it will only\n",
            "\n",
            "--- Chunk 6756 ---\n",
            "save your model when its performance on the validation set is the best so far. This\n",
            "\n",
            "--- Chunk 6757 ---\n",
            "way, you do not need to worry about training for too long and overfitting the training\n",
            "\n",
            "--- Chunk 6758 ---\n",
            "set: simply restore the last model saved after training, and this will be the best model\n",
            "\n",
            "--- Chunk 6759 ---\n",
            "on the validation set. The following code is a simple way to implement early stopping\n",
            "(introduced in Chapter 4):\n",
            "\n",
            "--- Chunk 6760 ---\n",
            "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\",\n",
            "                                                save_best_only=True)\n",
            "\n",
            "--- Chunk 6761 ---\n",
            "history = model.fit(X_train, y_train, epochs=10,\n",
            "                    validation_data=(X_valid, y_valid),\n",
            "\n",
            "--- Chunk 6762 ---\n",
            "callbacks=[checkpoint_cb])\n",
            "model = keras.models.load_model(\"my_keras_model.h5\") # roll back to best model\n",
            "\n",
            "--- Chunk 6763 ---\n",
            "Another way to implement early stopping is to simply use the EarlyStopping call‐\n",
            "\n",
            "--- Chunk 6764 ---\n",
            "back. It will interrupt training when it measures no progress on the validation set for\n",
            "\n",
            "--- Chunk 6765 ---\n",
            "Implementing MLPs with Keras | 315\n",
            "\n",
            "--- Chunk 6766 ---\n",
            "a number of epochs (defined by the patience argument), and it will optionally roll\n",
            "\n",
            "--- Chunk 6767 ---\n",
            "back to the best model. You can combine both callbacks to save checkpoints of your\n",
            "\n",
            "--- Chunk 6768 ---\n",
            "model (in case your computer crashes) and interrupt training early when there is no\n",
            "more progress (to avoid wasting time and resources):\n",
            "\n",
            "--- Chunk 6769 ---\n",
            "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
            "                                                  restore_best_weights=True)\n",
            "\n",
            "--- Chunk 6770 ---\n",
            "history = model.fit(X_train, y_train, epochs=100,\n",
            "                    validation_data=(X_valid, y_valid),\n",
            "\n",
            "--- Chunk 6771 ---\n",
            "callbacks=[checkpoint_cb, early_stopping_cb])\n",
            "\n",
            "--- Chunk 6772 ---\n",
            "The number of epochs can be set to a large value since training will stop automati‐\n",
            "\n",
            "--- Chunk 6773 ---\n",
            "cally when there is no more progress. In this case, there is no need to restore the best\n",
            "\n",
            "--- Chunk 6774 ---\n",
            "model saved because the EarlyStopping callback will keep track of the best weights\n",
            "and restore them for you at the end of training.\n",
            "\n",
            "--- Chunk 6775 ---\n",
            "There are many other callbacks available in the keras.callbacks\n",
            "package.\n",
            "\n",
            "--- Chunk 6776 ---\n",
            "If you need extra control, you can easily write your own custom callbacks. As an\n",
            "\n",
            "--- Chunk 6777 ---\n",
            "example of how to do that, the following custom callback will display the ratio\n",
            "\n",
            "--- Chunk 6778 ---\n",
            "between the validation loss and the training loss during training (e.g., to detect over‐\n",
            "fitting):\n",
            "\n",
            "--- Chunk 6779 ---\n",
            "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
            "    def on_epoch_end(self, epoch, logs):\n",
            "\n",
            "--- Chunk 6780 ---\n",
            "print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))\n",
            "\n",
            "--- Chunk 6781 ---\n",
            "As you might expect, you can implement on_train_begin(), on_train_end(),\n",
            "\n",
            "--- Chunk 6782 ---\n",
            "on_epoch_begin(), on_epoch_end(), on_batch_begin(), and on_batch_end(). Call‐\n",
            "\n",
            "--- Chunk 6783 ---\n",
            "backs can also be used during evaluation and predictions, should you ever need them\n",
            "\n",
            "--- Chunk 6784 ---\n",
            "(e.g., for debugging). For evaluation, you should implement on_test_begin(),\n",
            "\n",
            "--- Chunk 6785 ---\n",
            "on_test_end(), on_test_batch_begin(), or on_test_batch_end() (called by evalu\n",
            "\n",
            "--- Chunk 6786 ---\n",
            "ate()), and for prediction you should implement on_predict_begin(), on_pre\n",
            "dict_end(), on_predict_batch_begin(), or on_predict_batch_end() (called by\n",
            "\n",
            "--- Chunk 6787 ---\n",
            "predict()).\n",
            "Now let’s take a look at one more tool you should definitely have in your toolbox\n",
            "when using tf.keras: TensorBoard.\n",
            "\n",
            "--- Chunk 6788 ---\n",
            "316 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 6789 ---\n",
            "Using TensorBoard for Visualization\n",
            "TensorBoard is a great interactive visualization tool that you can use to view the\n",
            "\n",
            "--- Chunk 6790 ---\n",
            "learning curves during training, compare learning curves between multiple runs, vis‐\n",
            "\n",
            "--- Chunk 6791 ---\n",
            "ualize the computation graph, analyze training statistics, view images generated by\n",
            "\n",
            "--- Chunk 6792 ---\n",
            "your model, visualize complex multidimensional data projected down to 3D and\n",
            "\n",
            "--- Chunk 6793 ---\n",
            "automatically clustered for you, and more! This tool is installed automatically when\n",
            "you install TensorFlow, so you already have it.\n",
            "\n",
            "--- Chunk 6794 ---\n",
            "To use it, you must modify your program so that it outputs the data you want to visu‐\n",
            "\n",
            "--- Chunk 6795 ---\n",
            "alize to special binary log files called event files. Each binary data record is called a\n",
            "\n",
            "--- Chunk 6796 ---\n",
            "summary. The TensorBoard server will monitor the log directory, and it will automat‐\n",
            "\n",
            "--- Chunk 6797 ---\n",
            "ically pick up the changes and update the visualizations: this allows you to visualize\n",
            "\n",
            "--- Chunk 6798 ---\n",
            "live data (with a short delay), such as the learning curves during training. In general,\n",
            "\n",
            "--- Chunk 6799 ---\n",
            "you want to point the TensorBoard server to a root log directory and configure your\n",
            "\n",
            "--- Chunk 6800 ---\n",
            "program so that it writes to a different subdirectory every time it runs. This way, the\n",
            "\n",
            "--- Chunk 6801 ---\n",
            "same TensorBoard server instance will allow you to visualize and compare data from\n",
            "\n",
            "--- Chunk 6802 ---\n",
            "multiple runs of your program, without getting everything mixed up.\n",
            "\n",
            "--- Chunk 6803 ---\n",
            "Let’s start by defining the root log directory we will use for our TensorBoard logs,\n",
            "\n",
            "--- Chunk 6804 ---\n",
            "plus a small function that will generate a subdirectory path based on the current date\n",
            "\n",
            "--- Chunk 6805 ---\n",
            "and time so that it’s different at every run. You may want to include extra information\n",
            "\n",
            "--- Chunk 6806 ---\n",
            "in the log directory name, such as hyperparameter values that you are testing, to\n",
            "make it easier to know what you are looking at in TensorBoard:\n",
            "\n",
            "--- Chunk 6807 ---\n",
            "import os\n",
            "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
            "\n",
            "--- Chunk 6808 ---\n",
            "def get_run_logdir():\n",
            "    import time\n",
            "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
            "    return os.path.join(root_logdir, run_id)\n",
            "\n",
            "--- Chunk 6809 ---\n",
            "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'\n",
            "\n",
            "--- Chunk 6810 ---\n",
            "The good news is that Keras provides a nice TensorBoard() callback:\n",
            "[...] # Build and compile your model\n",
            "\n",
            "--- Chunk 6811 ---\n",
            "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
            "history = model.fit(X_train, y_train, epochs=30,\n",
            "\n",
            "--- Chunk 6812 ---\n",
            "validation_data=(X_valid, y_valid),\n",
            "                    callbacks=[tensorboard_cb])\n",
            "\n",
            "--- Chunk 6813 ---\n",
            "And that’s all there is to it! It could hardly be easier to use. If you run this code, the\n",
            "\n",
            "--- Chunk 6814 ---\n",
            "TensorBoard() callback will take care of creating the log directory for you (along\n",
            "\n",
            "--- Chunk 6815 ---\n",
            "with its parent directories if needed), and during training it will create event files and\n",
            "\n",
            "--- Chunk 6816 ---\n",
            "write summaries to them. After running the program a second time (perhaps\n",
            "\n",
            "--- Chunk 6817 ---\n",
            "Implementing MLPs with Keras | 317\n",
            "\n",
            "\n",
            "\n",
            "changing some hyperparameter value), you will end up with a directory structure\n",
            "similar to this one:\n",
            "\n",
            "--- Chunk 6818 ---\n",
            "my_logs/\n",
            "├── run_2019_06_07-15_15_22\n",
            "│   ├── train\n",
            "│   │   ├── events.out.tfevents.1559891732.mycomputer.local.38511.694049.v2\n",
            "\n",
            "--- Chunk 6819 ---\n",
            "│   │   ├── events.out.tfevents.1559891732.mycomputer.local.profile-empty\n",
            "│   │   └── plugins/profile/2019-06-07_15-15-32\n",
            "│   │       └── local.trace\n",
            "\n",
            "--- Chunk 6820 ---\n",
            "│   └── validation\n",
            "│       └── events.out.tfevents.1559891733.mycomputer.local.38511.696430.v2\n",
            "└── run_2019_06_07-15_15_49\n",
            "    └── [...]\n",
            "\n",
            "--- Chunk 6821 ---\n",
            "There’s one directory per run, each containing one subdirectory for training logs and\n",
            "\n",
            "--- Chunk 6822 ---\n",
            "one for validation logs. Both contain event files, but the training logs also include\n",
            "\n",
            "--- Chunk 6823 ---\n",
            "profiling traces: this allows TensorBoard to show you exactly how much time the\n",
            "\n",
            "--- Chunk 6824 ---\n",
            "model spent on each part of your model, across all your devices, which is great for\n",
            "locating performance bottlenecks.\n",
            "\n",
            "--- Chunk 6825 ---\n",
            "Next you need to start the TensorBoard server. One way to do this is by running a\n",
            "\n",
            "--- Chunk 6826 ---\n",
            "command in a terminal. If you installed TensorFlow within a virtualenv, you should\n",
            "\n",
            "--- Chunk 6827 ---\n",
            "activate it. Next, run the following command at the root of the project (or from any‐\n",
            "\n",
            "--- Chunk 6828 ---\n",
            "where else, as long as you point to the appropriate log directory):\n",
            "\n",
            "--- Chunk 6829 ---\n",
            "$ tensorboard --logdir=./my_logs --port=6006\n",
            "TensorBoard 2.0.0 at http://mycomputer.local:6006/ (Press CTRL+C to quit)\n",
            "\n",
            "--- Chunk 6830 ---\n",
            "If your shell cannot find the tensorboard script, then you must update your PATH envi‐\n",
            "\n",
            "--- Chunk 6831 ---\n",
            "ronment variable so that it contains the directory in which the script was installed\n",
            "\n",
            "--- Chunk 6832 ---\n",
            "(alternatively, you can just replace tensorboard in the command line with python3\n",
            "\n",
            "--- Chunk 6833 ---\n",
            "-m tensorboard.main). Once the server is up, you can open a web browser and go to\n",
            "http://localhost:6006.\n",
            "\n",
            "--- Chunk 6834 ---\n",
            "Alternatively, you can use TensorBoard directly within Jupyter, by running the fol‐\n",
            "\n",
            "--- Chunk 6835 ---\n",
            "lowing commands. The first line loads the TensorBoard extension, and the second\n",
            "\n",
            "--- Chunk 6836 ---\n",
            "line starts a TensorBoard server on port 6006 (unless it is already started) and con‐\n",
            "nects to it:\n",
            "\n",
            "--- Chunk 6837 ---\n",
            "%load_ext tensorboard\n",
            "%tensorboard --logdir=./my_logs --port=6006\n",
            "\n",
            "--- Chunk 6838 ---\n",
            "Either way, you should see TensorBoard’s web interface. Click the SCALARS tab to\n",
            "\n",
            "--- Chunk 6839 ---\n",
            "view the learning curves (see Figure 10-17). At the bottom left, select the logs you\n",
            "\n",
            "--- Chunk 6840 ---\n",
            "want to visualize (e.g., the training logs from the first and second run), and click the\n",
            "\n",
            "--- Chunk 6841 ---\n",
            "epoch_loss scalar. Notice that the training loss went down nicely during both runs,\n",
            "\n",
            "--- Chunk 6842 ---\n",
            "but the second run went down much faster. Indeed, we used a learning rate of 0.05\n",
            "(optimizer=keras.optimizers.SGD(lr=0.05)) instead of 0.001.\n",
            "\n",
            "--- Chunk 6843 ---\n",
            "318 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "\n",
            "\n",
            "Figure 10-17. Visualizing learning curves with TensorBoard\n",
            "\n",
            "--- Chunk 6844 ---\n",
            "You can also visualize the whole graph, the learned weights (projected to 3D), or the\n",
            "\n",
            "--- Chunk 6845 ---\n",
            "profiling traces. The TensorBoard() callback has options to log extra data too, such\n",
            "as embeddings (see Chapter 13).\n",
            "\n",
            "--- Chunk 6846 ---\n",
            "Additionally, TensorFlow offers a lower-level API in the tf.summary package. The\n",
            "\n",
            "--- Chunk 6847 ---\n",
            "following code creates a SummaryWriter using the create_file_writer() function,\n",
            "\n",
            "--- Chunk 6848 ---\n",
            "and it uses this writer as a context to log scalars, histograms, images, audio, and text,\n",
            "\n",
            "--- Chunk 6849 ---\n",
            "all of which can then be visualized using TensorBoard (give it a try!):\n",
            "\n",
            "--- Chunk 6850 ---\n",
            "test_logdir = get_run_logdir()\n",
            "writer = tf.summary.create_file_writer(test_logdir)\n",
            "with writer.as_default():\n",
            "    for step in range(1, 1000 + 1):\n",
            "\n",
            "--- Chunk 6851 ---\n",
            "tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
            "        data = (np.random.randn(100) + 2) * step / 100 # some random data\n",
            "\n",
            "--- Chunk 6852 ---\n",
            "tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
            "        images = np.random.rand(2, 32, 32, 3) # random 32×32 RGB images\n",
            "\n",
            "--- Chunk 6853 ---\n",
            "tf.summary.image(\"my_images\", images * step / 1000, step=step)\n",
            "        texts = [\"The step is \" + str(step), \"Its square is \" + str(step**2)]\n",
            "\n",
            "--- Chunk 6854 ---\n",
            "tf.summary.text(\"my_text\", texts, step=step)\n",
            "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
            "\n",
            "--- Chunk 6855 ---\n",
            "audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
            "        tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step=step)\n",
            "\n",
            "--- Chunk 6856 ---\n",
            "Implementing MLPs with Keras | 319\n",
            "\n",
            "--- Chunk 6857 ---\n",
            "This is actually a useful visualization tool to have, even beyond TensorFlow or Deep\n",
            "Learning.\n",
            "\n",
            "--- Chunk 6858 ---\n",
            "Learning.\n",
            "Let’s summarize what you’ve learned so far in this chapter: we saw where neural nets\n",
            "\n",
            "--- Chunk 6859 ---\n",
            "came from, what an MLP is and how you can use it for classification and regression,\n",
            "\n",
            "--- Chunk 6860 ---\n",
            "how to use tf.keras’s Sequential API to build MLPs, and how to use the Functional\n",
            "\n",
            "--- Chunk 6861 ---\n",
            "API or the Subclassing API to build more complex model architectures. You learned\n",
            "\n",
            "--- Chunk 6862 ---\n",
            "how to save and restore a model and how to use callbacks for checkpointing, early\n",
            "\n",
            "--- Chunk 6863 ---\n",
            "stopping, and more. Finally, you learned how to use TensorBoard for visualization.\n",
            "\n",
            "--- Chunk 6864 ---\n",
            "You can already go ahead and use neural networks to tackle many problems! How‐\n",
            "\n",
            "--- Chunk 6865 ---\n",
            "ever, you may wonder how to choose the number of hidden layers, the number of\n",
            "\n",
            "--- Chunk 6866 ---\n",
            "neurons in the network, and all the other hyperparameters. Let’s look at this now.\n",
            "\n",
            "--- Chunk 6867 ---\n",
            "Fine-Tuning Neural Network Hyperparameters\n",
            "The flexibility of neural networks is also one of their main drawbacks: there are many\n",
            "\n",
            "--- Chunk 6868 ---\n",
            "hyperparameters to tweak. Not only can you use any imaginable network architec‐\n",
            "\n",
            "--- Chunk 6869 ---\n",
            "ture, but even in a simple MLP you can change the number of layers, the number of\n",
            "\n",
            "--- Chunk 6870 ---\n",
            "neurons per layer, the type of activation function to use in each layer, the weight initi‐\n",
            "\n",
            "--- Chunk 6871 ---\n",
            "alization logic, and much more. How do you know what combination of hyperpara‐\n",
            "meters is the best for your task?\n",
            "\n",
            "--- Chunk 6872 ---\n",
            "One option is to simply try many combinations of hyperparameters and see which\n",
            "\n",
            "--- Chunk 6873 ---\n",
            "one works best on the validation set (or use K-fold cross-validation). For example, we\n",
            "\n",
            "--- Chunk 6874 ---\n",
            "can use GridSearchCV or RandomizedSearchCV to explore the hyperparameter space,\n",
            "\n",
            "--- Chunk 6875 ---\n",
            "as we did in Chapter 2. To do this, we need to wrap our Keras models in objects that\n",
            "\n",
            "--- Chunk 6876 ---\n",
            "mimic regular Scikit-Learn regressors. The first step is to create a function that will\n",
            "\n",
            "--- Chunk 6877 ---\n",
            "build and compile a Keras model, given a set of hyperparameters:\n",
            "\n",
            "--- Chunk 6878 ---\n",
            "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
            "    model = keras.models.Sequential()\n",
            "\n",
            "--- Chunk 6879 ---\n",
            "model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
            "    for layer in range(n_hidden):\n",
            "\n",
            "--- Chunk 6880 ---\n",
            "model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
            "    model.add(keras.layers.Dense(1))\n",
            "\n",
            "--- Chunk 6881 ---\n",
            "optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
            "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
            "    return model\n",
            "\n",
            "--- Chunk 6882 ---\n",
            "This function creates a simple Sequential model for univariate regression (only one\n",
            "\n",
            "--- Chunk 6883 ---\n",
            "output neuron), with the given input shape and the given number of hidden layers\n",
            "\n",
            "--- Chunk 6884 ---\n",
            "and neurons, and it compiles it using an SGD optimizer configured with the specified\n",
            "\n",
            "--- Chunk 6885 ---\n",
            "learning rate. It is good practice to provide reasonable defaults to as many hyperpara‐\n",
            "meters as you can, as Scikit-Learn does.\n",
            "\n",
            "--- Chunk 6886 ---\n",
            "Next, let’s create a KerasRegressor based on this build_model() function:\n",
            "\n",
            "--- Chunk 6887 ---\n",
            "320 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "\n",
            "\n",
            "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
            "\n",
            "--- Chunk 6888 ---\n",
            "The KerasRegressor object is a thin wrapper around the Keras model built using\n",
            "\n",
            "--- Chunk 6889 ---\n",
            "build_model(). Since we did not specify any hyperparameters when creating it, it\n",
            "\n",
            "--- Chunk 6890 ---\n",
            "will use the default hyperparameters we defined in build_model(). Now we can use\n",
            "\n",
            "--- Chunk 6891 ---\n",
            "this object like a regular Scikit-Learn regressor: we can train it using its fit()\n",
            "\n",
            "--- Chunk 6892 ---\n",
            "method, then evaluate it using its score() method, and use it to make predictions\n",
            "using its predict() method, as you can see in the following code:\n",
            "\n",
            "--- Chunk 6893 ---\n",
            "keras_reg.fit(X_train, y_train, epochs=100,\n",
            "              validation_data=(X_valid, y_valid),\n",
            "\n",
            "--- Chunk 6894 ---\n",
            "callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
            "mse_test = keras_reg.score(X_test, y_test)\n",
            "y_pred = keras_reg.predict(X_new)\n",
            "\n",
            "--- Chunk 6895 ---\n",
            "Note that any extra parameter you pass to the fit() method will get passed to the\n",
            "\n",
            "--- Chunk 6896 ---\n",
            "underlying Keras model. Also note that the score will be the opposite of the MSE\n",
            "\n",
            "--- Chunk 6897 ---\n",
            "because Scikit-Learn wants scores, not losses (i.e., higher should be better).\n",
            "\n",
            "--- Chunk 6898 ---\n",
            "We don’t want to train and evaluate a single model like this, though we want to train\n",
            "\n",
            "--- Chunk 6899 ---\n",
            "hundreds of variants and see which one performs best on the validation set. Since\n",
            "\n",
            "--- Chunk 6900 ---\n",
            "there are many hyperparameters, it is preferable to use a randomized search rather\n",
            "\n",
            "--- Chunk 6901 ---\n",
            "than grid search (as we discussed in Chapter 2). Let’s try to explore the number of\n",
            "hidden layers, the number of neurons, and the learning rate:\n",
            "\n",
            "--- Chunk 6902 ---\n",
            "from scipy.stats import reciprocal\n",
            "from sklearn.model_selection import RandomizedSearchCV\n",
            "\n",
            "--- Chunk 6903 ---\n",
            "param_distribs = {\n",
            "    \"n_hidden\": [0, 1, 2, 3],\n",
            "    \"n_neurons\": np.arange(1, 100),\n",
            "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
            "}\n",
            "\n",
            "--- Chunk 6904 ---\n",
            "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
            "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
            "\n",
            "--- Chunk 6905 ---\n",
            "validation_data=(X_valid, y_valid),\n",
            "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
            "\n",
            "--- Chunk 6906 ---\n",
            "This is identical to what we did in Chapter 2, except here we pass extra parameters to\n",
            "\n",
            "--- Chunk 6907 ---\n",
            "the fit() method, and they get relayed to the underlying Keras models. Note that\n",
            "\n",
            "--- Chunk 6908 ---\n",
            "RandomizedSearchCV uses K-fold cross-validation, so it does not use X_valid and\n",
            "y_valid, which are only used for early stopping.\n",
            "\n",
            "--- Chunk 6909 ---\n",
            "The exploration may last many hours, depending on the hardware, the size of the\n",
            "\n",
            "--- Chunk 6910 ---\n",
            "dataset, the complexity of the model, and the values of n_iter and cv. When it’s over,\n",
            "\n",
            "--- Chunk 6911 ---\n",
            "you can access the best parameters found, the best score, and the trained Keras model\n",
            "like this:\n",
            "\n",
            "--- Chunk 6912 ---\n",
            "Fine-Tuning Neural Network Hyperparameters | 321\n",
            "\n",
            "--- Chunk 6913 ---\n",
            ">>> rnd_search_cv.best_params_\n",
            "{'learning_rate': 0.0033625641252688094, 'n_hidden': 2, 'n_neurons': 42}\n",
            ">>> rnd_search_cv.best_score_\n",
            "\n",
            "--- Chunk 6914 ---\n",
            "-0.3189529188278931\n",
            ">>> model = rnd_search_cv.best_estimator_.model\n",
            "\n",
            "--- Chunk 6915 ---\n",
            "You can now save this model, evaluate it on the test set, and, if you are satisfied with\n",
            "\n",
            "--- Chunk 6916 ---\n",
            "its performance, deploy it to production. Using randomized search is not too hard,\n",
            "\n",
            "--- Chunk 6917 ---\n",
            "and it works well for many fairly simple problems. When training is slow, however\n",
            "\n",
            "--- Chunk 6918 ---\n",
            "(e.g., for more complex problems with larger datasets), this approach will only\n",
            "\n",
            "--- Chunk 6919 ---\n",
            "explore a tiny portion of the hyperparameter space. You can partially alleviate this\n",
            "\n",
            "--- Chunk 6920 ---\n",
            "problem by assisting the search process manually: first run a quick random search\n",
            "\n",
            "--- Chunk 6921 ---\n",
            "using wide ranges of hyperparameter values, then run another search using smaller\n",
            "\n",
            "--- Chunk 6922 ---\n",
            "ranges of values centered on the best ones found during the first run, and so on. This\n",
            "\n",
            "--- Chunk 6923 ---\n",
            "approach will hopefully zoom in on a good set of hyperparameters. However, it’s very\n",
            "time consuming, and probably not the best use of your time.\n",
            "\n",
            "--- Chunk 6924 ---\n",
            "Fortunately, there are many techniques to explore a search space much more effi‐\n",
            "\n",
            "--- Chunk 6925 ---\n",
            "ciently than randomly. Their core idea is simple: when a region of the space turns out\n",
            "\n",
            "--- Chunk 6926 ---\n",
            "to be good, it should be explored more. Such techniques take care of the “zooming”\n",
            "\n",
            "--- Chunk 6927 ---\n",
            "process for you and lead to much better solutions in much less time. Here are some\n",
            "Python libraries you can use to optimize hyperparameters:\n",
            "Hyperopt\n",
            "\n",
            "--- Chunk 6928 ---\n",
            "A popular library for optimizing over all sorts of complex search spaces (includ‐\n",
            "\n",
            "--- Chunk 6929 ---\n",
            "ing real values, such as the learning rate, and discrete values, such as the number\n",
            "of layers).\n",
            "\n",
            "--- Chunk 6930 ---\n",
            "Hyperas, kopt, or Talos\n",
            "Useful libraries for optimizing hyperparameters for Keras models (the first two\n",
            "are based on Hyperopt).\n",
            "\n",
            "--- Chunk 6931 ---\n",
            "Keras Tuner\n",
            "An easy-to-use hyperparameter optimization library by Google for Keras models,\n",
            "with a hosted service for visualization and analysis.\n",
            "\n",
            "--- Chunk 6932 ---\n",
            "Scikit-Optimize (skopt)\n",
            "A general-purpose optimization library. The BayesSearchCV class performs\n",
            "\n",
            "--- Chunk 6933 ---\n",
            "Bayesian optimization using an interface similar to GridSearchCV.\n",
            "\n",
            "--- Chunk 6934 ---\n",
            "Spearmint\n",
            "A Bayesian optimization library.\n",
            "\n",
            "322 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 6935 ---\n",
            "Hyperband\n",
            "A fast hyperparameter tuning library based on the recent Hyperband paper22 by\n",
            "Lisha Li et al.\n",
            "\n",
            "--- Chunk 6936 ---\n",
            "Sklearn-Deap\n",
            "A hyperparameter optimization library based on evolutionary algorithms, with a\n",
            "GridSearchCV-like interface.\n",
            "\n",
            "--- Chunk 6937 ---\n",
            "Moreover, many companies offer services for hyperparameter optimization. We’ll dis‐\n",
            "\n",
            "--- Chunk 6938 ---\n",
            "cuss Google Cloud AI Platform’s hyperparameter tuning service in Chapter 19. Other\n",
            "\n",
            "--- Chunk 6939 ---\n",
            "options include services by Arimo and SigOpt, and CallDesk’s Oscar.\n",
            "\n",
            "--- Chunk 6940 ---\n",
            "Hyperparameter tuning is still an active area of research, and evolutionary algorithms\n",
            "\n",
            "--- Chunk 6941 ---\n",
            "are making a comeback. For example, check out DeepMind’s excellent 2017 paper,23\n",
            "\n",
            "--- Chunk 6942 ---\n",
            "where the authors jointly optimize a population of models and their hyperparame‐\n",
            "\n",
            "--- Chunk 6943 ---\n",
            "ters. Google has also used an evolutionary approach, not just to search for hyperpara‐\n",
            "\n",
            "--- Chunk 6944 ---\n",
            "meters but also to look for the best neural network architecture for the problem; their\n",
            "\n",
            "--- Chunk 6945 ---\n",
            "AutoML suite is already available as a cloud service. Perhaps the days of building neu‐\n",
            "\n",
            "--- Chunk 6946 ---\n",
            "ral networks manually will soon be over? Check out Google’s post on this topic. In\n",
            "\n",
            "--- Chunk 6947 ---\n",
            "fact, evolutionary algorithms have been used successfully to train individual neural\n",
            "\n",
            "--- Chunk 6948 ---\n",
            "networks, replacing the ubiquitous Gradient Descent! For an example, see the 2017\n",
            "\n",
            "--- Chunk 6949 ---\n",
            "post by Uber where the authors introduce their Deep Neuroevolution technique.\n",
            "\n",
            "--- Chunk 6950 ---\n",
            "But despite all this exciting progress and all these tools and services, it still helps to\n",
            "\n",
            "--- Chunk 6951 ---\n",
            "have an idea of what values are reasonable for each hyperparameter so that you can\n",
            "\n",
            "--- Chunk 6952 ---\n",
            "build a quick prototype and restrict the search space. The following sections provide\n",
            "\n",
            "--- Chunk 6953 ---\n",
            "guidelines for choosing the number of hidden layers and neurons in an MLP and for\n",
            "selecting good values for some of the main hyperparameters.\n",
            "\n",
            "--- Chunk 6954 ---\n",
            "Number of Hidden Layers\n",
            "For many problems, you can begin with a single hidden layer and get reasonable\n",
            "\n",
            "--- Chunk 6955 ---\n",
            "results. An MLP with just one hidden layer can theoretically model even the most\n",
            "\n",
            "--- Chunk 6956 ---\n",
            "complex functions, provided it has enough neurons. But for complex problems, deep\n",
            "\n",
            "--- Chunk 6957 ---\n",
            "networks have a much higher parameter efficiency than shallow ones: they can model\n",
            "\n",
            "--- Chunk 6958 ---\n",
            "complex functions using exponentially fewer neurons than shallow nets, allowing\n",
            "\n",
            "--- Chunk 6959 ---\n",
            "them to reach much better performance with the same amount of training data.\n",
            "\n",
            "--- Chunk 6960 ---\n",
            "To understand why, suppose you are asked to draw a forest using some drawing soft‐\n",
            "\n",
            "--- Chunk 6961 ---\n",
            "ware, but you are forbidden to copy and paste anything. It would take an enormous\n",
            "\n",
            "--- Chunk 6962 ---\n",
            "22 Lisha Li et al., “Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization,” Journal of\n",
            "\n",
            "--- Chunk 6963 ---\n",
            "Machine Learning Research 18 (April 2018): 1–52.\n",
            "\n",
            "--- Chunk 6964 ---\n",
            "23 Max Jaderberg et al., “Population Based Training of Neural Networks,” arXiv preprint arXiv:1711.09846\n",
            "(2017).\n",
            "\n",
            "--- Chunk 6965 ---\n",
            "Fine-Tuning Neural Network Hyperparameters | 323\n",
            "\n",
            "--- Chunk 6966 ---\n",
            "amount of time: you would have to draw each tree individually, branch by branch,\n",
            "\n",
            "--- Chunk 6967 ---\n",
            "leaf by leaf. If you could instead draw one leaf, copy and paste it to draw a branch,\n",
            "\n",
            "--- Chunk 6968 ---\n",
            "then copy and paste that branch to create a tree, and finally copy and paste this tree to\n",
            "\n",
            "--- Chunk 6969 ---\n",
            "make a forest, you would be finished in no time. Real-world data is often structured\n",
            "\n",
            "--- Chunk 6970 ---\n",
            "in such a hierarchical way, and deep neural networks automatically take advantage of\n",
            "\n",
            "--- Chunk 6971 ---\n",
            "this fact: lower hidden layers model low-level structures (e.g., line segments of vari‐\n",
            "\n",
            "--- Chunk 6972 ---\n",
            "ous shapes and orientations), intermediate hidden layers combine these low-level\n",
            "\n",
            "--- Chunk 6973 ---\n",
            "structures to model intermediate-level structures (e.g., squares, circles), and the high‐\n",
            "\n",
            "--- Chunk 6974 ---\n",
            "est hidden layers and the output layer combine these intermediate structures to\n",
            "model high-level structures (e.g., faces).\n",
            "\n",
            "--- Chunk 6975 ---\n",
            "Not only does this hierarchical architecture help DNNs converge faster to a good sol‐\n",
            "\n",
            "--- Chunk 6976 ---\n",
            "ution, but it also improves their ability to generalize to new datasets. For example, if\n",
            "\n",
            "--- Chunk 6977 ---\n",
            "you have already trained a model to recognize faces in pictures and you now want to\n",
            "\n",
            "--- Chunk 6978 ---\n",
            "train a new neural network to recognize hairstyles, you can kickstart the training by\n",
            "\n",
            "--- Chunk 6979 ---\n",
            "reusing the lower layers of the first network. Instead of randomly initializing the\n",
            "\n",
            "--- Chunk 6980 ---\n",
            "weights and biases of the first few layers of the new neural network, you can initialize\n",
            "\n",
            "--- Chunk 6981 ---\n",
            "them to the values of the weights and biases of the lower layers of the first network.\n",
            "\n",
            "--- Chunk 6982 ---\n",
            "This way the network will not have to learn from scratch all the low-level structures\n",
            "\n",
            "--- Chunk 6983 ---\n",
            "that occur in most pictures; it will only have to learn the higher-level structures (e.g.,\n",
            "hairstyles). This is called transfer learning.\n",
            "\n",
            "--- Chunk 6984 ---\n",
            "In summary, for many problems you can start with just one or two hidden layers and\n",
            "\n",
            "--- Chunk 6985 ---\n",
            "the neural network will work just fine. For instance, you can easily reach above 97%\n",
            "\n",
            "--- Chunk 6986 ---\n",
            "accuracy on the MNIST dataset using just one hidden layer with a few hundred neu‐\n",
            "\n",
            "--- Chunk 6987 ---\n",
            "rons, and above 98% accuracy using two hidden layers with the same total number of\n",
            "\n",
            "--- Chunk 6988 ---\n",
            "neurons, in roughly the same amount of training time. For more complex problems,\n",
            "\n",
            "--- Chunk 6989 ---\n",
            "you can ramp up the number of hidden layers until you start overfitting the training\n",
            "\n",
            "--- Chunk 6990 ---\n",
            "set. Very complex tasks, such as large image classification or speech recognition, typi‐\n",
            "\n",
            "--- Chunk 6991 ---\n",
            "cally require networks with dozens of layers (or even hundreds, but not fully connec‐\n",
            "\n",
            "--- Chunk 6992 ---\n",
            "ted ones, as we will see in Chapter 14), and they need a huge amount of training data.\n",
            "\n",
            "--- Chunk 6993 ---\n",
            "You will rarely have to train such networks from scratch: it is much more common to\n",
            "\n",
            "--- Chunk 6994 ---\n",
            "reuse parts of a pretrained state-of-the-art network that performs a similar task.\n",
            "\n",
            "--- Chunk 6995 ---\n",
            "Training will then be a lot faster and require much less data (we will discuss this in\n",
            "Chapter 11).\n",
            "\n",
            "--- Chunk 6996 ---\n",
            "Number of Neurons per Hidden Layer\n",
            "The number of neurons in the input and output layers is determined by the type of\n",
            "\n",
            "--- Chunk 6997 ---\n",
            "input and output your task requires. For example, the MNIST task requires 28 × 28 =\n",
            "784 input neurons and 10 output neurons.\n",
            "\n",
            "--- Chunk 6998 ---\n",
            "As for the hidden layers, it used to be common to size them to form a pyramid, with\n",
            "\n",
            "--- Chunk 6999 ---\n",
            "fewer and fewer neurons at each layer—the rationale being that many low-level fea‐\n",
            "\n",
            "--- Chunk 7000 ---\n",
            "324 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 7001 ---\n",
            "tures can coalesce into far fewer high-level features. A typical neural network for\n",
            "\n",
            "--- Chunk 7002 ---\n",
            "MNIST might have 3 hidden layers, the first with 300 neurons, the second with 200,\n",
            "\n",
            "--- Chunk 7003 ---\n",
            "and the third with 100. However, this practice has been largely abandoned because it\n",
            "\n",
            "--- Chunk 7004 ---\n",
            "seems that using the same number of neurons in all hidden layers performs just as\n",
            "\n",
            "--- Chunk 7005 ---\n",
            "well in most cases, or even better; plus, there is only one hyperparameter to tune,\n",
            "\n",
            "--- Chunk 7006 ---\n",
            "instead of one per layer. That said, depending on the dataset, it can sometimes help to\n",
            "make the first hidden layer bigger than the others.\n",
            "\n",
            "--- Chunk 7007 ---\n",
            "Just like the number of layers, you can try increasing the number of neurons gradu‐\n",
            "\n",
            "--- Chunk 7008 ---\n",
            "ally until the network starts overfitting. But in practice, it’s often simpler and more\n",
            "\n",
            "--- Chunk 7009 ---\n",
            "efficient to pick a model with more layers and neurons than you actually need, then\n",
            "\n",
            "--- Chunk 7010 ---\n",
            "use early stopping and other regularization techniques to prevent it from overfitting.\n",
            "\n",
            "--- Chunk 7011 ---\n",
            "Vincent Vanhoucke, a scientist at Google, has dubbed this the “stretch pants”\n",
            "\n",
            "--- Chunk 7012 ---\n",
            "approach: instead of wasting time looking for pants that perfectly match your size,\n",
            "\n",
            "--- Chunk 7013 ---\n",
            "just use large stretch pants that will shrink down to the right size. With this approach,\n",
            "\n",
            "--- Chunk 7014 ---\n",
            "you avoid bottleneck layers that could ruin your model. On the flip side, if a layer has\n",
            "\n",
            "--- Chunk 7015 ---\n",
            "too few neurons, it will not have enough representational power to preserve all the\n",
            "\n",
            "--- Chunk 7016 ---\n",
            "useful information from the inputs (e.g., a layer with two neurons can only output 2D\n",
            "\n",
            "--- Chunk 7017 ---\n",
            "data, so if it processes 3D data, some information will be lost). No matter how big and\n",
            "\n",
            "--- Chunk 7018 ---\n",
            "powerful the rest of the network is, that information will never be recovered.\n",
            "\n",
            "--- Chunk 7019 ---\n",
            "In general you will get more bang for your buck by increasing the\n",
            "number of layers instead of the number of neurons per layer.\n",
            "\n",
            "--- Chunk 7020 ---\n",
            "Learning Rate, Batch Size, and Other Hyperparameters\n",
            "The numbers of hidden layers and neurons are not the only hyperparameters you can\n",
            "\n",
            "--- Chunk 7021 ---\n",
            "tweak in an MLP. Here are some of the most important ones, as well as tips on how to\n",
            "set them:\n",
            "Learning rate\n",
            "\n",
            "--- Chunk 7022 ---\n",
            "The learning rate is arguably the most important hyperparameter. In general, the\n",
            "\n",
            "--- Chunk 7023 ---\n",
            "optimal learning rate is about half of the maximum learning rate (i.e., the learn‐\n",
            "\n",
            "--- Chunk 7024 ---\n",
            "ing rate above which the training algorithm diverges, as we saw in Chapter 4).\n",
            "\n",
            "--- Chunk 7025 ---\n",
            "One way to find a good learning rate is to train the model for a few hundred iter‐\n",
            "\n",
            "--- Chunk 7026 ---\n",
            "ations, starting with a very low learning rate (e.g., 10-5) and gradually increasing\n",
            "\n",
            "--- Chunk 7027 ---\n",
            "it up to a very large value (e.g., 10). This is done by multiplying the learning rate\n",
            "\n",
            "--- Chunk 7028 ---\n",
            "by a constant factor at each iteration (e.g., by exp(log(106)/500) to go from 10-5 to\n",
            "\n",
            "--- Chunk 7029 ---\n",
            "10 in 500 iterations). If you plot the loss as a function of the learning rate (using a\n",
            "\n",
            "--- Chunk 7030 ---\n",
            "log scale for the learning rate), you should see it dropping at first. But after a\n",
            "\n",
            "--- Chunk 7031 ---\n",
            "while, the learning rate will be too large, so the loss will shoot back up: the opti‐\n",
            "\n",
            "--- Chunk 7032 ---\n",
            "Fine-Tuning Neural Network Hyperparameters | 325\n",
            "\n",
            "--- Chunk 7033 ---\n",
            "mal learning rate will be a bit lower than the point at which the loss starts to\n",
            "\n",
            "--- Chunk 7034 ---\n",
            "climb (typically about 10 times lower than the turning point). You can then reini‐\n",
            "\n",
            "--- Chunk 7035 ---\n",
            "tialize your model and train it normally using this good learning rate. We will\n",
            "look at more learning rate techniques in Chapter 11.\n",
            "\n",
            "--- Chunk 7036 ---\n",
            "Optimizer\n",
            "Choosing a better optimizer than plain old Mini-batch Gradient Descent (and\n",
            "\n",
            "--- Chunk 7037 ---\n",
            "tuning its hyperparameters) is also quite important. We will see several advanced\n",
            "optimizers in Chapter 11.\n",
            "\n",
            "--- Chunk 7038 ---\n",
            "Batch size\n",
            "The batch size can have a significant impact on your model’s performance and\n",
            "\n",
            "--- Chunk 7039 ---\n",
            "training time. The main benefit of using large batch sizes is that hardware accel‐\n",
            "\n",
            "--- Chunk 7040 ---\n",
            "erators like GPUs can process them efficiently (see Chapter 19), so the training\n",
            "\n",
            "--- Chunk 7041 ---\n",
            "algorithm will see more instances per second. Therefore, many researchers and\n",
            "\n",
            "--- Chunk 7042 ---\n",
            "practitioners recommend using the largest batch size that can fit in GPU RAM.\n",
            "\n",
            "--- Chunk 7043 ---\n",
            "There’s a catch, though: in practice, large batch sizes often lead to training insta‐\n",
            "\n",
            "--- Chunk 7044 ---\n",
            "bilities, especially at the beginning of training, and the resulting model may not\n",
            "\n",
            "--- Chunk 7045 ---\n",
            "generalize as well as a model trained with a small batch size. In April 2018, Yann\n",
            "\n",
            "--- Chunk 7046 ---\n",
            "LeCun even tweeted “Friends don’t let friends use mini-batches larger than 32,”\n",
            "\n",
            "--- Chunk 7047 ---\n",
            "citing a 2018 paper24 by Dominic Masters and Carlo Luschi which concluded that\n",
            "\n",
            "--- Chunk 7048 ---\n",
            "using small batches (from 2 to 32) was preferable because small batches led to\n",
            "\n",
            "--- Chunk 7049 ---\n",
            "better models in less training time. Other papers point in the opposite direction,\n",
            "\n",
            "--- Chunk 7050 ---\n",
            "however; in 2017, papers by Elad Hoffer et al.25 and Priya Goyal et al.26 showed\n",
            "\n",
            "--- Chunk 7051 ---\n",
            "that it was possible to use very large batch sizes (up to 8,192) using various tech‐\n",
            "\n",
            "--- Chunk 7052 ---\n",
            "niques such as warming up the learning rate (i.e., starting training with a small\n",
            "\n",
            "--- Chunk 7053 ---\n",
            "learning rate, then ramping it up, as we will see in Chapter 11). This led to a very\n",
            "\n",
            "--- Chunk 7054 ---\n",
            "short training time, without any generalization gap. So, one strategy is to try to\n",
            "\n",
            "--- Chunk 7055 ---\n",
            "use a large batch size, using learning rate warmup, and if training is unstable or\n",
            "\n",
            "--- Chunk 7056 ---\n",
            "the final performance is disappointing, then try using a small batch size instead.\n",
            "\n",
            "--- Chunk 7057 ---\n",
            "Activation function\n",
            "We discussed how to choose the activation function earlier in this chapter: in\n",
            "\n",
            "--- Chunk 7058 ---\n",
            "general, the ReLU activation function will be a good default for all hidden layers.\n",
            "For the output layer, it really depends on your task.\n",
            "\n",
            "--- Chunk 7059 ---\n",
            "24 Dominic Masters and Carlo Luschi, “Revisiting Small Batch Training for Deep Neural Networks,” arXiv pre‐\n",
            "print arXiv:1804.07612 (2018).\n",
            "\n",
            "--- Chunk 7060 ---\n",
            "25 Elad Hoffer et al., “Train Longer, Generalize Better: Closing the Generalization Gap in Large Batch Training\n",
            "\n",
            "--- Chunk 7061 ---\n",
            "of Neural Networks,” Proceedings of the 31st International Conference on Neural Information Processing Systems\n",
            "(2017): 1729–1739.\n",
            "\n",
            "--- Chunk 7062 ---\n",
            "26 Priya Goyal et al., “Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour,” arXiv preprint arXiv:\n",
            "1706.02677 (2017).\n",
            "\n",
            "--- Chunk 7063 ---\n",
            "326 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 7064 ---\n",
            "Number of iterations\n",
            "In most cases, the number of training iterations does not actually need to be\n",
            "tweaked: just use early stopping instead.\n",
            "\n",
            "--- Chunk 7065 ---\n",
            "The optimal learning rate depends on the other hyperparameters—\n",
            "especially the batch size—so if you modify any hyperparameter,\n",
            "\n",
            "--- Chunk 7066 ---\n",
            "make sure to update the learning rate as well.\n",
            "\n",
            "--- Chunk 7067 ---\n",
            "For more best practices regarding tuning neural network hyperparameters, check out\n",
            "the excellent 2018 paper27 by Leslie Smith.\n",
            "\n",
            "--- Chunk 7068 ---\n",
            "This concludes our introduction to artificial neural networks and their implementa‐\n",
            "\n",
            "--- Chunk 7069 ---\n",
            "tion with Keras. In the next few chapters, we will discuss techniques to train very\n",
            "\n",
            "--- Chunk 7070 ---\n",
            "deep nets. We will also explore how to customize models using TensorFlow’s lower-\n",
            "\n",
            "--- Chunk 7071 ---\n",
            "level API and how to load and preprocess data efficiently using the Data API. And we\n",
            "\n",
            "--- Chunk 7072 ---\n",
            "will dive into other popular neural network architectures: convolutional neural net‐\n",
            "\n",
            "--- Chunk 7073 ---\n",
            "works for image processing, recurrent neural networks for sequential data, autoen‐\n",
            "\n",
            "--- Chunk 7074 ---\n",
            "coders for representation learning, and generative adversarial networks to model and\n",
            "generate data.28\n",
            "\n",
            "--- Chunk 7075 ---\n",
            "Exercises\n",
            "1. The TensorFlow Playground is a handy neural network simulator built by the\n",
            "\n",
            "--- Chunk 7076 ---\n",
            "TensorFlow team. In this exercise, you will train several binary classifiers in just a\n",
            "\n",
            "--- Chunk 7077 ---\n",
            "few clicks, and tweak the model’s architecture and its hyperparameters to gain\n",
            "\n",
            "--- Chunk 7078 ---\n",
            "some intuition on how neural networks work and what their hyperparameters\n",
            "do. Take some time to explore the following:\n",
            "\n",
            "--- Chunk 7079 ---\n",
            "a. The patterns learned by a neural net. Try training the default neural network\n",
            "\n",
            "--- Chunk 7080 ---\n",
            "by clicking the Run button (top left). Notice how it quickly finds a good solu‐\n",
            "\n",
            "--- Chunk 7081 ---\n",
            "tion for the classification task. The neurons in the first hidden layer have\n",
            "\n",
            "--- Chunk 7082 ---\n",
            "learned simple patterns, while the neurons in the second hidden layer have\n",
            "learned to combine the simple patterns of the first hidden layer into more\n",
            "\n",
            "--- Chunk 7083 ---\n",
            "complex patterns. In general, the more layers there are, the more complex the\n",
            "patterns can be.\n",
            "\n",
            "--- Chunk 7084 ---\n",
            "b. Activation functions. Try replacing the tanh activation function with a ReLU\n",
            "\n",
            "--- Chunk 7085 ---\n",
            "activation function, and train the network again. Notice that it finds a solution\n",
            "\n",
            "--- Chunk 7086 ---\n",
            "27 Leslie N. Smith, “A Disciplined Approach to Neural Network Hyper-Parameters: Part 1—Learning Rate, Batch\n",
            "\n",
            "--- Chunk 7087 ---\n",
            "Size, Momentum, and Weight Decay,” arXiv preprint arXiv:1803.09820 (2018).\n",
            "\n",
            "--- Chunk 7088 ---\n",
            "28 A few extra ANN architectures are presented in Appendix E.\n",
            "\n",
            "Exercises | 327\n",
            "\n",
            "--- Chunk 7089 ---\n",
            "Exercises | 327\n",
            "\n",
            "\n",
            "\n",
            "even faster, but this time the boundaries are linear. This is due to the shape of\n",
            "the ReLU function.\n",
            "\n",
            "--- Chunk 7090 ---\n",
            "c. The risk of local minima. Modify the network architecture to have just one\n",
            "\n",
            "--- Chunk 7091 ---\n",
            "hidden layer with three neurons. Train it multiple times (to reset the network\n",
            "\n",
            "--- Chunk 7092 ---\n",
            "weights, click the Reset button next to the Play button). Notice that the train‐\n",
            "\n",
            "--- Chunk 7093 ---\n",
            "ing time varies a lot, and sometimes it even gets stuck in a local minimum.\n",
            "\n",
            "--- Chunk 7094 ---\n",
            "d. What happens when neural nets are too small. Remove one neuron to keep\n",
            "\n",
            "--- Chunk 7095 ---\n",
            "just two. Notice that the neural network is now incapable of finding a good\n",
            "\n",
            "--- Chunk 7096 ---\n",
            "solution, even if you try multiple times. The model has too few parameters\n",
            "and systematically underfits the training set.\n",
            "\n",
            "--- Chunk 7097 ---\n",
            "e. What happens when neural nets are large enough. Set the number of neurons\n",
            "\n",
            "--- Chunk 7098 ---\n",
            "to eight, and train the network several times. Notice that it is now consistently\n",
            "\n",
            "--- Chunk 7099 ---\n",
            "fast and never gets stuck. This highlights an important finding in neural net‐\n",
            "\n",
            "--- Chunk 7100 ---\n",
            "work theory: large neural networks almost never get stuck in local minima,\n",
            "and even when they do these local optima are almost as good as the global\n",
            "\n",
            "--- Chunk 7101 ---\n",
            "optimum. However, they can still get stuck on long plateaus for a long time.\n",
            "\n",
            "--- Chunk 7102 ---\n",
            "f. The risk of vanishing gradients in deep networks. Select the spiral dataset (the\n",
            "\n",
            "--- Chunk 7103 ---\n",
            "bottom-right dataset under “DATA”), and change the network architecture to\n",
            "\n",
            "--- Chunk 7104 ---\n",
            "have four hidden layers with eight neurons each. Notice that training takes\n",
            "\n",
            "--- Chunk 7105 ---\n",
            "much longer and often gets stuck on plateaus for long periods of time. Also\n",
            "\n",
            "--- Chunk 7106 ---\n",
            "notice that the neurons in the highest layers (on the right) tend to evolve\n",
            "\n",
            "--- Chunk 7107 ---\n",
            "faster than the neurons in the lowest layers (on the left). This problem, called\n",
            "\n",
            "--- Chunk 7108 ---\n",
            "the “vanishing gradients” problem, can be alleviated with better weight initial‐\n",
            "\n",
            "--- Chunk 7109 ---\n",
            "ization and other techniques, better optimizers (such as AdaGrad or Adam),\n",
            "or Batch Normalization (discussed in Chapter 11).\n",
            "\n",
            "--- Chunk 7110 ---\n",
            "g. Go further. Take an hour or so to play around with other parameters and get a\n",
            "\n",
            "--- Chunk 7111 ---\n",
            "feel for what they do, to build an intuitive understanding about neural\n",
            "networks.\n",
            "\n",
            "--- Chunk 7112 ---\n",
            "2. Draw an ANN using the original artificial neurons (like the ones in Figure 10-3)\n",
            "\n",
            "--- Chunk 7113 ---\n",
            "that computes A ⊕ B (where ⊕ represents the XOR operation). Hint: A ⊕ B =\n",
            "(A ∧ ¬ B ∨ (¬ A ∧ B).\n",
            "\n",
            "--- Chunk 7114 ---\n",
            "3. Why is it generally preferable to use a Logistic Regression classifier rather than a\n",
            "\n",
            "--- Chunk 7115 ---\n",
            "classical Perceptron (i.e., a single layer of threshold logic units trained using the\n",
            "\n",
            "--- Chunk 7116 ---\n",
            "Perceptron training algorithm)? How can you tweak a Perceptron to make it\n",
            "equivalent to a Logistic Regression classifier?\n",
            "\n",
            "--- Chunk 7117 ---\n",
            "4. Why was the logistic activation function a key ingredient in training the first\n",
            "MLPs?\n",
            "\n",
            "--- Chunk 7118 ---\n",
            "5. Name three popular activation functions. Can you draw them?\n",
            "\n",
            "328 | Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
            "\n",
            "--- Chunk 7119 ---\n",
            "6. Suppose you have an MLP composed of one input layer with 10 passthrough\n",
            "\n",
            "--- Chunk 7120 ---\n",
            "neurons, followed by one hidden layer with 50 artificial neurons, and finally one\n",
            "\n",
            "--- Chunk 7121 ---\n",
            "output layer with 3 artificial neurons. All artificial neurons use the ReLU activa‐\n",
            "tion function.\n",
            "• What is the shape of the input matrix X?\n",
            "\n",
            "--- Chunk 7122 ---\n",
            "• What are the shapes of the hidden layer’s weight vector Wh and its bias vector\n",
            "\n",
            "--- Chunk 7123 ---\n",
            "bh?\n",
            "• What are the shapes of the output layer’s weight vector Wo and its bias vector\n",
            "\n",
            "--- Chunk 7124 ---\n",
            "bo?\n",
            "• What is the shape of the network’s output matrix Y?\n",
            "• Write the equation that computes the network’s output matrix Y as a function\n",
            "\n",
            "--- Chunk 7125 ---\n",
            "of X, Wh, bh, Wo, and bo.\n",
            "\n",
            "--- Chunk 7126 ---\n",
            "7. How many neurons do you need in the output layer if you want to classify email\n",
            "\n",
            "--- Chunk 7127 ---\n",
            "into spam or ham? What activation function should you use in the output layer?\n",
            "\n",
            "--- Chunk 7128 ---\n",
            "If instead you want to tackle MNIST, how many neurons do you need in the out‐\n",
            "\n",
            "--- Chunk 7129 ---\n",
            "put layer, and which activation function should you use? What about for getting\n",
            "your network to predict housing prices, as in Chapter 2?\n",
            "\n",
            "--- Chunk 7130 ---\n",
            "8. What is backpropagation and how does it work? What is the difference between\n",
            "backpropagation and reverse-mode autodiff?\n",
            "\n",
            "--- Chunk 7131 ---\n",
            "9. Can you list all the hyperparameters you can tweak in a basic MLP? If the MLP\n",
            "\n",
            "--- Chunk 7132 ---\n",
            "overfits the training data, how could you tweak these hyperparameters to try to\n",
            "solve the problem?\n",
            "\n",
            "--- Chunk 7133 ---\n",
            "10. Train a deep MLP on the MNIST dataset (you can load it using keras.data\n",
            "\n",
            "--- Chunk 7134 ---\n",
            "sets.mnist.load_data(). See if you can get over 98% precision. Try searching\n",
            "\n",
            "--- Chunk 7135 ---\n",
            "for the optimal learning rate by using the approach presented in this chapter (i.e.,\n",
            "\n",
            "--- Chunk 7136 ---\n",
            "by growing the learning rate exponentially, plotting the loss, and finding the\n",
            "\n",
            "--- Chunk 7137 ---\n",
            "point where the loss shoots up). Try adding all the bells and whistles—save\n",
            "\n",
            "--- Chunk 7138 ---\n",
            "checkpoints, use early stopping, and plot learning curves using TensorBoard.\n",
            "\n",
            "--- Chunk 7139 ---\n",
            "Solutions to these exercises are available in Appendix A.\n",
            "\n",
            "Exercises | 329\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER 11\n",
            "Training Deep Neural Networks\n",
            "\n",
            "--- Chunk 7140 ---\n",
            "In Chapter 10 we introduced artificial neural networks and trained our first deep\n",
            "\n",
            "--- Chunk 7141 ---\n",
            "neural networks. But they were shallow nets, with just a few hidden layers. What if\n",
            "\n",
            "--- Chunk 7142 ---\n",
            "you need to tackle a complex problem, such as detecting hundreds of types of objects\n",
            "\n",
            "--- Chunk 7143 ---\n",
            "in high-resolution images? You may need to train a much deeper DNN, perhaps with\n",
            "\n",
            "--- Chunk 7144 ---\n",
            "10 layers or many more, each containing hundreds of neurons, linked by hundreds of\n",
            "\n",
            "--- Chunk 7145 ---\n",
            "thousands of connections. Training a deep DNN isn’t a walk in the park. Here are\n",
            "some of the problems you could run into:\n",
            "\n",
            "--- Chunk 7146 ---\n",
            "• You may be faced with the tricky vanishing gradients problem or the related\n",
            "\n",
            "--- Chunk 7147 ---\n",
            "exploding gradients problem. This is when the gradients grow smaller and\n",
            "smaller, or larger and larger, when flowing backward through the DNN during\n",
            "\n",
            "--- Chunk 7148 ---\n",
            "training. Both of these problems make lower layers very hard to train.\n",
            "\n",
            "--- Chunk 7149 ---\n",
            "• You might not have enough training data for such a large network, or it might be\n",
            "too costly to label.\n",
            "\n",
            "--- Chunk 7150 ---\n",
            "• Training may be extremely slow.\n",
            "• A model with millions of parameters would severely risk overfitting the training\n",
            "\n",
            "--- Chunk 7151 ---\n",
            "set, especially if there are not enough training instances or if they are too noisy.\n",
            "\n",
            "--- Chunk 7152 ---\n",
            "In this chapter we will go through each of these problems and present techniques to\n",
            "\n",
            "--- Chunk 7153 ---\n",
            "solve them. We will start by exploring the vanishing and exploding gradients prob‐\n",
            "\n",
            "--- Chunk 7154 ---\n",
            "lems and some of their most popular solutions. Next, we will look at transfer learning\n",
            "\n",
            "--- Chunk 7155 ---\n",
            "and unsupervised pretraining, which can help you tackle complex tasks even when\n",
            "\n",
            "--- Chunk 7156 ---\n",
            "you have little labeled data. Then we will discuss various optimizers that can speed up\n",
            "\n",
            "--- Chunk 7157 ---\n",
            "training large models tremendously. Finally, we will go through a few popular regula‐\n",
            "rization techniques for large neural networks.\n",
            "\n",
            "--- Chunk 7158 ---\n",
            "With these tools, you will be able to train very deep nets. Welcome to Deep Learning!\n",
            "\n",
            "--- Chunk 7159 ---\n",
            "331\n",
            "\n",
            "--- Chunk 7160 ---\n",
            "The Vanishing/Exploding Gradients Problems\n",
            "As we discussed in Chapter 10, the backpropagation algorithm works by going from\n",
            "\n",
            "--- Chunk 7161 ---\n",
            "the output layer to the input layer, propagating the error gradient along the way. Once\n",
            "\n",
            "--- Chunk 7162 ---\n",
            "the algorithm has computed the gradient of the cost function with regard to each\n",
            "\n",
            "--- Chunk 7163 ---\n",
            "parameter in the network, it uses these gradients to update each parameter with a\n",
            "Gradient Descent step.\n",
            "\n",
            "--- Chunk 7164 ---\n",
            "Unfortunately, gradients often get smaller and smaller as the algorithm progresses\n",
            "\n",
            "--- Chunk 7165 ---\n",
            "down to the lower layers. As a result, the Gradient Descent update leaves the lower\n",
            "\n",
            "--- Chunk 7166 ---\n",
            "layers’ connection weights virtually unchanged, and training never converges to a\n",
            "\n",
            "--- Chunk 7167 ---\n",
            "good solution. We call this the vanishing gradients problem. In some cases, the oppo‐\n",
            "\n",
            "--- Chunk 7168 ---\n",
            "site can happen: the gradients can grow bigger and bigger until layers get insanely\n",
            "\n",
            "--- Chunk 7169 ---\n",
            "large weight updates and the algorithm diverges. This is the exploding gradients prob‐\n",
            "\n",
            "--- Chunk 7170 ---\n",
            "lem, which surfaces in recurrent neural networks (see Chapter 15). More generally,\n",
            "\n",
            "--- Chunk 7171 ---\n",
            "deep neural networks suffer from unstable gradients; different layers may learn at\n",
            "widely different speeds.\n",
            "\n",
            "--- Chunk 7172 ---\n",
            "This unfortunate behavior was empirically observed long ago, and it was one of the\n",
            "\n",
            "--- Chunk 7173 ---\n",
            "reasons deep neural networks were mostly abandoned in the early 2000s. It wasn’t\n",
            "\n",
            "--- Chunk 7174 ---\n",
            "clear what caused the gradients to be so unstable when training a DNN, but some\n",
            "\n",
            "--- Chunk 7175 ---\n",
            "light was shed in a 2010 paper by Xavier Glorot and Yoshua Bengio.1 The authors\n",
            "\n",
            "--- Chunk 7176 ---\n",
            "found a few suspects, including the combination of the popular logistic sigmoid acti‐\n",
            "\n",
            "--- Chunk 7177 ---\n",
            "vation function and the weight initialization technique that was most popular at the\n",
            "\n",
            "--- Chunk 7178 ---\n",
            "time (i.e., a normal distribution with a mean of 0 and a standard deviation of 1). In\n",
            "\n",
            "--- Chunk 7179 ---\n",
            "short, they showed that with this activation function and this initialization scheme,\n",
            "\n",
            "--- Chunk 7180 ---\n",
            "the variance of the outputs of each layer is much greater than the variance of its\n",
            "\n",
            "--- Chunk 7181 ---\n",
            "inputs. Going forward in the network, the variance keeps increasing after each layer\n",
            "\n",
            "--- Chunk 7182 ---\n",
            "until the activation function saturates at the top layers. This saturation is actually\n",
            "\n",
            "--- Chunk 7183 ---\n",
            "made worse by the fact that the logistic function has a mean of 0.5, not 0 (the hyper‐\n",
            "\n",
            "--- Chunk 7184 ---\n",
            "bolic tangent function has a mean of 0 and behaves slightly better than the logistic\n",
            "function in deep networks).\n",
            "\n",
            "--- Chunk 7185 ---\n",
            "Looking at the logistic activation function (see Figure 11-1), you can see that when\n",
            "\n",
            "--- Chunk 7186 ---\n",
            "inputs become large (negative or positive), the function saturates at 0 or 1, with a\n",
            "\n",
            "--- Chunk 7187 ---\n",
            "derivative extremely close to 0. Thus, when backpropagation kicks in it has virtually\n",
            "\n",
            "--- Chunk 7188 ---\n",
            "no gradient to propagate back through the network; and what little gradient exists\n",
            "\n",
            "--- Chunk 7189 ---\n",
            "keeps getting diluted as backpropagation progresses down through the top layers, so\n",
            "there is really nothing left for the lower layers.\n",
            "\n",
            "--- Chunk 7190 ---\n",
            "1 Xavier Glorot and Yoshua Bengio, “Understanding the Difficulty of Training Deep Feedforward Neural Net‐\n",
            "\n",
            "--- Chunk 7191 ---\n",
            "works,” Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (2010): 249–256.\n",
            "\n",
            "--- Chunk 7192 ---\n",
            "332 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "\n",
            "\n",
            "Figure 11-1. Logistic activation function saturation\n",
            "\n",
            "--- Chunk 7193 ---\n",
            "Glorot and He Initialization\n",
            "In their paper, Glorot and Bengio propose a way to significantly alleviate the unstable\n",
            "\n",
            "--- Chunk 7194 ---\n",
            "gradients problem. They point out that we need the signal to flow properly in both\n",
            "\n",
            "--- Chunk 7195 ---\n",
            "directions: in the forward direction when making predictions, and in the reverse\n",
            "\n",
            "--- Chunk 7196 ---\n",
            "direction when backpropagating gradients. We don’t want the signal to die out, nor\n",
            "\n",
            "--- Chunk 7197 ---\n",
            "do we want it to explode and saturate. For the signal to flow properly, the authors\n",
            "\n",
            "--- Chunk 7198 ---\n",
            "argue that we need the variance of the outputs of each layer to be equal to the var‐\n",
            "\n",
            "--- Chunk 7199 ---\n",
            "iance of its inputs,2 and we need the gradients to have equal variance before and after\n",
            "\n",
            "--- Chunk 7200 ---\n",
            "flowing through a layer in the reverse direction (please check out the paper if you are\n",
            "\n",
            "--- Chunk 7201 ---\n",
            "interested in the mathematical details). It is actually not possible to guarantee both\n",
            "\n",
            "--- Chunk 7202 ---\n",
            "unless the layer has an equal number of inputs and neurons (these numbers are called\n",
            "\n",
            "--- Chunk 7203 ---\n",
            "the fan-in and fan-out of the layer), but Glorot and Bengio proposed a good compro‐\n",
            "\n",
            "--- Chunk 7204 ---\n",
            "mise that has proven to work very well in practice: the connection weights of each\n",
            "\n",
            "--- Chunk 7205 ---\n",
            "layer must be initialized randomly as described in Equation 11-1, where fanavg = (fanin\n",
            "\n",
            "--- Chunk 7206 ---\n",
            "+ fanout)/2. This initialization strategy is called Xavier initialization or Glorot initiali‐\n",
            "zation, after the paper’s first author.\n",
            "\n",
            "--- Chunk 7207 ---\n",
            "2 Here’s an analogy: if you set a microphone amplifier’s knob too close to zero, people won’t hear your voice, but\n",
            "\n",
            "--- Chunk 7208 ---\n",
            "if you set it too close to the max, your voice will be saturated and people won’t understand what you are say‐\n",
            "\n",
            "--- Chunk 7209 ---\n",
            "ing. Now imagine a chain of such amplifiers: they all need to be set properly in order for your voice to come\n",
            "\n",
            "--- Chunk 7210 ---\n",
            "out loud and clear at the end of the chain. Your voice has to come out of each amplifier at the same amplitude\n",
            "as it came in.\n",
            "\n",
            "--- Chunk 7211 ---\n",
            "The Vanishing/Exploding Gradients Problems | 333\n",
            "\n",
            "\n",
            "\n",
            "Equation 11-1. Glorot initialization (when using the logistic activation function)\n",
            "\n",
            "--- Chunk 7212 ---\n",
            "Normal distribution with mean 0 and variance σ2 = 1\n",
            "fanavg\n",
            "\n",
            "Or a uniform distribution between −r and  + r, with r = 3\n",
            "fanavg\n",
            "\n",
            "--- Chunk 7213 ---\n",
            "If you replace fanavg with fanin in Equation 11-1, you get an initialization strategy that\n",
            "\n",
            "--- Chunk 7214 ---\n",
            "Yann LeCun proposed in the 1990s. He called it LeCun initialization. Genevieve Orr\n",
            "\n",
            "--- Chunk 7215 ---\n",
            "and Klaus-Robert Müller even recommended it in their 1998 book Neural Networks:\n",
            "\n",
            "--- Chunk 7216 ---\n",
            "Tricks of the Trade (Springer). LeCun initialization is equivalent to Glorot initializa‐\n",
            "\n",
            "--- Chunk 7217 ---\n",
            "tion when fanin = fanout. It took over a decade for researchers to realize how important\n",
            "\n",
            "--- Chunk 7218 ---\n",
            "this trick is. Using Glorot initialization can speed up training considerably, and it is\n",
            "one of the tricks that led to the success of Deep Learning.\n",
            "\n",
            "--- Chunk 7219 ---\n",
            "Some papers3 have provided similar strategies for different activation functions.\n",
            "\n",
            "--- Chunk 7220 ---\n",
            "These strategies differ only by the scale of the variance and whether they use fanavg or\n",
            "\n",
            "--- Chunk 7221 ---\n",
            "fanin, as shown in Table 11-1 (for the uniform distribution, just compute r = 3σ2).\n",
            "\n",
            "--- Chunk 7222 ---\n",
            "The initialization strategy for the ReLU activation function (and its variants, includ‐\n",
            "\n",
            "--- Chunk 7223 ---\n",
            "ing the ELU activation described shortly) is sometimes called He initialization, after\n",
            "\n",
            "--- Chunk 7224 ---\n",
            "the paper’s first author. The SELU activation function will be explained later in this\n",
            "\n",
            "--- Chunk 7225 ---\n",
            "chapter. It should be used with LeCun initialization (preferably with a normal distri‐\n",
            "bution, as we will see).\n",
            "\n",
            "--- Chunk 7226 ---\n",
            "Table 11-1. Initialization parameters for each type of activation function\n",
            "Initialization Activation functions σ² (Normal)\n",
            "\n",
            "--- Chunk 7227 ---\n",
            "Glorot None, tanh, logistic, softmax 1 / fanavg\n",
            "\n",
            "--- Chunk 7228 ---\n",
            "He ReLU and variants 2 / fanin\n",
            "\n",
            "LeCun SELU 1 / fanin\n",
            "\n",
            "--- Chunk 7229 ---\n",
            "By default, Keras uses Glorot initialization with a uniform distribution. When creat‐\n",
            "\n",
            "--- Chunk 7230 ---\n",
            "ing a layer, you can change this to He initialization by setting kernel_initial\n",
            "izer=\"he_uniform\" or kernel_initializer=\"he_normal\" like this:\n",
            "\n",
            "--- Chunk 7231 ---\n",
            "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
            "\n",
            "--- Chunk 7232 ---\n",
            "If you want He initialization with a uniform distribution but based on fanavg rather\n",
            "\n",
            "--- Chunk 7233 ---\n",
            "than fanin, you can use the VarianceScaling initializer like this:\n",
            "\n",
            "--- Chunk 7234 ---\n",
            "3 E.g., Kaiming He et al., “Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet\n",
            "\n",
            "--- Chunk 7235 ---\n",
            "Classification,” Proceedings of the 2015 IEEE International Conference on Computer Vision (2015): 1026–1034.\n",
            "\n",
            "--- Chunk 7236 ---\n",
            "334 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "--- Chunk 7237 ---\n",
            "he_avg_init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',\n",
            "                                                 distribution='uniform')\n",
            "\n",
            "--- Chunk 7238 ---\n",
            "keras.layers.Dense(10, activation=\"sigmoid\", kernel_initializer=he_avg_init)\n",
            "\n",
            "--- Chunk 7239 ---\n",
            "Nonsaturating Activation Functions\n",
            "One of the insights in the 2010 paper by Glorot and Bengio was that the problems\n",
            "\n",
            "--- Chunk 7240 ---\n",
            "with unstable gradients were in part due to a poor choice of activation function. Until\n",
            "\n",
            "--- Chunk 7241 ---\n",
            "then most people had assumed that if Mother Nature had chosen to use roughly sig‐\n",
            "\n",
            "--- Chunk 7242 ---\n",
            "moid activation functions in biological neurons, they must be an excellent choice. But\n",
            "\n",
            "--- Chunk 7243 ---\n",
            "it turns out that other activation functions behave much better in deep neural net‐\n",
            "\n",
            "--- Chunk 7244 ---\n",
            "works—in particular, the ReLU activation function, mostly because it does not satu‐\n",
            "rate for positive values (and because it is fast to compute).\n",
            "\n",
            "--- Chunk 7245 ---\n",
            "Unfortunately, the ReLU activation function is not perfect. It suffers from a problem\n",
            "\n",
            "--- Chunk 7246 ---\n",
            "known as the dying ReLUs: during training, some neurons effectively “die,” meaning\n",
            "\n",
            "--- Chunk 7247 ---\n",
            "they stop outputting anything other than 0. In some cases, you may find that half of\n",
            "\n",
            "--- Chunk 7248 ---\n",
            "your network’s neurons are dead, especially if you used a large learning rate. A neu‐\n",
            "\n",
            "--- Chunk 7249 ---\n",
            "ron dies when its weights get tweaked in such a way that the weighted sum of its\n",
            "\n",
            "--- Chunk 7250 ---\n",
            "inputs are negative for all instances in the training set. When this happens, it just\n",
            "\n",
            "--- Chunk 7251 ---\n",
            "keeps outputting zeros, and Gradient Descent does not affect it anymore because the\n",
            "\n",
            "--- Chunk 7252 ---\n",
            "gradient of the ReLU function is zero when its input is negative.4\n",
            "\n",
            "--- Chunk 7253 ---\n",
            "To solve this problem, you may want to use a variant of the ReLU function, such as\n",
            "\n",
            "--- Chunk 7254 ---\n",
            "the leaky ReLU. This function is defined as LeakyReLUα(z) = max(αz, z) (see\n",
            "\n",
            "--- Chunk 7255 ---\n",
            "Figure 11-2). The hyperparameter α defines how much the function “leaks”: it is the\n",
            "\n",
            "--- Chunk 7256 ---\n",
            "slope of the function for z < 0 and is typically set to 0.01. This small slope ensures that\n",
            "\n",
            "--- Chunk 7257 ---\n",
            "leaky ReLUs never die; they can go into a long coma, but they have a chance to even‐\n",
            "\n",
            "--- Chunk 7258 ---\n",
            "tually wake up. A 2015 paper5 compared several variants of the ReLU activation func‐\n",
            "\n",
            "--- Chunk 7259 ---\n",
            "tion, and one of its conclusions was that the leaky variants always outperformed the\n",
            "\n",
            "--- Chunk 7260 ---\n",
            "strict ReLU activation function. In fact, setting α = 0.2 (a huge leak) seemed to result\n",
            "\n",
            "--- Chunk 7261 ---\n",
            "in better performance than α = 0.01 (a small leak). The paper also evaluated the\n",
            "\n",
            "--- Chunk 7262 ---\n",
            "randomized leaky ReLU (RReLU), where α is picked randomly in a given range during\n",
            "\n",
            "--- Chunk 7263 ---\n",
            "training and is fixed to an average value during testing. RReLU also performed fairly\n",
            "\n",
            "--- Chunk 7264 ---\n",
            "well and seemed to act as a regularizer (reducing the risk of overfitting the training\n",
            "\n",
            "--- Chunk 7265 ---\n",
            "set). Finally, the paper evaluated the parametric leaky ReLU (PReLU), where α is\n",
            "\n",
            "--- Chunk 7266 ---\n",
            "authorized to be learned during training (instead of being a hyperparameter, it\n",
            "\n",
            "--- Chunk 7267 ---\n",
            "becomes a parameter that can be modified by backpropagation like any other param‐\n",
            "\n",
            "--- Chunk 7268 ---\n",
            "4 Unless it is part of the first hidden layer, a dead neuron may sometimes come back to life: Gradient Descent\n",
            "\n",
            "--- Chunk 7269 ---\n",
            "may indeed tweak neurons in the layers below in such a way that the weighted sum of the dead neuron’s\n",
            "inputs is positive again.\n",
            "\n",
            "--- Chunk 7270 ---\n",
            "5 Bing Xu et al., “Empirical Evaluation of Rectified Activations in Convolutional Network,” arXiv preprint\n",
            "arXiv:1505.00853 (2015).\n",
            "\n",
            "--- Chunk 7271 ---\n",
            "The Vanishing/Exploding Gradients Problems | 335\n",
            "\n",
            "--- Chunk 7272 ---\n",
            "eter). PReLU was reported to strongly outperform ReLU on large image datasets, but\n",
            "\n",
            "--- Chunk 7273 ---\n",
            "on smaller datasets it runs the risk of overfitting the training set.\n",
            "\n",
            "--- Chunk 7274 ---\n",
            "Figure 11-2. Leaky ReLU: like ReLU, but with a small slope for negative values\n",
            "\n",
            "--- Chunk 7275 ---\n",
            "Last but not least, a 2015 paper by Djork-Arné Clevert et al.6 proposed a new activa‐\n",
            "\n",
            "--- Chunk 7276 ---\n",
            "tion function called the exponential linear unit (ELU) that outperformed all the ReLU\n",
            "\n",
            "--- Chunk 7277 ---\n",
            "variants in the authors’ experiments: training time was reduced, and the neural net‐\n",
            "\n",
            "--- Chunk 7278 ---\n",
            "work performed better on the test set. Figure 11-3 graphs the function, and Equation\n",
            "11-2 shows its definition.\n",
            "\n",
            "--- Chunk 7279 ---\n",
            "Equation 11-2. ELU activation function\n",
            "α exp z − 1 if z < 0\n",
            "\n",
            "ELUα z =\n",
            "z if z ≥ 0\n",
            "\n",
            "Figure 11-3. ELU activation function\n",
            "\n",
            "--- Chunk 7280 ---\n",
            "6 Djork-Arné Clevert et al., “Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs),”\n",
            "\n",
            "--- Chunk 7281 ---\n",
            "Proceedings of the International Conference on Learning Representations (2016).\n",
            "\n",
            "--- Chunk 7282 ---\n",
            "336 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "\n",
            "\n",
            "The ELU activation function looks a lot like the ReLU function, with a few major\n",
            "differences:\n",
            "\n",
            "--- Chunk 7283 ---\n",
            "• It takes on negative values when z < 0, which allows the unit to have an average\n",
            "\n",
            "--- Chunk 7284 ---\n",
            "output closer to 0 and helps alleviate the vanishing gradients problem. The\n",
            "\n",
            "--- Chunk 7285 ---\n",
            "hyperparameter α defines the value that the ELU function approaches when z is a\n",
            "\n",
            "--- Chunk 7286 ---\n",
            "large negative number. It is usually set to 1, but you can tweak it like any other\n",
            "hyperparameter.\n",
            "\n",
            "--- Chunk 7287 ---\n",
            "• It has a nonzero gradient for z < 0, which avoids the dead neurons problem.\n",
            "\n",
            "--- Chunk 7288 ---\n",
            "• If α is equal to 1 then the function is smooth everywhere, including around z = 0,\n",
            "\n",
            "--- Chunk 7289 ---\n",
            "which helps speed up Gradient Descent since it does not bounce as much to the\n",
            "left and right of z = 0.\n",
            "\n",
            "--- Chunk 7290 ---\n",
            "The main drawback of the ELU activation function is that it is slower to compute\n",
            "\n",
            "--- Chunk 7291 ---\n",
            "than the ReLU function and its variants (due to the use of the exponential function).\n",
            "\n",
            "--- Chunk 7292 ---\n",
            "Its faster convergence rate during training compensates for that slow computation,\n",
            "\n",
            "--- Chunk 7293 ---\n",
            "but still, at test time an ELU network will be slower than a ReLU network.\n",
            "\n",
            "--- Chunk 7294 ---\n",
            "Then, a 2017 paper7 by Günter Klambauer et al. introduced the Scaled ELU (SELU)\n",
            "\n",
            "--- Chunk 7295 ---\n",
            "activation function: as its name suggests, it is a scaled variant of the ELU activation\n",
            "\n",
            "--- Chunk 7296 ---\n",
            "function. The authors showed that if you build a neural network composed exclu‐\n",
            "\n",
            "--- Chunk 7297 ---\n",
            "sively of a stack of dense layers, and if all hidden layers use the SELU activation func‐\n",
            "\n",
            "--- Chunk 7298 ---\n",
            "tion, then the network will self-normalize: the output of each layer will tend to\n",
            "\n",
            "--- Chunk 7299 ---\n",
            "preserve a mean of 0 and standard deviation of 1 during training, which solves the\n",
            "\n",
            "--- Chunk 7300 ---\n",
            "vanishing/exploding gradients problem. As a result, the SELU activation function\n",
            "\n",
            "--- Chunk 7301 ---\n",
            "often significantly outperforms other activation functions for such neural nets (espe‐\n",
            "\n",
            "--- Chunk 7302 ---\n",
            "cially deep ones). There are, however, a few conditions for self-normalization to hap‐\n",
            "pen (see the paper for the mathematical justification):\n",
            "\n",
            "--- Chunk 7303 ---\n",
            "• The input features must be standardized (mean 0 and standard deviation 1).\n",
            "\n",
            "--- Chunk 7304 ---\n",
            "• Every hidden layer’s weights must be initialized with LeCun normal initialization.\n",
            "\n",
            "--- Chunk 7305 ---\n",
            "In Keras, this means setting kernel_initializer=\"lecun_normal\".\n",
            "• The network’s architecture must be sequential. Unfortunately, if you try to use\n",
            "\n",
            "--- Chunk 7306 ---\n",
            "SELU in nonsequential architectures, such as recurrent networks (see Chap‐\n",
            "\n",
            "--- Chunk 7307 ---\n",
            "ter 15) or networks with skip connections (i.e., connections that skip layers, such\n",
            "\n",
            "--- Chunk 7308 ---\n",
            "as in Wide & Deep nets), self-normalization will not be guaranteed, so SELU will\n",
            "not necessarily outperform other activation functions.\n",
            "\n",
            "--- Chunk 7309 ---\n",
            "7 Günter Klambauer et al., “Self-Normalizing Neural Networks,” Proceedings of the 31st International Conference\n",
            "\n",
            "--- Chunk 7310 ---\n",
            "on Neural Information Processing Systems (2017): 972–981.\n",
            "\n",
            "--- Chunk 7311 ---\n",
            "The Vanishing/Exploding Gradients Problems | 337\n",
            "\n",
            "--- Chunk 7312 ---\n",
            "• The paper only guarantees self-normalization if all layers are dense, but some\n",
            "\n",
            "--- Chunk 7313 ---\n",
            "researchers have noted that the SELU activation function can improve perfor‐\n",
            "mance in convolutional neural nets as well (see Chapter 14).\n",
            "\n",
            "--- Chunk 7314 ---\n",
            "So, which activation function should you use for the hidden layers\n",
            "of your deep neural networks? Although your mileage will vary, in\n",
            "\n",
            "--- Chunk 7315 ---\n",
            "general SELU > ELU > leaky ReLU (and its variants) > ReLU > tanh\n",
            "> logistic. If the network’s architecture prevents it from self-\n",
            "\n",
            "--- Chunk 7316 ---\n",
            "normalizing, then ELU may perform better than SELU (since SELU\n",
            "is not smooth at z = 0). If you care a lot about runtime latency, then\n",
            "\n",
            "--- Chunk 7317 ---\n",
            "you may prefer leaky ReLU. If you don’t want to tweak yet another\n",
            "hyperparameter, you may use the default α values used by Keras\n",
            "\n",
            "--- Chunk 7318 ---\n",
            "(e.g., 0.3 for leaky ReLU). If you have spare time and computing\n",
            "power, you can use cross-validation to evaluate other activation\n",
            "\n",
            "--- Chunk 7319 ---\n",
            "functions, such as RReLU if your network is overfitting or PReLU\n",
            "if you have a huge training set. That said, because ReLU is the most\n",
            "\n",
            "--- Chunk 7320 ---\n",
            "used activation function (by far), many libraries and hardware\n",
            "accelerators provide ReLU-specific optimizations; therefore, if\n",
            "\n",
            "--- Chunk 7321 ---\n",
            "speed is your priority, ReLU might still be the best choice.\n",
            "\n",
            "--- Chunk 7322 ---\n",
            "To use the leaky ReLU activation function, create a LeakyReLU layer and add it to your\n",
            "model just after the layer you want to apply it to:\n",
            "\n",
            "--- Chunk 7323 ---\n",
            "model = keras.models.Sequential([\n",
            "    [...]\n",
            "    keras.layers.Dense(10, kernel_initializer=\"he_normal\"),\n",
            "    keras.layers.LeakyReLU(alpha=0.2),\n",
            "\n",
            "--- Chunk 7324 ---\n",
            "[...]\n",
            "])\n",
            "\n",
            "--- Chunk 7325 ---\n",
            "For PReLU, replace LeakyRelu(alpha=0.2) with PReLU(). There is currently no offi‐\n",
            "\n",
            "--- Chunk 7326 ---\n",
            "cial implementation of RReLU in Keras, but you can fairly easily implement your own\n",
            "\n",
            "--- Chunk 7327 ---\n",
            "(to learn how to do that, see the exercises at the end of Chapter 12).\n",
            "For SELU activation, set activation=\"selu\" and kernel_initializer=\"lecun_nor\n",
            "\n",
            "--- Chunk 7328 ---\n",
            "mal\" when creating a layer:\n",
            "\n",
            "--- Chunk 7329 ---\n",
            "layer = keras.layers.Dense(10, activation=\"selu\",\n",
            "                           kernel_initializer=\"lecun_normal\")\n",
            "\n",
            "--- Chunk 7330 ---\n",
            "Batch Normalization\n",
            "Although using He initialization along with ELU (or any variant of ReLU) can signifi‐\n",
            "\n",
            "--- Chunk 7331 ---\n",
            "cantly reduce the danger of the vanishing/exploding gradients problems at the begin‐\n",
            "\n",
            "--- Chunk 7332 ---\n",
            "ning of training, it doesn’t guarantee that they won’t come back during training.\n",
            "\n",
            "--- Chunk 7333 ---\n",
            "338 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "--- Chunk 7334 ---\n",
            "In a 2015 paper,8 Sergey Ioffe and Christian Szegedy proposed a technique called\n",
            "\n",
            "--- Chunk 7335 ---\n",
            "Batch Normalization (BN) that addresses these problems. The technique consists of\n",
            "\n",
            "--- Chunk 7336 ---\n",
            "adding an operation in the model just before or after the activation function of each\n",
            "\n",
            "--- Chunk 7337 ---\n",
            "hidden layer. This operation simply zero-centers and normalizes each input, then\n",
            "\n",
            "--- Chunk 7338 ---\n",
            "scales and shifts the result using two new parameter vectors per layer: one for scaling,\n",
            "\n",
            "--- Chunk 7339 ---\n",
            "the other for shifting. In other words, the operation lets the model learn the optimal\n",
            "\n",
            "--- Chunk 7340 ---\n",
            "scale and mean of each of the layer’s inputs. In many cases, if you add a BN layer as\n",
            "\n",
            "--- Chunk 7341 ---\n",
            "the very first layer of your neural network, you do not need to standardize your train‐\n",
            "\n",
            "--- Chunk 7342 ---\n",
            "ing set (e.g., using a StandardScaler); the BN layer will do it for you (well, approxi‐\n",
            "\n",
            "--- Chunk 7343 ---\n",
            "mately, since it only looks at one batch at a time, and it can also rescale and shift each\n",
            "input feature).\n",
            "\n",
            "--- Chunk 7344 ---\n",
            "input feature).\n",
            "In order to zero-center and normalize the inputs, the algorithm needs to estimate\n",
            "\n",
            "--- Chunk 7345 ---\n",
            "each input’s mean and standard deviation. It does so by evaluating the mean and stan‐\n",
            "\n",
            "--- Chunk 7346 ---\n",
            "dard deviation of the input over the current mini-batch (hence the name “Batch Nor‐\n",
            "\n",
            "--- Chunk 7347 ---\n",
            "malization”). The whole operation is summarized step by step in Equation 11-3.\n",
            "\n",
            "--- Chunk 7348 ---\n",
            "Equation 11-3. Batch Normalization algorithm\n",
            "mB\n",
            "\n",
            "1 . μB = 1\n",
            "m ∑ x i\n",
            "\n",
            "B i = 1\n",
            "mB\n",
            "\n",
            "2 . σ 2 2\n",
            "B = 1\n",
            "\n",
            "m ∑ x i − μ\n",
            "B i = 1 B\n",
            "\n",
            "3 . x i x i − μ\n",
            "= B\n",
            "\n",
            "--- Chunk 7349 ---\n",
            "σ 2\n",
            "B + ε\n",
            "\n",
            "4 . z i = γ⊗ x i + β\n",
            "\n",
            "In this algorithm:\n",
            "\n",
            "--- Chunk 7350 ---\n",
            "In this algorithm:\n",
            "\n",
            "• μB is the vector of input means, evaluated over the whole mini-batch B (it con‐\n",
            "tains one mean per input).\n",
            "\n",
            "--- Chunk 7351 ---\n",
            "• σB is the vector of input standard deviations, also evaluated over the whole mini-\n",
            "batch (it contains one standard deviation per input).\n",
            "\n",
            "--- Chunk 7352 ---\n",
            "• mB is the number of instances in the mini-batch.\n",
            "• x(i) is the vector of zero-centered and normalized inputs for instance i.\n",
            "\n",
            "--- Chunk 7353 ---\n",
            "8 Sergey Ioffe and Christian Szegedy, “Batch Normalization: Accelerating Deep Network Training by Reducing\n",
            "\n",
            "--- Chunk 7354 ---\n",
            "Internal Covariate Shift,” Proceedings of the 32nd International Conference on Machine Learning (2015): 448–\n",
            "456.\n",
            "\n",
            "--- Chunk 7355 ---\n",
            "The Vanishing/Exploding Gradients Problems | 339\n",
            "\n",
            "--- Chunk 7356 ---\n",
            "• γ is the output scale parameter vector for the layer (it contains one scale parame‐\n",
            "ter per input).\n",
            "\n",
            "--- Chunk 7357 ---\n",
            "• ⊗ represents element-wise multiplication (each input is multiplied by its corre‐\n",
            "sponding output scale parameter).\n",
            "\n",
            "--- Chunk 7358 ---\n",
            "• β is the output shift (offset) parameter vector for the layer (it contains one offset\n",
            "\n",
            "--- Chunk 7359 ---\n",
            "parameter per input). Each input is offset by its corresponding shift parameter.\n",
            "\n",
            "--- Chunk 7360 ---\n",
            "• ε is a tiny number that avoids division by zero (typically 10–5). This is called a\n",
            "smoothing term.\n",
            "\n",
            "--- Chunk 7361 ---\n",
            "• z(i) is the output of the BN operation. It is a rescaled and shifted version of the\n",
            "inputs.\n",
            "\n",
            "--- Chunk 7362 ---\n",
            "So during training, BN standardizes its inputs, then rescales and offsets them. Good!\n",
            "\n",
            "--- Chunk 7363 ---\n",
            "What about at test time? Well, it’s not that simple. Indeed, we may need to make pre‐\n",
            "\n",
            "--- Chunk 7364 ---\n",
            "dictions for individual instances rather than for batches of instances: in this case, we\n",
            "\n",
            "--- Chunk 7365 ---\n",
            "will have no way to compute each input’s mean and standard deviation. Moreover,\n",
            "\n",
            "--- Chunk 7366 ---\n",
            "even if we do have a batch of instances, it may be too small, or the instances may not\n",
            "\n",
            "--- Chunk 7367 ---\n",
            "be independent and identically distributed, so computing statistics over the batch\n",
            "\n",
            "--- Chunk 7368 ---\n",
            "instances would be unreliable. One solution could be to wait until the end of training,\n",
            "\n",
            "--- Chunk 7369 ---\n",
            "then run the whole training set through the neural network and compute the mean\n",
            "\n",
            "--- Chunk 7370 ---\n",
            "and standard deviation of each input of the BN layer. These “final” input means and\n",
            "\n",
            "--- Chunk 7371 ---\n",
            "standard deviations could then be used instead of the batch input means and stan‐\n",
            "\n",
            "--- Chunk 7372 ---\n",
            "dard deviations when making predictions. However, most implementations of Batch\n",
            "\n",
            "--- Chunk 7373 ---\n",
            "Normalization estimate these final statistics during training by using a moving aver‐\n",
            "\n",
            "--- Chunk 7374 ---\n",
            "age of the layer’s input means and standard deviations. This is what Keras does auto‐\n",
            "\n",
            "--- Chunk 7375 ---\n",
            "matically when you use the BatchNormalization layer. To sum up, four parameter\n",
            "\n",
            "--- Chunk 7376 ---\n",
            "vectors are learned in each batch-normalized layer: γ (the output scale vector) and β\n",
            "\n",
            "--- Chunk 7377 ---\n",
            "(the output offset vector) are learned through regular backpropagation, and μ (the\n",
            "\n",
            "--- Chunk 7378 ---\n",
            "final input mean vector) and σ (the final input standard deviation vector) are estima‐\n",
            "\n",
            "--- Chunk 7379 ---\n",
            "ted using an exponential moving average. Note that μ and σ are estimated during\n",
            "\n",
            "--- Chunk 7380 ---\n",
            "training, but they are used only after training (to replace the batch input means and\n",
            "standard deviations in Equation 11-3).\n",
            "\n",
            "--- Chunk 7381 ---\n",
            "Ioffe and Szegedy demonstrated that Batch Normalization considerably improved all\n",
            "\n",
            "--- Chunk 7382 ---\n",
            "the deep neural networks they experimented with, leading to a huge improvement in\n",
            "\n",
            "--- Chunk 7383 ---\n",
            "the ImageNet classification task (ImageNet is a large database of images classified into\n",
            "\n",
            "--- Chunk 7384 ---\n",
            "many classes, commonly used to evaluate computer vision systems). The vanishing\n",
            "\n",
            "--- Chunk 7385 ---\n",
            "gradients problem was strongly reduced, to the point that they could use saturating\n",
            "\n",
            "--- Chunk 7386 ---\n",
            "activation functions such as the tanh and even the logistic activation function. The\n",
            "\n",
            "--- Chunk 7387 ---\n",
            "networks were also much less sensitive to the weight initialization. The authors were\n",
            "\n",
            "--- Chunk 7388 ---\n",
            "able to use much larger learning rates, significantly speeding up the learning process.\n",
            "Specifically, they note that:\n",
            "\n",
            "--- Chunk 7389 ---\n",
            "340 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "--- Chunk 7390 ---\n",
            "Applied to a state-of-the-art image classification model, Batch Normalization achieves\n",
            "\n",
            "--- Chunk 7391 ---\n",
            "the same accuracy with 14 times fewer training steps, and beats the original model by a\n",
            "\n",
            "--- Chunk 7392 ---\n",
            "significant margin. […] Using an ensemble of batch-normalized networks, we improve\n",
            "\n",
            "--- Chunk 7393 ---\n",
            "upon the best published result on ImageNet classification: reaching 4.9% top-5 valida‐\n",
            "\n",
            "--- Chunk 7394 ---\n",
            "tion error (and 4.8% test error), exceeding the accuracy of human raters.\n",
            "\n",
            "--- Chunk 7395 ---\n",
            "Finally, like a gift that keeps on giving, Batch Normalization acts like a regularizer,\n",
            "\n",
            "--- Chunk 7396 ---\n",
            "reducing the need for other regularization techniques (such as dropout, described\n",
            "later in this chapter).\n",
            "\n",
            "--- Chunk 7397 ---\n",
            "Batch Normalization does, however, add some complexity to the model (although it\n",
            "\n",
            "--- Chunk 7398 ---\n",
            "can remove the need for normalizing the input data, as we discussed earlier). More‐\n",
            "\n",
            "--- Chunk 7399 ---\n",
            "over, there is a runtime penalty: the neural network makes slower predictions due to\n",
            "\n",
            "--- Chunk 7400 ---\n",
            "the extra computations required at each layer. Fortunately, it’s often possible to fuse\n",
            "\n",
            "--- Chunk 7401 ---\n",
            "the BN layer with the previous layer, after training, thereby avoiding the runtime pen‐\n",
            "\n",
            "--- Chunk 7402 ---\n",
            "alty. This is done by updating the previous layer’s weights and biases so that it directly\n",
            "\n",
            "--- Chunk 7403 ---\n",
            "produces outputs of the appropriate scale and offset. For example, if the previous\n",
            "\n",
            "--- Chunk 7404 ---\n",
            "layer computes XW + b, then the BN layer will compute γ⊗(XW + b – μ)/σ + β\n",
            "\n",
            "--- Chunk 7405 ---\n",
            "(ignoring the smoothing term ε in the denominator). If we define W′ = γ⊗W/σ and b\n",
            "\n",
            "--- Chunk 7406 ---\n",
            "′ = γ⊗(b – μ)/σ + β, the equation simplifies to XW′ + b′. So if we replace the previous\n",
            "\n",
            "--- Chunk 7407 ---\n",
            "layer’s weights and biases (W and b) with the updated weights and biases (W′ and b′),\n",
            "\n",
            "--- Chunk 7408 ---\n",
            "we can get rid of the BN layer (TFLite’s optimizer does this automatically; see Chap‐\n",
            "ter 19).\n",
            "\n",
            "--- Chunk 7409 ---\n",
            "You may find that training is rather slow, because each epoch takes\n",
            "much more time when you use Batch Normalization. This is usu‐\n",
            "\n",
            "--- Chunk 7410 ---\n",
            "ally counterbalanced by the fact that convergence is much faster\n",
            "with BN, so it will take fewer epochs to reach the same perfor‐\n",
            "\n",
            "--- Chunk 7411 ---\n",
            "mance. All in all, wall time will usually be shorter (this is the time\n",
            "measured by the clock on your wall).\n",
            "\n",
            "--- Chunk 7412 ---\n",
            "Implementing Batch Normalization with Keras\n",
            "As with most things with Keras, implementing Batch Normalization is simple and\n",
            "\n",
            "--- Chunk 7413 ---\n",
            "intuitive. Just add a BatchNormalization layer before or after each hidden layer’s\n",
            "\n",
            "--- Chunk 7414 ---\n",
            "activation function, and optionally add a BN layer as well as the first layer in your\n",
            "\n",
            "--- Chunk 7415 ---\n",
            "model. For example, this model applies BN after every hidden layer and as the first\n",
            "layer in the model (after flattening the input images):\n",
            "\n",
            "--- Chunk 7416 ---\n",
            "The Vanishing/Exploding Gradients Problems | 341\n",
            "\n",
            "--- Chunk 7417 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.Flatten(input_shape=[28, 28]),\n",
            "    keras.layers.BatchNormalization(),\n",
            "\n",
            "--- Chunk 7418 ---\n",
            "keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
            "    keras.layers.BatchNormalization(),\n",
            "\n",
            "--- Chunk 7419 ---\n",
            "keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
            "    keras.layers.BatchNormalization(),\n",
            "\n",
            "--- Chunk 7420 ---\n",
            "keras.layers.Dense(10, activation=\"softmax\")\n",
            "])\n",
            "\n",
            "--- Chunk 7421 ---\n",
            "That’s all! In this tiny example with just two hidden layers, it’s unlikely that Batch\n",
            "\n",
            "--- Chunk 7422 ---\n",
            "Normalization will have a very positive impact; but for deeper networks it can make a\n",
            "tremendous difference.\n",
            "Let’s display the model summary:\n",
            "\n",
            "--- Chunk 7423 ---\n",
            ">>> model.summary()\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "\n",
            "--- Chunk 7424 ---\n",
            "Layer (type)                 Output Shape              Param #\n",
            "=================================================================\n",
            "\n",
            "--- Chunk 7425 ---\n",
            "flatten_3 (Flatten)          (None, 784)               0\n",
            "_________________________________________________________________\n",
            "\n",
            "--- Chunk 7426 ---\n",
            "batch_normalization_v2 (Batc (None, 784)               3136\n",
            "_________________________________________________________________\n",
            "\n",
            "--- Chunk 7427 ---\n",
            "dense_50 (Dense)             (None, 300)               235500\n",
            "_________________________________________________________________\n",
            "\n",
            "--- Chunk 7428 ---\n",
            "batch_normalization_v2_1 (Ba (None, 300)               1200\n",
            "_________________________________________________________________\n",
            "\n",
            "--- Chunk 7429 ---\n",
            "dense_51 (Dense)             (None, 100)               30100\n",
            "_________________________________________________________________\n",
            "\n",
            "--- Chunk 7430 ---\n",
            "batch_normalization_v2_2 (Ba (None, 100)               400\n",
            "_________________________________________________________________\n",
            "\n",
            "--- Chunk 7431 ---\n",
            "dense_52 (Dense)             (None, 10)                1010\n",
            "=================================================================\n",
            "Total params: 271,346\n",
            "\n",
            "--- Chunk 7432 ---\n",
            "Trainable params: 268,978\n",
            "Non-trainable params: 2,368\n",
            "\n",
            "--- Chunk 7433 ---\n",
            "As you can see, each BN layer adds four parameters per input: γ, β, μ, and σ (for\n",
            "\n",
            "--- Chunk 7434 ---\n",
            "example, the first BN layer adds 3,136 parameters, which is 4 × 784). The last two\n",
            "\n",
            "--- Chunk 7435 ---\n",
            "parameters, μ and σ, are the moving averages; they are not affected by backpropaga‐\n",
            "\n",
            "--- Chunk 7436 ---\n",
            "tion, so Keras calls them “non-trainable”9 (if you count the total number of BN\n",
            "\n",
            "--- Chunk 7437 ---\n",
            "parameters, 3,136 + 1,200 + 400, and divide by 2, you get 2,368, which is the total\n",
            "number of non-trainable parameters in this model).\n",
            "\n",
            "--- Chunk 7438 ---\n",
            "9 However, they are estimated during training, based on the training data, so arguably they are trainable. In\n",
            "\n",
            "--- Chunk 7439 ---\n",
            "Keras, “non-trainable” really means “untouched by backpropagation.”\n",
            "\n",
            "--- Chunk 7440 ---\n",
            "342 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "--- Chunk 7441 ---\n",
            "Let’s look at the parameters of the first BN layer. Two are trainable (by backpropaga‐\n",
            "tion), and two are not:\n",
            "\n",
            "--- Chunk 7442 ---\n",
            ">>> [(var.name, var.trainable) for var in model.layers[1].variables]\n",
            "[('batch_normalization_v2/gamma:0', True),\n",
            "\n",
            "--- Chunk 7443 ---\n",
            "('batch_normalization_v2/beta:0', True),\n",
            " ('batch_normalization_v2/moving_mean:0', False),\n",
            " ('batch_normalization_v2/moving_variance:0', False)]\n",
            "\n",
            "--- Chunk 7444 ---\n",
            "Now when you create a BN layer in Keras, it also creates two operations that will be\n",
            "\n",
            "--- Chunk 7445 ---\n",
            "called by Keras at each iteration during training. These operations will update the\n",
            "\n",
            "--- Chunk 7446 ---\n",
            "moving averages. Since we are using the TensorFlow backend, these operations are\n",
            "TensorFlow operations (we will discuss TF operations in Chapter 12):\n",
            "\n",
            "--- Chunk 7447 ---\n",
            ">>> model.layers[1].updates\n",
            "[<tf.Operation 'cond_2/Identity' type=Identity>,\n",
            " <tf.Operation 'cond_3/Identity' type=Identity>]\n",
            "\n",
            "--- Chunk 7448 ---\n",
            "The authors of the BN paper argued in favor of adding the BN layers before the acti‐\n",
            "\n",
            "--- Chunk 7449 ---\n",
            "vation functions, rather than after (as we just did). There is some debate about this, as\n",
            "\n",
            "--- Chunk 7450 ---\n",
            "which is preferable seems to depend on the task—you can experiment with this too to\n",
            "\n",
            "--- Chunk 7451 ---\n",
            "see which option works best on your dataset. To add the BN layers before the activa‐\n",
            "\n",
            "--- Chunk 7452 ---\n",
            "tion functions, you must remove the activation function from the hidden layers and\n",
            "\n",
            "--- Chunk 7453 ---\n",
            "add them as separate layers after the BN layers. Moreover, since a Batch Normaliza‐\n",
            "\n",
            "--- Chunk 7454 ---\n",
            "tion layer includes one offset parameter per input, you can remove the bias term from\n",
            "the previous layer (just pass use_bias=False when creating it):\n",
            "\n",
            "--- Chunk 7455 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.Flatten(input_shape=[28, 28]),\n",
            "    keras.layers.BatchNormalization(),\n",
            "\n",
            "--- Chunk 7456 ---\n",
            "keras.layers.Dense(300, kernel_initializer=\"he_normal\", use_bias=False),\n",
            "    keras.layers.BatchNormalization(),\n",
            "\n",
            "--- Chunk 7457 ---\n",
            "keras.layers.Activation(\"elu\"),\n",
            "    keras.layers.Dense(100, kernel_initializer=\"he_normal\", use_bias=False),\n",
            "\n",
            "--- Chunk 7458 ---\n",
            "keras.layers.BatchNormalization(),\n",
            "    keras.layers.Activation(\"elu\"),\n",
            "    keras.layers.Dense(10, activation=\"softmax\")\n",
            "])\n",
            "\n",
            "--- Chunk 7459 ---\n",
            "The BatchNormalization class has quite a few hyperparameters you can tweak. The\n",
            "\n",
            "--- Chunk 7460 ---\n",
            "defaults will usually be fine, but you may occasionally need to tweak the momentum.\n",
            "\n",
            "--- Chunk 7461 ---\n",
            "This hyperparameter is used by the BatchNormalization layer when it updates the\n",
            "\n",
            "--- Chunk 7462 ---\n",
            "exponential moving averages; given a new value v (i.e., a new vector of input means\n",
            "\n",
            "--- Chunk 7463 ---\n",
            "or standard deviations computed over the current batch), the layer updates the run‐\n",
            "ning average � using the following equation:\n",
            "\n",
            "--- Chunk 7464 ---\n",
            "v v × momentum + v × 1 − momentum\n",
            "\n",
            "The Vanishing/Exploding Gradients Problems | 343\n",
            "\n",
            "--- Chunk 7465 ---\n",
            "A good momentum value is typically close to 1; for example, 0.9, 0.99, or 0.999 (you\n",
            "want more 9s for larger datasets and smaller mini-batches).\n",
            "\n",
            "--- Chunk 7466 ---\n",
            "Another important hyperparameter is axis: it determines which axis should be nor‐\n",
            "\n",
            "--- Chunk 7467 ---\n",
            "malized. It defaults to –1, meaning that by default it will normalize the last axis (using\n",
            "\n",
            "--- Chunk 7468 ---\n",
            "the means and standard deviations computed across the other axes). When the input\n",
            "\n",
            "--- Chunk 7469 ---\n",
            "batch is 2D (i.e., the batch shape is [batch size, features]), this means that each input\n",
            "\n",
            "--- Chunk 7470 ---\n",
            "feature will be normalized based on the mean and standard deviation computed\n",
            "\n",
            "--- Chunk 7471 ---\n",
            "across all the instances in the batch. For example, the first BN layer in the previous\n",
            "\n",
            "--- Chunk 7472 ---\n",
            "code example will independently normalize (and rescale and shift) each of the 784\n",
            "\n",
            "--- Chunk 7473 ---\n",
            "input features. If we move the first BN layer before the Flatten layer, then the input\n",
            "\n",
            "--- Chunk 7474 ---\n",
            "batches will be 3D, with shape [batch size, height, width]; therefore, the BN layer will\n",
            "\n",
            "--- Chunk 7475 ---\n",
            "compute 28 means and 28 standard deviations (1 per column of pixels, computed\n",
            "\n",
            "--- Chunk 7476 ---\n",
            "across all instances in the batch and across all rows in the column), and it will nor‐\n",
            "\n",
            "--- Chunk 7477 ---\n",
            "malize all pixels in a given column using the same mean and standard deviation.\n",
            "\n",
            "--- Chunk 7478 ---\n",
            "There will also be just 28 scale parameters and 28 shift parameters. If instead you still\n",
            "\n",
            "--- Chunk 7479 ---\n",
            "want to treat each of the 784 pixels independently, then you should set axis=[1, 2].\n",
            "\n",
            "--- Chunk 7480 ---\n",
            "Notice that the BN layer does not perform the same computation during training and\n",
            "\n",
            "--- Chunk 7481 ---\n",
            "after training: it uses batch statistics during training and the “final” statistics after\n",
            "\n",
            "--- Chunk 7482 ---\n",
            "training (i.e., the final values of the moving averages). Let’s take a peek at the source\n",
            "code of this class to see how this is handled:\n",
            "\n",
            "--- Chunk 7483 ---\n",
            "class BatchNormalization(keras.layers.Layer):\n",
            "    [...]\n",
            "    def call(self, inputs, training=None):\n",
            "        [...]\n",
            "\n",
            "--- Chunk 7484 ---\n",
            "The call() method is the one that performs the computations; as you can see, it has\n",
            "\n",
            "--- Chunk 7485 ---\n",
            "an extra training argument, which is set to None by default, but the fit() method\n",
            "\n",
            "--- Chunk 7486 ---\n",
            "sets to it to 1 during training. If you ever need to write a custom layer, and it must\n",
            "\n",
            "--- Chunk 7487 ---\n",
            "behave differently during training and testing, add a training argument to the\n",
            "\n",
            "--- Chunk 7488 ---\n",
            "call() method and use this argument in the method to decide what to compute10 (we\n",
            "will discuss custom layers in Chapter 12).\n",
            "\n",
            "--- Chunk 7489 ---\n",
            "BatchNormalization has become one of the most-used layers in deep neural net‐\n",
            "\n",
            "--- Chunk 7490 ---\n",
            "works, to the point that it is often omitted in the diagrams, as it is assumed that BN is\n",
            "\n",
            "--- Chunk 7491 ---\n",
            "added after every layer. But a recent paper11 by Hongyi Zhang et al. may change this\n",
            "\n",
            "--- Chunk 7492 ---\n",
            "assumption: by using a novel fixed-update (fixup) weight initialization technique, the\n",
            "\n",
            "--- Chunk 7493 ---\n",
            "authors managed to train a very deep neural network (10,000 layers!) without BN,\n",
            "\n",
            "--- Chunk 7494 ---\n",
            "10 The Keras API also specifies a keras.backend.learning_phase() function that should return 1 during train‐\n",
            "ing and 0 otherwise.\n",
            "\n",
            "--- Chunk 7495 ---\n",
            "11 Hongyi Zhang et al., “Fixup Initialization: Residual Learning Without Normalization,” arXiv preprint arXiv:\n",
            "1901.09321 (2019).\n",
            "\n",
            "--- Chunk 7496 ---\n",
            "344 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "--- Chunk 7497 ---\n",
            "achieving state-of-the-art performance on complex image classification tasks. As this\n",
            "\n",
            "--- Chunk 7498 ---\n",
            "is bleeding-edge research, however, you may want to wait for additional research to\n",
            "confirm this finding before you drop Batch Normalization.\n",
            "\n",
            "--- Chunk 7499 ---\n",
            "Gradient Clipping\n",
            "Another popular technique to mitigate the exploding gradients problem is to clip the\n",
            "\n",
            "--- Chunk 7500 ---\n",
            "gradients during backpropagation so that they never exceed some threshold. This is\n",
            "\n",
            "--- Chunk 7501 ---\n",
            "called Gradient Clipping.12 This technique is most often used in recurrent neural net‐\n",
            "\n",
            "--- Chunk 7502 ---\n",
            "works, as Batch Normalization is tricky to use in RNNs, as we will see in Chapter 15.\n",
            "For other types of networks, BN is usually sufficient.\n",
            "\n",
            "--- Chunk 7503 ---\n",
            "In Keras, implementing Gradient Clipping is just a matter of setting the clipvalue or\n",
            "clipnorm argument when creating an optimizer, like this:\n",
            "\n",
            "--- Chunk 7504 ---\n",
            "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
            "model.compile(loss=\"mse\", optimizer=optimizer)\n",
            "\n",
            "--- Chunk 7505 ---\n",
            "This optimizer will clip every component of the gradient vector to a value between\n",
            "\n",
            "--- Chunk 7506 ---\n",
            "–1.0 and 1.0. This means that all the partial derivatives of the loss (with regard to each\n",
            "\n",
            "--- Chunk 7507 ---\n",
            "and every trainable parameter) will be clipped between –1.0 and 1.0. The threshold is\n",
            "\n",
            "--- Chunk 7508 ---\n",
            "a hyperparameter you can tune. Note that it may change the orientation of the gradi‐\n",
            "\n",
            "--- Chunk 7509 ---\n",
            "ent vector. For instance, if the original gradient vector is [0.9, 100.0], it points mostly\n",
            "\n",
            "--- Chunk 7510 ---\n",
            "in the direction of the second axis; but once you clip it by value, you get [0.9, 1.0],\n",
            "\n",
            "--- Chunk 7511 ---\n",
            "which points roughly in the diagonal between the two axes. In practice, this approach\n",
            "\n",
            "--- Chunk 7512 ---\n",
            "works well. If you want to ensure that Gradient Clipping does not change the direc‐\n",
            "\n",
            "--- Chunk 7513 ---\n",
            "tion of the gradient vector, you should clip by norm by setting clipnorm instead of\n",
            "\n",
            "--- Chunk 7514 ---\n",
            "clipvalue. This will clip the whole gradient if its ℓ2 norm is greater than the thres‐\n",
            "\n",
            "--- Chunk 7515 ---\n",
            "hold you picked. For example, if you set clipnorm=1.0, then the vector [0.9, 100.0]\n",
            "\n",
            "--- Chunk 7516 ---\n",
            "will be clipped to [0.00899964, 0.9999595], preserving its orientation but almost elim‐\n",
            "\n",
            "--- Chunk 7517 ---\n",
            "inating the first component. If you observe that the gradients explode during training\n",
            "\n",
            "--- Chunk 7518 ---\n",
            "(you can track the size of the gradients using TensorBoard), you may want to try both\n",
            "\n",
            "--- Chunk 7519 ---\n",
            "clipping by value and clipping by norm, with different thresholds, and see which\n",
            "option performs best on the validation set.\n",
            "\n",
            "--- Chunk 7520 ---\n",
            "Reusing Pretrained Layers\n",
            "It is generally not a good idea to train a very large DNN from scratch: instead, you\n",
            "\n",
            "--- Chunk 7521 ---\n",
            "should always try to find an existing neural network that accomplishes a similar task\n",
            "\n",
            "--- Chunk 7522 ---\n",
            "to the one you are trying to tackle (we will discuss how to find them in Chapter 14),\n",
            "\n",
            "--- Chunk 7523 ---\n",
            "then reuse the lower layers of this network. This technique is called transfer learning.\n",
            "\n",
            "--- Chunk 7524 ---\n",
            "12 Razvan Pascanu et al., “On the Difficulty of Training Recurrent Neural Networks,” Proceedings of the 30th\n",
            "\n",
            "--- Chunk 7525 ---\n",
            "International Conference on Machine Learning (2013): 1310–1318.\n",
            "\n",
            "--- Chunk 7526 ---\n",
            "Reusing Pretrained Layers | 345\n",
            "\n",
            "--- Chunk 7527 ---\n",
            "It will not only speed up training considerably, but also require significantly less\n",
            "training data.\n",
            "\n",
            "--- Chunk 7528 ---\n",
            "training data.\n",
            "Suppose you have access to a DNN that was trained to classify pictures into 100 dif‐\n",
            "\n",
            "--- Chunk 7529 ---\n",
            "ferent categories, including animals, plants, vehicles, and everyday objects. You now\n",
            "\n",
            "--- Chunk 7530 ---\n",
            "want to train a DNN to classify specific types of vehicles. These tasks are very similar,\n",
            "\n",
            "--- Chunk 7531 ---\n",
            "even partly overlapping, so you should try to reuse parts of the first network (see\n",
            "Figure 11-4).\n",
            "\n",
            "--- Chunk 7532 ---\n",
            "Figure 11-4. Reusing pretrained layers\n",
            "\n",
            "--- Chunk 7533 ---\n",
            "If the input pictures of your new task don’t have the same size as\n",
            "the ones used in the original task, you will usually have to add a\n",
            "\n",
            "--- Chunk 7534 ---\n",
            "preprocessing step to resize them to the size expected by the origi‐\n",
            "nal model. More generally, transfer learning will work best when\n",
            "\n",
            "--- Chunk 7535 ---\n",
            "the inputs have similar low-level features.\n",
            "\n",
            "--- Chunk 7536 ---\n",
            "The output layer of the original model should usually be replaced because it is most\n",
            "\n",
            "--- Chunk 7537 ---\n",
            "likely not useful at all for the new task, and it may not even have the right number of\n",
            "outputs for the new task.\n",
            "\n",
            "--- Chunk 7538 ---\n",
            "Similarly, the upper hidden layers of the original model are less likely to be as useful\n",
            "\n",
            "--- Chunk 7539 ---\n",
            "as the lower layers, since the high-level features that are most useful for the new task\n",
            "\n",
            "--- Chunk 7540 ---\n",
            "may differ significantly from the ones that were most useful for the original task. You\n",
            "want to find the right number of layers to reuse.\n",
            "\n",
            "--- Chunk 7541 ---\n",
            "346 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "--- Chunk 7542 ---\n",
            "The more similar the tasks are, the more layers you want to reuse\n",
            "(starting with the lower layers). For very similar tasks, try keeping\n",
            "\n",
            "--- Chunk 7543 ---\n",
            "all the hidden layers and just replacing the output layer.\n",
            "\n",
            "--- Chunk 7544 ---\n",
            "Try freezing all the reused layers first (i.e., make their weights non-trainable so that\n",
            "\n",
            "--- Chunk 7545 ---\n",
            "Gradient Descent won’t modify them), then train your model and see how it per‐\n",
            "\n",
            "--- Chunk 7546 ---\n",
            "forms. Then try unfreezing one or two of the top hidden layers to let backpropaga‐\n",
            "\n",
            "--- Chunk 7547 ---\n",
            "tion tweak them and see if performance improves. The more training data you have,\n",
            "\n",
            "--- Chunk 7548 ---\n",
            "the more layers you can unfreeze. It is also useful to reduce the learning rate when\n",
            "\n",
            "--- Chunk 7549 ---\n",
            "you unfreeze reused layers: this will avoid wrecking their fine-tuned weights.\n",
            "\n",
            "--- Chunk 7550 ---\n",
            "If you still cannot get good performance, and you have little training data, try drop‐\n",
            "\n",
            "--- Chunk 7551 ---\n",
            "ping the top hidden layer(s) and freezing all the remaining hidden layers again. You\n",
            "\n",
            "--- Chunk 7552 ---\n",
            "can iterate until you find the right number of layers to reuse. If you have plenty of\n",
            "\n",
            "--- Chunk 7553 ---\n",
            "training data, you may try replacing the top hidden layers instead of dropping them,\n",
            "and even adding more hidden layers.\n",
            "\n",
            "--- Chunk 7554 ---\n",
            "Transfer Learning with Keras\n",
            "Let’s look at an example. Suppose the Fashion MNIST dataset only contained eight\n",
            "\n",
            "--- Chunk 7555 ---\n",
            "classes—for example, all the classes except for sandal and shirt. Someone built and\n",
            "\n",
            "--- Chunk 7556 ---\n",
            "trained a Keras model on that set and got reasonably good performance (>90% accu‐\n",
            "\n",
            "--- Chunk 7557 ---\n",
            "racy). Let’s call this model A. You now want to tackle a different task: you have images\n",
            "\n",
            "--- Chunk 7558 ---\n",
            "of sandals and shirts, and you want to train a binary classifier (positive=shirt,\n",
            "\n",
            "--- Chunk 7559 ---\n",
            "negative=sandal). Your dataset is quite small; you only have 200 labeled images.\n",
            "\n",
            "--- Chunk 7560 ---\n",
            "When you train a new model for this task (let’s call it model B) with the same archi‐\n",
            "\n",
            "--- Chunk 7561 ---\n",
            "tecture as model A, it performs reasonably well (97.2% accuracy). But since it’s a\n",
            "\n",
            "--- Chunk 7562 ---\n",
            "much easier task (there are just two classes), you were hoping for more. While drink‐\n",
            "\n",
            "--- Chunk 7563 ---\n",
            "ing your morning coffee, you realize that your task is quite similar to task A, so per‐\n",
            "haps transfer learning can help? Let’s find out!\n",
            "\n",
            "--- Chunk 7564 ---\n",
            "First, you need to load model A and create a new model based on that model’s layers.\n",
            "Let’s reuse all the layers except for the output layer:\n",
            "\n",
            "--- Chunk 7565 ---\n",
            "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
            "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
            "\n",
            "--- Chunk 7566 ---\n",
            "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
            "\n",
            "--- Chunk 7567 ---\n",
            "Note that model_A and model_B_on_A now share some layers. When you train\n",
            "\n",
            "--- Chunk 7568 ---\n",
            "model_B_on_A, it will also affect model_A. If you want to avoid that, you need to clone\n",
            "\n",
            "--- Chunk 7569 ---\n",
            "model_A before you reuse its layers. To do this, you clone model A’s architecture with\n",
            "\n",
            "--- Chunk 7570 ---\n",
            "clone_model(), then copy its weights (since clone_model() does not clone the\n",
            "weights):\n",
            "\n",
            "--- Chunk 7571 ---\n",
            "Reusing Pretrained Layers | 347\n",
            "\n",
            "\n",
            "\n",
            "model_A_clone = keras.models.clone_model(model_A)\n",
            "model_A_clone.set_weights(model_A.get_weights())\n",
            "\n",
            "--- Chunk 7572 ---\n",
            "Now you could train model_B_on_A for task B, but since the new output layer was ini‐\n",
            "\n",
            "--- Chunk 7573 ---\n",
            "tialized randomly it will make large errors (at least during the first few epochs), so\n",
            "\n",
            "--- Chunk 7574 ---\n",
            "there will be large error gradients that may wreck the reused weights. To avoid this,\n",
            "\n",
            "--- Chunk 7575 ---\n",
            "one approach is to freeze the reused layers during the first few epochs, giving the new\n",
            "\n",
            "--- Chunk 7576 ---\n",
            "layer some time to learn reasonable weights. To do this, set every layer’s trainable\n",
            "attribute to False and compile the model:\n",
            "\n",
            "--- Chunk 7577 ---\n",
            "for layer in model_B_on_A.layers[:-1]:\n",
            "    layer.trainable = False\n",
            "\n",
            "--- Chunk 7578 ---\n",
            "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\",\n",
            "                     metrics=[\"accuracy\"])\n",
            "\n",
            "--- Chunk 7579 ---\n",
            "You must always compile your model after you freeze or unfreeze\n",
            "layers.\n",
            "\n",
            "--- Chunk 7580 ---\n",
            "Now you can train the model for a few epochs, then unfreeze the reused layers (which\n",
            "\n",
            "--- Chunk 7581 ---\n",
            "requires compiling the model again) and continue training to fine-tune the reused\n",
            "\n",
            "--- Chunk 7582 ---\n",
            "layers for task B. After unfreezing the reused layers, it is usually a good idea to reduce\n",
            "\n",
            "--- Chunk 7583 ---\n",
            "the learning rate, once again to avoid damaging the reused weights:\n",
            "\n",
            "--- Chunk 7584 ---\n",
            "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
            "                           validation_data=(X_valid_B, y_valid_B))\n",
            "\n",
            "--- Chunk 7585 ---\n",
            "for layer in model_B_on_A.layers[:-1]:\n",
            "    layer.trainable = True\n",
            "\n",
            "--- Chunk 7586 ---\n",
            "optimizer = keras.optimizers.SGD(lr=1e-4) # the default lr is 1e-2\n",
            "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
            "\n",
            "--- Chunk 7587 ---\n",
            "metrics=[\"accuracy\"])\n",
            "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
            "\n",
            "--- Chunk 7588 ---\n",
            "validation_data=(X_valid_B, y_valid_B))\n",
            "\n",
            "--- Chunk 7589 ---\n",
            "So, what’s the final verdict? Well, this model’s test accuracy is 99.25%, which means\n",
            "\n",
            "--- Chunk 7590 ---\n",
            "that transfer learning reduced the error rate from 2.8% down to almost 0.7%! That’s a\n",
            "factor of four!\n",
            "\n",
            "--- Chunk 7591 ---\n",
            ">>> model_B_on_A.evaluate(X_test_B, y_test_B)\n",
            "[0.06887910133600235, 0.9925]\n",
            "\n",
            "--- Chunk 7592 ---\n",
            "Are you convinced? You shouldn’t be: I cheated! I tried many configurations until I\n",
            "\n",
            "--- Chunk 7593 ---\n",
            "found one that demonstrated a strong improvement. If you try to change the classes\n",
            "\n",
            "--- Chunk 7594 ---\n",
            "or the random seed, you will see that the improvement generally drops, or even van‐\n",
            "\n",
            "--- Chunk 7595 ---\n",
            "ishes or reverses. What I did is called “torturing the data until it confesses.” When a\n",
            "\n",
            "--- Chunk 7596 ---\n",
            "348 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "--- Chunk 7597 ---\n",
            "paper just looks too positive, you should be suspicious: perhaps the flashy new tech‐\n",
            "\n",
            "--- Chunk 7598 ---\n",
            "nique does not actually help much (in fact, it may even degrade performance), but the\n",
            "\n",
            "--- Chunk 7599 ---\n",
            "authors tried many variants and reported only the best results (which may be due to\n",
            "\n",
            "--- Chunk 7600 ---\n",
            "sheer luck), without mentioning how many failures they encountered on the way.\n",
            "\n",
            "--- Chunk 7601 ---\n",
            "Most of the time, this is not malicious at all, but it is part of the reason so many\n",
            "results in science can never be reproduced.\n",
            "\n",
            "--- Chunk 7602 ---\n",
            "Why did I cheat? It turns out that transfer learning does not work very well with\n",
            "\n",
            "--- Chunk 7603 ---\n",
            "small dense networks, presumably because small networks learn few patterns, and\n",
            "\n",
            "--- Chunk 7604 ---\n",
            "dense networks learn very specific patterns, which are unlikely to be useful in other\n",
            "\n",
            "--- Chunk 7605 ---\n",
            "tasks. Transfer learning works best with deep convolutional neural networks, which\n",
            "\n",
            "--- Chunk 7606 ---\n",
            "tend to learn feature detectors that are much more general (especially in the lower\n",
            "\n",
            "--- Chunk 7607 ---\n",
            "layers). We will revisit transfer learning in Chapter 14, using the techniques we just\n",
            "\n",
            "--- Chunk 7608 ---\n",
            "discussed (and this time there will be no cheating, I promise!).\n",
            "\n",
            "--- Chunk 7609 ---\n",
            "Unsupervised Pretraining\n",
            "Suppose you want to tackle a complex task for which you don’t have much labeled\n",
            "\n",
            "--- Chunk 7610 ---\n",
            "training data, but unfortunately you cannot find a model trained on a similar task.\n",
            "\n",
            "--- Chunk 7611 ---\n",
            "Don’t lose hope! First, you should try to gather more labeled training data, but if you\n",
            "\n",
            "--- Chunk 7612 ---\n",
            "can’t, you may still be able to perform unsupervised pretraining (see Figure 11-5).\n",
            "\n",
            "--- Chunk 7613 ---\n",
            "Indeed, it is often cheap to gather unlabeled training examples, but expensive to label\n",
            "\n",
            "--- Chunk 7614 ---\n",
            "them. If you can gather plenty of unlabeled training data, you can try to use it to train\n",
            "\n",
            "--- Chunk 7615 ---\n",
            "an unsupervised model, such as an autoencoder or a generative adversarial network\n",
            "\n",
            "--- Chunk 7616 ---\n",
            "(see Chapter 17). Then you can reuse the lower layers of the autoencoder or the lower\n",
            "\n",
            "--- Chunk 7617 ---\n",
            "layers of the GAN’s discriminator, add the output layer for your task on top, and fine-\n",
            "\n",
            "--- Chunk 7618 ---\n",
            "tune the final network using supervised learning (i.e., with the labeled training\n",
            "examples).\n",
            "\n",
            "--- Chunk 7619 ---\n",
            "examples).\n",
            "It is this technique that Geoffrey Hinton and his team used in 2006 and which led to\n",
            "\n",
            "--- Chunk 7620 ---\n",
            "the revival of neural networks and the success of Deep Learning. Until 2010, unsuper‐\n",
            "\n",
            "--- Chunk 7621 ---\n",
            "vised pretraining—typically with restricted Boltzmann machines (RBMs; see Appen‐\n",
            "\n",
            "--- Chunk 7622 ---\n",
            "dix E)—was the norm for deep nets, and only after the vanishing gradients problem\n",
            "\n",
            "--- Chunk 7623 ---\n",
            "was alleviated did it become much more common to train DNNs purely using super‐\n",
            "\n",
            "--- Chunk 7624 ---\n",
            "vised learning. Unsupervised pretraining (today typically using autoencoders or\n",
            "\n",
            "--- Chunk 7625 ---\n",
            "GANs rather than RBMs) is still a good option when you have a complex task to\n",
            "\n",
            "--- Chunk 7626 ---\n",
            "solve, no similar model you can reuse, and little labeled training data but plenty of\n",
            "unlabeled training data.\n",
            "\n",
            "--- Chunk 7627 ---\n",
            "Note that in the early days of Deep Learning it was difficult to train deep models, so\n",
            "\n",
            "--- Chunk 7628 ---\n",
            "people would use a technique called greedy layer-wise pretraining (depicted in\n",
            "\n",
            "--- Chunk 7629 ---\n",
            "Figure 11-5). They would first train an unsupervised model with a single layer, typi‐\n",
            "\n",
            "--- Chunk 7630 ---\n",
            "cally an RBM, then they would freeze that layer and add another one on top of it,\n",
            "\n",
            "--- Chunk 7631 ---\n",
            "then train the model again (effectively just training the new layer), then freeze the\n",
            "\n",
            "--- Chunk 7632 ---\n",
            "Reusing Pretrained Layers | 349\n",
            "\n",
            "--- Chunk 7633 ---\n",
            "new layer and add another layer on top of it, train the model again, and so on. Nowa‐\n",
            "\n",
            "--- Chunk 7634 ---\n",
            "days, things are much simpler: people generally train the full unsupervised model in\n",
            "\n",
            "--- Chunk 7635 ---\n",
            "one shot (i.e., in Figure 11-5, just start directly at step three) and use autoencoders or\n",
            "GANs rather than RBMs.\n",
            "\n",
            "--- Chunk 7636 ---\n",
            "Figure 11-5. In unsupervised training, a model is trained on the unlabeled data (or on\n",
            "\n",
            "--- Chunk 7637 ---\n",
            "all the data) using an unsupervised learning technique, then it is fine-tuned for the final\n",
            "\n",
            "--- Chunk 7638 ---\n",
            "task on the labeled data using a supervised learning technique; the unsupervised part\n",
            "\n",
            "--- Chunk 7639 ---\n",
            "may train one layer at a time as shown here, or it may train the full model directly\n",
            "\n",
            "--- Chunk 7640 ---\n",
            "Pretraining on an Auxiliary Task\n",
            "If you do not have much labeled training data, one last option is to train a first neural\n",
            "\n",
            "--- Chunk 7641 ---\n",
            "network on an auxiliary task for which you can easily obtain or generate labeled\n",
            "\n",
            "--- Chunk 7642 ---\n",
            "training data, then reuse the lower layers of that network for your actual task. The\n",
            "\n",
            "--- Chunk 7643 ---\n",
            "first neural network’s lower layers will learn feature detectors that will likely be reusa‐\n",
            "ble by the second neural network.\n",
            "\n",
            "--- Chunk 7644 ---\n",
            "For example, if you want to build a system to recognize faces, you may only have a\n",
            "\n",
            "--- Chunk 7645 ---\n",
            "few pictures of each individual—clearly not enough to train a good classifier. Gather‐\n",
            "\n",
            "--- Chunk 7646 ---\n",
            "ing hundreds of pictures of each person would not be practical. You could, however,\n",
            "\n",
            "--- Chunk 7647 ---\n",
            "gather a lot of pictures of random people on the web and train a first neural network\n",
            "\n",
            "--- Chunk 7648 ---\n",
            "to detect whether or not two different pictures feature the same person. Such a\n",
            "\n",
            "--- Chunk 7649 ---\n",
            "350 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "--- Chunk 7650 ---\n",
            "network would learn good feature detectors for faces, so reusing its lower layers\n",
            "\n",
            "--- Chunk 7651 ---\n",
            "would allow you to train a good face classifier that uses little training data.\n",
            "\n",
            "--- Chunk 7652 ---\n",
            "For natural language processing (NLP) applications, you can download a corpus of\n",
            "\n",
            "--- Chunk 7653 ---\n",
            "millions of text documents and automatically generate labeled data from it. For exam‐\n",
            "\n",
            "--- Chunk 7654 ---\n",
            "ple, you could randomly mask out some words and train a model to predict what the\n",
            "\n",
            "--- Chunk 7655 ---\n",
            "missing words are (e.g., it should predict that the missing word in the sentence “What\n",
            "\n",
            "--- Chunk 7656 ---\n",
            "___ you saying?” is probably “are” or “were”). If you can train a model to reach good\n",
            "\n",
            "--- Chunk 7657 ---\n",
            "performance on this task, then it will already know quite a lot about language, and\n",
            "\n",
            "--- Chunk 7658 ---\n",
            "you can certainly reuse it for your actual task and fine-tune it on your labeled data\n",
            "(we will discuss more pretraining tasks in Chapter 15).\n",
            "\n",
            "--- Chunk 7659 ---\n",
            "Self-supervised learning is when you automatically generate the\n",
            "labels from the data itself, then you train a model on the resulting\n",
            "\n",
            "--- Chunk 7660 ---\n",
            "“labeled” dataset using supervised learning techniques. Since this\n",
            "approach requires no human labeling whatsoever, it is best classi‐\n",
            "\n",
            "--- Chunk 7661 ---\n",
            "fied as a form of unsupervised learning.\n",
            "\n",
            "--- Chunk 7662 ---\n",
            "Faster Optimizers\n",
            "Training a very large deep neural network can be painfully slow. So far we have seen\n",
            "\n",
            "--- Chunk 7663 ---\n",
            "four ways to speed up training (and reach a better solution): applying a good initiali‐\n",
            "\n",
            "--- Chunk 7664 ---\n",
            "zation strategy for the connection weights, using a good activation function, using\n",
            "\n",
            "--- Chunk 7665 ---\n",
            "Batch Normalization, and reusing parts of a pretrained network (possibly built on an\n",
            "\n",
            "--- Chunk 7666 ---\n",
            "auxiliary task or using unsupervised learning). Another huge speed boost comes from\n",
            "\n",
            "--- Chunk 7667 ---\n",
            "using a faster optimizer than the regular Gradient Descent optimizer. In this section\n",
            "\n",
            "--- Chunk 7668 ---\n",
            "we will present the most popular algorithms: momentum optimization, Nesterov\n",
            "Accelerated Gradient, AdaGrad, RMSProp, and finally Adam and Nadam\n",
            "\n",
            "--- Chunk 7669 ---\n",
            "optimization.\n",
            "\n",
            "--- Chunk 7670 ---\n",
            "Momentum Optimization\n",
            "Imagine a bowling ball rolling down a gentle slope on a smooth surface: it will start\n",
            "\n",
            "--- Chunk 7671 ---\n",
            "out slowly, but it will quickly pick up momentum until it eventually reaches terminal\n",
            "\n",
            "--- Chunk 7672 ---\n",
            "velocity (if there is some friction or air resistance). This is the very simple idea behind\n",
            "\n",
            "--- Chunk 7673 ---\n",
            "momentum optimization, proposed by Boris Polyak in 1964.13 In contrast, regular\n",
            "\n",
            "--- Chunk 7674 ---\n",
            "Gradient Descent will simply take small, regular steps down the slope, so the algo‐\n",
            "rithm will take much more time to reach the bottom.\n",
            "\n",
            "--- Chunk 7675 ---\n",
            "13 Boris T. Polyak, “Some Methods of Speeding Up the Convergence of Iteration Methods,” USSR Computational\n",
            "\n",
            "--- Chunk 7676 ---\n",
            "Mathematics and Mathematical Physics 4, no. 5 (1964): 1–17.\n",
            "\n",
            "--- Chunk 7677 ---\n",
            "Faster Optimizers | 351\n",
            "\n",
            "--- Chunk 7678 ---\n",
            "Recall that Gradient Descent updates the weights θ by directly subtracting the gradi‐\n",
            "\n",
            "--- Chunk 7679 ---\n",
            "ent of the cost function J(θ) with regard to the weights (∇θJ(θ)) multiplied by the\n",
            "\n",
            "--- Chunk 7680 ---\n",
            "learning rate η. The equation is: θ ← θ – η∇θJ(θ). It does not care about what the ear‐\n",
            "\n",
            "--- Chunk 7681 ---\n",
            "lier gradients were. If the local gradient is tiny, it goes very slowly.\n",
            "\n",
            "--- Chunk 7682 ---\n",
            "Momentum optimization cares a great deal about what previous gradients were: at\n",
            "\n",
            "--- Chunk 7683 ---\n",
            "each iteration, it subtracts the local gradient from the momentum vector m (multi‐\n",
            "\n",
            "--- Chunk 7684 ---\n",
            "plied by the learning rate η), and it updates the weights by adding this momentum\n",
            "\n",
            "--- Chunk 7685 ---\n",
            "vector (see Equation 11-4). In other words, the gradient is used for acceleration, not\n",
            "\n",
            "--- Chunk 7686 ---\n",
            "for speed. To simulate some sort of friction mechanism and prevent the momentum\n",
            "\n",
            "--- Chunk 7687 ---\n",
            "from growing too large, the algorithm introduces a new hyperparameter β, called the\n",
            "\n",
            "--- Chunk 7688 ---\n",
            "momentum, which must be set between 0 (high friction) and 1 (no friction). A typical\n",
            "momentum value is 0.9.\n",
            "\n",
            "--- Chunk 7689 ---\n",
            "Equation 11-4. Momentum algorithm\n",
            "1 . m βm − η∇θJ θ\n",
            "2 . θ θ + m\n",
            "\n",
            "--- Chunk 7690 ---\n",
            "You can easily verify that if the gradient remains constant, the terminal velocity (i.e.,\n",
            "\n",
            "--- Chunk 7691 ---\n",
            "the maximum size of the weight updates) is equal to that gradient multiplied by the\n",
            "\n",
            "--- Chunk 7692 ---\n",
            "learning rate η multiplied by 1/(1–β) (ignoring the sign). For example, if β = 0.9, then\n",
            "\n",
            "--- Chunk 7693 ---\n",
            "the terminal velocity is equal to 10 times the gradient times the learning rate, so\n",
            "\n",
            "--- Chunk 7694 ---\n",
            "momentum optimization ends up going 10 times faster than Gradient Descent! This\n",
            "\n",
            "--- Chunk 7695 ---\n",
            "allows momentum optimization to escape from plateaus much faster than Gradient\n",
            "\n",
            "--- Chunk 7696 ---\n",
            "Descent. We saw in Chapter 4 that when the inputs have very different scales, the cost\n",
            "\n",
            "--- Chunk 7697 ---\n",
            "function will look like an elongated bowl (see Figure 4-7). Gradient Descent goes\n",
            "\n",
            "--- Chunk 7698 ---\n",
            "down the steep slope quite fast, but then it takes a very long time to go down the val‐\n",
            "\n",
            "--- Chunk 7699 ---\n",
            "ley. In contrast, momentum optimization will roll down the valley faster and faster\n",
            "\n",
            "--- Chunk 7700 ---\n",
            "until it reaches the bottom (the optimum). In deep neural networks that don’t use\n",
            "\n",
            "--- Chunk 7701 ---\n",
            "Batch Normalization, the upper layers will often end up having inputs with very dif‐\n",
            "\n",
            "--- Chunk 7702 ---\n",
            "ferent scales, so using momentum optimization helps a lot. It can also help roll past\n",
            "local optima.\n",
            "\n",
            "--- Chunk 7703 ---\n",
            "Due to the momentum, the optimizer may overshoot a bit, then\n",
            "come back, overshoot again, and oscillate like this many times\n",
            "\n",
            "--- Chunk 7704 ---\n",
            "before stabilizing at the minimum. This is one of the reasons it’s\n",
            "good to have a bit of friction in the system: it gets rid of these oscil‐\n",
            "\n",
            "--- Chunk 7705 ---\n",
            "lations and thus speeds up convergence.\n",
            "\n",
            "--- Chunk 7706 ---\n",
            "Implementing momentum optimization in Keras is a no-brainer: just use the SGD\n",
            "\n",
            "--- Chunk 7707 ---\n",
            "optimizer and set its momentum hyperparameter, then lie back and profit!\n",
            "\n",
            "--- Chunk 7708 ---\n",
            "352 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "\n",
            "\n",
            "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
            "\n",
            "--- Chunk 7709 ---\n",
            "The one drawback of momentum optimization is that it adds yet another hyperpara‐\n",
            "\n",
            "--- Chunk 7710 ---\n",
            "meter to tune. However, the momentum value of 0.9 usually works well in practice\n",
            "and almost always goes faster than regular Gradient Descent.\n",
            "\n",
            "--- Chunk 7711 ---\n",
            "Nesterov Accelerated Gradient\n",
            "One small variant to momentum optimization, proposed by Yurii Nesterov in 1983,14\n",
            "\n",
            "--- Chunk 7712 ---\n",
            "is almost always faster than vanilla momentum optimization. The Nesterov Acceler‐\n",
            "\n",
            "--- Chunk 7713 ---\n",
            "ated Gradient (NAG) method, also known as Nesterov momentum optimization, meas‐\n",
            "\n",
            "--- Chunk 7714 ---\n",
            "ures the gradient of the cost function not at the local position θ but slightly ahead in\n",
            "\n",
            "--- Chunk 7715 ---\n",
            "the direction of the momentum, at θ + βm (see Equation 11-5).\n",
            "\n",
            "--- Chunk 7716 ---\n",
            "Equation 11-5. Nesterov Accelerated Gradient algorithm\n",
            "1 . m βm − η∇θJ θ + βm\n",
            "2 . θ θ + m\n",
            "\n",
            "--- Chunk 7717 ---\n",
            "This small tweak works because in general the momentum vector will be pointing in\n",
            "\n",
            "--- Chunk 7718 ---\n",
            "the right direction (i.e., toward the optimum), so it will be slightly more accurate to\n",
            "\n",
            "--- Chunk 7719 ---\n",
            "use the gradient measured a bit farther in that direction rather than the gradient at\n",
            "\n",
            "--- Chunk 7720 ---\n",
            "the original position, as you can see in Figure 11-6 (where ∇1 represents the gradient\n",
            "\n",
            "--- Chunk 7721 ---\n",
            "of the cost function measured at the starting point θ, and ∇2 represents the gradient\n",
            "at the point located at θ + βm).\n",
            "\n",
            "--- Chunk 7722 ---\n",
            "As you can see, the Nesterov update ends up slightly closer to the optimum. After a\n",
            "\n",
            "--- Chunk 7723 ---\n",
            "while, these small improvements add up and NAG ends up being significantly faster\n",
            "\n",
            "--- Chunk 7724 ---\n",
            "than regular momentum optimization. Moreover, note that when the momentum\n",
            "\n",
            "--- Chunk 7725 ---\n",
            "pushes the weights across a valley, ∇1 continues to push farther across the valley,\n",
            "\n",
            "--- Chunk 7726 ---\n",
            "while ∇2 pushes back toward the bottom of the valley. This helps reduce oscillations\n",
            "and thus NAG converges faster.\n",
            "\n",
            "--- Chunk 7727 ---\n",
            "NAG is generally faster than regular momentum optimization. To use it, simply set\n",
            "nesterov=True when creating the SGD optimizer:\n",
            "\n",
            "--- Chunk 7728 ---\n",
            "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
            "\n",
            "--- Chunk 7729 ---\n",
            "14 Yurii Nesterov, “A Method for Unconstrained Convex Minimization Problem with the Rate of Convergence\n",
            "\n",
            "--- Chunk 7730 ---\n",
            "O(1/k2),” Doklady AN USSR 269 (1983): 543–547.\n",
            "\n",
            "--- Chunk 7731 ---\n",
            "Faster Optimizers | 353\n",
            "\n",
            "--- Chunk 7732 ---\n",
            "Figure 11-6. Regular versus Nesterov momentum optimization: the former applies the\n",
            "\n",
            "--- Chunk 7733 ---\n",
            "gradients computed before the momentum step, while the latter applies the gradients\n",
            "computed after\n",
            "\n",
            "--- Chunk 7734 ---\n",
            "AdaGrad\n",
            "Consider the elongated bowl problem again: Gradient Descent starts by quickly going\n",
            "\n",
            "--- Chunk 7735 ---\n",
            "down the steepest slope, which does not point straight toward the global optimum,\n",
            "\n",
            "--- Chunk 7736 ---\n",
            "then it very slowly goes down to the bottom of the valley. It would be nice if the algo‐\n",
            "\n",
            "--- Chunk 7737 ---\n",
            "rithm could correct its direction earlier to point a bit more toward the global opti‐\n",
            "\n",
            "--- Chunk 7738 ---\n",
            "mum. The AdaGrad algorithm15 achieves this correction by scaling down the gradient\n",
            "vector along the steepest dimensions (see Equation 11-6).\n",
            "\n",
            "--- Chunk 7739 ---\n",
            "Equation 11-6. AdaGrad algorithm\n",
            "1 . s s +∇θJ θ ⊗∇θJ θ\n",
            "2 . θ θ − η∇θJ θ ⊘ s + ε\n",
            "\n",
            "--- Chunk 7740 ---\n",
            "The first step accumulates the square of the gradients into the vector s (recall that the\n",
            "\n",
            "--- Chunk 7741 ---\n",
            "⊗ symbol represents the element-wise multiplication). This vectorized form is equiv‐\n",
            "\n",
            "--- Chunk 7742 ---\n",
            "alent to computing si ← si + (∂ J(θ) / ∂ θi)2 for each element si of the vector s; in other\n",
            "\n",
            "--- Chunk 7743 ---\n",
            "words, each si accumulates the squares of the partial derivative of the cost function\n",
            "\n",
            "--- Chunk 7744 ---\n",
            "with regard to parameter θi. If the cost function is steep along the ith dimension, then\n",
            "si will get larger and larger at each iteration.\n",
            "\n",
            "--- Chunk 7745 ---\n",
            "The second step is almost identical to Gradient Descent, but with one big difference:\n",
            "\n",
            "--- Chunk 7746 ---\n",
            "the gradient vector is scaled down by a factor of s + ε (the ⊘ symbol represents the\n",
            "\n",
            "--- Chunk 7747 ---\n",
            "15 John Duchi et al., “Adaptive Subgradient Methods for Online Learning and Stochastic Optimization,” Journal\n",
            "\n",
            "--- Chunk 7748 ---\n",
            "of Machine Learning Research 12 (2011): 2121–2159.\n",
            "\n",
            "--- Chunk 7749 ---\n",
            "354 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "--- Chunk 7750 ---\n",
            "element-wise division, and ε is a smoothing term to avoid division by zero, typically\n",
            "\n",
            "--- Chunk 7751 ---\n",
            "set to 10–10). This vectorized form is equivalent to simultaneously computing\n",
            "θi θi − η ∂J θ / ∂θi/ si + ε for all parameters θi.\n",
            "\n",
            "--- Chunk 7752 ---\n",
            "In short, this algorithm decays the learning rate, but it does so faster for steep dimen‐\n",
            "\n",
            "--- Chunk 7753 ---\n",
            "sions than for dimensions with gentler slopes. This is called an adaptive learning rate.\n",
            "\n",
            "--- Chunk 7754 ---\n",
            "It helps point the resulting updates more directly toward the global optimum (see\n",
            "\n",
            "--- Chunk 7755 ---\n",
            "Figure 11-7). One additional benefit is that it requires much less tuning of the learn‐\n",
            "ing rate hyperparameter η.\n",
            "\n",
            "--- Chunk 7756 ---\n",
            "Figure 11-7. AdaGrad versus Gradient Descent: the former can correct its direction ear‐\n",
            "lier to point to the optimum\n",
            "\n",
            "--- Chunk 7757 ---\n",
            "AdaGrad frequently performs well for simple quadratic problems, but it often stops\n",
            "\n",
            "--- Chunk 7758 ---\n",
            "too early when training neural networks. The learning rate gets scaled down so much\n",
            "\n",
            "--- Chunk 7759 ---\n",
            "that the algorithm ends up stopping entirely before reaching the global optimum. So\n",
            "\n",
            "--- Chunk 7760 ---\n",
            "even though Keras has an Adagrad optimizer, you should not use it to train deep neu‐\n",
            "\n",
            "--- Chunk 7761 ---\n",
            "ral networks (it may be efficient for simpler tasks such as Linear Regression, though).\n",
            "\n",
            "--- Chunk 7762 ---\n",
            "Still, understanding AdaGrad is helpful to grasp the other adaptive learning rate\n",
            "optimizers.\n",
            "\n",
            "--- Chunk 7763 ---\n",
            "RMSProp\n",
            "As we’ve seen, AdaGrad runs the risk of slowing down a bit too fast and never con‐\n",
            "\n",
            "--- Chunk 7764 ---\n",
            "verging to the global optimum. The RMSProp algorithm16 fixes this by accumulating\n",
            "\n",
            "--- Chunk 7765 ---\n",
            "only the gradients from the most recent iterations (as opposed to all the gradients\n",
            "\n",
            "--- Chunk 7766 ---\n",
            "16 This algorithm was created by Geoffrey Hinton and Tijmen Tieleman in 2012 and presented by Geoffrey Hin‐\n",
            "\n",
            "--- Chunk 7767 ---\n",
            "ton in his Coursera class on neural networks (slides: https://homl.info/57; video: https://homl.info/58). Amus‐\n",
            "\n",
            "--- Chunk 7768 ---\n",
            "ingly, since the authors did not write a paper to describe the algorithm, researchers often cite “slide 29 in\n",
            "lecture 6” in their papers.\n",
            "\n",
            "--- Chunk 7769 ---\n",
            "Faster Optimizers | 355\n",
            "\n",
            "\n",
            "\n",
            "since the beginning of training). It does so by using exponential decay in the first step\n",
            "(see Equation 11-7).\n",
            "\n",
            "--- Chunk 7770 ---\n",
            "Equation 11-7. RMSProp algorithm\n",
            "1 . s βs + 1 − β ∇θJ θ ⊗∇θJ θ\n",
            "2 . θ θ − η∇θJ θ ⊘ s + ε\n",
            "\n",
            "--- Chunk 7771 ---\n",
            "The decay rate β is typically set to 0.9. Yes, it is once again a new hyperparameter, but\n",
            "\n",
            "--- Chunk 7772 ---\n",
            "this default value often works well, so you may not need to tune it at all.\n",
            "As you might expect, Keras has an RMSprop optimizer:\n",
            "\n",
            "--- Chunk 7773 ---\n",
            "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
            "\n",
            "--- Chunk 7774 ---\n",
            "Note that the rho argument corresponds to β in Equation 11-7. Except on very simple\n",
            "\n",
            "--- Chunk 7775 ---\n",
            "problems, this optimizer almost always performs much better than AdaGrad. In fact,\n",
            "\n",
            "--- Chunk 7776 ---\n",
            "it was the preferred optimization algorithm of many researchers until Adam optimi‐\n",
            "zation came around.\n",
            "\n",
            "--- Chunk 7777 ---\n",
            "Adam and Nadam Optimization\n",
            "Adam,17 which stands for adaptive moment estimation, combines the ideas of momen‐\n",
            "\n",
            "--- Chunk 7778 ---\n",
            "tum optimization and RMSProp: just like momentum optimization, it keeps track of\n",
            "\n",
            "--- Chunk 7779 ---\n",
            "an exponentially decaying average of past gradients; and just like RMSProp, it keeps\n",
            "\n",
            "--- Chunk 7780 ---\n",
            "track of an exponentially decaying average of past squared gradients (see Equation\n",
            "11-8).18\n",
            "\n",
            "--- Chunk 7781 ---\n",
            "Equation 11-8. Adam algorithm\n",
            "1 . m β1m − 1 − β1 ∇θJ θ\n",
            "2 . s β2s + 1 − β2 ∇θJ θ ⊗∇θJ θ\n",
            "\n",
            "3 . m m\n",
            "1 − β t\n",
            "\n",
            "1\n",
            "\n",
            "4 . s s\n",
            "1 − β t\n",
            "\n",
            "2\n",
            "5 . θ θ + η m⊘ s + ε\n",
            "\n",
            "--- Chunk 7782 ---\n",
            "17 Diederik P. Kingma and Jimmy Ba, “Adam: A Method for Stochastic Optimization,” arXiv preprint arXiv:\n",
            "1412.6980 (2014).\n",
            "\n",
            "--- Chunk 7783 ---\n",
            "18 These are estimations of the mean and (uncentered) variance of the gradients. The mean is often called the\n",
            "\n",
            "--- Chunk 7784 ---\n",
            "first moment while the variance is often called the second moment, hence the name of the algorithm.\n",
            "\n",
            "--- Chunk 7785 ---\n",
            "356 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "--- Chunk 7786 ---\n",
            "In this equation, t represents the iteration number (starting at 1).\n",
            "\n",
            "--- Chunk 7787 ---\n",
            "If you just look at steps 1, 2, and 5, you will notice Adam’s close similarity to both\n",
            "\n",
            "--- Chunk 7788 ---\n",
            "momentum optimization and RMSProp. The only difference is that step 1 computes\n",
            "\n",
            "--- Chunk 7789 ---\n",
            "an exponentially decaying average rather than an exponentially decaying sum, but\n",
            "\n",
            "--- Chunk 7790 ---\n",
            "these are actually equivalent except for a constant factor (the decaying average is just\n",
            "\n",
            "--- Chunk 7791 ---\n",
            "1 – β1 times the decaying sum). Steps 3 and 4 are somewhat of a technical detail: since\n",
            "\n",
            "--- Chunk 7792 ---\n",
            "m and s are initialized at 0, they will be biased toward 0 at the beginning of training,\n",
            "\n",
            "--- Chunk 7793 ---\n",
            "so these two steps will help boost m and s at the beginning of training.\n",
            "\n",
            "--- Chunk 7794 ---\n",
            "The momentum decay hyperparameter β1 is typically initialized to 0.9, while the scal‐\n",
            "\n",
            "--- Chunk 7795 ---\n",
            "ing decay hyperparameter β2 is often initialized to 0.999. As earlier, the smoothing\n",
            "\n",
            "--- Chunk 7796 ---\n",
            "term ε is usually initialized to a tiny number such as 10–7. These are the default values\n",
            "\n",
            "--- Chunk 7797 ---\n",
            "for the Adam class (to be precise, epsilon defaults to None, which tells Keras to use\n",
            "\n",
            "--- Chunk 7798 ---\n",
            "keras.backend.epsilon(), which defaults to 10–7; you can change it using\n",
            "keras.backend.set_epsilon()). Here is how to create an Adam optimizer using\n",
            "\n",
            "--- Chunk 7799 ---\n",
            "Keras:\n",
            "\n",
            "--- Chunk 7800 ---\n",
            "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
            "\n",
            "--- Chunk 7801 ---\n",
            "Since Adam is an adaptive learning rate algorithm (like AdaGrad and RMSProp), it\n",
            "\n",
            "--- Chunk 7802 ---\n",
            "requires less tuning of the learning rate hyperparameter η. You can often use the\n",
            "\n",
            "--- Chunk 7803 ---\n",
            "default value η = 0.001, making Adam even easier to use than Gradient Descent.\n",
            "\n",
            "--- Chunk 7804 ---\n",
            "If you are starting to feel overwhelmed by all these different techni‐\n",
            "ques and are wondering how to choose the right ones for your task,\n",
            "\n",
            "--- Chunk 7805 ---\n",
            "don’t worry: some practical guidelines are provided at the end of\n",
            "this chapter.\n",
            "\n",
            "--- Chunk 7806 ---\n",
            "Finally, two variants of Adam are worth mentioning:\n",
            "AdaMax\n",
            "\n",
            "--- Chunk 7807 ---\n",
            "Notice that in step 2 of Equation 11-8, Adam accumulates the squares of the gra‐\n",
            "\n",
            "--- Chunk 7808 ---\n",
            "dients in s (with a greater weight for more recent gradients). In step 5, if we\n",
            "\n",
            "--- Chunk 7809 ---\n",
            "ignore ε and steps 3 and 4 (which are technical details anyway), Adam scales\n",
            "\n",
            "--- Chunk 7810 ---\n",
            "down the parameter updates by the square root of s. In short, Adam scales down\n",
            "\n",
            "--- Chunk 7811 ---\n",
            "the parameter updates by the ℓ2 norm of the time-decayed gradients (recall that\n",
            "\n",
            "--- Chunk 7812 ---\n",
            "the ℓ2 norm is the square root of the sum of squares). AdaMax, introduced in the\n",
            "\n",
            "--- Chunk 7813 ---\n",
            "same paper as Adam, replaces the ℓ2 norm with the ℓ∞ norm (a fancy way of say‐\n",
            "\n",
            "--- Chunk 7814 ---\n",
            "ing the max). Specifically, it replaces step 2 in Equation 11-8 with s ← max\n",
            "\n",
            "--- Chunk 7815 ---\n",
            "(β2s,∇θJ(θ)), it drops step 4, and in step 5 it scales down the gradient updates by a\n",
            "\n",
            "--- Chunk 7816 ---\n",
            "factor of s, which is just the max of the time-decayed gradients. In practice, this\n",
            "\n",
            "--- Chunk 7817 ---\n",
            "can make AdaMax more stable than Adam, but it really depends on the dataset,\n",
            "\n",
            "--- Chunk 7818 ---\n",
            "Faster Optimizers | 357\n",
            "\n",
            "--- Chunk 7819 ---\n",
            "and in general Adam performs better. So, this is just one more optimizer you can\n",
            "try if you experience problems with Adam on some task.\n",
            "\n",
            "--- Chunk 7820 ---\n",
            "Nadam\n",
            "Nadam optimization is Adam optimization plus the Nesterov trick, so it will\n",
            "\n",
            "--- Chunk 7821 ---\n",
            "often converge slightly faster than Adam. In his report introducing this techni‐\n",
            "\n",
            "--- Chunk 7822 ---\n",
            "que,19 the researcher Timothy Dozat compares many different optimizers on vari‐\n",
            "\n",
            "--- Chunk 7823 ---\n",
            "ous tasks and finds that Nadam generally outperforms Adam but is sometimes\n",
            "outperformed by RMSProp.\n",
            "\n",
            "--- Chunk 7824 ---\n",
            "Adaptive optimization methods (including RMSProp, Adam, and\n",
            "Nadam optimization) are often great, converging fast to a good sol‐\n",
            "\n",
            "--- Chunk 7825 ---\n",
            "ution. However, a 2017 paper20 by Ashia C. Wilson et al. showed\n",
            "that they can lead to solutions that generalize poorly on some data‐\n",
            "\n",
            "--- Chunk 7826 ---\n",
            "sets. So when you are disappointed by your model’s performance,\n",
            "try using plain Nesterov Accelerated Gradient instead: your dataset\n",
            "\n",
            "--- Chunk 7827 ---\n",
            "may just be allergic to adaptive gradients. Also check out the latest\n",
            "research, because it’s moving fast.\n",
            "\n",
            "--- Chunk 7828 ---\n",
            "All the optimization techniques discussed so far only rely on the first-order partial\n",
            "\n",
            "--- Chunk 7829 ---\n",
            "derivatives (Jacobians). The optimization literature also contains amazing algorithms\n",
            "\n",
            "--- Chunk 7830 ---\n",
            "based on the second-order partial derivatives (the Hessians, which are the partial\n",
            "\n",
            "--- Chunk 7831 ---\n",
            "derivatives of the Jacobians). Unfortunately, these algorithms are very hard to apply\n",
            "\n",
            "--- Chunk 7832 ---\n",
            "to deep neural networks because there are n2 Hessians per output (where n is the\n",
            "\n",
            "--- Chunk 7833 ---\n",
            "number of parameters), as opposed to just n Jacobians per output. Since DNNs typi‐\n",
            "\n",
            "--- Chunk 7834 ---\n",
            "cally have tens of thousands of parameters, the second-order optimization algorithms\n",
            "\n",
            "--- Chunk 7835 ---\n",
            "often don’t even fit in memory, and even when they do, computing the Hessians is\n",
            "just too slow.\n",
            "\n",
            "--- Chunk 7836 ---\n",
            "19 Timothy Dozat, “Incorporating Nesterov Momentum into Adam” (2016).\n",
            "\n",
            "--- Chunk 7837 ---\n",
            "20 Ashia C. Wilson et al., “The Marginal Value of Adaptive Gradient Methods in Machine Learning,” Advances in\n",
            "\n",
            "--- Chunk 7838 ---\n",
            "Neural Information Processing Systems 30 (2017): 4148–4158.\n",
            "\n",
            "358 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "--- Chunk 7839 ---\n",
            "Training Sparse Models\n",
            "All the optimization algorithms just presented produce dense models, meaning that\n",
            "\n",
            "--- Chunk 7840 ---\n",
            "most parameters will be nonzero. If you need a blazingly fast model at runtime, or if\n",
            "\n",
            "--- Chunk 7841 ---\n",
            "you need it to take up less memory, you may prefer to end up with a sparse model\n",
            "instead.\n",
            "\n",
            "--- Chunk 7842 ---\n",
            "instead.\n",
            "One easy way to achieve this is to train the model as usual, then get rid of the tiny\n",
            "\n",
            "--- Chunk 7843 ---\n",
            "weights (set them to zero). Note that this will typically not lead to a very sparse\n",
            "model, and it may degrade the model’s performance.\n",
            "\n",
            "--- Chunk 7844 ---\n",
            "A better option is to apply strong ℓ1 regularization during training (we will see how\n",
            "\n",
            "--- Chunk 7845 ---\n",
            "later in this chapter), as it pushes the optimizer to zero out as many weights as it can\n",
            "\n",
            "--- Chunk 7846 ---\n",
            "(as discussed in “Lasso Regression” on page 137 in Chapter 4).\n",
            "If these techniques remain insufficient, check out the TensorFlow Model Optimiza‐\n",
            "\n",
            "--- Chunk 7847 ---\n",
            "tion Toolkit (TF-MOT), which provides a pruning API capable of iteratively remov‐\n",
            "ing connections during training based on their magnitude.\n",
            "\n",
            "--- Chunk 7848 ---\n",
            "Table 11-2 compares all the optimizers we’ve discussed so far (* is bad, ** is average,\n",
            "and *** is good).\n",
            "\n",
            "--- Chunk 7849 ---\n",
            "Table 11-2. Optimizer comparison\n",
            "Class Convergence speed Convergence quality\n",
            "SGD * ***\n",
            "SGD(momentum=...) ** ***\n",
            "\n",
            "--- Chunk 7850 ---\n",
            "SGD(momentum=..., nesterov=True) ** ***\n",
            "Adagrad *** * (stops too early)\n",
            "RMSprop *** ** or ***\n",
            "Adam *** ** or ***\n",
            "Nadam *** ** or ***\n",
            "\n",
            "--- Chunk 7851 ---\n",
            "Nadam *** ** or ***\n",
            "AdaMax *** ** or ***\n",
            "\n",
            "--- Chunk 7852 ---\n",
            "Learning Rate Scheduling\n",
            "Finding a good learning rate is very important. If you set it much too high, training\n",
            "\n",
            "--- Chunk 7853 ---\n",
            "may diverge (as we discussed in “Gradient Descent” on page 118). If you set it too\n",
            "\n",
            "--- Chunk 7854 ---\n",
            "low, training will eventually converge to the optimum, but it will take a very long\n",
            "\n",
            "--- Chunk 7855 ---\n",
            "time. If you set it slightly too high, it will make progress very quickly at first, but it\n",
            "\n",
            "--- Chunk 7856 ---\n",
            "will end up dancing around the optimum, never really settling down. If you have a\n",
            "\n",
            "--- Chunk 7857 ---\n",
            "limited computing budget, you may have to interrupt training before it has converged\n",
            "properly, yielding a suboptimal solution (see Figure 11-8).\n",
            "\n",
            "--- Chunk 7858 ---\n",
            "Faster Optimizers | 359\n",
            "\n",
            "\n",
            "\n",
            "Figure 11-8. Learning curves for various learning rates η\n",
            "\n",
            "--- Chunk 7859 ---\n",
            "As we discussed in Chapter 10, you can find a good learning rate by training the\n",
            "\n",
            "--- Chunk 7860 ---\n",
            "model for a few hundred iterations, exponentially increasing the learning rate from a\n",
            "\n",
            "--- Chunk 7861 ---\n",
            "very small value to a very large value, and then looking at the learning curve and\n",
            "\n",
            "--- Chunk 7862 ---\n",
            "picking a learning rate slightly lower than the one at which the learning curve starts\n",
            "\n",
            "--- Chunk 7863 ---\n",
            "shooting back up. You can then reinitialize your model and train it with that learning\n",
            "rate.\n",
            "\n",
            "--- Chunk 7864 ---\n",
            "rate.\n",
            "But you can do better than a constant learning rate: if you start with a large learning\n",
            "\n",
            "--- Chunk 7865 ---\n",
            "rate and then reduce it once training stops making fast progress, you can reach a\n",
            "\n",
            "--- Chunk 7866 ---\n",
            "good solution faster than with the optimal constant learning rate. There are many dif‐\n",
            "\n",
            "--- Chunk 7867 ---\n",
            "ferent strategies to reduce the learning rate during training. It can also be beneficial to\n",
            "\n",
            "--- Chunk 7868 ---\n",
            "start with a low learning rate, increase it, then drop it again. These strategies are\n",
            "\n",
            "--- Chunk 7869 ---\n",
            "called learning schedules (we briefly introduced this concept in Chapter 4). These are\n",
            "the most commonly used learning schedules:\n",
            "Power scheduling\n",
            "\n",
            "--- Chunk 7870 ---\n",
            "Set the learning rate to a function of the iteration number t: η(t) = η0 / (1 + t/s)c.\n",
            "\n",
            "--- Chunk 7871 ---\n",
            "The initial learning rate η0, the power c (typically set to 1), and the steps s are\n",
            "\n",
            "--- Chunk 7872 ---\n",
            "hyperparameters. The learning rate drops at each step. After s steps, it is down to\n",
            "\n",
            "--- Chunk 7873 ---\n",
            "η0 / 2. After s more steps, it is down to η0 / 3, then it goes down to η0 / 4, then η0 /\n",
            "\n",
            "--- Chunk 7874 ---\n",
            "5, and so on. As you can see, this schedule first drops quickly, then more and\n",
            "\n",
            "--- Chunk 7875 ---\n",
            "more slowly. Of course, power scheduling requires tuning η0 and s (and possibly\n",
            "c).\n",
            "\n",
            "--- Chunk 7876 ---\n",
            "Exponential scheduling\n",
            "Set the learning rate to η(t) = η0 0.1t/s. The learning rate will gradually drop by a\n",
            "\n",
            "--- Chunk 7877 ---\n",
            "factor of 10 every s steps. While power scheduling reduces the learning rate more\n",
            "\n",
            "--- Chunk 7878 ---\n",
            "and more slowly, exponential scheduling keeps slashing it by a factor of 10 every\n",
            "s steps.\n",
            "\n",
            "--- Chunk 7879 ---\n",
            "360 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "--- Chunk 7880 ---\n",
            "Piecewise constant scheduling\n",
            "Use a constant learning rate for a number of epochs (e.g., η0 = 0.1 for 5 epochs),\n",
            "\n",
            "--- Chunk 7881 ---\n",
            "then a smaller learning rate for another number of epochs (e.g., η1 = 0.001 for 50\n",
            "\n",
            "--- Chunk 7882 ---\n",
            "epochs), and so on. Although this solution can work very well, it requires fid‐\n",
            "\n",
            "--- Chunk 7883 ---\n",
            "dling around to figure out the right sequence of learning rates and how long to\n",
            "use each of them.\n",
            "\n",
            "--- Chunk 7884 ---\n",
            "Performance scheduling\n",
            "Measure the validation error every N steps (just like for early stopping), and\n",
            "\n",
            "--- Chunk 7885 ---\n",
            "reduce the learning rate by a factor of λ when the error stops dropping.\n",
            "\n",
            "--- Chunk 7886 ---\n",
            "1cycle scheduling\n",
            "Contrary to the other approaches, 1cycle (introduced in a 2018 paper21 by Leslie\n",
            "\n",
            "--- Chunk 7887 ---\n",
            "Smith) starts by increasing the initial learning rate η0, growing linearly up to η1\n",
            "\n",
            "--- Chunk 7888 ---\n",
            "halfway through training. Then it decreases the learning rate linearly down to η0\n",
            "\n",
            "--- Chunk 7889 ---\n",
            "again during the second half of training, finishing the last few epochs by drop‐\n",
            "\n",
            "--- Chunk 7890 ---\n",
            "ping the rate down by several orders of magnitude (still linearly). The maximum\n",
            "\n",
            "--- Chunk 7891 ---\n",
            "learning rate η1 is chosen using the same approach we used to find the optimal\n",
            "\n",
            "--- Chunk 7892 ---\n",
            "learning rate, and the initial learning rate η0 is chosen to be roughly 10 times\n",
            "\n",
            "--- Chunk 7893 ---\n",
            "lower. When using a momentum, we start with a high momentum first (e.g.,\n",
            "\n",
            "--- Chunk 7894 ---\n",
            "0.95), then drop it down to a lower momentum during the first half of training\n",
            "\n",
            "--- Chunk 7895 ---\n",
            "(e.g., down to 0.85, linearly), and then bring it back up to the maximum value\n",
            "\n",
            "--- Chunk 7896 ---\n",
            "(e.g., 0.95) during the second half of training, finishing the last few epochs with\n",
            "\n",
            "--- Chunk 7897 ---\n",
            "that maximum value. Smith did many experiments showing that this approach\n",
            "\n",
            "--- Chunk 7898 ---\n",
            "was often able to speed up training considerably and reach better performance.\n",
            "\n",
            "--- Chunk 7899 ---\n",
            "For example, on the popular CIFAR10 image dataset, this approach reached\n",
            "\n",
            "--- Chunk 7900 ---\n",
            "91.9% validation accuracy in just 100 epochs, instead of 90.3% accuracy in 800\n",
            "epochs through a standard approach (with the same neural network\n",
            "\n",
            "--- Chunk 7901 ---\n",
            "architecture).\n",
            "\n",
            "--- Chunk 7902 ---\n",
            "A 2013 paper22 by Andrew Senior et al. compared the performance of some of the\n",
            "\n",
            "--- Chunk 7903 ---\n",
            "most popular learning schedules when using momentum optimization to train deep\n",
            "\n",
            "--- Chunk 7904 ---\n",
            "neural networks for speech recognition. The authors concluded that, in this setting,\n",
            "\n",
            "--- Chunk 7905 ---\n",
            "both performance scheduling and exponential scheduling performed well. They\n",
            "\n",
            "--- Chunk 7906 ---\n",
            "favored exponential scheduling because it was easy to tune and it converged slightly\n",
            "\n",
            "--- Chunk 7907 ---\n",
            "faster to the optimal solution (they also mentioned that it was easier to implement\n",
            "\n",
            "--- Chunk 7908 ---\n",
            "21 Leslie N. Smith, “A Disciplined Approach to Neural Network Hyper-Parameters: Part 1—Learning Rate, Batch\n",
            "\n",
            "--- Chunk 7909 ---\n",
            "Size, Momentum, and Weight Decay,” arXiv preprint arXiv:1803.09820 (2018).\n",
            "\n",
            "--- Chunk 7910 ---\n",
            "22 Andrew Senior et al., “An Empirical Study of Learning Rates in Deep Neural Networks for Speech Recogni‐\n",
            "\n",
            "--- Chunk 7911 ---\n",
            "tion,” Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (2013):\n",
            "6724–6728.\n",
            "\n",
            "--- Chunk 7912 ---\n",
            "Faster Optimizers | 361\n",
            "\n",
            "--- Chunk 7913 ---\n",
            "than performance scheduling, but in Keras both options are easy). That said, the\n",
            "1cycle approach seems to perform even better.\n",
            "\n",
            "--- Chunk 7914 ---\n",
            "Implementing power scheduling in Keras is the easiest option: just set the decay\n",
            "hyperparameter when creating an optimizer:\n",
            "\n",
            "--- Chunk 7915 ---\n",
            "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)\n",
            "\n",
            "--- Chunk 7916 ---\n",
            "The decay is the inverse of s (the number of steps it takes to divide the learning rate\n",
            "by one more unit), and Keras assumes that c is equal to 1.\n",
            "\n",
            "--- Chunk 7917 ---\n",
            "Exponential scheduling and piecewise scheduling are quite simple too. You first need\n",
            "\n",
            "--- Chunk 7918 ---\n",
            "to define a function that takes the current epoch and returns the learning rate. For\n",
            "example, let’s implement exponential scheduling:\n",
            "\n",
            "--- Chunk 7919 ---\n",
            "def exponential_decay_fn(epoch):\n",
            "    return 0.01 * 0.1**(epoch / 20)\n",
            "\n",
            "--- Chunk 7920 ---\n",
            "If you do not want to hardcode η0 and s, you can create a function that returns a con‐\n",
            "figured function:\n",
            "\n",
            "--- Chunk 7921 ---\n",
            "def exponential_decay(lr0, s):\n",
            "    def exponential_decay_fn(epoch):\n",
            "        return lr0 * 0.1**(epoch / s)\n",
            "    return exponential_decay_fn\n",
            "\n",
            "--- Chunk 7922 ---\n",
            "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)\n",
            "\n",
            "--- Chunk 7923 ---\n",
            "Next, create a LearningRateScheduler callback, giving it the schedule function, and\n",
            "pass this callback to the fit() method:\n",
            "\n",
            "--- Chunk 7924 ---\n",
            "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
            "\n",
            "--- Chunk 7925 ---\n",
            "history = model.fit(X_train_scaled, y_train, [...], callbacks=[lr_scheduler])\n",
            "\n",
            "--- Chunk 7926 ---\n",
            "The LearningRateScheduler will update the optimizer’s learning_rate attribute at\n",
            "\n",
            "--- Chunk 7927 ---\n",
            "the beginning of each epoch. Updating the learning rate once per epoch is usually\n",
            "\n",
            "--- Chunk 7928 ---\n",
            "enough, but if you want it to be updated more often, for example at every step, you\n",
            "\n",
            "--- Chunk 7929 ---\n",
            "can always write your own callback (see the “Exponential Scheduling” section of the\n",
            "\n",
            "--- Chunk 7930 ---\n",
            "notebook for an example). Updating the learning rate at every step makes sense if\n",
            "\n",
            "--- Chunk 7931 ---\n",
            "there are many steps per epoch. Alternatively, you can use the keras.optimiz\n",
            "ers.schedules approach, described shortly.\n",
            "\n",
            "--- Chunk 7932 ---\n",
            "The schedule function can optionally take the current learning rate as a second argu‐\n",
            "\n",
            "--- Chunk 7933 ---\n",
            "ment. For example, the following schedule function multiplies the previous learning\n",
            "\n",
            "--- Chunk 7934 ---\n",
            "rate by 0.11/20, which results in the same exponential decay (except the decay now\n",
            "starts at the beginning of epoch 0 instead of 1):\n",
            "\n",
            "--- Chunk 7935 ---\n",
            "def exponential_decay_fn(epoch, lr):\n",
            "    return lr * 0.1**(1 / 20)\n",
            "\n",
            "362 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "--- Chunk 7936 ---\n",
            "This implementation relies on the optimizer’s initial learning rate (contrary to the\n",
            "previous implementation), so make sure to set it appropriately.\n",
            "\n",
            "--- Chunk 7937 ---\n",
            "When you save a model, the optimizer and its learning rate get saved along with it.\n",
            "\n",
            "--- Chunk 7938 ---\n",
            "This means that with this new schedule function, you could just load a trained model\n",
            "\n",
            "--- Chunk 7939 ---\n",
            "and continue training where it left off, no problem. Things are not so simple if your\n",
            "\n",
            "--- Chunk 7940 ---\n",
            "schedule function uses the epoch argument, however: the epoch does not get saved,\n",
            "\n",
            "--- Chunk 7941 ---\n",
            "and it gets reset to 0 every time you call the fit() method. If you were to continue\n",
            "\n",
            "--- Chunk 7942 ---\n",
            "training a model where it left off, this could lead to a very large learning rate, which\n",
            "\n",
            "--- Chunk 7943 ---\n",
            "would likely damage your model’s weights. One solution is to manually set the fit()\n",
            "\n",
            "--- Chunk 7944 ---\n",
            "method’s initial_epoch argument so the epoch starts at the right value.\n",
            "\n",
            "--- Chunk 7945 ---\n",
            "For piecewise constant scheduling, you can use a schedule function like the following\n",
            "\n",
            "--- Chunk 7946 ---\n",
            "one (as earlier, you can define a more general function if you want; see the “Piecewise\n",
            "\n",
            "--- Chunk 7947 ---\n",
            "Constant Scheduling” section of the notebook for an example), then create a Lear\n",
            "\n",
            "--- Chunk 7948 ---\n",
            "ningRateScheduler callback with this function and pass it to the fit() method, just\n",
            "like we did for exponential scheduling:\n",
            "\n",
            "--- Chunk 7949 ---\n",
            "def piecewise_constant_fn(epoch):\n",
            "    if epoch < 5:\n",
            "        return 0.01\n",
            "    elif epoch < 15:\n",
            "        return 0.005\n",
            "    else:\n",
            "        return 0.001\n",
            "\n",
            "--- Chunk 7950 ---\n",
            "For performance scheduling, use the ReduceLROnPlateau callback. For example, if\n",
            "\n",
            "--- Chunk 7951 ---\n",
            "you pass the following callback to the fit() method, it will multiply the learning rate\n",
            "\n",
            "--- Chunk 7952 ---\n",
            "by 0.5 whenever the best validation loss does not improve for five consecutive epochs\n",
            "\n",
            "--- Chunk 7953 ---\n",
            "(other options are available; please check the documentation for more details):\n",
            "\n",
            "--- Chunk 7954 ---\n",
            "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
            "\n",
            "--- Chunk 7955 ---\n",
            "Lastly, tf.keras offers an alternative way to implement learning rate scheduling: define\n",
            "\n",
            "--- Chunk 7956 ---\n",
            "the learning rate using one of the schedules available in keras.optimizers.sched\n",
            "\n",
            "--- Chunk 7957 ---\n",
            "ules, then pass this learning rate to any optimizer. This approach updates the learn‐\n",
            "\n",
            "--- Chunk 7958 ---\n",
            "ing rate at each step rather than at each epoch. For example, here is how to implement\n",
            "\n",
            "--- Chunk 7959 ---\n",
            "the same exponential schedule as the exponential_decay_fn() function we defined\n",
            "earlier:\n",
            "\n",
            "--- Chunk 7960 ---\n",
            "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
            "\n",
            "--- Chunk 7961 ---\n",
            "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
            "optimizer = keras.optimizers.SGD(learning_rate)\n",
            "\n",
            "--- Chunk 7962 ---\n",
            "This is nice and simple, plus when you save the model, the learning rate and its\n",
            "\n",
            "--- Chunk 7963 ---\n",
            "schedule (including its state) get saved as well. This approach, however, is not part of\n",
            "the Keras API; it is specific to tf.keras.\n",
            "\n",
            "--- Chunk 7964 ---\n",
            "Faster Optimizers | 363\n",
            "\n",
            "--- Chunk 7965 ---\n",
            "As for the 1cycle approach, the implementation poses no particular difficulty: just\n",
            "\n",
            "--- Chunk 7966 ---\n",
            "create a custom callback that modifies the learning rate at each iteration (you can\n",
            "\n",
            "--- Chunk 7967 ---\n",
            "update the optimizer’s learning rate by changing self.model.optimizer.lr). See the\n",
            "“1Cycle scheduling” section of the notebook for an example.\n",
            "\n",
            "--- Chunk 7968 ---\n",
            "To sum up, exponential decay, performance scheduling, and 1cycle can considerably\n",
            "speed up convergence, so give them a try!\n",
            "\n",
            "--- Chunk 7969 ---\n",
            "Avoiding Overfitting Through Regularization\n",
            "With four parameters I can fit an elephant and with five I can make him wiggle his\n",
            "trunk.\n",
            "\n",
            "--- Chunk 7970 ---\n",
            "—John von Neumann, cited by Enrico Fermi in Nature 427\n",
            "\n",
            "--- Chunk 7971 ---\n",
            "With thousands of parameters, you can fit the whole zoo. Deep neural networks typi‐\n",
            "\n",
            "--- Chunk 7972 ---\n",
            "cally have tens of thousands of parameters, sometimes even millions. This gives them\n",
            "\n",
            "--- Chunk 7973 ---\n",
            "an incredible amount of freedom and means they can fit a huge variety of complex\n",
            "\n",
            "--- Chunk 7974 ---\n",
            "datasets. But this great flexibility also makes the network prone to overfitting the\n",
            "training set. We need regularization.\n",
            "\n",
            "--- Chunk 7975 ---\n",
            "We already implemented one of the best regularization techniques in Chapter 10:\n",
            "\n",
            "--- Chunk 7976 ---\n",
            "early stopping. Moreover, even though Batch Normalization was designed to solve\n",
            "\n",
            "--- Chunk 7977 ---\n",
            "the unstable gradients problems, it also acts like a pretty good regularizer. In this sec‐\n",
            "\n",
            "--- Chunk 7978 ---\n",
            "tion we will examine other popular regularization techniques for neural networks: ℓ1\n",
            "and ℓ2 regularization, dropout, and max-norm regularization.\n",
            "\n",
            "--- Chunk 7979 ---\n",
            "ℓ1 and ℓ2 Regularization\n",
            "Just like you did in Chapter 4 for simple linear models, you can use ℓ2 regularization\n",
            "\n",
            "--- Chunk 7980 ---\n",
            "to constrain a neural network’s connection weights, and/or ℓ1 regularization if you\n",
            "\n",
            "--- Chunk 7981 ---\n",
            "want a sparse model (with many weights equal to 0). Here is how to apply ℓ2 regulari‐\n",
            "\n",
            "--- Chunk 7982 ---\n",
            "zation to a Keras layer’s connection weights, using a regularization factor of 0.01:\n",
            "\n",
            "--- Chunk 7983 ---\n",
            "layer = keras.layers.Dense(100, activation=\"elu\",\n",
            "                           kernel_initializer=\"he_normal\",\n",
            "\n",
            "--- Chunk 7984 ---\n",
            "kernel_regularizer=keras.regularizers.l2(0.01))\n",
            "\n",
            "--- Chunk 7985 ---\n",
            "The l2() function returns a regularizer that will be called at each step during training\n",
            "\n",
            "--- Chunk 7986 ---\n",
            "to compute the regularization loss. This is then added to the final loss. As you might\n",
            "\n",
            "--- Chunk 7987 ---\n",
            "expect, you can just use keras.regularizers.l1() if you want ℓ1 regularization; if\n",
            "\n",
            "--- Chunk 7988 ---\n",
            "you want both ℓ1 and ℓ2 regularization, use keras.regularizers.l1_l2() (specifying\n",
            "both regularization factors).\n",
            "\n",
            "--- Chunk 7989 ---\n",
            "Since you will typically want to apply the same regularizer to all layers in your net‐\n",
            "\n",
            "--- Chunk 7990 ---\n",
            "work, as well as using the same activation function and the same initialization strat‐\n",
            "\n",
            "--- Chunk 7991 ---\n",
            "egy in all hidden layers, you may find yourself repeating the same arguments. This\n",
            "\n",
            "--- Chunk 7992 ---\n",
            "364 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "--- Chunk 7993 ---\n",
            "makes the code ugly and error-prone. To avoid this, you can try refactoring your code\n",
            "\n",
            "--- Chunk 7994 ---\n",
            "to use loops. Another option is to use Python’s functools.partial() function,\n",
            "\n",
            "--- Chunk 7995 ---\n",
            "which lets you create a thin wrapper for any callable, with some default argument\n",
            "values:\n",
            "\n",
            "--- Chunk 7996 ---\n",
            "from functools import partial\n",
            "\n",
            "--- Chunk 7997 ---\n",
            "RegularizedDense = partial(keras.layers.Dense,\n",
            "                           activation=\"elu\",\n",
            "\n",
            "--- Chunk 7998 ---\n",
            "kernel_initializer=\"he_normal\",\n",
            "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
            "\n",
            "--- Chunk 7999 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.Flatten(input_shape=[28, 28]),\n",
            "    RegularizedDense(300),\n",
            "    RegularizedDense(100),\n",
            "\n",
            "--- Chunk 8000 ---\n",
            "RegularizedDense(10, activation=\"softmax\",\n",
            "                     kernel_initializer=\"glorot_uniform\")\n",
            "])\n",
            "\n",
            "--- Chunk 8001 ---\n",
            "Dropout\n",
            "Dropout is one of the most popular regularization techniques for deep neural net‐\n",
            "\n",
            "--- Chunk 8002 ---\n",
            "works. It was proposed in a paper23 by Geoffrey Hinton in 2012 and further detailed\n",
            "\n",
            "--- Chunk 8003 ---\n",
            "in a 2014 paper24 by Nitish Srivastava et al., and it has proven to be highly successful:\n",
            "\n",
            "--- Chunk 8004 ---\n",
            "even the state-of-the-art neural networks get a 1–2% accuracy boost simply by adding\n",
            "\n",
            "--- Chunk 8005 ---\n",
            "dropout. This may not sound like a lot, but when a model already has 95% accuracy,\n",
            "\n",
            "--- Chunk 8006 ---\n",
            "getting a 2% accuracy boost means dropping the error rate by almost 40% (going\n",
            "from 5% error to roughly 3%).\n",
            "\n",
            "--- Chunk 8007 ---\n",
            "It is a fairly simple algorithm: at every training step, every neuron (including the\n",
            "\n",
            "--- Chunk 8008 ---\n",
            "input neurons, but always excluding the output neurons) has a probability p of being\n",
            "\n",
            "--- Chunk 8009 ---\n",
            "temporarily “dropped out,” meaning it will be entirely ignored during this training\n",
            "\n",
            "--- Chunk 8010 ---\n",
            "step, but it may be active during the next step (see Figure 11-9). The hyperparameter\n",
            "\n",
            "--- Chunk 8011 ---\n",
            "p is called the dropout rate, and it is typically set between 10% and 50%: closer to 20–\n",
            "\n",
            "--- Chunk 8012 ---\n",
            "30% in recurrent neural nets (see Chapter 15), and closer to 40–50% in convolutional\n",
            "\n",
            "--- Chunk 8013 ---\n",
            "neural networks (see Chapter 14). After training, neurons don’t get dropped any‐\n",
            "\n",
            "--- Chunk 8014 ---\n",
            "more. And that’s all (except for a technical detail we will discuss momentarily).\n",
            "\n",
            "--- Chunk 8015 ---\n",
            "23 Geoffrey E. Hinton et al., “Improving Neural Networks by Preventing Co-Adaptation of Feature Detectors,”\n",
            "arXiv preprint arXiv:1207.0580 (2012).\n",
            "\n",
            "--- Chunk 8016 ---\n",
            "24 Nitish Srivastava et al., “Dropout: A Simple Way to Prevent Neural Networks from Overfitting,” Journal of\n",
            "\n",
            "--- Chunk 8017 ---\n",
            "Machine Learning Research 15 (2014): 1929–1958.\n",
            "\n",
            "--- Chunk 8018 ---\n",
            "Avoiding Overfitting Through Regularization | 365\n",
            "\n",
            "--- Chunk 8019 ---\n",
            "Figure 11-9. With dropout regularization, at each training iteration a random subset of\n",
            "\n",
            "--- Chunk 8020 ---\n",
            "all neurons in one or more layers—except the output layer—are “dropped out”; these\n",
            "\n",
            "--- Chunk 8021 ---\n",
            "neurons output 0 at this iteration (represented by the dashed arrows)\n",
            "\n",
            "--- Chunk 8022 ---\n",
            "It’s surprising at first that this destructive technique works at all. Would a company\n",
            "\n",
            "--- Chunk 8023 ---\n",
            "perform better if its employees were told to toss a coin every morning to decide\n",
            "\n",
            "--- Chunk 8024 ---\n",
            "whether or not to go to work? Well, who knows; perhaps it would! The company\n",
            "\n",
            "--- Chunk 8025 ---\n",
            "would be forced to adapt its organization; it could not rely on any single person to\n",
            "\n",
            "--- Chunk 8026 ---\n",
            "work the coffee machine or perform any other critical tasks, so this expertise would\n",
            "\n",
            "--- Chunk 8027 ---\n",
            "have to be spread across several people. Employees would have to learn to cooperate\n",
            "\n",
            "--- Chunk 8028 ---\n",
            "with many of their coworkers, not just a handful of them. The company would\n",
            "\n",
            "--- Chunk 8029 ---\n",
            "become much more resilient. If one person quit, it wouldn’t make much of a differ‐\n",
            "\n",
            "--- Chunk 8030 ---\n",
            "ence. It’s unclear whether this idea would actually work for companies, but it certainly\n",
            "\n",
            "--- Chunk 8031 ---\n",
            "does for neural networks. Neurons trained with dropout cannot co-adapt with their\n",
            "\n",
            "--- Chunk 8032 ---\n",
            "neighboring neurons; they have to be as useful as possible on their own. They also\n",
            "\n",
            "--- Chunk 8033 ---\n",
            "cannot rely excessively on just a few input neurons; they must pay attention to each of\n",
            "\n",
            "--- Chunk 8034 ---\n",
            "their input neurons. They end up being less sensitive to slight changes in the inputs.\n",
            "\n",
            "--- Chunk 8035 ---\n",
            "In the end, you get a more robust network that generalizes better.\n",
            "Another way to understand the power of dropout is to realize that a unique neural\n",
            "\n",
            "--- Chunk 8036 ---\n",
            "network is generated at each training step. Since each neuron can be either present or\n",
            "\n",
            "--- Chunk 8037 ---\n",
            "absent, there are a total of 2N possible networks (where N is the total number of drop‐\n",
            "\n",
            "--- Chunk 8038 ---\n",
            "pable neurons). This is such a huge number that it is virtually impossible for the same\n",
            "\n",
            "--- Chunk 8039 ---\n",
            "neural network to be sampled twice. Once you have run 10,000 training steps, you\n",
            "\n",
            "--- Chunk 8040 ---\n",
            "have essentially trained 10,000 different neural networks (each with just one training\n",
            "\n",
            "--- Chunk 8041 ---\n",
            "instance). These neural networks are obviously not independent because they share\n",
            "\n",
            "--- Chunk 8042 ---\n",
            "many of their weights, but they are nevertheless all different. The resulting neural\n",
            "\n",
            "--- Chunk 8043 ---\n",
            "network can be seen as an averaging ensemble of all these smaller neural networks.\n",
            "\n",
            "--- Chunk 8044 ---\n",
            "366 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "--- Chunk 8045 ---\n",
            "In practice, you can usually apply dropout only to the neurons in\n",
            "the top one to three layers (excluding the output layer).\n",
            "\n",
            "--- Chunk 8046 ---\n",
            "There is one small but important technical detail. Suppose p = 50%, in which case\n",
            "\n",
            "--- Chunk 8047 ---\n",
            "during testing a neuron would be connected to twice as many input neurons as it\n",
            "\n",
            "--- Chunk 8048 ---\n",
            "would be (on average) during training. To compensate for this fact, we need to multi‐\n",
            "\n",
            "--- Chunk 8049 ---\n",
            "ply each neuron’s input connection weights by 0.5 after training. If we don’t, each\n",
            "\n",
            "--- Chunk 8050 ---\n",
            "neuron will get a total input signal roughly twice as large as what the network was\n",
            "\n",
            "--- Chunk 8051 ---\n",
            "trained on and will be unlikely to perform well. More generally, we need to multiply\n",
            "\n",
            "--- Chunk 8052 ---\n",
            "each input connection weight by the keep probability (1 – p) after training. Alterna‐\n",
            "\n",
            "--- Chunk 8053 ---\n",
            "tively, we can divide each neuron’s output by the keep probability during training\n",
            "\n",
            "--- Chunk 8054 ---\n",
            "(these alternatives are not perfectly equivalent, but they work equally well).\n",
            "\n",
            "--- Chunk 8055 ---\n",
            "To implement dropout using Keras, you can use the keras.layers.Dropout layer.\n",
            "\n",
            "--- Chunk 8056 ---\n",
            "During training, it randomly drops some inputs (setting them to 0) and divides the\n",
            "\n",
            "--- Chunk 8057 ---\n",
            "remaining inputs by the keep probability. After training, it does nothing at all; it just\n",
            "\n",
            "--- Chunk 8058 ---\n",
            "passes the inputs to the next layer. The following code applies dropout regularization\n",
            "before every Dense layer, using a dropout rate of 0.2:\n",
            "\n",
            "--- Chunk 8059 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.Flatten(input_shape=[28, 28]),\n",
            "    keras.layers.Dropout(rate=0.2),\n",
            "\n",
            "--- Chunk 8060 ---\n",
            "keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
            "    keras.layers.Dropout(rate=0.2),\n",
            "\n",
            "--- Chunk 8061 ---\n",
            "keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
            "    keras.layers.Dropout(rate=0.2),\n",
            "\n",
            "--- Chunk 8062 ---\n",
            "keras.layers.Dense(10, activation=\"softmax\")\n",
            "])\n",
            "\n",
            "--- Chunk 8063 ---\n",
            "Since dropout is only active during training, comparing the train‐\n",
            "ing loss and the validation loss can be misleading. In particular, a\n",
            "\n",
            "--- Chunk 8064 ---\n",
            "model may be overfitting the training set and yet have similar\n",
            "training and validation losses. So make sure to evaluate the training\n",
            "\n",
            "--- Chunk 8065 ---\n",
            "loss without dropout (e.g., after training).\n",
            "\n",
            "--- Chunk 8066 ---\n",
            "If you observe that the model is overfitting, you can increase the dropout rate. Con‐\n",
            "\n",
            "--- Chunk 8067 ---\n",
            "versely, you should try decreasing the dropout rate if the model underfits the training\n",
            "\n",
            "--- Chunk 8068 ---\n",
            "set. It can also help to increase the dropout rate for large layers, and reduce it for\n",
            "\n",
            "--- Chunk 8069 ---\n",
            "small ones. Moreover, many state-of-the-art architectures only use dropout after the\n",
            "\n",
            "--- Chunk 8070 ---\n",
            "last hidden layer, so you may want to try this if full dropout is too strong.\n",
            "\n",
            "--- Chunk 8071 ---\n",
            "Avoiding Overfitting Through Regularization | 367\n",
            "\n",
            "--- Chunk 8072 ---\n",
            "Dropout does tend to significantly slow down convergence, but it usually results in a\n",
            "\n",
            "--- Chunk 8073 ---\n",
            "much better model when tuned properly. So, it is generally well worth the extra time\n",
            "and effort.\n",
            "\n",
            "--- Chunk 8074 ---\n",
            "If you want to regularize a self-normalizing network based on the\n",
            "SELU activation function (as discussed earlier), you should use\n",
            "\n",
            "--- Chunk 8075 ---\n",
            "alpha dropout: this is a variant of dropout that preserves the mean\n",
            "and standard deviation of its inputs (it was introduced in the same\n",
            "\n",
            "--- Chunk 8076 ---\n",
            "paper as SELU, as regular dropout would break self-normalization).\n",
            "\n",
            "--- Chunk 8077 ---\n",
            "Monte Carlo (MC) Dropout\n",
            "In 2016, a paper25 by Yarin Gal and Zoubin Ghahramani added a few more good rea‐\n",
            "sons to use dropout:\n",
            "\n",
            "--- Chunk 8078 ---\n",
            "• First, the paper established a profound connection between dropout networks\n",
            "\n",
            "--- Chunk 8079 ---\n",
            "(i.e., neural networks containing a Dropout layer before every weight layer) and\n",
            "\n",
            "--- Chunk 8080 ---\n",
            "approximate Bayesian inference,26 giving dropout a solid mathematical justifica‐\n",
            "tion.\n",
            "\n",
            "--- Chunk 8081 ---\n",
            "• Second, the authors introduced a powerful technique called MC Dropout, which\n",
            "\n",
            "--- Chunk 8082 ---\n",
            "can boost the performance of any trained dropout model without having to\n",
            "\n",
            "--- Chunk 8083 ---\n",
            "retrain it or even modify it at all, provides a much better measure of the model’s\n",
            "uncertainty, and is also amazingly simple to implement.\n",
            "\n",
            "--- Chunk 8084 ---\n",
            "If this all sounds like a “one weird trick” advertisement, then take a look at the follow‐\n",
            "\n",
            "--- Chunk 8085 ---\n",
            "ing code. It is the full implementation of MC Dropout, boosting the dropout model\n",
            "we trained earlier without retraining it:\n",
            "\n",
            "--- Chunk 8086 ---\n",
            "y_probas = np.stack([model(X_test_scaled, training=True)\n",
            "                     for sample in range(100)])\n",
            "y_proba = y_probas.mean(axis=0)\n",
            "\n",
            "--- Chunk 8087 ---\n",
            "We just make 100 predictions over the test set, setting training=True to ensure that\n",
            "\n",
            "--- Chunk 8088 ---\n",
            "the Dropout layer is active, and stack the predictions. Since dropout is active, all the\n",
            "\n",
            "--- Chunk 8089 ---\n",
            "predictions will be different. Recall that predict() returns a matrix with one row per\n",
            "\n",
            "--- Chunk 8090 ---\n",
            "instance and one column per class. Because there are 10,000 instances in the test set\n",
            "\n",
            "--- Chunk 8091 ---\n",
            "and 10 classes, this is a matrix of shape [10000, 10]. We stack 100 such matrices, so\n",
            "\n",
            "--- Chunk 8092 ---\n",
            "y_probas is an array of shape [100, 10000, 10]. Once we average over the first\n",
            "\n",
            "--- Chunk 8093 ---\n",
            "25 Yarin Gal and Zoubin Ghahramani, “Dropout as a Bayesian Approximation: Representing Model Uncertainty\n",
            "\n",
            "--- Chunk 8094 ---\n",
            "in Deep Learning,” Proceedings of the 33rd International Conference on Machine Learning (2016): 1050–1059.\n",
            "\n",
            "--- Chunk 8095 ---\n",
            "26 Specifically, they show that training a dropout network is mathematically equivalent to approximate Bayesian\n",
            "\n",
            "--- Chunk 8096 ---\n",
            "inference in a specific type of probabilistic model called a Deep Gaussian Process.\n",
            "\n",
            "--- Chunk 8097 ---\n",
            "368 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "--- Chunk 8098 ---\n",
            "dimension (axis=0), we get y_proba, an array of shape [10000, 10], like we would get\n",
            "\n",
            "--- Chunk 8099 ---\n",
            "with a single prediction. That’s all! Averaging over multiple predictions with dropout\n",
            "\n",
            "--- Chunk 8100 ---\n",
            "on gives us a Monte Carlo estimate that is generally more reliable than the result of a\n",
            "\n",
            "--- Chunk 8101 ---\n",
            "single prediction with dropout off. For example, let’s look at the model’s prediction\n",
            "\n",
            "--- Chunk 8102 ---\n",
            "for the first instance in the Fashion MNIST test set, with dropout off:\n",
            "\n",
            "--- Chunk 8103 ---\n",
            ">>> np.round(model.predict(X_test_scaled[:1]), 2)\n",
            "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
            "      dtype=float32)\n",
            "\n",
            "--- Chunk 8104 ---\n",
            "The model seems almost certain that this image belongs to class 9 (ankle boot).\n",
            "\n",
            "--- Chunk 8105 ---\n",
            "Should you trust it? Is there really so little room for doubt? Compare this with the\n",
            "predictions made when dropout is activated:\n",
            "\n",
            "--- Chunk 8106 ---\n",
            ">>> np.round(y_probas[:, :1], 2)\n",
            "array([[[0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.17, 0.  , 0.68]],\n",
            "\n",
            "--- Chunk 8107 ---\n",
            "[[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.2 , 0.  , 0.64]],\n",
            "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.01, 0.  , 0.97]],\n",
            "\n",
            "--- Chunk 8108 ---\n",
            "[...]\n",
            "\n",
            "--- Chunk 8109 ---\n",
            "This tells a very different story: apparently, when we activate dropout, the model is\n",
            "\n",
            "--- Chunk 8110 ---\n",
            "not sure anymore. It still seems to prefer class 9, but sometimes it hesitates with\n",
            "\n",
            "--- Chunk 8111 ---\n",
            "classes 5 (sandal) and 7 (sneaker), which makes sense given they’re all footwear. Once\n",
            "\n",
            "--- Chunk 8112 ---\n",
            "we average over the first dimension, we get the following MC Dropout predictions:\n",
            "\n",
            "--- Chunk 8113 ---\n",
            ">>> np.round(y_proba[:1], 2)\n",
            "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 0.  , 0.16, 0.  , 0.62]],\n",
            "      dtype=float32)\n",
            "\n",
            "--- Chunk 8114 ---\n",
            "The model still thinks this image belongs to class 9, but only with a 62% confidence,\n",
            "\n",
            "--- Chunk 8115 ---\n",
            "which seems much more reasonable than 99%. Plus it’s useful to know exactly which\n",
            "\n",
            "--- Chunk 8116 ---\n",
            "other classes it thinks are likely. And you can also take a look at the standard devia‐\n",
            "tion of the probability estimates:\n",
            "\n",
            "--- Chunk 8117 ---\n",
            ">>> y_std = y_probas.std(axis=0)\n",
            ">>> np.round(y_std[:1], 2)\n",
            "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.28, 0.  , 0.21, 0.02, 0.32]],\n",
            "\n",
            "--- Chunk 8118 ---\n",
            "dtype=float32)\n",
            "\n",
            "--- Chunk 8119 ---\n",
            "Apparently there’s quite a lot of variance in the probability estimates: if you were\n",
            "\n",
            "--- Chunk 8120 ---\n",
            "building a risk-sensitive system (e.g., a medical or financial system), you should prob‐\n",
            "\n",
            "--- Chunk 8121 ---\n",
            "ably treat such an uncertain prediction with extreme caution. You definitely would\n",
            "\n",
            "--- Chunk 8122 ---\n",
            "not treat it like a 99% confident prediction. Moreover, the model’s accuracy got a\n",
            "small boost from 86.8 to 86.9:\n",
            "\n",
            "--- Chunk 8123 ---\n",
            ">>> accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
            ">>> accuracy\n",
            "0.8694\n",
            "\n",
            "Avoiding Overfitting Through Regularization | 369\n",
            "\n",
            "--- Chunk 8124 ---\n",
            "The number of Monte Carlo samples you use (100 in this example)\n",
            "is a hyperparameter you can tweak. The higher it is, the more accu‐\n",
            "\n",
            "--- Chunk 8125 ---\n",
            "rate the predictions and their uncertainty estimates will be. How‐\n",
            "ever, if you double it, inference time will also be doubled.\n",
            "\n",
            "--- Chunk 8126 ---\n",
            "Moreover, above a certain number of samples, you will notice little\n",
            "improvement. So your job is to find the right trade-off between\n",
            "\n",
            "--- Chunk 8127 ---\n",
            "latency and accuracy, depending on your application.\n",
            "\n",
            "--- Chunk 8128 ---\n",
            "If your model contains other layers that behave in a special way during training (such\n",
            "\n",
            "--- Chunk 8129 ---\n",
            "as BatchNormalization layers), then you should not force training mode like we just\n",
            "\n",
            "--- Chunk 8130 ---\n",
            "did. Instead, you should replace the Dropout layers with the following MCDropout\n",
            "class:27\n",
            "\n",
            "--- Chunk 8131 ---\n",
            "class MCDropout(keras.layers.Dropout):\n",
            "    def call(self, inputs):\n",
            "        return super().call(inputs, training=True)\n",
            "\n",
            "--- Chunk 8132 ---\n",
            "Here, we just subclass the Dropout layer and override the call() method to force its\n",
            "\n",
            "--- Chunk 8133 ---\n",
            "training argument to True (see Chapter 12). Similarly, you could define an MCAlpha\n",
            "\n",
            "--- Chunk 8134 ---\n",
            "Dropout class by subclassing AlphaDropout instead. If you are creating a model from\n",
            "\n",
            "--- Chunk 8135 ---\n",
            "scratch, it’s just a matter of using MCDropout rather than Dropout. But if you have a\n",
            "\n",
            "--- Chunk 8136 ---\n",
            "model that was already trained using Dropout, you need to create a new model that’s\n",
            "\n",
            "--- Chunk 8137 ---\n",
            "identical to the existing model except that it replaces the Dropout layers with MCDrop\n",
            "out, then copy the existing model’s weights to your new model.\n",
            "\n",
            "--- Chunk 8138 ---\n",
            "In short, MC Dropout is a fantastic technique that boosts dropout models and pro‐\n",
            "\n",
            "--- Chunk 8139 ---\n",
            "vides better uncertainty estimates. And of course, since it is just regular dropout dur‐\n",
            "ing training, it also acts like a regularizer.\n",
            "\n",
            "--- Chunk 8140 ---\n",
            "Max-Norm Regularization\n",
            "Another regularization technique that is popular for neural networks is called max-\n",
            "\n",
            "--- Chunk 8141 ---\n",
            "norm regularization: for each neuron, it constrains the weights w of the incoming\n",
            "\n",
            "--- Chunk 8142 ---\n",
            "connections such that ∥ w ∥2 ≤ r, where r is the max-norm hyperparameter and ∥ · ∥2\n",
            "is the ℓ2 norm.\n",
            "\n",
            "--- Chunk 8143 ---\n",
            "is the ℓ2 norm.\n",
            "Max-norm regularization does not add a regularization loss term to the overall loss\n",
            "\n",
            "--- Chunk 8144 ---\n",
            "function. Instead, it is typically implemented by computing ∥w∥2 after each training\n",
            "step and rescaling w if needed (w ← w r/‖ w ‖2).\n",
            "\n",
            "--- Chunk 8145 ---\n",
            "27 This MCDropout class will work with all Keras APIs, including the Sequential API. If you only care about the\n",
            "\n",
            "--- Chunk 8146 ---\n",
            "Functional API or the Subclassing API, you do not have to create an MCDropout class; you can create a regular\n",
            "\n",
            "--- Chunk 8147 ---\n",
            "Dropout layer and call it with training=True.\n",
            "\n",
            "--- Chunk 8148 ---\n",
            "370 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "--- Chunk 8149 ---\n",
            "Reducing r increases the amount of regularization and helps reduce overfitting. Max-\n",
            "\n",
            "--- Chunk 8150 ---\n",
            "norm regularization can also help alleviate the unstable gradients problems (if you\n",
            "are not using Batch Normalization).\n",
            "\n",
            "--- Chunk 8151 ---\n",
            "To implement max-norm regularization in Keras, set the kernel_constraint argu‐\n",
            "\n",
            "--- Chunk 8152 ---\n",
            "ment of each hidden layer to a max_norm() constraint with the appropriate max value,\n",
            "like this:\n",
            "\n",
            "--- Chunk 8153 ---\n",
            "keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
            "                   kernel_constraint=keras.constraints.max_norm(1.))\n",
            "\n",
            "--- Chunk 8154 ---\n",
            "After each training iteration, the model’s fit() method will call the object returned\n",
            "\n",
            "--- Chunk 8155 ---\n",
            "by max_norm(), passing it the layer’s weights and getting rescaled weights in return,\n",
            "\n",
            "--- Chunk 8156 ---\n",
            "which then replace the layer’s weights. As you’ll see in Chapter 12, you can define\n",
            "\n",
            "--- Chunk 8157 ---\n",
            "your own custom constraint function if necessary and use it as the kernel_con\n",
            "\n",
            "--- Chunk 8158 ---\n",
            "straint. You can also constrain the bias terms by setting the bias_constraint\n",
            "argument.\n",
            "\n",
            "--- Chunk 8159 ---\n",
            "argument.\n",
            "The max_norm() function has an axis argument that defaults to 0. A Dense layer usu‐\n",
            "\n",
            "--- Chunk 8160 ---\n",
            "ally has weights of shape [number of inputs, number of neurons], so using axis=0\n",
            "\n",
            "--- Chunk 8161 ---\n",
            "means that the max-norm constraint will apply independently to each neuron’s\n",
            "\n",
            "--- Chunk 8162 ---\n",
            "weight vector. If you want to use max-norm with convolutional layers (see Chap‐\n",
            "\n",
            "--- Chunk 8163 ---\n",
            "ter 14), make sure to set the max_norm() constraint’s axis argument appropriately\n",
            "(usually axis=[0, 1, 2]).\n",
            "\n",
            "--- Chunk 8164 ---\n",
            "Summary and Practical Guidelines\n",
            "In this chapter we have covered a wide range of techniques, and you may be wonder‐\n",
            "\n",
            "--- Chunk 8165 ---\n",
            "ing which ones you should use. This depends on the task, and there is no clear con‐\n",
            "\n",
            "--- Chunk 8166 ---\n",
            "sensus yet, but I have found the configuration in Table 11-3 to work fine in most\n",
            "\n",
            "--- Chunk 8167 ---\n",
            "cases, without requiring much hyperparameter tuning. That said, please do not con‐\n",
            "sider these defaults as hard rules!\n",
            "\n",
            "--- Chunk 8168 ---\n",
            "Table 11-3. Default DNN configuration\n",
            "Hyperparameter Default value\n",
            "Kernel initializer He initialization\n",
            "Activation function ELU\n",
            "\n",
            "--- Chunk 8169 ---\n",
            "Normalization None if shallow; Batch Norm if deep\n",
            "Regularization Early stopping (+ℓ2 reg. if needed)\n",
            "\n",
            "--- Chunk 8170 ---\n",
            "Optimizer Momentum optimization (or RMSProp or Nadam)\n",
            "Learning rate schedule 1cycle\n",
            "\n",
            "--- Chunk 8171 ---\n",
            "Summary and Practical Guidelines | 371\n",
            "\n",
            "--- Chunk 8172 ---\n",
            "If the network is a simple stack of dense layers, then it can self-normalize, and you\n",
            "should use the configuration in Table 11-4 instead.\n",
            "\n",
            "--- Chunk 8173 ---\n",
            "Table 11-4. DNN configuration for a self-normalizing net\n",
            "Hyperparameter Default value\n",
            "Kernel initializer LeCun initialization\n",
            "\n",
            "--- Chunk 8174 ---\n",
            "Activation function SELU\n",
            "Normalization None (self-normalization)\n",
            "Regularization Alpha dropout if needed\n",
            "\n",
            "--- Chunk 8175 ---\n",
            "Optimizer Momentum optimization (or RMSProp or Nadam)\n",
            "Learning rate schedule 1cycle\n",
            "\n",
            "--- Chunk 8176 ---\n",
            "Don’t forget to normalize the input features! You should also try to reuse parts of a\n",
            "\n",
            "--- Chunk 8177 ---\n",
            "pretrained neural network if you can find one that solves a similar problem, or use\n",
            "\n",
            "--- Chunk 8178 ---\n",
            "unsupervised pretraining if you have a lot of unlabeled data, or use pretraining on an\n",
            "\n",
            "--- Chunk 8179 ---\n",
            "auxiliary task if you have a lot of labeled data for a similar task.\n",
            "While the previous guidelines should cover most cases, here are some exceptions:\n",
            "\n",
            "--- Chunk 8180 ---\n",
            "• If you need a sparse model, you can use ℓ1 regularization (and optionally zero out\n",
            "\n",
            "--- Chunk 8181 ---\n",
            "the tiny weights after training). If you need an even sparser model, you can use\n",
            "\n",
            "--- Chunk 8182 ---\n",
            "the TensorFlow Model Optimization Toolkit. This will break self-normalization,\n",
            "so you should use the default configuration in this case.\n",
            "\n",
            "--- Chunk 8183 ---\n",
            "• If you need a low-latency model (one that performs lightning-fast predictions),\n",
            "\n",
            "--- Chunk 8184 ---\n",
            "you may need to use fewer layers, fold the Batch Normalization layers into the\n",
            "\n",
            "--- Chunk 8185 ---\n",
            "previous layers, and possibly use a faster activation function such as leaky ReLU\n",
            "\n",
            "--- Chunk 8186 ---\n",
            "or just ReLU. Having a sparse model will also help. Finally, you may want to\n",
            "\n",
            "--- Chunk 8187 ---\n",
            "reduce the float precision from 32 bits to 16 or even 8 bits (see “Deploying a\n",
            "\n",
            "--- Chunk 8188 ---\n",
            "Model to a Mobile or Embedded Device” on page 685). Again, check out TF-\n",
            "MOT.\n",
            "\n",
            "--- Chunk 8189 ---\n",
            "• If you are building a risk-sensitive application, or inference latency is not very\n",
            "\n",
            "--- Chunk 8190 ---\n",
            "important in your application, you can use MC Dropout to boost performance\n",
            "\n",
            "--- Chunk 8191 ---\n",
            "and get more reliable probability estimates, along with uncertainty estimates.\n",
            "\n",
            "--- Chunk 8192 ---\n",
            "With these guidelines, you are now ready to train very deep nets! I hope you are now\n",
            "\n",
            "--- Chunk 8193 ---\n",
            "convinced that you can go quite a long way using just Keras. There may come a time,\n",
            "\n",
            "--- Chunk 8194 ---\n",
            "however, when you need to have even more control; for example, to write a custom\n",
            "\n",
            "--- Chunk 8195 ---\n",
            "loss function or to tweak the training algorithm. For such cases you will need to use\n",
            "\n",
            "--- Chunk 8196 ---\n",
            "TensorFlow’s lower-level API, as you will see in the next chapter.\n",
            "\n",
            "--- Chunk 8197 ---\n",
            "372 | Chapter 11: Training Deep Neural Networks\n",
            "\n",
            "\n",
            "\n",
            "Exercises\n",
            "1. Is it OK to initialize all the weights to the same value as long as that value is\n",
            "\n",
            "--- Chunk 8198 ---\n",
            "selected randomly using He initialization?\n",
            "2. Is it OK to initialize the bias terms to 0?\n",
            "\n",
            "--- Chunk 8199 ---\n",
            "3. Name three advantages of the SELU activation function over ReLU.\n",
            "\n",
            "--- Chunk 8200 ---\n",
            "4. In which cases would you want to use each of the following activation functions:\n",
            "\n",
            "--- Chunk 8201 ---\n",
            "SELU, leaky ReLU (and its variants), ReLU, tanh, logistic, and softmax?\n",
            "\n",
            "--- Chunk 8202 ---\n",
            "5. What may happen if you set the momentum hyperparameter too close to 1 (e.g.,\n",
            "\n",
            "--- Chunk 8203 ---\n",
            "0.99999) when using an SGD optimizer?\n",
            "6. Name three ways you can produce a sparse model.\n",
            "\n",
            "--- Chunk 8204 ---\n",
            "7. Does dropout slow down training? Does it slow down inference (i.e., making\n",
            "\n",
            "--- Chunk 8205 ---\n",
            "predictions on new instances)? What about MC Dropout?\n",
            "8. Practice training a deep neural network on the CIFAR10 image dataset:\n",
            "\n",
            "--- Chunk 8206 ---\n",
            "a. Build a DNN with 20 hidden layers of 100 neurons each (that’s too many, but\n",
            "\n",
            "--- Chunk 8207 ---\n",
            "it’s the point of this exercise). Use He initialization and the ELU activation\n",
            "function.\n",
            "\n",
            "--- Chunk 8208 ---\n",
            "b. Using Nadam optimization and early stopping, train the network on the\n",
            "CIFAR10 dataset. You can load it with keras.datasets.cifar10.load_\n",
            "\n",
            "--- Chunk 8209 ---\n",
            "data(). The dataset is composed of 60,000 32 × 32–pixel color images (50,000\n",
            "\n",
            "--- Chunk 8210 ---\n",
            "for training, 10,000 for testing) with 10 classes, so you’ll need a softmax out‐\n",
            "\n",
            "--- Chunk 8211 ---\n",
            "put layer with 10 neurons. Remember to search for the right learning rate each\n",
            "time you change the model’s architecture or hyperparameters.\n",
            "\n",
            "--- Chunk 8212 ---\n",
            "c. Now try adding Batch Normalization and compare the learning curves: Is it\n",
            "\n",
            "--- Chunk 8213 ---\n",
            "converging faster than before? Does it produce a better model? How does it\n",
            "affect training speed?\n",
            "\n",
            "--- Chunk 8214 ---\n",
            "d. Try replacing Batch Normalization with SELU, and make the necessary adjust‐\n",
            "\n",
            "--- Chunk 8215 ---\n",
            "ements to ensure the network self-normalizes (i.e., standardize the input fea‐\n",
            "\n",
            "--- Chunk 8216 ---\n",
            "tures, use LeCun normal initialization, make sure the DNN contains only a\n",
            "sequence of dense layers, etc.).\n",
            "\n",
            "--- Chunk 8217 ---\n",
            "e. Try regularizing the model with alpha dropout. Then, without retraining your\n",
            "model, see if you can achieve better accuracy using MC Dropout.\n",
            "\n",
            "--- Chunk 8218 ---\n",
            "f. Retrain your model using 1cycle scheduling and see if it improves training\n",
            "speed and model accuracy.\n",
            "\n",
            "--- Chunk 8219 ---\n",
            "Solutions to these exercises are available in Appendix A.\n",
            "\n",
            "Exercises | 373\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER 12\n",
            "Custom Models and Training\n",
            "\n",
            "with TensorFlow\n",
            "\n",
            "--- Chunk 8220 ---\n",
            "Up until now, we’ve used only TensorFlow’s high-level API, tf.keras, but it already got\n",
            "\n",
            "--- Chunk 8221 ---\n",
            "us pretty far: we built various neural network architectures, including regression and\n",
            "\n",
            "--- Chunk 8222 ---\n",
            "classification nets, Wide & Deep nets, and self-normalizing nets, using all sorts of\n",
            "\n",
            "--- Chunk 8223 ---\n",
            "techniques, such as Batch Normalization, dropout, and learning rate schedules. In\n",
            "\n",
            "--- Chunk 8224 ---\n",
            "fact, 95% of the use cases you will encounter will not require anything other than\n",
            "\n",
            "--- Chunk 8225 ---\n",
            "tf.keras (and tf.data; see Chapter 13). But now it’s time to dive deeper into TensorFlow\n",
            "\n",
            "--- Chunk 8226 ---\n",
            "and take a look at its lower-level Python API. This will be useful when you need extra\n",
            "\n",
            "--- Chunk 8227 ---\n",
            "control to write custom loss functions, custom metrics, layers, models, initializers,\n",
            "\n",
            "--- Chunk 8228 ---\n",
            "regularizers, weight constraints, and more. You may even need to fully control the\n",
            "\n",
            "--- Chunk 8229 ---\n",
            "training loop itself, for example to apply special transformations or constraints to the\n",
            "\n",
            "--- Chunk 8230 ---\n",
            "gradients (beyond just clipping them) or to use multiple optimizers for different parts\n",
            "\n",
            "--- Chunk 8231 ---\n",
            "of the network. We will cover all these cases in this chapter, and we will also look at\n",
            "\n",
            "--- Chunk 8232 ---\n",
            "how you can boost your custom models and training algorithms using TensorFlow’s\n",
            "\n",
            "--- Chunk 8233 ---\n",
            "automatic graph generation feature. But first, let’s take a quick tour of TensorFlow.\n",
            "\n",
            "--- Chunk 8234 ---\n",
            "TensorFlow 2.0 (beta) was released in June 2019, making Tensor‐\n",
            "Flow much easier to use. The first edition of this book used TF 1,\n",
            "\n",
            "--- Chunk 8235 ---\n",
            "while this edition uses TF 2.\n",
            "\n",
            "--- Chunk 8236 ---\n",
            "Custom Models and Training with TensorFlow | 375\n",
            "\n",
            "--- Chunk 8237 ---\n",
            "A Quick Tour of TensorFlow\n",
            "As you know, TensorFlow is a powerful library for numerical computation, particu‐\n",
            "\n",
            "--- Chunk 8238 ---\n",
            "larly well suited and fine-tuned for large-scale Machine Learning (but you could use\n",
            "\n",
            "--- Chunk 8239 ---\n",
            "it for anything else that requires heavy computations). It was developed by the Google\n",
            "\n",
            "--- Chunk 8240 ---\n",
            "Brain team and it powers many of Google’s large-scale services, such as Google Cloud\n",
            "\n",
            "--- Chunk 8241 ---\n",
            "Speech, Google Photos, and Google Search. It was open sourced in November 2015,\n",
            "\n",
            "--- Chunk 8242 ---\n",
            "and it is now the most popular Deep Learning library (in terms of citations in papers,\n",
            "\n",
            "--- Chunk 8243 ---\n",
            "adoption in companies, stars on GitHub, etc.). Countless projects use TensorFlow for\n",
            "\n",
            "--- Chunk 8244 ---\n",
            "all sorts of Machine Learning tasks, such as image classification, natural language\n",
            "processing, recommender systems, and time series forecasting.\n",
            "\n",
            "--- Chunk 8245 ---\n",
            "So what does TensorFlow offer? Here’s a summary:\n",
            "\n",
            "--- Chunk 8246 ---\n",
            "• Its core is very similar to NumPy, but with GPU support.\n",
            "• It supports distributed computing (across multiple devices and servers).\n",
            "\n",
            "--- Chunk 8247 ---\n",
            "• It includes a kind of just-in-time (JIT) compiler that allows it to optimize compu‐\n",
            "\n",
            "--- Chunk 8248 ---\n",
            "tations for speed and memory usage. It works by extracting the computation\n",
            "graph from a Python function, then optimizing it (e.g., by pruning unused\n",
            "\n",
            "--- Chunk 8249 ---\n",
            "nodes), and finally running it efficiently (e.g., by automatically running inde‐\n",
            "pendent operations in parallel).\n",
            "\n",
            "--- Chunk 8250 ---\n",
            "• Computation graphs can be exported to a portable format, so you can train a\n",
            "\n",
            "--- Chunk 8251 ---\n",
            "TensorFlow model in one environment (e.g., using Python on Linux) and run it\n",
            "in another (e.g., using Java on an Android device).\n",
            "\n",
            "--- Chunk 8252 ---\n",
            "• It implements autodiff (see Chapter 10 and Appendix D) and provides some\n",
            "\n",
            "--- Chunk 8253 ---\n",
            "excellent optimizers, such as RMSProp and Nadam (see Chapter 11), so you can\n",
            "easily minimize all sorts of loss functions.\n",
            "\n",
            "--- Chunk 8254 ---\n",
            "TensorFlow offers many more features built on top of these core features: the most\n",
            "\n",
            "--- Chunk 8255 ---\n",
            "important is of course tf.keras,1 but it also has data loading and preprocessing ops\n",
            "\n",
            "--- Chunk 8256 ---\n",
            "(tf.data, tf.io, etc.), image processing ops (tf.image), signal processing ops\n",
            "\n",
            "--- Chunk 8257 ---\n",
            "(tf.signal), and more (see Figure 12-1 for an overview of TensorFlow’s Python\n",
            "API).\n",
            "\n",
            "--- Chunk 8258 ---\n",
            "1 TensorFlow includes another Deep Learning API called the Estimators API, but the TensorFlow team recom‐\n",
            "mends using tf.keras instead.\n",
            "\n",
            "--- Chunk 8259 ---\n",
            "376 | Chapter 12: Custom Models and Training with TensorFlow\n",
            "\n",
            "--- Chunk 8260 ---\n",
            "We will cover many of the packages and functions of the Tensor‐\n",
            "Flow API, but it’s impossible to cover them all, so you should really\n",
            "\n",
            "--- Chunk 8261 ---\n",
            "take some time to browse through the API; you will find that it is\n",
            "quite rich and well documented.\n",
            "\n",
            "--- Chunk 8262 ---\n",
            "Figure 12-1. TensorFlow’s Python API\n",
            "\n",
            "--- Chunk 8263 ---\n",
            "At the lowest level, each TensorFlow operation (op for short) is implemented using\n",
            "\n",
            "--- Chunk 8264 ---\n",
            "highly efficient C++ code.2 Many operations have multiple implementations called\n",
            "\n",
            "--- Chunk 8265 ---\n",
            "kernels: each kernel is dedicated to a specific device type, such as CPUs, GPUs, or\n",
            "\n",
            "--- Chunk 8266 ---\n",
            "even TPUs (tensor processing units). As you may know, GPUs can dramatically speed\n",
            "\n",
            "--- Chunk 8267 ---\n",
            "up computations by splitting them into many smaller chunks and running them in\n",
            "\n",
            "--- Chunk 8268 ---\n",
            "parallel across many GPU threads. TPUs are even faster: they are custom ASIC chips\n",
            "\n",
            "--- Chunk 8269 ---\n",
            "built specifically for Deep Learning operations3 (we will discuss how to use Tensor‐\n",
            "Flow with GPUs or TPUs in Chapter 19).\n",
            "\n",
            "--- Chunk 8270 ---\n",
            "TensorFlow’s architecture is shown in Figure 12-2. Most of the time your code will\n",
            "\n",
            "--- Chunk 8271 ---\n",
            "use the high-level APIs (especially tf.keras and tf.data); but when you need more flex‐\n",
            "\n",
            "--- Chunk 8272 ---\n",
            "ibility, you will use the lower-level Python API, handling tensors directly. Note that\n",
            "\n",
            "--- Chunk 8273 ---\n",
            "2 If you ever need to (but you probably won’t), you can write your own operations using the C++ API.\n",
            "\n",
            "--- Chunk 8274 ---\n",
            "3 To learn more about TPUs and how they work, check out https://homl.info/tpus.\n",
            "\n",
            "--- Chunk 8275 ---\n",
            "A Quick Tour of TensorFlow | 377\n",
            "\n",
            "--- Chunk 8276 ---\n",
            "APIs for other languages are also available. In any case, TensorFlow’s execution\n",
            "\n",
            "--- Chunk 8277 ---\n",
            "engine will take care of running the operations efficiently, even across multiple devi‐\n",
            "ces and machines if you tell it to.\n",
            "\n",
            "--- Chunk 8278 ---\n",
            "Figure 12-2. TensorFlow’s architecture\n",
            "\n",
            "--- Chunk 8279 ---\n",
            "TensorFlow runs not only on Windows, Linux, and macOS, but also on mobile devi‐\n",
            "\n",
            "--- Chunk 8280 ---\n",
            "ces (using TensorFlow Lite), including both iOS and Android (see Chapter 19). If you\n",
            "\n",
            "--- Chunk 8281 ---\n",
            "do not want to use the Python API, there are C++, Java, Go, and Swift APIs. There is\n",
            "\n",
            "--- Chunk 8282 ---\n",
            "even a JavaScript implementation called TensorFlow.js that makes it possible to run\n",
            "your models directly in your browser.\n",
            "\n",
            "--- Chunk 8283 ---\n",
            "There’s more to TensorFlow than the library. TensorFlow is at the center of an exten‐\n",
            "\n",
            "--- Chunk 8284 ---\n",
            "sive ecosystem of libraries. First, there’s TensorBoard for visualization (see Chap‐\n",
            "\n",
            "--- Chunk 8285 ---\n",
            "ter 10). Next, there’s TensorFlow Extended (TFX), which is a set of libraries built by\n",
            "\n",
            "--- Chunk 8286 ---\n",
            "Google to productionize TensorFlow projects: it includes tools for data validation,\n",
            "\n",
            "--- Chunk 8287 ---\n",
            "preprocessing, model analysis, and serving (with TF Serving; see Chapter 19). Goo‐\n",
            "\n",
            "--- Chunk 8288 ---\n",
            "gle’s TensorFlow Hub provides a way to easily download and reuse pretrained neural\n",
            "\n",
            "--- Chunk 8289 ---\n",
            "networks. You can also get many neural network architectures, some of them pre‐\n",
            "\n",
            "--- Chunk 8290 ---\n",
            "trained, in TensorFlow’s model garden. Check out the TensorFlow Resources and\n",
            "\n",
            "--- Chunk 8291 ---\n",
            "https://github.com/jtoy/awesome-tensorflow for more TensorFlow-based projects. You\n",
            "\n",
            "--- Chunk 8292 ---\n",
            "will find hundreds of TensorFlow projects on GitHub, so it is often easy to find exist‐\n",
            "ing code for whatever you are trying to do.\n",
            "\n",
            "--- Chunk 8293 ---\n",
            "More and more ML papers are released along with their implemen‐\n",
            "tations, and sometimes even with pretrained models. Check out\n",
            "\n",
            "--- Chunk 8294 ---\n",
            "https://paperswithcode.com/ to easily find them.\n",
            "\n",
            "--- Chunk 8295 ---\n",
            "378 | Chapter 12: Custom Models and Training with TensorFlow\n",
            "\n",
            "--- Chunk 8296 ---\n",
            "Last but not least, TensorFlow has a dedicated team of passionate and helpful devel‐\n",
            "\n",
            "--- Chunk 8297 ---\n",
            "opers, as well as a large community contributing to improving it. To ask technical\n",
            "\n",
            "--- Chunk 8298 ---\n",
            "questions, you should use http://stackoverflow.com/ and tag your question with ten‐\n",
            "\n",
            "--- Chunk 8299 ---\n",
            "sorflow and python. You can file bugs and feature requests through GitHub. For gen‐\n",
            "eral discussions, join the Google group.\n",
            "\n",
            "--- Chunk 8300 ---\n",
            "OK, it’s time to start coding!\n",
            "\n",
            "--- Chunk 8301 ---\n",
            "Using TensorFlow like NumPy\n",
            "TensorFlow’s API revolves around tensors, which flow from operation to operation—\n",
            "\n",
            "--- Chunk 8302 ---\n",
            "hence the name TensorFlow. A tensor is very similar to a NumPy ndarray: it is usu‐\n",
            "\n",
            "--- Chunk 8303 ---\n",
            "ally a multidimensional array, but it can also hold a scalar (a simple value, such as 42).\n",
            "\n",
            "--- Chunk 8304 ---\n",
            "These tensors will be important when we create custom cost functions, custom met‐\n",
            "\n",
            "--- Chunk 8305 ---\n",
            "rics, custom layers, and more, so let’s see how to create and manipulate them.\n",
            "\n",
            "--- Chunk 8306 ---\n",
            "Tensors and Operations\n",
            "You can create a tensor with tf.constant(). For example, here is a tensor represent‐\n",
            "\n",
            "--- Chunk 8307 ---\n",
            "ing a matrix with two rows and three columns of floats:\n",
            "\n",
            "--- Chunk 8308 ---\n",
            ">>> tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix\n",
            "<tf.Tensor: id=0, shape=(2, 3), dtype=float32, numpy=\n",
            "array([[1., 2., 3.],\n",
            "\n",
            "--- Chunk 8309 ---\n",
            "[4., 5., 6.]], dtype=float32)>\n",
            ">>> tf.constant(42) # scalar\n",
            "<tf.Tensor: id=1, shape=(), dtype=int32, numpy=42>\n",
            "\n",
            "--- Chunk 8310 ---\n",
            "Just like an ndarray, a tf.Tensor has a shape and a data type (dtype):\n",
            ">>> t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
            ">>> t.shape\n",
            "\n",
            "--- Chunk 8311 ---\n",
            ">>> t.shape\n",
            "TensorShape([2, 3])\n",
            ">>> t.dtype\n",
            "tf.float32\n",
            "\n",
            "--- Chunk 8312 ---\n",
            "Indexing works much like in NumPy:\n",
            ">>> t[:, 1:]\n",
            "<tf.Tensor: id=5, shape=(2, 2), dtype=float32, numpy=\n",
            "array([[2., 3.],\n",
            "\n",
            "--- Chunk 8313 ---\n",
            "array([[2., 3.],\n",
            "       [5., 6.]], dtype=float32)>\n",
            ">>> t[..., 1, tf.newaxis]\n",
            "<tf.Tensor: id=15, shape=(2, 1), dtype=float32, numpy=\n",
            "array([[2.],\n",
            "\n",
            "--- Chunk 8314 ---\n",
            "array([[2.],\n",
            "       [5.]], dtype=float32)>\n",
            "\n",
            "--- Chunk 8315 ---\n",
            "Most importantly, all sorts of tensor operations are available:\n",
            ">>> t + 10\n",
            "<tf.Tensor: id=18, shape=(2, 3), dtype=float32, numpy=\n",
            "\n",
            "--- Chunk 8316 ---\n",
            "Using TensorFlow like NumPy | 379\n",
            "\n",
            "--- Chunk 8317 ---\n",
            "array([[11., 12., 13.],\n",
            "       [14., 15., 16.]], dtype=float32)>\n",
            ">>> tf.square(t)\n",
            "<tf.Tensor: id=20, shape=(2, 3), dtype=float32, numpy=\n",
            "\n",
            "--- Chunk 8318 ---\n",
            "array([[ 1.,  4.,  9.],\n",
            "       [16., 25., 36.]], dtype=float32)>\n",
            ">>> t @ tf.transpose(t)\n",
            "<tf.Tensor: id=24, shape=(2, 2), dtype=float32, numpy=\n",
            "\n",
            "--- Chunk 8319 ---\n",
            "array([[14., 32.],\n",
            "       [32., 77.]], dtype=float32)>\n",
            "\n",
            "--- Chunk 8320 ---\n",
            "Note that writing t + 10 is equivalent to calling tf.add(t, 10) (indeed, Python calls\n",
            "\n",
            "--- Chunk 8321 ---\n",
            "the magic method t.__add__(10), which just calls tf.add(t, 10)). Other operators\n",
            "\n",
            "--- Chunk 8322 ---\n",
            "like - and * are also supported. The @ operator was added in Python 3.5, for matrix\n",
            "\n",
            "--- Chunk 8323 ---\n",
            "multiplication: it is equivalent to calling the tf.matmul() function.\n",
            "You will find all the basic math operations you need (tf.add(), tf.multiply(),\n",
            "\n",
            "--- Chunk 8324 ---\n",
            "tf.square(), tf.exp(), tf.sqrt(), etc.) and most operations that you can find in\n",
            "\n",
            "--- Chunk 8325 ---\n",
            "NumPy (e.g., tf.reshape(), tf.squeeze(), tf.tile()). Some functions have a dif‐\n",
            "\n",
            "--- Chunk 8326 ---\n",
            "ferent name than in NumPy; for instance, tf.reduce_mean(), tf.reduce_sum(),\n",
            "\n",
            "--- Chunk 8327 ---\n",
            "tf.reduce_max(), and tf.math.log() are the equivalent of np.mean(), np.sum(),\n",
            "\n",
            "--- Chunk 8328 ---\n",
            "np.max() and np.log(). When the name differs, there is often a good reason for it.\n",
            "\n",
            "--- Chunk 8329 ---\n",
            "For example, in TensorFlow you must write tf.transpose(t); you cannot just write\n",
            "\n",
            "--- Chunk 8330 ---\n",
            "t.T like in NumPy. The reason is that the tf.transpose() function does not do\n",
            "\n",
            "--- Chunk 8331 ---\n",
            "exactly the same thing as NumPy’s T attribute: in TensorFlow, a new tensor is created\n",
            "\n",
            "--- Chunk 8332 ---\n",
            "with its own copy of the transposed data, while in NumPy, t.T is just a transposed\n",
            "\n",
            "--- Chunk 8333 ---\n",
            "view on the same data. Similarly, the tf.reduce_sum() operation is named this way\n",
            "\n",
            "--- Chunk 8334 ---\n",
            "because its GPU kernel (i.e., GPU implementation) uses a reduce algorithm that does\n",
            "\n",
            "--- Chunk 8335 ---\n",
            "not guarantee the order in which the elements are added: because 32-bit floats have\n",
            "\n",
            "--- Chunk 8336 ---\n",
            "limited precision, the result may change ever so slightly every time you call this oper‐\n",
            "\n",
            "--- Chunk 8337 ---\n",
            "ation. The same is true of tf.reduce_mean() (but of course tf.reduce_max() is\n",
            "deterministic).\n",
            "\n",
            "--- Chunk 8338 ---\n",
            "Many functions and classes have aliases. For example, tf.add()\n",
            "and tf.math.add() are the same function. This allows TensorFlow\n",
            "\n",
            "--- Chunk 8339 ---\n",
            "to have concise names for the most common operations4 while pre‐\n",
            "serving well-organized packages.\n",
            "\n",
            "--- Chunk 8340 ---\n",
            "4 A notable exception is tf.math.log(), which is commonly used but doesn’t have a tf.log() alias (as it might\n",
            "be confused with logging).\n",
            "\n",
            "--- Chunk 8341 ---\n",
            "380 | Chapter 12: Custom Models and Training with TensorFlow\n",
            "\n",
            "--- Chunk 8342 ---\n",
            "Keras’ Low-Level API\n",
            "The Keras API has its own low-level API, located in keras.backend. It includes func‐\n",
            "\n",
            "--- Chunk 8343 ---\n",
            "tions like square(), exp(), and sqrt(). In tf.keras, these functions generally just call\n",
            "\n",
            "--- Chunk 8344 ---\n",
            "the corresponding TensorFlow operations. If you want to write code that will be\n",
            "\n",
            "--- Chunk 8345 ---\n",
            "portable to other Keras implementations, you should use these Keras functions. How‐\n",
            "\n",
            "--- Chunk 8346 ---\n",
            "ever, they only cover a subset of all functions available in TensorFlow, so in this book\n",
            "\n",
            "--- Chunk 8347 ---\n",
            "we will use the TensorFlow operations directly. Here is as simple example using\n",
            "keras.backend, which is commonly named K for short:\n",
            "\n",
            "--- Chunk 8348 ---\n",
            ">>> from tensorflow import keras\n",
            ">>> K = keras.backend\n",
            ">>> K.square(K.transpose(t)) + 10\n",
            "<tf.Tensor: id=39, shape=(3, 2), dtype=float32, numpy=\n",
            "\n",
            "--- Chunk 8349 ---\n",
            "array([[11., 26.],\n",
            "       [14., 35.],\n",
            "       [19., 46.]], dtype=float32)>\n",
            "\n",
            "--- Chunk 8350 ---\n",
            "Tensors and NumPy\n",
            "Tensors play nice with NumPy: you can create a tensor from a NumPy array, and vice\n",
            "\n",
            "--- Chunk 8351 ---\n",
            "versa. You can even apply TensorFlow operations to NumPy arrays and NumPy oper‐\n",
            "ations to tensors:\n",
            "\n",
            "--- Chunk 8352 ---\n",
            ">>> a = np.array([2., 4., 5.])\n",
            ">>> tf.constant(a)\n",
            "<tf.Tensor: id=111, shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>\n",
            "\n",
            "--- Chunk 8353 ---\n",
            ">>> t.numpy() # or np.array(t)\n",
            "array([[1., 2., 3.],\n",
            "       [4., 5., 6.]], dtype=float32)\n",
            ">>> tf.square(a)\n",
            "\n",
            "--- Chunk 8354 ---\n",
            ">>> tf.square(a)\n",
            "<tf.Tensor: id=116, shape=(3,), dtype=float64, numpy=array([4., 16., 25.])>\n",
            ">>> np.square(t)\n",
            "array([[ 1.,  4.,  9.],\n",
            "\n",
            "--- Chunk 8355 ---\n",
            "[16., 25., 36.]], dtype=float32)\n",
            "\n",
            "--- Chunk 8356 ---\n",
            "Notice that NumPy uses 64-bit precision by default, while Tensor‐\n",
            "Flow uses 32-bit. This is because 32-bit precision is generally more\n",
            "\n",
            "--- Chunk 8357 ---\n",
            "than enough for neural networks, plus it runs faster and uses less\n",
            "RAM. So when you create a tensor from a NumPy array, make sure\n",
            "\n",
            "--- Chunk 8358 ---\n",
            "to set dtype=tf.float32.\n",
            "\n",
            "--- Chunk 8359 ---\n",
            "Type Conversions\n",
            "Type conversions can significantly hurt performance, and they can easily go unno‐\n",
            "\n",
            "--- Chunk 8360 ---\n",
            "ticed when they are done automatically. To avoid this, TensorFlow does not perform\n",
            "\n",
            "--- Chunk 8361 ---\n",
            "Using TensorFlow like NumPy | 381\n",
            "\n",
            "--- Chunk 8362 ---\n",
            "any type conversions automatically: it just raises an exception if you try to execute an\n",
            "\n",
            "--- Chunk 8363 ---\n",
            "operation on tensors with incompatible types. For example, you cannot add a float\n",
            "\n",
            "--- Chunk 8364 ---\n",
            "tensor and an integer tensor, and you cannot even add a 32-bit float and a 64-bit float:\n",
            "\n",
            "--- Chunk 8365 ---\n",
            ">>> tf.constant(2.) + tf.constant(40)\n",
            "Traceback[...]InvalidArgumentError[...]expected to be a float[...]\n",
            "\n",
            "--- Chunk 8366 ---\n",
            ">>> tf.constant(2.) + tf.constant(40., dtype=tf.float64)\n",
            "Traceback[...]InvalidArgumentError[...]expected to be a double[...]\n",
            "\n",
            "--- Chunk 8367 ---\n",
            "This may be a bit annoying at first, but remember that it’s for a good cause! And of\n",
            "\n",
            "--- Chunk 8368 ---\n",
            "course you can use tf.cast() when you really need to convert types:\n",
            "\n",
            "--- Chunk 8369 ---\n",
            ">>> t2 = tf.constant(40., dtype=tf.float64)\n",
            ">>> tf.constant(2.0) + tf.cast(t2, tf.float32)\n",
            "<tf.Tensor: id=136, shape=(), dtype=float32, numpy=42.0>\n",
            "\n",
            "--- Chunk 8370 ---\n",
            "Variables\n",
            "The tf.Tensor values we’ve seen so far are immutable: you cannot modify them. This\n",
            "\n",
            "--- Chunk 8371 ---\n",
            "means that we cannot use regular tensors to implement weights in a neural network,\n",
            "\n",
            "--- Chunk 8372 ---\n",
            "since they need to be tweaked by backpropagation. Plus, other parameters may also\n",
            "\n",
            "--- Chunk 8373 ---\n",
            "need to change over time (e.g., a momentum optimizer keeps track of past gradients).\n",
            "What we need is a tf.Variable:\n",
            "\n",
            "--- Chunk 8374 ---\n",
            ">>> v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
            ">>> v\n",
            "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[1., 2., 3.],\n",
            "\n",
            "--- Chunk 8375 ---\n",
            "[4., 5., 6.]], dtype=float32)>\n",
            "\n",
            "--- Chunk 8376 ---\n",
            "A tf.Variable acts much like a tf.Tensor: you can perform the same operations\n",
            "\n",
            "--- Chunk 8377 ---\n",
            "with it, it plays nicely with NumPy as well, and it is just as picky with types. But it can\n",
            "\n",
            "--- Chunk 8378 ---\n",
            "also be modified in place using the assign() method (or assign_add() or\n",
            "\n",
            "--- Chunk 8379 ---\n",
            "assign_sub(), which increment or decrement the variable by the given value). You\n",
            "\n",
            "--- Chunk 8380 ---\n",
            "can also modify individual cells (or slices), by using the cell’s (or slice’s) assign()\n",
            "\n",
            "--- Chunk 8381 ---\n",
            "method (direct item assignment will not work) or by using the scatter_update() or\n",
            "scatter_nd_update() methods:\n",
            "\n",
            "--- Chunk 8382 ---\n",
            "v.assign(2 * v)           # => [[2., 4., 6.], [8., 10., 12.]]\n",
            "v[0, 1].assign(42)        # => [[2., 42., 6.], [8., 10., 12.]]\n",
            "\n",
            "--- Chunk 8383 ---\n",
            "v[:, 2].assign([0., 1.])  # => [[2., 42., 0.], [8., 10., 1.]]\n",
            "v.scatter_nd_update(indices=[[0, 0], [1, 2]], updates=[100., 200.])\n",
            "\n",
            "--- Chunk 8384 ---\n",
            "# => [[100., 42., 0.], [8., 10., 200.]]\n",
            "\n",
            "--- Chunk 8385 ---\n",
            "382 | Chapter 12: Custom Models and Training with TensorFlow\n",
            "\n",
            "--- Chunk 8386 ---\n",
            "In practice you will rarely have to create variables manually, since\n",
            "Keras provides an add_weight() method that will take care of it for\n",
            "\n",
            "--- Chunk 8387 ---\n",
            "you, as we will see. Moreover, model parameters will generally be\n",
            "updated directly by the optimizers, so you will rarely need to\n",
            "\n",
            "--- Chunk 8388 ---\n",
            "update variables manually.\n",
            "\n",
            "--- Chunk 8389 ---\n",
            "Other Data Structures\n",
            "TensorFlow supports several other data structures, including the following (please see\n",
            "\n",
            "--- Chunk 8390 ---\n",
            "the “Tensors and Operations” section in the notebook or Appendix F for more\n",
            "details):\n",
            "Sparse tensors (tf.SparseTensor)\n",
            "\n",
            "--- Chunk 8391 ---\n",
            "Efficiently represent tensors containing mostly zeros. The tf.sparse package\n",
            "contains operations for sparse tensors.\n",
            "\n",
            "--- Chunk 8392 ---\n",
            "Tensor arrays (tf.TensorArray)\n",
            "Are lists of tensors. They have a fixed size by default but can optionally be made\n",
            "\n",
            "--- Chunk 8393 ---\n",
            "dynamic. All tensors they contain must have the same shape and data type.\n",
            "\n",
            "--- Chunk 8394 ---\n",
            "Ragged tensors (tf.RaggedTensor)\n",
            "Represent static lists of lists of tensors, where every tensor has the same shape\n",
            "\n",
            "--- Chunk 8395 ---\n",
            "and data type. The tf.ragged package contains operations for ragged tensors.\n",
            "\n",
            "--- Chunk 8396 ---\n",
            "String tensors\n",
            "Are regular tensors of type tf.string. These represent byte strings, not Unicode\n",
            "\n",
            "--- Chunk 8397 ---\n",
            "strings, so if you create a string tensor using a Unicode string (e.g., a regular\n",
            "\n",
            "--- Chunk 8398 ---\n",
            "Python 3 string like \"café\"), then it will get encoded to UTF-8 automatically\n",
            "\n",
            "--- Chunk 8399 ---\n",
            "(e.g., b\"caf\\xc3\\xa9\"). Alternatively, you can represent Unicode strings using\n",
            "\n",
            "--- Chunk 8400 ---\n",
            "tensors of type tf.int32, where each item represents a Unicode code point (e.g.,\n",
            "\n",
            "--- Chunk 8401 ---\n",
            "[99, 97, 102, 233]). The tf.strings package (with an s) contains ops for byte\n",
            "\n",
            "--- Chunk 8402 ---\n",
            "strings and Unicode strings (and to convert one into the other). It’s important to\n",
            "\n",
            "--- Chunk 8403 ---\n",
            "note that a tf.string is atomic, meaning that its length does not appear in the\n",
            "\n",
            "--- Chunk 8404 ---\n",
            "tensor’s shape. Once you convert it to a Unicode tensor (i.e., a tensor of type\n",
            "\n",
            "--- Chunk 8405 ---\n",
            "tf.int32 holding Unicode code points), the length appears in the shape.\n",
            "\n",
            "--- Chunk 8406 ---\n",
            "Sets\n",
            "Are represented as regular tensors (or sparse tensors). For example, tf.con\n",
            "\n",
            "--- Chunk 8407 ---\n",
            "stant([[1, 2], [3, 4]]) represents the two sets {1, 2} and {3, 4}. More gener‐\n",
            "\n",
            "--- Chunk 8408 ---\n",
            "ally, each set is represented by a vector in the tensor’s last axis. You can\n",
            "manipulate sets using operations from the tf.sets package.\n",
            "\n",
            "--- Chunk 8409 ---\n",
            "Queues\n",
            "Store tensors across multiple steps. TensorFlow offers various kinds of queues:\n",
            "\n",
            "--- Chunk 8410 ---\n",
            "simple First In, First Out (FIFO) queues (FIFOQueue), queues that can prioritize\n",
            "\n",
            "--- Chunk 8411 ---\n",
            "Using TensorFlow like NumPy | 383\n",
            "\n",
            "--- Chunk 8412 ---\n",
            "some items (PriorityQueue), shuffle their items (RandomShuffleQueue), and\n",
            "\n",
            "--- Chunk 8413 ---\n",
            "batch items of different shapes by padding (PaddingFIFOQueue). These classes are\n",
            "all in the tf.queue package.\n",
            "\n",
            "--- Chunk 8414 ---\n",
            "With tensors, operations, variables, and various data structures at your disposal, you\n",
            "\n",
            "--- Chunk 8415 ---\n",
            "are now ready to customize your models and training algorithms!\n",
            "\n",
            "--- Chunk 8416 ---\n",
            "Customizing Models and Training Algorithms\n",
            "Let’s start by creating a custom loss function, which is a simple and common use case.\n",
            "\n",
            "--- Chunk 8417 ---\n",
            "Custom Loss Functions\n",
            "Suppose you want to train a regression model, but your training set is a bit noisy. Of\n",
            "\n",
            "--- Chunk 8418 ---\n",
            "course, you start by trying to clean up your dataset by removing or fixing the outliers,\n",
            "\n",
            "--- Chunk 8419 ---\n",
            "but that turns out to be insufficient; the dataset is still noisy. Which loss function\n",
            "\n",
            "--- Chunk 8420 ---\n",
            "should you use? The mean squared error might penalize large errors too much and\n",
            "\n",
            "--- Chunk 8421 ---\n",
            "cause your model to be imprecise. The mean absolute error would not penalize outli‐\n",
            "\n",
            "--- Chunk 8422 ---\n",
            "ers as much, but training might take a while to converge, and the trained model\n",
            "\n",
            "--- Chunk 8423 ---\n",
            "might not be very precise. This is probably a good time to use the Huber loss (intro‐\n",
            "\n",
            "--- Chunk 8424 ---\n",
            "duced in Chapter 10) instead of the good old MSE. The Huber loss is not currently\n",
            "\n",
            "--- Chunk 8425 ---\n",
            "part of the official Keras API, but it is available in tf.keras (just use an instance of the\n",
            "\n",
            "--- Chunk 8426 ---\n",
            "keras.losses.Huber class). But let’s pretend it’s not there: implementing it is easy as\n",
            "\n",
            "--- Chunk 8427 ---\n",
            "pie! Just create a function that takes the labels and predictions as arguments, and use\n",
            "TensorFlow operations to compute every instance’s loss:\n",
            "\n",
            "--- Chunk 8428 ---\n",
            "def huber_fn(y_true, y_pred):\n",
            "    error = y_true - y_pred\n",
            "    is_small_error = tf.abs(error) < 1\n",
            "    squared_loss = tf.square(error) / 2\n",
            "\n",
            "--- Chunk 8429 ---\n",
            "linear_loss  = tf.abs(error) - 0.5\n",
            "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
            "\n",
            "--- Chunk 8430 ---\n",
            "For better performance, you should use a vectorized implementa‐\n",
            "tion, as in this example. Moreover, if you want to benefit from Ten‐\n",
            "\n",
            "--- Chunk 8431 ---\n",
            "sorFlow’s graph features, you should use only TensorFlow\n",
            "operations.\n",
            "\n",
            "--- Chunk 8432 ---\n",
            "It is also preferable to return a tensor containing one loss per instance, rather than\n",
            "\n",
            "--- Chunk 8433 ---\n",
            "returning the mean loss. This way, Keras can apply class weights or sample weights\n",
            "when requested (see Chapter 10).\n",
            "\n",
            "--- Chunk 8434 ---\n",
            "384 | Chapter 12: Custom Models and Training with TensorFlow\n",
            "\n",
            "--- Chunk 8435 ---\n",
            "Now you can use this loss when you compile the Keras model, then train your model:\n",
            "model.compile(loss=huber_fn, optimizer=\"nadam\")\n",
            "\n",
            "--- Chunk 8436 ---\n",
            "model.fit(X_train, y_train, [...])\n",
            "\n",
            "--- Chunk 8437 ---\n",
            "And that’s it! For each batch during training, Keras will call the huber_fn() function\n",
            "\n",
            "--- Chunk 8438 ---\n",
            "to compute the loss and use it to perform a Gradient Descent step. Moreover, it will\n",
            "\n",
            "--- Chunk 8439 ---\n",
            "keep track of the total loss since the beginning of the epoch, and it will display the\n",
            "mean loss.\n",
            "\n",
            "--- Chunk 8440 ---\n",
            "mean loss.\n",
            "But what happens to this custom loss when you save the model?\n",
            "\n",
            "--- Chunk 8441 ---\n",
            "Saving and Loading Models That Contain Custom Components\n",
            "Saving a model containing a custom loss function works fine, as Keras saves the name\n",
            "\n",
            "--- Chunk 8442 ---\n",
            "of the function. Whenever you load it, you’ll need to provide a dictionary that maps\n",
            "\n",
            "--- Chunk 8443 ---\n",
            "the function name to the actual function. More generally, when you load a model\n",
            "containing custom objects, you need to map the names to the objects:\n",
            "\n",
            "--- Chunk 8444 ---\n",
            "model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n",
            "                                custom_objects={\"huber_fn\": huber_fn})\n",
            "\n",
            "--- Chunk 8445 ---\n",
            "With the current implementation, any error between –1 and 1 is considered “small.”\n",
            "\n",
            "--- Chunk 8446 ---\n",
            "But what if you want a different threshold? One solution is to create a function that\n",
            "creates a configured loss function:\n",
            "\n",
            "--- Chunk 8447 ---\n",
            "def create_huber(threshold=1.0):\n",
            "    def huber_fn(y_true, y_pred):\n",
            "        error = y_true - y_pred\n",
            "\n",
            "--- Chunk 8448 ---\n",
            "is_small_error = tf.abs(error) < threshold\n",
            "        squared_loss = tf.square(error) / 2\n",
            "\n",
            "--- Chunk 8449 ---\n",
            "linear_loss  = threshold * tf.abs(error) - threshold**2 / 2\n",
            "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
            "\n",
            "--- Chunk 8450 ---\n",
            "return huber_fn\n",
            "\n",
            "--- Chunk 8451 ---\n",
            "model.compile(loss=create_huber(2.0), optimizer=\"nadam\")\n",
            "\n",
            "--- Chunk 8452 ---\n",
            "Unfortunately, when you save the model, the threshold will not be saved. This means\n",
            "\n",
            "--- Chunk 8453 ---\n",
            "that you will have to specify the threshold value when loading the model (note that\n",
            "\n",
            "--- Chunk 8454 ---\n",
            "the name to use is \"huber_fn\", which is the name of the function you gave Keras, not\n",
            "the name of the function that created it):\n",
            "\n",
            "--- Chunk 8455 ---\n",
            "model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.h5\",\n",
            "\n",
            "--- Chunk 8456 ---\n",
            "custom_objects={\"huber_fn\": create_huber(2.0)})\n",
            "\n",
            "--- Chunk 8457 ---\n",
            "You can solve this by creating a subclass of the keras.losses.Loss class, and then\n",
            "implementing its get_config() method:\n",
            "\n",
            "--- Chunk 8458 ---\n",
            "Customizing Models and Training Algorithms | 385\n",
            "\n",
            "--- Chunk 8459 ---\n",
            "class HuberLoss(keras.losses.Loss):\n",
            "    def __init__(self, threshold=1.0, **kwargs):\n",
            "        self.threshold = threshold\n",
            "\n",
            "--- Chunk 8460 ---\n",
            "super().__init__(**kwargs)\n",
            "    def call(self, y_true, y_pred):\n",
            "        error = y_true - y_pred\n",
            "\n",
            "--- Chunk 8461 ---\n",
            "is_small_error = tf.abs(error) < self.threshold\n",
            "        squared_loss = tf.square(error) / 2\n",
            "\n",
            "--- Chunk 8462 ---\n",
            "linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
            "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
            "\n",
            "--- Chunk 8463 ---\n",
            "def get_config(self):\n",
            "        base_config = super().get_config()\n",
            "        return {**base_config, \"threshold\": self.threshold}\n",
            "\n",
            "--- Chunk 8464 ---\n",
            "The Keras API currently only specifies how to use subclassing to\n",
            "define layers, models, callbacks, and regularizers. If you build other\n",
            "\n",
            "--- Chunk 8465 ---\n",
            "components (such as losses, metrics, initializers, or constraints)\n",
            "using subclassing, they may not be portable to other Keras imple‐\n",
            "\n",
            "--- Chunk 8466 ---\n",
            "mentations. It’s likely that the Keras API will be updated to specify\n",
            "subclassing for all these components as well.\n",
            "\n",
            "--- Chunk 8467 ---\n",
            "Let’s walk through this code:\n",
            "\n",
            "--- Chunk 8468 ---\n",
            "• The constructor accepts **kwargs and passes them to the parent constructor,\n",
            "\n",
            "--- Chunk 8469 ---\n",
            "which handles standard hyperparameters: the name of the loss and the reduction\n",
            "\n",
            "--- Chunk 8470 ---\n",
            "algorithm to use to aggregate the individual instance losses. By default, it is\n",
            "\n",
            "--- Chunk 8471 ---\n",
            "\"sum_over_batch_size\", which means that the loss will be the sum of the\n",
            "\n",
            "--- Chunk 8472 ---\n",
            "instance losses, weighted by the sample weights, if any, and divided by the batch\n",
            "\n",
            "--- Chunk 8473 ---\n",
            "size (not by the sum of weights, so this is not the weighted mean).5 Other possible\n",
            "values are \"sum\" and \"none\".\n",
            "\n",
            "--- Chunk 8474 ---\n",
            "• The call() method takes the labels and predictions, computes all the instance\n",
            "losses, and returns them.\n",
            "\n",
            "--- Chunk 8475 ---\n",
            "• The get_config() method returns a dictionary mapping each hyperparameter\n",
            "\n",
            "--- Chunk 8476 ---\n",
            "name to its value. It first calls the parent class’s get_config() method, then adds\n",
            "\n",
            "--- Chunk 8477 ---\n",
            "the new hyperparameters to this dictionary (note that the convenient {**x} syn‐\n",
            "tax was added in Python 3.5).\n",
            "\n",
            "--- Chunk 8478 ---\n",
            "You can then use any instance of this class when you compile the model:\n",
            "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\")\n",
            "\n",
            "--- Chunk 8479 ---\n",
            "5 It would not be a good idea to use a weighted mean: if you did, then two instances with the same weight but in\n",
            "\n",
            "--- Chunk 8480 ---\n",
            "different batches would have a different impact on training, depending on the total weight of each batch.\n",
            "\n",
            "--- Chunk 8481 ---\n",
            "386 | Chapter 12: Custom Models and Training with TensorFlow\n",
            "\n",
            "--- Chunk 8482 ---\n",
            "When you save the model, the threshold will be saved along with it; and when you\n",
            "\n",
            "--- Chunk 8483 ---\n",
            "load the model, you just need to map the class name to the class itself:\n",
            "\n",
            "--- Chunk 8484 ---\n",
            "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",\n",
            "                                custom_objects={\"HuberLoss\": HuberLoss})\n",
            "\n",
            "--- Chunk 8485 ---\n",
            "When you save a model, Keras calls the loss instance’s get_config() method and\n",
            "\n",
            "--- Chunk 8486 ---\n",
            "saves the config as JSON in the HDF5 file. When you load the model, it calls the\n",
            "\n",
            "--- Chunk 8487 ---\n",
            "from_config() class method on the HuberLoss class: this method is implemented by\n",
            "\n",
            "--- Chunk 8488 ---\n",
            "the base class (Loss) and creates an instance of the class, passing **config to the\n",
            "constructor.\n",
            "\n",
            "--- Chunk 8489 ---\n",
            "constructor.\n",
            "That’s it for losses! That wasn’t too hard, was it? Just as simple are custom activation\n",
            "\n",
            "--- Chunk 8490 ---\n",
            "functions, initializers, regularizers, and constraints. Let’s look at these now.\n",
            "\n",
            "--- Chunk 8491 ---\n",
            "Custom Activation Functions, Initializers, Regularizers, and\n",
            "Constraints\n",
            "\n",
            "--- Chunk 8492 ---\n",
            "Constraints\n",
            "Most Keras functionalities, such as losses, regularizers, constraints, initializers, met‐\n",
            "\n",
            "--- Chunk 8493 ---\n",
            "rics, activation functions, layers, and even full models, can be customized in very\n",
            "\n",
            "--- Chunk 8494 ---\n",
            "much the same way. Most of the time, you will just need to write a simple function\n",
            "\n",
            "--- Chunk 8495 ---\n",
            "with the appropriate inputs and outputs. Here are examples of a custom activation\n",
            "\n",
            "--- Chunk 8496 ---\n",
            "function (equivalent to keras.activations.softplus() or tf.nn.softplus()), a\n",
            "\n",
            "--- Chunk 8497 ---\n",
            "custom Glorot initializer (equivalent to keras.initializers.glorot_normal()), a\n",
            "\n",
            "--- Chunk 8498 ---\n",
            "custom ℓ1 regularizer (equivalent to keras.regularizers.l1(0.01)), and a custom\n",
            "\n",
            "--- Chunk 8499 ---\n",
            "constraint that ensures weights are all positive (equivalent to keras.con\n",
            "straints.nonneg() or tf.nn.relu()):\n",
            "\n",
            "--- Chunk 8500 ---\n",
            "def my_softplus(z): # return value is just tf.nn.softplus(z)\n",
            "    return tf.math.log(tf.exp(z) + 1.0)\n",
            "\n",
            "--- Chunk 8501 ---\n",
            "def my_glorot_initializer(shape, dtype=tf.float32):\n",
            "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
            "\n",
            "--- Chunk 8502 ---\n",
            "return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
            "\n",
            "--- Chunk 8503 ---\n",
            "def my_l1_regularizer(weights):\n",
            "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
            "\n",
            "--- Chunk 8504 ---\n",
            "def my_positive_weights(weights): # return value is just tf.nn.relu(weights)\n",
            "    return tf.where(weights < 0., tf.zeros_like(weights), weights)\n",
            "\n",
            "--- Chunk 8505 ---\n",
            "As you can see, the arguments depend on the type of custom function. These custom\n",
            "functions can then be used normally; for example:\n",
            "\n",
            "--- Chunk 8506 ---\n",
            "layer = keras.layers.Dense(30, activation=my_softplus,\n",
            "                           kernel_initializer=my_glorot_initializer,\n",
            "\n",
            "--- Chunk 8507 ---\n",
            "kernel_regularizer=my_l1_regularizer,\n",
            "                           kernel_constraint=my_positive_weights)\n",
            "\n",
            "--- Chunk 8508 ---\n",
            "Customizing Models and Training Algorithms | 387\n",
            "\n",
            "--- Chunk 8509 ---\n",
            "The activation function will be applied to the output of this Dense layer, and its result\n",
            "\n",
            "--- Chunk 8510 ---\n",
            "will be passed on to the next layer. The layer’s weights will be initialized using the\n",
            "\n",
            "--- Chunk 8511 ---\n",
            "value returned by the initializer. At each training step the weights will be passed to the\n",
            "\n",
            "--- Chunk 8512 ---\n",
            "regularization function to compute the regularization loss, which will be added to the\n",
            "\n",
            "--- Chunk 8513 ---\n",
            "main loss to get the final loss used for training. Finally, the constraint function will be\n",
            "\n",
            "--- Chunk 8514 ---\n",
            "called after each training step, and the layer’s weights will be replaced by the con‐\n",
            "strained weights.\n",
            "\n",
            "--- Chunk 8515 ---\n",
            "strained weights.\n",
            "If a function has hyperparameters that need to be saved along with the model, then\n",
            "\n",
            "--- Chunk 8516 ---\n",
            "you will want to subclass the appropriate class, such as keras.regularizers.Regular\n",
            "\n",
            "--- Chunk 8517 ---\n",
            "izer, keras.constraints.Constraint, keras.initializers.Initializer, or\n",
            "\n",
            "--- Chunk 8518 ---\n",
            "keras.layers.Layer (for any layer, including activation functions). Much like we did\n",
            "\n",
            "--- Chunk 8519 ---\n",
            "for the custom loss, here is a simple class for ℓ1 regularization that saves its factor\n",
            "\n",
            "--- Chunk 8520 ---\n",
            "hyperparameter (this time we do not need to call the parent constructor or the\n",
            "get_config() method, as they are not defined by the parent class):\n",
            "\n",
            "--- Chunk 8521 ---\n",
            "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
            "    def __init__(self, factor):\n",
            "        self.factor = factor\n",
            "    def __call__(self, weights):\n",
            "\n",
            "--- Chunk 8522 ---\n",
            "return tf.reduce_sum(tf.abs(self.factor * weights))\n",
            "    def get_config(self):\n",
            "        return {\"factor\": self.factor}\n",
            "\n",
            "--- Chunk 8523 ---\n",
            "Note that you must implement the call() method for losses, layers (including activa‐\n",
            "\n",
            "--- Chunk 8524 ---\n",
            "tion functions), and models, or the __call__() method for regularizers, initializers,\n",
            "\n",
            "--- Chunk 8525 ---\n",
            "and constraints. For metrics, things are a bit different, as we will see now.\n",
            "\n",
            "--- Chunk 8526 ---\n",
            "Custom Metrics\n",
            "Losses and metrics are conceptually not the same thing: losses (e.g., cross entropy)\n",
            "\n",
            "--- Chunk 8527 ---\n",
            "are used by Gradient Descent to train a model, so they must be differentiable (at least\n",
            "\n",
            "--- Chunk 8528 ---\n",
            "where they are evaluated), and their gradients should not be 0 everywhere. Plus, it’s\n",
            "\n",
            "--- Chunk 8529 ---\n",
            "OK if they are not easily interpretable by humans. In contrast, metrics (e.g., accuracy)\n",
            "\n",
            "--- Chunk 8530 ---\n",
            "are used to evaluate a model: they must be more easily interpretable, and they can be\n",
            "non-differentiable or have 0 gradients everywhere.\n",
            "\n",
            "--- Chunk 8531 ---\n",
            "That said, in most cases, defining a custom metric function is exactly the same as\n",
            "\n",
            "--- Chunk 8532 ---\n",
            "defining a custom loss function. In fact, we could even use the Huber loss function we\n",
            "\n",
            "--- Chunk 8533 ---\n",
            "created earlier as a metric;6 it would work just fine (and persistence would also work\n",
            "\n",
            "--- Chunk 8534 ---\n",
            "the same way, in this case only saving the name of the function, \"huber_fn\"):\n",
            "\n",
            "--- Chunk 8535 ---\n",
            "6 However, the Huber loss is seldom used as a metric (the MAE or MSE is preferred).\n",
            "\n",
            "388 | Chapter 12: Custom Models and Training with TensorFlow\n",
            "\n",
            "--- Chunk 8536 ---\n",
            "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])\n",
            "\n",
            "--- Chunk 8537 ---\n",
            "For each batch during training, Keras will compute this metric and keep track of its\n",
            "\n",
            "--- Chunk 8538 ---\n",
            "mean since the beginning of the epoch. Most of the time, this is exactly what you\n",
            "\n",
            "--- Chunk 8539 ---\n",
            "want. But not always! Consider a binary classifier’s precision, for example. As we saw\n",
            "\n",
            "--- Chunk 8540 ---\n",
            "in Chapter 3, precision is the number of true positives divided by the number of posi‐\n",
            "\n",
            "--- Chunk 8541 ---\n",
            "tive predictions (including both true positives and false positives). Suppose the model\n",
            "\n",
            "--- Chunk 8542 ---\n",
            "made five positive predictions in the first batch, four of which were correct: that’s 80%\n",
            "\n",
            "--- Chunk 8543 ---\n",
            "precision. Then suppose the model made three positive predictions in the second\n",
            "\n",
            "--- Chunk 8544 ---\n",
            "batch, but they were all incorrect: that’s 0% precision for the second batch. If you just\n",
            "\n",
            "--- Chunk 8545 ---\n",
            "compute the mean of these two precisions, you get 40%. But wait a second—that’s not\n",
            "\n",
            "--- Chunk 8546 ---\n",
            "the model’s precision over these two batches! Indeed, there were a total of four true\n",
            "\n",
            "--- Chunk 8547 ---\n",
            "positives (4 + 0) out of eight positive predictions (5 + 3), so the overall precision is\n",
            "\n",
            "--- Chunk 8548 ---\n",
            "50%, not 40%. What we need is an object that can keep track of the number of true\n",
            "\n",
            "--- Chunk 8549 ---\n",
            "positives and the number of false positives and that can compute their ratio when\n",
            "\n",
            "--- Chunk 8550 ---\n",
            "requested. This is precisely what the keras.metrics.Precision class does:\n",
            "\n",
            "--- Chunk 8551 ---\n",
            ">>> precision = keras.metrics.Precision()\n",
            ">>> precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])\n",
            "\n",
            "--- Chunk 8552 ---\n",
            "<tf.Tensor: id=581729, shape=(), dtype=float32, numpy=0.8>\n",
            ">>> precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])\n",
            "\n",
            "--- Chunk 8553 ---\n",
            "<tf.Tensor: id=581780, shape=(), dtype=float32, numpy=0.5>\n",
            "\n",
            "--- Chunk 8554 ---\n",
            "In this example, we created a Precision object, then we used it like a function, pass‐\n",
            "\n",
            "--- Chunk 8555 ---\n",
            "ing it the labels and predictions for the first batch, then for the second batch (note\n",
            "\n",
            "--- Chunk 8556 ---\n",
            "that we could also have passed sample weights). We used the same number of true\n",
            "\n",
            "--- Chunk 8557 ---\n",
            "and false positives as in the example we just discussed. After the first batch, it returns\n",
            "\n",
            "--- Chunk 8558 ---\n",
            "a precision of 80%; then after the second batch, it returns 50% (which is the overall\n",
            "\n",
            "--- Chunk 8559 ---\n",
            "precision so far, not the second batch’s precision). This is called a streaming metric (or\n",
            "\n",
            "--- Chunk 8560 ---\n",
            "stateful metric), as it is gradually updated, batch after batch.\n",
            "\n",
            "--- Chunk 8561 ---\n",
            "At any point, we can call the result() method to get the current value of the metric.\n",
            "\n",
            "--- Chunk 8562 ---\n",
            "We can also look at its variables (tracking the number of true and false positives) by\n",
            "\n",
            "--- Chunk 8563 ---\n",
            "using the variables attribute, and we can reset these variables using the\n",
            "reset_states() method:\n",
            "\n",
            "--- Chunk 8564 ---\n",
            ">>> precision.result()\n",
            "<tf.Tensor: id=581794, shape=(), dtype=float32, numpy=0.5>\n",
            ">>> precision.variables\n",
            "\n",
            "--- Chunk 8565 ---\n",
            "[<tf.Variable 'true_positives:0' [...] numpy=array([4.], dtype=float32)>,\n",
            " <tf.Variable 'false_positives:0' [...] numpy=array([4.], dtype=float32)>]\n",
            "\n",
            "--- Chunk 8566 ---\n",
            ">>> precision.reset_states() # both variables get reset to 0.0\n",
            "\n",
            "--- Chunk 8567 ---\n",
            "If you need to create such a streaming metric, create a subclass of the keras.met\n",
            "\n",
            "--- Chunk 8568 ---\n",
            "rics.Metric class. Here is a simple example that keeps track of the total Huber loss\n",
            "\n",
            "--- Chunk 8569 ---\n",
            "Customizing Models and Training Algorithms | 389\n",
            "\n",
            "--- Chunk 8570 ---\n",
            "and the number of instances seen so far. When asked for the result, it returns the\n",
            "ratio, which is simply the mean Huber loss:\n",
            "\n",
            "--- Chunk 8571 ---\n",
            "class HuberMetric(keras.metrics.Metric):\n",
            "    def __init__(self, threshold=1.0, **kwargs):\n",
            "\n",
            "--- Chunk 8572 ---\n",
            "super().__init__(**kwargs) # handles base args (e.g., dtype)\n",
            "        self.threshold = threshold\n",
            "\n",
            "--- Chunk 8573 ---\n",
            "self.huber_fn = create_huber(threshold)\n",
            "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
            "\n",
            "--- Chunk 8574 ---\n",
            "self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
            "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
            "\n",
            "--- Chunk 8575 ---\n",
            "metric = self.huber_fn(y_true, y_pred)\n",
            "        self.total.assign_add(tf.reduce_sum(metric))\n",
            "\n",
            "--- Chunk 8576 ---\n",
            "self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
            "    def result(self):\n",
            "        return self.total / self.count\n",
            "\n",
            "--- Chunk 8577 ---\n",
            "def get_config(self):\n",
            "        base_config = super().get_config()\n",
            "        return {**base_config, \"threshold\": self.threshold}\n",
            "\n",
            "--- Chunk 8578 ---\n",
            "Let’s walk through this code:7\n",
            "\n",
            "--- Chunk 8579 ---\n",
            "• The constructor uses the add_weight() method to create the variables needed to\n",
            "\n",
            "--- Chunk 8580 ---\n",
            "keep track of the metric’s state over multiple batches—in this case, the sum of all\n",
            "\n",
            "--- Chunk 8581 ---\n",
            "Huber losses (total) and the number of instances seen so far (count). You could\n",
            "\n",
            "--- Chunk 8582 ---\n",
            "just create variables manually if you preferred. Keras tracks any tf.Variable that\n",
            "\n",
            "--- Chunk 8583 ---\n",
            "is set as an attribute (and more generally, any “trackable” object, such as layers or\n",
            "models).\n",
            "\n",
            "--- Chunk 8584 ---\n",
            "• The update_state() method is called when you use an instance of this class as a\n",
            "\n",
            "--- Chunk 8585 ---\n",
            "function (as we did with the Precision object). It updates the variables, given the\n",
            "\n",
            "--- Chunk 8586 ---\n",
            "labels and predictions for one batch (and sample weights, but in this case we\n",
            "ignore them).\n",
            "\n",
            "--- Chunk 8587 ---\n",
            "• The result() method computes and returns the final result, in this case the\n",
            "\n",
            "--- Chunk 8588 ---\n",
            "mean Huber metric over all instances. When you use the metric as a function, the\n",
            "\n",
            "--- Chunk 8589 ---\n",
            "update_state() method gets called first, then the result() method is called,\n",
            "and its output is returned.\n",
            "\n",
            "--- Chunk 8590 ---\n",
            "• We also implement the get_config() method to ensure the threshold gets\n",
            "saved along with the model.\n",
            "\n",
            "--- Chunk 8591 ---\n",
            "• The default implementation of the reset_states() method resets all variables to\n",
            "0.0 (but you can override it if needed).\n",
            "\n",
            "--- Chunk 8592 ---\n",
            "7 This class is for illustration purposes only. A simpler and better implementation would just subclass the\n",
            "\n",
            "--- Chunk 8593 ---\n",
            "keras.metrics.Mean class; see the “Streaming metrics” section of the notebook for an example.\n",
            "\n",
            "--- Chunk 8594 ---\n",
            "390 | Chapter 12: Custom Models and Training with TensorFlow\n",
            "\n",
            "\n",
            "\n",
            "Keras will take care of variable persistence seamlessly; no action is\n",
            "required.\n",
            "\n",
            "--- Chunk 8595 ---\n",
            "When you define a metric using a simple function, Keras automatically calls it for\n",
            "\n",
            "--- Chunk 8596 ---\n",
            "each batch, and it keeps track of the mean during each epoch, just like we did man‐\n",
            "\n",
            "--- Chunk 8597 ---\n",
            "ually. So the only benefit of our HuberMetric class is that the threshold will be saved.\n",
            "\n",
            "--- Chunk 8598 ---\n",
            "But of course, some metrics, like precision, cannot simply be averaged over batches:\n",
            "\n",
            "--- Chunk 8599 ---\n",
            "in those cases, there’s no other option than to implement a streaming metric.\n",
            "\n",
            "--- Chunk 8600 ---\n",
            "Now that we have built a streaming metric, building a custom layer will seem like a\n",
            "walk in the park!\n",
            "\n",
            "--- Chunk 8601 ---\n",
            "Custom Layers\n",
            "You may occasionally want to build an architecture that contains an exotic layer for\n",
            "\n",
            "--- Chunk 8602 ---\n",
            "which TensorFlow does not provide a default implementation. In this case, you will\n",
            "\n",
            "--- Chunk 8603 ---\n",
            "need to create a custom layer. Or you may simply want to build a very repetitive\n",
            "\n",
            "--- Chunk 8604 ---\n",
            "architecture, containing identical blocks of layers repeated many times, and it would\n",
            "\n",
            "--- Chunk 8605 ---\n",
            "be convenient to treat each block of layers as a single layer. For example, if the model\n",
            "\n",
            "--- Chunk 8606 ---\n",
            "is a sequence of layers A, B, C, A, B, C, A, B, C, then you might want to define a cus‐\n",
            "\n",
            "--- Chunk 8607 ---\n",
            "tom layer D containing layers A, B, C, so your model would then simply be D, D, D.\n",
            "Let’s see how to build custom layers.\n",
            "\n",
            "--- Chunk 8608 ---\n",
            "First, some layers have no weights, such as keras.layers.Flatten or keras.lay\n",
            "\n",
            "--- Chunk 8609 ---\n",
            "ers.ReLU. If you want to create a custom layer without any weights, the simplest\n",
            "\n",
            "--- Chunk 8610 ---\n",
            "option is to write a function and wrap it in a keras.layers.Lambda layer. For exam‐\n",
            "\n",
            "--- Chunk 8611 ---\n",
            "ple, the following layer will apply the exponential function to its inputs:\n",
            "\n",
            "--- Chunk 8612 ---\n",
            "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))\n",
            "\n",
            "--- Chunk 8613 ---\n",
            "This custom layer can then be used like any other layer, using the Sequential API, the\n",
            "\n",
            "--- Chunk 8614 ---\n",
            "Functional API, or the Subclassing API. You can also use it as an activation function\n",
            "\n",
            "--- Chunk 8615 ---\n",
            "(or you could use activation=tf.exp, activation=keras.activations.exponen\n",
            "\n",
            "--- Chunk 8616 ---\n",
            "tial, or simply activation=\"exponential\"). The exponential layer is sometimes\n",
            "\n",
            "--- Chunk 8617 ---\n",
            "used in the output layer of a regression model when the values to predict have very\n",
            "different scales (e.g., 0.001, 10., 1,000.).\n",
            "\n",
            "--- Chunk 8618 ---\n",
            "As you’ve probably guessed by now, to build a custom stateful layer (i.e., a layer with\n",
            "\n",
            "--- Chunk 8619 ---\n",
            "weights), you need to create a subclass of the keras.layers.Layer class. For exam‐\n",
            "\n",
            "--- Chunk 8620 ---\n",
            "ple, the following class implements a simplified version of the Dense layer:\n",
            "\n",
            "--- Chunk 8621 ---\n",
            "Customizing Models and Training Algorithms | 391\n",
            "\n",
            "--- Chunk 8622 ---\n",
            "class MyDense(keras.layers.Layer):\n",
            "    def __init__(self, units, activation=None, **kwargs):\n",
            "        super().__init__(**kwargs)\n",
            "\n",
            "--- Chunk 8623 ---\n",
            "self.units = units\n",
            "        self.activation = keras.activations.get(activation)\n",
            "\n",
            "--- Chunk 8624 ---\n",
            "def build(self, batch_input_shape):\n",
            "        self.kernel = self.add_weight(\n",
            "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
            "\n",
            "--- Chunk 8625 ---\n",
            "initializer=\"glorot_normal\")\n",
            "        self.bias = self.add_weight(\n",
            "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
            "\n",
            "--- Chunk 8626 ---\n",
            "super().build(batch_input_shape) # must be at the end\n",
            "\n",
            "--- Chunk 8627 ---\n",
            "def call(self, X):\n",
            "        return self.activation(X @ self.kernel + self.bias)\n",
            "\n",
            "--- Chunk 8628 ---\n",
            "def compute_output_shape(self, batch_input_shape):\n",
            "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
            "\n",
            "--- Chunk 8629 ---\n",
            "def get_config(self):\n",
            "        base_config = super().get_config()\n",
            "        return {**base_config, \"units\": self.units,\n",
            "\n",
            "--- Chunk 8630 ---\n",
            "\"activation\": keras.activations.serialize(self.activation)}\n",
            "\n",
            "--- Chunk 8631 ---\n",
            "Let’s walk through this code:\n",
            "\n",
            "--- Chunk 8632 ---\n",
            "• The constructor takes all the hyperparameters as arguments (in this example,\n",
            "\n",
            "--- Chunk 8633 ---\n",
            "units and activation), and importantly it also takes a **kwargs argument. It\n",
            "\n",
            "--- Chunk 8634 ---\n",
            "calls the parent constructor, passing it the kwargs: this takes care of standard\n",
            "\n",
            "--- Chunk 8635 ---\n",
            "arguments such as input_shape, trainable, and name. Then it saves the hyper‐\n",
            "\n",
            "--- Chunk 8636 ---\n",
            "parameters as attributes, converting the activation argument to the appropriate\n",
            "\n",
            "--- Chunk 8637 ---\n",
            "activation function using the keras.activations.get() function (it accepts\n",
            "functions, standard strings like \"relu\" or \"selu\", or simply None).8\n",
            "\n",
            "--- Chunk 8638 ---\n",
            "• The build() method’s role is to create the layer’s variables by calling the\n",
            "\n",
            "--- Chunk 8639 ---\n",
            "add_weight() method for each weight. The build() method is called the first\n",
            "\n",
            "--- Chunk 8640 ---\n",
            "time the layer is used. At that point, Keras will know the shape of this layer’s\n",
            "\n",
            "--- Chunk 8641 ---\n",
            "inputs, and it will pass it to the build() method,9 which is often necessary to cre‐\n",
            "\n",
            "--- Chunk 8642 ---\n",
            "ate some of the weights. For example, we need to know the number of neurons in\n",
            "\n",
            "--- Chunk 8643 ---\n",
            "the previous layer in order to create the connection weights matrix (i.e., the\n",
            "\n",
            "--- Chunk 8644 ---\n",
            "\"kernel\"): this corresponds to the size of the last dimension of the inputs. At the\n",
            "\n",
            "--- Chunk 8645 ---\n",
            "end of the build() method (and only at the end), you must call the parent’s\n",
            "\n",
            "--- Chunk 8646 ---\n",
            "8 This function is specific to tf.keras. You could use keras.layers.Activation instead.\n",
            "\n",
            "--- Chunk 8647 ---\n",
            "9 The Keras API calls this argument input_shape, but since it also includes the batch dimension, I prefer to call\n",
            "\n",
            "--- Chunk 8648 ---\n",
            "it batch_input_shape. Same for compute_output_shape().\n",
            "\n",
            "392 | Chapter 12: Custom Models and Training with TensorFlow\n",
            "\n",
            "--- Chunk 8649 ---\n",
            "build() method: this tells Keras that the layer is built (it just sets\n",
            "self.built=True).\n",
            "\n",
            "--- Chunk 8650 ---\n",
            "• The call() method performs the desired operations. In this case, we compute\n",
            "\n",
            "--- Chunk 8651 ---\n",
            "the matrix multiplication of the inputs X and the layer’s kernel, we add the bias\n",
            "\n",
            "--- Chunk 8652 ---\n",
            "vector, and we apply the activation function to the result, and this gives us the\n",
            "output of the layer.\n",
            "\n",
            "--- Chunk 8653 ---\n",
            "• The compute_output_shape() method simply returns the shape of this layer’s\n",
            "\n",
            "--- Chunk 8654 ---\n",
            "outputs. In this case, it is the same shape as the inputs, except the last dimension\n",
            "\n",
            "--- Chunk 8655 ---\n",
            "is replaced with the number of neurons in the layer. Note that in tf.keras, shapes\n",
            "\n",
            "--- Chunk 8656 ---\n",
            "are instances of the tf.TensorShape class, which you can convert to Python lists\n",
            "using as_list().\n",
            "\n",
            "--- Chunk 8657 ---\n",
            "• The get_config() method is just like in the previous custom classes. Note that\n",
            "\n",
            "--- Chunk 8658 ---\n",
            "we save the activation function’s full configuration by calling keras.activa\n",
            "tions.serialize().\n",
            "\n",
            "--- Chunk 8659 ---\n",
            "You can now use a MyDense layer just like any other layer!\n",
            "\n",
            "--- Chunk 8660 ---\n",
            "You can generally omit the compute_output_shape() method, as\n",
            "tf.keras automatically infers the output shape, except when the\n",
            "\n",
            "--- Chunk 8661 ---\n",
            "layer is dynamic (as we will see shortly). In other Keras implemen‐\n",
            "tations, this method is either required or its default implementation\n",
            "\n",
            "--- Chunk 8662 ---\n",
            "assumes the output shape is the same as the input shape.\n",
            "\n",
            "--- Chunk 8663 ---\n",
            "To create a layer with multiple inputs (e.g., Concatenate), the argument to the call()\n",
            "\n",
            "--- Chunk 8664 ---\n",
            "method should be a tuple containing all the inputs, and similarly the argument to the\n",
            "\n",
            "--- Chunk 8665 ---\n",
            "compute_output_shape() method should be a tuple containing each input’s batch\n",
            "\n",
            "--- Chunk 8666 ---\n",
            "shape. To create a layer with multiple outputs, the call() method should return the\n",
            "\n",
            "--- Chunk 8667 ---\n",
            "list of outputs, and compute_output_shape() should return the list of batch output\n",
            "\n",
            "--- Chunk 8668 ---\n",
            "shapes (one per output). For example, the following toy layer takes two inputs and\n",
            "returns three outputs:\n",
            "\n",
            "--- Chunk 8669 ---\n",
            "class MyMultiLayer(keras.layers.Layer):\n",
            "    def call(self, X):\n",
            "        X1, X2 = X\n",
            "        return [X1 + X2, X1 * X2, X1 / X2]\n",
            "\n",
            "--- Chunk 8670 ---\n",
            "def compute_output_shape(self, batch_input_shape):\n",
            "        b1, b2 = batch_input_shape\n",
            "\n",
            "--- Chunk 8671 ---\n",
            "return [b1, b1, b1] # should probably handle broadcasting rules\n",
            "\n",
            "--- Chunk 8672 ---\n",
            "Customizing Models and Training Algorithms | 393\n",
            "\n",
            "--- Chunk 8673 ---\n",
            "This layer may now be used like any other layer, but of course only using the Func‐\n",
            "\n",
            "--- Chunk 8674 ---\n",
            "tional and Subclassing APIs, not the Sequential API (which only accepts layers with\n",
            "one input and one output).\n",
            "\n",
            "--- Chunk 8675 ---\n",
            "If your layer needs to have a different behavior during training and during testing\n",
            "\n",
            "--- Chunk 8676 ---\n",
            "(e.g., if it uses Dropout or BatchNormalization layers), then you must add a train\n",
            "\n",
            "--- Chunk 8677 ---\n",
            "ing argument to the call() method and use this argument to decide what to do. For\n",
            "\n",
            "--- Chunk 8678 ---\n",
            "example, let’s create a layer that adds Gaussian noise during training (for regulariza‐\n",
            "\n",
            "--- Chunk 8679 ---\n",
            "tion) but does nothing during testing (Keras has a layer that does the same thing,\n",
            "keras.layers.GaussianNoise):\n",
            "\n",
            "--- Chunk 8680 ---\n",
            "class MyGaussianNoise(keras.layers.Layer):\n",
            "    def __init__(self, stddev, **kwargs):\n",
            "        super().__init__(**kwargs)\n",
            "        self.stddev = stddev\n",
            "\n",
            "--- Chunk 8681 ---\n",
            "def call(self, X, training=None):\n",
            "        if training:\n",
            "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
            "\n",
            "--- Chunk 8682 ---\n",
            "return X + noise\n",
            "        else:\n",
            "            return X\n",
            "\n",
            "--- Chunk 8683 ---\n",
            "def compute_output_shape(self, batch_input_shape):\n",
            "        return batch_input_shape\n",
            "\n",
            "--- Chunk 8684 ---\n",
            "With that, you can now build any custom layer you need! Now let’s create custom\n",
            "models.\n",
            "\n",
            "--- Chunk 8685 ---\n",
            "Custom Models\n",
            "We already looked at creating custom model classes in Chapter 10, when we dis‐\n",
            "\n",
            "--- Chunk 8686 ---\n",
            "cussed the Subclassing API.10 It’s straightforward: subclass the keras.Model class, cre‐\n",
            "\n",
            "--- Chunk 8687 ---\n",
            "ate layers and variables in the constructor, and implement the call() method to do\n",
            "\n",
            "--- Chunk 8688 ---\n",
            "whatever you want the model to do. Suppose you want to build the model repre‐\n",
            "sented in Figure 12-3.\n",
            "\n",
            "--- Chunk 8689 ---\n",
            "10 The name “Subclassing API” usually refers only to the creation of custom models by subclassing, although\n",
            "\n",
            "--- Chunk 8690 ---\n",
            "many other things can be created by subclassing, as we saw in this chapter.\n",
            "\n",
            "--- Chunk 8691 ---\n",
            "394 | Chapter 12: Custom Models and Training with TensorFlow\n",
            "\n",
            "--- Chunk 8692 ---\n",
            "Figure 12-3. Custom model example: an arbitrary model with a custom ResidualBlock\n",
            "layer containing a skip connection\n",
            "\n",
            "--- Chunk 8693 ---\n",
            "The inputs go through a first dense layer, then through a residual block composed of\n",
            "\n",
            "--- Chunk 8694 ---\n",
            "two dense layers and an addition operation (as we will see in Chapter 14, a residual\n",
            "\n",
            "--- Chunk 8695 ---\n",
            "block adds its inputs to its outputs), then through this same residual block three more\n",
            "\n",
            "--- Chunk 8696 ---\n",
            "times, then through a second residual block, and the final result goes through a dense\n",
            "\n",
            "--- Chunk 8697 ---\n",
            "output layer. Note that this model does not make much sense; it’s just an example to\n",
            "\n",
            "--- Chunk 8698 ---\n",
            "illustrate the fact that you can easily build any kind of model you want, even one that\n",
            "\n",
            "--- Chunk 8699 ---\n",
            "contains loops and skip connections. To implement this model, it is best to first create\n",
            "\n",
            "--- Chunk 8700 ---\n",
            "a ResidualBlock layer, since we are going to create a couple of identical blocks (and\n",
            "we might want to reuse it in another model):\n",
            "\n",
            "--- Chunk 8701 ---\n",
            "class ResidualBlock(keras.layers.Layer):\n",
            "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
            "        super().__init__(**kwargs)\n",
            "\n",
            "--- Chunk 8702 ---\n",
            "self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\",\n",
            "                                          kernel_initializer=\"he_normal\")\n",
            "\n",
            "--- Chunk 8703 ---\n",
            "for _ in range(n_layers)]\n",
            "\n",
            "--- Chunk 8704 ---\n",
            "def call(self, inputs):\n",
            "        Z = inputs\n",
            "        for layer in self.hidden:\n",
            "            Z = layer(Z)\n",
            "        return inputs + Z\n",
            "\n",
            "--- Chunk 8705 ---\n",
            "This layer is a bit special since it contains other layers. This is handled transparently\n",
            "\n",
            "--- Chunk 8706 ---\n",
            "by Keras: it automatically detects that the hidden attribute contains trackable objects\n",
            "\n",
            "--- Chunk 8707 ---\n",
            "(layers in this case), so their variables are automatically added to this layer’s list of\n",
            "\n",
            "--- Chunk 8708 ---\n",
            "Customizing Models and Training Algorithms | 395\n",
            "\n",
            "--- Chunk 8709 ---\n",
            "variables. The rest of this class is self-explanatory. Next, let’s use the Subclassing API\n",
            "to define the model itself:\n",
            "\n",
            "--- Chunk 8710 ---\n",
            "class ResidualRegressor(keras.Model):\n",
            "    def __init__(self, output_dim, **kwargs):\n",
            "        super().__init__(**kwargs)\n",
            "\n",
            "--- Chunk 8711 ---\n",
            "self.hidden1 = keras.layers.Dense(30, activation=\"elu\",\n",
            "                                          kernel_initializer=\"he_normal\")\n",
            "\n",
            "--- Chunk 8712 ---\n",
            "self.block1 = ResidualBlock(2, 30)\n",
            "        self.block2 = ResidualBlock(2, 30)\n",
            "        self.out = keras.layers.Dense(output_dim)\n",
            "\n",
            "--- Chunk 8713 ---\n",
            "def call(self, inputs):\n",
            "        Z = self.hidden1(inputs)\n",
            "        for _ in range(1 + 3):\n",
            "            Z = self.block1(Z)\n",
            "\n",
            "--- Chunk 8714 ---\n",
            "Z = self.block2(Z)\n",
            "        return self.out(Z)\n",
            "\n",
            "--- Chunk 8715 ---\n",
            "We create the layers in the constructor and use them in the call() method. This\n",
            "\n",
            "--- Chunk 8716 ---\n",
            "model can then be used like any other model (compile it, fit it, evaluate it, and use it\n",
            "\n",
            "--- Chunk 8717 ---\n",
            "to make predictions). If you also want to be able to save the model using the save()\n",
            "\n",
            "--- Chunk 8718 ---\n",
            "method and load it using the keras.models.load_model() function, you must\n",
            "\n",
            "--- Chunk 8719 ---\n",
            "implement the get_config() method (as we did earlier) in both the ResidualBlock\n",
            "\n",
            "--- Chunk 8720 ---\n",
            "class and the ResidualRegressor class. Alternatively, you can save and load the\n",
            "weights using the save_weights() and load_weights() methods.\n",
            "\n",
            "--- Chunk 8721 ---\n",
            "The Model class is a subclass of the Layer class, so models can be defined and used\n",
            "\n",
            "--- Chunk 8722 ---\n",
            "exactly like layers. But a model has some extra functionalities, including of course its\n",
            "\n",
            "--- Chunk 8723 ---\n",
            "compile(), fit(), evaluate(), and predict() methods (and a few variants), plus the\n",
            "\n",
            "--- Chunk 8724 ---\n",
            "get_layers() method (which can return any of the model’s layers by name or by\n",
            "\n",
            "--- Chunk 8725 ---\n",
            "index) and the save() method (and support for keras.models.load_model() and\n",
            "keras.models.clone_model()).\n",
            "\n",
            "--- Chunk 8726 ---\n",
            "If models provide more functionality than layers, why not just\n",
            "define every layer as a model? Well, technically you could, but it is\n",
            "\n",
            "--- Chunk 8727 ---\n",
            "usually cleaner to distinguish the internal components of your\n",
            "model (i.e., layers or reusable blocks of layers) from the model itself\n",
            "\n",
            "--- Chunk 8728 ---\n",
            "(i.e., the object you will train). The former should subclass the\n",
            "Layer class, while the latter should subclass the Model class.\n",
            "\n",
            "--- Chunk 8729 ---\n",
            "With that, you can naturally and concisely build almost any model that you find in a\n",
            "\n",
            "--- Chunk 8730 ---\n",
            "paper, using the Sequential API, the Functional API, the Subclassing API, or even a\n",
            "\n",
            "--- Chunk 8731 ---\n",
            "mix of these. “Almost” any model? Yes, there are still a few things that we need to look\n",
            "\n",
            "--- Chunk 8732 ---\n",
            "396 | Chapter 12: Custom Models and Training with TensorFlow\n",
            "\n",
            "--- Chunk 8733 ---\n",
            "at: first, how to define losses or metrics based on model internals, and second, how to\n",
            "build a custom training loop.\n",
            "\n",
            "--- Chunk 8734 ---\n",
            "Losses and Metrics Based on Model Internals\n",
            "The custom losses and metrics we defined earlier were all based on the labels and the\n",
            "\n",
            "--- Chunk 8735 ---\n",
            "predictions (and optionally sample weights). There will be times when you want to\n",
            "\n",
            "--- Chunk 8736 ---\n",
            "define losses based on other parts of your model, such as the weights or activations of\n",
            "\n",
            "--- Chunk 8737 ---\n",
            "its hidden layers. This may be useful for regularization purposes or to monitor some\n",
            "internal aspect of your model.\n",
            "\n",
            "--- Chunk 8738 ---\n",
            "To define a custom loss based on model internals, compute it based on any part of the\n",
            "\n",
            "--- Chunk 8739 ---\n",
            "model you want, then pass the result to the add_loss() method.For example, let’s\n",
            "\n",
            "--- Chunk 8740 ---\n",
            "build a custom regression MLP model composed of a stack of five hidden layers plus\n",
            "\n",
            "--- Chunk 8741 ---\n",
            "an output layer. This custom model will also have an auxiliary output on top of the\n",
            "\n",
            "--- Chunk 8742 ---\n",
            "upper hidden layer. The loss associated to this auxiliary output will be called the\n",
            "\n",
            "--- Chunk 8743 ---\n",
            "reconstruction loss (see Chapter 17): it is the mean squared difference between the\n",
            "\n",
            "--- Chunk 8744 ---\n",
            "reconstruction and the inputs. By adding this reconstruction loss to the main loss, we\n",
            "\n",
            "--- Chunk 8745 ---\n",
            "will encourage the model to preserve as much information as possible through the\n",
            "\n",
            "--- Chunk 8746 ---\n",
            "hidden layers—even information that is not directly useful for the regression task\n",
            "\n",
            "--- Chunk 8747 ---\n",
            "itself. In practice, this loss sometimes improves generalization (it is a regularization\n",
            "\n",
            "--- Chunk 8748 ---\n",
            "loss). Here is the code for this custom model with a custom reconstruction loss:\n",
            "\n",
            "--- Chunk 8749 ---\n",
            "class ReconstructingRegressor(keras.Model):\n",
            "    def __init__(self, output_dim, **kwargs):\n",
            "        super().__init__(**kwargs)\n",
            "\n",
            "--- Chunk 8750 ---\n",
            "self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
            "                                          kernel_initializer=\"lecun_normal\")\n",
            "\n",
            "--- Chunk 8751 ---\n",
            "for _ in range(5)]\n",
            "        self.out = keras.layers.Dense(output_dim)\n",
            "\n",
            "--- Chunk 8752 ---\n",
            "def build(self, batch_input_shape):\n",
            "        n_inputs = batch_input_shape[-1]\n",
            "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
            "\n",
            "--- Chunk 8753 ---\n",
            "super().build(batch_input_shape)\n",
            "\n",
            "--- Chunk 8754 ---\n",
            "def call(self, inputs):\n",
            "        Z = inputs\n",
            "        for layer in self.hidden:\n",
            "            Z = layer(Z)\n",
            "\n",
            "--- Chunk 8755 ---\n",
            "reconstruction = self.reconstruct(Z)\n",
            "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
            "\n",
            "--- Chunk 8756 ---\n",
            "self.add_loss(0.05 * recon_loss)\n",
            "        return self.out(Z)\n",
            "\n",
            "--- Chunk 8757 ---\n",
            "Customizing Models and Training Algorithms | 397\n",
            "\n",
            "\n",
            "\n",
            "Let’s go through this code:\n",
            "\n",
            "--- Chunk 8758 ---\n",
            "• The constructor creates the DNN with five dense hidden layers and one dense\n",
            "output layer.\n",
            "\n",
            "--- Chunk 8759 ---\n",
            "• The build() method creates an extra dense layer which will be used to recon‐\n",
            "\n",
            "--- Chunk 8760 ---\n",
            "struct the inputs of the model. It must be created here because its number of units\n",
            "\n",
            "--- Chunk 8761 ---\n",
            "must be equal to the number of inputs, and this number is unknown before the\n",
            "build() method is called.\n",
            "\n",
            "--- Chunk 8762 ---\n",
            "• The call() method processes the inputs through all five hidden layers, then\n",
            "\n",
            "--- Chunk 8763 ---\n",
            "passes the result through the reconstruction layer, which produces the recon‐\n",
            "struction.\n",
            "\n",
            "--- Chunk 8764 ---\n",
            "• Then the call() method computes the reconstruction loss (the mean squared\n",
            "\n",
            "--- Chunk 8765 ---\n",
            "difference between the reconstruction and the inputs), and adds it to the model’s\n",
            "\n",
            "--- Chunk 8766 ---\n",
            "list of losses using the add_loss() method.11 Notice that we scale down the\n",
            "\n",
            "--- Chunk 8767 ---\n",
            "reconstruction loss by multiplying it by 0.05 (this is a hyperparameter you can\n",
            "\n",
            "--- Chunk 8768 ---\n",
            "tune). This ensures that the reconstruction loss does not dominate the main loss.\n",
            "\n",
            "--- Chunk 8769 ---\n",
            "• Finally, the call() method passes the output of the hidden layers to the output\n",
            "layer and returns its output.\n",
            "\n",
            "--- Chunk 8770 ---\n",
            "Similarly, you can add a custom metric based on model internals by computing it in\n",
            "\n",
            "--- Chunk 8771 ---\n",
            "any way you want, as long as the result is the output of a metric object. For example,\n",
            "\n",
            "--- Chunk 8772 ---\n",
            "you can create a keras.metrics.Mean object in the constructor, then call it in the\n",
            "\n",
            "--- Chunk 8773 ---\n",
            "call() method, passing it the recon_loss, and finally add it to the model by calling\n",
            "\n",
            "--- Chunk 8774 ---\n",
            "the model’s add_metric() method. This way, when you train the model, Keras will\n",
            "\n",
            "--- Chunk 8775 ---\n",
            "display both the mean loss over each epoch (the loss is the sum of the main loss plus\n",
            "\n",
            "--- Chunk 8776 ---\n",
            "0.05 times the reconstruction loss) and the mean reconstruction error over each\n",
            "epoch. Both will go down during training:\n",
            "\n",
            "--- Chunk 8777 ---\n",
            "Epoch 1/5\n",
            "11610/11610 [=============] [...] loss: 4.3092 - reconstruction_error: 1.7360\n",
            "Epoch 2/5\n",
            "\n",
            "--- Chunk 8778 ---\n",
            "Epoch 2/5\n",
            "11610/11610 [=============] [...] loss: 1.1232 - reconstruction_error: 0.8964\n",
            "[...]\n",
            "\n",
            "--- Chunk 8779 ---\n",
            "In over 99% of cases, everything we have discussed so far will be sufficient to imple‐\n",
            "\n",
            "--- Chunk 8780 ---\n",
            "ment whatever model you want to build, even with complex architectures, losses, and\n",
            "\n",
            "--- Chunk 8781 ---\n",
            "metrics. However, in some rare cases you may need to customize the training loop\n",
            "\n",
            "--- Chunk 8782 ---\n",
            "11 You can also call add_loss() on any layer inside the model, as the model recursively gathers losses from all of\n",
            "its layers.\n",
            "\n",
            "--- Chunk 8783 ---\n",
            "398 | Chapter 12: Custom Models and Training with TensorFlow\n",
            "\n",
            "--- Chunk 8784 ---\n",
            "itself. Before we get there, we need to look at how to compute gradients automatically\n",
            "in TensorFlow.\n",
            "\n",
            "--- Chunk 8785 ---\n",
            "Computing Gradients Using Autodiff\n",
            "To understand how to use autodiff (see Chapter 10 and Appendix D) to compute gra‐\n",
            "\n",
            "--- Chunk 8786 ---\n",
            "dients automatically, let’s consider a simple toy function:\n",
            "\n",
            "--- Chunk 8787 ---\n",
            "def f(w1, w2):\n",
            "    return 3 * w1 ** 2 + 2 * w1 * w2\n",
            "\n",
            "--- Chunk 8788 ---\n",
            "If you know calculus, you can analytically find that the partial derivative of this func‐\n",
            "\n",
            "--- Chunk 8789 ---\n",
            "tion with regard to w1 is 6 * w1 + 2 * w2. You can also find that its partial derivative\n",
            "\n",
            "--- Chunk 8790 ---\n",
            "with regard to w2 is 2 * w1. For example, at the point (w1, w2) = (5, 3), these par‐\n",
            "\n",
            "--- Chunk 8791 ---\n",
            "tial derivatives are equal to 36 and 10, respectively, so the gradient vector at this point\n",
            "\n",
            "--- Chunk 8792 ---\n",
            "is (36, 10). But if this were a neural network, the function would be much more com‐\n",
            "\n",
            "--- Chunk 8793 ---\n",
            "plex, typically with tens of thousands of parameters, and finding the partial deriva‐\n",
            "\n",
            "--- Chunk 8794 ---\n",
            "tives analytically by hand would be an almost impossible task. One solution could be\n",
            "\n",
            "--- Chunk 8795 ---\n",
            "to compute an approximation of each partial derivative by measuring how much the\n",
            "\n",
            "--- Chunk 8796 ---\n",
            "function’s output changes when you tweak the corresponding parameter:\n",
            "\n",
            "--- Chunk 8797 ---\n",
            ">>> w1, w2 = 5, 3\n",
            ">>> eps = 1e-6\n",
            ">>> (f(w1 + eps, w2) - f(w1, w2)) / eps\n",
            "36.000003007075065\n",
            ">>> (f(w1, w2 + eps) - f(w1, w2)) / eps\n",
            "\n",
            "--- Chunk 8798 ---\n",
            "10.000000003174137\n",
            "\n",
            "--- Chunk 8799 ---\n",
            "Looks about right! This works rather well and is easy to implement, but it is just an\n",
            "\n",
            "--- Chunk 8800 ---\n",
            "approximation, and importantly you need to call f() at least once per parameter (not\n",
            "\n",
            "--- Chunk 8801 ---\n",
            "twice, since we could compute f(w1, w2) just once). Needing to call f() at least once\n",
            "\n",
            "--- Chunk 8802 ---\n",
            "per parameter makes this approach intractable for large neural networks. So instead,\n",
            "we should use autodiff. TensorFlow makes this pretty simple:\n",
            "\n",
            "--- Chunk 8803 ---\n",
            "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
            "with tf.GradientTape() as tape:\n",
            "    z = f(w1, w2)\n",
            "\n",
            "gradients = tape.gradient(z, [w1, w2])\n",
            "\n",
            "--- Chunk 8804 ---\n",
            "We first define two variables w1 and w2, then we create a tf.GradientTape context\n",
            "\n",
            "--- Chunk 8805 ---\n",
            "that will automatically record every operation that involves a variable, and finally we\n",
            "\n",
            "--- Chunk 8806 ---\n",
            "ask this tape to compute the gradients of the result z with regard to both variables\n",
            "\n",
            "--- Chunk 8807 ---\n",
            "[w1, w2]. Let’s take a look at the gradients that TensorFlow computed:\n",
            "\n",
            "--- Chunk 8808 ---\n",
            ">>> gradients\n",
            "[<tf.Tensor: id=828234, shape=(), dtype=float32, numpy=36.0>,\n",
            " <tf.Tensor: id=828229, shape=(), dtype=float32, numpy=10.0>]\n",
            "\n",
            "--- Chunk 8809 ---\n",
            "Customizing Models and Training Algorithms | 399\n",
            "\n",
            "--- Chunk 8810 ---\n",
            "Perfect! Not only is the result accurate (the precision is only limited by the floating-\n",
            "\n",
            "--- Chunk 8811 ---\n",
            "point errors), but the gradient() method only goes through the recorded computa‐\n",
            "\n",
            "--- Chunk 8812 ---\n",
            "tions once (in reverse order), no matter how many variables there are, so it is\n",
            "incredibly efficient. It’s like magic!\n",
            "\n",
            "--- Chunk 8813 ---\n",
            "To save memory, only put the strict minimum inside the tf.Gra\n",
            "dientTape() block. Alternatively, pause recording by creating a\n",
            "\n",
            "--- Chunk 8814 ---\n",
            "with tape.stop_recording() block inside the tf.Gradient\n",
            "Tape() block.\n",
            "\n",
            "--- Chunk 8815 ---\n",
            "The tape is automatically erased immediately after you call its gradient() method, so\n",
            "you will get an exception if you try to call gradient() twice:\n",
            "\n",
            "--- Chunk 8816 ---\n",
            "with tf.GradientTape() as tape:\n",
            "    z = f(w1, w2)\n",
            "\n",
            "dz_dw1 = tape.gradient(z, w1) # => tensor 36.0\n",
            "dz_dw2 = tape.gradient(z, w2) # RuntimeError!\n",
            "\n",
            "--- Chunk 8817 ---\n",
            "If you need to call gradient() more than once, you must make the tape persistent\n",
            "and delete it each time you are done with it to free resources:12\n",
            "\n",
            "--- Chunk 8818 ---\n",
            "with tf.GradientTape(persistent=True) as tape:\n",
            "    z = f(w1, w2)\n",
            "\n",
            "--- Chunk 8819 ---\n",
            "dz_dw1 = tape.gradient(z, w1) # => tensor 36.0\n",
            "dz_dw2 = tape.gradient(z, w2) # => tensor 10.0, works fine now!\n",
            "del tape\n",
            "\n",
            "--- Chunk 8820 ---\n",
            "By default, the tape will only track operations involving variables, so if you try to\n",
            "\n",
            "--- Chunk 8821 ---\n",
            "compute the gradient of z with regard to anything other than a variable, the result\n",
            "will be None:\n",
            "\n",
            "--- Chunk 8822 ---\n",
            "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
            "with tf.GradientTape() as tape:\n",
            "    z = f(c1, c2)\n",
            "\n",
            "--- Chunk 8823 ---\n",
            "gradients = tape.gradient(z, [c1, c2]) # returns [None, None]\n",
            "\n",
            "--- Chunk 8824 ---\n",
            "However, you can force the tape to watch any tensors you like, to record every opera‐\n",
            "\n",
            "--- Chunk 8825 ---\n",
            "tion that involves them. You can then compute gradients with regard to these tensors,\n",
            "as if they were variables:\n",
            "\n",
            "--- Chunk 8826 ---\n",
            "12 If the tape goes out of scope, for example when the function that used it returns, Python’s garbage collector\n",
            "will delete it for you.\n",
            "\n",
            "--- Chunk 8827 ---\n",
            "400 | Chapter 12: Custom Models and Training with TensorFlow\n",
            "\n",
            "--- Chunk 8828 ---\n",
            "with tf.GradientTape() as tape:\n",
            "    tape.watch(c1)\n",
            "    tape.watch(c2)\n",
            "    z = f(c1, c2)\n",
            "\n",
            "--- Chunk 8829 ---\n",
            "gradients = tape.gradient(z, [c1, c2]) # returns [tensor 36., tensor 10.]\n",
            "\n",
            "--- Chunk 8830 ---\n",
            "This can be useful in some cases, like if you want to implement a regularization loss\n",
            "\n",
            "--- Chunk 8831 ---\n",
            "that penalizes activations that vary a lot when the inputs vary little: the loss will be\n",
            "\n",
            "--- Chunk 8832 ---\n",
            "based on the gradient of the activations with regard to the inputs. Since the inputs are\n",
            "\n",
            "--- Chunk 8833 ---\n",
            "not variables, you would need to tell the tape to watch them.\n",
            "Most of the time a gradient tape is used to compute the gradients of a single value\n",
            "\n",
            "--- Chunk 8834 ---\n",
            "(usually the loss) with regard to a set of values (usually the model parameters). This is\n",
            "\n",
            "--- Chunk 8835 ---\n",
            "where reverse-mode autodiff shines, as it just needs to do one forward pass and one\n",
            "\n",
            "--- Chunk 8836 ---\n",
            "reverse pass to get all the gradients at once. If you try to compute the gradients of a\n",
            "\n",
            "--- Chunk 8837 ---\n",
            "vector, for example a vector containing multiple losses, then TensorFlow will com‐\n",
            "\n",
            "--- Chunk 8838 ---\n",
            "pute the gradients of the vector’s sum. So if you ever need to get the individual gradi‐\n",
            "\n",
            "--- Chunk 8839 ---\n",
            "ents (e.g., the gradients of each loss with regard to the model parameters), you must\n",
            "\n",
            "--- Chunk 8840 ---\n",
            "call the tape’s jacobian() method: it will perform reverse-mode autodiff once for\n",
            "\n",
            "--- Chunk 8841 ---\n",
            "each loss in the vector (all in parallel by default). It is even possible to compute\n",
            "\n",
            "--- Chunk 8842 ---\n",
            "second-order partial derivatives (the Hessians, i.e., the partial derivatives of the par‐\n",
            "\n",
            "--- Chunk 8843 ---\n",
            "tial derivatives), but this is rarely needed in practice (see the “Computing Gradients\n",
            "with Autodiff ” section of the notebook for an example).\n",
            "\n",
            "--- Chunk 8844 ---\n",
            "In some cases you may want to stop gradients from backpropagating through some\n",
            "\n",
            "--- Chunk 8845 ---\n",
            "part of your neural network. To do this, you must use the tf.stop_gradient() func‐\n",
            "\n",
            "--- Chunk 8846 ---\n",
            "tion. The function returns its inputs during the forward pass (like tf.identity()),\n",
            "\n",
            "--- Chunk 8847 ---\n",
            "but it does not let gradients through during backpropagation (it acts like a constant):\n",
            "\n",
            "--- Chunk 8848 ---\n",
            "def f(w1, w2):\n",
            "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
            "\n",
            "--- Chunk 8849 ---\n",
            "with tf.GradientTape() as tape:\n",
            "    z = f(w1, w2) # same result as without stop_gradient()\n",
            "\n",
            "--- Chunk 8850 ---\n",
            "gradients = tape.gradient(z, [w1, w2]) # => returns [tensor 30., None]\n",
            "\n",
            "--- Chunk 8851 ---\n",
            "Finally, you may occasionally run into some numerical issues when computing gradi‐\n",
            "\n",
            "--- Chunk 8852 ---\n",
            "ents. For example, if you compute the gradients of the my_softplus() function for\n",
            "large inputs, the result will be NaN:\n",
            "\n",
            "--- Chunk 8853 ---\n",
            ">>> x = tf.Variable([100.])\n",
            ">>> with tf.GradientTape() as tape:\n",
            "...     z = my_softplus(x)\n",
            "...\n",
            ">>> tape.gradient(z, [x])\n",
            "\n",
            "--- Chunk 8854 ---\n",
            "<tf.Tensor: [...] numpy=array([nan], dtype=float32)>\n",
            "\n",
            "--- Chunk 8855 ---\n",
            "Customizing Models and Training Algorithms | 401\n",
            "\n",
            "--- Chunk 8856 ---\n",
            "This is because computing the gradients of this function using autodiff leads to some\n",
            "\n",
            "--- Chunk 8857 ---\n",
            "numerical difficulties: due to floating-point precision errors, autodiff ends up com‐\n",
            "\n",
            "--- Chunk 8858 ---\n",
            "puting infinity divided by infinity (which returns NaN). Fortunately, we can analyti‐\n",
            "\n",
            "--- Chunk 8859 ---\n",
            "cally find that the derivative of the softplus function is just 1 / (1 + 1 / exp(x)), which\n",
            "\n",
            "--- Chunk 8860 ---\n",
            "is numerically stable. Next, we can tell TensorFlow to use this stable function when\n",
            "\n",
            "--- Chunk 8861 ---\n",
            "computing the gradients of the my_softplus() function by decorating it with\n",
            "\n",
            "--- Chunk 8862 ---\n",
            "@tf.custom_gradient and making it return both its normal output and the function\n",
            "\n",
            "--- Chunk 8863 ---\n",
            "that computes the derivatives (note that it will receive as input the gradients that were\n",
            "\n",
            "--- Chunk 8864 ---\n",
            "backpropagated so far, down to the softplus function; and according to the chain rule,\n",
            "we should multiply them with this function’s gradients):\n",
            "\n",
            "--- Chunk 8865 ---\n",
            "@tf.custom_gradient\n",
            "def my_better_softplus(z):\n",
            "    exp = tf.exp(z)\n",
            "    def my_softplus_gradients(grad):\n",
            "        return grad / (1 + 1 / exp)\n",
            "\n",
            "--- Chunk 8866 ---\n",
            "return tf.math.log(exp + 1), my_softplus_gradients\n",
            "\n",
            "--- Chunk 8867 ---\n",
            "Now when we compute the gradients of the my_better_softplus() function, we get\n",
            "\n",
            "--- Chunk 8868 ---\n",
            "the proper result, even for large input values (however, the main output still explodes\n",
            "\n",
            "--- Chunk 8869 ---\n",
            "because of the exponential; one workaround is to use tf.where() to return the inputs\n",
            "when they are large).\n",
            "\n",
            "--- Chunk 8870 ---\n",
            "Congratulations! You can now compute the gradients of any function (provided it is\n",
            "\n",
            "--- Chunk 8871 ---\n",
            "differentiable at the point where you compute it), even blocking backpropagation\n",
            "\n",
            "--- Chunk 8872 ---\n",
            "when needed, and write your own gradient functions! This is probably more flexibil‐\n",
            "\n",
            "--- Chunk 8873 ---\n",
            "ity than you will ever need, even if you build your own custom training loops, as we\n",
            "will see now.\n",
            "\n",
            "--- Chunk 8874 ---\n",
            "Custom Training Loops\n",
            "In some rare cases, the fit() method may not be flexible enough for what you need\n",
            "\n",
            "--- Chunk 8875 ---\n",
            "to do. For example, the Wide & Deep paper we discussed in Chapter 10 uses two dif‐\n",
            "\n",
            "--- Chunk 8876 ---\n",
            "ferent optimizers: one for the wide path and the other for the deep path. Since the\n",
            "\n",
            "--- Chunk 8877 ---\n",
            "fit() method only uses one optimizer (the one that we specify when compiling the\n",
            "\n",
            "--- Chunk 8878 ---\n",
            "model), implementing this paper requires writing your own custom loop.\n",
            "\n",
            "--- Chunk 8879 ---\n",
            "You may also like to write custom training loops simply to feel more confident that\n",
            "\n",
            "--- Chunk 8880 ---\n",
            "they do precisely what you intend them to do (perhaps you are unsure about some\n",
            "\n",
            "--- Chunk 8881 ---\n",
            "details of the fit() method). It can sometimes feel safer to make everything explicit.\n",
            "\n",
            "--- Chunk 8882 ---\n",
            "However, remember that writing a custom training loop will make your code longer,\n",
            "more error-prone, and harder to maintain.\n",
            "\n",
            "--- Chunk 8883 ---\n",
            "402 | Chapter 12: Custom Models and Training with TensorFlow\n",
            "\n",
            "--- Chunk 8884 ---\n",
            "Unless you really need the extra flexibility, you should prefer using\n",
            "the fit() method rather than implementing your own training\n",
            "\n",
            "--- Chunk 8885 ---\n",
            "loop, especially if you work in a team.\n",
            "\n",
            "--- Chunk 8886 ---\n",
            "First, let’s build a simple model. No need to compile it, since we will handle the train‐\n",
            "ing loop manually:\n",
            "\n",
            "--- Chunk 8887 ---\n",
            "l2_reg = keras.regularizers.l2(0.05)\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
            "\n",
            "--- Chunk 8888 ---\n",
            "kernel_regularizer=l2_reg),\n",
            "    keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
            "])\n",
            "\n",
            "--- Chunk 8889 ---\n",
            "Next, let’s create a tiny function that will randomly sample a batch of instances from\n",
            "\n",
            "--- Chunk 8890 ---\n",
            "the training set (in Chapter 13 we will discuss the Data API, which offers a much bet‐\n",
            "ter alternative):\n",
            "\n",
            "--- Chunk 8891 ---\n",
            "def random_batch(X, y, batch_size=32):\n",
            "    idx = np.random.randint(len(X), size=batch_size)\n",
            "    return X[idx], y[idx]\n",
            "\n",
            "--- Chunk 8892 ---\n",
            "Let’s also define a function that will display the training status, including the number\n",
            "\n",
            "--- Chunk 8893 ---\n",
            "of steps, the total number of steps, the mean loss since the start of the epoch (i.e., we\n",
            "will use the Mean metric to compute it), and other metrics:\n",
            "\n",
            "--- Chunk 8894 ---\n",
            "def print_status_bar(iteration, total, loss, metrics=None):\n",
            "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
            "\n",
            "--- Chunk 8895 ---\n",
            "for m in [loss] + (metrics or [])])\n",
            "    end = \"\" if iteration < total else \"\\n\"\n",
            "\n",
            "--- Chunk 8896 ---\n",
            "print(\"\\r{}/{} - \".format(iteration, total) + metrics,\n",
            "          end=end)\n",
            "\n",
            "--- Chunk 8897 ---\n",
            "This code is self-explanatory, unless you are unfamiliar with Python string format‐\n",
            "\n",
            "--- Chunk 8898 ---\n",
            "ting: {:.4f} will format a float with four digits after the decimal point, and using \\r\n",
            "\n",
            "--- Chunk 8899 ---\n",
            "(carriage return) along with end=\"\" ensures that the status bar always gets printed on\n",
            "\n",
            "--- Chunk 8900 ---\n",
            "the same line. In the notebook, the print_status_bar() function includes a progress\n",
            "bar, but you could use the handy tqdm library instead.\n",
            "\n",
            "--- Chunk 8901 ---\n",
            "With that, let’s get down to business! First, we need to define some hyperparameters\n",
            "\n",
            "--- Chunk 8902 ---\n",
            "and choose the optimizer, the loss function, and the metrics (just the MAE in this\n",
            "example):\n",
            "\n",
            "--- Chunk 8903 ---\n",
            "n_epochs = 5\n",
            "batch_size = 32\n",
            "n_steps = len(X_train) // batch_size\n",
            "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
            "\n",
            "--- Chunk 8904 ---\n",
            "loss_fn = keras.losses.mean_squared_error\n",
            "\n",
            "--- Chunk 8905 ---\n",
            "Customizing Models and Training Algorithms | 403\n",
            "\n",
            "\n",
            "\n",
            "mean_loss = keras.metrics.Mean()\n",
            "metrics = [keras.metrics.MeanAbsoluteError()]\n",
            "\n",
            "--- Chunk 8906 ---\n",
            "And now we are ready to build the custom loop!\n",
            "for epoch in range(1, n_epochs + 1):\n",
            "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
            "\n",
            "--- Chunk 8907 ---\n",
            "for step in range(1, n_steps + 1):\n",
            "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
            "        with tf.GradientTape() as tape:\n",
            "\n",
            "--- Chunk 8908 ---\n",
            "y_pred = model(X_batch, training=True)\n",
            "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
            "\n",
            "--- Chunk 8909 ---\n",
            "loss = tf.add_n([main_loss] + model.losses)\n",
            "        gradients = tape.gradient(loss, model.trainable_variables)\n",
            "\n",
            "--- Chunk 8910 ---\n",
            "optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
            "        mean_loss(loss)\n",
            "        for metric in metrics:\n",
            "\n",
            "--- Chunk 8911 ---\n",
            "metric(y_batch, y_pred)\n",
            "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
            "\n",
            "--- Chunk 8912 ---\n",
            "print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
            "    for metric in [mean_loss] + metrics:\n",
            "        metric.reset_states()\n",
            "\n",
            "--- Chunk 8913 ---\n",
            "There’s a lot going on in this code, so let’s walk through it:\n",
            "\n",
            "--- Chunk 8914 ---\n",
            "• We create two nested loops: one for the epochs, the other for the batches within\n",
            "an epoch.\n",
            "\n",
            "--- Chunk 8915 ---\n",
            "• Then we sample a random batch from the training set.\n",
            "• Inside the tf.GradientTape() block, we make a prediction for one batch (using\n",
            "\n",
            "--- Chunk 8916 ---\n",
            "the model as a function), and we compute the loss: it is equal to the main loss\n",
            "\n",
            "--- Chunk 8917 ---\n",
            "plus the other losses (in this model, there is one regularization loss per layer).\n",
            "\n",
            "--- Chunk 8918 ---\n",
            "Since the mean_squared_error() function returns one loss per instance, we\n",
            "compute the mean over the batch using tf.reduce_mean() (if you wanted to\n",
            "\n",
            "--- Chunk 8919 ---\n",
            "apply different weights to each instance, this is where you would do it). The regu‐\n",
            "\n",
            "--- Chunk 8920 ---\n",
            "larization losses are already reduced to a single scalar each, so we just need to\n",
            "\n",
            "--- Chunk 8921 ---\n",
            "sum them (using tf.add_n(), which sums multiple tensors of the same shape\n",
            "and data type).\n",
            "\n",
            "--- Chunk 8922 ---\n",
            "• Next, we ask the tape to compute the gradient of the loss with regard to each\n",
            "\n",
            "--- Chunk 8923 ---\n",
            "trainable variable (not all variables!), and we apply them to the optimizer to per‐\n",
            "form a Gradient Descent step.\n",
            "\n",
            "--- Chunk 8924 ---\n",
            "• Then we update the mean loss and the metrics (over the current epoch), and we\n",
            "display the status bar.\n",
            "\n",
            "--- Chunk 8925 ---\n",
            "404 | Chapter 12: Custom Models and Training with TensorFlow\n",
            "\n",
            "--- Chunk 8926 ---\n",
            "• At the end of each epoch, we display the status bar again to make it look com‐\n",
            "\n",
            "--- Chunk 8927 ---\n",
            "plete13 and to print a line feed, and we reset the states of the mean loss and the\n",
            "metrics.\n",
            "\n",
            "--- Chunk 8928 ---\n",
            "If you set the optimizer’s clipnorm or clipvalue hyperparameter, it will take care of\n",
            "\n",
            "--- Chunk 8929 ---\n",
            "this for you. If you want to apply any other transformation to the gradients, simply do\n",
            "so before calling the apply_gradients() method.\n",
            "\n",
            "--- Chunk 8930 ---\n",
            "If you add weight constraints to your model (e.g., by setting kernel_constraint or\n",
            "\n",
            "--- Chunk 8931 ---\n",
            "bias_constraint when creating a layer), you should update the training loop to\n",
            "apply these constraints just after apply_gradients():\n",
            "\n",
            "--- Chunk 8932 ---\n",
            "for variable in model.variables:\n",
            "    if variable.constraint is not None:\n",
            "        variable.assign(variable.constraint(variable))\n",
            "\n",
            "--- Chunk 8933 ---\n",
            "Most importantly, this training loop does not handle layers that behave differently\n",
            "\n",
            "--- Chunk 8934 ---\n",
            "during training and testing (e.g., BatchNormalization or Dropout). To handle these,\n",
            "\n",
            "--- Chunk 8935 ---\n",
            "you need to call the model with training=True and make sure it propagates this to\n",
            "every layer that needs it.\n",
            "\n",
            "--- Chunk 8936 ---\n",
            "As you can see, there are quite a lot of things you need to get right, and it’s easy to\n",
            "\n",
            "--- Chunk 8937 ---\n",
            "make a mistake. But on the bright side, you get full control, so it’s your call.\n",
            "\n",
            "--- Chunk 8938 ---\n",
            "Now that you know how to customize any part of your models14 and training algo‐\n",
            "\n",
            "--- Chunk 8939 ---\n",
            "rithms, let’s see how you can use TensorFlow’s automatic graph generation feature: it\n",
            "\n",
            "--- Chunk 8940 ---\n",
            "can speed up your custom code considerably, and it will also make it portable to any\n",
            "platform supported by TensorFlow (see Chapter 19).\n",
            "\n",
            "--- Chunk 8941 ---\n",
            "TensorFlow Functions and Graphs\n",
            "In TensorFlow 1, graphs were unavoidable (as were the complexities that came with\n",
            "\n",
            "--- Chunk 8942 ---\n",
            "them) because they were a central part of TensorFlow’s API. In TensorFlow 2, they are\n",
            "\n",
            "--- Chunk 8943 ---\n",
            "still there, but not as central, and they’re much (much!) simpler to use. To show just\n",
            "\n",
            "--- Chunk 8944 ---\n",
            "how simple, let’s start with a trivial function that computes the cube of its input:\n",
            "\n",
            "--- Chunk 8945 ---\n",
            "def cube(x):\n",
            "    return x ** 3\n",
            "\n",
            "--- Chunk 8946 ---\n",
            "13 The truth is we did not process every single instance in the training set, because we sampled instances ran‐\n",
            "\n",
            "--- Chunk 8947 ---\n",
            "domly: some were processed more than once, while others were not processed at all. Likewise, if the training\n",
            "\n",
            "--- Chunk 8948 ---\n",
            "set size is not a multiple of the batch size, we will miss a few instances. In practice that’s fine.\n",
            "\n",
            "--- Chunk 8949 ---\n",
            "14 With the exception of optimizers, as very few people ever customize these; see the “Custom Optimizers” sec‐\n",
            "tion in the notebook for an example.\n",
            "\n",
            "--- Chunk 8950 ---\n",
            "TensorFlow Functions and Graphs | 405\n",
            "\n",
            "--- Chunk 8951 ---\n",
            "We can obviously call this function with a Python value, such as an int or a float, or\n",
            "we can call it with a tensor:\n",
            "\n",
            "--- Chunk 8952 ---\n",
            ">>> cube(2)\n",
            "8\n",
            ">>> cube(tf.constant(2.0))\n",
            "<tf.Tensor: id=18634148, shape=(), dtype=float32, numpy=8.0>\n",
            "\n",
            "--- Chunk 8953 ---\n",
            "Now, let’s use tf.function() to convert this Python function to a TensorFlow\n",
            "Function:\n",
            "\n",
            "--- Chunk 8954 ---\n",
            ">>> tf_cube = tf.function(cube)\n",
            ">>> tf_cube\n",
            "<tensorflow.python.eager.def_function.Function at 0x1546fc080>\n",
            "\n",
            "--- Chunk 8955 ---\n",
            "This TF Function can then be used exactly like the original Python function, and it\n",
            "will return the same result (but as tensors):\n",
            "\n",
            "--- Chunk 8956 ---\n",
            ">>> tf_cube(2)\n",
            "<tf.Tensor: id=18634201, shape=(), dtype=int32, numpy=8>\n",
            ">>> tf_cube(tf.constant(2.0))\n",
            "\n",
            "--- Chunk 8957 ---\n",
            "<tf.Tensor: id=18634211, shape=(), dtype=float32, numpy=8.0>\n",
            "\n",
            "--- Chunk 8958 ---\n",
            "Under the hood, tf.function() analyzed the computations performed by the cube()\n",
            "\n",
            "--- Chunk 8959 ---\n",
            "function and generated an equivalent computation graph! As you can see, it was\n",
            "\n",
            "--- Chunk 8960 ---\n",
            "rather painless (we will see how this works shortly). Alternatively, we could have used\n",
            "tf.function as a decorator; this is actually more common:\n",
            "\n",
            "--- Chunk 8961 ---\n",
            "@tf.function\n",
            "def tf_cube(x):\n",
            "    return x ** 3\n",
            "\n",
            "--- Chunk 8962 ---\n",
            "The original Python function is still available via the TF Function’s python_function\n",
            "attribute, in case you ever need it:\n",
            "\n",
            "--- Chunk 8963 ---\n",
            ">>> tf_cube.python_function(2)\n",
            "8\n",
            "\n",
            "--- Chunk 8964 ---\n",
            "TensorFlow optimizes the computation graph, pruning unused nodes, simplifying\n",
            "\n",
            "--- Chunk 8965 ---\n",
            "expressions (e.g., 1 + 2 would get replaced with 3), and more. Once the optimized\n",
            "\n",
            "--- Chunk 8966 ---\n",
            "graph is ready, the TF Function efficiently executes the operations in the graph, in the\n",
            "\n",
            "--- Chunk 8967 ---\n",
            "appropriate order (and in parallel when it can). As a result, a TF Function will usually\n",
            "\n",
            "--- Chunk 8968 ---\n",
            "run much faster than the original Python function, especially if it performs complex\n",
            "\n",
            "--- Chunk 8969 ---\n",
            "computations.15 Most of the time you will not really need to know more than that:\n",
            "\n",
            "--- Chunk 8970 ---\n",
            "when you want to boost a Python function, just transform it into a TF Function.\n",
            "That’s all!\n",
            "\n",
            "--- Chunk 8971 ---\n",
            "15 However, in this trivial example, the computation graph is so small that there is nothing at all to optimize, so\n",
            "\n",
            "--- Chunk 8972 ---\n",
            "tf_cube() actually runs much slower than cube().\n",
            "\n",
            "--- Chunk 8973 ---\n",
            "406 | Chapter 12: Custom Models and Training with TensorFlow\n",
            "\n",
            "--- Chunk 8974 ---\n",
            "Moreover, when you write a custom loss function, a custom metric, a custom layer, or\n",
            "\n",
            "--- Chunk 8975 ---\n",
            "any other custom function and you use it in a Keras model (as we did throughout this\n",
            "\n",
            "--- Chunk 8976 ---\n",
            "chapter), Keras automatically converts your function into a TF Function—no need to\n",
            "\n",
            "--- Chunk 8977 ---\n",
            "use tf.function(). So most of the time, all this magic is 100% transparent.\n",
            "\n",
            "--- Chunk 8978 ---\n",
            "You can tell Keras not to convert your Python functions to TF\n",
            "Functions by setting dynamic=True when creating a custom layer\n",
            "\n",
            "--- Chunk 8979 ---\n",
            "or a custom model. Alternatively, you can set run_eagerly=True\n",
            "when calling the model’s compile() method.\n",
            "\n",
            "--- Chunk 8980 ---\n",
            "By default, a TF Function generates a new graph for every unique set of input shapes\n",
            "\n",
            "--- Chunk 8981 ---\n",
            "and data types and caches it for subsequent calls. For example, if you call\n",
            "\n",
            "--- Chunk 8982 ---\n",
            "tf_cube(tf.constant(10)), a graph will be generated for int32 tensors of shape [].\n",
            "\n",
            "--- Chunk 8983 ---\n",
            "Then if you call tf_cube(tf.constant(20)), the same graph will be reused. But if\n",
            "\n",
            "--- Chunk 8984 ---\n",
            "you then call tf_cube(tf.constant([10, 20])), a new graph will be generated for\n",
            "\n",
            "--- Chunk 8985 ---\n",
            "int32 tensors of shape [2]. This is how TF Functions handle polymorphism (i.e., vary‐\n",
            "\n",
            "--- Chunk 8986 ---\n",
            "ing argument types and shapes). However, this is only true for tensor arguments: if\n",
            "\n",
            "--- Chunk 8987 ---\n",
            "you pass numerical Python values to a TF Function, a new graph will be generated for\n",
            "\n",
            "--- Chunk 8988 ---\n",
            "every distinct value: for example, calling tf_cube(10) and tf_cube(20) will generate\n",
            "two graphs.\n",
            "\n",
            "--- Chunk 8989 ---\n",
            "If you call a TF Function many times with different numerical\n",
            "Python values, then many graphs will be generated, slowing down\n",
            "\n",
            "--- Chunk 8990 ---\n",
            "your program and using up a lot of RAM (you must delete the TF\n",
            "Function to release it). Python values should be reserved for argu‐\n",
            "\n",
            "--- Chunk 8991 ---\n",
            "ments that will have few unique values, such as hyperparameters\n",
            "like the number of neurons per layer. This allows TensorFlow to\n",
            "\n",
            "--- Chunk 8992 ---\n",
            "better optimize each variant of your model.\n",
            "\n",
            "--- Chunk 8993 ---\n",
            "AutoGraph and Tracing\n",
            "So how does TensorFlow generate graphs? It starts by analyzing the Python function’s\n",
            "\n",
            "--- Chunk 8994 ---\n",
            "source code to capture all the control flow statements, such as for loops, while loops,\n",
            "\n",
            "--- Chunk 8995 ---\n",
            "and if statements, as well as break, continue, and return statements. This first step\n",
            "\n",
            "--- Chunk 8996 ---\n",
            "is called AutoGraph. The reason TensorFlow has to analyze the source code is that\n",
            "\n",
            "--- Chunk 8997 ---\n",
            "Python does not provide any other way to capture control flow statements: it offers\n",
            "\n",
            "--- Chunk 8998 ---\n",
            "magic methods like __add__() and __mul__() to capture operators like + and *, but\n",
            "\n",
            "--- Chunk 8999 ---\n",
            "there are no __while__() or __if__() magic methods. After analyzing the function’s\n",
            "\n",
            "--- Chunk 9000 ---\n",
            "code, AutoGraph outputs an upgraded version of that function in which all the con‐\n",
            "\n",
            "--- Chunk 9001 ---\n",
            "trol flow statements are replaced by the appropriate TensorFlow operations, such as\n",
            "\n",
            "--- Chunk 9002 ---\n",
            "tf.while_loop() for loops and tf.cond() for if statements. For example, in\n",
            "\n",
            "--- Chunk 9003 ---\n",
            "Figure 12-4, AutoGraph analyzes the source code of the sum_squares() Python\n",
            "\n",
            "--- Chunk 9004 ---\n",
            "TensorFlow Functions and Graphs | 407\n",
            "\n",
            "--- Chunk 9005 ---\n",
            "function, and it generates the tf__sum_squares() function. In this function, the for\n",
            "\n",
            "--- Chunk 9006 ---\n",
            "loop is replaced by the definition of the loop_body() function (containing the body\n",
            "\n",
            "--- Chunk 9007 ---\n",
            "of the original for loop), followed by a call to the for_stmt() function. This call will\n",
            "\n",
            "--- Chunk 9008 ---\n",
            "build the appropriate tf.while_loop() operation in the computation graph.\n",
            "\n",
            "--- Chunk 9009 ---\n",
            "Figure 12-4. How TensorFlow generates graphs using AutoGraph and tracing\n",
            "\n",
            "--- Chunk 9010 ---\n",
            "Next, TensorFlow calls this “upgraded” function, but instead of passing the argument,\n",
            "\n",
            "--- Chunk 9011 ---\n",
            "it passes a symbolic tensor—a tensor without any actual value, only a name, a data\n",
            "\n",
            "--- Chunk 9012 ---\n",
            "type, and a shape. For example, if you call sum_squares(tf.constant(10)), then the\n",
            "\n",
            "--- Chunk 9013 ---\n",
            "tf__sum_squares() function will be called with a symbolic tensor of type int32 and\n",
            "\n",
            "--- Chunk 9014 ---\n",
            "shape []. The function will run in graph mode, meaning that each TensorFlow opera‐\n",
            "\n",
            "--- Chunk 9015 ---\n",
            "tion will add a node in the graph to represent itself and its output tensor(s) (as\n",
            "\n",
            "--- Chunk 9016 ---\n",
            "opposed to the regular mode, called eager execution, or eager mode). In graph mode,\n",
            "\n",
            "--- Chunk 9017 ---\n",
            "TF operations do not perform any computations. This should feel familiar if you\n",
            "\n",
            "--- Chunk 9018 ---\n",
            "know TensorFlow 1, as graph mode was the default mode. In Figure 12-4, you can see\n",
            "\n",
            "--- Chunk 9019 ---\n",
            "the tf__sum_squares() function being called with a symbolic tensor as its argument\n",
            "\n",
            "--- Chunk 9020 ---\n",
            "(in this case, an int32 tensor of shape []) and the final graph being generated during\n",
            "\n",
            "--- Chunk 9021 ---\n",
            "tracing. The nodes represent operations, and the arrows represent tensors (both the\n",
            "generated function and the graph are simplified).\n",
            "\n",
            "--- Chunk 9022 ---\n",
            "408 | Chapter 12: Custom Models and Training with TensorFlow\n",
            "\n",
            "--- Chunk 9023 ---\n",
            "To view the generated function’s source code, you can call tf.auto\n",
            "graph.to_code(sum_squares.python_function). The code is not\n",
            "\n",
            "--- Chunk 9024 ---\n",
            "meant to be pretty, but it can sometimes help for debugging.\n",
            "\n",
            "--- Chunk 9025 ---\n",
            "TF Function Rules\n",
            "Most of the time, converting a Python function that performs TensorFlow operations\n",
            "\n",
            "--- Chunk 9026 ---\n",
            "into a TF Function is trivial: decorate it with @tf.function or let Keras take care of it\n",
            "for you. However, there are a few rules to respect:\n",
            "\n",
            "--- Chunk 9027 ---\n",
            "• If you call any external library, including NumPy or even the standard library,\n",
            "\n",
            "--- Chunk 9028 ---\n",
            "this call will run only during tracing; it will not be part of the graph. Indeed, a\n",
            "\n",
            "--- Chunk 9029 ---\n",
            "TensorFlow graph can only include TensorFlow constructs (tensors, operations,\n",
            "\n",
            "--- Chunk 9030 ---\n",
            "variables, datasets, and so on). So, make sure you use tf.reduce_sum() instead\n",
            "\n",
            "--- Chunk 9031 ---\n",
            "of np.sum(), tf.sort() instead of the built-in sorted() function, and so on\n",
            "\n",
            "--- Chunk 9032 ---\n",
            "(unless you really want the code to run only during tracing). This has a few addi‐\n",
            "tional implications:\n",
            "\n",
            "--- Chunk 9033 ---\n",
            "— If you define a TF Function f(x) that just returns np.random.rand(), a ran‐\n",
            "\n",
            "--- Chunk 9034 ---\n",
            "dom number will only be generated when the function is traced, so f(tf.con\n",
            "stant(2.)) and f(tf.constant(3.)) will return the same random number,\n",
            "\n",
            "--- Chunk 9035 ---\n",
            "but f(tf.constant([2., 3.])) will return a different one. If you replace\n",
            "np.random.rand() with tf.random.uniform([]), then a new random num‐\n",
            "\n",
            "--- Chunk 9036 ---\n",
            "ber will be generated upon every call, since the operation will be part of the\n",
            "graph.\n",
            "\n",
            "--- Chunk 9037 ---\n",
            "— If your non-TensorFlow code has side effects (such as logging something or\n",
            "\n",
            "--- Chunk 9038 ---\n",
            "updating a Python counter), then you should not expect those side effects to\n",
            "\n",
            "--- Chunk 9039 ---\n",
            "occur every time you call the TF Function, as they will only occur when the\n",
            "function is traced.\n",
            "\n",
            "--- Chunk 9040 ---\n",
            "— You can wrap arbitrary Python code in a tf.py_function() operation, but\n",
            "doing so will hinder performance, as TensorFlow will not be able to do any\n",
            "\n",
            "--- Chunk 9041 ---\n",
            "graph optimization on this code. It will also reduce portability, as the graph\n",
            "\n",
            "--- Chunk 9042 ---\n",
            "will only run on platforms where Python is available (and where the right\n",
            "libraries are installed).\n",
            "\n",
            "--- Chunk 9043 ---\n",
            "• You can call other Python functions or TF Functions, but they should follow the\n",
            "\n",
            "--- Chunk 9044 ---\n",
            "same rules, as TensorFlow will capture their operations in the computation\n",
            "graph. Note that these other functions do not need to be decorated with\n",
            "\n",
            "--- Chunk 9045 ---\n",
            "@tf.function.\n",
            "\n",
            "--- Chunk 9046 ---\n",
            "• If the function creates a TensorFlow variable (or any other stateful TensorFlow\n",
            "\n",
            "--- Chunk 9047 ---\n",
            "object, such as a dataset or a queue), it must do so upon the very first call, and\n",
            "\n",
            "--- Chunk 9048 ---\n",
            "only then, or else you will get an exception. It is usually preferable to create\n",
            "\n",
            "--- Chunk 9049 ---\n",
            "TensorFlow Functions and Graphs | 409\n",
            "\n",
            "--- Chunk 9050 ---\n",
            "variables outside of the TF Function (e.g., in the build() method of a custom\n",
            "\n",
            "--- Chunk 9051 ---\n",
            "layer). If you want to assign a new value to the variable, make sure you call its\n",
            "assign() method, instead of using the = operator.\n",
            "\n",
            "--- Chunk 9052 ---\n",
            "• The source code of your Python function should be available to TensorFlow. If\n",
            "\n",
            "--- Chunk 9053 ---\n",
            "the source code is unavailable (for example, if you define your function in the\n",
            "\n",
            "--- Chunk 9054 ---\n",
            "Python shell, which does not give access to the source code, or if you deploy only\n",
            "\n",
            "--- Chunk 9055 ---\n",
            "the compiled *.pyc Python files to production), then the graph generation process\n",
            "will fail or have limited functionality.\n",
            "\n",
            "--- Chunk 9056 ---\n",
            "• TensorFlow will only capture for loops that iterate over a tensor or a dataset. So\n",
            "\n",
            "--- Chunk 9057 ---\n",
            "make sure you use for i in tf.range(x) rather than for i in range(x), or\n",
            "\n",
            "--- Chunk 9058 ---\n",
            "else the loop will not be captured in the graph. Instead, it will run during tracing.\n",
            "\n",
            "--- Chunk 9059 ---\n",
            "(This may be what you want if the for loop is meant to build the graph, for\n",
            "example to create each layer in a neural network.)\n",
            "\n",
            "--- Chunk 9060 ---\n",
            "• As always, for performance reasons, you should prefer a vectorized implementa‐\n",
            "tion whenever you can, rather than using loops.\n",
            "\n",
            "--- Chunk 9061 ---\n",
            "It’s time to sum up! In this chapter we started with a brief overview of TensorFlow,\n",
            "\n",
            "--- Chunk 9062 ---\n",
            "then we looked at TensorFlow’s low-level API, including tensors, operations, vari‐\n",
            "\n",
            "--- Chunk 9063 ---\n",
            "ables, and special data structures. We then used these tools to customize almost every\n",
            "\n",
            "--- Chunk 9064 ---\n",
            "component in tf.keras. Finally, we looked at how TF Functions can boost perfor‐\n",
            "\n",
            "--- Chunk 9065 ---\n",
            "mance, how graphs are generated using AutoGraph and tracing, and what rules to\n",
            "\n",
            "--- Chunk 9066 ---\n",
            "follow when you write TF Functions (if you would like to open the black box a bit\n",
            "\n",
            "--- Chunk 9067 ---\n",
            "further, for example to explore the generated graphs, you will find technical details in\n",
            "Appendix G).\n",
            "\n",
            "--- Chunk 9068 ---\n",
            "Appendix G).\n",
            "In the next chapter, we will look at how to efficiently load and preprocess data with\n",
            "TensorFlow.\n",
            "\n",
            "--- Chunk 9069 ---\n",
            "Exercises\n",
            "1. How would you describe TensorFlow in a short sentence? What are its main fea‐\n",
            "\n",
            "--- Chunk 9070 ---\n",
            "tures? Can you name other popular Deep Learning libraries?\n",
            "2. Is TensorFlow a drop-in replacement for NumPy? What are the main differences\n",
            "\n",
            "--- Chunk 9071 ---\n",
            "between the two?\n",
            "3. Do you get the same result with tf.range(10) and tf.constant(np.ara\n",
            "\n",
            "--- Chunk 9072 ---\n",
            "nge(10))?\n",
            "4. Can you name six other data structures available in TensorFlow, beyond regular\n",
            "\n",
            "tensors?\n",
            "\n",
            "--- Chunk 9073 ---\n",
            "tensors?\n",
            "\n",
            "410 | Chapter 12: Custom Models and Training with TensorFlow\n",
            "\n",
            "--- Chunk 9074 ---\n",
            "5. A custom loss function can be defined by writing a function or by subclassing the\n",
            "keras.losses.Loss class. When would you use each option?\n",
            "\n",
            "--- Chunk 9075 ---\n",
            "6. Similarly, a custom metric can be defined in a function or a subclass of\n",
            "keras.metrics.Metric. When would you use each option?\n",
            "\n",
            "--- Chunk 9076 ---\n",
            "7. When should you create a custom layer versus a custom model?\n",
            "8. What are some use cases that require writing your own custom training loop?\n",
            "\n",
            "--- Chunk 9077 ---\n",
            "9. Can custom Keras components contain arbitrary Python code, or must they be\n",
            "\n",
            "--- Chunk 9078 ---\n",
            "convertible to TF Functions?\n",
            "10. What are the main rules to respect if you want a function to be convertible to a\n",
            "\n",
            "--- Chunk 9079 ---\n",
            "TF Function?\n",
            "11. When would you need to create a dynamic Keras model? How do you do that?\n",
            "\n",
            "--- Chunk 9080 ---\n",
            "Why not make all your models dynamic?\n",
            "12. Implement a custom layer that performs Layer Normalization (we will use this\n",
            "\n",
            "--- Chunk 9081 ---\n",
            "type of layer in Chapter 15):\n",
            "a. The build() method should define two trainable weights α and β, both of\n",
            "\n",
            "--- Chunk 9082 ---\n",
            "shape input_shape[-1:] and data type tf.float32. α should be initialized\n",
            "with 1s, and β with 0s.\n",
            "\n",
            "--- Chunk 9083 ---\n",
            "b. The call() method should compute the mean μ and standard deviation σ of\n",
            "each instance’s features. For this, you can use tf.nn.moments(inputs,\n",
            "\n",
            "--- Chunk 9084 ---\n",
            "axes=-1, keepdims=True), which returns the mean μ and the variance σ2 of\n",
            "all instances (compute the square root of the variance to get the standard\n",
            "\n",
            "--- Chunk 9085 ---\n",
            "deviation). Then the function should compute and return α⊗(X - μ)/(σ + ε) +\n",
            "\n",
            "--- Chunk 9086 ---\n",
            "β, where ⊗ represents itemwise multiplication (*) and ε is a smoothing term\n",
            "(small constant to avoid division by zero, e.g., 0.001).\n",
            "\n",
            "--- Chunk 9087 ---\n",
            "c. Ensure that your custom layer produces the same (or very nearly the same)\n",
            "output as the keras.layers.LayerNormalization layer.\n",
            "\n",
            "--- Chunk 9088 ---\n",
            "13. Train a model using a custom training loop to tackle the Fashion MNIST dataset\n",
            "(see Chapter 10).\n",
            "\n",
            "--- Chunk 9089 ---\n",
            "(see Chapter 10).\n",
            "a. Display the epoch, iteration, mean training loss, and mean accuracy over each\n",
            "\n",
            "--- Chunk 9090 ---\n",
            "epoch (updated at each iteration), as well as the validation loss and accuracy at\n",
            "the end of each epoch.\n",
            "\n",
            "--- Chunk 9091 ---\n",
            "b. Try using a different optimizer with a different learning rate for the upper lay‐\n",
            "ers and the lower layers.\n",
            "\n",
            "--- Chunk 9092 ---\n",
            "Solutions to these exercises are available in Appendix A.\n",
            "\n",
            "Exercises | 411\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER 13\n",
            "Loading and Preprocessing Data\n",
            "\n",
            "with TensorFlow\n",
            "\n",
            "--- Chunk 9093 ---\n",
            "So far we have used only datasets that fit in memory, but Deep Learning systems are\n",
            "\n",
            "--- Chunk 9094 ---\n",
            "often trained on very large datasets that will not fit in RAM. Ingesting a large dataset\n",
            "\n",
            "--- Chunk 9095 ---\n",
            "and preprocessing it efficiently can be tricky to implement with other Deep Learning\n",
            "\n",
            "--- Chunk 9096 ---\n",
            "libraries, but TensorFlow makes it easy thanks to the Data API: you just create a data‐\n",
            "\n",
            "--- Chunk 9097 ---\n",
            "set object, and tell it where to get the data and how to transform it. TensorFlow takes\n",
            "\n",
            "--- Chunk 9098 ---\n",
            "care of all the implementation details, such as multithreading, queuing, batching, and\n",
            "\n",
            "--- Chunk 9099 ---\n",
            "prefetching. Moreover, the Data API works seamlessly with tf.keras!\n",
            "\n",
            "--- Chunk 9100 ---\n",
            "Off the shelf, the Data API can read from text files (such as CSV files), binary files\n",
            "\n",
            "--- Chunk 9101 ---\n",
            "with fixed-size records, and binary files that use TensorFlow’s TFRecord format,\n",
            "\n",
            "--- Chunk 9102 ---\n",
            "which supports records of varying sizes. TFRecord is a flexible and efficient binary\n",
            "\n",
            "--- Chunk 9103 ---\n",
            "format usually containing protocol buffers (an open source binary format). The Data\n",
            "\n",
            "--- Chunk 9104 ---\n",
            "API also has support for reading from SQL databases. Moreover, many open source\n",
            "\n",
            "--- Chunk 9105 ---\n",
            "extensions are available to read from all sorts of data sources, such as Google’s Big‐\n",
            "Query service.\n",
            "\n",
            "--- Chunk 9106 ---\n",
            "Query service.\n",
            "Reading huge datasets efficiently is not the only difficulty: the data also needs to be\n",
            "\n",
            "--- Chunk 9107 ---\n",
            "preprocessed, usually normalized. Moreover, it is not always composed strictly of\n",
            "\n",
            "--- Chunk 9108 ---\n",
            "convenient numerical fields: there may be text features, categorical features, and so\n",
            "\n",
            "--- Chunk 9109 ---\n",
            "on. These need to be encoded, for example using one-hot encoding, bag-of-words\n",
            "\n",
            "--- Chunk 9110 ---\n",
            "encoding, or embeddings (as we will see, an embedding is a trainable dense vector that\n",
            "\n",
            "--- Chunk 9111 ---\n",
            "represents a category or token). One option to handle all this preprocessing is to\n",
            "\n",
            "--- Chunk 9112 ---\n",
            "write your own custom preprocessing layers. Another is to use the standard prepro‐\n",
            "cessing layers provided by Keras.\n",
            "\n",
            "--- Chunk 9113 ---\n",
            "Loading and Preprocessing Data with TensorFlow | 413\n",
            "\n",
            "--- Chunk 9114 ---\n",
            "In this chapter, we will cover the Data API, the TFRecord format, and how to create\n",
            "\n",
            "--- Chunk 9115 ---\n",
            "custom preprocessing layers and use the standard Keras ones. We will also take a\n",
            "quick look at a few related projects from TensorFlow’s ecosystem:\n",
            "\n",
            "--- Chunk 9116 ---\n",
            "TF Transform (tf.Transform)\n",
            "\n",
            "--- Chunk 9117 ---\n",
            "Makes it possible to write a single preprocessing function that can be run in\n",
            "\n",
            "--- Chunk 9118 ---\n",
            "batch mode on your full training set, before training (to speed it up), and then\n",
            "\n",
            "--- Chunk 9119 ---\n",
            "exported to a TF Function and incorporated into your trained model so that once\n",
            "\n",
            "--- Chunk 9120 ---\n",
            "it is deployed in production it can take care of preprocessing new instances on\n",
            "the fly.\n",
            "\n",
            "--- Chunk 9121 ---\n",
            "TF Datasets (TFDS)\n",
            "Provides a convenient function to download many common datasets of all kinds,\n",
            "\n",
            "--- Chunk 9122 ---\n",
            "including large ones like ImageNet, as well as convenient dataset objects to\n",
            "manipulate them using the Data API.\n",
            "\n",
            "--- Chunk 9123 ---\n",
            "So let’s get started!\n",
            "\n",
            "--- Chunk 9124 ---\n",
            "The Data API\n",
            "The whole Data API revolves around the concept of a dataset: as you might suspect,\n",
            "\n",
            "--- Chunk 9125 ---\n",
            "this represents a sequence of data items. Usually you will use datasets that gradually\n",
            "\n",
            "--- Chunk 9126 ---\n",
            "read data from disk, but for simplicity let’s create a dataset entirely in RAM using\n",
            "tf.data.Dataset.from_tensor_slices():\n",
            "\n",
            "--- Chunk 9127 ---\n",
            ">>> X = tf.range(10)  # any data tensor\n",
            ">>> dataset = tf.data.Dataset.from_tensor_slices(X)\n",
            ">>> dataset\n",
            "\n",
            "--- Chunk 9128 ---\n",
            ">>> dataset\n",
            "<TensorSliceDataset shapes: (), types: tf.int32>\n",
            "\n",
            "--- Chunk 9129 ---\n",
            "The from_tensor_slices() function takes a tensor and creates a tf.data.Dataset\n",
            "\n",
            "--- Chunk 9130 ---\n",
            "whose elements are all the slices of X (along the first dimension), so this dataset con‐\n",
            "\n",
            "--- Chunk 9131 ---\n",
            "tains 10 items: tensors 0, 1, 2, …, 9. In this case we would have obtained the same\n",
            "dataset if we had used tf.data.Dataset.range(10).\n",
            "\n",
            "--- Chunk 9132 ---\n",
            "You can simply iterate over a dataset’s items like this:\n",
            "\n",
            "--- Chunk 9133 ---\n",
            ">>> for item in dataset:\n",
            "...     print(item)\n",
            "...\n",
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "\n",
            "--- Chunk 9134 ---\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "[...]\n",
            "tf.Tensor(9, shape=(), dtype=int32)\n",
            "\n",
            "--- Chunk 9135 ---\n",
            "414 | Chapter 13: Loading and Preprocessing Data with TensorFlow\n",
            "\n",
            "--- Chunk 9136 ---\n",
            "Chaining Transformations\n",
            "Once you have a dataset, you can apply all sorts of transformations to it by calling its\n",
            "\n",
            "--- Chunk 9137 ---\n",
            "transformation methods. Each method returns a new dataset, so you can chain trans‐\n",
            "formations like this (this chain is illustrated in Figure 13-1):\n",
            "\n",
            "--- Chunk 9138 ---\n",
            ">>> dataset = dataset.repeat(3).batch(7)\n",
            ">>> for item in dataset:\n",
            "...     print(item)\n",
            "...\n",
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
            "\n",
            "--- Chunk 9139 ---\n",
            "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
            "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
            "\n",
            "--- Chunk 9140 ---\n",
            "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
            "tf.Tensor([8 9], shape=(2,), dtype=int32)\n",
            "\n",
            "--- Chunk 9141 ---\n",
            "Figure 13-1. Chaining dataset transformations\n",
            "\n",
            "--- Chunk 9142 ---\n",
            "In this example, we first call the repeat() method on the original dataset, and it\n",
            "\n",
            "--- Chunk 9143 ---\n",
            "returns a new dataset that will repeat the items of the original dataset three times. Of\n",
            "\n",
            "--- Chunk 9144 ---\n",
            "course, this will not copy all the data in memory three times! (If you call this method\n",
            "\n",
            "--- Chunk 9145 ---\n",
            "with no arguments, the new dataset will repeat the source dataset forever, so the code\n",
            "\n",
            "--- Chunk 9146 ---\n",
            "that iterates over the dataset will have to decide when to stop.) Then we call the\n",
            "\n",
            "--- Chunk 9147 ---\n",
            "batch() method on this new dataset, and again this creates a new dataset. This one\n",
            "\n",
            "--- Chunk 9148 ---\n",
            "will group the items of the previous dataset in batches of seven items. Finally, we iter‐\n",
            "\n",
            "--- Chunk 9149 ---\n",
            "ate over the items of this final dataset. As you can see, the batch() method had to\n",
            "\n",
            "--- Chunk 9150 ---\n",
            "output a final batch of size two instead of seven, but you can call it with drop_remain\n",
            "\n",
            "--- Chunk 9151 ---\n",
            "der=True if you want it to drop this final batch so that all batches have the exact same\n",
            "size.\n",
            "\n",
            "--- Chunk 9152 ---\n",
            "The Data API | 415\n",
            "\n",
            "--- Chunk 9153 ---\n",
            "The dataset methods do not modify datasets, they create new ones,\n",
            "so make sure to keep a reference to these new datasets (e.g., with\n",
            "\n",
            "--- Chunk 9154 ---\n",
            "dataset = ...), or else nothing will happen.\n",
            "\n",
            "--- Chunk 9155 ---\n",
            "You can also transform the items by calling the map() method. For example, this cre‐\n",
            "ates a new dataset with all items doubled:\n",
            "\n",
            "--- Chunk 9156 ---\n",
            ">>> dataset = dataset.map(lambda x: x * 2) # Items: [0,2,4,6,8,10,12]\n",
            "\n",
            "--- Chunk 9157 ---\n",
            "This function is the one you will call to apply any preprocessing you want to your\n",
            "\n",
            "--- Chunk 9158 ---\n",
            "data. Sometimes this will include computations that can be quite intensive, such as\n",
            "\n",
            "--- Chunk 9159 ---\n",
            "reshaping or rotating an image, so you will usually want to spawn multiple threads to\n",
            "\n",
            "--- Chunk 9160 ---\n",
            "speed things up: it’s as simple as setting the num_parallel_calls argument. Note that\n",
            "\n",
            "--- Chunk 9161 ---\n",
            "the function you pass to the map() method must be convertible to a TF Function (see\n",
            "Chapter 12).\n",
            "\n",
            "--- Chunk 9162 ---\n",
            "Chapter 12).\n",
            "While the map() method applies a transformation to each item, the apply() method\n",
            "\n",
            "--- Chunk 9163 ---\n",
            "applies a transformation to the dataset as a whole. For example, the following code\n",
            "\n",
            "--- Chunk 9164 ---\n",
            "applies the unbatch() function to the dataset (this function is currently experimental,\n",
            "\n",
            "--- Chunk 9165 ---\n",
            "but it will most likely move to the core API in a future release). Each item in the new\n",
            "\n",
            "--- Chunk 9166 ---\n",
            "dataset will be a single-integer tensor instead of a batch of seven integers:\n",
            "\n",
            "--- Chunk 9167 ---\n",
            ">>> dataset = dataset.apply(tf.data.experimental.unbatch()) # Items: 0,2,4,...\n",
            "\n",
            "--- Chunk 9168 ---\n",
            "It is also possible to simply filter the dataset using the filter() method:\n",
            "\n",
            "--- Chunk 9169 ---\n",
            ">>> dataset = dataset.filter(lambda x: x < 10) # Items: 0 2 4 6 8 0 2 4 6...\n",
            "\n",
            "--- Chunk 9170 ---\n",
            "You will often want to look at just a few items from a dataset. You can use the take()\n",
            "method for that:\n",
            "\n",
            "--- Chunk 9171 ---\n",
            ">>> for item in dataset.take(3):\n",
            "...     print(item)\n",
            "...\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "\n",
            "--- Chunk 9172 ---\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "\n",
            "--- Chunk 9173 ---\n",
            "Shuffling the Data\n",
            "As you know, Gradient Descent works best when the instances in the training set are\n",
            "\n",
            "--- Chunk 9174 ---\n",
            "independent and identically distributed (see Chapter 4). A simple way to ensure this\n",
            "\n",
            "--- Chunk 9175 ---\n",
            "is to shuffle the instances, using the shuffle() method. It will create a new dataset\n",
            "\n",
            "--- Chunk 9176 ---\n",
            "that will start by filling up a buffer with the first items of the source dataset. Then,\n",
            "\n",
            "--- Chunk 9177 ---\n",
            "whenever it is asked for an item, it will pull one out randomly from the buffer and\n",
            "\n",
            "--- Chunk 9178 ---\n",
            "replace it with a fresh one from the source dataset, until it has iterated entirely\n",
            "\n",
            "--- Chunk 9179 ---\n",
            "through the source dataset. At this point it continues to pull out items randomly from\n",
            "\n",
            "--- Chunk 9180 ---\n",
            "416 | Chapter 13: Loading and Preprocessing Data with TensorFlow\n",
            "\n",
            "--- Chunk 9181 ---\n",
            "the buffer until it is empty. You must specify the buffer size, and it is important to\n",
            "\n",
            "--- Chunk 9182 ---\n",
            "make it large enough, or else shuffling will not be very effective.1 Just don’t exceed the\n",
            "\n",
            "--- Chunk 9183 ---\n",
            "amount of RAM you have, and even if you have plenty of it, there’s no need to go\n",
            "\n",
            "--- Chunk 9184 ---\n",
            "beyond the dataset’s size. You can provide a random seed if you want the same ran‐\n",
            "\n",
            "--- Chunk 9185 ---\n",
            "dom order every time you run your program. For example, the following code creates\n",
            "\n",
            "--- Chunk 9186 ---\n",
            "and displays a dataset containing the integers 0 to 9, repeated 3 times, shuffled using a\n",
            "\n",
            "--- Chunk 9187 ---\n",
            "buffer of size 5 and a random seed of 42, and batched with a batch size of 7:\n",
            "\n",
            "--- Chunk 9188 ---\n",
            ">>> dataset = tf.data.Dataset.range(10).repeat(3) # 0 to 9, three times\n",
            ">>> dataset = dataset.shuffle(buffer_size=5, seed=42).batch(7)\n",
            "\n",
            "--- Chunk 9189 ---\n",
            ">>> for item in dataset:\n",
            "...     print(item)\n",
            "...\n",
            "tf.Tensor([0 2 3 6 7 9 4], shape=(7,), dtype=int64)\n",
            "\n",
            "--- Chunk 9190 ---\n",
            "tf.Tensor([5 0 1 1 8 6 5], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4 8 7 1 2 3 0], shape=(7,), dtype=int64)\n",
            "\n",
            "--- Chunk 9191 ---\n",
            "tf.Tensor([5 4 2 7 8 9 9], shape=(7,), dtype=int64)\n",
            "tf.Tensor([3 6], shape=(2,), dtype=int64)\n",
            "\n",
            "--- Chunk 9192 ---\n",
            "If you call repeat() on a shuffled dataset, by default it will generate\n",
            "a new order at every iteration. This is generally a good idea, but if\n",
            "\n",
            "--- Chunk 9193 ---\n",
            "you prefer to reuse the same order at each iteration (e.g., for tests\n",
            "or debugging), you can set reshuffle_each_iteration=False.\n",
            "\n",
            "--- Chunk 9194 ---\n",
            "For a large dataset that does not fit in memory, this simple shuffling-buffer approach\n",
            "\n",
            "--- Chunk 9195 ---\n",
            "may not be sufficient, since the buffer will be small compared to the dataset. One sol‐\n",
            "\n",
            "--- Chunk 9196 ---\n",
            "ution is to shuffle the source data itself (for example, on Linux you can shuffle text\n",
            "\n",
            "--- Chunk 9197 ---\n",
            "files using the shuf command). This will definitely improve shuffling a lot! Even if\n",
            "\n",
            "--- Chunk 9198 ---\n",
            "the source data is shuffled, you will usually want to shuffle it some more, or else the\n",
            "\n",
            "--- Chunk 9199 ---\n",
            "same order will be repeated at each epoch, and the model may end up being biased\n",
            "\n",
            "--- Chunk 9200 ---\n",
            "(e.g., due to some spurious patterns present by chance in the source data’s order). To\n",
            "\n",
            "--- Chunk 9201 ---\n",
            "shuffle the instances some more, a common approach is to split the source data into\n",
            "\n",
            "--- Chunk 9202 ---\n",
            "multiple files, then read them in a random order during training. However, instances\n",
            "\n",
            "--- Chunk 9203 ---\n",
            "located in the same file will still end up close to each other. To avoid this you can pick\n",
            "\n",
            "--- Chunk 9204 ---\n",
            "multiple files randomly and read them simultaneously, interleaving their records.\n",
            "\n",
            "--- Chunk 9205 ---\n",
            "Then on top of that you can add a shuffling buffer using the shuffle() method. If all\n",
            "\n",
            "--- Chunk 9206 ---\n",
            "1 Imagine a sorted deck of cards on your left: suppose you just take the top three cards and shuffle them, then\n",
            "\n",
            "--- Chunk 9207 ---\n",
            "pick one randomly and put it to your right, keeping the other two in your hands. Take another card on your\n",
            "\n",
            "--- Chunk 9208 ---\n",
            "left, shuffle the three cards in your hands and pick one of them randomly, and put it on your right. When you\n",
            "\n",
            "--- Chunk 9209 ---\n",
            "are done going through all the cards like this, you will have a deck of cards on your right: do you think it will\n",
            "be perfectly shuffled?\n",
            "\n",
            "--- Chunk 9210 ---\n",
            "The Data API | 417\n",
            "\n",
            "--- Chunk 9211 ---\n",
            "this sounds like a lot of work, don’t worry: the Data API makes all this possible in just\n",
            "a few lines of code. Let’s see how to do this.\n",
            "\n",
            "--- Chunk 9212 ---\n",
            "Interleaving lines from multiple files\n",
            "First, let’s suppose that you’ve loaded the California housing dataset, shuffled it\n",
            "\n",
            "--- Chunk 9213 ---\n",
            "(unless it was already shuffled), and split it into a training set, a validation set, and a\n",
            "\n",
            "--- Chunk 9214 ---\n",
            "test set. Then you split each set into many CSV files that each look like this (each row\n",
            "\n",
            "--- Chunk 9215 ---\n",
            "contains eight input features plus the target median house value):\n",
            "\n",
            "--- Chunk 9216 ---\n",
            "MedInc,HouseAge,AveRooms,AveBedrms,Popul,AveOccup,Lat,Long,MedianHouseValue\n",
            "3.5214,15.0,3.0499,1.1065,1447.0,1.6059,37.63,-122.43,1.442\n",
            "\n",
            "--- Chunk 9217 ---\n",
            "5.3275,5.0,6.4900,0.9910,3464.0,3.4433,33.69,-117.39,1.687\n",
            "3.1,29.0,7.5423,1.5915,1328.0,2.2508,38.44,-122.98,1.621\n",
            "[...]\n",
            "\n",
            "--- Chunk 9218 ---\n",
            "Let’s also suppose train_filepaths contains the list of training file paths (and you\n",
            "also have valid_filepaths and test_filepaths):\n",
            "\n",
            "--- Chunk 9219 ---\n",
            ">>> train_filepaths\n",
            "['datasets/housing/my_train_00.csv', 'datasets/housing/my_train_01.csv',...]\n",
            "\n",
            "--- Chunk 9220 ---\n",
            "Alternatively, you could use file patterns; for example, train_filepaths = \"data\n",
            "\n",
            "--- Chunk 9221 ---\n",
            "sets/housing/my_train_*.csv\". Now let’s create a dataset containing only these file\n",
            "paths:\n",
            "\n",
            "--- Chunk 9222 ---\n",
            "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)\n",
            "\n",
            "--- Chunk 9223 ---\n",
            "By default, the list_files() function returns a dataset that shuffles the file paths. In\n",
            "\n",
            "--- Chunk 9224 ---\n",
            "general this is a good thing, but you can set shuffle=False if you do not want that\n",
            "for some reason.\n",
            "\n",
            "--- Chunk 9225 ---\n",
            "for some reason.\n",
            "Next, you can call the interleave() method to read from five files at a time and\n",
            "\n",
            "--- Chunk 9226 ---\n",
            "interleave their lines (skipping the first line of each file, which is the header row,\n",
            "using the skip() method):\n",
            "\n",
            "--- Chunk 9227 ---\n",
            "n_readers = 5\n",
            "dataset = filepath_dataset.interleave(\n",
            "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
            "    cycle_length=n_readers)\n",
            "\n",
            "--- Chunk 9228 ---\n",
            "The interleave() method will create a dataset that will pull five file paths from the\n",
            "\n",
            "--- Chunk 9229 ---\n",
            "filepath_dataset, and for each one it will call the function you gave it (a lambda in\n",
            "\n",
            "--- Chunk 9230 ---\n",
            "this example) to create a new dataset (in this case a TextLineDataset). To be clear, at\n",
            "\n",
            "--- Chunk 9231 ---\n",
            "this stage there will be seven datasets in all: the filepath dataset, the interleave dataset,\n",
            "\n",
            "--- Chunk 9232 ---\n",
            "and the five TextLineDatasets created internally by the interleave dataset. When we\n",
            "\n",
            "--- Chunk 9233 ---\n",
            "iterate over the interleave dataset, it will cycle through these five TextLineDatasets,\n",
            "\n",
            "--- Chunk 9234 ---\n",
            "reading one line at a time from each until all datasets are out of items. Then it will get\n",
            "\n",
            "--- Chunk 9235 ---\n",
            "418 | Chapter 13: Loading and Preprocessing Data with TensorFlow\n",
            "\n",
            "--- Chunk 9236 ---\n",
            "the next five file paths from the filepath_dataset and interleave them the same way,\n",
            "and so on until it runs out of file paths.\n",
            "\n",
            "--- Chunk 9237 ---\n",
            "For interleaving to work best, it is preferable to have files of identi‐\n",
            "cal length; otherwise the ends of the longest files will not be inter‐\n",
            "\n",
            "--- Chunk 9238 ---\n",
            "leaved.\n",
            "\n",
            "--- Chunk 9239 ---\n",
            "By default, interleave() does not use parallelism; it just reads one line at a time\n",
            "\n",
            "--- Chunk 9240 ---\n",
            "from each file, sequentially. If you want it to actually read files in parallel, you can set\n",
            "\n",
            "--- Chunk 9241 ---\n",
            "the num_parallel_calls argument to the number of threads you want (note that the\n",
            "\n",
            "--- Chunk 9242 ---\n",
            "map() method also has this argument). You can even set it to tf.data.experimen\n",
            "\n",
            "--- Chunk 9243 ---\n",
            "tal.AUTOTUNE to make TensorFlow choose the right number of threads dynamically\n",
            "\n",
            "--- Chunk 9244 ---\n",
            "based on the available CPU (however, this is an experimental feature for now). Let’s\n",
            "look at what the dataset contains now:\n",
            "\n",
            "--- Chunk 9245 ---\n",
            ">>> for line in dataset.take(5):\n",
            "...     print(line.numpy())\n",
            "...\n",
            "b'4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782'\n",
            "\n",
            "--- Chunk 9246 ---\n",
            "b'4.1812,52.0,5.7013,0.9965,692.0,2.4027,33.73,-118.31,3.215'\n",
            "b'3.6875,44.0,4.5244,0.9930,457.0,3.1958,34.04,-118.15,1.625'\n",
            "\n",
            "--- Chunk 9247 ---\n",
            "b'3.3456,37.0,4.5140,0.9084,458.0,3.2253,36.67,-121.7,2.526'\n",
            "b'3.5214,15.0,3.0499,1.1065,1447.0,1.6059,37.63,-122.43,1.442'\n",
            "\n",
            "--- Chunk 9248 ---\n",
            "These are the first rows (ignoring the header row) of five CSV files, chosen randomly.\n",
            "\n",
            "--- Chunk 9249 ---\n",
            "Looks good! But as you can see, these are just byte strings; we need to parse them and\n",
            "scale the data.\n",
            "\n",
            "--- Chunk 9250 ---\n",
            "Preprocessing the Data\n",
            "Let’s implement a small function that will perform this preprocessing:\n",
            "\n",
            "--- Chunk 9251 ---\n",
            "X_mean, X_std = [...] # mean and scale of each feature in the training set\n",
            "n_inputs = 8\n",
            "\n",
            "--- Chunk 9252 ---\n",
            "def preprocess(line):\n",
            "  defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
            "  fields = tf.io.decode_csv(line, record_defaults=defs)\n",
            "\n",
            "--- Chunk 9253 ---\n",
            "x = tf.stack(fields[:-1])\n",
            "  y = tf.stack(fields[-1:])\n",
            "  return (x - X_mean) / X_std, y\n",
            "\n",
            "--- Chunk 9254 ---\n",
            "Let’s walk through this code:\n",
            "\n",
            "The Data API | 419\n",
            "\n",
            "--- Chunk 9255 ---\n",
            "• First, the code assumes that we have precomputed the mean and standard devia‐\n",
            "\n",
            "--- Chunk 9256 ---\n",
            "tion of each feature in the training set. X_mean and X_std are just 1D tensors (or\n",
            "NumPy arrays) containing eight floats, one per input feature.\n",
            "\n",
            "--- Chunk 9257 ---\n",
            "• The preprocess() function takes one CSV line and starts by parsing it. For this\n",
            "\n",
            "--- Chunk 9258 ---\n",
            "it uses the tf.io.decode_csv() function, which takes two arguments: the first is\n",
            "\n",
            "--- Chunk 9259 ---\n",
            "the line to parse, and the second is an array containing the default value for each\n",
            "\n",
            "--- Chunk 9260 ---\n",
            "column in the CSV file. This array tells TensorFlow not only the default value for\n",
            "\n",
            "--- Chunk 9261 ---\n",
            "each column, but also the number of columns and their types. In this example,\n",
            "\n",
            "--- Chunk 9262 ---\n",
            "we tell it that all feature columns are floats and that missing values should default\n",
            "\n",
            "--- Chunk 9263 ---\n",
            "to 0, but we provide an empty array of type tf.float32 as the default value for\n",
            "\n",
            "--- Chunk 9264 ---\n",
            "the last column (the target): the array tells TensorFlow that this column contains\n",
            "\n",
            "--- Chunk 9265 ---\n",
            "floats, but that there is no default value, so it will raise an exception if it encoun‐\n",
            "ters a missing value.\n",
            "\n",
            "--- Chunk 9266 ---\n",
            "• The decode_csv() function returns a list of scalar tensors (one per column), but\n",
            "\n",
            "--- Chunk 9267 ---\n",
            "we need to return 1D tensor arrays. So we call tf.stack() on all tensors except\n",
            "\n",
            "--- Chunk 9268 ---\n",
            "for the last one (the target): this will stack these tensors into a 1D array. We then\n",
            "\n",
            "--- Chunk 9269 ---\n",
            "do the same for the target value (this makes it a 1D tensor array with a single\n",
            "value, rather than a scalar tensor).\n",
            "\n",
            "--- Chunk 9270 ---\n",
            "• Finally, we scale the input features by subtracting the feature means and then\n",
            "\n",
            "--- Chunk 9271 ---\n",
            "dividing by the feature standard deviations, and we return a tuple containing the\n",
            "scaled features and the target.\n",
            "\n",
            "--- Chunk 9272 ---\n",
            "Let’s test this preprocessing function:\n",
            ">>> preprocess(b'4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782')\n",
            "\n",
            "--- Chunk 9273 ---\n",
            "(<tf.Tensor: id=6227, shape=(8,), dtype=float32, numpy=\n",
            " array([ 0.16579159,  1.216324  , -0.05204564, -0.39215982, -0.5277444 ,\n",
            "\n",
            "--- Chunk 9274 ---\n",
            "-0.2633488 ,  0.8543046 , -1.3072058 ], dtype=float32)>,\n",
            " <tf.Tensor: [...], numpy=array([2.782], dtype=float32)>)\n",
            "\n",
            "--- Chunk 9275 ---\n",
            "Looks good! We can now apply the function to the dataset.\n",
            "\n",
            "--- Chunk 9276 ---\n",
            "Putting Everything Together\n",
            "To make the code reusable, let’s put together everything we have discussed so far into\n",
            "\n",
            "--- Chunk 9277 ---\n",
            "a small helper function: it will create and return a dataset that will efficiently load Cal‐\n",
            "\n",
            "--- Chunk 9278 ---\n",
            "ifornia housing data from multiple CSV files, preprocess it, shuffle it, optionally\n",
            "repeat it, and batch it (see Figure 13-2):\n",
            "\n",
            "--- Chunk 9279 ---\n",
            "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
            "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
            "\n",
            "--- Chunk 9280 ---\n",
            "n_parse_threads=5, batch_size=32):\n",
            "    dataset = tf.data.Dataset.list_files(filepaths)\n",
            "    dataset = dataset.interleave(\n",
            "\n",
            "--- Chunk 9281 ---\n",
            "lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
            "\n",
            "--- Chunk 9282 ---\n",
            "420 | Chapter 13: Loading and Preprocessing Data with TensorFlow\n",
            "\n",
            "--- Chunk 9283 ---\n",
            "cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
            "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
            "\n",
            "--- Chunk 9284 ---\n",
            "dataset = dataset.shuffle(shuffle_buffer_size).repeat(repeat)\n",
            "    return dataset.batch(batch_size).prefetch(1)\n",
            "\n",
            "--- Chunk 9285 ---\n",
            "Everything should make sense in this code, except the very last line (prefetch(1)),\n",
            "which is important for performance.\n",
            "\n",
            "--- Chunk 9286 ---\n",
            "Figure 13-2. Loading and preprocessing data from multiple CSV files\n",
            "\n",
            "--- Chunk 9287 ---\n",
            "Prefetching\n",
            "By calling prefetch(1) at the end, we are creating a dataset that will do its best to\n",
            "\n",
            "--- Chunk 9288 ---\n",
            "always be one batch ahead.2 In other words, while our training algorithm is working\n",
            "\n",
            "--- Chunk 9289 ---\n",
            "on one batch, the dataset will already be working in parallel on getting the next batch\n",
            "\n",
            "--- Chunk 9290 ---\n",
            "ready (e.g., reading the data from disk and preprocessing it). This can improve per‐\n",
            "\n",
            "--- Chunk 9291 ---\n",
            "formance dramatically, as is illustrated in Figure 13-3. If we also ensure that loading\n",
            "\n",
            "--- Chunk 9292 ---\n",
            "and preprocessing are multithreaded (by setting num_parallel_calls when calling\n",
            "\n",
            "--- Chunk 9293 ---\n",
            "interleave() and map()), we can exploit multiple cores on the CPU and hopefully\n",
            "\n",
            "--- Chunk 9294 ---\n",
            "make preparing one batch of data shorter than running a training step on the GPU:\n",
            "\n",
            "--- Chunk 9295 ---\n",
            "2 In general, just prefetching one batch is fine, but in some cases you may need to prefetch a few more. Alterna‐\n",
            "\n",
            "--- Chunk 9296 ---\n",
            "tively, you can let TensorFlow decide automatically by passing tf.data.experimental.AUTOTUNE (this is an\n",
            "experimental feature for now).\n",
            "\n",
            "--- Chunk 9297 ---\n",
            "The Data API | 421\n",
            "\n",
            "--- Chunk 9298 ---\n",
            "this way the GPU will be almost 100% utilized (except for the data transfer time from\n",
            "the CPU to the GPU3), and training will run much faster.\n",
            "\n",
            "--- Chunk 9299 ---\n",
            "Figure 13-3. With prefetching, the CPU and the GPU work in parallel: as the GPU works\n",
            "on one batch, the CPU works on the next\n",
            "\n",
            "--- Chunk 9300 ---\n",
            "If you plan to purchase a GPU card, its processing power and its\n",
            "memory size are of course very important (in particular, a large\n",
            "\n",
            "--- Chunk 9301 ---\n",
            "amount of RAM is crucial for computer vision). Just as important\n",
            "to get good performance is its memory bandwidth; this is the num‐\n",
            "\n",
            "--- Chunk 9302 ---\n",
            "ber of gigabytes of data it can get into or out of its RAM per\n",
            "second.\n",
            "\n",
            "--- Chunk 9303 ---\n",
            "If the dataset is small enough to fit in memory, you can significantly speed up train‐\n",
            "\n",
            "--- Chunk 9304 ---\n",
            "ing by using the dataset’s cache() method to cache its content to RAM. You should\n",
            "\n",
            "--- Chunk 9305 ---\n",
            "generally do this after loading and preprocessing the data, but before shuffling,\n",
            "\n",
            "--- Chunk 9306 ---\n",
            "repeating, batching, and prefetching. This way, each instance will only be read and\n",
            "\n",
            "--- Chunk 9307 ---\n",
            "3 But check out the tf.data.experimental.prefetch_to_device() function, which can prefetch data directly\n",
            "to the GPU.\n",
            "\n",
            "--- Chunk 9308 ---\n",
            "422 | Chapter 13: Loading and Preprocessing Data with TensorFlow\n",
            "\n",
            "--- Chunk 9309 ---\n",
            "preprocessed once (instead of once per epoch), but the data will still be shuffled dif‐\n",
            "\n",
            "--- Chunk 9310 ---\n",
            "ferently at each epoch, and the next batch will still be prepared in advance.\n",
            "\n",
            "--- Chunk 9311 ---\n",
            "You now know how to build efficient input pipelines to load and preprocess data\n",
            "\n",
            "--- Chunk 9312 ---\n",
            "from multiple text files. We have discussed the most common dataset methods, but\n",
            "\n",
            "--- Chunk 9313 ---\n",
            "there are a few more you may want to look at: concatenate(), zip(), window(),\n",
            "\n",
            "--- Chunk 9314 ---\n",
            "reduce(), shard(), flat_map(), and padded_batch(). There are also a couple more\n",
            "\n",
            "--- Chunk 9315 ---\n",
            "class methods: from_generator() and from_tensors(), which create a new dataset\n",
            "\n",
            "--- Chunk 9316 ---\n",
            "from a Python generator or a list of tensors, respectively. Please check the API docu‐\n",
            "\n",
            "--- Chunk 9317 ---\n",
            "mentation for more details. Also note that there are experimental features available in\n",
            "\n",
            "--- Chunk 9318 ---\n",
            "tf.data.experimental, many of which will likely make it to the core API in future\n",
            "\n",
            "--- Chunk 9319 ---\n",
            "releases (e.g., check out the CsvDataset class, as well as the make_csv_dataset()\n",
            "method, which takes care of inferring the type of each column).\n",
            "\n",
            "--- Chunk 9320 ---\n",
            "Using the Dataset with tf.keras\n",
            "Now we can use the csv_reader_dataset() function to create a dataset for the train‐\n",
            "\n",
            "--- Chunk 9321 ---\n",
            "ing set. Note that we do not need to repeat it, as this will be taken care of by tf.keras.\n",
            "\n",
            "--- Chunk 9322 ---\n",
            "We also create datasets for the validation set and the test set:\n",
            "\n",
            "--- Chunk 9323 ---\n",
            "train_set = csv_reader_dataset(train_filepaths)\n",
            "valid_set = csv_reader_dataset(valid_filepaths)\n",
            "test_set = csv_reader_dataset(test_filepaths)\n",
            "\n",
            "--- Chunk 9324 ---\n",
            "And now we can simply build and train a Keras model using these datasets.4 All we\n",
            "\n",
            "--- Chunk 9325 ---\n",
            "need to do is pass the training and validation datasets to the fit() method, instead of\n",
            "X_train, y_train, X_valid, and y_valid:5\n",
            "\n",
            "--- Chunk 9326 ---\n",
            "model = keras.models.Sequential([...])\n",
            "model.compile([...])\n",
            "model.fit(train_set, epochs=10, validation_data=valid_set)\n",
            "\n",
            "--- Chunk 9327 ---\n",
            "Similarly, we can pass a dataset to the evaluate() and predict() methods:\n",
            "model.evaluate(test_set)\n",
            "\n",
            "--- Chunk 9328 ---\n",
            "new_set = test_set.take(3).map(lambda X, y: X) # pretend we have 3 new instances\n",
            "model.predict(new_set) # a dataset containing new instances\n",
            "\n",
            "--- Chunk 9329 ---\n",
            "Unlike the other sets, the new_set will usually not contain labels (if it does, Keras will\n",
            "\n",
            "--- Chunk 9330 ---\n",
            "ignore them). Note that in all these cases, you can still use NumPy arrays instead of\n",
            "\n",
            "--- Chunk 9331 ---\n",
            "4 Support for datasets is specific to tf.keras; this will not work in other implementations of the Keras API.\n",
            "\n",
            "--- Chunk 9332 ---\n",
            "5 The fit() method will take care of repeating the training dataset. Alternatively, you could call repeat() on\n",
            "\n",
            "--- Chunk 9333 ---\n",
            "the training dataset so that it repeats forever and specify the steps_per_epoch argument when calling the\n",
            "\n",
            "--- Chunk 9334 ---\n",
            "fit() method. This may be useful in some rare cases, for example if you want to use a shuffle buffer that\n",
            "crosses over epochs.\n",
            "\n",
            "--- Chunk 9335 ---\n",
            "The Data API | 423\n",
            "\n",
            "--- Chunk 9336 ---\n",
            "datasets if you want (but of course they need to have been loaded and preprocessed\n",
            "first).\n",
            "\n",
            "--- Chunk 9337 ---\n",
            "first).\n",
            "If you want to build your own custom training loop (as in Chapter 12), you can just\n",
            "iterate over the training set, very naturally:\n",
            "\n",
            "--- Chunk 9338 ---\n",
            "for X_batch, y_batch in train_set:\n",
            "    [...] # perform one Gradient Descent step\n",
            "\n",
            "--- Chunk 9339 ---\n",
            "In fact, it is even possible to create a TF Function (see Chapter 12) that performs the\n",
            "whole training loop:\n",
            "\n",
            "--- Chunk 9340 ---\n",
            "@tf.function\n",
            "def train(model, optimizer, loss_fn, n_epochs, [...]):\n",
            "    train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs, [...])\n",
            "\n",
            "--- Chunk 9341 ---\n",
            "for X_batch, y_batch in train_set:\n",
            "        with tf.GradientTape() as tape:\n",
            "            y_pred = model(X_batch)\n",
            "\n",
            "--- Chunk 9342 ---\n",
            "main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
            "            loss = tf.add_n([main_loss] + model.losses)\n",
            "\n",
            "--- Chunk 9343 ---\n",
            "grads = tape.gradient(loss, model.trainable_variables)\n",
            "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
            "\n",
            "--- Chunk 9344 ---\n",
            "Congratulations, you now know how to build powerful input pipelines using the Data\n",
            "\n",
            "--- Chunk 9345 ---\n",
            "API! However, so far we have used CSV files, which are common, simple, and conve‐\n",
            "\n",
            "--- Chunk 9346 ---\n",
            "nient but not really efficient, and do not support large or complex data structures\n",
            "\n",
            "--- Chunk 9347 ---\n",
            "(such as images or audio) very well. So let’s see how to use TFRecords instead.\n",
            "\n",
            "--- Chunk 9348 ---\n",
            "If you are happy with CSV files (or whatever other format you are\n",
            "using), you do not have to use TFRecords. As the saying goes, if it\n",
            "\n",
            "--- Chunk 9349 ---\n",
            "ain’t broke, don’t fix it! TFRecords are useful when the bottleneck\n",
            "during training is loading and parsing the data.\n",
            "\n",
            "--- Chunk 9350 ---\n",
            "The TFRecord Format\n",
            "The TFRecord format is TensorFlow’s preferred format for storing large amounts of\n",
            "\n",
            "--- Chunk 9351 ---\n",
            "data and reading it efficiently. It is a very simple binary format that just contains a\n",
            "\n",
            "--- Chunk 9352 ---\n",
            "sequence of binary records of varying sizes (each record is comprised of a length, a\n",
            "\n",
            "--- Chunk 9353 ---\n",
            "CRC checksum to check that the length was not corrupted, then the actual data, and\n",
            "\n",
            "--- Chunk 9354 ---\n",
            "finally a CRC checksum for the data). You can easily create a TFRecord file using the\n",
            "tf.io.TFRecordWriter class:\n",
            "\n",
            "--- Chunk 9355 ---\n",
            "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
            "    f.write(b\"This is the first record\")\n",
            "    f.write(b\"And this is the second record\")\n",
            "\n",
            "--- Chunk 9356 ---\n",
            "424 | Chapter 13: Loading and Preprocessing Data with TensorFlow\n",
            "\n",
            "--- Chunk 9357 ---\n",
            "And you can then use a tf.data.TFRecordDataset to read one or more TFRecord\n",
            "files:\n",
            "\n",
            "--- Chunk 9358 ---\n",
            "filepaths = [\"my_data.tfrecord\"]\n",
            "dataset = tf.data.TFRecordDataset(filepaths)\n",
            "for item in dataset:\n",
            "    print(item)\n",
            "\n",
            "--- Chunk 9359 ---\n",
            "This will output:\n",
            "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
            "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n",
            "\n",
            "--- Chunk 9360 ---\n",
            "By default, a TFRecordDataset will read files one by one, but you\n",
            "can make it read multiple files in parallel and interleave their\n",
            "\n",
            "--- Chunk 9361 ---\n",
            "records by setting num_parallel_reads. Alternatively, you could\n",
            "obtain the same result by using list_files() and interleave()\n",
            "\n",
            "--- Chunk 9362 ---\n",
            "as we did earlier to read multiple CSV files.\n",
            "\n",
            "--- Chunk 9363 ---\n",
            "Compressed TFRecord Files\n",
            "It can sometimes be useful to compress your TFRecord files, especially if they need to\n",
            "\n",
            "--- Chunk 9364 ---\n",
            "be loaded via a network connection. You can create a compressed TFRecord file by\n",
            "setting the options argument:\n",
            "\n",
            "--- Chunk 9365 ---\n",
            "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
            "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:\n",
            "  [...]\n",
            "\n",
            "--- Chunk 9366 ---\n",
            "When reading a compressed TFRecord file, you need to specify the compression type:\n",
            "dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"],\n",
            "\n",
            "--- Chunk 9367 ---\n",
            "compression_type=\"GZIP\")\n",
            "\n",
            "--- Chunk 9368 ---\n",
            "A Brief Introduction to Protocol Buffers\n",
            "Even though each record can use any binary format you want, TFRecord files usually\n",
            "\n",
            "--- Chunk 9369 ---\n",
            "contain serialized protocol buffers (also called protobufs). This is a portable, extensi‐\n",
            "\n",
            "--- Chunk 9370 ---\n",
            "ble, and efficient binary format developed at Google back in 2001 and made open\n",
            "\n",
            "--- Chunk 9371 ---\n",
            "source in 2008; protobufs are now widely used, in particular in gRPC, Google’s\n",
            "\n",
            "--- Chunk 9372 ---\n",
            "remote procedure call system. They are defined using a simple language that looks\n",
            "like this:\n",
            "\n",
            "--- Chunk 9373 ---\n",
            "syntax = \"proto3\";\n",
            "message Person {\n",
            "  string name = 1;\n",
            "  int32 id = 2;\n",
            "  repeated string email = 3;\n",
            "}\n",
            "\n",
            "The TFRecord Format | 425\n",
            "\n",
            "--- Chunk 9374 ---\n",
            "This definition says we are using version 3 of the protobuf format, and it specifies\n",
            "\n",
            "--- Chunk 9375 ---\n",
            "that each Person object6 may (optionally) have a name of type string, an id of type\n",
            "\n",
            "--- Chunk 9376 ---\n",
            "int32, and zero or more email fields, each of type string. The numbers 1, 2, and 3\n",
            "\n",
            "--- Chunk 9377 ---\n",
            "are the field identifiers: they will be used in each record’s binary representation. Once\n",
            "\n",
            "--- Chunk 9378 ---\n",
            "you have a definition in a .proto file, you can compile it. This requires protoc, the\n",
            "\n",
            "--- Chunk 9379 ---\n",
            "protobuf compiler, to generate access classes in Python (or some other language).\n",
            "\n",
            "--- Chunk 9380 ---\n",
            "Note that the protobuf definitions we will use have already been compiled for you,\n",
            "\n",
            "--- Chunk 9381 ---\n",
            "and their Python classes are part of TensorFlow, so you will not need to use protoc.\n",
            "\n",
            "--- Chunk 9382 ---\n",
            "All you need to know is how to use protobuf access classes in Python. To illustrate the\n",
            "\n",
            "--- Chunk 9383 ---\n",
            "basics, let’s look at a simple example that uses the access classes generated for the\n",
            "Person protobuf (the code is explained in the comments):\n",
            "\n",
            "--- Chunk 9384 ---\n",
            ">>> from person_pb2 import Person  # import the generated access class\n",
            ">>> person = Person(name=\"Al\", id=123, email=[\"a@b.com\"])  # create a Person\n",
            "\n",
            "--- Chunk 9385 ---\n",
            ">>> print(person)  # display the Person\n",
            "name: \"Al\"\n",
            "id: 123\n",
            "email: \"a@b.com\"\n",
            ">>> person.name  # read a field\n",
            "\"Al\"\n",
            "\n",
            "--- Chunk 9386 ---\n",
            "\"Al\"\n",
            ">>> person.name = \"Alice\"  # modify a field\n",
            ">>> person.email[0]  # repeated fields can be accessed like arrays\n",
            "\"a@b.com\"\n",
            "\n",
            "--- Chunk 9387 ---\n",
            "\"a@b.com\"\n",
            ">>> person.email.append(\"c@d.com\")  # add an email address\n",
            ">>> s = person.SerializeToString()  # serialize the object to a byte string\n",
            "\n",
            "--- Chunk 9388 ---\n",
            ">>> s\n",
            "b'\\n\\x05Alice\\x10{\\x1a\\x07a@b.com\\x1a\\x07c@d.com'\n",
            ">>> person2 = Person()  # create a new Person\n",
            "\n",
            "--- Chunk 9389 ---\n",
            ">>> person2.ParseFromString(s)  # parse the byte string (27 bytes long)\n",
            "27\n",
            ">>> person == person2  # now they are equal\n",
            "True\n",
            "\n",
            "--- Chunk 9390 ---\n",
            "In short, we import the Person class generated by protoc, we create an instance and\n",
            "\n",
            "--- Chunk 9391 ---\n",
            "play with it, visualizing it and reading and writing some fields, then we serialize it\n",
            "\n",
            "--- Chunk 9392 ---\n",
            "using the SerializeToString() method. This is the binary data that is ready to be\n",
            "\n",
            "--- Chunk 9393 ---\n",
            "saved or transmitted over the network. When reading or receiving this binary data,\n",
            "\n",
            "--- Chunk 9394 ---\n",
            "we can parse it using the ParseFromString() method, and we get a copy of the object\n",
            "that was serialized.7\n",
            "\n",
            "--- Chunk 9395 ---\n",
            "We could save the serialized Person object to a TFRecord file, then we could load and\n",
            "\n",
            "--- Chunk 9396 ---\n",
            "parse it: everything would work fine. However, SerializeToString() and ParseFrom\n",
            "\n",
            "--- Chunk 9397 ---\n",
            "6 Since protobuf objects are meant to be serialized and transmitted, they are called messages.\n",
            "\n",
            "--- Chunk 9398 ---\n",
            "7 This chapter contains the bare minimum you need to know about protobufs to use TFRecords. To learn more\n",
            "\n",
            "--- Chunk 9399 ---\n",
            "about protobufs, please visit https://homl.info/protobuf.\n",
            "\n",
            "426 | Chapter 13: Loading and Preprocessing Data with TensorFlow\n",
            "\n",
            "--- Chunk 9400 ---\n",
            "String() are not TensorFlow operations (and neither are the other operations in this\n",
            "\n",
            "--- Chunk 9401 ---\n",
            "code), so they cannot be included in a TensorFlow Function (except by wrapping\n",
            "\n",
            "--- Chunk 9402 ---\n",
            "them in a tf.py_function() operation, which would make the code slower and less\n",
            "\n",
            "--- Chunk 9403 ---\n",
            "portable, as we saw in Chapter 12). Fortunately, TensorFlow does include special pro‐\n",
            "tobuf definitions for which it provides parsing operations.\n",
            "\n",
            "--- Chunk 9404 ---\n",
            "TensorFlow Protobufs\n",
            "The main protobuf typically used in a TFRecord file is the Example protobuf, which\n",
            "\n",
            "--- Chunk 9405 ---\n",
            "represents one instance in a dataset. It contains a list of named features, where each\n",
            "\n",
            "--- Chunk 9406 ---\n",
            "feature can either be a list of byte strings, a list of floats, or a list of integers. Here is\n",
            "the protobuf definition:\n",
            "\n",
            "--- Chunk 9407 ---\n",
            "syntax = \"proto3\";\n",
            "message BytesList { repeated bytes value = 1; }\n",
            "message FloatList { repeated float value = 1 [packed = true]; }\n",
            "\n",
            "--- Chunk 9408 ---\n",
            "message Int64List { repeated int64 value = 1 [packed = true]; }\n",
            "message Feature {\n",
            "    oneof kind {\n",
            "        BytesList bytes_list = 1;\n",
            "\n",
            "--- Chunk 9409 ---\n",
            "FloatList float_list = 2;\n",
            "        Int64List int64_list = 3;\n",
            "    }\n",
            "};\n",
            "message Features { map<string, Feature> feature = 1; };\n",
            "\n",
            "--- Chunk 9410 ---\n",
            "message Example { Features features = 1; };\n",
            "\n",
            "--- Chunk 9411 ---\n",
            "The definitions of BytesList, FloatList, and Int64List are straightforward\n",
            "\n",
            "--- Chunk 9412 ---\n",
            "enough. Note that [packed = true] is used for repeated numerical fields, for a more\n",
            "\n",
            "--- Chunk 9413 ---\n",
            "efficient encoding. A Feature contains either a BytesList, a FloatList, or an\n",
            "\n",
            "--- Chunk 9414 ---\n",
            "Int64List. A Features (with an s) contains a dictionary that maps a feature name to\n",
            "\n",
            "--- Chunk 9415 ---\n",
            "the corresponding feature value. And finally, an Example contains only a Features\n",
            "\n",
            "--- Chunk 9416 ---\n",
            "object.8 Here is how you could create a tf.train.Example representing the same per‐\n",
            "son as earlier and write it to a TFRecord file:\n",
            "\n",
            "--- Chunk 9417 ---\n",
            "from tensorflow.train import BytesList, FloatList, Int64List\n",
            "from tensorflow.train import Feature, Features, Example\n",
            "\n",
            "--- Chunk 9418 ---\n",
            "person_example = Example(\n",
            "    features=Features(\n",
            "        feature={\n",
            "            \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])),\n",
            "\n",
            "--- Chunk 9419 ---\n",
            "8 Why was Example even defined, since it contains no more than a Features object? Well, TensorFlow’s devel‐\n",
            "\n",
            "--- Chunk 9420 ---\n",
            "opers may one day decide to add more fields to it. As long as the new Example definition still contains the\n",
            "\n",
            "--- Chunk 9421 ---\n",
            "features field, with the same ID, it will be backward compatible. This extensibility is one of the great features\n",
            "of protobufs.\n",
            "\n",
            "--- Chunk 9422 ---\n",
            "The TFRecord Format | 427\n",
            "\n",
            "--- Chunk 9423 ---\n",
            "\"id\": Feature(int64_list=Int64List(value=[123])),\n",
            "            \"emails\": Feature(bytes_list=BytesList(value=[b\"a@b.com\",\n",
            "\n",
            "--- Chunk 9424 ---\n",
            "b\"c@d.com\"]))\n",
            "        }))\n",
            "\n",
            "--- Chunk 9425 ---\n",
            "The code is a bit verbose and repetitive, but it’s rather straightforward (and you could\n",
            "\n",
            "--- Chunk 9426 ---\n",
            "easily wrap it inside a small helper function). Now that we have an Example protobuf,\n",
            "\n",
            "--- Chunk 9427 ---\n",
            "we can serialize it by calling its SerializeToString() method, then write the result‐\n",
            "ing data to a TFRecord file:\n",
            "\n",
            "--- Chunk 9428 ---\n",
            "with tf.io.TFRecordWriter(\"my_contacts.tfrecord\") as f:\n",
            "    f.write(person_example.SerializeToString())\n",
            "\n",
            "--- Chunk 9429 ---\n",
            "Normally you would write much more than one Example! Typically, you would create\n",
            "\n",
            "--- Chunk 9430 ---\n",
            "a conversion script that reads from your current format (say, CSV files), creates an\n",
            "\n",
            "--- Chunk 9431 ---\n",
            "Example protobuf for each instance, serializes them, and saves them to several TFRe‐\n",
            "\n",
            "--- Chunk 9432 ---\n",
            "cord files, ideally shuffling them in the process. This requires a bit of work, so once\n",
            "\n",
            "--- Chunk 9433 ---\n",
            "again make sure it is really necessary (perhaps your pipeline works fine with CSV\n",
            "files).\n",
            "\n",
            "--- Chunk 9434 ---\n",
            "files).\n",
            "Now that we have a nice TFRecord file containing a serialized Example, let’s try to\n",
            "load it.\n",
            "\n",
            "--- Chunk 9435 ---\n",
            "Loading and Parsing Examples\n",
            "To load the serialized Example protobufs, we will use a tf.data.TFRecordDataset\n",
            "\n",
            "--- Chunk 9436 ---\n",
            "once again, and we will parse each Example using tf.io.parse_single_example().\n",
            "\n",
            "--- Chunk 9437 ---\n",
            "This is a TensorFlow operation, so it can be included in a TF Function. It requires at\n",
            "\n",
            "--- Chunk 9438 ---\n",
            "least two arguments: a string scalar tensor containing the serialized data, and a\n",
            "\n",
            "--- Chunk 9439 ---\n",
            "description of each feature. The description is a dictionary that maps each feature\n",
            "\n",
            "--- Chunk 9440 ---\n",
            "name to either a tf.io.FixedLenFeature descriptor indicating the feature’s shape,\n",
            "\n",
            "--- Chunk 9441 ---\n",
            "type, and default value, or a tf.io.VarLenFeature descriptor indicating only the type\n",
            "\n",
            "--- Chunk 9442 ---\n",
            "(if the length of the feature’s list may vary, such as for the \"emails\" feature).\n",
            "\n",
            "--- Chunk 9443 ---\n",
            "The following code defines a description dictionary, then it iterates over the TFRecord\n",
            "\n",
            "--- Chunk 9444 ---\n",
            "Dataset and parses the serialized Example protobuf this dataset contains:\n",
            "\n",
            "--- Chunk 9445 ---\n",
            "feature_description = {\n",
            "    \"name\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
            "\n",
            "--- Chunk 9446 ---\n",
            "\"id\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
            "    \"emails\": tf.io.VarLenFeature(tf.string),\n",
            "}\n",
            "\n",
            "--- Chunk 9447 ---\n",
            "for serialized_example in tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]):\n",
            "    parsed_example = tf.io.parse_single_example(serialized_example,\n",
            "\n",
            "--- Chunk 9448 ---\n",
            "feature_description)\n",
            "\n",
            "--- Chunk 9449 ---\n",
            "428 | Chapter 13: Loading and Preprocessing Data with TensorFlow\n",
            "\n",
            "--- Chunk 9450 ---\n",
            "The fixed-length features are parsed as regular tensors, but the variable-length fea‐\n",
            "\n",
            "--- Chunk 9451 ---\n",
            "tures are parsed as sparse tensors. You can convert a sparse tensor to a dense tensor\n",
            "\n",
            "--- Chunk 9452 ---\n",
            "using tf.sparse.to_dense(), but in this case it is simpler to just access its values:\n",
            "\n",
            "--- Chunk 9453 ---\n",
            ">>> tf.sparse.to_dense(parsed_example[\"emails\"], default_value=b\"\")\n",
            "<tf.Tensor: [...] dtype=string, numpy=array([b'a@b.com', b'c@d.com'], [...])>\n",
            "\n",
            "--- Chunk 9454 ---\n",
            ">>> parsed_example[\"emails\"].values\n",
            "<tf.Tensor: [...] dtype=string, numpy=array([b'a@b.com', b'c@d.com'], [...])>\n",
            "\n",
            "--- Chunk 9455 ---\n",
            "A BytesList can contain any binary data you want, including any serialized object.\n",
            "\n",
            "--- Chunk 9456 ---\n",
            "For example, you can use tf.io.encode_jpeg() to encode an image using the JPEG\n",
            "\n",
            "--- Chunk 9457 ---\n",
            "format and put this binary data in a BytesList. Later, when your code reads the\n",
            "\n",
            "--- Chunk 9458 ---\n",
            "TFRecord, it will start by parsing the Example, then it will need to call\n",
            "\n",
            "--- Chunk 9459 ---\n",
            "tf.io.decode_jpeg() to parse the data and get the original image (or you can use\n",
            "\n",
            "--- Chunk 9460 ---\n",
            "tf.io.decode_image(), which can decode any BMP, GIF, JPEG, or PNG image). You\n",
            "\n",
            "--- Chunk 9461 ---\n",
            "can also store any tensor you want in a BytesList by serializing the tensor using\n",
            "\n",
            "--- Chunk 9462 ---\n",
            "tf.io.serialize_tensor() then putting the resulting byte string in a BytesList\n",
            "\n",
            "--- Chunk 9463 ---\n",
            "feature. Later, when you parse the TFRecord, you can parse this data using\n",
            "tf.io.parse_tensor().\n",
            "\n",
            "--- Chunk 9464 ---\n",
            "Instead of parsing examples one by one using tf.io.parse_single_example(), you\n",
            "may want to parse them batch by batch using tf.io.parse_example():\n",
            "\n",
            "--- Chunk 9465 ---\n",
            "dataset = tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]).batch(10)\n",
            "for serialized_examples in dataset:\n",
            "\n",
            "--- Chunk 9466 ---\n",
            "parsed_examples = tf.io.parse_example(serialized_examples,\n",
            "                                          feature_description)\n",
            "\n",
            "--- Chunk 9467 ---\n",
            "As you can see, the Example protobuf will probably be sufficient for most use cases.\n",
            "\n",
            "--- Chunk 9468 ---\n",
            "However, it may be a bit cumbersome to use when you are dealing with lists of lists.\n",
            "\n",
            "--- Chunk 9469 ---\n",
            "For example, suppose you want to classify text documents. Each document may be\n",
            "\n",
            "--- Chunk 9470 ---\n",
            "represented as a list of sentences, where each sentence is represented as a list of\n",
            "\n",
            "--- Chunk 9471 ---\n",
            "words. And perhaps each document also has a list of comments, where each com‐\n",
            "\n",
            "--- Chunk 9472 ---\n",
            "ment is represented as a list of words. There may be some contextual data too, such as\n",
            "\n",
            "--- Chunk 9473 ---\n",
            "the document’s author, title, and publication date. TensorFlow’s SequenceExample\n",
            "protobuf is designed for such use cases.\n",
            "\n",
            "--- Chunk 9474 ---\n",
            "Handling Lists of Lists Using the SequenceExample Protobuf\n",
            "Here is the definition of the SequenceExample protobuf:\n",
            "\n",
            "--- Chunk 9475 ---\n",
            "message FeatureList { repeated Feature feature = 1; };\n",
            "message FeatureLists { map<string, FeatureList> feature_list = 1; };\n",
            "\n",
            "--- Chunk 9476 ---\n",
            "message SequenceExample {\n",
            "    Features context = 1;\n",
            "    FeatureLists feature_lists = 2;\n",
            "};\n",
            "\n",
            "--- Chunk 9477 ---\n",
            "The TFRecord Format | 429\n",
            "\n",
            "--- Chunk 9478 ---\n",
            "A SequenceExample contains a Features object for the contextual data and a Fea\n",
            "\n",
            "--- Chunk 9479 ---\n",
            "tureLists object that contains one or more named FeatureList objects (e.g., a Fea\n",
            "\n",
            "--- Chunk 9480 ---\n",
            "tureList named \"content\" and another named \"comments\"). Each FeatureList\n",
            "\n",
            "--- Chunk 9481 ---\n",
            "contains a list of Feature objects, each of which may be a list of byte strings, a list of\n",
            "\n",
            "--- Chunk 9482 ---\n",
            "64-bit integers, or a list of floats (in this example, each Feature would represent a\n",
            "\n",
            "--- Chunk 9483 ---\n",
            "sentence or a comment, perhaps in the form of a list of word identifiers). Building a\n",
            "\n",
            "--- Chunk 9484 ---\n",
            "SequenceExample, serializing it, and parsing it is similar to building, serializing, and\n",
            "\n",
            "--- Chunk 9485 ---\n",
            "parsing an Example, but you must use tf.io.parse_single_sequence_example() to\n",
            "\n",
            "--- Chunk 9486 ---\n",
            "parse a single SequenceExample or tf.io.parse_sequence_example() to parse a\n",
            "\n",
            "--- Chunk 9487 ---\n",
            "batch. Both functions return a tuple containing the context features (as a dictionary)\n",
            "\n",
            "--- Chunk 9488 ---\n",
            "and the feature lists (also as a dictionary). If the feature lists contain sequences of\n",
            "\n",
            "--- Chunk 9489 ---\n",
            "varying sizes (as in the preceding example), you may want to convert them to ragged\n",
            "\n",
            "--- Chunk 9490 ---\n",
            "tensors, using tf.RaggedTensor.from_sparse() (see the notebook for the full code):\n",
            "\n",
            "--- Chunk 9491 ---\n",
            "parsed_context, parsed_feature_lists = tf.io.parse_single_sequence_example(\n",
            "    serialized_sequence_example, context_feature_descriptions,\n",
            "\n",
            "--- Chunk 9492 ---\n",
            "sequence_feature_descriptions)\n",
            "parsed_content = tf.RaggedTensor.from_sparse(parsed_feature_lists[\"content\"])\n",
            "\n",
            "--- Chunk 9493 ---\n",
            "Now that you know how to efficiently store, load, and parse data, the next step is to\n",
            "prepare it so that it can be fed to a neural network.\n",
            "\n",
            "--- Chunk 9494 ---\n",
            "Preprocessing the Input Features\n",
            "Preparing your data for a neural network requires converting all features into numer‐\n",
            "\n",
            "--- Chunk 9495 ---\n",
            "ical features, generally normalizing them, and more. In particular, if your data con‐\n",
            "\n",
            "--- Chunk 9496 ---\n",
            "tains categorical features or text features, they need to be converted to numbers. This\n",
            "\n",
            "--- Chunk 9497 ---\n",
            "can be done ahead of time when preparing your data files, using any tool you like\n",
            "\n",
            "--- Chunk 9498 ---\n",
            "(e.g., NumPy, pandas, or Scikit-Learn). Alternatively, you can preprocess your data on\n",
            "\n",
            "--- Chunk 9499 ---\n",
            "the fly when loading it with the Data API (e.g., using the dataset’s map() method, as\n",
            "\n",
            "--- Chunk 9500 ---\n",
            "we saw earlier), or you can include a preprocessing layer directly in your model. Let’s\n",
            "look at this last option now.\n",
            "\n",
            "--- Chunk 9501 ---\n",
            "For example, here is how you can implement a standardization layer using a Lambda\n",
            "\n",
            "--- Chunk 9502 ---\n",
            "layer. For each feature, it subtracts the mean and divides by its standard deviation\n",
            "(plus a tiny smoothing term to avoid division by zero):\n",
            "\n",
            "--- Chunk 9503 ---\n",
            "means = np.mean(X_train, axis=0, keepdims=True)\n",
            "stds = np.std(X_train, axis=0, keepdims=True)\n",
            "eps = keras.backend.epsilon()\n",
            "\n",
            "--- Chunk 9504 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.Lambda(lambda inputs: (inputs - means) / (stds + eps)),\n",
            "    [...] # other layers\n",
            "])\n",
            "\n",
            "--- Chunk 9505 ---\n",
            "430 | Chapter 13: Loading and Preprocessing Data with TensorFlow\n",
            "\n",
            "--- Chunk 9506 ---\n",
            "That’s not too hard! However, you may prefer to use a nice self-contained custom\n",
            "\n",
            "--- Chunk 9507 ---\n",
            "layer (much like Scikit-Learn’s StandardScaler), rather than having global variables\n",
            "like means and stds dangling around:\n",
            "\n",
            "--- Chunk 9508 ---\n",
            "class Standardization(keras.layers.Layer):\n",
            "    def adapt(self, data_sample):\n",
            "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
            "\n",
            "--- Chunk 9509 ---\n",
            "self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
            "    def call(self, inputs):\n",
            "\n",
            "--- Chunk 9510 ---\n",
            "return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())\n",
            "\n",
            "--- Chunk 9511 ---\n",
            "Before you can use this standardization layer, you will need to adapt it to your dataset\n",
            "\n",
            "--- Chunk 9512 ---\n",
            "by calling the adapt() method and passing it a data sample. This will allow it to use\n",
            "the appropriate mean and standard deviation for each feature:\n",
            "\n",
            "--- Chunk 9513 ---\n",
            "std_layer = Standardization()\n",
            "std_layer.adapt(data_sample)\n",
            "\n",
            "--- Chunk 9514 ---\n",
            "This sample must be large enough to be representative of your dataset, but it does not\n",
            "\n",
            "--- Chunk 9515 ---\n",
            "have to be the full training set: in general, a few hundred randomly selected instances\n",
            "\n",
            "--- Chunk 9516 ---\n",
            "will suffice (however, this depends on your task). Next, you can use this preprocess‐\n",
            "ing layer like a normal layer:\n",
            "\n",
            "--- Chunk 9517 ---\n",
            "model = keras.Sequential()\n",
            "model.add(std_layer)\n",
            "[...] # create the rest of the model\n",
            "model.compile([...])\n",
            "model.fit([...])\n",
            "\n",
            "--- Chunk 9518 ---\n",
            "If you are thinking that Keras should contain a standardization layer like this one,\n",
            "\n",
            "--- Chunk 9519 ---\n",
            "here’s some good news for you: by the time you read this, the keras.layers.Normal\n",
            "\n",
            "--- Chunk 9520 ---\n",
            "ization layer will probably be available. It will work very much like our custom\n",
            "\n",
            "--- Chunk 9521 ---\n",
            "Standardization layer: first, create the layer, then adapt it to your dataset by passing\n",
            "\n",
            "--- Chunk 9522 ---\n",
            "a data sample to the adapt() method, and finally use the layer normally.\n",
            "\n",
            "--- Chunk 9523 ---\n",
            "Now let’s look at categorical features. We will start by encoding them as one-hot\n",
            "vectors.\n",
            "\n",
            "--- Chunk 9524 ---\n",
            "Encoding Categorical Features Using One-Hot Vectors\n",
            "Consider the ocean_proximity feature in the California housing dataset we explored\n",
            "\n",
            "--- Chunk 9525 ---\n",
            "in Chapter 2: it is a categorical feature with five possible values: \"<1H OCEAN\",\n",
            "\n",
            "--- Chunk 9526 ---\n",
            "\"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", and \"ISLAND\". We need to encode this feature\n",
            "\n",
            "--- Chunk 9527 ---\n",
            "before we feed it to a neural network. Since there are very few categories, we can use\n",
            "\n",
            "--- Chunk 9528 ---\n",
            "one-hot encoding. For this, we first need to map each category to its index (0 to 4),\n",
            "which can be done using a lookup table:\n",
            "\n",
            "--- Chunk 9529 ---\n",
            "vocab = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\"]\n",
            "indices = tf.range(len(vocab), dtype=tf.int64)\n",
            "\n",
            "--- Chunk 9530 ---\n",
            "Preprocessing the Input Features | 431\n",
            "\n",
            "--- Chunk 9531 ---\n",
            "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
            "num_oov_buckets = 2\n",
            "\n",
            "--- Chunk 9532 ---\n",
            "num_oov_buckets = 2\n",
            "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets)\n",
            "\n",
            "--- Chunk 9533 ---\n",
            "Let’s go through this code:\n",
            "\n",
            "--- Chunk 9534 ---\n",
            "• We first define the vocabulary: this is the list of all possible categories.\n",
            "• Then we create a tensor with the corresponding indices (0 to 4).\n",
            "\n",
            "--- Chunk 9535 ---\n",
            "• Next, we create an initializer for the lookup table, passing it the list of categories\n",
            "\n",
            "--- Chunk 9536 ---\n",
            "and their corresponding indices. In this example, we already have this data, so we\n",
            "\n",
            "--- Chunk 9537 ---\n",
            "use a KeyValueTensorInitializer; but if the categories were listed in a text file\n",
            "\n",
            "--- Chunk 9538 ---\n",
            "(with one category per line), we would use a TextFileInitializer instead.\n",
            "\n",
            "--- Chunk 9539 ---\n",
            "• In the last two lines we create the lookup table, giving it the initializer and speci‐\n",
            "\n",
            "--- Chunk 9540 ---\n",
            "fying the number of out-of-vocabulary (oov) buckets. If we look up a category\n",
            "\n",
            "--- Chunk 9541 ---\n",
            "that does not exist in the vocabulary, the lookup table will compute a hash of this\n",
            "\n",
            "--- Chunk 9542 ---\n",
            "category and use it to assign the unknown category to one of the oov buckets.\n",
            "\n",
            "--- Chunk 9543 ---\n",
            "Their indices start after the known categories, so in this example the indices of\n",
            "the two oov buckets are 5 and 6.\n",
            "\n",
            "--- Chunk 9544 ---\n",
            "Why use oov buckets? Well, if the number of categories is large (e.g., zip codes, cities,\n",
            "\n",
            "--- Chunk 9545 ---\n",
            "words, products, or users) and the dataset is large as well, or it keeps changing, then\n",
            "\n",
            "--- Chunk 9546 ---\n",
            "getting the full list of categories may not be convenient. One solution is to define the\n",
            "\n",
            "--- Chunk 9547 ---\n",
            "vocabulary based on a data sample (rather than the whole training set) and add some\n",
            "\n",
            "--- Chunk 9548 ---\n",
            "oov buckets for the other categories that were not in the data sample. The more\n",
            "\n",
            "--- Chunk 9549 ---\n",
            "unknown categories you expect to find during training, the more oov buckets you\n",
            "\n",
            "--- Chunk 9550 ---\n",
            "should use. Indeed, if there are not enough oov buckets, there will be collisions: dif‐\n",
            "\n",
            "--- Chunk 9551 ---\n",
            "ferent categories will end up in the same bucket, so the neural network will not be\n",
            "able to distinguish them (at least not based on this feature).\n",
            "\n",
            "--- Chunk 9552 ---\n",
            "Now let’s use the lookup table to encode a small batch of categorical features to one-\n",
            "hot vectors:\n",
            "\n",
            "--- Chunk 9553 ---\n",
            ">>> categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
            ">>> cat_indices = table.lookup(categories)\n",
            ">>> cat_indices\n",
            "\n",
            "--- Chunk 9554 ---\n",
            ">>> cat_indices\n",
            "<tf.Tensor: id=514, shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1])>\n",
            "\n",
            "--- Chunk 9555 ---\n",
            ">>> cat_one_hot = tf.one_hot(cat_indices, depth=len(vocab) + num_oov_buckets)\n",
            ">>> cat_one_hot\n",
            "<tf.Tensor: id=524, shape=(4, 7), dtype=float32, numpy=\n",
            "\n",
            "--- Chunk 9556 ---\n",
            "array([[0., 0., 0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 1., 0.],\n",
            "       [0., 1., 0., 0., 0., 0., 0.],\n",
            "\n",
            "--- Chunk 9557 ---\n",
            "[0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>\n",
            "\n",
            "--- Chunk 9558 ---\n",
            "As you can see, \"NEAR BAY\" was mapped to index 3, the unknown category \"DESERT\"\n",
            "\n",
            "--- Chunk 9559 ---\n",
            "was mapped to one of the two oov buckets (at index 5), and \"INLAND\" was mapped to\n",
            "\n",
            "--- Chunk 9560 ---\n",
            "432 | Chapter 13: Loading and Preprocessing Data with TensorFlow\n",
            "\n",
            "--- Chunk 9561 ---\n",
            "index 1, twice. Then we used tf.one_hot() to one-hot encode these indices. Notice\n",
            "\n",
            "--- Chunk 9562 ---\n",
            "that we have to tell this function the total number of indices, which is equal to the\n",
            "\n",
            "--- Chunk 9563 ---\n",
            "vocabulary size plus the number of oov buckets. Now you know how to encode cate‐\n",
            "gorical features to one-hot vectors using TensorFlow!\n",
            "\n",
            "--- Chunk 9564 ---\n",
            "Just like earlier, it wouldn’t be too difficult to bundle all of this logic into a nice self-\n",
            "\n",
            "--- Chunk 9565 ---\n",
            "contained class. Its adapt() method would take a data sample and extract all the dis‐\n",
            "\n",
            "--- Chunk 9566 ---\n",
            "tinct categories it contains. It would create a lookup table to map each category to its\n",
            "\n",
            "--- Chunk 9567 ---\n",
            "index (including unknown categories using oov buckets). Then its call() method\n",
            "\n",
            "--- Chunk 9568 ---\n",
            "would use the lookup table to map the input categories to their indices. Well, here’s\n",
            "\n",
            "--- Chunk 9569 ---\n",
            "more good news: by the time you read this, Keras will probably include a layer called\n",
            "\n",
            "--- Chunk 9570 ---\n",
            "keras.layers.TextVectorization, which will be capable of doing exactly that: its\n",
            "\n",
            "--- Chunk 9571 ---\n",
            "adapt() method will extract the vocabulary from a data sample, and its call()\n",
            "\n",
            "--- Chunk 9572 ---\n",
            "method will convert each category to its index in the vocabulary. You could add this\n",
            "\n",
            "--- Chunk 9573 ---\n",
            "layer at the beginning of your model, followed by a Lambda layer that would apply the\n",
            "\n",
            "--- Chunk 9574 ---\n",
            "tf.one_hot() function, if you want to convert these indices to one-hot vectors.\n",
            "\n",
            "--- Chunk 9575 ---\n",
            "This may not be the best solution, though. The size of each one-hot vector is the\n",
            "\n",
            "--- Chunk 9576 ---\n",
            "vocabulary length plus the number of oov buckets. This is fine when there are just a\n",
            "\n",
            "--- Chunk 9577 ---\n",
            "few possible categories, but if the vocabulary is large, it is much more efficient to\n",
            "encode them using embeddings instead.\n",
            "\n",
            "--- Chunk 9578 ---\n",
            "As a rule of thumb, if the number of categories is lower than 10,\n",
            "then one-hot encoding is generally the way to go (but your mileage\n",
            "\n",
            "--- Chunk 9579 ---\n",
            "may vary!). If the number of categories is greater than 50 (which is\n",
            "often the case when you use hash buckets), then embeddings are\n",
            "\n",
            "--- Chunk 9580 ---\n",
            "usually preferable. In between 10 and 50 categories, you may want\n",
            "to experiment with both options and see which one works best for\n",
            "your use case.\n",
            "\n",
            "--- Chunk 9581 ---\n",
            "Encoding Categorical Features Using Embeddings\n",
            "An embedding is a trainable dense vector that represents a category. By default,\n",
            "\n",
            "--- Chunk 9582 ---\n",
            "embeddings are initialized randomly, so for example the \"NEAR BAY\" category could\n",
            "\n",
            "--- Chunk 9583 ---\n",
            "be represented initially by a random vector such as [0.131, 0.890], while the \"NEAR\n",
            "\n",
            "--- Chunk 9584 ---\n",
            "OCEAN\" category might be represented by another random vector such as [0.631,\n",
            "\n",
            "--- Chunk 9585 ---\n",
            "0.791]. In this example, we use 2D embeddings, but the number of dimensions is a\n",
            "\n",
            "--- Chunk 9586 ---\n",
            "hyperparameter you can tweak. Since these embeddings are trainable, they will grad‐\n",
            "\n",
            "--- Chunk 9587 ---\n",
            "ually improve during training; and as they represent fairly similar categories, Gradi‐\n",
            "\n",
            "--- Chunk 9588 ---\n",
            "ent Descent will certainly end up pushing them closer together, while it will tend to\n",
            "\n",
            "--- Chunk 9589 ---\n",
            "move them away from the \"INLAND\" category’s embedding (see Figure 13-4). Indeed,\n",
            "\n",
            "--- Chunk 9590 ---\n",
            "the better the representation, the easier it will be for the neural network to make\n",
            "\n",
            "--- Chunk 9591 ---\n",
            "accurate predictions, so training tends to make embeddings useful representations of\n",
            "\n",
            "--- Chunk 9592 ---\n",
            "Preprocessing the Input Features | 433\n",
            "\n",
            "--- Chunk 9593 ---\n",
            "the categories. This is called representation learning (we will see other types of repre‐\n",
            "sentation learning in Chapter 17).\n",
            "\n",
            "--- Chunk 9594 ---\n",
            "Figure 13-4. Embeddings will gradually improve during training\n",
            "\n",
            "--- Chunk 9595 ---\n",
            "Word Embeddings\n",
            "Not only will embeddings generally be useful representations for the task at hand, but\n",
            "\n",
            "--- Chunk 9596 ---\n",
            "quite often these same embeddings can be reused successfully for other tasks. The\n",
            "\n",
            "--- Chunk 9597 ---\n",
            "most common example of this is word embeddings (i.e., embeddings of individual\n",
            "\n",
            "--- Chunk 9598 ---\n",
            "words): when you are working on a natural language processing task, you are often\n",
            "\n",
            "--- Chunk 9599 ---\n",
            "better off reusing pretrained word embeddings than training your own.\n",
            "The idea of using vectors to represent words dates back to the 1960s, and many\n",
            "\n",
            "--- Chunk 9600 ---\n",
            "sophisticated techniques have been used to generate useful vectors, including using\n",
            "\n",
            "--- Chunk 9601 ---\n",
            "neural networks. But things really took off in 2013, when Tomáš Mikolov and other\n",
            "\n",
            "--- Chunk 9602 ---\n",
            "Google researchers published a paper9 describing an efficient technique to learn word\n",
            "\n",
            "--- Chunk 9603 ---\n",
            "embeddings using neural networks, significantly outperforming previous attempts.\n",
            "\n",
            "--- Chunk 9604 ---\n",
            "This allowed them to learn embeddings on a very large corpus of text: they trained a\n",
            "\n",
            "--- Chunk 9605 ---\n",
            "neural network to predict the words near any given word, and obtained astounding\n",
            "\n",
            "--- Chunk 9606 ---\n",
            "word embeddings. For example, synonyms had very close embeddings, and semanti‐\n",
            "\n",
            "--- Chunk 9607 ---\n",
            "cally related words such as France, Spain, and Italy ended up clustered together.\n",
            "\n",
            "--- Chunk 9608 ---\n",
            "It’s not just about proximity, though: word embeddings were also organized along\n",
            "\n",
            "--- Chunk 9609 ---\n",
            "meaningful axes in the embedding space. Here is a famous example: if you compute\n",
            "\n",
            "--- Chunk 9610 ---\n",
            "King – Man + Woman (adding and subtracting the embedding vectors of these\n",
            "\n",
            "--- Chunk 9611 ---\n",
            "words), then the result will be very close to the embedding of the word Queen (see\n",
            "\n",
            "--- Chunk 9612 ---\n",
            "Figure 13-5). In other words, the word embeddings encode the concept of gender!\n",
            "\n",
            "--- Chunk 9613 ---\n",
            "9 Tomas Mikolov et al., “Distributed Representations of Words and Phrases and Their Compositionality,” Pro‐\n",
            "\n",
            "--- Chunk 9614 ---\n",
            "ceedings of the 26th International Conference on Neural Information Processing Systems 2 (2013): 3111–3119.\n",
            "\n",
            "--- Chunk 9615 ---\n",
            "434 | Chapter 13: Loading and Preprocessing Data with TensorFlow\n",
            "\n",
            "--- Chunk 9616 ---\n",
            "Similarly, you can compute Madrid – Spain + France, and the result is close to Paris,\n",
            "\n",
            "--- Chunk 9617 ---\n",
            "which seems to show that the notion of capital city was also encoded in the\n",
            "embeddings.\n",
            "\n",
            "--- Chunk 9618 ---\n",
            "Figure 13-5. Word embeddings of similar words tend to be close, and some axes seem to\n",
            "encode meaningful concepts\n",
            "\n",
            "--- Chunk 9619 ---\n",
            "Unfortunately, word embeddings sometimes capture our worst biases. For example,\n",
            "\n",
            "--- Chunk 9620 ---\n",
            "although they correctly learn that Man is to King as Woman is to Queen, they also\n",
            "\n",
            "--- Chunk 9621 ---\n",
            "seem to learn that Man is to Doctor as Woman is to Nurse: quite a sexist bias! To be\n",
            "\n",
            "--- Chunk 9622 ---\n",
            "fair, this particular example is probably exaggerated, as was pointed out in a 2019\n",
            "\n",
            "--- Chunk 9623 ---\n",
            "paper10 by Malvina Nissim et al. Nevertheless, ensuring fairness in Deep Learning\n",
            "algorithms is an important and active research topic.\n",
            "\n",
            "--- Chunk 9624 ---\n",
            "Let’s look at how we could implement embeddings manually, to understand how they\n",
            "\n",
            "--- Chunk 9625 ---\n",
            "work (then we will use a simple Keras layer instead). First, we need to create an\n",
            "\n",
            "--- Chunk 9626 ---\n",
            "embedding matrix containing each category’s embedding, initialized randomly; it will\n",
            "\n",
            "--- Chunk 9627 ---\n",
            "have one row per category and per oov bucket, and one column per embedding\n",
            "dimension:\n",
            "\n",
            "--- Chunk 9628 ---\n",
            "embedding_dim = 2\n",
            "embed_init = tf.random.uniform([len(vocab) + num_oov_buckets, embedding_dim])\n",
            "embedding_matrix = tf.Variable(embed_init)\n",
            "\n",
            "--- Chunk 9629 ---\n",
            "10 Malvina Nissim et al., “Fair Is Better Than Sensational: Man Is to Doctor as Woman Is to Doctor,” arXiv pre‐\n",
            "print arXiv:1905.09866 (2019).\n",
            "\n",
            "--- Chunk 9630 ---\n",
            "Preprocessing the Input Features | 435\n",
            "\n",
            "--- Chunk 9631 ---\n",
            "In this example we are using 2D embeddings, but as a rule of thumb embeddings typ‐\n",
            "\n",
            "--- Chunk 9632 ---\n",
            "ically have 10 to 300 dimensions, depending on the task and the vocabulary size (you\n",
            "will have to tune this hyperparameter).\n",
            "\n",
            "--- Chunk 9633 ---\n",
            "This embedding matrix is a random 6 × 2 matrix, stored in a variable (so it can be\n",
            "tweaked by Gradient Descent during training):\n",
            "\n",
            "--- Chunk 9634 ---\n",
            ">>> embedding_matrix\n",
            "<tf.Variable 'Variable:0' shape=(6, 2) dtype=float32, numpy=\n",
            "array([[0.6645621 , 0.44100678],\n",
            "       [0.3528825 , 0.46448255],\n",
            "\n",
            "--- Chunk 9635 ---\n",
            "[0.03366041, 0.68467236],\n",
            "       [0.74011743, 0.8724445 ],\n",
            "       [0.22632635, 0.22319686],\n",
            "       [0.3103881 , 0.7223358 ]], dtype=float32)>\n",
            "\n",
            "--- Chunk 9636 ---\n",
            "Now let’s encode the same batch of categorical features as earlier, but this time using\n",
            "these embeddings:\n",
            "\n",
            "--- Chunk 9637 ---\n",
            ">>> categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
            ">>> cat_indices = table.lookup(categories)\n",
            ">>> cat_indices\n",
            "\n",
            "--- Chunk 9638 ---\n",
            ">>> cat_indices\n",
            "<tf.Tensor: id=741, shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1])>\n",
            ">>> tf.nn.embedding_lookup(embedding_matrix, cat_indices)\n",
            "\n",
            "--- Chunk 9639 ---\n",
            "<tf.Tensor: id=864, shape=(4, 2), dtype=float32, numpy=\n",
            "array([[0.74011743, 0.8724445 ],\n",
            "       [0.3103881 , 0.7223358 ],\n",
            "\n",
            "--- Chunk 9640 ---\n",
            "[0.3528825 , 0.46448255],\n",
            "       [0.3528825 , 0.46448255]], dtype=float32)>\n",
            "\n",
            "--- Chunk 9641 ---\n",
            "The tf.nn.embedding_lookup() function looks up the rows in the embedding\n",
            "\n",
            "--- Chunk 9642 ---\n",
            "matrix, at the given indices—that’s all it does. For example, the lookup table says that\n",
            "\n",
            "--- Chunk 9643 ---\n",
            "the \"INLAND\" category is at index 1, so the tf.nn.embedding_lookup() function\n",
            "\n",
            "--- Chunk 9644 ---\n",
            "returns the embedding at row 1 in the embedding matrix (twice): [0.3528825,\n",
            "0.46448255].\n",
            "\n",
            "--- Chunk 9645 ---\n",
            "0.46448255].\n",
            "Keras provides a keras.layers.Embedding layer that handles the embedding matrix\n",
            "\n",
            "--- Chunk 9646 ---\n",
            "(trainable, by default); when the layer is created it initializes the embedding matrix\n",
            "\n",
            "--- Chunk 9647 ---\n",
            "randomly, and then when it is called with some category indices it returns the rows at\n",
            "those indices in the embedding matrix:\n",
            "\n",
            "--- Chunk 9648 ---\n",
            ">>> embedding = keras.layers.Embedding(input_dim=len(vocab) + num_oov_buckets,\n",
            "...                                    output_dim=embedding_dim)\n",
            "...\n",
            "\n",
            "--- Chunk 9649 ---\n",
            "...\n",
            ">>> embedding(cat_indices)\n",
            "<tf.Tensor: id=814, shape=(4, 2), dtype=float32, numpy=\n",
            "array([[ 0.02401174,  0.03724445],\n",
            "\n",
            "--- Chunk 9650 ---\n",
            "[-0.01896119,  0.02223358],\n",
            "       [-0.01471175, -0.00355174],\n",
            "       [-0.01471175, -0.00355174]], dtype=float32)>\n",
            "\n",
            "--- Chunk 9651 ---\n",
            "436 | Chapter 13: Loading and Preprocessing Data with TensorFlow\n",
            "\n",
            "--- Chunk 9652 ---\n",
            "Putting everything together, we can now create a Keras model that can process cate‐\n",
            "\n",
            "--- Chunk 9653 ---\n",
            "gorical features (along with regular numerical features) and learn an embedding for\n",
            "each category (as well as for each oov bucket):\n",
            "\n",
            "--- Chunk 9654 ---\n",
            "regular_inputs = keras.layers.Input(shape=[8])\n",
            "categories = keras.layers.Input(shape=[], dtype=tf.string)\n",
            "\n",
            "--- Chunk 9655 ---\n",
            "cat_indices = keras.layers.Lambda(lambda cats: table.lookup(cats))(categories)\n",
            "\n",
            "--- Chunk 9656 ---\n",
            "cat_embed = keras.layers.Embedding(input_dim=6, output_dim=2)(cat_indices)\n",
            "encoded_inputs = keras.layers.concatenate([regular_inputs, cat_embed])\n",
            "\n",
            "--- Chunk 9657 ---\n",
            "outputs = keras.layers.Dense(1)(encoded_inputs)\n",
            "model = keras.models.Model(inputs=[regular_inputs, categories],\n",
            "\n",
            "--- Chunk 9658 ---\n",
            "outputs=[outputs])\n",
            "\n",
            "--- Chunk 9659 ---\n",
            "This model takes two inputs: a regular input containing eight numerical features per\n",
            "\n",
            "--- Chunk 9660 ---\n",
            "instance, plus a categorical input (containing one categorical feature per instance). It\n",
            "\n",
            "--- Chunk 9661 ---\n",
            "uses a Lambda layer to look up each category’s index, then it looks up the embeddings\n",
            "\n",
            "--- Chunk 9662 ---\n",
            "for these indices. Next, it concatenates the embeddings and the regular inputs in\n",
            "\n",
            "--- Chunk 9663 ---\n",
            "order to give the encoded inputs, which are ready to be fed to a neural network. We\n",
            "\n",
            "--- Chunk 9664 ---\n",
            "could add any kind of neural network at this point, but we just add a dense output\n",
            "layer, and we create the Keras model.\n",
            "\n",
            "--- Chunk 9665 ---\n",
            "When the keras.layers.TextVectorization layer is available, you can call its\n",
            "\n",
            "--- Chunk 9666 ---\n",
            "adapt() method to make it extract the vocabulary from a data sample (it will take\n",
            "\n",
            "--- Chunk 9667 ---\n",
            "care of creating the lookup table for you). Then you can add it to your model, and it\n",
            "\n",
            "--- Chunk 9668 ---\n",
            "will perform the index lookup (replacing the Lambda layer in the previous code\n",
            "example).\n",
            "\n",
            "--- Chunk 9669 ---\n",
            "One-hot encoding followed by a Dense layer (with no activation\n",
            "function and no biases) is equivalent to an Embedding layer. How‐\n",
            "\n",
            "--- Chunk 9670 ---\n",
            "ever, the Embedding layer uses way fewer computations (the perfor‐\n",
            "mance difference becomes clear when the size of the embedding\n",
            "\n",
            "--- Chunk 9671 ---\n",
            "matrix grows). The Dense layer’s weight matrix plays the role of the\n",
            "embedding matrix. For example, using one-hot vectors of size 20\n",
            "\n",
            "--- Chunk 9672 ---\n",
            "and a Dense layer with 10 units is equivalent to using an Embedding\n",
            "layer with input_dim=20 and output_dim=10. As a result, it would\n",
            "\n",
            "--- Chunk 9673 ---\n",
            "be wasteful to use more embedding dimensions than the number\n",
            "of units in the layer that follows the Embedding layer.\n",
            "\n",
            "--- Chunk 9674 ---\n",
            "Now let’s look a bit more closely at the Keras preprocessing layers.\n",
            "\n",
            "--- Chunk 9675 ---\n",
            "Keras Preprocessing Layers\n",
            "The TensorFlow team is working on providing a set of standard Keras preprocessing\n",
            "\n",
            "--- Chunk 9676 ---\n",
            "layers. They will probably be available by the time you read this; however, the API\n",
            "\n",
            "--- Chunk 9677 ---\n",
            "may change slightly by then, so please refer to the notebook for this chapter if any‐\n",
            "\n",
            "--- Chunk 9678 ---\n",
            "thing behaves unexpectedly. This new API will likely supersede the existing Feature\n",
            "\n",
            "--- Chunk 9679 ---\n",
            "Preprocessing the Input Features | 437\n",
            "\n",
            "--- Chunk 9680 ---\n",
            "Columns API, which is harder to use and less intuitive (if you want to learn more\n",
            "\n",
            "--- Chunk 9681 ---\n",
            "about the Feature Columns API anyway, please check out the notebook for this chap‐\n",
            "ter).\n",
            "\n",
            "--- Chunk 9682 ---\n",
            "ter).\n",
            "We already discussed two of these layers: the keras.layers.Normalization layer that\n",
            "\n",
            "--- Chunk 9683 ---\n",
            "will perform feature standardization (it will be equivalent to the Standardization\n",
            "\n",
            "--- Chunk 9684 ---\n",
            "layer we defined earlier), and the TextVectorization layer that will be capable of\n",
            "\n",
            "--- Chunk 9685 ---\n",
            "encoding each word in the inputs into its index in the vocabulary. In both cases, you\n",
            "\n",
            "--- Chunk 9686 ---\n",
            "create the layer, you call its adapt() method with a data sample, and then you use the\n",
            "\n",
            "--- Chunk 9687 ---\n",
            "layer normally in your model. The other preprocessing layers will follow the same\n",
            "pattern.\n",
            "\n",
            "--- Chunk 9688 ---\n",
            "pattern.\n",
            "The API will also include a keras.layers.Discretization layer that will chop con‐\n",
            "\n",
            "--- Chunk 9689 ---\n",
            "tinuous data into different bins and encode each bin as a one-hot vector. For example,\n",
            "\n",
            "--- Chunk 9690 ---\n",
            "you could use it to discretize prices into three categories, (low, medium, high), which\n",
            "\n",
            "--- Chunk 9691 ---\n",
            "would be encoded as [1, 0, 0], [0, 1, 0], and [0, 0, 1], respectively. Of course this loses a\n",
            "\n",
            "--- Chunk 9692 ---\n",
            "lot of information, but in some cases it can help the model detect patterns that would\n",
            "\n",
            "--- Chunk 9693 ---\n",
            "otherwise not be obvious when just looking at the continuous values.\n",
            "\n",
            "--- Chunk 9694 ---\n",
            "The Discretization layer will not be differentiable, and it should\n",
            "only be used at the start of your model. Indeed, the model’s prepro‐\n",
            "\n",
            "--- Chunk 9695 ---\n",
            "cessing layers will be frozen during training, so their parameters\n",
            "will not be affected by Gradient Descent, and thus they do not need\n",
            "\n",
            "--- Chunk 9696 ---\n",
            "to be differentiable. This also means that you should not use an\n",
            "Embedding layer directly in a custom preprocessing layer, if you\n",
            "\n",
            "--- Chunk 9697 ---\n",
            "want it to be trainable: instead, it should be added separately to\n",
            "your model, as in the previous code example.\n",
            "\n",
            "--- Chunk 9698 ---\n",
            "It will also be possible to chain multiple preprocessing layers using the Preproces\n",
            "\n",
            "--- Chunk 9699 ---\n",
            "singStage class. For example, the following code will create a preprocessing pipeline\n",
            "\n",
            "--- Chunk 9700 ---\n",
            "that will first normalize the inputs, then discretize them (this may remind you of\n",
            "\n",
            "--- Chunk 9701 ---\n",
            "Scikit-Learn pipelines). After you adapt this pipeline to a data sample, you can use it\n",
            "\n",
            "--- Chunk 9702 ---\n",
            "like a regular layer in your models (but again, only at the start of the model, since it\n",
            "contains a nondifferentiable preprocessing layer):\n",
            "\n",
            "--- Chunk 9703 ---\n",
            "normalization = keras.layers.Normalization()\n",
            "discretization = keras.layers.Discretization([...])\n",
            "\n",
            "--- Chunk 9704 ---\n",
            "pipeline = keras.layers.PreprocessingStage([normalization, discretization])\n",
            "pipeline.adapt(data_sample)\n",
            "\n",
            "--- Chunk 9705 ---\n",
            "The TextVectorization layer will also have an option to output word-count vectors\n",
            "\n",
            "--- Chunk 9706 ---\n",
            "instead of word indices. For example, if the vocabulary contains three words, say\n",
            "\n",
            "--- Chunk 9707 ---\n",
            "[\"and\", \"basketball\", \"more\"], then the text \"more and more\" will be mapped to\n",
            "\n",
            "--- Chunk 9708 ---\n",
            "the vector [1, 0, 2]: the word \"and\" appears once, the word \"basketball\" does not\n",
            "\n",
            "--- Chunk 9709 ---\n",
            "appear at all, and the word \"more\" appears twice. This text representation is called a\n",
            "\n",
            "--- Chunk 9710 ---\n",
            "438 | Chapter 13: Loading and Preprocessing Data with TensorFlow\n",
            "\n",
            "--- Chunk 9711 ---\n",
            "bag of words, since it completely loses the order of the words. Common words like\n",
            "\n",
            "--- Chunk 9712 ---\n",
            "\"and\" will have a large value in most texts, even though they are usually the least\n",
            "\n",
            "--- Chunk 9713 ---\n",
            "interesting (e.g., in the text \"more and more basketball\" the word \"basketball\" is\n",
            "\n",
            "--- Chunk 9714 ---\n",
            "clearly the most important, precisely because it is not a very frequent word). So, the\n",
            "\n",
            "--- Chunk 9715 ---\n",
            "word counts should be normalized in a way that reduces the importance of frequent\n",
            "\n",
            "--- Chunk 9716 ---\n",
            "words. A common way to do this is to divide each word count by the log of the total\n",
            "\n",
            "--- Chunk 9717 ---\n",
            "number of training instances in which the word appears. This technique is called\n",
            "\n",
            "--- Chunk 9718 ---\n",
            "Term-Frequency × Inverse-Document-Frequency (TF-IDF). For example, let’s imagine\n",
            "\n",
            "--- Chunk 9719 ---\n",
            "that the words \"and\", \"basketball\", and \"more\" appear respectively in 200, 10, and\n",
            "\n",
            "--- Chunk 9720 ---\n",
            "100 text instances in the training set: in this case, the final vector will be [1/\n",
            "\n",
            "--- Chunk 9721 ---\n",
            "log(200), 0/log(10), 2/log(100)], which is approximately equal to [0.19, 0.,\n",
            "\n",
            "--- Chunk 9722 ---\n",
            "0.43]. The TextVectorization layer will (likely) have an option to perform TF-IDF.\n",
            "\n",
            "--- Chunk 9723 ---\n",
            "If the standard preprocessing layers are insufficient for your task,\n",
            "you will still have the option to create your own custom prepro‐\n",
            "\n",
            "--- Chunk 9724 ---\n",
            "cessing layer, much like we did earlier with the Standardization\n",
            "class. Create a subclass of the keras.layers.PreprocessingLayer\n",
            "\n",
            "--- Chunk 9725 ---\n",
            "class with an adapt() method, which should take a data_sample\n",
            "argument and optionally an extra reset_state argument: if True,\n",
            "\n",
            "--- Chunk 9726 ---\n",
            "then the adapt() method should reset any existing state before\n",
            "computing the new state; if False, it should try to update the exist‐\n",
            "ing state.\n",
            "\n",
            "--- Chunk 9727 ---\n",
            "As you can see, these Keras preprocessing layers will make preprocessing much eas‐\n",
            "\n",
            "--- Chunk 9728 ---\n",
            "ier! Now, whether you choose to write your own preprocessing layers or use Keras’s\n",
            "\n",
            "--- Chunk 9729 ---\n",
            "(or even use the Feature Columns API), all the preprocessing will be done on the fly.\n",
            "\n",
            "--- Chunk 9730 ---\n",
            "During training, however, it may be preferable to perform preprocessing ahead of\n",
            "time. Let’s see why we’d want to do that and how we’d go about it.\n",
            "\n",
            "--- Chunk 9731 ---\n",
            "TF Transform\n",
            "If preprocessing is computationally expensive, then handling it before training rather\n",
            "\n",
            "--- Chunk 9732 ---\n",
            "than on the fly may give you a significant speedup: the data will be preprocessed just\n",
            "\n",
            "--- Chunk 9733 ---\n",
            "once per instance before training, rather than once per instance and per epoch during\n",
            "\n",
            "--- Chunk 9734 ---\n",
            "training. As mentioned earlier, if the dataset is small enough to fit in RAM, you can\n",
            "\n",
            "--- Chunk 9735 ---\n",
            "use its cache() method. But if it is too large, then tools like Apache Beam or Spark\n",
            "\n",
            "--- Chunk 9736 ---\n",
            "will help. They let you run efficient data processing pipelines over large amounts of\n",
            "\n",
            "--- Chunk 9737 ---\n",
            "data, even distributed across multiple servers, so you can use them to preprocess all\n",
            "the training data before training.\n",
            "\n",
            "--- Chunk 9738 ---\n",
            "This works great and indeed can speed up training, but there is one problem: once\n",
            "\n",
            "--- Chunk 9739 ---\n",
            "your model is trained, suppose you want to deploy it to a mobile app. In that case you\n",
            "\n",
            "--- Chunk 9740 ---\n",
            "will need to write some code in your app to take care of preprocessing the data before\n",
            "\n",
            "--- Chunk 9741 ---\n",
            "TF Transform | 439\n",
            "\n",
            "--- Chunk 9742 ---\n",
            "it is fed to the model. And suppose you also want to deploy the model to Tensor‐\n",
            "\n",
            "--- Chunk 9743 ---\n",
            "Flow.js so that it runs in a web browser? Once again, you will need to write some pre‐\n",
            "\n",
            "--- Chunk 9744 ---\n",
            "processing code. This can become a maintenance nightmare: whenever you want to\n",
            "\n",
            "--- Chunk 9745 ---\n",
            "change the preprocessing logic, you will need to update your Apache Beam code,\n",
            "\n",
            "--- Chunk 9746 ---\n",
            "your mobile app code, and your JavaScript code. This is not only time-consuming,\n",
            "\n",
            "--- Chunk 9747 ---\n",
            "but also error-prone: you may end up with subtle differences between the preprocess‐\n",
            "\n",
            "--- Chunk 9748 ---\n",
            "ing operations performed before training and the ones performed in your app or in\n",
            "\n",
            "--- Chunk 9749 ---\n",
            "the browser. This training/serving skew will lead to bugs or degraded performance.\n",
            "\n",
            "--- Chunk 9750 ---\n",
            "One improvement would be to take the trained model (trained on data that was pre‐\n",
            "\n",
            "--- Chunk 9751 ---\n",
            "processed by your Apache Beam or Spark code) and, before deploying it to your app\n",
            "\n",
            "--- Chunk 9752 ---\n",
            "or the browser, add extra preprocessing layers to take care of preprocessing on the fly.\n",
            "\n",
            "--- Chunk 9753 ---\n",
            "That’s definitely better, since now you just have two versions of your preprocessing\n",
            "\n",
            "--- Chunk 9754 ---\n",
            "code: the Apache Beam or Spark code, and the preprocessing layers’ code.\n",
            "\n",
            "--- Chunk 9755 ---\n",
            "But what if you could define your preprocessing operations just once? This is what\n",
            "\n",
            "--- Chunk 9756 ---\n",
            "TF Transform was designed for. It is part of TensorFlow Extended (TFX), an end-to-\n",
            "\n",
            "--- Chunk 9757 ---\n",
            "end platform for productionizing TensorFlow models. First, to use a TFX component\n",
            "\n",
            "--- Chunk 9758 ---\n",
            "such as TF Transform, you must install it; it does not come bundled with TensorFlow.\n",
            "\n",
            "--- Chunk 9759 ---\n",
            "You then define your preprocessing function just once (in Python), by using TF\n",
            "\n",
            "--- Chunk 9760 ---\n",
            "Transform functions for scaling, bucketizing, and more. You can also use any Tensor‐\n",
            "\n",
            "--- Chunk 9761 ---\n",
            "Flow operation you need. Here is what this preprocessing function might look like if\n",
            "we just had two features:\n",
            "\n",
            "--- Chunk 9762 ---\n",
            "import tensorflow_transform as tft\n",
            "\n",
            "--- Chunk 9763 ---\n",
            "def preprocess(inputs):  # inputs = a batch of input features\n",
            "    median_age = inputs[\"housing_median_age\"]\n",
            "\n",
            "--- Chunk 9764 ---\n",
            "ocean_proximity = inputs[\"ocean_proximity\"]\n",
            "    standardized_age = tft.scale_to_z_score(median_age)\n",
            "\n",
            "--- Chunk 9765 ---\n",
            "ocean_proximity_id = tft.compute_and_apply_vocabulary(ocean_proximity)\n",
            "    return {\n",
            "        \"standardized_median_age\": standardized_age,\n",
            "\n",
            "--- Chunk 9766 ---\n",
            "\"ocean_proximity_id\": ocean_proximity_id\n",
            "    }\n",
            "\n",
            "--- Chunk 9767 ---\n",
            "Next, TF Transform lets you apply this preprocess() function to the whole training\n",
            "\n",
            "--- Chunk 9768 ---\n",
            "set using Apache Beam (it provides an AnalyzeAndTransformDataset class that you\n",
            "\n",
            "--- Chunk 9769 ---\n",
            "can use for this purpose in your Apache Beam pipeline). In the process, it will also\n",
            "\n",
            "--- Chunk 9770 ---\n",
            "compute all the necessary statistics over the whole training set: in this example, the\n",
            "\n",
            "--- Chunk 9771 ---\n",
            "mean and standard deviation of the housing_median_age feature, and the vocabulary\n",
            "\n",
            "--- Chunk 9772 ---\n",
            "for the ocean_proximity feature. The components that compute these statistics are\n",
            "called analyzers.\n",
            "\n",
            "--- Chunk 9773 ---\n",
            "called analyzers.\n",
            "Importantly, TF Transform will also generate an equivalent TensorFlow Function that\n",
            "\n",
            "--- Chunk 9774 ---\n",
            "you can plug into the model you deploy. This TF Function includes some constants\n",
            "\n",
            "--- Chunk 9775 ---\n",
            "440 | Chapter 13: Loading and Preprocessing Data with TensorFlow\n",
            "\n",
            "--- Chunk 9776 ---\n",
            "that correspond to all the all the necessary statistics computed by Apache Beam (the\n",
            "mean, standard deviation, and vocabulary).\n",
            "\n",
            "--- Chunk 9777 ---\n",
            "With the Data API, TFRecords, the Keras preprocessing layers, and TF Transform,\n",
            "\n",
            "--- Chunk 9778 ---\n",
            "you can build highly scalable input pipelines for training and benefit from fast and\n",
            "portable data preprocessing in production.\n",
            "\n",
            "--- Chunk 9779 ---\n",
            "But what if you just wanted to use a standard dataset? Well in that case, things are\n",
            "much simpler: just use TFDS!\n",
            "\n",
            "--- Chunk 9780 ---\n",
            "The TensorFlow Datasets (TFDS) Project\n",
            "The TensorFlow Datasets project makes it very easy to download common datasets,\n",
            "\n",
            "--- Chunk 9781 ---\n",
            "from small ones like MNIST or Fashion MNIST to huge datasets like ImageNet (you\n",
            "\n",
            "--- Chunk 9782 ---\n",
            "will need quite a bit of disk space!). The list includes image datasets, text datasets\n",
            "\n",
            "--- Chunk 9783 ---\n",
            "(including translation datasets), and audio and video datasets. You can visit https://\n",
            "\n",
            "--- Chunk 9784 ---\n",
            "homl.info/tfds to view the full list, along with a description of each dataset.\n",
            "\n",
            "--- Chunk 9785 ---\n",
            "TFDS is not bundled with TensorFlow, so you need to install the tensorflow-\n",
            "\n",
            "--- Chunk 9786 ---\n",
            "datasets library (e.g., using pip). Then call the tfds.load() function, and it will\n",
            "\n",
            "--- Chunk 9787 ---\n",
            "download the data you want (unless it was already downloaded earlier) and return\n",
            "\n",
            "--- Chunk 9788 ---\n",
            "the data as a dictionary of datasets (typically one for training and one for testing, but\n",
            "\n",
            "--- Chunk 9789 ---\n",
            "this depends on the dataset you choose). For example, let’s download MNIST:\n",
            "\n",
            "--- Chunk 9790 ---\n",
            "import tensorflow_datasets as tfds\n",
            "\n",
            "dataset = tfds.load(name=\"mnist\")\n",
            "mnist_train, mnist_test = dataset[\"train\"], dataset[\"test\"]\n",
            "\n",
            "--- Chunk 9791 ---\n",
            "You can then apply any transformation you want (typically shuffling, batching, and\n",
            "\n",
            "--- Chunk 9792 ---\n",
            "prefetching), and you’re ready to train your model. Here is a simple example:\n",
            "\n",
            "--- Chunk 9793 ---\n",
            "mnist_train = mnist_train.shuffle(10000).batch(32).prefetch(1)\n",
            "for item in mnist_train:\n",
            "    images = item[\"image\"]\n",
            "    labels = item[\"label\"]\n",
            "\n",
            "--- Chunk 9794 ---\n",
            "[...]\n",
            "\n",
            "--- Chunk 9795 ---\n",
            "The load() function shuffles each data shard it downloads (only\n",
            "for the training set). This may not be sufficient, so it’s best to shuf‐\n",
            "\n",
            "--- Chunk 9796 ---\n",
            "fle the training data some more.\n",
            "\n",
            "--- Chunk 9797 ---\n",
            "Note that each item in the dataset is a dictionary containing both the features and the\n",
            "\n",
            "--- Chunk 9798 ---\n",
            "labels. But Keras expects each item to be a tuple containing two elements (again, the\n",
            "\n",
            "--- Chunk 9799 ---\n",
            "features and the labels). You could transform the dataset using the map() method, like\n",
            "this:\n",
            "\n",
            "--- Chunk 9800 ---\n",
            "The TensorFlow Datasets (TFDS) Project | 441\n",
            "\n",
            "--- Chunk 9801 ---\n",
            "mnist_train = mnist_train.shuffle(10000).batch(32)\n",
            "mnist_train = mnist_train.map(lambda items: (items[\"image\"], items[\"label\"]))\n",
            "\n",
            "--- Chunk 9802 ---\n",
            "mnist_train = mnist_train.prefetch(1)\n",
            "\n",
            "--- Chunk 9803 ---\n",
            "But it’s simpler to ask the load() function to do this for you by setting as_super\n",
            "\n",
            "--- Chunk 9804 ---\n",
            "vised=True (obviously this works only for labeled datasets). You can also specify the\n",
            "\n",
            "--- Chunk 9805 ---\n",
            "batch size if you want. Then you can pass the dataset directly to your tf.keras model:\n",
            "\n",
            "--- Chunk 9806 ---\n",
            "dataset = tfds.load(name=\"mnist\", batch_size=32, as_supervised=True)\n",
            "mnist_train = dataset[\"train\"].prefetch(1)\n",
            "\n",
            "--- Chunk 9807 ---\n",
            "model = keras.models.Sequential([...])\n",
            "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\")\n",
            "model.fit(mnist_train, epochs=5)\n",
            "\n",
            "--- Chunk 9808 ---\n",
            "This was quite a technical chapter, and you may feel that it is a bit far from the\n",
            "\n",
            "--- Chunk 9809 ---\n",
            "abstract beauty of neural networks, but the fact is Deep Learning often involves large\n",
            "\n",
            "--- Chunk 9810 ---\n",
            "amounts of data, and knowing how to load, parse, and preprocess it efficiently is a\n",
            "\n",
            "--- Chunk 9811 ---\n",
            "crucial skill to have. In the next chapter, we will look at convolutional neural net‐\n",
            "\n",
            "--- Chunk 9812 ---\n",
            "works, which are among the most successful neural net architectures for image pro‐\n",
            "cessing and many other applications.\n",
            "\n",
            "--- Chunk 9813 ---\n",
            "Exercises\n",
            "1. Why would you want to use the Data API?\n",
            "2. What are the benefits of splitting a large dataset into multiple files?\n",
            "\n",
            "--- Chunk 9814 ---\n",
            "3. During training, how can you tell that your input pipeline is the bottleneck?\n",
            "\n",
            "--- Chunk 9815 ---\n",
            "What can you do to fix it?\n",
            "4. Can you save any binary data to a TFRecord file, or only serialized protocol\n",
            "\n",
            "--- Chunk 9816 ---\n",
            "buffers?\n",
            "5. Why would you go through the hassle of converting all your data to the Example\n",
            "\n",
            "--- Chunk 9817 ---\n",
            "protobuf format? Why not use your own protobuf definition?\n",
            "6. When using TFRecords, when would you want to activate compression? Why\n",
            "\n",
            "--- Chunk 9818 ---\n",
            "not do it systematically?\n",
            "7. Data can be preprocessed directly when writing the data files, or within the\n",
            "\n",
            "--- Chunk 9819 ---\n",
            "tf.data pipeline, or in preprocessing layers within your model, or using TF Trans‐\n",
            "form. Can you list a few pros and cons of each option?\n",
            "\n",
            "--- Chunk 9820 ---\n",
            "8. Name a few common techniques you can use to encode categorical features.\n",
            "What about text?\n",
            "\n",
            "--- Chunk 9821 ---\n",
            "9. Load the Fashion MNIST dataset (introduced in Chapter 10); split it into a train‐\n",
            "\n",
            "--- Chunk 9822 ---\n",
            "ing set, a validation set, and a test set; shuffle the training set; and save each\n",
            "\n",
            "--- Chunk 9823 ---\n",
            "dataset to multiple TFRecord files. Each record should be a serialized Example\n",
            "\n",
            "--- Chunk 9824 ---\n",
            "protobuf with two features: the serialized image (use tf.io.serialize_tensor()\n",
            "\n",
            "--- Chunk 9825 ---\n",
            "442 | Chapter 13: Loading and Preprocessing Data with TensorFlow\n",
            "\n",
            "--- Chunk 9826 ---\n",
            "to serialize each image), and the label.11 Then use tf.data to create an efficient\n",
            "\n",
            "--- Chunk 9827 ---\n",
            "dataset for each set. Finally, use a Keras model to train these datasets, including a\n",
            "\n",
            "--- Chunk 9828 ---\n",
            "preprocessing layer to standardize each input feature. Try to make the input\n",
            "\n",
            "--- Chunk 9829 ---\n",
            "pipeline as efficient as possible, using TensorBoard to visualize profiling data.\n",
            "\n",
            "--- Chunk 9830 ---\n",
            "10. In this exercise you will download a dataset, split it, create a tf.data.Dataset to\n",
            "\n",
            "--- Chunk 9831 ---\n",
            "load it and preprocess it efficiently, then build and train a binary classification\n",
            "model containing an Embedding layer:\n",
            "\n",
            "--- Chunk 9832 ---\n",
            "a. Download the Large Movie Review Dataset, which contains 50,000 movies\n",
            "\n",
            "--- Chunk 9833 ---\n",
            "reviews from the Internet Movie Database. The data is organized in two direc‐\n",
            "\n",
            "--- Chunk 9834 ---\n",
            "tories, train and test, each containing a pos subdirectory with 12,500 positive\n",
            "\n",
            "--- Chunk 9835 ---\n",
            "reviews and a neg subdirectory with 12,500 negative reviews. Each review is\n",
            "\n",
            "--- Chunk 9836 ---\n",
            "stored in a separate text file. There are other files and folders (including pre‐\n",
            "processed bag-of-words), but we will ignore them in this exercise.\n",
            "\n",
            "--- Chunk 9837 ---\n",
            "b. Split the test set into a validation set (15,000) and a test set (10,000).\n",
            "c. Use tf.data to create an efficient dataset for each set.\n",
            "\n",
            "--- Chunk 9838 ---\n",
            "d. Create a binary classification model, using a TextVectorization layer to pre‐\n",
            "\n",
            "--- Chunk 9839 ---\n",
            "process each review. If the TextVectorization layer is not yet available (or if\n",
            "\n",
            "--- Chunk 9840 ---\n",
            "you like a challenge), try to create your own custom preprocessing layer: you\n",
            "can use the functions in the tf.strings package, for example lower() to\n",
            "\n",
            "--- Chunk 9841 ---\n",
            "make everything lowercase, regex_replace() to replace punctuation with\n",
            "spaces, and split() to split words on spaces. You should use a lookup table to\n",
            "\n",
            "--- Chunk 9842 ---\n",
            "output word indices, which must be prepared in the adapt() method.\n",
            "\n",
            "--- Chunk 9843 ---\n",
            "e. Add an Embedding layer and compute the mean embedding for each review,\n",
            "\n",
            "--- Chunk 9844 ---\n",
            "multiplied by the square root of the number of words (see Chapter 16). This\n",
            "rescaled mean embedding can then be passed to the rest of your model.\n",
            "\n",
            "--- Chunk 9845 ---\n",
            "f. Train the model and see what accuracy you get. Try to optimize your pipelines\n",
            "to make training as fast as possible.\n",
            "\n",
            "--- Chunk 9846 ---\n",
            "g. Use TFDS to load the same dataset more easily: tfds.load(\"imdb_reviews\").\n",
            "\n",
            "Solutions to these exercises are available in Appendix A.\n",
            "\n",
            "--- Chunk 9847 ---\n",
            "11 For large images, you could use tf.io.encode_jpeg() instead. This would save a lot of space, but it would\n",
            "lose a bit of image quality.\n",
            "\n",
            "--- Chunk 9848 ---\n",
            "Exercises | 443\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER 14\n",
            "Deep Computer Vision Using\n",
            "\n",
            "Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 9849 ---\n",
            "Although IBM’s Deep Blue supercomputer beat the chess world champion Garry Kas‐\n",
            "\n",
            "--- Chunk 9850 ---\n",
            "parov back in 1996, it wasn’t until fairly recently that computers were able to reliably\n",
            "\n",
            "--- Chunk 9851 ---\n",
            "perform seemingly trivial tasks such as detecting a puppy in a picture or recognizing\n",
            "\n",
            "--- Chunk 9852 ---\n",
            "spoken words. Why are these tasks so effortless to us humans? The answer lies in the\n",
            "\n",
            "--- Chunk 9853 ---\n",
            "fact that perception largely takes place outside the realm of our consciousness, within\n",
            "\n",
            "--- Chunk 9854 ---\n",
            "specialized visual, auditory, and other sensory modules in our brains. By the time\n",
            "\n",
            "--- Chunk 9855 ---\n",
            "sensory information reaches our consciousness, it is already adorned with high-level\n",
            "\n",
            "--- Chunk 9856 ---\n",
            "features; for example, when you look at a picture of a cute puppy, you cannot choose\n",
            "\n",
            "--- Chunk 9857 ---\n",
            "not to see the puppy, not to notice its cuteness. Nor can you explain how you recog‐\n",
            "\n",
            "--- Chunk 9858 ---\n",
            "nize a cute puppy; it’s just obvious to you. Thus, we cannot trust our subjective expe‐\n",
            "\n",
            "--- Chunk 9859 ---\n",
            "rience: perception is not trivial at all, and to understand it we must look at how the\n",
            "sensory modules work.\n",
            "\n",
            "--- Chunk 9860 ---\n",
            "Convolutional neural networks (CNNs) emerged from the study of the brain’s visual\n",
            "\n",
            "--- Chunk 9861 ---\n",
            "cortex, and they have been used in image recognition since the 1980s. In the last few\n",
            "\n",
            "--- Chunk 9862 ---\n",
            "years, thanks to the increase in computational power, the amount of available training\n",
            "\n",
            "--- Chunk 9863 ---\n",
            "data, and the tricks presented in Chapter 11 for training deep nets, CNNs have man‐\n",
            "\n",
            "--- Chunk 9864 ---\n",
            "aged to achieve superhuman performance on some complex visual tasks. They power\n",
            "\n",
            "--- Chunk 9865 ---\n",
            "image search services, self-driving cars, automatic video classification systems, and\n",
            "\n",
            "--- Chunk 9866 ---\n",
            "more. Moreover, CNNs are not restricted to visual perception: they are also successful\n",
            "\n",
            "--- Chunk 9867 ---\n",
            "at many other tasks, such as voice recognition and natural language processing. How‐\n",
            "ever, we will focus on visual applications for now.\n",
            "\n",
            "--- Chunk 9868 ---\n",
            "In this chapter we will explore where CNNs came from, what their building blocks\n",
            "\n",
            "--- Chunk 9869 ---\n",
            "look like, and how to implement them using TensorFlow and Keras. Then we will dis‐\n",
            "\n",
            "--- Chunk 9870 ---\n",
            "cuss some of the best CNN architectures, as well as other visual tasks, including\n",
            "\n",
            "--- Chunk 9871 ---\n",
            "445\n",
            "\n",
            "--- Chunk 9872 ---\n",
            "object detection (classifying multiple objects in an image and placing bounding boxes\n",
            "\n",
            "--- Chunk 9873 ---\n",
            "around them) and semantic segmentation (classifying each pixel according to the\n",
            "class of the object it belongs to).\n",
            "\n",
            "--- Chunk 9874 ---\n",
            "The Architecture of the Visual Cortex\n",
            "David H. Hubel and Torsten Wiesel performed a series of experiments on cats in\n",
            "\n",
            "--- Chunk 9875 ---\n",
            "19581 and 19592 (and a few years later on monkeys3), giving crucial insights into the\n",
            "\n",
            "--- Chunk 9876 ---\n",
            "structure of the visual cortex (the authors received the Nobel Prize in Physiology or\n",
            "\n",
            "--- Chunk 9877 ---\n",
            "Medicine in 1981 for their work). In particular, they showed that many neurons in\n",
            "\n",
            "--- Chunk 9878 ---\n",
            "the visual cortex have a small local receptive field, meaning they react only to visual\n",
            "\n",
            "--- Chunk 9879 ---\n",
            "stimuli located in a limited region of the visual field (see Figure 14-1, in which the\n",
            "\n",
            "--- Chunk 9880 ---\n",
            "local receptive fields of five neurons are represented by dashed circles). The receptive\n",
            "\n",
            "--- Chunk 9881 ---\n",
            "fields of different neurons may overlap, and together they tile the whole visual field.\n",
            "\n",
            "--- Chunk 9882 ---\n",
            "Moreover, the authors showed that some neurons react only to images of horizontal\n",
            "\n",
            "--- Chunk 9883 ---\n",
            "lines, while others react only to lines with different orientations (two neurons may\n",
            "\n",
            "--- Chunk 9884 ---\n",
            "have the same receptive field but react to different line orientations). They also\n",
            "\n",
            "--- Chunk 9885 ---\n",
            "noticed that some neurons have larger receptive fields, and they react to more com‐\n",
            "\n",
            "--- Chunk 9886 ---\n",
            "plex patterns that are combinations of the lower-level patterns. These observations\n",
            "\n",
            "--- Chunk 9887 ---\n",
            "led to the idea that the higher-level neurons are based on the outputs of neighboring\n",
            "\n",
            "--- Chunk 9888 ---\n",
            "lower-level neurons (in Figure 14-1, notice that each neuron is connected only to a\n",
            "\n",
            "--- Chunk 9889 ---\n",
            "few neurons from the previous layer). This powerful architecture is able to detect all\n",
            "sorts of complex patterns in any area of the visual field.\n",
            "\n",
            "--- Chunk 9890 ---\n",
            "1 David H. Hubel, “Single Unit Activity in Striate Cortex of Unrestrained Cats,” The Journal of Physiology 147\n",
            "(1959): 226–238.\n",
            "\n",
            "--- Chunk 9891 ---\n",
            "2 David H. Hubel and Torsten N. Wiesel, “Receptive Fields of Single Neurons in the Cat’s Striate Cortex,” The\n",
            "\n",
            "--- Chunk 9892 ---\n",
            "Journal of Physiology 148 (1959): 574–591.\n",
            "\n",
            "--- Chunk 9893 ---\n",
            "3 David H. Hubel and Torsten N. Wiesel, “Receptive Fields and Functional Architecture of Monkey Striate Cor‐\n",
            "\n",
            "--- Chunk 9894 ---\n",
            "tex,” The Journal of Physiology 195 (1968): 215–243.\n",
            "\n",
            "--- Chunk 9895 ---\n",
            "446 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 9896 ---\n",
            "Figure 14-1. Biological neurons in the visual cortex respond to specific patterns in small\n",
            "\n",
            "--- Chunk 9897 ---\n",
            "regions of the visual field called receptive fields; as the visual signal makes its way\n",
            "\n",
            "--- Chunk 9898 ---\n",
            "through consecutive brain modules, neurons respond to more complex patterns in larger\n",
            "receptive fields.\n",
            "\n",
            "--- Chunk 9899 ---\n",
            "These studies of the visual cortex inspired the neocognitron,4 introduced in 1980,\n",
            "\n",
            "--- Chunk 9900 ---\n",
            "which gradually evolved into what we now call convolutional neural networks. An\n",
            "\n",
            "--- Chunk 9901 ---\n",
            "important milestone was a 1998 paper5 by Yann LeCun et al. that introduced the\n",
            "\n",
            "--- Chunk 9902 ---\n",
            "famous LeNet-5 architecture, widely used by banks to recognize handwritten check\n",
            "\n",
            "--- Chunk 9903 ---\n",
            "numbers. This architecture has some building blocks that you already know, such as\n",
            "\n",
            "--- Chunk 9904 ---\n",
            "fully connected layers and sigmoid activation functions, but it also introduces two\n",
            "\n",
            "--- Chunk 9905 ---\n",
            "new building blocks: convolutional layers and pooling layers. Let’s look at them now.\n",
            "\n",
            "--- Chunk 9906 ---\n",
            "Why not simply use a deep neural network with fully connected\n",
            "layers for image recognition tasks? Unfortunately, although this\n",
            "\n",
            "--- Chunk 9907 ---\n",
            "works fine for small images (e.g., MNIST), it breaks down for\n",
            "larger images because of the huge number of parameters it\n",
            "\n",
            "--- Chunk 9908 ---\n",
            "requires. For example, a 100 × 100–pixel image has 10,000 pixels,\n",
            "and if the first layer has just 1,000 neurons (which already severely\n",
            "\n",
            "--- Chunk 9909 ---\n",
            "restricts the amount of information transmitted to the next layer),\n",
            "this means a total of 10 million connections. And that’s just the first\n",
            "\n",
            "--- Chunk 9910 ---\n",
            "layer. CNNs solve this problem using partially connected layers and\n",
            "weight sharing.\n",
            "\n",
            "--- Chunk 9911 ---\n",
            "4 Kunihiko Fukushima, “Neocognitron: A Self-Organizing Neural Network Model for a Mechanism of Pattern\n",
            "\n",
            "--- Chunk 9912 ---\n",
            "Recognition Unaffected by Shift in Position,” Biological Cybernetics 36 (1980): 193–202.\n",
            "\n",
            "--- Chunk 9913 ---\n",
            "5 Yann LeCun et al., “Gradient-Based Learning Applied to Document Recognition,” Proceedings of the IEEE 86,\n",
            "no. 11 (1998): 2278–2324.\n",
            "\n",
            "--- Chunk 9914 ---\n",
            "The Architecture of the Visual Cortex | 447\n",
            "\n",
            "--- Chunk 9915 ---\n",
            "Convolutional Layers\n",
            "The most important building block of a CNN is the convolutional layer:6 neurons in\n",
            "\n",
            "--- Chunk 9916 ---\n",
            "the first convolutional layer are not connected to every single pixel in the input image\n",
            "\n",
            "--- Chunk 9917 ---\n",
            "(like they were in the layers discussed in previous chapters), but only to pixels in their\n",
            "\n",
            "--- Chunk 9918 ---\n",
            "receptive fields (see Figure 14-2). In turn, each neuron in the second convolutional\n",
            "\n",
            "--- Chunk 9919 ---\n",
            "layer is connected only to neurons located within a small rectangle in the first layer.\n",
            "\n",
            "--- Chunk 9920 ---\n",
            "This architecture allows the network to concentrate on small low-level features in the\n",
            "\n",
            "--- Chunk 9921 ---\n",
            "first hidden layer, then assemble them into larger higher-level features in the next\n",
            "\n",
            "--- Chunk 9922 ---\n",
            "hidden layer, and so on. This hierarchical structure is common in real-world images,\n",
            "\n",
            "--- Chunk 9923 ---\n",
            "which is one of the reasons why CNNs work so well for image recognition.\n",
            "\n",
            "--- Chunk 9924 ---\n",
            "Figure 14-2. CNN layers with rectangular local receptive fields\n",
            "\n",
            "--- Chunk 9925 ---\n",
            "All the multilayer neural networks we’ve looked at so far had layers\n",
            "composed of a long line of neurons, and we had to flatten input\n",
            "\n",
            "--- Chunk 9926 ---\n",
            "images to 1D before feeding them to the neural network. In a CNN\n",
            "each layer is represented in 2D, which makes it easier to match\n",
            "\n",
            "--- Chunk 9927 ---\n",
            "neurons with their corresponding inputs.\n",
            "\n",
            "--- Chunk 9928 ---\n",
            "6 A convolution is a mathematical operation that slides one function over another and measures the integral of\n",
            "\n",
            "--- Chunk 9929 ---\n",
            "their pointwise multiplication. It has deep connections with the Fourier transform and the Laplace transform\n",
            "\n",
            "--- Chunk 9930 ---\n",
            "and is heavily used in signal processing. Convolutional layers actually use cross-correlations, which are very\n",
            "\n",
            "--- Chunk 9931 ---\n",
            "similar to convolutions (see https://homl.info/76 for more details).\n",
            "\n",
            "--- Chunk 9932 ---\n",
            "448 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 9933 ---\n",
            "A neuron located in row i, column j of a given layer is connected to the outputs of the\n",
            "\n",
            "--- Chunk 9934 ---\n",
            "neurons in the previous layer located in rows i to i + fh – 1, columns j to j + fw – 1,\n",
            "\n",
            "--- Chunk 9935 ---\n",
            "where fh and fw are the height and width of the receptive field (see Figure 14-3). In\n",
            "\n",
            "--- Chunk 9936 ---\n",
            "order for a layer to have the same height and width as the previous layer, it is com‐\n",
            "\n",
            "--- Chunk 9937 ---\n",
            "mon to add zeros around the inputs, as shown in the diagram. This is called zero\n",
            "padding.\n",
            "\n",
            "--- Chunk 9938 ---\n",
            "Figure 14-3. Connections between layers and zero padding\n",
            "\n",
            "--- Chunk 9939 ---\n",
            "It is also possible to connect a large input layer to a much smaller layer by spacing out\n",
            "\n",
            "--- Chunk 9940 ---\n",
            "the receptive fields, as shown in Figure 14-4. This dramatically reduces the model’s\n",
            "\n",
            "--- Chunk 9941 ---\n",
            "computational complexity. The shift from one receptive field to the next is called the\n",
            "\n",
            "--- Chunk 9942 ---\n",
            "stride. In the diagram, a 5 × 7 input layer (plus zero padding) is connected to a 3 × 4\n",
            "\n",
            "--- Chunk 9943 ---\n",
            "layer, using 3 × 3 receptive fields and a stride of 2 (in this example the stride is the\n",
            "\n",
            "--- Chunk 9944 ---\n",
            "same in both directions, but it does not have to be so). A neuron located in row i,\n",
            "\n",
            "--- Chunk 9945 ---\n",
            "column j in the upper layer is connected to the outputs of the neurons in the previous\n",
            "\n",
            "--- Chunk 9946 ---\n",
            "layer located in rows i × sh to i × sh + fh – 1, columns j × sw to j × sw + fw – 1, where sh\n",
            "and sw are the vertical and horizontal strides.\n",
            "\n",
            "--- Chunk 9947 ---\n",
            "Convolutional Layers | 449\n",
            "\n",
            "\n",
            "\n",
            "Figure 14-4. Reducing dimensionality using a stride of 2\n",
            "\n",
            "--- Chunk 9948 ---\n",
            "Filters\n",
            "A neuron’s weights can be represented as a small image the size of the receptive field.\n",
            "\n",
            "--- Chunk 9949 ---\n",
            "For example, Figure 14-5 shows two possible sets of weights, called filters (or convolu‐\n",
            "\n",
            "--- Chunk 9950 ---\n",
            "tion kernels). The first one is represented as a black square with a vertical white line in\n",
            "\n",
            "--- Chunk 9951 ---\n",
            "the middle (it is a 7 × 7 matrix full of 0s except for the central column, which is full of\n",
            "\n",
            "--- Chunk 9952 ---\n",
            "1s); neurons using these weights will ignore everything in their receptive field except\n",
            "\n",
            "--- Chunk 9953 ---\n",
            "for the central vertical line (since all inputs will get multiplied by 0, except for the\n",
            "\n",
            "--- Chunk 9954 ---\n",
            "ones located in the central vertical line). The second filter is a black square with a\n",
            "\n",
            "--- Chunk 9955 ---\n",
            "horizontal white line in the middle. Once again, neurons using these weights will\n",
            "\n",
            "--- Chunk 9956 ---\n",
            "ignore everything in their receptive field except for the central horizontal line.\n",
            "\n",
            "--- Chunk 9957 ---\n",
            "Now if all neurons in a layer use the same vertical line filter (and the same bias term),\n",
            "\n",
            "--- Chunk 9958 ---\n",
            "and you feed the network the input image shown in Figure 14-5 (the bottom image),\n",
            "\n",
            "--- Chunk 9959 ---\n",
            "the layer will output the top-left image. Notice that the vertical white lines get\n",
            "\n",
            "--- Chunk 9960 ---\n",
            "enhanced while the rest gets blurred. Similarly, the upper-right image is what you get\n",
            "\n",
            "--- Chunk 9961 ---\n",
            "if all neurons use the same horizontal line filter; notice that the horizontal white lines\n",
            "\n",
            "--- Chunk 9962 ---\n",
            "get enhanced while the rest is blurred out. Thus, a layer full of neurons using the\n",
            "\n",
            "--- Chunk 9963 ---\n",
            "same filter outputs a feature map, which highlights the areas in an image that activate\n",
            "\n",
            "--- Chunk 9964 ---\n",
            "the filter the most. Of course, you do not have to define the filters manually: instead,\n",
            "\n",
            "--- Chunk 9965 ---\n",
            "during training the convolutional layer will automatically learn the most useful filters\n",
            "\n",
            "--- Chunk 9966 ---\n",
            "for its task, and the layers above will learn to combine them into more complex\n",
            "patterns.\n",
            "\n",
            "--- Chunk 9967 ---\n",
            "450 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "\n",
            "\n",
            "Figure 14-5. Applying two different filters to get two feature maps\n",
            "\n",
            "--- Chunk 9968 ---\n",
            "Stacking Multiple Feature Maps\n",
            "Up to now, for simplicity, I have represented the output of each convolutional layer as\n",
            "\n",
            "--- Chunk 9969 ---\n",
            "a 2D layer, but in reality a convolutional layer has multiple filters (you decide how\n",
            "\n",
            "--- Chunk 9970 ---\n",
            "many) and outputs one feature map per filter, so it is more accurately represented in\n",
            "\n",
            "--- Chunk 9971 ---\n",
            "3D (see Figure 14-6). It has one neuron per pixel in each feature map, and all neurons\n",
            "\n",
            "--- Chunk 9972 ---\n",
            "within a given feature map share the same parameters (i.e., the same weights and bias\n",
            "\n",
            "--- Chunk 9973 ---\n",
            "term). Neurons in different feature maps use different parameters. A neuron’s recep‐\n",
            "\n",
            "--- Chunk 9974 ---\n",
            "tive field is the same as described earlier, but it extends across all the previous layers’\n",
            "\n",
            "--- Chunk 9975 ---\n",
            "feature maps. In short, a convolutional layer simultaneously applies multiple trainable\n",
            "\n",
            "--- Chunk 9976 ---\n",
            "filters to its inputs, making it capable of detecting multiple features anywhere in its\n",
            "inputs.\n",
            "\n",
            "--- Chunk 9977 ---\n",
            "The fact that all neurons in a feature map share the same parame‐\n",
            "ters dramatically reduces the number of parameters in the model.\n",
            "\n",
            "--- Chunk 9978 ---\n",
            "Once the CNN has learned to recognize a pattern in one location, it\n",
            "can recognize it in any other location. In contrast, once a regular\n",
            "\n",
            "--- Chunk 9979 ---\n",
            "DNN has learned to recognize a pattern in one location, it can rec‐\n",
            "ognize it only in that particular location.\n",
            "\n",
            "--- Chunk 9980 ---\n",
            "Input images are also composed of multiple sublayers: one per color channel. There\n",
            "\n",
            "--- Chunk 9981 ---\n",
            "are typically three: red, green, and blue (RGB). Grayscale images have just one\n",
            "\n",
            "--- Chunk 9982 ---\n",
            "Convolutional Layers | 451\n",
            "\n",
            "--- Chunk 9983 ---\n",
            "channel, but some images may have much more—for example, satellite images that\n",
            "capture extra light frequencies (such as infrared).\n",
            "\n",
            "--- Chunk 9984 ---\n",
            "Figure 14-6. Convolutional layers with multiple feature maps, and images with three\n",
            "color channels\n",
            "\n",
            "--- Chunk 9985 ---\n",
            "Specifically, a neuron located in row i, column j of the feature map k in a given convo‐\n",
            "\n",
            "--- Chunk 9986 ---\n",
            "lutional layer l is connected to the outputs of the neurons in the previous layer l – 1,\n",
            "\n",
            "--- Chunk 9987 ---\n",
            "located in rows i × sh to i × sh + fh – 1 and columns j × sw to j × sw + fw – 1, across all\n",
            "\n",
            "--- Chunk 9988 ---\n",
            "feature maps (in layer l – 1). Note that all neurons located in the same row i and col‐\n",
            "\n",
            "--- Chunk 9989 ---\n",
            "umn j but in different feature maps are connected to the outputs of the exact same\n",
            "neurons in the previous layer.\n",
            "\n",
            "--- Chunk 9990 ---\n",
            "Equation 14-1 summarizes the preceding explanations in one big mathematical equa‐\n",
            "\n",
            "--- Chunk 9991 ---\n",
            "tion: it shows how to compute the output of a given neuron in a convolutional layer.\n",
            "\n",
            "--- Chunk 9992 ---\n",
            "452 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 9993 ---\n",
            "It is a bit ugly due to all the different indices, but all it does is calculate the weighted\n",
            "sum of all the inputs, plus the bias term.\n",
            "\n",
            "--- Chunk 9994 ---\n",
            "Equation 14-1. Computing the output of a neuron in a convolutional layer\n",
            "f h − 1 f w − 1 f n − 1\n",
            "\n",
            "--- Chunk 9995 ---\n",
            "′ i′ = i × s + u\n",
            "zi, j, k = bk + ∑ ∑ ∑ xi , j , k . w ith h\n",
            "\n",
            "u = 0 v = 0 k ′ ′ u, v, k′, k w\n",
            "′ = 0 ′ j′ = j × sw + v\n",
            "\n",
            "In this equation:\n",
            "\n",
            "--- Chunk 9996 ---\n",
            "In this equation:\n",
            "\n",
            "• zi, j, k is the output of the neuron located in row i, column j in feature map k of the\n",
            "convolutional layer (layer l).\n",
            "\n",
            "--- Chunk 9997 ---\n",
            "• As explained earlier, sh and sw are the vertical and horizontal strides, fh and fw are\n",
            "\n",
            "--- Chunk 9998 ---\n",
            "the height and width of the receptive field, and fn′ is the number of feature maps\n",
            "in the previous layer (layer l – 1).\n",
            "\n",
            "--- Chunk 9999 ---\n",
            "• xi′, j′, k′ is the output of the neuron located in layer l – 1, row i′, column j′, feature\n",
            "\n",
            "--- Chunk 10000 ---\n",
            "map k′ (or channel k′ if the previous layer is the input layer).\n",
            "\n",
            "--- Chunk 10001 ---\n",
            "• bk is the bias term for feature map k (in layer l). You can think of it as a knob that\n",
            "tweaks the overall brightness of the feature map k.\n",
            "\n",
            "--- Chunk 10002 ---\n",
            "• wu, v, k′ ,k is the connection weight between any neuron in feature map k of the layer\n",
            "\n",
            "--- Chunk 10003 ---\n",
            "l and its input located at row u, column v (relative to the neuron’s receptive field),\n",
            "and feature map k′.\n",
            "\n",
            "--- Chunk 10004 ---\n",
            "TensorFlow Implementation\n",
            "In TensorFlow, each input image is typically represented as a 3D tensor of shape\n",
            "\n",
            "--- Chunk 10005 ---\n",
            "[height, width, channels]. A mini-batch is represented as a 4D tensor of shape [mini-\n",
            "\n",
            "--- Chunk 10006 ---\n",
            "batch size, height, width, channels]. The weights of a convolutional layer are repre‐\n",
            "\n",
            "--- Chunk 10007 ---\n",
            "sented as a 4D tensor of shape [fh, fw, fn′, fn]. The bias terms of a convolutional layer\n",
            "are simply represented as a 1D tensor of shape [fn].\n",
            "\n",
            "--- Chunk 10008 ---\n",
            "Let’s look at a simple example. The following code loads two sample images, using\n",
            "\n",
            "--- Chunk 10009 ---\n",
            "Scikit-Learn’s load_sample_image() (which loads two color images, one of a Chinese\n",
            "\n",
            "--- Chunk 10010 ---\n",
            "temple, and the other of a flower), then it creates two filters and applies them to both\n",
            "\n",
            "--- Chunk 10011 ---\n",
            "images, and finally it displays one of the resulting feature maps. Note that you must\n",
            "pip install the Pillow package to use load_sample_image().\n",
            "\n",
            "--- Chunk 10012 ---\n",
            "from sklearn.datasets import load_sample_image\n",
            "\n",
            "--- Chunk 10013 ---\n",
            "# Load sample images\n",
            "china = load_sample_image(\"china.jpg\") / 255\n",
            "flower = load_sample_image(\"flower.jpg\") / 255\n",
            "\n",
            "Convolutional Layers | 453\n",
            "\n",
            "--- Chunk 10014 ---\n",
            "images = np.array([china, flower])\n",
            "batch_size, height, width, channels = images.shape\n",
            "\n",
            "--- Chunk 10015 ---\n",
            "# Create 2 filters\n",
            "filters = np.zeros(shape=(7, 7, channels, 2), dtype=np.float32)\n",
            "filters[:, 3, :, 0] = 1  # vertical line\n",
            "\n",
            "--- Chunk 10016 ---\n",
            "filters[3, :, :, 1] = 1  # horizontal line\n",
            "\n",
            "--- Chunk 10017 ---\n",
            "outputs = tf.nn.conv2d(images, filters, strides=1, padding=\"SAME\")\n",
            "\n",
            "--- Chunk 10018 ---\n",
            "plt.imshow(outputs[0, :, :, 1], cmap=\"gray\") # plot 1st image's 2nd feature map\n",
            "plt.show()\n",
            "\n",
            "Let’s go through this code:\n",
            "\n",
            "--- Chunk 10019 ---\n",
            "• The pixel intensity for each color channel is represented as a byte from 0 to 255,\n",
            "\n",
            "--- Chunk 10020 ---\n",
            "so we scale these features simply by dividing by 255, to get floats ranging from 0\n",
            "to 1.\n",
            "\n",
            "--- Chunk 10021 ---\n",
            "• Then we create two 7 × 7 filters (one with a vertical white line in the middle, and\n",
            "the other with a horizontal white line in the middle).\n",
            "\n",
            "--- Chunk 10022 ---\n",
            "• We apply them to both images using the tf.nn.conv2d() function, which is part\n",
            "\n",
            "--- Chunk 10023 ---\n",
            "of TensorFlow’s low-level Deep Learning API. In this example, we use zero pad‐\n",
            "ding (padding=\"SAME\") and a stride of 1.\n",
            "\n",
            "--- Chunk 10024 ---\n",
            "• Finally, we plot one of the resulting feature maps (similar to the top-right image\n",
            "in Figure 14-5).\n",
            "\n",
            "--- Chunk 10025 ---\n",
            "The tf.nn.conv2d() line deserves a bit more explanation:\n",
            "\n",
            "--- Chunk 10026 ---\n",
            "• images is the input mini-batch (a 4D tensor, as explained earlier).\n",
            "\n",
            "--- Chunk 10027 ---\n",
            "• filters is the set of filters to apply (also a 4D tensor, as explained earlier).\n",
            "\n",
            "--- Chunk 10028 ---\n",
            "• strides is equal to 1, but it could also be a 1D array with four elements, where\n",
            "\n",
            "--- Chunk 10029 ---\n",
            "the two central elements are the vertical and horizontal strides (sh and sw). The\n",
            "\n",
            "--- Chunk 10030 ---\n",
            "first and last elements must currently be equal to 1. They may one day be used to\n",
            "\n",
            "--- Chunk 10031 ---\n",
            "specify a batch stride (to skip some instances) and a channel stride (to skip some\n",
            "of the previous layer’s feature maps or channels).\n",
            "\n",
            "--- Chunk 10032 ---\n",
            "• padding must be either \"SAME\" or \"VALID\":\n",
            "— If set to \"SAME\", the convolutional layer uses zero padding if necessary. The\n",
            "\n",
            "--- Chunk 10033 ---\n",
            "output size is set to the number of input neurons divided by the stride, roun‐\n",
            "\n",
            "--- Chunk 10034 ---\n",
            "ded up. For example, if the input size is 13 and the stride is 5 (see Figure 14-7),\n",
            "\n",
            "--- Chunk 10035 ---\n",
            "then the output size is 3 (i.e., 13 / 5 = 2.6, rounded up to 3). Then zeros are\n",
            "\n",
            "--- Chunk 10036 ---\n",
            "added as evenly as possible around the inputs, as needed. When strides=1,\n",
            "\n",
            "--- Chunk 10037 ---\n",
            "the layer’s outputs will have the same spatial dimensions (width and height) as\n",
            "its inputs, hence the name same.\n",
            "\n",
            "--- Chunk 10038 ---\n",
            "454 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 10039 ---\n",
            "— If set to \"VALID\", the convolutional layer does not use zero padding and may\n",
            "\n",
            "--- Chunk 10040 ---\n",
            "ignore some rows and columns at the bottom and right of the input image,\n",
            "\n",
            "--- Chunk 10041 ---\n",
            "depending on the stride, as shown in Figure 14-7 (for simplicity, only the hor‐\n",
            "\n",
            "--- Chunk 10042 ---\n",
            "izontal dimension is shown here, but of course the same logic applies to the\n",
            "\n",
            "--- Chunk 10043 ---\n",
            "vertical dimension). This means that every neuron’s receptive field lies strictly\n",
            "\n",
            "--- Chunk 10044 ---\n",
            "within valid positions inside the input (it does not go out of bounds), hence\n",
            "the name valid.\n",
            "\n",
            "--- Chunk 10045 ---\n",
            "Figure 14-7. Padding=\"SAME” or “VALID” (with input width 13, filter width 6, stride\n",
            "5)\n",
            "\n",
            "--- Chunk 10046 ---\n",
            "In this example we manually defined the filters, but in a real CNN you would nor‐\n",
            "\n",
            "--- Chunk 10047 ---\n",
            "mally define filters as trainable variables so the neural net can learn which filters\n",
            "\n",
            "--- Chunk 10048 ---\n",
            "work best, as explained earlier. Instead of manually creating the variables, use the\n",
            "keras.layers.Conv2D layer:\n",
            "\n",
            "--- Chunk 10049 ---\n",
            "conv = keras.layers.Conv2D(filters=32, kernel_size=3, strides=1,\n",
            "                           padding=\"same\", activation=\"relu\")\n",
            "\n",
            "--- Chunk 10050 ---\n",
            "This code creates a Conv2D layer with 32 filters, each 3 × 3, using a stride of 1 (both\n",
            "\n",
            "--- Chunk 10051 ---\n",
            "horizontally and vertically) and \"same\" padding, and applying the ReLU activation\n",
            "\n",
            "--- Chunk 10052 ---\n",
            "function to its outputs. As you can see, convolutional layers have quite a few hyper‐\n",
            "\n",
            "--- Chunk 10053 ---\n",
            "parameters: you must choose the number of filters, their height and width, the\n",
            "\n",
            "--- Chunk 10054 ---\n",
            "strides, and the padding type. As always, you can use cross-validation to find the right\n",
            "\n",
            "--- Chunk 10055 ---\n",
            "hyperparameter values, but this is very time-consuming. We will discuss common\n",
            "\n",
            "--- Chunk 10056 ---\n",
            "CNN architectures later, to give you some idea of which hyperparameter values work\n",
            "best in practice.\n",
            "\n",
            "--- Chunk 10057 ---\n",
            "Convolutional Layers | 455\n",
            "\n",
            "--- Chunk 10058 ---\n",
            "Memory Requirements\n",
            "Another problem with CNNs is that the convolutional layers require a huge amount\n",
            "\n",
            "--- Chunk 10059 ---\n",
            "of RAM. This is especially true during training, because the reverse pass of backpro‐\n",
            "\n",
            "--- Chunk 10060 ---\n",
            "pagation requires all the intermediate values computed during the forward pass.\n",
            "\n",
            "--- Chunk 10061 ---\n",
            "For example, consider a convolutional layer with 5 × 5 filters, outputting 200 feature\n",
            "\n",
            "--- Chunk 10062 ---\n",
            "maps of size 150 × 100, with stride 1 and \"same\" padding. If the input is a 150 × 100\n",
            "\n",
            "--- Chunk 10063 ---\n",
            "RGB image (three channels), then the number of parameters is (5 × 5 × 3 + 1) × 200\n",
            "\n",
            "--- Chunk 10064 ---\n",
            "= 15,200 (the + 1 corresponds to the bias terms), which is fairly small compared to a\n",
            "\n",
            "--- Chunk 10065 ---\n",
            "fully connected layer.7 However, each of the 200 feature maps contains 150 × 100 neu‐\n",
            "\n",
            "--- Chunk 10066 ---\n",
            "rons, and each of these neurons needs to compute a weighted sum of its 5 × 5 × 3 =\n",
            "\n",
            "--- Chunk 10067 ---\n",
            "75 inputs: that’s a total of 225 million float multiplications. Not as bad as a fully con‐\n",
            "\n",
            "--- Chunk 10068 ---\n",
            "nected layer, but still quite computationally intensive. Moreover, if the feature maps\n",
            "\n",
            "--- Chunk 10069 ---\n",
            "are represented using 32-bit floats, then the convolutional layer’s output will occupy\n",
            "\n",
            "--- Chunk 10070 ---\n",
            "200 × 150 × 100 × 32 = 96 million bits (12 MB) of RAM.8 And that’s just for one\n",
            "\n",
            "--- Chunk 10071 ---\n",
            "instance—if a training batch contains 100 instances, then this layer will use up 1.2 GB\n",
            "of RAM!\n",
            "\n",
            "--- Chunk 10072 ---\n",
            "of RAM!\n",
            "During inference (i.e., when making a prediction for a new instance) the RAM occu‐\n",
            "\n",
            "--- Chunk 10073 ---\n",
            "pied by one layer can be released as soon as the next layer has been computed, so you\n",
            "\n",
            "--- Chunk 10074 ---\n",
            "only need as much RAM as required by two consecutive layers. But during training\n",
            "\n",
            "--- Chunk 10075 ---\n",
            "everything computed during the forward pass needs to be preserved for the reverse\n",
            "\n",
            "--- Chunk 10076 ---\n",
            "pass, so the amount of RAM needed is (at least) the total amount of RAM required by\n",
            "all layers.\n",
            "\n",
            "--- Chunk 10077 ---\n",
            "If training crashes because of an out-of-memory error, you can try\n",
            "reducing the mini-batch size. Alternatively, you can try reducing\n",
            "\n",
            "--- Chunk 10078 ---\n",
            "dimensionality using a stride, or removing a few layers. Or you can\n",
            "try using 16-bit floats instead of 32-bit floats. Or you could distrib‐\n",
            "\n",
            "--- Chunk 10079 ---\n",
            "ute the CNN across multiple devices.\n",
            "\n",
            "--- Chunk 10080 ---\n",
            "Now let’s look at the second common building block of CNNs: the pooling layer.\n",
            "\n",
            "--- Chunk 10081 ---\n",
            "Pooling Layers\n",
            "Once you understand how convolutional layers work, the pooling layers are quite\n",
            "\n",
            "--- Chunk 10082 ---\n",
            "easy to grasp. Their goal is to subsample (i.e., shrink) the input image in order to\n",
            "\n",
            "--- Chunk 10083 ---\n",
            "7 A fully connected layer with 150 × 100 neurons, each connected to all 150 × 100 × 3 inputs, would have 1502\n",
            "× 1002 × 3 = 675 million parameters!\n",
            "\n",
            "--- Chunk 10084 ---\n",
            "8 In the international system of units (SI), 1 MB = 1,000 KB = 1,000 × 1,000 bytes = 1,000 × 1,000 × 8 bits.\n",
            "\n",
            "--- Chunk 10085 ---\n",
            "456 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 10086 ---\n",
            "reduce the computational load, the memory usage, and the number of parameters\n",
            "(thereby limiting the risk of overfitting).\n",
            "\n",
            "--- Chunk 10087 ---\n",
            "Just like in convolutional layers, each neuron in a pooling layer is connected to the\n",
            "\n",
            "--- Chunk 10088 ---\n",
            "outputs of a limited number of neurons in the previous layer, located within a small\n",
            "\n",
            "--- Chunk 10089 ---\n",
            "rectangular receptive field. You must define its size, the stride, and the padding type,\n",
            "\n",
            "--- Chunk 10090 ---\n",
            "just like before. However, a pooling neuron has no weights; all it does is aggregate the\n",
            "\n",
            "--- Chunk 10091 ---\n",
            "inputs using an aggregation function such as the max or mean. Figure 14-8 shows a\n",
            "\n",
            "--- Chunk 10092 ---\n",
            "max pooling layer, which is the most common type of pooling layer. In this example,\n",
            "\n",
            "--- Chunk 10093 ---\n",
            "we use a 2 × 2 pooling kernel,9 with a stride of 2 and no padding. Only the max input\n",
            "\n",
            "--- Chunk 10094 ---\n",
            "value in each receptive field makes it to the next layer, while the other inputs are\n",
            "\n",
            "--- Chunk 10095 ---\n",
            "dropped. For example, in the lower-left receptive field in Figure 14-8, the input values\n",
            "\n",
            "--- Chunk 10096 ---\n",
            "are 1, 5, 3, 2, so only the max value, 5, is propagated to the next layer. Because of the\n",
            "\n",
            "--- Chunk 10097 ---\n",
            "stride of 2, the output image has half the height and half the width of the input image\n",
            "(rounded down since we use no padding).\n",
            "\n",
            "--- Chunk 10098 ---\n",
            "Figure 14-8. Max pooling layer (2 × 2 pooling kernel, stride 2, no padding)\n",
            "\n",
            "--- Chunk 10099 ---\n",
            "A pooling layer typically works on every input channel independ‐\n",
            "ently, so the output depth is the same as the input depth.\n",
            "\n",
            "--- Chunk 10100 ---\n",
            "Other than reducing computations, memory usage, and the number of parameters, a\n",
            "\n",
            "--- Chunk 10101 ---\n",
            "max pooling layer also introduces some level of invariance to small translations, as\n",
            "\n",
            "--- Chunk 10102 ---\n",
            "shown in Figure 14-9. Here we assume that the bright pixels have a lower value than\n",
            "\n",
            "--- Chunk 10103 ---\n",
            "dark pixels, and we consider three images (A, B, C) going through a max pooling\n",
            "\n",
            "--- Chunk 10104 ---\n",
            "layer with a 2 × 2 kernel and stride 2. Images B and C are the same as image A, but\n",
            "\n",
            "--- Chunk 10105 ---\n",
            "9 Other kernels we’ve discussed so far had weights, but pooling kernels do not: they are just stateless sliding\n",
            "windows.\n",
            "\n",
            "Pooling Layers | 457\n",
            "\n",
            "--- Chunk 10106 ---\n",
            "shifted by one and two pixels to the right. As you can see, the outputs of the max\n",
            "\n",
            "--- Chunk 10107 ---\n",
            "pooling layer for images A and B are identical. This is what translation invariance\n",
            "\n",
            "--- Chunk 10108 ---\n",
            "means. For image C, the output is different: it is shifted one pixel to the right (but\n",
            "\n",
            "--- Chunk 10109 ---\n",
            "there is still 75% invariance). By inserting a max pooling layer every few layers in a\n",
            "\n",
            "--- Chunk 10110 ---\n",
            "CNN, it is possible to get some level of translation invariance at a larger scale. More‐\n",
            "\n",
            "--- Chunk 10111 ---\n",
            "over, max pooling offers a small amount of rotational invariance and a slight scale\n",
            "\n",
            "--- Chunk 10112 ---\n",
            "invariance. Such invariance (even if it is limited) can be useful in cases where the pre‐\n",
            "\n",
            "--- Chunk 10113 ---\n",
            "diction should not depend on these details, such as in classification tasks.\n",
            "\n",
            "--- Chunk 10114 ---\n",
            "Figure 14-9. Invariance to small translations\n",
            "\n",
            "--- Chunk 10115 ---\n",
            "However, max pooling has some downsides too. Firstly, it is obviously very destruc‐\n",
            "\n",
            "--- Chunk 10116 ---\n",
            "tive: even with a tiny 2 × 2 kernel and a stride of 2, the output will be two times\n",
            "\n",
            "--- Chunk 10117 ---\n",
            "smaller in both directions (so its area will be four times smaller), simply dropping\n",
            "\n",
            "--- Chunk 10118 ---\n",
            "75% of the input values. And in some applications, invariance is not desirable. Take\n",
            "\n",
            "--- Chunk 10119 ---\n",
            "semantic segmentation (the task of classifying each pixel in an image according to the\n",
            "\n",
            "--- Chunk 10120 ---\n",
            "object that pixel belongs to, which we’ll explore later in this chapter): obviously, if the\n",
            "\n",
            "--- Chunk 10121 ---\n",
            "input image is translated by one pixel to the right, the output should also be trans‐\n",
            "\n",
            "--- Chunk 10122 ---\n",
            "lated by one pixel to the right. The goal in this case is equivariance, not invariance: a\n",
            "\n",
            "--- Chunk 10123 ---\n",
            "small change to the inputs should lead to a corresponding small change in the output.\n",
            "\n",
            "--- Chunk 10124 ---\n",
            "TensorFlow Implementation\n",
            "Implementing a max pooling layer in TensorFlow is quite easy. The following code\n",
            "\n",
            "--- Chunk 10125 ---\n",
            "creates a max pooling layer using a 2 × 2 kernel. The strides default to the kernel size,\n",
            "\n",
            "--- Chunk 10126 ---\n",
            "so this layer will use a stride of 2 (both horizontally and vertically). By default, it uses\n",
            "\"valid\" padding (i.e., no padding at all):\n",
            "\n",
            "--- Chunk 10127 ---\n",
            "458 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "\n",
            "\n",
            "max_pool = keras.layers.MaxPool2D(pool_size=2)\n",
            "\n",
            "--- Chunk 10128 ---\n",
            "To create an average pooling layer, just use AvgPool2D instead of MaxPool2D. As you\n",
            "\n",
            "--- Chunk 10129 ---\n",
            "might expect, it works exactly like a max pooling layer, except it computes the mean\n",
            "\n",
            "--- Chunk 10130 ---\n",
            "rather than the max. Average pooling layers used to be very popular, but people\n",
            "\n",
            "--- Chunk 10131 ---\n",
            "mostly use max pooling layers now, as they generally perform better. This may seem\n",
            "\n",
            "--- Chunk 10132 ---\n",
            "surprising, since computing the mean generally loses less information than comput‐\n",
            "\n",
            "--- Chunk 10133 ---\n",
            "ing the max. But on the other hand, max pooling preserves only the strongest fea‐\n",
            "\n",
            "--- Chunk 10134 ---\n",
            "tures, getting rid of all the meaningless ones, so the next layers get a cleaner signal to\n",
            "\n",
            "--- Chunk 10135 ---\n",
            "work with. Moreover, max pooling offers stronger translation invariance than average\n",
            "pooling, and it requires slightly less compute.\n",
            "\n",
            "--- Chunk 10136 ---\n",
            "Note that max pooling and average pooling can be performed along the depth dimen‐\n",
            "\n",
            "--- Chunk 10137 ---\n",
            "sion rather than the spatial dimensions, although this is not as common. This can\n",
            "\n",
            "--- Chunk 10138 ---\n",
            "allow the CNN to learn to be invariant to various features. For example, it could learn\n",
            "\n",
            "--- Chunk 10139 ---\n",
            "multiple filters, each detecting a different rotation of the same pattern (such as hand-\n",
            "\n",
            "--- Chunk 10140 ---\n",
            "written digits; see Figure 14-10), and the depthwise max pooling layer would ensure\n",
            "\n",
            "--- Chunk 10141 ---\n",
            "that the output is the same regardless of the rotation. The CNN could similarly learn\n",
            "\n",
            "--- Chunk 10142 ---\n",
            "to be invariant to anything else: thickness, brightness, skew, color, and so on.\n",
            "\n",
            "--- Chunk 10143 ---\n",
            "Figure 14-10. Depthwise max pooling can help the CNN learn any invariance\n",
            "\n",
            "Pooling Layers | 459\n",
            "\n",
            "--- Chunk 10144 ---\n",
            "Keras does not include a depthwise max pooling layer, but TensorFlow’s low-level\n",
            "\n",
            "--- Chunk 10145 ---\n",
            "Deep Learning API does: just use the tf.nn.max_pool() function, and specify the\n",
            "\n",
            "--- Chunk 10146 ---\n",
            "kernel size and strides as 4-tuples (i.e., tuples of size 4). The first three values of each\n",
            "\n",
            "--- Chunk 10147 ---\n",
            "should be 1: this indicates that the kernel size and stride along the batch, height, and\n",
            "\n",
            "--- Chunk 10148 ---\n",
            "width dimensions should be 1. The last value should be whatever kernel size and\n",
            "\n",
            "--- Chunk 10149 ---\n",
            "stride you want along the depth dimension—for example, 3 (this must be a divisor of\n",
            "\n",
            "--- Chunk 10150 ---\n",
            "the input depth; it will not work if the previous layer outputs 20 feature maps, since\n",
            "20 is not a multiple of 3):\n",
            "\n",
            "--- Chunk 10151 ---\n",
            "output = tf.nn.max_pool(images,\n",
            "                        ksize=(1, 1, 1, 3),\n",
            "                        strides=(1, 1, 1, 3),\n",
            "\n",
            "--- Chunk 10152 ---\n",
            "padding=\"valid\")\n",
            "\n",
            "--- Chunk 10153 ---\n",
            "If you want to include this as a layer in your Keras models, wrap it in a Lambda layer\n",
            "(or create a custom Keras layer):\n",
            "\n",
            "--- Chunk 10154 ---\n",
            "depth_pool = keras.layers.Lambda(\n",
            "    lambda X: tf.nn.max_pool(X, ksize=(1, 1, 1, 3), strides=(1, 1, 1, 3),\n",
            "\n",
            "--- Chunk 10155 ---\n",
            "padding=\"valid\"))\n",
            "\n",
            "--- Chunk 10156 ---\n",
            "One last type of pooling layer that you will often see in modern architectures is the\n",
            "\n",
            "--- Chunk 10157 ---\n",
            "global average pooling layer. It works very differently: all it does is compute the mean\n",
            "\n",
            "--- Chunk 10158 ---\n",
            "of each entire feature map (it’s like an average pooling layer using a pooling kernel\n",
            "\n",
            "--- Chunk 10159 ---\n",
            "with the same spatial dimensions as the inputs). This means that it just outputs a sin‐\n",
            "\n",
            "--- Chunk 10160 ---\n",
            "gle number per feature map and per instance. Although this is of course extremely\n",
            "\n",
            "--- Chunk 10161 ---\n",
            "destructive (most of the information in the feature map is lost), it can be useful as the\n",
            "\n",
            "--- Chunk 10162 ---\n",
            "output layer, as we will see later in this chapter. To create such a layer, simply use the\n",
            "keras.layers.GlobalAvgPool2D class:\n",
            "\n",
            "--- Chunk 10163 ---\n",
            "global_avg_pool = keras.layers.GlobalAvgPool2D()\n",
            "\n",
            "--- Chunk 10164 ---\n",
            "It’s equivalent to this simple Lambda layer, which computes the mean over the spatial\n",
            "dimensions (height and width):\n",
            "\n",
            "--- Chunk 10165 ---\n",
            "global_avg_pool = keras.layers.Lambda(lambda X: tf.reduce_mean(X, axis=[1, 2]))\n",
            "\n",
            "--- Chunk 10166 ---\n",
            "Now you know all the building blocks to create convolutional neural networks. Let’s\n",
            "see how to assemble them.\n",
            "\n",
            "--- Chunk 10167 ---\n",
            "CNN Architectures\n",
            "Typical CNN architectures stack a few convolutional layers (each one generally fol‐\n",
            "\n",
            "--- Chunk 10168 ---\n",
            "lowed by a ReLU layer), then a pooling layer, then another few convolutional layers\n",
            "\n",
            "--- Chunk 10169 ---\n",
            "(+ReLU), then another pooling layer, and so on. The image gets smaller and smaller\n",
            "\n",
            "--- Chunk 10170 ---\n",
            "as it progresses through the network, but it also typically gets deeper and deeper (i.e.,\n",
            "\n",
            "--- Chunk 10171 ---\n",
            "with more feature maps), thanks to the convolutional layers (see Figure 14-11). At the\n",
            "\n",
            "--- Chunk 10172 ---\n",
            "top of the stack, a regular feedforward neural network is added, composed of a few\n",
            "\n",
            "--- Chunk 10173 ---\n",
            "460 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 10174 ---\n",
            "fully connected layers (+ReLUs), and the final layer outputs the prediction (e.g., a\n",
            "softmax layer that outputs estimated class probabilities).\n",
            "\n",
            "--- Chunk 10175 ---\n",
            "Figure 14-11. Typical CNN architecture\n",
            "\n",
            "--- Chunk 10176 ---\n",
            "A common mistake is to use convolution kernels that are too large.\n",
            "For example, instead of using a convolutional layer with a 5 × 5\n",
            "\n",
            "--- Chunk 10177 ---\n",
            "kernel, stack two layers with 3 × 3 kernels: it will use fewer parame‐\n",
            "ters and require fewer computations, and it will usually perform\n",
            "\n",
            "--- Chunk 10178 ---\n",
            "better. One exception is for the first convolutional layer: it can typi‐\n",
            "cally have a large kernel (e.g., 5 × 5), usually with a stride of 2 or\n",
            "\n",
            "--- Chunk 10179 ---\n",
            "more: this will reduce the spatial dimension of the image without\n",
            "losing too much information, and since the input image only has\n",
            "\n",
            "--- Chunk 10180 ---\n",
            "three channels in general, it will not be too costly.\n",
            "\n",
            "--- Chunk 10181 ---\n",
            "Here is how you can implement a simple CNN to tackle the Fashion MNIST dataset\n",
            "(introduced in Chapter 10):\n",
            "\n",
            "--- Chunk 10182 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n",
            "\n",
            "--- Chunk 10183 ---\n",
            "input_shape=[28, 28, 1]),\n",
            "    keras.layers.MaxPooling2D(2),\n",
            "\n",
            "--- Chunk 10184 ---\n",
            "keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
            "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
            "\n",
            "--- Chunk 10185 ---\n",
            "keras.layers.MaxPooling2D(2),\n",
            "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
            "\n",
            "--- Chunk 10186 ---\n",
            "keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
            "    keras.layers.MaxPooling2D(2),\n",
            "    keras.layers.Flatten(),\n",
            "\n",
            "--- Chunk 10187 ---\n",
            "keras.layers.Dense(128, activation=\"relu\"),\n",
            "    keras.layers.Dropout(0.5),\n",
            "    keras.layers.Dense(64, activation=\"relu\"),\n",
            "\n",
            "--- Chunk 10188 ---\n",
            "keras.layers.Dropout(0.5),\n",
            "    keras.layers.Dense(10, activation=\"softmax\")\n",
            "])\n",
            "\n",
            "--- Chunk 10189 ---\n",
            "CNN Architectures | 461\n",
            "\n",
            "\n",
            "\n",
            "Let’s go through this model:\n",
            "\n",
            "--- Chunk 10190 ---\n",
            "• The first layer uses 64 fairly large filters (7 × 7) but no stride because the input\n",
            "\n",
            "--- Chunk 10191 ---\n",
            "images are not very large. It also sets input_shape=[28, 28, 1], because the\n",
            "\n",
            "--- Chunk 10192 ---\n",
            "images are 28 × 28 pixels, with a single color channel (i.e., grayscale).\n",
            "\n",
            "--- Chunk 10193 ---\n",
            "• Next we have a max pooling layer which uses a pool size of 2, so it divides each\n",
            "spatial dimension by a factor of 2.\n",
            "\n",
            "--- Chunk 10194 ---\n",
            "• Then we repeat the same structure twice: two convolutional layers followed by a\n",
            "\n",
            "--- Chunk 10195 ---\n",
            "max pooling layer. For larger images, we could repeat this structure several more\n",
            "times (the number of repetitions is a hyperparameter you can tune).\n",
            "\n",
            "--- Chunk 10196 ---\n",
            "• Note that the number of filters grows as we climb up the CNN toward the output\n",
            "\n",
            "--- Chunk 10197 ---\n",
            "layer (it is initially 64, then 128, then 256): it makes sense for it to grow, since the\n",
            "\n",
            "--- Chunk 10198 ---\n",
            "number of low-level features is often fairly low (e.g., small circles, horizontal\n",
            "\n",
            "--- Chunk 10199 ---\n",
            "lines), but there are many different ways to combine them into higher-level fea‐\n",
            "\n",
            "--- Chunk 10200 ---\n",
            "tures. It is a common practice to double the number of filters after each pooling\n",
            "\n",
            "--- Chunk 10201 ---\n",
            "layer: since a pooling layer divides each spatial dimension by a factor of 2, we can\n",
            "\n",
            "--- Chunk 10202 ---\n",
            "afford to double the number of feature maps in the next layer without fear of\n",
            "\n",
            "--- Chunk 10203 ---\n",
            "exploding the number of parameters, memory usage, or computational load.\n",
            "\n",
            "--- Chunk 10204 ---\n",
            "• Next is the fully connected network, composed of two hidden dense layers and a\n",
            "\n",
            "--- Chunk 10205 ---\n",
            "dense output layer. Note that we must flatten its inputs, since a dense network\n",
            "\n",
            "--- Chunk 10206 ---\n",
            "expects a 1D array of features for each instance. We also add two dropout layers,\n",
            "with a dropout rate of 50% each, to reduce overfitting.\n",
            "\n",
            "--- Chunk 10207 ---\n",
            "This CNN reaches over 92% accuracy on the test set. It’s not state of the art, but it is\n",
            "\n",
            "--- Chunk 10208 ---\n",
            "pretty good, and clearly much better than what we achieved with dense networks in\n",
            "Chapter 10.\n",
            "\n",
            "--- Chunk 10209 ---\n",
            "Chapter 10.\n",
            "Over the years, variants of this fundamental architecture have been developed, lead‐\n",
            "\n",
            "--- Chunk 10210 ---\n",
            "ing to amazing advances in the field. A good measure of this progress is the error rate\n",
            "\n",
            "--- Chunk 10211 ---\n",
            "in competitions such as the ILSVRC ImageNet challenge. In this competition the top-\n",
            "\n",
            "--- Chunk 10212 ---\n",
            "five error rate for image classification fell from over 26% to less than 2.3% in just six\n",
            "\n",
            "--- Chunk 10213 ---\n",
            "years. The top-five error rate is the number of test images for which the system’s top\n",
            "\n",
            "--- Chunk 10214 ---\n",
            "five predictions did not include the correct answer. The images are large (256 pixels\n",
            "\n",
            "--- Chunk 10215 ---\n",
            "high) and there are 1,000 classes, some of which are really subtle (try distinguishing\n",
            "\n",
            "--- Chunk 10216 ---\n",
            "120 dog breeds). Looking at the evolution of the winning entries is a good way to\n",
            "understand how CNNs work.\n",
            "\n",
            "--- Chunk 10217 ---\n",
            "We will first look at the classical LeNet-5 architecture (1998), then three of the win‐\n",
            "\n",
            "--- Chunk 10218 ---\n",
            "ners of the ILSVRC challenge: AlexNet (2012), GoogLeNet (2014), and ResNet\n",
            "(2015).\n",
            "\n",
            "--- Chunk 10219 ---\n",
            "462 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 10220 ---\n",
            "LeNet-5\n",
            "The LeNet-5 architecture10 is perhaps the most widely known CNN architecture. As\n",
            "\n",
            "--- Chunk 10221 ---\n",
            "mentioned earlier, it was created by Yann LeCun in 1998 and has been widely used\n",
            "\n",
            "--- Chunk 10222 ---\n",
            "for handwritten digit recognition (MNIST). It is composed of the layers shown in\n",
            "Table 14-1.\n",
            "\n",
            "--- Chunk 10223 ---\n",
            "Table 14-1. LeNet-5 architecture\n",
            "Layer Type Maps Size Kernel size Stride Activation\n",
            "Out Fully connected – 10 – – RBF\n",
            "\n",
            "--- Chunk 10224 ---\n",
            "F6 Fully connected – 84 – – tanh\n",
            "C5 Convolution 120 1 × 1 5 × 5 1 tanh\n",
            "S4 Avg pooling 16 5 × 5 2 × 2 2 tanh\n",
            "C3 Convolution 16 10 × 10 5 × 5 1 tanh\n",
            "\n",
            "--- Chunk 10225 ---\n",
            "S2 Avg pooling 6 14 × 14 2 × 2 2 tanh\n",
            "C1 Convolution 6 28 × 28 5 × 5 1 tanh\n",
            "In Input 1 32 × 32 – – –\n",
            "\n",
            "--- Chunk 10226 ---\n",
            "There are a few extra details to be noted:\n",
            "\n",
            "--- Chunk 10227 ---\n",
            "• MNIST images are 28 × 28 pixels, but they are zero-padded to 32 × 32 pixels and\n",
            "\n",
            "--- Chunk 10228 ---\n",
            "normalized before being fed to the network. The rest of the network does not use\n",
            "\n",
            "--- Chunk 10229 ---\n",
            "any padding, which is why the size keeps shrinking as the image progresses\n",
            "through the network.\n",
            "\n",
            "--- Chunk 10230 ---\n",
            "• The average pooling layers are slightly more complex than usual: each neuron\n",
            "\n",
            "--- Chunk 10231 ---\n",
            "computes the mean of its inputs, then multiplies the result by a learnable coeffi‐\n",
            "\n",
            "--- Chunk 10232 ---\n",
            "cient (one per map) and adds a learnable bias term (again, one per map), then\n",
            "finally applies the activation function.\n",
            "\n",
            "--- Chunk 10233 ---\n",
            "• Most neurons in C3 maps are connected to neurons in only three or four S2\n",
            "\n",
            "--- Chunk 10234 ---\n",
            "maps (instead of all six S2 maps). See table 1 (page 8) in the original paper10 for\n",
            "details.\n",
            "\n",
            "--- Chunk 10235 ---\n",
            "• The output layer is a bit special: instead of computing the matrix multiplication\n",
            "\n",
            "--- Chunk 10236 ---\n",
            "of the inputs and the weight vector, each neuron outputs the square of the Eucli‐\n",
            "\n",
            "--- Chunk 10237 ---\n",
            "dian distance between its input vector and its weight vector. Each output meas‐\n",
            "\n",
            "--- Chunk 10238 ---\n",
            "ures how much the image belongs to a particular digit class. The cross-entropy\n",
            "\n",
            "--- Chunk 10239 ---\n",
            "10 Yann LeCun et al., “Gradient-Based Learning Applied to Document Recognition,” Proceedings of the IEEE 86,\n",
            "no. 11 (1998): 2278–2324.\n",
            "\n",
            "--- Chunk 10240 ---\n",
            "CNN Architectures | 463\n",
            "\n",
            "--- Chunk 10241 ---\n",
            "cost function is now preferred, as it penalizes bad predictions much more, pro‐\n",
            "ducing larger gradients and converging faster.\n",
            "\n",
            "--- Chunk 10242 ---\n",
            "Yann LeCun’s website features great demos of LeNet-5 classifying digits.\n",
            "\n",
            "--- Chunk 10243 ---\n",
            "AlexNet\n",
            "The AlexNet CNN architecture11 won the 2012 ImageNet ILSVRC challenge by a\n",
            "\n",
            "--- Chunk 10244 ---\n",
            "large margin: it achieved a top-five error rate of 17%, while the second best achieved\n",
            "\n",
            "--- Chunk 10245 ---\n",
            "only 26%! It was developed by Alex Krizhevsky (hence the name), Ilya Sutskever, and\n",
            "\n",
            "--- Chunk 10246 ---\n",
            "Geoffrey Hinton. It is similar to LeNet-5, only much larger and deeper, and it was the\n",
            "\n",
            "--- Chunk 10247 ---\n",
            "first to stack convolutional layers directly on top of one another, instead of stacking a\n",
            "\n",
            "--- Chunk 10248 ---\n",
            "pooling layer on top of each convolutional layer. Table 14-2 presents this architecture.\n",
            "\n",
            "--- Chunk 10249 ---\n",
            "Table 14-2. AlexNet architecture\n",
            "Layer Type Maps Size Kernel size Stride Padding Activation\n",
            "Out Fully connected – 1,000 – – – Softmax\n",
            "\n",
            "--- Chunk 10250 ---\n",
            "F10 Fully connected – 4,096 – – – ReLU\n",
            "F9 Fully connected – 4,096 – – – ReLU\n",
            "S8 Max pooling 256 6 × 6 3 × 3 2 valid –\n",
            "\n",
            "--- Chunk 10251 ---\n",
            "C7 Convolution 256 13 × 13 3 × 3 1 same ReLU\n",
            "C6 Convolution 384 13 × 13 3 × 3 1 same ReLU\n",
            "C5 Convolution 384 13 × 13 3 × 3 1 same ReLU\n",
            "\n",
            "--- Chunk 10252 ---\n",
            "S4 Max pooling 256 13 × 13 3 × 3 2 valid –\n",
            "C3 Convolution 256 27 × 27 5 × 5 1 same ReLU\n",
            "S2 Max pooling 96 27 × 27 3 × 3 2 valid –\n",
            "\n",
            "--- Chunk 10253 ---\n",
            "C1 Convolution 96 55 × 55 11 × 11 4 valid ReLU\n",
            "In Input 3 (RGB) 227 × 227 – – – –\n",
            "\n",
            "--- Chunk 10254 ---\n",
            "To reduce overfitting, the authors used two regularization techniques. First, they\n",
            "\n",
            "--- Chunk 10255 ---\n",
            "applied dropout (introduced in Chapter 11) with a 50% dropout rate during training\n",
            "\n",
            "--- Chunk 10256 ---\n",
            "to the outputs of layers F9 and F10. Second, they performed data augmentation by\n",
            "\n",
            "--- Chunk 10257 ---\n",
            "randomly shifting the training images by various offsets, flipping them horizontally,\n",
            "and changing the lighting conditions.\n",
            "\n",
            "--- Chunk 10258 ---\n",
            "11 Alex Krizhevsky et al., “ImageNet Classification with Deep Convolutional Neural Networks,” _Proceedings of\n",
            "\n",
            "--- Chunk 10259 ---\n",
            "the 25th International Conference on Neural Information Processing Systems 1 (2012): 1097–1105.\n",
            "\n",
            "--- Chunk 10260 ---\n",
            "464 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 10261 ---\n",
            "Data Augmentation\n",
            "Data augmentation artificially increases the size of the training set by generating\n",
            "\n",
            "--- Chunk 10262 ---\n",
            "many realistic variants of each training instance. This reduces overfitting, making this\n",
            "\n",
            "--- Chunk 10263 ---\n",
            "a regularization technique. The generated instances should be as realistic as possible:\n",
            "\n",
            "--- Chunk 10264 ---\n",
            "ideally, given an image from the augmented training set, a human should not be able\n",
            "\n",
            "--- Chunk 10265 ---\n",
            "to tell whether it was augmented or not. Simply adding white noise will not help; the\n",
            "modifications should be learnable (white noise is not).\n",
            "\n",
            "--- Chunk 10266 ---\n",
            "For example, you can slightly shift, rotate, and resize every picture in the training set\n",
            "\n",
            "--- Chunk 10267 ---\n",
            "by various amounts and add the resulting pictures to the training set (see\n",
            "\n",
            "--- Chunk 10268 ---\n",
            "Figure 14-12). This forces the model to be more tolerant to variations in the position,\n",
            "\n",
            "--- Chunk 10269 ---\n",
            "orientation, and size of the objects in the pictures. For a model that’s more tolerant of\n",
            "\n",
            "--- Chunk 10270 ---\n",
            "different lighting conditions, you can similarly generate many images with various\n",
            "\n",
            "--- Chunk 10271 ---\n",
            "contrasts. In general, you can also flip the pictures horizontally (except for text, and\n",
            "\n",
            "--- Chunk 10272 ---\n",
            "other asymmetrical objects). By combining these transformations, you can greatly\n",
            "increase the size of your training set.\n",
            "\n",
            "--- Chunk 10273 ---\n",
            "Figure 14-12. Generating new training instances from existing ones\n",
            "\n",
            "--- Chunk 10274 ---\n",
            "AlexNet also uses a competitive normalization step immediately after the ReLU step\n",
            "\n",
            "--- Chunk 10275 ---\n",
            "of layers C1 and C3, called local response normalization (LRN): the most strongly acti‐\n",
            "\n",
            "--- Chunk 10276 ---\n",
            "vated neurons inhibit other neurons located at the same position in neighboring fea‐\n",
            "\n",
            "--- Chunk 10277 ---\n",
            "ture maps (such competitive activation has been observed in biological neurons).\n",
            "\n",
            "--- Chunk 10278 ---\n",
            "This encourages different feature maps to specialize, pushing them apart and forcing\n",
            "\n",
            "--- Chunk 10279 ---\n",
            "CNN Architectures | 465\n",
            "\n",
            "\n",
            "\n",
            "them to explore a wider range of features, ultimately improving generalization. Equa‐\n",
            "tion 14-2 shows how to apply LRN.\n",
            "\n",
            "--- Chunk 10280 ---\n",
            "Equation 14-2. Local response normalization (LRN)\n",
            "\n",
            "j −β\n",
            "high j i h m n + 2 f −\n",
            "\n",
            "bi = ai k + α ∑ a 2 h g = i i r , n 1\n",
            "j with\n",
            "\n",
            "--- Chunk 10281 ---\n",
            "j = jlow jlow = max 0, i − r\n",
            "2\n",
            "\n",
            "In this equation:\n",
            "\n",
            "--- Chunk 10282 ---\n",
            "• bi is the normalized output of the neuron located in feature map i, at some row u\n",
            "\n",
            "--- Chunk 10283 ---\n",
            "and column v (note that in this equation we consider only neurons located at this\n",
            "row and column, so u and v are not shown).\n",
            "\n",
            "--- Chunk 10284 ---\n",
            "• ai is the activation of that neuron after the ReLU step, but before normalization.\n",
            "\n",
            "--- Chunk 10285 ---\n",
            "• k, α, β, and r are hyperparameters. k is called the bias, and r is called the depth\n",
            "\n",
            "--- Chunk 10286 ---\n",
            "radius.\n",
            "• fn is the number of feature maps.\n",
            "\n",
            "--- Chunk 10287 ---\n",
            "For example, if r = 2 and a neuron has a strong activation, it will inhibit the activation\n",
            "\n",
            "--- Chunk 10288 ---\n",
            "of the neurons located in the feature maps immediately above and below its own.\n",
            "\n",
            "--- Chunk 10289 ---\n",
            "In AlexNet, the hyperparameters are set as follows: r = 2, α = 0.00002, β = 0.75, and\n",
            "\n",
            "--- Chunk 10290 ---\n",
            "k = 1. This step can be implemented using the tf.nn.local_response_normaliza\n",
            "\n",
            "--- Chunk 10291 ---\n",
            "tion() function (which you can wrap in a Lambda layer if you want to use it in a\n",
            "Keras model).\n",
            "\n",
            "--- Chunk 10292 ---\n",
            "Keras model).\n",
            "A variant of AlexNet called ZF Net12 was developed by Matthew Zeiler and Rob Fer‐\n",
            "\n",
            "--- Chunk 10293 ---\n",
            "gus and won the 2013 ILSVRC challenge. It is essentially AlexNet with a few tweaked\n",
            "\n",
            "--- Chunk 10294 ---\n",
            "hyperparameters (number of feature maps, kernel size, stride, etc.).\n",
            "\n",
            "--- Chunk 10295 ---\n",
            "GoogLeNet\n",
            "The GoogLeNet architecture was developed by Christian Szegedy et al. from Google\n",
            "\n",
            "--- Chunk 10296 ---\n",
            "Research,13 and it won the ILSVRC 2014 challenge by pushing the top-five error rate\n",
            "\n",
            "--- Chunk 10297 ---\n",
            "below 7%. This great performance came in large part from the fact that the network\n",
            "\n",
            "--- Chunk 10298 ---\n",
            "was much deeper than previous CNNs (as you’ll see in Figure 14-14). This was made\n",
            "\n",
            "--- Chunk 10299 ---\n",
            "12 Matthew D. Zeiler and Rob Fergus, “Visualizing and Understanding Convolutional Networks,” Proceedings of\n",
            "\n",
            "--- Chunk 10300 ---\n",
            "the European Conference on Computer Vision (2014): 818-833.\n",
            "\n",
            "--- Chunk 10301 ---\n",
            "13 Christian Szegedy et al., “Going Deeper with Convolutions,” Proceedings of the IEEE Conference on Computer\n",
            "\n",
            "--- Chunk 10302 ---\n",
            "Vision and Pattern Recognition (2015): 1–9.\n",
            "\n",
            "--- Chunk 10303 ---\n",
            "466 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 10304 ---\n",
            "possible by subnetworks called inception modules,14 which allow GoogLeNet to use\n",
            "\n",
            "--- Chunk 10305 ---\n",
            "parameters much more efficiently than previous architectures: GoogLeNet actually\n",
            "\n",
            "--- Chunk 10306 ---\n",
            "has 10 times fewer parameters than AlexNet (roughly 6 million instead of 60 million).\n",
            "\n",
            "--- Chunk 10307 ---\n",
            "Figure 14-13 shows the architecture of an inception module. The notation “3 × 3 +\n",
            "\n",
            "--- Chunk 10308 ---\n",
            "1(S)” means that the layer uses a 3 × 3 kernel, stride 1, and \"same\" padding. The input\n",
            "\n",
            "--- Chunk 10309 ---\n",
            "signal is first copied and fed to four different layers. All convolutional layers use the\n",
            "\n",
            "--- Chunk 10310 ---\n",
            "ReLU activation function. Note that the second set of convolutional layers uses differ‐\n",
            "\n",
            "--- Chunk 10311 ---\n",
            "ent kernel sizes (1 × 1, 3 × 3, and 5 × 5), allowing them to capture patterns at different\n",
            "\n",
            "--- Chunk 10312 ---\n",
            "scales. Also note that every single layer uses a stride of 1 and \"same\" padding (even\n",
            "\n",
            "--- Chunk 10313 ---\n",
            "the max pooling layer), so their outputs all have the same height and width as their\n",
            "\n",
            "--- Chunk 10314 ---\n",
            "inputs. This makes it possible to concatenate all the outputs along the depth dimen‐\n",
            "\n",
            "--- Chunk 10315 ---\n",
            "sion in the final depth concatenation layer (i.e., stack the feature maps from all four\n",
            "\n",
            "--- Chunk 10316 ---\n",
            "top convolutional layers). This concatenation layer can be implemented in Tensor‐\n",
            "\n",
            "--- Chunk 10317 ---\n",
            "Flow using the tf.concat() operation, with axis=3 (the axis is the depth).\n",
            "\n",
            "--- Chunk 10318 ---\n",
            "Figure 14-13. Inception module\n",
            "\n",
            "--- Chunk 10319 ---\n",
            "You may wonder why inception modules have convolutional layers with 1 × 1 ker‐\n",
            "\n",
            "--- Chunk 10320 ---\n",
            "nels. Surely these layers cannot capture any features because they look at only one\n",
            "pixel at a time? In fact, the layers serve three purposes:\n",
            "\n",
            "--- Chunk 10321 ---\n",
            "• Although they cannot capture spatial patterns, they can capture patterns along\n",
            "the depth dimension.\n",
            "\n",
            "--- Chunk 10322 ---\n",
            "• They are configured to output fewer feature maps than their inputs, so they serve\n",
            "\n",
            "--- Chunk 10323 ---\n",
            "as bottleneck layers, meaning they reduce dimensionality. This cuts the computa‐\n",
            "\n",
            "--- Chunk 10324 ---\n",
            "14 In the 2010 movie Inception, the characters keep going deeper and deeper into multiple layers of dreams;\n",
            "hence the name of these modules.\n",
            "\n",
            "--- Chunk 10325 ---\n",
            "CNN Architectures | 467\n",
            "\n",
            "\n",
            "\n",
            "tional cost and the number of parameters, speeding up training and improving\n",
            "generalization.\n",
            "\n",
            "--- Chunk 10326 ---\n",
            "• Each pair of convolutional layers ([1 × 1, 3 × 3] and [1 × 1, 5 × 5]) acts like a\n",
            "\n",
            "--- Chunk 10327 ---\n",
            "single powerful convolutional layer, capable of capturing more complex patterns.\n",
            "\n",
            "--- Chunk 10328 ---\n",
            "Indeed, instead of sweeping a simple linear classifier across the image (as a single\n",
            "\n",
            "--- Chunk 10329 ---\n",
            "convolutional layer does), this pair of convolutional layers sweeps a two-layer\n",
            "neural network across the image.\n",
            "\n",
            "--- Chunk 10330 ---\n",
            "In short, you can think of the whole inception module as a convolutional layer on\n",
            "\n",
            "--- Chunk 10331 ---\n",
            "steroids, able to output feature maps that capture complex patterns at various scales.\n",
            "\n",
            "--- Chunk 10332 ---\n",
            "The number of convolutional kernels for each convolutional layer\n",
            "is a hyperparameter. Unfortunately, this means that you have six\n",
            "\n",
            "--- Chunk 10333 ---\n",
            "more hyperparameters to tweak for every inception layer you add.\n",
            "\n",
            "--- Chunk 10334 ---\n",
            "Now let’s look at the architecture of the GoogLeNet CNN (see Figure 14-14). The\n",
            "\n",
            "--- Chunk 10335 ---\n",
            "number of feature maps output by each convolutional layer and each pooling layer is\n",
            "\n",
            "--- Chunk 10336 ---\n",
            "shown before the kernel size. The architecture is so deep that it has to be represented\n",
            "\n",
            "--- Chunk 10337 ---\n",
            "in three columns, but GoogLeNet is actually one tall stack, including nine inception\n",
            "\n",
            "--- Chunk 10338 ---\n",
            "modules (the boxes with the spinning tops). The six numbers in the inception mod‐\n",
            "\n",
            "--- Chunk 10339 ---\n",
            "ules represent the number of feature maps output by each convolutional layer in the\n",
            "\n",
            "--- Chunk 10340 ---\n",
            "module (in the same order as in Figure 14-13). Note that all the convolutional layers\n",
            "use the ReLU activation function.\n",
            "\n",
            "--- Chunk 10341 ---\n",
            "468 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "\n",
            "\n",
            "Figure 14-14. GoogLeNet architecture\n",
            "\n",
            "Let’s go through this network:\n",
            "\n",
            "--- Chunk 10342 ---\n",
            "• The first two layers divide the image’s height and width by 4 (so its area is divided\n",
            "\n",
            "--- Chunk 10343 ---\n",
            "by 16), to reduce the computational load. The first layer uses a large kernel size so\n",
            "that much of the information is preserved.\n",
            "\n",
            "--- Chunk 10344 ---\n",
            "• Then the local response normalization layer ensures that the previous layers learn\n",
            "a wide variety of features (as discussed earlier).\n",
            "\n",
            "--- Chunk 10345 ---\n",
            "• Two convolutional layers follow, where the first acts like a bottleneck layer. As\n",
            "\n",
            "--- Chunk 10346 ---\n",
            "explained earlier, you can think of this pair as a single smarter convolutional\n",
            "layer.\n",
            "\n",
            "--- Chunk 10347 ---\n",
            "• Again, a local response normalization layer ensures that the previous layers cap‐\n",
            "ture a wide variety of patterns.\n",
            "\n",
            "--- Chunk 10348 ---\n",
            "• Next, a max pooling layer reduces the image height and width by 2, again to\n",
            "speed up computations.\n",
            "\n",
            "--- Chunk 10349 ---\n",
            "• Then comes the tall stack of nine inception modules, interleaved with a couple\n",
            "max pooling layers to reduce dimensionality and speed up the net.\n",
            "\n",
            "--- Chunk 10350 ---\n",
            "CNN Architectures | 469\n",
            "\n",
            "--- Chunk 10351 ---\n",
            "• Next, the global average pooling layer outputs the mean of each feature map: this\n",
            "\n",
            "--- Chunk 10352 ---\n",
            "drops any remaining spatial information, which is fine because there was not\n",
            "\n",
            "--- Chunk 10353 ---\n",
            "much spatial information left at that point. Indeed, GoogLeNet input images are\n",
            "\n",
            "--- Chunk 10354 ---\n",
            "typically expected to be 224 × 224 pixels, so after 5 max pooling layers, each\n",
            "\n",
            "--- Chunk 10355 ---\n",
            "dividing the height and width by 2, the feature maps are down to 7 × 7. More‐\n",
            "\n",
            "--- Chunk 10356 ---\n",
            "over, it is a classification task, not localization, so it does not matter where the\n",
            "\n",
            "--- Chunk 10357 ---\n",
            "object is. Thanks to the dimensionality reduction brought by this layer, there is\n",
            "\n",
            "--- Chunk 10358 ---\n",
            "no need to have several fully connected layers at the top of the CNN (like in\n",
            "\n",
            "--- Chunk 10359 ---\n",
            "AlexNet), and this considerably reduces the number of parameters in the net‐\n",
            "work and limits the risk of overfitting.\n",
            "\n",
            "--- Chunk 10360 ---\n",
            "• The last layers are self-explanatory: dropout for regularization, then a fully con‐\n",
            "\n",
            "--- Chunk 10361 ---\n",
            "nected layer with 1,000 units (since there are 1,000 classes) and a softmax activa‐\n",
            "tion function to output estimated class probabilities.\n",
            "\n",
            "--- Chunk 10362 ---\n",
            "This diagram is slightly simplified: the original GoogLeNet architecture also included\n",
            "\n",
            "--- Chunk 10363 ---\n",
            "two auxiliary classifiers plugged on top of the third and sixth inception modules.\n",
            "\n",
            "--- Chunk 10364 ---\n",
            "They were both composed of one average pooling layer, one convolutional layer, two\n",
            "\n",
            "--- Chunk 10365 ---\n",
            "fully connected layers, and a softmax activation layer. During training, their loss\n",
            "\n",
            "--- Chunk 10366 ---\n",
            "(scaled down by 70%) was added to the overall loss. The goal was to fight the vanish‐\n",
            "\n",
            "--- Chunk 10367 ---\n",
            "ing gradients problem and regularize the network. However, it was later shown that\n",
            "their effect was relatively minor.\n",
            "\n",
            "--- Chunk 10368 ---\n",
            "Several variants of the GoogLeNet architecture were later proposed by Google\n",
            "\n",
            "--- Chunk 10369 ---\n",
            "researchers, including Inception-v3 and Inception-v4, using slightly different incep‐\n",
            "tion modules and reaching even better performance.\n",
            "\n",
            "--- Chunk 10370 ---\n",
            "VGGNet\n",
            "The runner-up in the ILSVRC 2014 challenge was VGGNet,15 developed by Karen\n",
            "\n",
            "--- Chunk 10371 ---\n",
            "Simonyan and Andrew Zisserman from the Visual Geometry Group (VGG) research\n",
            "\n",
            "--- Chunk 10372 ---\n",
            "lab at Oxford University. It had a very simple and classical architecture, with 2 or 3\n",
            "\n",
            "--- Chunk 10373 ---\n",
            "convolutional layers and a pooling layer, then again 2 or 3 convolutional layers and a\n",
            "\n",
            "--- Chunk 10374 ---\n",
            "pooling layer, and so on (reaching a total of just 16 or 19 convolutional layers,\n",
            "\n",
            "--- Chunk 10375 ---\n",
            "depending on the VGG variant), plus a final dense network with 2 hidden layers and\n",
            "the output layer. It used only 3 × 3 filters, but many filters.\n",
            "\n",
            "--- Chunk 10376 ---\n",
            "15 Karen Simonyan and Andrew Zisserman, “Very Deep Convolutional Networks for Large-Scale Image Recog‐\n",
            "\n",
            "--- Chunk 10377 ---\n",
            "nition,” arXiv preprint arXiv:1409.1556 (2014).\n",
            "\n",
            "--- Chunk 10378 ---\n",
            "470 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 10379 ---\n",
            "ResNet\n",
            "Kaiming He et al. won the ILSVRC 2015 challenge using a Residual Network (or\n",
            "\n",
            "--- Chunk 10380 ---\n",
            "ResNet),16 that delivered an astounding top-five error rate under 3.6%. The winning\n",
            "\n",
            "--- Chunk 10381 ---\n",
            "variant used an extremely deep CNN composed of 152 layers (other variants had 34,\n",
            "\n",
            "--- Chunk 10382 ---\n",
            "50, and 101 layers). It confirmed the general trend: models are getting deeper and\n",
            "\n",
            "--- Chunk 10383 ---\n",
            "deeper, with fewer and fewer parameters. The key to being able to train such a deep\n",
            "\n",
            "--- Chunk 10384 ---\n",
            "network is to use skip connections (also called shortcut connections): the signal feeding\n",
            "\n",
            "--- Chunk 10385 ---\n",
            "into a layer is also added to the output of a layer located a bit higher up the stack. Let’s\n",
            "see why this is useful.\n",
            "\n",
            "--- Chunk 10386 ---\n",
            "When training a neural network, the goal is to make it model a target function h(x).\n",
            "\n",
            "--- Chunk 10387 ---\n",
            "If you add the input x to the output of the network (i.e., you add a skip connection),\n",
            "\n",
            "--- Chunk 10388 ---\n",
            "then the network will be forced to model f(x) = h(x) – x rather than h(x). This is\n",
            "called residual learning (see Figure 14-15).\n",
            "\n",
            "--- Chunk 10389 ---\n",
            "Figure 14-15. Residual learning\n",
            "\n",
            "--- Chunk 10390 ---\n",
            "When you initialize a regular neural network, its weights are close to zero, so the net‐\n",
            "\n",
            "--- Chunk 10391 ---\n",
            "work just outputs values close to zero. If you add a skip connection, the resulting net‐\n",
            "\n",
            "--- Chunk 10392 ---\n",
            "work just outputs a copy of its inputs; in other words, it initially models the identity\n",
            "\n",
            "--- Chunk 10393 ---\n",
            "function. If the target function is fairly close to the identity function (which is often\n",
            "the case), this will speed up training considerably.\n",
            "\n",
            "--- Chunk 10394 ---\n",
            "Moreover, if you add many skip connections, the network can start making progress\n",
            "\n",
            "--- Chunk 10395 ---\n",
            "even if several layers have not started learning yet (see Figure 14-16). Thanks to skip\n",
            "\n",
            "--- Chunk 10396 ---\n",
            "connections, the signal can easily make its way across the whole network. The deep\n",
            "\n",
            "--- Chunk 10397 ---\n",
            "residual network can be seen as a stack of residual units (RUs), where each residual\n",
            "unit is a small neural network with a skip connection.\n",
            "\n",
            "--- Chunk 10398 ---\n",
            "16 Kaiming He et al., “Deep Residual Learning for Image Recognition,” arXiv preprint arXiv:1512:03385 (2015).\n",
            "\n",
            "CNN Architectures | 471\n",
            "\n",
            "--- Chunk 10399 ---\n",
            "Figure 14-16. Regular deep neural network (left) and deep residual network (right)\n",
            "\n",
            "--- Chunk 10400 ---\n",
            "Now let’s look at ResNet’s architecture (see Figure 14-17). It is surprisingly simple. It\n",
            "\n",
            "--- Chunk 10401 ---\n",
            "starts and ends exactly like GoogLeNet (except without a dropout layer), and in\n",
            "\n",
            "--- Chunk 10402 ---\n",
            "between is just a very deep stack of simple residual units. Each residual unit is com‐\n",
            "\n",
            "--- Chunk 10403 ---\n",
            "posed of two convolutional layers (and no pooling layer!), with Batch Normalization\n",
            "\n",
            "--- Chunk 10404 ---\n",
            "(BN) and ReLU activation, using 3 × 3 kernels and preserving spatial dimensions\n",
            "(stride 1, \"same\" padding).\n",
            "\n",
            "--- Chunk 10405 ---\n",
            "472 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "\n",
            "\n",
            "Figure 14-17. ResNet architecture\n",
            "\n",
            "--- Chunk 10406 ---\n",
            "Note that the number of feature maps is doubled every few residual units, at the same\n",
            "\n",
            "--- Chunk 10407 ---\n",
            "time as their height and width are halved (using a convolutional layer with stride 2).\n",
            "\n",
            "--- Chunk 10408 ---\n",
            "When this happens, the inputs cannot be added directly to the outputs of the residual\n",
            "\n",
            "--- Chunk 10409 ---\n",
            "unit because they don’t have the same shape (for example, this problem affects the\n",
            "\n",
            "--- Chunk 10410 ---\n",
            "skip connection represented by the dashed arrow in Figure 14-17). To solve this prob‐\n",
            "\n",
            "--- Chunk 10411 ---\n",
            "lem, the inputs are passed through a 1 × 1 convolutional layer with stride 2 and the\n",
            "right number of output feature maps (see Figure 14-18).\n",
            "\n",
            "--- Chunk 10412 ---\n",
            "Figure 14-18. Skip connection when changing feature map size and depth\n",
            "\n",
            "CNN Architectures | 473\n",
            "\n",
            "--- Chunk 10413 ---\n",
            "ResNet-34 is the ResNet with 34 layers (only counting the convolutional layers and\n",
            "\n",
            "--- Chunk 10414 ---\n",
            "the fully connected layer)17 containing 3 residual units that output 64 feature maps, 4\n",
            "\n",
            "--- Chunk 10415 ---\n",
            "RUs with 128 maps, 6 RUs with 256 maps, and 3 RUs with 512 maps. We will imple‐\n",
            "ment this architecture later in this chapter.\n",
            "\n",
            "--- Chunk 10416 ---\n",
            "ResNets deeper than that, such as ResNet-152, use slightly different residual units.\n",
            "\n",
            "--- Chunk 10417 ---\n",
            "Instead of two 3 × 3 convolutional layers with, say, 256 feature maps, they use three\n",
            "\n",
            "--- Chunk 10418 ---\n",
            "convolutional layers: first a 1 × 1 convolutional layer with just 64 feature maps (4\n",
            "\n",
            "--- Chunk 10419 ---\n",
            "times less), which acts as a bottleneck layer (as discussed already), then a 3 × 3 layer\n",
            "\n",
            "--- Chunk 10420 ---\n",
            "with 64 feature maps, and finally another 1 × 1 convolutional layer with 256 feature\n",
            "\n",
            "--- Chunk 10421 ---\n",
            "maps (4 times 64) that restores the original depth. ResNet-152 contains 3 such RUs\n",
            "\n",
            "--- Chunk 10422 ---\n",
            "that output 256 maps, then 8 RUs with 512 maps, a whopping 36 RUs with 1,024\n",
            "maps, and finally 3 RUs with 2,048 maps.\n",
            "\n",
            "--- Chunk 10423 ---\n",
            "Google’s Inception-v418 architecture merged the ideas of GoogLe‐\n",
            "Net and ResNet and achieved a top-five error rate of close to 3% on\n",
            "\n",
            "--- Chunk 10424 ---\n",
            "ImageNet classification.\n",
            "\n",
            "--- Chunk 10425 ---\n",
            "Xception\n",
            "Another variant of the GoogLeNet architecture is worth noting: Xception19 (which\n",
            "\n",
            "--- Chunk 10426 ---\n",
            "stands for Extreme Inception) was proposed in 2016 by François Chollet (the author\n",
            "\n",
            "--- Chunk 10427 ---\n",
            "of Keras), and it significantly outperformed Inception-v3 on a huge vision task (350\n",
            "\n",
            "--- Chunk 10428 ---\n",
            "million images and 17,000 classes). Just like Inception-v4, it merges the ideas of Goo‐\n",
            "\n",
            "--- Chunk 10429 ---\n",
            "gLeNet and ResNet, but it replaces the inception modules with a special type of layer\n",
            "\n",
            "--- Chunk 10430 ---\n",
            "called a depthwise separable convolution layer (or separable convolution layer for\n",
            "\n",
            "--- Chunk 10431 ---\n",
            "short20). These layers had been used before in some CNN architectures, but they were\n",
            "\n",
            "--- Chunk 10432 ---\n",
            "not as central as in the Xception architecture. While a regular convolutional layer\n",
            "\n",
            "--- Chunk 10433 ---\n",
            "uses filters that try to simultaneously capture spatial patterns (e.g., an oval) and cross-\n",
            "\n",
            "--- Chunk 10434 ---\n",
            "channel patterns (e.g., mouth + nose + eyes = face), a separable convolutional layer\n",
            "\n",
            "--- Chunk 10435 ---\n",
            "makes the strong assumption that spatial patterns and cross-channel patterns can be\n",
            "\n",
            "--- Chunk 10436 ---\n",
            "modeled separately (see Figure 14-19). Thus, it is composed of two parts: the first part\n",
            "\n",
            "--- Chunk 10437 ---\n",
            "applies a single spatial filter for each input feature map, then the second part looks\n",
            "\n",
            "--- Chunk 10438 ---\n",
            "17 It is a common practice when describing a neural network to count only layers with parameters.\n",
            "\n",
            "--- Chunk 10439 ---\n",
            "18 Christian Szegedy et al., “Inception–v4, Inception-ResNet and the Impact of Residual Connections on Learn‐\n",
            "\n",
            "--- Chunk 10440 ---\n",
            "ing,” arXiv preprint arXiv:1602.07261 (2016).\n",
            "\n",
            "--- Chunk 10441 ---\n",
            "19 François Chollet, “Xception: Deep Learning with Depthwise Separable Convolutions,” arXiv preprint arXiv:\n",
            "\n",
            "--- Chunk 10442 ---\n",
            "1610.02357 (2016).\n",
            "20 This name can sometimes be ambiguous, since spatially separable convolutions are often called “separable\n",
            "\n",
            "--- Chunk 10443 ---\n",
            "convolutions” as well.\n",
            "\n",
            "474 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 10444 ---\n",
            "exclusively for cross-channel patterns—it is just a regular convolutional layer with 1 ×\n",
            "1 filters.\n",
            "\n",
            "--- Chunk 10445 ---\n",
            "Figure 14-19. Depthwise separable convolutional layer\n",
            "\n",
            "--- Chunk 10446 ---\n",
            "Since separable convolutional layers only have one spatial filter per input channel,\n",
            "\n",
            "--- Chunk 10447 ---\n",
            "you should avoid using them after layers that have too few channels, such as the input\n",
            "\n",
            "--- Chunk 10448 ---\n",
            "layer (granted, that’s what Figure 14-19 represents, but it is just for illustration pur‐\n",
            "\n",
            "--- Chunk 10449 ---\n",
            "poses). For this reason, the Xception architecture starts with 2 regular convolutional\n",
            "\n",
            "--- Chunk 10450 ---\n",
            "layers, but then the rest of the architecture uses only separable convolutions (34 in\n",
            "\n",
            "--- Chunk 10451 ---\n",
            "all), plus a few max pooling layers and the usual final layers (a global average pooling\n",
            "layer and a dense output layer).\n",
            "\n",
            "--- Chunk 10452 ---\n",
            "You might wonder why Xception is considered a variant of GoogLeNet, since it con‐\n",
            "\n",
            "--- Chunk 10453 ---\n",
            "tains no inception module at all. Well, as we discussed earlier, an inception module\n",
            "\n",
            "--- Chunk 10454 ---\n",
            "contains convolutional layers with 1 × 1 filters: these look exclusively for cross-\n",
            "\n",
            "--- Chunk 10455 ---\n",
            "channel patterns. However, the convolutional layers that sit on top of them are regu‐\n",
            "\n",
            "--- Chunk 10456 ---\n",
            "lar convolutional layers that look both for spatial and cross-channel patterns. So you\n",
            "\n",
            "--- Chunk 10457 ---\n",
            "can think of an inception module as an intermediate between a regular convolutional\n",
            "\n",
            "--- Chunk 10458 ---\n",
            "layer (which considers spatial patterns and cross-channel patterns jointly) and a sepa‐\n",
            "\n",
            "--- Chunk 10459 ---\n",
            "rable convolutional layer (which considers them separately). In practice, it seems that\n",
            "separable convolutional layers generally perform better.\n",
            "\n",
            "--- Chunk 10460 ---\n",
            "CNN Architectures | 475\n",
            "\n",
            "--- Chunk 10461 ---\n",
            "Separable convolutional layers use fewer parameters, less memory,\n",
            "and fewer computations than regular convolutional layers, and in\n",
            "\n",
            "--- Chunk 10462 ---\n",
            "general they even perform better, so you should consider using\n",
            "them by default (except after layers with few channels).\n",
            "\n",
            "--- Chunk 10463 ---\n",
            "The ILSVRC 2016 challenge was won by the CUImage team from the Chinese Uni‐\n",
            "\n",
            "--- Chunk 10464 ---\n",
            "versity of Hong Kong. They used an ensemble of many different techniques, includ‐\n",
            "\n",
            "--- Chunk 10465 ---\n",
            "ing a sophisticated object-detection system called GBD-Net,21 to achieve a top-five\n",
            "\n",
            "--- Chunk 10466 ---\n",
            "error rate below 3%. Although this result is unquestionably impressive, the complex‐\n",
            "\n",
            "--- Chunk 10467 ---\n",
            "ity of the solution contrasted with the simplicity of ResNets. Moreover, one year later\n",
            "\n",
            "--- Chunk 10468 ---\n",
            "another fairly simple architecture performed even better, as we will see now.\n",
            "\n",
            "--- Chunk 10469 ---\n",
            "SENet\n",
            "The winning architecture in the ILSVRC 2017 challenge was the Squeeze-and-\n",
            "\n",
            "--- Chunk 10470 ---\n",
            "Excitation Network (SENet).22 This architecture extends existing architectures such as\n",
            "\n",
            "--- Chunk 10471 ---\n",
            "inception networks and ResNets, and boosts their performance. This allowed SENet\n",
            "\n",
            "--- Chunk 10472 ---\n",
            "to win the competition with an astonishing 2.25% top-five error rate! The extended\n",
            "\n",
            "--- Chunk 10473 ---\n",
            "versions of inception networks and ResNets are called SE-Inception and SE-ResNet,\n",
            "\n",
            "--- Chunk 10474 ---\n",
            "respectively. The boost comes from the fact that a SENet adds a small neural network,\n",
            "\n",
            "--- Chunk 10475 ---\n",
            "called an SE block, to every unit in the original architecture (i.e., every inception\n",
            "module or every residual unit), as shown in Figure 14-20.\n",
            "\n",
            "--- Chunk 10476 ---\n",
            "Figure 14-20. SE-Inception module (left) and SE-ResNet unit (right)\n",
            "\n",
            "--- Chunk 10477 ---\n",
            "21 Xingyu Zeng et al., “Crafting GBD-Net for Object Detection,” IEEE Transactions on Pattern Analysis and\n",
            "\n",
            "--- Chunk 10478 ---\n",
            "Machine Intelligence 40, no. 9 (2018): 2109–2123.\n",
            "\n",
            "--- Chunk 10479 ---\n",
            "22 Jie Hu et al., “Squeeze-and-Excitation Networks,” Proceedings of the IEEE Conference on Computer Vision and\n",
            "\n",
            "--- Chunk 10480 ---\n",
            "Pattern Recognition (2018): 7132–7141.\n",
            "\n",
            "--- Chunk 10481 ---\n",
            "476 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 10482 ---\n",
            "An SE block analyzes the output of the unit it is attached to, focusing exclusively on\n",
            "\n",
            "--- Chunk 10483 ---\n",
            "the depth dimension (it does not look for any spatial pattern), and it learns which fea‐\n",
            "\n",
            "--- Chunk 10484 ---\n",
            "tures are usually most active together. It then uses this information to recalibrate the\n",
            "\n",
            "--- Chunk 10485 ---\n",
            "feature maps, as shown in Figure 14-21. For example, an SE block may learn that\n",
            "\n",
            "--- Chunk 10486 ---\n",
            "mouths, noses, and eyes usually appear together in pictures: if you see a mouth and a\n",
            "\n",
            "--- Chunk 10487 ---\n",
            "nose, you should expect to see eyes as well. So if the block sees a strong activation in\n",
            "\n",
            "--- Chunk 10488 ---\n",
            "the mouth and nose feature maps, but only mild activation in the eye feature map, it\n",
            "\n",
            "--- Chunk 10489 ---\n",
            "will boost the eye feature map (more accurately, it will reduce irrelevant feature\n",
            "\n",
            "--- Chunk 10490 ---\n",
            "maps). If the eyes were somewhat confused with something else, this feature map\n",
            "recalibration will help resolve the ambiguity.\n",
            "\n",
            "--- Chunk 10491 ---\n",
            "Figure 14-21. An SE block performs feature map recalibration\n",
            "\n",
            "--- Chunk 10492 ---\n",
            "An SE block is composed of just three layers: a global average pooling layer, a hidden\n",
            "\n",
            "--- Chunk 10493 ---\n",
            "dense layer using the ReLU activation function, and a dense output layer using the\n",
            "sigmoid activation function (see Figure 14-22).\n",
            "\n",
            "--- Chunk 10494 ---\n",
            "Figure 14-22. SE block architecture\n",
            "\n",
            "--- Chunk 10495 ---\n",
            "As earlier, the global average pooling layer computes the mean activation for each fea‐\n",
            "\n",
            "--- Chunk 10496 ---\n",
            "ture map: for example, if its input contains 256 feature maps, it will output 256\n",
            "\n",
            "--- Chunk 10497 ---\n",
            "CNN Architectures | 477\n",
            "\n",
            "--- Chunk 10498 ---\n",
            "numbers representing the overall level of response for each filter. The next layer is\n",
            "\n",
            "--- Chunk 10499 ---\n",
            "where the “squeeze” happens: this layer has significantly fewer than 256 neurons—\n",
            "\n",
            "--- Chunk 10500 ---\n",
            "typically 16 times fewer than the number of feature maps (e.g., 16 neurons)—so the\n",
            "\n",
            "--- Chunk 10501 ---\n",
            "256 numbers get compressed into a small vector (e.g., 16 dimensions). This is a low-\n",
            "\n",
            "--- Chunk 10502 ---\n",
            "dimensional vector representation (i.e., an embedding) of the distribution of feature\n",
            "\n",
            "--- Chunk 10503 ---\n",
            "responses. This bottleneck step forces the SE block to learn a general representation\n",
            "\n",
            "--- Chunk 10504 ---\n",
            "of the feature combinations (we will see this principle in action again when we dis‐\n",
            "\n",
            "--- Chunk 10505 ---\n",
            "cuss autoencoders in Chapter 17). Finally, the output layer takes the embedding and\n",
            "\n",
            "--- Chunk 10506 ---\n",
            "outputs a recalibration vector containing one number per feature map (e.g., 256),\n",
            "\n",
            "--- Chunk 10507 ---\n",
            "each between 0 and 1. The feature maps are then multiplied by this recalibration vec‐\n",
            "\n",
            "--- Chunk 10508 ---\n",
            "tor, so irrelevant features (with a low recalibration score) get scaled down while rele‐\n",
            "\n",
            "--- Chunk 10509 ---\n",
            "vant features (with a recalibration score close to 1) are left alone.\n",
            "\n",
            "--- Chunk 10510 ---\n",
            "Implementing a ResNet-34 CNN Using Keras\n",
            "Most CNN architectures described so far are fairly straightforward to implement\n",
            "\n",
            "--- Chunk 10511 ---\n",
            "(although generally you would load a pretrained network instead, as we will see). To\n",
            "\n",
            "--- Chunk 10512 ---\n",
            "illustrate the process, let’s implement a ResNet-34 from scratch using Keras. First, let’s\n",
            "create a ResidualUnit layer:\n",
            "\n",
            "--- Chunk 10513 ---\n",
            "class ResidualUnit(keras.layers.Layer):\n",
            "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
            "        super().__init__(**kwargs)\n",
            "\n",
            "--- Chunk 10514 ---\n",
            "self.activation = keras.activations.get(activation)\n",
            "        self.main_layers = [\n",
            "            keras.layers.Conv2D(filters, 3, strides=strides,\n",
            "\n",
            "--- Chunk 10515 ---\n",
            "padding=\"same\", use_bias=False),\n",
            "            keras.layers.BatchNormalization(),\n",
            "            self.activation,\n",
            "\n",
            "--- Chunk 10516 ---\n",
            "keras.layers.Conv2D(filters, 3, strides=1,\n",
            "                                padding=\"same\", use_bias=False),\n",
            "\n",
            "--- Chunk 10517 ---\n",
            "keras.layers.BatchNormalization()]\n",
            "        self.skip_layers = []\n",
            "        if strides > 1:\n",
            "            self.skip_layers = [\n",
            "\n",
            "--- Chunk 10518 ---\n",
            "keras.layers.Conv2D(filters, 1, strides=strides,\n",
            "                                    padding=\"same\", use_bias=False),\n",
            "\n",
            "--- Chunk 10519 ---\n",
            "keras.layers.BatchNormalization()]\n",
            "\n",
            "--- Chunk 10520 ---\n",
            "def call(self, inputs):\n",
            "        Z = inputs\n",
            "        for layer in self.main_layers:\n",
            "            Z = layer(Z)\n",
            "        skip_Z = inputs\n",
            "\n",
            "--- Chunk 10521 ---\n",
            "for layer in self.skip_layers:\n",
            "            skip_Z = layer(skip_Z)\n",
            "        return self.activation(Z + skip_Z)\n",
            "\n",
            "--- Chunk 10522 ---\n",
            "478 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 10523 ---\n",
            "As you can see, this code matches Figure 14-18 pretty closely. In the constructor, we\n",
            "\n",
            "--- Chunk 10524 ---\n",
            "create all the layers we will need: the main layers are the ones on the right side of the\n",
            "\n",
            "--- Chunk 10525 ---\n",
            "diagram, and the skip layers are the ones on the left (only needed if the stride is\n",
            "\n",
            "--- Chunk 10526 ---\n",
            "greater than 1). Then in the call() method, we make the inputs go through the main\n",
            "\n",
            "--- Chunk 10527 ---\n",
            "layers and the skip layers (if any), then we add both outputs and apply the activation\n",
            "function.\n",
            "\n",
            "--- Chunk 10528 ---\n",
            "function.\n",
            "Next, we can build the ResNet-34 using a Sequential model, since it’s really just a\n",
            "\n",
            "--- Chunk 10529 ---\n",
            "long sequence of layers (we can treat each residual unit as a single layer now that we\n",
            "have the ResidualUnit class):\n",
            "\n",
            "--- Chunk 10530 ---\n",
            "model = keras.models.Sequential()\n",
            "model.add(keras.layers.Conv2D(64, 7, strides=2, input_shape=[224, 224, 3],\n",
            "\n",
            "--- Chunk 10531 ---\n",
            "padding=\"same\", use_bias=False))\n",
            "model.add(keras.layers.BatchNormalization())\n",
            "\n",
            "--- Chunk 10532 ---\n",
            "model.add(keras.layers.Activation(\"relu\"))\n",
            "model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\"))\n",
            "prev_filters = 64\n",
            "\n",
            "--- Chunk 10533 ---\n",
            "prev_filters = 64\n",
            "for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
            "    strides = 1 if filters == prev_filters else 2\n",
            "\n",
            "--- Chunk 10534 ---\n",
            "model.add(ResidualUnit(filters, strides=strides))\n",
            "    prev_filters = filters\n",
            "model.add(keras.layers.GlobalAvgPool2D())\n",
            "\n",
            "--- Chunk 10535 ---\n",
            "model.add(keras.layers.Flatten())\n",
            "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
            "\n",
            "--- Chunk 10536 ---\n",
            "The only slightly tricky part in this code is the loop that adds the ResidualUnit layers\n",
            "\n",
            "--- Chunk 10537 ---\n",
            "to the model: as explained earlier, the first 3 RUs have 64 filters, then the next 4 RUs\n",
            "\n",
            "--- Chunk 10538 ---\n",
            "have 128 filters, and so on. We then set the stride to 1 when the number of filters is\n",
            "\n",
            "--- Chunk 10539 ---\n",
            "the same as in the previous RU, or else we set it to 2. Then we add the ResidualUnit,\n",
            "and finally we update prev_filters.\n",
            "\n",
            "--- Chunk 10540 ---\n",
            "It is amazing that in fewer than 40 lines of code, we can build the model that won the\n",
            "\n",
            "--- Chunk 10541 ---\n",
            "ILSVRC 2015 challenge! This demonstrates both the elegance of the ResNet model\n",
            "\n",
            "--- Chunk 10542 ---\n",
            "and the expressiveness of the Keras API. Implementing the other CNN architectures\n",
            "\n",
            "--- Chunk 10543 ---\n",
            "is not much harder. However, Keras comes with several of these architectures built in,\n",
            "so why not use them instead?\n",
            "\n",
            "--- Chunk 10544 ---\n",
            "Using Pretrained Models from Keras\n",
            "In general, you won’t have to implement standard models like GoogLeNet or ResNet\n",
            "\n",
            "--- Chunk 10545 ---\n",
            "manually, since pretrained networks are readily available with a single line of code in\n",
            "\n",
            "--- Chunk 10546 ---\n",
            "the keras.applications package. For example, you can load the ResNet-50 model,\n",
            "pretrained on ImageNet, with the following line of code:\n",
            "\n",
            "--- Chunk 10547 ---\n",
            "model = keras.applications.resnet50.ResNet50(weights=\"imagenet\")\n",
            "\n",
            "Using Pretrained Models from Keras | 479\n",
            "\n",
            "--- Chunk 10548 ---\n",
            "That’s all! This will create a ResNet-50 model and download weights pretrained on\n",
            "\n",
            "--- Chunk 10549 ---\n",
            "the ImageNet dataset. To use it, you first need to ensure that the images have the right\n",
            "\n",
            "--- Chunk 10550 ---\n",
            "size. A ResNet-50 model expects 224 × 224-pixel images (other models may expect\n",
            "\n",
            "--- Chunk 10551 ---\n",
            "other sizes, such as 299 × 299), so let’s use TensorFlow’s tf.image.resize() function\n",
            "to resize the images we loaded earlier:\n",
            "\n",
            "--- Chunk 10552 ---\n",
            "images_resized = tf.image.resize(images, [224, 224])\n",
            "\n",
            "--- Chunk 10553 ---\n",
            "The tf.image.resize() will not preserve the aspect ratio. If this is\n",
            "a problem, try cropping the images to the appropriate aspect ratio\n",
            "\n",
            "--- Chunk 10554 ---\n",
            "before resizing. Both operations can be done in one shot with\n",
            "tf.image.crop_and_resize().\n",
            "\n",
            "--- Chunk 10555 ---\n",
            "The pretrained models assume that the images are preprocessed in a specific way. In\n",
            "\n",
            "--- Chunk 10556 ---\n",
            "some cases they may expect the inputs to be scaled from 0 to 1, or –1 to 1, and so on.\n",
            "\n",
            "--- Chunk 10557 ---\n",
            "Each model provides a preprocess_input() function that you can use to preprocess\n",
            "\n",
            "--- Chunk 10558 ---\n",
            "your images. These functions assume that the pixel values range from 0 to 255, so we\n",
            "\n",
            "--- Chunk 10559 ---\n",
            "must multiply them by 255 (since earlier we scaled them to the 0–1 range):\n",
            "\n",
            "--- Chunk 10560 ---\n",
            "inputs = keras.applications.resnet50.preprocess_input(images_resized * 255)\n",
            "\n",
            "--- Chunk 10561 ---\n",
            "Now we can use the pretrained model to make predictions:\n",
            "Y_proba = model.predict(inputs)\n",
            "\n",
            "--- Chunk 10562 ---\n",
            "As usual, the output Y_proba is a matrix with one row per image and one column per\n",
            "\n",
            "--- Chunk 10563 ---\n",
            "class (in this case, there are 1,000 classes). If you want to display the top K predic‐\n",
            "\n",
            "--- Chunk 10564 ---\n",
            "tions, including the class name and the estimated probability of each predicted class,\n",
            "\n",
            "--- Chunk 10565 ---\n",
            "use the decode_predictions() function. For each image, it returns an array contain‐\n",
            "\n",
            "--- Chunk 10566 ---\n",
            "ing the top K predictions, where each prediction is represented as an array containing\n",
            "\n",
            "--- Chunk 10567 ---\n",
            "the class identifier,23 its name, and the corresponding confidence score:\n",
            "\n",
            "--- Chunk 10568 ---\n",
            "top_K = keras.applications.resnet50.decode_predictions(Y_proba, top=3)\n",
            "for image_index in range(len(images)):\n",
            "\n",
            "--- Chunk 10569 ---\n",
            "print(\"Image #{}\".format(image_index))\n",
            "    for class_id, name, y_proba in top_K[image_index]:\n",
            "\n",
            "--- Chunk 10570 ---\n",
            "print(\"  {} - {:12s} {:.2f}%\".format(class_id, name, y_proba * 100))\n",
            "    print()\n",
            "\n",
            "--- Chunk 10571 ---\n",
            "The output looks like this:\n",
            "Image #0\n",
            "  n03877845 - palace       42.87%\n",
            "  n02825657 - bell_cote    40.57%\n",
            "  n03781244 - monastery    14.56%\n",
            "\n",
            "--- Chunk 10572 ---\n",
            "23 In the ImageNet dataset, each image is associated to a word in the WordNet dataset: the class ID is just a\n",
            "WordNet ID.\n",
            "\n",
            "--- Chunk 10573 ---\n",
            "480 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 10574 ---\n",
            "Image #1\n",
            "  n04522168 - vase         46.83%\n",
            "  n07930864 - cup          7.78%\n",
            "  n11939491 - daisy        4.87%\n",
            "\n",
            "--- Chunk 10575 ---\n",
            "The correct classes (monastery and daisy) appear in the top three results for both\n",
            "\n",
            "--- Chunk 10576 ---\n",
            "images. That’s pretty good, considering that the model had to choose from among\n",
            "1,000 classes.\n",
            "\n",
            "--- Chunk 10577 ---\n",
            "1,000 classes.\n",
            "As you can see, it is very easy to create a pretty good image classifier using a pre‐\n",
            "\n",
            "--- Chunk 10578 ---\n",
            "trained model. Other vision models are available in keras.applications, including\n",
            "\n",
            "--- Chunk 10579 ---\n",
            "several ResNet variants, GoogLeNet variants like Inception-v3 and Xception,\n",
            "\n",
            "--- Chunk 10580 ---\n",
            "VGGNet variants, and MobileNet and MobileNetV2 (lightweight models for use in\n",
            "mobile applications).\n",
            "\n",
            "--- Chunk 10581 ---\n",
            "But what if you want to use an image classifier for classes of images that are not part\n",
            "\n",
            "--- Chunk 10582 ---\n",
            "of ImageNet? In that case, you may still benefit from the pretrained models to per‐\n",
            "form transfer learning.\n",
            "\n",
            "--- Chunk 10583 ---\n",
            "Pretrained Models for Transfer Learning\n",
            "If you want to build an image classifier but you do not have enough training data,\n",
            "\n",
            "--- Chunk 10584 ---\n",
            "then it is often a good idea to reuse the lower layers of a pretrained model, as we dis‐\n",
            "\n",
            "--- Chunk 10585 ---\n",
            "cussed in Chapter 11. For example, let’s train a model to classify pictures of flowers,\n",
            "\n",
            "--- Chunk 10586 ---\n",
            "reusing a pretrained Xception model. First, let’s load the dataset using TensorFlow\n",
            "Datasets (see Chapter 13):\n",
            "\n",
            "--- Chunk 10587 ---\n",
            "import tensorflow_datasets as tfds\n",
            "\n",
            "--- Chunk 10588 ---\n",
            "dataset, info = tfds.load(\"tf_flowers\", as_supervised=True, with_info=True)\n",
            "dataset_size = info.splits[\"train\"].num_examples # 3670\n",
            "\n",
            "--- Chunk 10589 ---\n",
            "class_names = info.features[\"label\"].names # [\"dandelion\", \"daisy\", ...]\n",
            "n_classes = info.features[\"label\"].num_classes # 5\n",
            "\n",
            "--- Chunk 10590 ---\n",
            "Note that you can get information about the dataset by setting with_info=True. Here,\n",
            "\n",
            "--- Chunk 10591 ---\n",
            "we get the dataset size and the names of the classes. Unfortunately, there is only a\n",
            "\n",
            "--- Chunk 10592 ---\n",
            "\"train\" dataset, no test set or validation set, so we need to split the training set. The\n",
            "\n",
            "--- Chunk 10593 ---\n",
            "TF Datasets project provides an API for this. For example, let’s take the first 10% of\n",
            "\n",
            "--- Chunk 10594 ---\n",
            "the dataset for testing, the next 15% for validation, and the remaining 75% for\n",
            "training:\n",
            "\n",
            "--- Chunk 10595 ---\n",
            "test_split, valid_split, train_split = tfds.Split.TRAIN.subsplit([10, 15, 75])\n",
            "\n",
            "--- Chunk 10596 ---\n",
            "test_set = tfds.load(\"tf_flowers\", split=test_split, as_supervised=True)\n",
            "valid_set = tfds.load(\"tf_flowers\", split=valid_split, as_supervised=True)\n",
            "\n",
            "--- Chunk 10597 ---\n",
            "train_set = tfds.load(\"tf_flowers\", split=train_split, as_supervised=True)\n",
            "\n",
            "--- Chunk 10598 ---\n",
            "Pretrained Models for Transfer Learning | 481\n",
            "\n",
            "--- Chunk 10599 ---\n",
            "Next we must preprocess the images. The CNN expects 224 × 224 images, so we need\n",
            "\n",
            "--- Chunk 10600 ---\n",
            "to resize them. We also need to run the images through Xception’s prepro\n",
            "cess_input() function:\n",
            "\n",
            "--- Chunk 10601 ---\n",
            "def preprocess(image, label):\n",
            "    resized_image = tf.image.resize(image, [224, 224])\n",
            "\n",
            "--- Chunk 10602 ---\n",
            "final_image = keras.applications.xception.preprocess_input(resized_image)\n",
            "    return final_image, label\n",
            "\n",
            "--- Chunk 10603 ---\n",
            "Let’s apply this preprocessing function to all three datasets, shuffle the training set,\n",
            "and add batching and prefetching to all the datasets:\n",
            "\n",
            "--- Chunk 10604 ---\n",
            "batch_size = 32\n",
            "train_set = train_set.shuffle(1000)\n",
            "train_set = train_set.map(preprocess).batch(batch_size).prefetch(1)\n",
            "\n",
            "--- Chunk 10605 ---\n",
            "valid_set = valid_set.map(preprocess).batch(batch_size).prefetch(1)\n",
            "test_set = test_set.map(preprocess).batch(batch_size).prefetch(1)\n",
            "\n",
            "--- Chunk 10606 ---\n",
            "If you want to perform some data augmentation, change the preprocessing function\n",
            "\n",
            "--- Chunk 10607 ---\n",
            "for the training set, adding some random transformations to the training images. For\n",
            "\n",
            "--- Chunk 10608 ---\n",
            "example, use tf.image.random_crop() to randomly crop the images, use\n",
            "tf.image.random_flip_left_right() to randomly flip the images horizontally, and\n",
            "\n",
            "--- Chunk 10609 ---\n",
            "so on (see the “Pretrained Models for Transfer Learning” section of the notebook for\n",
            "an example).\n",
            "\n",
            "--- Chunk 10610 ---\n",
            "The keras.preprocessing.image.ImageDataGenerator class\n",
            "makes it easy to load images from disk and augment them in vari‐\n",
            "\n",
            "--- Chunk 10611 ---\n",
            "ous ways: you can shift each image, rotate it, rescale it, flip it hori‐\n",
            "zontally or vertically, shear it, or apply any transformation function\n",
            "\n",
            "--- Chunk 10612 ---\n",
            "you want to it. This is very convenient for simple projects. How‐\n",
            "ever, building a tf.data pipeline has many advantages: it can read\n",
            "\n",
            "--- Chunk 10613 ---\n",
            "the images efficiently (e.g., in parallel) from any source, not just the\n",
            "local disk; you can manipulate the Dataset as you wish; and if you\n",
            "\n",
            "--- Chunk 10614 ---\n",
            "write a preprocessing function based on tf.image operations, this\n",
            "function can be used both in the tf.data pipeline and in the model\n",
            "\n",
            "--- Chunk 10615 ---\n",
            "you will deploy to production (see Chapter 19).\n",
            "\n",
            "--- Chunk 10616 ---\n",
            "Next let’s load an Xception model, pretrained on ImageNet. We exclude the top of the\n",
            "\n",
            "--- Chunk 10617 ---\n",
            "network by setting include_top=False: this excludes the global average pooling layer\n",
            "\n",
            "--- Chunk 10618 ---\n",
            "and the dense output layer. We then add our own global average pooling layer, based\n",
            "\n",
            "--- Chunk 10619 ---\n",
            "on the output of the base model, followed by a dense output layer with one unit per\n",
            "\n",
            "--- Chunk 10620 ---\n",
            "class, using the softmax activation function. Finally, we create the Keras Model:\n",
            "\n",
            "--- Chunk 10621 ---\n",
            "base_model = keras.applications.xception.Xception(weights=\"imagenet\",\n",
            "                                                  include_top=False)\n",
            "\n",
            "--- Chunk 10622 ---\n",
            "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
            "output = keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
            "\n",
            "--- Chunk 10623 ---\n",
            "model = keras.Model(inputs=base_model.input, outputs=output)\n",
            "\n",
            "--- Chunk 10624 ---\n",
            "482 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 10625 ---\n",
            "As explained in Chapter 11, it’s usually a good idea to freeze the weights of the pre‐\n",
            "trained layers, at least at the beginning of training:\n",
            "\n",
            "--- Chunk 10626 ---\n",
            "for layer in base_model.layers:\n",
            "    layer.trainable = False\n",
            "\n",
            "--- Chunk 10627 ---\n",
            "Since our model uses the base model’s layers directly, rather than\n",
            "the base_model object itself, setting base_model.trainable=False\n",
            "\n",
            "--- Chunk 10628 ---\n",
            "would have no effect.\n",
            "\n",
            "--- Chunk 10629 ---\n",
            "Finally, we can compile the model and start training:\n",
            "optimizer = keras.optimizers.SGD(lr=0.2, momentum=0.9, decay=0.01)\n",
            "\n",
            "--- Chunk 10630 ---\n",
            "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
            "              metrics=[\"accuracy\"])\n",
            "\n",
            "--- Chunk 10631 ---\n",
            "history = model.fit(train_set, epochs=5, validation_data=valid_set)\n",
            "\n",
            "--- Chunk 10632 ---\n",
            "This will be very slow, unless you have a GPU. If you do not, then\n",
            "you should run this chapter’s notebook in Colab, using a GPU run‐\n",
            "\n",
            "--- Chunk 10633 ---\n",
            "time (it’s free!). See the instructions at https://github.com/ageron/\n",
            "handson-ml2.\n",
            "\n",
            "--- Chunk 10634 ---\n",
            "After training the model for a few epochs, its validation accuracy should reach about\n",
            "\n",
            "--- Chunk 10635 ---\n",
            "75–80% and stop making much progress. This means that the top layers are now\n",
            "\n",
            "--- Chunk 10636 ---\n",
            "pretty well trained, so we are ready to unfreeze all the layers (or you could try\n",
            "\n",
            "--- Chunk 10637 ---\n",
            "unfreezing just the top ones) and continue training (don’t forget to compile the\n",
            "\n",
            "--- Chunk 10638 ---\n",
            "model when you freeze or unfreeze layers). This time we use a much lower learning\n",
            "rate to avoid damaging the pretrained weights:\n",
            "\n",
            "--- Chunk 10639 ---\n",
            "for layer in base_model.layers:\n",
            "    layer.trainable = True\n",
            "\n",
            "--- Chunk 10640 ---\n",
            "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.001)\n",
            "model.compile(...)\n",
            "history = model.fit(...)\n",
            "\n",
            "--- Chunk 10641 ---\n",
            "It will take a while, but this model should reach around 95% accuracy on the test set.\n",
            "\n",
            "--- Chunk 10642 ---\n",
            "With that, you can start training amazing image classifiers! But there’s more to com‐\n",
            "\n",
            "--- Chunk 10643 ---\n",
            "puter vision than just classification. For example, what if you also want to know where\n",
            "the flower is in the picture? Let’s look at this now.\n",
            "\n",
            "--- Chunk 10644 ---\n",
            "Classification and Localization\n",
            "Localizing an object in a picture can be expressed as a regression task, as discussed in\n",
            "\n",
            "--- Chunk 10645 ---\n",
            "Chapter 10: to predict a bounding box around the object, a common approach is to\n",
            "\n",
            "--- Chunk 10646 ---\n",
            "Classification and Localization | 483\n",
            "\n",
            "--- Chunk 10647 ---\n",
            "predict the horizontal and vertical coordinates of the object’s center, as well as its\n",
            "\n",
            "--- Chunk 10648 ---\n",
            "height and width. This means we have four numbers to predict. It does not require\n",
            "\n",
            "--- Chunk 10649 ---\n",
            "much change to the model; we just need to add a second dense output layer with four\n",
            "\n",
            "--- Chunk 10650 ---\n",
            "units (typically on top of the global average pooling layer), and it can be trained using\n",
            "the MSE loss:\n",
            "\n",
            "--- Chunk 10651 ---\n",
            "base_model = keras.applications.xception.Xception(weights=\"imagenet\",\n",
            "                                                  include_top=False)\n",
            "\n",
            "--- Chunk 10652 ---\n",
            "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
            "class_output = keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
            "\n",
            "--- Chunk 10653 ---\n",
            "loc_output = keras.layers.Dense(4)(avg)\n",
            "model = keras.Model(inputs=base_model.input,\n",
            "                    outputs=[class_output, loc_output])\n",
            "\n",
            "--- Chunk 10654 ---\n",
            "model.compile(loss=[\"sparse_categorical_crossentropy\", \"mse\"],\n",
            "              loss_weights=[0.8, 0.2], # depends on what you care most about\n",
            "\n",
            "--- Chunk 10655 ---\n",
            "optimizer=optimizer, metrics=[\"accuracy\"])\n",
            "\n",
            "--- Chunk 10656 ---\n",
            "But now we have a problem: the flowers dataset does not have bounding boxes\n",
            "\n",
            "--- Chunk 10657 ---\n",
            "around the flowers. So, we need to add them ourselves. This is often one of the hard‐\n",
            "\n",
            "--- Chunk 10658 ---\n",
            "est and most costly parts of a Machine Learning project: getting the labels. It’s a good\n",
            "\n",
            "--- Chunk 10659 ---\n",
            "idea to spend time looking for the right tools. To annotate images with bounding\n",
            "\n",
            "--- Chunk 10660 ---\n",
            "boxes, you may want to use an open source image labeling tool like VGG Image\n",
            "\n",
            "--- Chunk 10661 ---\n",
            "Annotator, LabelImg, OpenLabeler, or ImgLab, or perhaps a commercial tool like\n",
            "\n",
            "--- Chunk 10662 ---\n",
            "LabelBox or Supervisely. You may also want to consider crowdsourcing platforms\n",
            "\n",
            "--- Chunk 10663 ---\n",
            "such as Amazon Mechanical Turk if you have a very large number of images to anno‐\n",
            "\n",
            "--- Chunk 10664 ---\n",
            "tate. However, it is quite a lot of work to set up a crowdsourcing platform, prepare the\n",
            "\n",
            "--- Chunk 10665 ---\n",
            "form to be sent to the workers, supervise them, and ensure that the quality of the\n",
            "\n",
            "--- Chunk 10666 ---\n",
            "bounding boxes they produce is good, so make sure it is worth the effort. If there are\n",
            "\n",
            "--- Chunk 10667 ---\n",
            "just a few thousand images to label, and you don’t plan to do this frequently, it may be\n",
            "\n",
            "--- Chunk 10668 ---\n",
            "preferable to do it yourself. Adriana Kovashka et al. wrote a very practical paper24\n",
            "\n",
            "--- Chunk 10669 ---\n",
            "about crowdsourcing in computer vision. I recommend you check it out, even if you\n",
            "do not plan to use crowdsourcing.\n",
            "\n",
            "--- Chunk 10670 ---\n",
            "Let’s suppose you’ve obtained the bounding boxes for every image in the flowers data‐\n",
            "\n",
            "--- Chunk 10671 ---\n",
            "set (for now we will assume there is a single bounding box per image). You then need\n",
            "\n",
            "--- Chunk 10672 ---\n",
            "to create a dataset whose items will be batches of preprocessed images along with\n",
            "\n",
            "--- Chunk 10673 ---\n",
            "their class labels and their bounding boxes. Each item should be a tuple of the form\n",
            "\n",
            "--- Chunk 10674 ---\n",
            "(images, (class_labels, bounding_boxes)). Then you are ready to train your\n",
            "model!\n",
            "\n",
            "--- Chunk 10675 ---\n",
            "24 Adriana Kovashka et al., “Crowdsourcing in Computer Vision,” Foundations and Trends in Computer Graphics\n",
            "and Vision 10, no. 3 (2014): 177–243.\n",
            "\n",
            "--- Chunk 10676 ---\n",
            "484 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 10677 ---\n",
            "The bounding boxes should be normalized so that the horizontal\n",
            "and vertical coordinates, as well as the height and width, all range\n",
            "\n",
            "--- Chunk 10678 ---\n",
            "from 0 to 1. Also, it is common to predict the square root of the\n",
            "height and width rather than the height and width directly: this\n",
            "\n",
            "--- Chunk 10679 ---\n",
            "way, a 10-pixel error for a large bounding box will not be penalized\n",
            "as much as a 10-pixel error for a small bounding box.\n",
            "\n",
            "--- Chunk 10680 ---\n",
            "The MSE often works fairly well as a cost function to train the model, but it is not a\n",
            "\n",
            "--- Chunk 10681 ---\n",
            "great metric to evaluate how well the model can predict bounding boxes. The most\n",
            "\n",
            "--- Chunk 10682 ---\n",
            "common metric for this is the Intersection over Union (IoU): the area of overlap\n",
            "\n",
            "--- Chunk 10683 ---\n",
            "between the predicted bounding box and the target bounding box, divided by the\n",
            "\n",
            "--- Chunk 10684 ---\n",
            "area of their union (see Figure 14-23). In tf.keras, it is implemented by the\n",
            "tf.keras.metrics.MeanIoU class.\n",
            "\n",
            "--- Chunk 10685 ---\n",
            "Figure 14-23. Intersection over Union (IoU) metric for bounding boxes\n",
            "\n",
            "--- Chunk 10686 ---\n",
            "Classifying and localizing a single object is nice, but what if the images contain multi‐\n",
            "ple objects (as is often the case in the flowers dataset)?\n",
            "\n",
            "--- Chunk 10687 ---\n",
            "Object Detection\n",
            "The task of classifying and localizing multiple objects in an image is called object\n",
            "\n",
            "--- Chunk 10688 ---\n",
            "detection. Until a few years ago, a common approach was to take a CNN that was\n",
            "\n",
            "--- Chunk 10689 ---\n",
            "trained to classify and locate a single object, then slide it across the image, as shown\n",
            "\n",
            "--- Chunk 10690 ---\n",
            "in Figure 14-24. In this example, the image was chopped into a 6 × 8 grid, and we\n",
            "\n",
            "--- Chunk 10691 ---\n",
            "show a CNN (the thick black rectangle) sliding across all 3 × 3 regions. When the\n",
            "\n",
            "--- Chunk 10692 ---\n",
            "CNN was looking at the top left of the image, it detected part of the leftmost rose, and\n",
            "\n",
            "--- Chunk 10693 ---\n",
            "then it detected that same rose again when it was first shifted one step to the right. At\n",
            "\n",
            "--- Chunk 10694 ---\n",
            "Object Detection | 485\n",
            "\n",
            "--- Chunk 10695 ---\n",
            "the next step, it started detecting part of the topmost rose, and then it detected it\n",
            "\n",
            "--- Chunk 10696 ---\n",
            "again once it was shifted one more step to the right. You would then continue to slide\n",
            "\n",
            "--- Chunk 10697 ---\n",
            "the CNN through the whole image, looking at all 3 × 3 regions. Moreover, since\n",
            "\n",
            "--- Chunk 10698 ---\n",
            "objects can have varying sizes, you would also slide the CNN across regions of differ‐\n",
            "\n",
            "--- Chunk 10699 ---\n",
            "ent sizes. For example, once you are done with the 3 × 3 regions, you might want to\n",
            "slide the CNN across all 4 × 4 regions as well.\n",
            "\n",
            "--- Chunk 10700 ---\n",
            "Figure 14-24. Detecting multiple objects by sliding a CNN across the image\n",
            "\n",
            "--- Chunk 10701 ---\n",
            "This technique is fairly straightforward, but as you can see it will detect the same\n",
            "\n",
            "--- Chunk 10702 ---\n",
            "object multiple times, at slightly different positions. Some post-processing will then\n",
            "\n",
            "--- Chunk 10703 ---\n",
            "be needed to get rid of all the unnecessary bounding boxes. A common approach for\n",
            "this is called non-max suppression. Here’s how you do it:\n",
            "\n",
            "--- Chunk 10704 ---\n",
            "1. First, you need to add an extra objectness output to your CNN, to estimate the\n",
            "\n",
            "--- Chunk 10705 ---\n",
            "probability that a flower is indeed present in the image (alternatively, you could\n",
            "\n",
            "--- Chunk 10706 ---\n",
            "add a “no-flower” class, but this usually does not work as well). It must use the\n",
            "\n",
            "--- Chunk 10707 ---\n",
            "sigmoid activation function, and you can train it using binary cross-entropy loss.\n",
            "\n",
            "--- Chunk 10708 ---\n",
            "Then get rid of all the bounding boxes for which the objectness score is below\n",
            "\n",
            "--- Chunk 10709 ---\n",
            "some threshold: this will drop all the bounding boxes that don’t actually contain a\n",
            "flower.\n",
            "\n",
            "--- Chunk 10710 ---\n",
            "2. Find the bounding box with the highest objectness score, and get rid of all the\n",
            "\n",
            "--- Chunk 10711 ---\n",
            "other bounding boxes that overlap a lot with it (e.g., with an IoU greater than\n",
            "\n",
            "--- Chunk 10712 ---\n",
            "60%). For example, in Figure 14-24, the bounding box with the max objectness\n",
            "\n",
            "--- Chunk 10713 ---\n",
            "score is the thick bounding box over the topmost rose (the objectness score is\n",
            "\n",
            "--- Chunk 10714 ---\n",
            "represented by the thickness of the bounding boxes). The other bounding box\n",
            "\n",
            "--- Chunk 10715 ---\n",
            "486 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 10716 ---\n",
            "over that same rose overlaps a lot with the max bounding box, so we will get rid\n",
            "of it.\n",
            "\n",
            "--- Chunk 10717 ---\n",
            "3. Repeat step two until there are no more bounding boxes to get rid of.\n",
            "\n",
            "--- Chunk 10718 ---\n",
            "This simple approach to object detection works pretty well, but it requires running\n",
            "\n",
            "--- Chunk 10719 ---\n",
            "the CNN many times, so it is quite slow. Fortunately, there is a much faster way to\n",
            "\n",
            "--- Chunk 10720 ---\n",
            "slide a CNN across an image: using a fully convolutional network (FCN).\n",
            "\n",
            "--- Chunk 10721 ---\n",
            "Fully Convolutional Networks\n",
            "The idea of FCNs was first introduced in a 2015 paper25 by Jonathan Long et al., for\n",
            "\n",
            "--- Chunk 10722 ---\n",
            "semantic segmentation (the task of classifying every pixel in an image according to\n",
            "\n",
            "--- Chunk 10723 ---\n",
            "the class of the object it belongs to). The authors pointed out that you could replace\n",
            "\n",
            "--- Chunk 10724 ---\n",
            "the dense layers at the top of a CNN by convolutional layers. To understand this, let’s\n",
            "\n",
            "--- Chunk 10725 ---\n",
            "look at an example: suppose a dense layer with 200 neurons sits on top of a convolu‐\n",
            "\n",
            "--- Chunk 10726 ---\n",
            "tional layer that outputs 100 feature maps, each of size 7 × 7 (this is the feature map\n",
            "\n",
            "--- Chunk 10727 ---\n",
            "size, not the kernel size). Each neuron will compute a weighted sum of all 100 × 7 × 7\n",
            "\n",
            "--- Chunk 10728 ---\n",
            "activations from the convolutional layer (plus a bias term). Now let’s see what hap‐\n",
            "\n",
            "--- Chunk 10729 ---\n",
            "pens if we replace the dense layer with a convolutional layer using 200 filters, each of\n",
            "\n",
            "--- Chunk 10730 ---\n",
            "size 7 × 7, and with \"valid\" padding. This layer will output 200 feature maps, each 1\n",
            "\n",
            "--- Chunk 10731 ---\n",
            "× 1 (since the kernel is exactly the size of the input feature maps and we are using\n",
            "\n",
            "--- Chunk 10732 ---\n",
            "\"valid\" padding). In other words, it will output 200 numbers, just like the dense\n",
            "\n",
            "--- Chunk 10733 ---\n",
            "layer did; and if you look closely at the computations performed by a convolutional\n",
            "\n",
            "--- Chunk 10734 ---\n",
            "layer, you will notice that these numbers will be precisely the same as those the dense\n",
            "\n",
            "--- Chunk 10735 ---\n",
            "layer produced. The only difference is that the dense layer’s output was a tensor of\n",
            "\n",
            "--- Chunk 10736 ---\n",
            "shape [batch size, 200], while the convolutional layer will output a tensor of shape\n",
            "[batch size, 1, 1, 200].\n",
            "\n",
            "--- Chunk 10737 ---\n",
            "To convert a dense layer to a convolutional layer, the number of fil‐\n",
            "ters in the convolutional layer must be equal to the number of units\n",
            "\n",
            "--- Chunk 10738 ---\n",
            "in the dense layer, the filter size must be equal to the size of the\n",
            "input feature maps, and you must use \"valid\" padding. The stride\n",
            "\n",
            "--- Chunk 10739 ---\n",
            "may be set to 1 or more, as we will see shortly.\n",
            "\n",
            "--- Chunk 10740 ---\n",
            "Why is this important? Well, while a dense layer expects a specific input size (since it\n",
            "\n",
            "--- Chunk 10741 ---\n",
            "has one weight per input feature), a convolutional layer will happily process images of\n",
            "\n",
            "--- Chunk 10742 ---\n",
            "any size26 (however, it does expect its inputs to have a specific number of channels,\n",
            "\n",
            "--- Chunk 10743 ---\n",
            "25 Jonathan Long et al., “Fully Convolutional Networks for Semantic Segmentation,” Proceedings of the IEEE\n",
            "\n",
            "--- Chunk 10744 ---\n",
            "Conference on Computer Vision and Pattern Recognition (2015): 3431–3440.\n",
            "\n",
            "--- Chunk 10745 ---\n",
            "26 There is one small exception: a convolutional layer using \"valid\" padding will complain if the input size is\n",
            "smaller than the kernel size.\n",
            "\n",
            "--- Chunk 10746 ---\n",
            "Object Detection | 487\n",
            "\n",
            "--- Chunk 10747 ---\n",
            "since each kernel contains a different set of weights for each input channel). Since an\n",
            "\n",
            "--- Chunk 10748 ---\n",
            "FCN contains only convolutional layers (and pooling layers, which have the same\n",
            "property), it can be trained and executed on images of any size!\n",
            "\n",
            "--- Chunk 10749 ---\n",
            "For example, suppose we’d already trained a CNN for flower classification and locali‐\n",
            "\n",
            "--- Chunk 10750 ---\n",
            "zation. It was trained on 224 × 224 images, and it outputs 10 numbers: outputs 0 to 4\n",
            "\n",
            "--- Chunk 10751 ---\n",
            "are sent through the softmax activation function, and this gives the class probabilities\n",
            "\n",
            "--- Chunk 10752 ---\n",
            "(one per class); output 5 is sent through the logistic activation function, and this gives\n",
            "\n",
            "--- Chunk 10753 ---\n",
            "the objectness score; outputs 6 to 9 do not use any activation function, and they rep‐\n",
            "\n",
            "--- Chunk 10754 ---\n",
            "resent the bounding box’s center coordinates, as well as its height and width. We can\n",
            "\n",
            "--- Chunk 10755 ---\n",
            "now convert its dense layers to convolutional layers. In fact, we don’t even need to\n",
            "\n",
            "--- Chunk 10756 ---\n",
            "retrain it; we can just copy the weights from the dense layers to the convolutional lay‐\n",
            "\n",
            "--- Chunk 10757 ---\n",
            "ers! Alternatively, we could have converted the CNN into an FCN before training.\n",
            "\n",
            "--- Chunk 10758 ---\n",
            "Now suppose the last convolutional layer before the output layer (also called the bot‐\n",
            "\n",
            "--- Chunk 10759 ---\n",
            "tleneck layer) outputs 7 × 7 feature maps when the network is fed a 224 × 224 image\n",
            "\n",
            "--- Chunk 10760 ---\n",
            "(see the left side of Figure 14-25). If we feed the FCN a 448 × 448 image (see the right\n",
            "\n",
            "--- Chunk 10761 ---\n",
            "side of Figure 14-25), the bottleneck layer will now output 14 × 14 feature maps.27\n",
            "\n",
            "--- Chunk 10762 ---\n",
            "Since the dense output layer was replaced by a convolutional layer using 10 filters of\n",
            "\n",
            "--- Chunk 10763 ---\n",
            "size 7 × 7, with \"valid\" padding and stride 1, the output will be composed of 10 fea‐\n",
            "\n",
            "--- Chunk 10764 ---\n",
            "tures maps, each of size 8 × 8 (since 14 – 7 + 1 = 8). In other words, the FCN will\n",
            "\n",
            "--- Chunk 10765 ---\n",
            "process the whole image only once, and it will output an 8 × 8 grid where each cell\n",
            "\n",
            "--- Chunk 10766 ---\n",
            "contains 10 numbers (5 class probabilities, 1 objectness score, and 4 bounding box\n",
            "\n",
            "--- Chunk 10767 ---\n",
            "coordinates). It’s exactly like taking the original CNN and sliding it across the image\n",
            "\n",
            "--- Chunk 10768 ---\n",
            "using 8 steps per row and 8 steps per column. To visualize this, imagine chopping the\n",
            "\n",
            "--- Chunk 10769 ---\n",
            "original image into a 14 × 14 grid, then sliding a 7 × 7 window across this grid; there\n",
            "\n",
            "--- Chunk 10770 ---\n",
            "will be 8 × 8 = 64 possible locations for the window, hence 8 × 8 predictions. How‐\n",
            "\n",
            "--- Chunk 10771 ---\n",
            "ever, the FCN approach is much more efficient, since the network only looks at the\n",
            "\n",
            "--- Chunk 10772 ---\n",
            "image once. In fact, You Only Look Once (YOLO) is the name of a very popular object\n",
            "detection architecture, which we’ll look at next.\n",
            "\n",
            "--- Chunk 10773 ---\n",
            "27 This assumes we used only \"same\" padding in the network: indeed, \"valid\" padding would reduce the size of\n",
            "\n",
            "--- Chunk 10774 ---\n",
            "the feature maps. Moreover, 448 can be neatly divided by 2 several times until we reach 7, without any round‐\n",
            "\n",
            "--- Chunk 10775 ---\n",
            "ing error. If any layer uses a different stride than 1 or 2, then there may be some rounding error, so again the\n",
            "\n",
            "--- Chunk 10776 ---\n",
            "feature maps may end up being smaller.\n",
            "\n",
            "--- Chunk 10777 ---\n",
            "488 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 10778 ---\n",
            "Figure 14-25. The same fully convolutional network processing a small image (left) and a\n",
            "large one (right)\n",
            "\n",
            "--- Chunk 10779 ---\n",
            "You Only Look Once (YOLO)\n",
            "YOLO is an extremely fast and accurate object detection architecture proposed by\n",
            "\n",
            "--- Chunk 10780 ---\n",
            "Joseph Redmon et al. in a 2015 paper,28 and subsequently improved in 201629\n",
            "\n",
            "--- Chunk 10781 ---\n",
            "(YOLOv2) and in 201830 (YOLOv3). It is so fast that it can run in real time on a video,\n",
            "as seen in Redmon’s demo.\n",
            "\n",
            "--- Chunk 10782 ---\n",
            "YOLOv3’s architecture is quite similar to the one we just discussed, but with a few\n",
            "important differences:\n",
            "\n",
            "--- Chunk 10783 ---\n",
            "28 Joseph Redmon et al., “You Only Look Once: Unified, Real-Time Object Detection,” Proceedings of the IEEE\n",
            "\n",
            "--- Chunk 10784 ---\n",
            "Conference on Computer Vision and Pattern Recognition (2016): 779–788.\n",
            "\n",
            "--- Chunk 10785 ---\n",
            "29 Joseph Redmon and Ali Farhadi, “YOLO9000: Better, Faster, Stronger,” Proceedings of the IEEE Conference on\n",
            "\n",
            "--- Chunk 10786 ---\n",
            "Computer Vision and Pattern Recognition (2017): 6517–6525.\n",
            "\n",
            "--- Chunk 10787 ---\n",
            "30 Joseph Redmon and Ali Farhadi, “YOLOv3: An Incremental Improvement,” arXiv preprint arXiv:1804.02767\n",
            "(2018).\n",
            "\n",
            "Object Detection | 489\n",
            "\n",
            "--- Chunk 10788 ---\n",
            "• It outputs five bounding boxes for each grid cell (instead of just one), and each\n",
            "\n",
            "--- Chunk 10789 ---\n",
            "bounding box comes with an objectness score. It also outputs 20 class probabili‐\n",
            "\n",
            "--- Chunk 10790 ---\n",
            "ties per grid cell, as it was trained on the PASCAL VOC dataset, which contains\n",
            "\n",
            "--- Chunk 10791 ---\n",
            "20 classes. That’s a total of 45 numbers per grid cell: 5 bounding boxes, each with\n",
            "\n",
            "--- Chunk 10792 ---\n",
            "4 coordinates, plus 5 objectness scores, plus 20 class probabilities.\n",
            "\n",
            "--- Chunk 10793 ---\n",
            "• Instead of predicting the absolute coordinates of the bounding box centers,\n",
            "\n",
            "--- Chunk 10794 ---\n",
            "YOLOv3 predicts an offset relative to the coordinates of the grid cell, where (0, 0)\n",
            "\n",
            "--- Chunk 10795 ---\n",
            "means the top left of that cell and (1, 1) means the bottom right. For each grid\n",
            "\n",
            "--- Chunk 10796 ---\n",
            "cell, YOLOv3 is trained to predict only bounding boxes whose center lies in that\n",
            "\n",
            "--- Chunk 10797 ---\n",
            "cell (but the bounding box itself generally extends well beyond the grid cell).\n",
            "\n",
            "--- Chunk 10798 ---\n",
            "YOLOv3 applies the logistic activation function to the bounding box coordinates\n",
            "to ensure they remain in the 0 to 1 range.\n",
            "\n",
            "--- Chunk 10799 ---\n",
            "• Before training the neural net, YOLOv3 finds five representative bounding box\n",
            "\n",
            "--- Chunk 10800 ---\n",
            "dimensions, called anchor boxes (or bounding box priors). It does this by applying\n",
            "\n",
            "--- Chunk 10801 ---\n",
            "the K-Means algorithm (see Chapter 9) to the height and width of the training set\n",
            "\n",
            "--- Chunk 10802 ---\n",
            "bounding boxes. For example, if the training images contain many pedestrians,\n",
            "\n",
            "--- Chunk 10803 ---\n",
            "then one of the anchor boxes will likely have the dimensions of a typical pedes‐\n",
            "\n",
            "--- Chunk 10804 ---\n",
            "trian. Then when the neural net predicts five bounding boxes per grid cell, it\n",
            "\n",
            "--- Chunk 10805 ---\n",
            "actually predicts how much to rescale each of the anchor boxes. For example,\n",
            "\n",
            "--- Chunk 10806 ---\n",
            "suppose one anchor box is 100 pixels tall and 50 pixels wide, and the network\n",
            "\n",
            "--- Chunk 10807 ---\n",
            "predicts, say, a vertical rescaling factor of 1.5 and a horizontal rescaling of 0.9 (for\n",
            "\n",
            "--- Chunk 10808 ---\n",
            "one of the grid cells). This will result in a predicted bounding box of size 150 × 45\n",
            "\n",
            "--- Chunk 10809 ---\n",
            "pixels. To be more precise, for each grid cell and each anchor box, the network\n",
            "\n",
            "--- Chunk 10810 ---\n",
            "predicts the log of the vertical and horizontal rescaling factors. Having these pri‐\n",
            "\n",
            "--- Chunk 10811 ---\n",
            "ors makes the network more likely to predict bounding boxes of the appropriate\n",
            "\n",
            "--- Chunk 10812 ---\n",
            "dimensions, and it also speeds up training because it will more quickly learn what\n",
            "reasonable bounding boxes look like.\n",
            "\n",
            "--- Chunk 10813 ---\n",
            "• The network is trained using images of different scales: every few batches during\n",
            "\n",
            "--- Chunk 10814 ---\n",
            "training, the network randomly chooses a new image dimension (from 330 × 330\n",
            "\n",
            "--- Chunk 10815 ---\n",
            "to 608 × 608 pixels). This allows the network to learn to detect objects at different\n",
            "\n",
            "--- Chunk 10816 ---\n",
            "scales. Moreover, it makes it possible to use YOLOv3 at different scales: the\n",
            "\n",
            "--- Chunk 10817 ---\n",
            "smaller scale will be less accurate but faster than the larger scale, so you can\n",
            "choose the right trade-off for your use case.\n",
            "\n",
            "--- Chunk 10818 ---\n",
            "There are a few more innovations you might be interested in, such as the use of skip\n",
            "\n",
            "--- Chunk 10819 ---\n",
            "connections to recover some of the spatial resolution that is lost in the CNN (we will\n",
            "\n",
            "--- Chunk 10820 ---\n",
            "discuss this shortly, when we look at semantic segmentation). In the 2016 paper, the\n",
            "\n",
            "--- Chunk 10821 ---\n",
            "authors introduce the YOLO9000 model that uses hierarchical classification: the\n",
            "\n",
            "--- Chunk 10822 ---\n",
            "model predicts a probability for each node in a visual hierarchy called WordTree. This\n",
            "\n",
            "--- Chunk 10823 ---\n",
            "makes it possible for the network to predict with high confidence that an image rep‐\n",
            "\n",
            "--- Chunk 10824 ---\n",
            "resents, say, a dog, even though it is unsure what specific type of dog. I encourage you\n",
            "\n",
            "--- Chunk 10825 ---\n",
            "490 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 10826 ---\n",
            "to go ahead and read all three papers: they are quite pleasant to read, and they pro‐\n",
            "\n",
            "--- Chunk 10827 ---\n",
            "vide excellent examples of how Deep Learning systems can be incrementally\n",
            "improved.\n",
            "\n",
            "--- Chunk 10828 ---\n",
            "Mean Average Precision (mAP)\n",
            "A very common metric used in object detection tasks is the mean Average Precision\n",
            "\n",
            "--- Chunk 10829 ---\n",
            "(mAP). “Mean Average” sounds a bit redundant, doesn’t it? To understand this met‐\n",
            "\n",
            "--- Chunk 10830 ---\n",
            "ric, let’s go back to two classification metrics we discussed in Chapter 3: precision and\n",
            "\n",
            "--- Chunk 10831 ---\n",
            "recall. Remember the trade-off: the higher the recall, the lower the precision. You can\n",
            "\n",
            "--- Chunk 10832 ---\n",
            "visualize this in a precision/recall curve (see Figure 3-5). To summarize this curve\n",
            "\n",
            "--- Chunk 10833 ---\n",
            "into a single number, we could compute its area under the curve (AUC). But note that\n",
            "\n",
            "--- Chunk 10834 ---\n",
            "the precision/recall curve may contain a few sections where precision actually goes up\n",
            "\n",
            "--- Chunk 10835 ---\n",
            "when recall increases, especially at low recall values (you can see this at the top left of\n",
            "\n",
            "--- Chunk 10836 ---\n",
            "Figure 3-5). This is one of the motivations for the mAP metric.\n",
            "Suppose the classifier has 90% precision at 10% recall, but 96% precision at 20%\n",
            "\n",
            "--- Chunk 10837 ---\n",
            "recall. There’s really no trade-off here: it simply makes more sense to use the classifier\n",
            "\n",
            "--- Chunk 10838 ---\n",
            "at 20% recall rather than at 10% recall, as you will get both higher recall and higher\n",
            "\n",
            "--- Chunk 10839 ---\n",
            "precision. So instead of looking at the precision at 10% recall, we should really be\n",
            "\n",
            "--- Chunk 10840 ---\n",
            "looking at the maximum precision that the classifier can offer with at least 10% recall.\n",
            "\n",
            "--- Chunk 10841 ---\n",
            "It would be 96%, not 90%. Therefore, one way to get a fair idea of the model’s perfor‐\n",
            "\n",
            "--- Chunk 10842 ---\n",
            "mance is to compute the maximum precision you can get with at least 0% recall, then\n",
            "\n",
            "--- Chunk 10843 ---\n",
            "10% recall, 20%, and so on up to 100%, and then calculate the mean of these maxi‐\n",
            "\n",
            "--- Chunk 10844 ---\n",
            "mum precisions. This is called the Average Precision (AP) metric. Now when there are\n",
            "\n",
            "--- Chunk 10845 ---\n",
            "more than two classes, we can compute the AP for each class, and then compute the\n",
            "mean AP (mAP). That’s it!\n",
            "\n",
            "--- Chunk 10846 ---\n",
            "In an object detection system, there is an additional level of complexity: what if the\n",
            "\n",
            "--- Chunk 10847 ---\n",
            "system detected the correct class, but at the wrong location (i.e., the bounding box is\n",
            "\n",
            "--- Chunk 10848 ---\n",
            "completely off)? Surely we should not count this as a positive prediction. One\n",
            "\n",
            "--- Chunk 10849 ---\n",
            "approach is to define an IOU threshold: for example, we may consider that a predic‐\n",
            "\n",
            "--- Chunk 10850 ---\n",
            "tion is correct only if the IOU is greater than, say, 0.5, and the predicted class is cor‐\n",
            "\n",
            "--- Chunk 10851 ---\n",
            "rect. The corresponding mAP is generally noted mAP@0.5 (or mAP@50%, or\n",
            "sometimes just AP50). In some competitions (such as the PASCAL VOC challenge),\n",
            "\n",
            "--- Chunk 10852 ---\n",
            "this is what is done. In others (such as the COCO competition), the mAP is computed\n",
            "\n",
            "--- Chunk 10853 ---\n",
            "for different IOU thresholds (0.50, 0.55, 0.60, …, 0.95), and the final metric is the\n",
            "\n",
            "--- Chunk 10854 ---\n",
            "mean of all these mAPs (noted AP@[.50:.95] or AP@[.50:0.05:.95]). Yes, that’s a mean\n",
            "mean average.\n",
            "\n",
            "--- Chunk 10855 ---\n",
            "Several YOLO implementations built using TensorFlow are available on GitHub. In\n",
            "\n",
            "--- Chunk 10856 ---\n",
            "particular, check out Zihao Zang’s TensorFlow 2 implementation. Other object detec‐\n",
            "\n",
            "--- Chunk 10857 ---\n",
            "tion models are available in the TensorFlow Models project, many with pretrained\n",
            "\n",
            "--- Chunk 10858 ---\n",
            "Object Detection | 491\n",
            "\n",
            "--- Chunk 10859 ---\n",
            "weights; and some have even been ported to TF Hub, such as SSD31 and Faster-\n",
            "\n",
            "--- Chunk 10860 ---\n",
            "RCNN,32 which are both quite popular. SSD is also a “single shot” detection model,\n",
            "\n",
            "--- Chunk 10861 ---\n",
            "similar to YOLO. Faster R-CNN is more complex: the image first goes through a\n",
            "\n",
            "--- Chunk 10862 ---\n",
            "CNN, then the output is passed to a Region Proposal Network (RPN) that proposes\n",
            "\n",
            "--- Chunk 10863 ---\n",
            "bounding boxes that are most likely to contain an object, and a classifier is run for\n",
            "each bounding box, based on the cropped output of the CNN.\n",
            "\n",
            "--- Chunk 10864 ---\n",
            "The choice of detection system depends on many factors: speed, accuracy, available\n",
            "\n",
            "--- Chunk 10865 ---\n",
            "pretrained models, training time, complexity, etc. The papers contain tables of met‐\n",
            "\n",
            "--- Chunk 10866 ---\n",
            "rics, but there is quite a lot of variability in the testing environments, and the technol‐\n",
            "\n",
            "--- Chunk 10867 ---\n",
            "ogies evolve so fast that it is difficult to make a fair comparison that will be useful for\n",
            "most people and remain valid for more than a few months.\n",
            "\n",
            "--- Chunk 10868 ---\n",
            "So, we can locate objects by drawing bounding boxes around them. Great! But per‐\n",
            "\n",
            "--- Chunk 10869 ---\n",
            "haps you want to be a bit more precise. Let’s see how to go down to the pixel level.\n",
            "\n",
            "--- Chunk 10870 ---\n",
            "Semantic Segmentation\n",
            "In semantic segmentation, each pixel is classified according to the class of the object it\n",
            "\n",
            "--- Chunk 10871 ---\n",
            "belongs to (e.g., road, car, pedestrian, building, etc.), as shown in Figure 14-26. Note\n",
            "\n",
            "--- Chunk 10872 ---\n",
            "that different objects of the same class are not distinguished. For example, all the bicy‐\n",
            "\n",
            "--- Chunk 10873 ---\n",
            "cles on the right side of the segmented image end up as one big lump of pixels. The\n",
            "\n",
            "--- Chunk 10874 ---\n",
            "main difficulty in this task is that when images go through a regular CNN, they grad‐\n",
            "\n",
            "--- Chunk 10875 ---\n",
            "ually lose their spatial resolution (due to the layers with strides greater than 1); so, a\n",
            "\n",
            "--- Chunk 10876 ---\n",
            "regular CNN may end up knowing that there’s a person somewhere in the bottom left\n",
            "of the image, but it will not be much more precise than that.\n",
            "\n",
            "--- Chunk 10877 ---\n",
            "Just like for object detection, there are many different approaches to tackle this prob‐\n",
            "\n",
            "--- Chunk 10878 ---\n",
            "lem, some quite complex. However, a fairly simple solution was proposed in the 2015\n",
            "\n",
            "--- Chunk 10879 ---\n",
            "paper by Jonathan Long et al. we discussed earlier. The authors start by taking a pre‐\n",
            "\n",
            "--- Chunk 10880 ---\n",
            "trained CNN and turning it into an FCN. The CNN applies an overall stride of 32 to\n",
            "\n",
            "--- Chunk 10881 ---\n",
            "the input image (i.e., if you add up all the strides greater than 1), meaning the last\n",
            "\n",
            "--- Chunk 10882 ---\n",
            "layer outputs feature maps that are 32 times smaller than the input image. This is\n",
            "\n",
            "--- Chunk 10883 ---\n",
            "clearly too coarse, so they add a single upsampling layer that multiplies the resolution\n",
            "by 32.\n",
            "\n",
            "--- Chunk 10884 ---\n",
            "31 Wei Liu et al., “SSD: Single Shot Multibox Detector,” Proceedings of the 14th European Conference on Computer\n",
            "Vision 1 (2016): 21–37.\n",
            "\n",
            "--- Chunk 10885 ---\n",
            "32 Shaoqing Ren et al., “Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks,”\n",
            "\n",
            "--- Chunk 10886 ---\n",
            "Proceedings of the 28th International Conference on Neural Information Processing Systems 1 (2015): 91–99.\n",
            "\n",
            "--- Chunk 10887 ---\n",
            "492 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "\n",
            "\n",
            "Figure 14-26. Semantic segmentation\n",
            "\n",
            "--- Chunk 10888 ---\n",
            "There are several solutions available for upsampling (increasing the size of an image),\n",
            "\n",
            "--- Chunk 10889 ---\n",
            "such as bilinear interpolation, but that only works reasonably well up to ×4 or ×8.\n",
            "\n",
            "--- Chunk 10890 ---\n",
            "Instead, they use a transposed convolutional layer:33 it is equivalent to first stretching\n",
            "\n",
            "--- Chunk 10891 ---\n",
            "the image by inserting empty rows and columns (full of zeros), then performing a\n",
            "\n",
            "--- Chunk 10892 ---\n",
            "regular convolution (see Figure 14-27). Alternatively, some people prefer to think of\n",
            "\n",
            "--- Chunk 10893 ---\n",
            "it as a regular convolutional layer that uses fractional strides (e.g., 1/2 in\n",
            "\n",
            "--- Chunk 10894 ---\n",
            "Figure 14-27). The transposed convolutional layer can be initialized to perform\n",
            "\n",
            "--- Chunk 10895 ---\n",
            "something close to linear interpolation, but since it is a trainable layer, it will learn to\n",
            "\n",
            "--- Chunk 10896 ---\n",
            "do better during training. In tf.keras, you can use the Conv2DTranspose layer.\n",
            "\n",
            "--- Chunk 10897 ---\n",
            "Figure 14-27. Upsampling using a transposed convolutional layer\n",
            "\n",
            "--- Chunk 10898 ---\n",
            "33 This type of layer is sometimes referred to as a deconvolution layer, but it does not perform what mathemati‐\n",
            "\n",
            "--- Chunk 10899 ---\n",
            "cians call a deconvolution, so this name should be avoided.\n",
            "\n",
            "--- Chunk 10900 ---\n",
            "Semantic Segmentation | 493\n",
            "\n",
            "--- Chunk 10901 ---\n",
            "In a transposed convolutional layer, the stride defines how much\n",
            "the input will be stretched, not the size of the filter steps, so the\n",
            "\n",
            "--- Chunk 10902 ---\n",
            "larger the stride, the larger the output (unlike for convolutional lay‐\n",
            "ers or pooling layers).\n",
            "\n",
            "--- Chunk 10903 ---\n",
            "TensorFlow Convolution Operations\n",
            "TensorFlow also offers a few other kinds of convolutional layers:\n",
            "keras.layers.Conv1D\n",
            "\n",
            "--- Chunk 10904 ---\n",
            "Creates a convolutional layer for 1D inputs, such as time series or text (sequences\n",
            "of letters or words), as we will see in Chapter 15.\n",
            "\n",
            "--- Chunk 10905 ---\n",
            "keras.layers.Conv3D\n",
            "Creates a convolutional layer for 3D inputs, such as 3D PET scans.\n",
            "\n",
            "--- Chunk 10906 ---\n",
            "dilation_rate\n",
            "Setting the dilation_rate hyperparameter of any convolutional layer to a value\n",
            "\n",
            "--- Chunk 10907 ---\n",
            "of 2 or more creates an à-trous convolutional layer (“à trous” is French for “with\n",
            "\n",
            "--- Chunk 10908 ---\n",
            "holes”). This is equivalent to using a regular convolutional layer with a filter dila‐\n",
            "\n",
            "--- Chunk 10909 ---\n",
            "ted by inserting rows and columns of zeros (i.e., holes). For example, a 1 × 3 filter\n",
            "\n",
            "--- Chunk 10910 ---\n",
            "equal to [[1,2,3]] may be dilated with a dilation rate of 4, resulting in a dilated\n",
            "\n",
            "--- Chunk 10911 ---\n",
            "filter of [[1, 0, 0, 0, 2, 0, 0, 0, 3]]. This lets the convolutional layer have\n",
            "\n",
            "--- Chunk 10912 ---\n",
            "a larger receptive field at no computational price and using no extra parameters.\n",
            "\n",
            "--- Chunk 10913 ---\n",
            "tf.nn.depthwise_conv2d()\n",
            "Can be used to create a depthwise convolutional layer (but you need to create the\n",
            "\n",
            "--- Chunk 10914 ---\n",
            "variables yourself). It applies every filter to every individual input channel inde‐\n",
            "\n",
            "--- Chunk 10915 ---\n",
            "pendently. Thus, if there are fn filters and fn′ input channels, then this will output\n",
            "fn × fn′ feature maps.\n",
            "\n",
            "--- Chunk 10916 ---\n",
            "This solution is OK, but still too imprecise. To do better, the authors added skip con‐\n",
            "\n",
            "--- Chunk 10917 ---\n",
            "nections from lower layers: for example, they upsampled the output image by a factor\n",
            "\n",
            "--- Chunk 10918 ---\n",
            "of 2 (instead of 32), and they added the output of a lower layer that had this double\n",
            "\n",
            "--- Chunk 10919 ---\n",
            "resolution. Then they upsampled the result by a factor of 16, leading to a total upsam‐\n",
            "\n",
            "--- Chunk 10920 ---\n",
            "pling factor of 32 (see Figure 14-28). This recovered some of the spatial resolution\n",
            "\n",
            "--- Chunk 10921 ---\n",
            "that was lost in earlier pooling layers. In their best architecture, they used a second\n",
            "\n",
            "--- Chunk 10922 ---\n",
            "similar skip connection to recover even finer details from an even lower layer. In\n",
            "\n",
            "--- Chunk 10923 ---\n",
            "short, the output of the original CNN goes through the following extra steps: upscale\n",
            "\n",
            "--- Chunk 10924 ---\n",
            "×2, add the output of a lower layer (of the appropriate scale), upscale ×2, add the out‐\n",
            "\n",
            "--- Chunk 10925 ---\n",
            "put of an even lower layer, and finally upscale ×8. It is even possible to scale up\n",
            "\n",
            "--- Chunk 10926 ---\n",
            "beyond the size of the original image: this can be used to increase the resolution of an\n",
            "image, which is a technique called super-resolution.\n",
            "\n",
            "--- Chunk 10927 ---\n",
            "494 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 10928 ---\n",
            "Figure 14-28. Skip layers recover some spatial resolution from lower layers\n",
            "\n",
            "--- Chunk 10929 ---\n",
            "Once again, many GitHub repositories provide TensorFlow implementations of\n",
            "\n",
            "--- Chunk 10930 ---\n",
            "semantic segmentation (TensorFlow 1 for now), and you will even find pretrained\n",
            "\n",
            "--- Chunk 10931 ---\n",
            "instance segmentation models in the TensorFlow Models project. Instance segmenta‐\n",
            "\n",
            "--- Chunk 10932 ---\n",
            "tion is similar to semantic segmentation, but instead of merging all objects of the\n",
            "\n",
            "--- Chunk 10933 ---\n",
            "same class into one big lump, each object is distinguished from the others (e.g., it\n",
            "\n",
            "--- Chunk 10934 ---\n",
            "identifies each individual bicycle). At present, the instance segmentation models\n",
            "\n",
            "--- Chunk 10935 ---\n",
            "available in the TensorFlow Models project are based on the Mask R-CNN architec‐\n",
            "\n",
            "--- Chunk 10936 ---\n",
            "ture, which was proposed in a 2017 paper:34 it extends the Faster R-CNN model by\n",
            "\n",
            "--- Chunk 10937 ---\n",
            "additionally producing a pixel mask for each bounding box. So not only do you get a\n",
            "\n",
            "--- Chunk 10938 ---\n",
            "bounding box around each object, with a set of estimated class probabilities, but you\n",
            "\n",
            "--- Chunk 10939 ---\n",
            "also get a pixel mask that locates pixels in the bounding box that belong to the object.\n",
            "\n",
            "--- Chunk 10940 ---\n",
            "As you can see, the field of Deep Computer Vision is vast and moving fast, with all\n",
            "\n",
            "--- Chunk 10941 ---\n",
            "sorts of architectures popping out every year, all based on convolutional neural net‐\n",
            "\n",
            "--- Chunk 10942 ---\n",
            "works. The progress made in just a few years has been astounding, and researchers\n",
            "\n",
            "--- Chunk 10943 ---\n",
            "are now focusing on harder and harder problems, such as adversarial learning (which\n",
            "\n",
            "--- Chunk 10944 ---\n",
            "attempts to make the network more resistant to images designed to fool it), explaina‐\n",
            "\n",
            "--- Chunk 10945 ---\n",
            "bility (understanding why the network makes a specific classification), realistic image\n",
            "\n",
            "--- Chunk 10946 ---\n",
            "generation (which we will come back to in Chapter 17), and single-shot learning (a sys‐\n",
            "\n",
            "--- Chunk 10947 ---\n",
            "tem that can recognize an object after it has seen it just once). Some even explore\n",
            "\n",
            "--- Chunk 10948 ---\n",
            "completely novel architectures, such as Geoffrey Hinton’s capsule networks35 (I pre‐\n",
            "\n",
            "--- Chunk 10949 ---\n",
            "sented them in a couple of videos, with the corresponding code in a notebook). Now\n",
            "\n",
            "--- Chunk 10950 ---\n",
            "on to the next chapter, where we will look at how to process sequential data such as\n",
            "\n",
            "--- Chunk 10951 ---\n",
            "time series using recurrent neural networks and convolutional neural networks.\n",
            "\n",
            "--- Chunk 10952 ---\n",
            "34 Kaiming He et al., “Mask R-CNN,” arXiv preprint arXiv:1703.06870 (2017).\n",
            "\n",
            "--- Chunk 10953 ---\n",
            "35 Geoffrey Hinton et al., “Matrix Capsules with EM Routing,” Proceedings of the International Conference on\n",
            "\n",
            "--- Chunk 10954 ---\n",
            "Learning Representations (2018).\n",
            "\n",
            "Semantic Segmentation | 495\n",
            "\n",
            "--- Chunk 10955 ---\n",
            "Exercises\n",
            "1. What are the advantages of a CNN over a fully connected DNN for image classi‐\n",
            "\n",
            "--- Chunk 10956 ---\n",
            "fication?\n",
            "2. Consider a CNN composed of three convolutional layers, each with 3 × 3 kernels,\n",
            "\n",
            "--- Chunk 10957 ---\n",
            "a stride of 2, and \"same\" padding. The lowest layer outputs 100 feature maps, the\n",
            "\n",
            "--- Chunk 10958 ---\n",
            "middle one outputs 200, and the top one outputs 400. The input images are RGB\n",
            "images of 200 × 300 pixels.\n",
            "\n",
            "--- Chunk 10959 ---\n",
            "What is the total number of parameters in the CNN? If we are using 32-bit floats,\n",
            "\n",
            "--- Chunk 10960 ---\n",
            "at least how much RAM will this network require when making a prediction for a\n",
            "\n",
            "--- Chunk 10961 ---\n",
            "single instance? What about when training on a mini-batch of 50 images?\n",
            "\n",
            "--- Chunk 10962 ---\n",
            "3. If your GPU runs out of memory while training a CNN, what are five things you\n",
            "could try to solve the problem?\n",
            "\n",
            "--- Chunk 10963 ---\n",
            "4. Why would you want to add a max pooling layer rather than a convolutional\n",
            "layer with the same stride?\n",
            "\n",
            "--- Chunk 10964 ---\n",
            "5. When would you want to add a local response normalization layer?\n",
            "6. Can you name the main innovations in AlexNet, compared to LeNet-5? What\n",
            "\n",
            "--- Chunk 10965 ---\n",
            "about the main innovations in GoogLeNet, ResNet, SENet, and Xception?\n",
            "\n",
            "--- Chunk 10966 ---\n",
            "7. What is a fully convolutional network? How can you convert a dense layer into a\n",
            "\n",
            "--- Chunk 10967 ---\n",
            "convolutional layer?\n",
            "8. What is the main technical difficulty of semantic segmentation?\n",
            "\n",
            "--- Chunk 10968 ---\n",
            "9. Build your own CNN from scratch and try to achieve the highest possible accu‐\n",
            "\n",
            "--- Chunk 10969 ---\n",
            "racy on MNIST.\n",
            "10. Use transfer learning for large image classification, going through these steps:\n",
            "\n",
            "--- Chunk 10970 ---\n",
            "a. Create a training set containing at least 100 images per class. For example, you\n",
            "\n",
            "--- Chunk 10971 ---\n",
            "could classify your own pictures based on the location (beach, mountain, city,\n",
            "\n",
            "--- Chunk 10972 ---\n",
            "etc.), or alternatively you can use an existing dataset (e.g., from TensorFlow\n",
            "Datasets).\n",
            "\n",
            "--- Chunk 10973 ---\n",
            "b. Split it into a training set, a validation set, and a test set.\n",
            "c. Build the input pipeline, including the appropriate preprocessing operations,\n",
            "\n",
            "--- Chunk 10974 ---\n",
            "and optionally add data augmentation.\n",
            "d. Fine-tune a pretrained model on this dataset.\n",
            "\n",
            "--- Chunk 10975 ---\n",
            "11. Go through TensorFlow’s Style Transfer tutorial. It is a fun way to generate art\n",
            "using Deep Learning.\n",
            "\n",
            "--- Chunk 10976 ---\n",
            "Solutions to these exercises are available in Appendix A.\n",
            "\n",
            "496 | Chapter 14: Deep Computer Vision Using Convolutional Neural Networks\n",
            "\n",
            "--- Chunk 10977 ---\n",
            "CHAPTER 15\n",
            "Processing Sequences Using\n",
            "\n",
            "RNNs and CNNs\n",
            "\n",
            "--- Chunk 10978 ---\n",
            "The batter hits the ball. The outfielder immediately starts running, anticipating the\n",
            "\n",
            "--- Chunk 10979 ---\n",
            "ball’s trajectory. He tracks it, adapts his movements, and finally catches it (under a\n",
            "\n",
            "--- Chunk 10980 ---\n",
            "thunder of applause). Predicting the future is something you do all the time, whether\n",
            "\n",
            "--- Chunk 10981 ---\n",
            "you are finishing a friend’s sentence or anticipating the smell of coffee at breakfast. In\n",
            "\n",
            "--- Chunk 10982 ---\n",
            "this chapter we will discuss recurrent neural networks (RNNs), a class of nets that can\n",
            "\n",
            "--- Chunk 10983 ---\n",
            "predict the future (well, up to a point, of course). They can analyze time series data\n",
            "\n",
            "--- Chunk 10984 ---\n",
            "such as stock prices, and tell you when to buy or sell. In autonomous driving systems,\n",
            "\n",
            "--- Chunk 10985 ---\n",
            "they can anticipate car trajectories and help avoid accidents. More generally, they can\n",
            "\n",
            "--- Chunk 10986 ---\n",
            "work on sequences of arbitrary lengths, rather than on fixed-sized inputs like all the\n",
            "\n",
            "--- Chunk 10987 ---\n",
            "nets we have considered so far. For example, they can take sentences, documents, or\n",
            "\n",
            "--- Chunk 10988 ---\n",
            "audio samples as input, making them extremely useful for natural language process‐\n",
            "ing applications such as automatic translation or speech-to-text.\n",
            "\n",
            "--- Chunk 10989 ---\n",
            "In this chapter we will first look at the fundamental concepts underlying RNNs and\n",
            "\n",
            "--- Chunk 10990 ---\n",
            "how to train them using backpropagation through time, then we will use them to\n",
            "\n",
            "--- Chunk 10991 ---\n",
            "forecast a time series. After that we’ll explore the two main difficulties that RNNs\n",
            "face:\n",
            "\n",
            "--- Chunk 10992 ---\n",
            "• Unstable gradients (discussed in Chapter 11), which can be alleviated using vari‐\n",
            "\n",
            "--- Chunk 10993 ---\n",
            "ous techniques, including recurrent dropout and recurrent layer normalization\n",
            "\n",
            "--- Chunk 10994 ---\n",
            "• A (very) limited short-term memory, which can be extended using LSTM and\n",
            "GRU cells\n",
            "\n",
            "--- Chunk 10995 ---\n",
            "RNNs are not the only types of neural networks capable of handling sequential data:\n",
            "\n",
            "--- Chunk 10996 ---\n",
            "for small sequences, a regular dense network can do the trick; and for very long\n",
            "\n",
            "--- Chunk 10997 ---\n",
            "sequences, such as audio samples or text, convolutional neural networks can actually\n",
            "\n",
            "--- Chunk 10998 ---\n",
            "497\n",
            "\n",
            "--- Chunk 10999 ---\n",
            "work quite well too. We will discuss both of these possibilities, and we will finish this\n",
            "\n",
            "--- Chunk 11000 ---\n",
            "chapter by implementing a WaveNet: this is a CNN architecture capable of handling\n",
            "\n",
            "--- Chunk 11001 ---\n",
            "sequences of tens of thousands of time steps. In Chapter 16, we will continue to\n",
            "\n",
            "--- Chunk 11002 ---\n",
            "explore RNNs and see how to use them for natural language processing, along with\n",
            "\n",
            "--- Chunk 11003 ---\n",
            "more recent architectures based on attention mechanisms. Let’s get started!\n",
            "\n",
            "--- Chunk 11004 ---\n",
            "Recurrent Neurons and Layers\n",
            "Up to now we have focused on feedforward neural networks, where the activations\n",
            "\n",
            "--- Chunk 11005 ---\n",
            "flow only in one direction, from the input layer to the output layer (a few exceptions\n",
            "\n",
            "--- Chunk 11006 ---\n",
            "are discussed in Appendix E). A recurrent neural network looks very much like a\n",
            "\n",
            "--- Chunk 11007 ---\n",
            "feedforward neural network, except it also has connections pointing backward. Let’s\n",
            "\n",
            "--- Chunk 11008 ---\n",
            "look at the simplest possible RNN, composed of one neuron receiving inputs, pro‐\n",
            "\n",
            "--- Chunk 11009 ---\n",
            "ducing an output, and sending that output back to itself, as shown in Figure 15-1\n",
            "\n",
            "--- Chunk 11010 ---\n",
            "(left). At each time step t (also called a frame), this recurrent neuron receives the inputs\n",
            "\n",
            "--- Chunk 11011 ---\n",
            "x(t) as well as its own output from the previous time step, y(t–1). Since there is no previ‐\n",
            "\n",
            "--- Chunk 11012 ---\n",
            "ous output at the first time step, it is generally set to 0. We can represent this tiny net‐\n",
            "\n",
            "--- Chunk 11013 ---\n",
            "work against the time axis, as shown in Figure 15-1 (right). This is called unrolling the\n",
            "\n",
            "--- Chunk 11014 ---\n",
            "network through time (it’s the same recurrent neuron represented once per time step).\n",
            "\n",
            "--- Chunk 11015 ---\n",
            "Figure 15-1. A recurrent neuron (left) unrolled through time (right)\n",
            "\n",
            "--- Chunk 11016 ---\n",
            "You can easily create a layer of recurrent neurons. At each time step t, every neuron\n",
            "\n",
            "--- Chunk 11017 ---\n",
            "receives both the input vector x(t) and the output vector from the previous time step\n",
            "\n",
            "--- Chunk 11018 ---\n",
            "y(t–1), as shown in Figure 15-2. Note that both the inputs and outputs are vectors now\n",
            "\n",
            "--- Chunk 11019 ---\n",
            "(when there was just a single neuron, the output was a scalar).\n",
            "\n",
            "--- Chunk 11020 ---\n",
            "498 | Chapter 15: Processing Sequences Using RNNs and CNNs\n",
            "\n",
            "\n",
            "\n",
            "Figure 15-2. A layer of recurrent neurons (left) unrolled through time (right)\n",
            "\n",
            "--- Chunk 11021 ---\n",
            "Each recurrent neuron has two sets of weights: one for the inputs x(t) and the other for\n",
            "\n",
            "--- Chunk 11022 ---\n",
            "the outputs of the previous time step, y(t–1). Let’s call these weight vectors wx and wy. If\n",
            "\n",
            "--- Chunk 11023 ---\n",
            "we consider the whole recurrent layer instead of just one recurrent neuron, we can\n",
            "\n",
            "--- Chunk 11024 ---\n",
            "place all the weight vectors in two weight matrices, Wx and Wy. The output vector of\n",
            "\n",
            "--- Chunk 11025 ---\n",
            "the whole recurrent layer can then be computed pretty much as you might expect, as\n",
            "\n",
            "--- Chunk 11026 ---\n",
            "shown in Equation 15-1 (b is the bias vector and ϕ(·) is the activation function (e.g.,\n",
            "ReLU1).\n",
            "\n",
            "--- Chunk 11027 ---\n",
            "Equation 15-1. Output of a recurrent layer for a single instance\n",
            "y t = ϕ W ⊺x t + W ⊺\n",
            "\n",
            "x y y t − 1 + b\n",
            "\n",
            "--- Chunk 11028 ---\n",
            "Just as with feedforward neural networks, we can compute a recurrent layer’s output\n",
            "\n",
            "--- Chunk 11029 ---\n",
            "in one shot for a whole mini-batch by placing all the inputs at time step t in an input\n",
            "matrix X(t) (see Equation 15-2).\n",
            "\n",
            "--- Chunk 11030 ---\n",
            "Equation 15-2. Outputs of a layer of recurrent neurons for all instances in a mini-\n",
            "batch\n",
            "Y t = ϕ X t Wx + Y t − 1 Wy + b\n",
            "\n",
            "--- Chunk 11031 ---\n",
            "W\n",
            "= ϕ X t Y t − 1 W + b with W = x\n",
            "\n",
            "Wy\n",
            "\n",
            "--- Chunk 11032 ---\n",
            "1 Note that many researchers prefer to use the hyperbolic tangent (tanh) activation function in RNNs rather\n",
            "\n",
            "--- Chunk 11033 ---\n",
            "than the ReLU activation function. For example, take a look at Vu Pham et al.’s 2013 paper “Dropout Improves\n",
            "\n",
            "--- Chunk 11034 ---\n",
            "Recurrent Neural Networks for Handwriting Recognition”. ReLU-based RNNs are also possible, as shown in\n",
            "\n",
            "--- Chunk 11035 ---\n",
            "Quoc V. Le et al.’s 2015 paper “A Simple Way to Initialize Recurrent Networks of Rectified Linear Units”.\n",
            "\n",
            "--- Chunk 11036 ---\n",
            "Recurrent Neurons and Layers | 499\n",
            "\n",
            "\n",
            "\n",
            "In this equation:\n",
            "\n",
            "--- Chunk 11037 ---\n",
            "• Y(t) is an m × nneurons matrix containing the layer’s outputs at time step t for each\n",
            "\n",
            "--- Chunk 11038 ---\n",
            "instance in the mini-batch (m is the number of instances in the mini-batch and\n",
            "nneurons is the number of neurons).\n",
            "\n",
            "--- Chunk 11039 ---\n",
            "• X(t) is an m × ninputs matrix containing the inputs for all instances (ninputs is the\n",
            "number of input features).\n",
            "\n",
            "--- Chunk 11040 ---\n",
            "• Wx is an ninputs × nneurons matrix containing the connection weights for the inputs\n",
            "of the current time step.\n",
            "\n",
            "--- Chunk 11041 ---\n",
            "• Wy is an nneurons × nneurons matrix containing the connection weights for the out‐\n",
            "puts of the previous time step.\n",
            "\n",
            "--- Chunk 11042 ---\n",
            "• b is a vector of size nneurons containing each neuron’s bias term.\n",
            "• The weight matrices Wx and Wy are often concatenated vertically into a single\n",
            "\n",
            "--- Chunk 11043 ---\n",
            "weight matrix W of shape (ninputs + nneurons) × nneurons (see the second line of Equa‐\n",
            "tion 15-2).\n",
            "\n",
            "--- Chunk 11044 ---\n",
            "• The notation [X(t) Y(t–1)] represents the horizontal concatenation of the matrices\n",
            "X(t) and Y(t–1).\n",
            "\n",
            "--- Chunk 11045 ---\n",
            "Notice that Y(t) is a function of X(t) and Y(t–1), which is a function of X(t–1) and Y(t–2),\n",
            "\n",
            "--- Chunk 11046 ---\n",
            "which is a function of X(t–2) and Y(t–3), and so on. This makes Y(t) a function of all the\n",
            "\n",
            "--- Chunk 11047 ---\n",
            "inputs since time t = 0 (that is, X(0), X(1), …, X(t)). At the first time step, t = 0, there are\n",
            "\n",
            "--- Chunk 11048 ---\n",
            "no previous outputs, so they are typically assumed to be all zeros.\n",
            "\n",
            "--- Chunk 11049 ---\n",
            "Memory Cells\n",
            "Since the output of a recurrent neuron at time step t is a function of all the inputs\n",
            "\n",
            "--- Chunk 11050 ---\n",
            "from previous time steps, you could say it has a form of memory. A part of a neural\n",
            "\n",
            "--- Chunk 11051 ---\n",
            "network that preserves some state across time steps is called a memory cell (or simply\n",
            "\n",
            "--- Chunk 11052 ---\n",
            "a cell). A single recurrent neuron, or a layer of recurrent neurons, is a very basic cell,\n",
            "\n",
            "--- Chunk 11053 ---\n",
            "capable of learning only short patterns (typically about 10 steps long, but this varies\n",
            "\n",
            "--- Chunk 11054 ---\n",
            "depending on the task). Later in this chapter, we will look at some more complex and\n",
            "\n",
            "--- Chunk 11055 ---\n",
            "powerful types of cells capable of learning longer patterns (roughly 10 times longer,\n",
            "but again, this depends on the task).\n",
            "\n",
            "--- Chunk 11056 ---\n",
            "In general a cell’s state at time step t, denoted h(t) (the “h” stands for “hidden”), is a\n",
            "\n",
            "--- Chunk 11057 ---\n",
            "function of some inputs at that time step and its state at the previous time step: h(t) =\n",
            "\n",
            "--- Chunk 11058 ---\n",
            "f(h(t–1), x(t)). Its output at time step t, denoted y(t), is also a function of the previous\n",
            "\n",
            "--- Chunk 11059 ---\n",
            "state and the current inputs. In the case of the basic cells we have discussed so far, the\n",
            "\n",
            "--- Chunk 11060 ---\n",
            "output is simply equal to the state, but in more complex cells this is not always the\n",
            "case, as shown in Figure 15-3.\n",
            "\n",
            "--- Chunk 11061 ---\n",
            "500 | Chapter 15: Processing Sequences Using RNNs and CNNs\n",
            "\n",
            "\n",
            "\n",
            "Figure 15-3. A cell’s hidden state and its output may be different\n",
            "\n",
            "--- Chunk 11062 ---\n",
            "Input and Output Sequences\n",
            "An RNN can simultaneously take a sequence of inputs and produce a sequence of\n",
            "\n",
            "--- Chunk 11063 ---\n",
            "outputs (see the top-left network in Figure 15-4). This type of sequence-to-sequence\n",
            "\n",
            "--- Chunk 11064 ---\n",
            "network is useful for predicting time series such as stock prices: you feed it the prices\n",
            "\n",
            "--- Chunk 11065 ---\n",
            "over the last N days, and it must output the prices shifted by one day into the future\n",
            "(i.e., from N – 1 days ago to tomorrow).\n",
            "\n",
            "--- Chunk 11066 ---\n",
            "Alternatively, you could feed the network a sequence of inputs and ignore all outputs\n",
            "\n",
            "--- Chunk 11067 ---\n",
            "except for the last one (see the top-right network in Figure 15-4). In other words, this\n",
            "\n",
            "--- Chunk 11068 ---\n",
            "is a sequence-to-vector network. For example, you could feed the network a sequence\n",
            "\n",
            "--- Chunk 11069 ---\n",
            "of words corresponding to a movie review, and the network would output a senti‐\n",
            "ment score (e.g., from –1 [hate] to +1 [love]).\n",
            "\n",
            "--- Chunk 11070 ---\n",
            "Conversely, you could feed the network the same input vector over and over again at\n",
            "\n",
            "--- Chunk 11071 ---\n",
            "each time step and let it output a sequence (see the bottom-left network of\n",
            "\n",
            "--- Chunk 11072 ---\n",
            "Figure 15-4). This is a vector-to-sequence network. For example, the input could be an\n",
            "\n",
            "--- Chunk 11073 ---\n",
            "image (or the output of a CNN), and the output could be a caption for that image.\n",
            "\n",
            "--- Chunk 11074 ---\n",
            "Lastly, you could have a sequence-to-vector network, called an encoder, followed by a\n",
            "\n",
            "--- Chunk 11075 ---\n",
            "vector-to-sequence network, called a decoder (see the bottom-right network of\n",
            "\n",
            "--- Chunk 11076 ---\n",
            "Figure 15-4). For example, this could be used for translating a sentence from one lan‐\n",
            "\n",
            "--- Chunk 11077 ---\n",
            "guage to another. You would feed the network a sentence in one language, the\n",
            "\n",
            "--- Chunk 11078 ---\n",
            "encoder would convert this sentence into a single vector representation, and then the\n",
            "\n",
            "--- Chunk 11079 ---\n",
            "decoder would decode this vector into a sentence in another language. This two-step\n",
            "\n",
            "--- Chunk 11080 ---\n",
            "model, called an Encoder–Decoder, works much better than trying to translate on the\n",
            "\n",
            "--- Chunk 11081 ---\n",
            "fly with a single sequence-to-sequence RNN (like the one represented at the top left):\n",
            "\n",
            "--- Chunk 11082 ---\n",
            "the last words of a sentence can affect the first words of the translation, so you need\n",
            "\n",
            "--- Chunk 11083 ---\n",
            "to wait until you have seen the whole sentence before translating it. We will see how\n",
            "\n",
            "--- Chunk 11084 ---\n",
            "to implement an Encoder–Decoder in Chapter 16 (as we will see, it is a bit more com‐\n",
            "plex than in Figure 15-4 suggests).\n",
            "\n",
            "--- Chunk 11085 ---\n",
            "Recurrent Neurons and Layers | 501\n",
            "\n",
            "--- Chunk 11086 ---\n",
            "Figure 15-4. Seq-to-seq (top left), seq-to-vector (top right), vector-to-seq (bottom left),\n",
            "and Encoder–Decoder (bottom right) networks\n",
            "\n",
            "--- Chunk 11087 ---\n",
            "Sounds promising, but how do you train a recurrent neural network?\n",
            "\n",
            "--- Chunk 11088 ---\n",
            "Training RNNs\n",
            "To train an RNN, the trick is to unroll it through time (like we just did) and then\n",
            "\n",
            "--- Chunk 11089 ---\n",
            "simply use regular backpropagation (see Figure 15-5). This strategy is called backpro‐\n",
            "pagation through time (BPTT).\n",
            "\n",
            "--- Chunk 11090 ---\n",
            "Just like in regular backpropagation, there is a first forward pass through the unrolled\n",
            "\n",
            "--- Chunk 11091 ---\n",
            "network (represented by the dashed arrows). Then the output sequence is evaluated\n",
            "\n",
            "--- Chunk 11092 ---\n",
            "using a cost function C(Y(0), Y(1), …Y(T)) (where T is the max time step). Note that this\n",
            "\n",
            "--- Chunk 11093 ---\n",
            "cost function may ignore some outputs, as shown in Figure 15-5 (for example, in a\n",
            "\n",
            "--- Chunk 11094 ---\n",
            "sequence-to-vector RNN, all outputs are ignored except for the very last one). The\n",
            "\n",
            "--- Chunk 11095 ---\n",
            "gradients of that cost function are then propagated backward through the unrolled\n",
            "\n",
            "--- Chunk 11096 ---\n",
            "network (represented by the solid arrows). Finally the model parameters are updated\n",
            "\n",
            "--- Chunk 11097 ---\n",
            "using the gradients computed during BPTT. Note that the gradients flow backward\n",
            "\n",
            "--- Chunk 11098 ---\n",
            "through all the outputs used by the cost function, not just through the final output\n",
            "\n",
            "--- Chunk 11099 ---\n",
            "(for example, in Figure 15-5 the cost function is computed using the last three out‐\n",
            "\n",
            "--- Chunk 11100 ---\n",
            "puts of the network, Y(2), Y(3), and Y(4), so gradients flow through these three outputs,\n",
            "\n",
            "--- Chunk 11101 ---\n",
            "502 | Chapter 15: Processing Sequences Using RNNs and CNNs\n",
            "\n",
            "--- Chunk 11102 ---\n",
            "but not through Y(0) and Y(1)). Moreover, since the same parameters W and b are used\n",
            "\n",
            "--- Chunk 11103 ---\n",
            "at each time step, backpropagation will do the right thing and sum over all time steps.\n",
            "\n",
            "--- Chunk 11104 ---\n",
            "Figure 15-5. Backpropagation through time\n",
            "\n",
            "Fortunately, tf.keras takes care of all of this complexity for you—so let’s start coding!\n",
            "\n",
            "--- Chunk 11105 ---\n",
            "Forecasting a Time Series\n",
            "Suppose you are studying the number of active users per hour on your website, or the\n",
            "\n",
            "--- Chunk 11106 ---\n",
            "daily temperature in your city, or your company’s financial health, measured quar‐\n",
            "\n",
            "--- Chunk 11107 ---\n",
            "terly using multiple metrics. In all these cases, the data will be a sequence of one or\n",
            "\n",
            "--- Chunk 11108 ---\n",
            "more values per time step. This is called a time series. In the first two examples there\n",
            "\n",
            "--- Chunk 11109 ---\n",
            "is a single value per time step, so these are univariate time series, while in the financial\n",
            "\n",
            "--- Chunk 11110 ---\n",
            "example there are multiple values per time step (e.g., the company’s revenue, debt,\n",
            "\n",
            "--- Chunk 11111 ---\n",
            "and so on), so it is a multivariate time series. A typical task is to predict future values,\n",
            "\n",
            "--- Chunk 11112 ---\n",
            "which is called forecasting. Another common task is to fill in the blanks: to predict (or\n",
            "\n",
            "--- Chunk 11113 ---\n",
            "rather “postdict”) missing values from the past. This is called imputation. For exam‐\n",
            "\n",
            "--- Chunk 11114 ---\n",
            "ple, Figure 15-6 shows 3 univariate time series, each of them 50 time steps long, and\n",
            "\n",
            "--- Chunk 11115 ---\n",
            "the goal here is to forecast the value at the next time step (represented by the X) for\n",
            "each of them.\n",
            "\n",
            "--- Chunk 11116 ---\n",
            "Forecasting a Time Series | 503\n",
            "\n",
            "\n",
            "\n",
            "Figure 15-6. Time series forecasting\n",
            "\n",
            "--- Chunk 11117 ---\n",
            "For simplicity, we are using a time series generated by the generate_time_series()\n",
            "function, shown here:\n",
            "\n",
            "--- Chunk 11118 ---\n",
            "def generate_time_series(batch_size, n_steps):\n",
            "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
            "\n",
            "--- Chunk 11119 ---\n",
            "time = np.linspace(0, 1, n_steps)\n",
            "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))  #   wave 1\n",
            "\n",
            "--- Chunk 11120 ---\n",
            "series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # + wave 2\n",
            "\n",
            "--- Chunk 11121 ---\n",
            "series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)   # + noise\n",
            "    return series[..., np.newaxis].astype(np.float32)\n",
            "\n",
            "--- Chunk 11122 ---\n",
            "This function creates as many time series as requested (via the batch_size argu‐\n",
            "\n",
            "--- Chunk 11123 ---\n",
            "ment), each of length n_steps, and there is just one value per time step in each series\n",
            "\n",
            "--- Chunk 11124 ---\n",
            "(i.e., all series are univariate). The function returns a NumPy array of shape [batch\n",
            "\n",
            "--- Chunk 11125 ---\n",
            "size, time steps, 1], where each series is the sum of two sine waves of fixed amplitudes\n",
            "but random frequencies and phases, plus a bit of noise.\n",
            "\n",
            "--- Chunk 11126 ---\n",
            "When dealing with time series (and other types of sequences such\n",
            "as sentences), the input features are generally represented as 3D\n",
            "\n",
            "--- Chunk 11127 ---\n",
            "arrays of shape [batch size, time steps, dimensionality], where\n",
            "dimensionality is 1 for univariate time series and more for multi‐\n",
            "\n",
            "--- Chunk 11128 ---\n",
            "variate time series.\n",
            "\n",
            "--- Chunk 11129 ---\n",
            "Now let’s create a training set, a validation set, and a test set using this function:\n",
            "n_steps = 50\n",
            "\n",
            "--- Chunk 11130 ---\n",
            "n_steps = 50\n",
            "series = generate_time_series(10000, n_steps + 1)\n",
            "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
            "\n",
            "--- Chunk 11131 ---\n",
            "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
            "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]\n",
            "\n",
            "--- Chunk 11132 ---\n",
            "X_train contains 7,000 time series (i.e., its shape is [7000, 50, 1]), while X_valid con‐\n",
            "\n",
            "--- Chunk 11133 ---\n",
            "tains 2,000 (from the 7,000th time series to the 8,999th) and X_test contains 1,000\n",
            "\n",
            "--- Chunk 11134 ---\n",
            "(from the 9,000th to the 9,999th). Since we want to forecast a single value for each ser‐\n",
            "\n",
            "--- Chunk 11135 ---\n",
            "ies, the targets are column vectors (e.g., y_train has a shape of [7000, 1]).\n",
            "\n",
            "--- Chunk 11136 ---\n",
            "504 | Chapter 15: Processing Sequences Using RNNs and CNNs\n",
            "\n",
            "--- Chunk 11137 ---\n",
            "Baseline Metrics\n",
            "Before we start using RNNs, it is often a good idea to have a few baseline metrics, or\n",
            "\n",
            "--- Chunk 11138 ---\n",
            "else we may end up thinking our model works great when in fact it is doing worse\n",
            "\n",
            "--- Chunk 11139 ---\n",
            "than basic models. For example, the simplest approach is to predict the last value in\n",
            "\n",
            "--- Chunk 11140 ---\n",
            "each series. This is called naive forecasting, and it is sometimes surprisingly difficult to\n",
            "\n",
            "--- Chunk 11141 ---\n",
            "outperform. In this case, it gives us a mean squared error of about 0.020:\n",
            "\n",
            "--- Chunk 11142 ---\n",
            ">>> y_pred = X_valid[:, -1]\n",
            ">>> np.mean(keras.losses.mean_squared_error(y_valid, y_pred))\n",
            "0.020211367\n",
            "\n",
            "--- Chunk 11143 ---\n",
            "Another simple approach is to use a fully connected network. Since it expects a flat\n",
            "\n",
            "--- Chunk 11144 ---\n",
            "list of features for each input, we need to add a Flatten layer. Let’s just use a simple\n",
            "\n",
            "--- Chunk 11145 ---\n",
            "Linear Regression model so that each prediction will be a linear combination of the\n",
            "values in the time series:\n",
            "\n",
            "--- Chunk 11146 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.Flatten(input_shape=[50, 1]),\n",
            "    keras.layers.Dense(1)\n",
            "])\n",
            "\n",
            "--- Chunk 11147 ---\n",
            "If we compile this model using the MSE loss and the default Adam optimizer, then fit\n",
            "\n",
            "--- Chunk 11148 ---\n",
            "it on the training set for 20 epochs and evaluate it on the validation set, we get an\n",
            "MSE of about 0.004. That’s much better than the naive approach!\n",
            "\n",
            "--- Chunk 11149 ---\n",
            "Implementing a Simple RNN\n",
            "Let’s see if we can beat that with a simple RNN:\n",
            "\n",
            "--- Chunk 11150 ---\n",
            "model = keras.models.Sequential([\n",
            "  keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
            "])\n",
            "\n",
            "--- Chunk 11151 ---\n",
            "That’s really the simplest RNN you can build. It just contains a single layer, with a sin‐\n",
            "\n",
            "--- Chunk 11152 ---\n",
            "gle neuron, as we saw in Figure 15-1. We do not need to specify the length of the\n",
            "\n",
            "--- Chunk 11153 ---\n",
            "input sequences (unlike in the previous model), since a recurrent neural network can\n",
            "\n",
            "--- Chunk 11154 ---\n",
            "process any number of time steps (this is why we set the first input dimension to\n",
            "\n",
            "--- Chunk 11155 ---\n",
            "None). By default, the SimpleRNN layer uses the hyperbolic tangent activation func‐\n",
            "\n",
            "--- Chunk 11156 ---\n",
            "tion. It works exactly as we saw earlier: the initial state h(init) is set to 0, and it is passed\n",
            "\n",
            "--- Chunk 11157 ---\n",
            "to a single recurrent neuron, along with the value of the first time step, x(0). The neu‐\n",
            "\n",
            "--- Chunk 11158 ---\n",
            "ron computes a weighted sum of these values and applies the hyperbolic tangent acti‐\n",
            "\n",
            "--- Chunk 11159 ---\n",
            "vation function to the result, and this gives the first output, y0. In a simple RNN, this\n",
            "\n",
            "--- Chunk 11160 ---\n",
            "output is also the new state h0. This new state is passed to the same recurrent neuron\n",
            "\n",
            "--- Chunk 11161 ---\n",
            "along with the next input value, x(1), and the process is repeated until the last time\n",
            "\n",
            "--- Chunk 11162 ---\n",
            "step. Then the layer just outputs the last value, y49. All of this is performed simultane‐\n",
            "ously for every time series.\n",
            "\n",
            "--- Chunk 11163 ---\n",
            "Forecasting a Time Series | 505\n",
            "\n",
            "--- Chunk 11164 ---\n",
            "By default, recurrent layers in Keras only return the final output. To\n",
            "make them return one output per time step, you must set\n",
            "\n",
            "--- Chunk 11165 ---\n",
            "return_sequences=True, as we will see.\n",
            "\n",
            "--- Chunk 11166 ---\n",
            "If you compile, fit, and evaluate this model (just like earlier, we train for 20 epochs\n",
            "\n",
            "--- Chunk 11167 ---\n",
            "using Adam), you will find that its MSE reaches only 0.014, so it is better than the\n",
            "\n",
            "--- Chunk 11168 ---\n",
            "naive approach but it does not beat a simple linear model. Note that for each neuron,\n",
            "\n",
            "--- Chunk 11169 ---\n",
            "a linear model has one parameter per input and per time step, plus a bias term (in the\n",
            "\n",
            "--- Chunk 11170 ---\n",
            "simple linear model we used, that’s a total of 51 parameters). In contrast, for each\n",
            "\n",
            "--- Chunk 11171 ---\n",
            "recurrent neuron in a simple RNN, there is just one parameter per input and per hid‐\n",
            "\n",
            "--- Chunk 11172 ---\n",
            "den state dimension (in a simple RNN, that’s just the number of recurrent neurons in\n",
            "\n",
            "--- Chunk 11173 ---\n",
            "the layer), plus a bias term. In this simple RNN, that’s a total of just three parameters.\n",
            "\n",
            "--- Chunk 11174 ---\n",
            "Trend and Seasonality\n",
            "There are many other models to forecast time series, such as weighted moving average\n",
            "\n",
            "--- Chunk 11175 ---\n",
            "models or autoregressive integrated moving average (ARIMA) models. Some of them\n",
            "\n",
            "--- Chunk 11176 ---\n",
            "require you to first remove the trend and seasonality. For example, if you are studying\n",
            "\n",
            "--- Chunk 11177 ---\n",
            "the number of active users on your website, and it is growing by 10% every month,\n",
            "\n",
            "--- Chunk 11178 ---\n",
            "you would have to remove this trend from the time series. Once the model is trained\n",
            "\n",
            "--- Chunk 11179 ---\n",
            "and starts making predictions, you would have to add the trend back to get the final\n",
            "\n",
            "--- Chunk 11180 ---\n",
            "predictions. Similarly, if you are trying to predict the amount of sunscreen lotion sold\n",
            "\n",
            "--- Chunk 11181 ---\n",
            "every month, you will probably observe strong seasonality: since it sells well every\n",
            "\n",
            "--- Chunk 11182 ---\n",
            "summer, a similar pattern will be repeated every year. You would have to remove this\n",
            "\n",
            "--- Chunk 11183 ---\n",
            "seasonality from the time series, for example by computing the difference between the\n",
            "\n",
            "--- Chunk 11184 ---\n",
            "value at each time step and the value one year earlier (this technique is called differ‐\n",
            "\n",
            "--- Chunk 11185 ---\n",
            "encing). Again, after the model is trained and makes predictions, you would have to\n",
            "add the seasonal pattern back to get the final predictions.\n",
            "\n",
            "--- Chunk 11186 ---\n",
            "When using RNNs, it is generally not necessary to do all this, but it may improve per‐\n",
            "\n",
            "--- Chunk 11187 ---\n",
            "formance in some cases, since the model will not have to learn the trend or the\n",
            "seasonality.\n",
            "\n",
            "--- Chunk 11188 ---\n",
            "Apparently our simple RNN was too simple to get good performance. So let’s try to\n",
            "add more recurrent layers!\n",
            "\n",
            "--- Chunk 11189 ---\n",
            "Deep RNNs\n",
            "It is quite common to stack multiple layers of cells, as shown in Figure 15-7. This\n",
            "gives you a deep RNN.\n",
            "\n",
            "--- Chunk 11190 ---\n",
            "506 | Chapter 15: Processing Sequences Using RNNs and CNNs\n",
            "\n",
            "\n",
            "\n",
            "Figure 15-7. Deep RNN (left) unrolled through time (right)\n",
            "\n",
            "--- Chunk 11191 ---\n",
            "Implementing a deep RNN with tf.keras is quite simple: just stack recurrent layers. In\n",
            "\n",
            "--- Chunk 11192 ---\n",
            "this example, we use three SimpleRNN layers (but we could add any other type of\n",
            "\n",
            "--- Chunk 11193 ---\n",
            "recurrent layer, such as an LSTM layer or a GRU layer, which we will discuss shortly):\n",
            "\n",
            "--- Chunk 11194 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
            "\n",
            "--- Chunk 11195 ---\n",
            "keras.layers.SimpleRNN(20, return_sequences=True),\n",
            "    keras.layers.SimpleRNN(1)\n",
            "])\n",
            "\n",
            "--- Chunk 11196 ---\n",
            "Make sure to set return_sequences=True for all recurrent layers\n",
            "(except the last one, if you only care about the last output). If you\n",
            "\n",
            "--- Chunk 11197 ---\n",
            "don’t, they will output a 2D array (containing only the output of\n",
            "the last time step) instead of a 3D array (containing outputs for all\n",
            "\n",
            "--- Chunk 11198 ---\n",
            "time steps), and the next recurrent layer will complain that you are\n",
            "not feeding it sequences in the expected 3D format.\n",
            "\n",
            "--- Chunk 11199 ---\n",
            "If you compile, fit, and evaluate this model, you will find that it reaches an MSE of\n",
            "0.003. We finally managed to beat the linear model!\n",
            "\n",
            "--- Chunk 11200 ---\n",
            "Note that the last layer is not ideal: it must have a single unit because we want to fore‐\n",
            "\n",
            "--- Chunk 11201 ---\n",
            "cast a univariate time series, and this means we must have a single output value per\n",
            "\n",
            "--- Chunk 11202 ---\n",
            "time step. However, having a single unit means that the hidden state is just a single\n",
            "\n",
            "--- Chunk 11203 ---\n",
            "number. That’s really not much, and it’s probably not that useful; presumably, the\n",
            "\n",
            "--- Chunk 11204 ---\n",
            "RNN will mostly use the hidden states of the other recurrent layers to carry over all\n",
            "\n",
            "--- Chunk 11205 ---\n",
            "the information it needs from time step to time step, and it will not use the final lay‐\n",
            "\n",
            "--- Chunk 11206 ---\n",
            "er’s hidden state very much. Moreover, since a SimpleRNN layer uses the tanh activa‐\n",
            "\n",
            "--- Chunk 11207 ---\n",
            "tion function by default, the predicted values must lie within the range –1 to 1. But\n",
            "\n",
            "--- Chunk 11208 ---\n",
            "what if you want to use another activation function? For both these reasons, it might\n",
            "\n",
            "--- Chunk 11209 ---\n",
            "be preferable to replace the output layer with a Dense layer: it would run slightly\n",
            "\n",
            "--- Chunk 11210 ---\n",
            "Forecasting a Time Series | 507\n",
            "\n",
            "--- Chunk 11211 ---\n",
            "faster, the accuracy would be roughly the same, and it would allow us to choose any\n",
            "\n",
            "--- Chunk 11212 ---\n",
            "output activation function we want. If you make this change, also make sure to\n",
            "\n",
            "--- Chunk 11213 ---\n",
            "remove return_sequences=True from the second (now last) recurrent layer:\n",
            "\n",
            "--- Chunk 11214 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
            "    keras.layers.SimpleRNN(20),\n",
            "\n",
            "--- Chunk 11215 ---\n",
            "keras.layers.Dense(1)\n",
            "])\n",
            "\n",
            "--- Chunk 11216 ---\n",
            "If you train this model, you will see that it converges faster and performs just as well.\n",
            "\n",
            "--- Chunk 11217 ---\n",
            "Plus, you could change the output activation function if you wanted.\n",
            "\n",
            "--- Chunk 11218 ---\n",
            "Forecasting Several Time Steps Ahead\n",
            "So far we have only predicted the value at the next time step, but we could just as\n",
            "\n",
            "--- Chunk 11219 ---\n",
            "easily have predicted the value several steps ahead by changing the targets appropri‐\n",
            "\n",
            "--- Chunk 11220 ---\n",
            "ately (e.g., to predict 10 steps ahead, just change the targets to be the value 10 steps\n",
            "\n",
            "--- Chunk 11221 ---\n",
            "ahead instead of 1 step ahead). But what if we want to predict the next 10 values?\n",
            "\n",
            "--- Chunk 11222 ---\n",
            "The first option is to use the model we already trained, make it predict the next value,\n",
            "\n",
            "--- Chunk 11223 ---\n",
            "then add that value to the inputs (acting as if this predicted value had actually occur‐\n",
            "\n",
            "--- Chunk 11224 ---\n",
            "red), and use the model again to predict the following value, and so on, as in the fol‐\n",
            "lowing code:\n",
            "\n",
            "--- Chunk 11225 ---\n",
            "series = generate_time_series(1, n_steps + 10)\n",
            "X_new, Y_new = series[:, :n_steps], series[:, n_steps:]\n",
            "X = X_new\n",
            "for step_ahead in range(10):\n",
            "\n",
            "--- Chunk 11226 ---\n",
            "y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
            "    X = np.concatenate([X, y_pred_one], axis=1)\n",
            "\n",
            "--- Chunk 11227 ---\n",
            "Y_pred = X[:, n_steps:]\n",
            "\n",
            "--- Chunk 11228 ---\n",
            "As you might expect, the prediction for the next step will usually be more accurate\n",
            "\n",
            "--- Chunk 11229 ---\n",
            "than the predictions for later time steps, since the errors might accumulate (as you\n",
            "\n",
            "--- Chunk 11230 ---\n",
            "can see in Figure 15-8). If you evaluate this approach on the validation set, you will\n",
            "\n",
            "--- Chunk 11231 ---\n",
            "find an MSE of about 0.029. This is much higher than the previous models, but it’s\n",
            "\n",
            "--- Chunk 11232 ---\n",
            "also a much harder task, so the comparison doesn’t mean much. It’s much more\n",
            "\n",
            "--- Chunk 11233 ---\n",
            "meaningful to compare this performance with naive predictions (just forecasting that\n",
            "\n",
            "--- Chunk 11234 ---\n",
            "the time series will remain constant for 10 time steps) or with a simple linear model.\n",
            "\n",
            "--- Chunk 11235 ---\n",
            "The naive approach is terrible (it gives an MSE of about 0.223), but the linear model\n",
            "\n",
            "--- Chunk 11236 ---\n",
            "gives an MSE of about 0.0188: it’s much better than using our RNN to forecast the\n",
            "\n",
            "--- Chunk 11237 ---\n",
            "future one step at a time, and also much faster to train and run. Still, if you only want\n",
            "\n",
            "--- Chunk 11238 ---\n",
            "to forecast a few time steps ahead, on more complex tasks, this approach may work\n",
            "well.\n",
            "\n",
            "--- Chunk 11239 ---\n",
            "508 | Chapter 15: Processing Sequences Using RNNs and CNNs\n",
            "\n",
            "\n",
            "\n",
            "Figure 15-8. Forecasting 10 steps ahead, 1 step at a time\n",
            "\n",
            "--- Chunk 11240 ---\n",
            "The second option is to train an RNN to predict all 10 next values at once. We can\n",
            "\n",
            "--- Chunk 11241 ---\n",
            "still use a sequence-to-vector model, but it will output 10 values instead of 1. How‐\n",
            "\n",
            "--- Chunk 11242 ---\n",
            "ever, we first need to change the targets to be vectors containing the next 10 values:\n",
            "\n",
            "--- Chunk 11243 ---\n",
            "series = generate_time_series(10000, n_steps + 10)\n",
            "X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n",
            "\n",
            "--- Chunk 11244 ---\n",
            "X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
            "X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]\n",
            "\n",
            "--- Chunk 11245 ---\n",
            "Now we just need the output layer to have 10 units instead of 1:\n",
            "model = keras.models.Sequential([\n",
            "\n",
            "--- Chunk 11246 ---\n",
            "keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
            "    keras.layers.SimpleRNN(20),\n",
            "    keras.layers.Dense(10)\n",
            "])\n",
            "\n",
            "--- Chunk 11247 ---\n",
            "After training this model, you can predict the next 10 values at once very easily:\n",
            "Y_pred = model.predict(X_new)\n",
            "\n",
            "--- Chunk 11248 ---\n",
            "This model works nicely: the MSE for the next 10 time steps is about 0.008. That’s\n",
            "\n",
            "--- Chunk 11249 ---\n",
            "much better than the linear model. But we can still do better: indeed, instead of train‐\n",
            "\n",
            "--- Chunk 11250 ---\n",
            "ing the model to forecast the next 10 values only at the very last time step, we can\n",
            "\n",
            "--- Chunk 11251 ---\n",
            "train it to forecast the next 10 values at each and every time step. In other words, we\n",
            "\n",
            "--- Chunk 11252 ---\n",
            "can turn this sequence-to-vector RNN into a sequence-to-sequence RNN. The advan‐\n",
            "\n",
            "--- Chunk 11253 ---\n",
            "tage of this technique is that the loss will contain a term for the output of the RNN at\n",
            "\n",
            "--- Chunk 11254 ---\n",
            "each and every time step, not just the output at the last time step. This means there\n",
            "\n",
            "--- Chunk 11255 ---\n",
            "will be many more error gradients flowing through the model, and they won’t have to\n",
            "\n",
            "--- Chunk 11256 ---\n",
            "flow only through time; they will also flow from the output of each time step. This\n",
            "will both stabilize and speed up training.\n",
            "\n",
            "--- Chunk 11257 ---\n",
            "Forecasting a Time Series | 509\n",
            "\n",
            "--- Chunk 11258 ---\n",
            "To be clear, at time step 0 the model will output a vector containing the forecasts for\n",
            "\n",
            "--- Chunk 11259 ---\n",
            "time steps 1 to 10, then at time step 1 the model will forecast time steps 2 to 11, and\n",
            "\n",
            "--- Chunk 11260 ---\n",
            "so on. So each target must be a sequence of the same length as the input sequence,\n",
            "\n",
            "--- Chunk 11261 ---\n",
            "containing a 10-dimensional vector at each step. Let’s prepare these target sequences:\n",
            "\n",
            "--- Chunk 11262 ---\n",
            "Y = np.empty((10000, n_steps, 10)) # each target is a sequence of 10D vectors\n",
            "for step_ahead in range(1, 10 + 1):\n",
            "\n",
            "--- Chunk 11263 ---\n",
            "Y[:, :, step_ahead - 1] = series[:, step_ahead:step_ahead + n_steps, 0]\n",
            "Y_train = Y[:7000]\n",
            "Y_valid = Y[7000:9000]\n",
            "Y_test = Y[9000:]\n",
            "\n",
            "--- Chunk 11264 ---\n",
            "It may be surprising that the targets will contain values that appear\n",
            "in the inputs (there is a lot of overlap between X_train and\n",
            "\n",
            "--- Chunk 11265 ---\n",
            "Y_train). Isn’t that cheating? Fortunately, not at all: at each time\n",
            "step, the model only knows about past time steps, so it cannot look\n",
            "\n",
            "--- Chunk 11266 ---\n",
            "ahead. It is said to be a causal model.\n",
            "\n",
            "--- Chunk 11267 ---\n",
            "To turn the model into a sequence-to-sequence model, we must set return_sequen\n",
            "\n",
            "--- Chunk 11268 ---\n",
            "ces=True in all recurrent layers (even the last one), and we must apply the output\n",
            "\n",
            "--- Chunk 11269 ---\n",
            "Dense layer at every time step. Keras offers a TimeDistributed layer for this very pur‐\n",
            "\n",
            "--- Chunk 11270 ---\n",
            "pose: it wraps any layer (e.g., a Dense layer) and applies it at every time step of its\n",
            "\n",
            "--- Chunk 11271 ---\n",
            "input sequence. It does this efficiently, by reshaping the inputs so that each time step\n",
            "\n",
            "--- Chunk 11272 ---\n",
            "is treated as a separate instance (i.e., it reshapes the inputs from [batch size, time steps,\n",
            "\n",
            "--- Chunk 11273 ---\n",
            "input dimensions] to [batch size × time steps, input dimensions]; in this example, the\n",
            "\n",
            "--- Chunk 11274 ---\n",
            "number of input dimensions is 20 because the previous SimpleRNN layer has 20 units),\n",
            "\n",
            "--- Chunk 11275 ---\n",
            "then it runs the Dense layer, and finally it reshapes the outputs back to sequences (i.e.,\n",
            "\n",
            "--- Chunk 11276 ---\n",
            "it reshapes the outputs from [batch size × time steps, output dimensions] to [batch size,\n",
            "\n",
            "--- Chunk 11277 ---\n",
            "time steps, output dimensions]; in this example the number of output dimensions is\n",
            "\n",
            "--- Chunk 11278 ---\n",
            "10, since the Dense layer has 10 units).2 Here is the updated model:\n",
            "\n",
            "--- Chunk 11279 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
            "\n",
            "--- Chunk 11280 ---\n",
            "keras.layers.SimpleRNN(20, return_sequences=True),\n",
            "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
            "])\n",
            "\n",
            "--- Chunk 11281 ---\n",
            "The Dense layer actually supports sequences as inputs (and even higher-dimensional\n",
            "\n",
            "--- Chunk 11282 ---\n",
            "inputs): it handles them just like TimeDistributed(Dense(…)), meaning it is applied\n",
            "\n",
            "--- Chunk 11283 ---\n",
            "to the last input dimension only (independently across all time steps). Thus, we could\n",
            "\n",
            "--- Chunk 11284 ---\n",
            "replace the last layer with just Dense(10). For the sake of clarity, however, we will\n",
            "\n",
            "--- Chunk 11285 ---\n",
            "keep using TimeDistributed(Dense(10)) because it makes it clear that the Dense\n",
            "\n",
            "--- Chunk 11286 ---\n",
            "2 Note that a TimeDistributed(Dense(n)) layer is equivalent to a Conv1D(n, filter_size=1) layer.\n",
            "\n",
            "--- Chunk 11287 ---\n",
            "510 | Chapter 15: Processing Sequences Using RNNs and CNNs\n",
            "\n",
            "--- Chunk 11288 ---\n",
            "layer is applied independently at each time step and that the model will output a\n",
            "sequence, not just a single vector.\n",
            "\n",
            "--- Chunk 11289 ---\n",
            "All outputs are needed during training, but only the output at the last time step is\n",
            "\n",
            "--- Chunk 11290 ---\n",
            "useful for predictions and for evaluation. So although we will rely on the MSE over all\n",
            "\n",
            "--- Chunk 11291 ---\n",
            "the outputs for training, we will use a custom metric for evaluation, to only compute\n",
            "the MSE over the output at the last time step:\n",
            "\n",
            "--- Chunk 11292 ---\n",
            "def last_time_step_mse(Y_true, Y_pred):\n",
            "    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\n",
            "\n",
            "--- Chunk 11293 ---\n",
            "optimizer = keras.optimizers.Adam(lr=0.01)\n",
            "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[last_time_step_mse])\n",
            "\n",
            "--- Chunk 11294 ---\n",
            "We get a validation MSE of about 0.006, which is 25% better than the previous model.\n",
            "\n",
            "--- Chunk 11295 ---\n",
            "You can combine this approach with the first one: just predict the next 10 values\n",
            "\n",
            "--- Chunk 11296 ---\n",
            "using this RNN, then concatenate these values to the input time series and use the\n",
            "\n",
            "--- Chunk 11297 ---\n",
            "model again to predict the next 10 values, and repeat the process as many times as\n",
            "\n",
            "--- Chunk 11298 ---\n",
            "needed. With this approach, you can generate arbitrarily long sequences. It may not\n",
            "\n",
            "--- Chunk 11299 ---\n",
            "be very accurate for long-term predictions, but it may be just fine if your goal is to\n",
            "generate original music or text, as we will see in Chapter 16.\n",
            "\n",
            "--- Chunk 11300 ---\n",
            "When forecasting time series, it is often useful to have some error\n",
            "bars along with your predictions. For this, an efficient technique is\n",
            "\n",
            "--- Chunk 11301 ---\n",
            "MC Dropout, introduced in Chapter 11: add an MC Dropout layer\n",
            "within each memory cell, dropping part of the inputs and hidden\n",
            "\n",
            "--- Chunk 11302 ---\n",
            "states. After training, to forecast a new time series, use the model\n",
            "many times and compute the mean and standard deviation of the\n",
            "\n",
            "--- Chunk 11303 ---\n",
            "predictions at each time step.\n",
            "\n",
            "--- Chunk 11304 ---\n",
            "Simple RNNs can be quite good at forecasting time series or handling other kinds of\n",
            "\n",
            "--- Chunk 11305 ---\n",
            "sequences, but they do not perform as well on long time series or sequences. Let’s dis‐\n",
            "cuss why and see what we can do about it.\n",
            "\n",
            "--- Chunk 11306 ---\n",
            "Handling Long Sequences\n",
            "To train an RNN on long sequences, we must run it over many time steps, making the\n",
            "\n",
            "--- Chunk 11307 ---\n",
            "unrolled RNN a very deep network. Just like any deep neural network it may suffer\n",
            "\n",
            "--- Chunk 11308 ---\n",
            "from the unstable gradients problem, discussed in Chapter 11: it may take forever to\n",
            "\n",
            "--- Chunk 11309 ---\n",
            "train, or training may be unstable. Moreover, when an RNN processes a long\n",
            "\n",
            "--- Chunk 11310 ---\n",
            "sequence, it will gradually forget the first inputs in the sequence. Let’s look at both\n",
            "these problems, starting with the unstable gradients problem.\n",
            "\n",
            "--- Chunk 11311 ---\n",
            "Handling Long Sequences | 511\n",
            "\n",
            "--- Chunk 11312 ---\n",
            "Fighting the Unstable Gradients Problem\n",
            "Many of the tricks we used in deep nets to alleviate the unstable gradients problem\n",
            "\n",
            "--- Chunk 11313 ---\n",
            "can also be used for RNNs: good parameter initialization, faster optimizers, dropout,\n",
            "\n",
            "--- Chunk 11314 ---\n",
            "and so on. However, nonsaturating activation functions (e.g., ReLU) may not help as\n",
            "\n",
            "--- Chunk 11315 ---\n",
            "much here; in fact, they may actually lead the RNN to be even more unstable during\n",
            "\n",
            "--- Chunk 11316 ---\n",
            "training. Why? Well, suppose Gradient Descent updates the weights in a way that\n",
            "\n",
            "--- Chunk 11317 ---\n",
            "increases the outputs slightly at the first time step. Because the same weights are used\n",
            "\n",
            "--- Chunk 11318 ---\n",
            "at every time step, the outputs at the second time step may also be slightly increased,\n",
            "\n",
            "--- Chunk 11319 ---\n",
            "and those at the third, and so on until the outputs explode—and a nonsaturating acti‐\n",
            "\n",
            "--- Chunk 11320 ---\n",
            "vation function does not prevent that. You can reduce this risk by using a smaller\n",
            "\n",
            "--- Chunk 11321 ---\n",
            "learning rate, but you can also simply use a saturating activation function like the\n",
            "\n",
            "--- Chunk 11322 ---\n",
            "hyperbolic tangent (this explains why it is the default). In much the same way, the\n",
            "\n",
            "--- Chunk 11323 ---\n",
            "gradients themselves can explode. If you notice that training is unstable, you may\n",
            "\n",
            "--- Chunk 11324 ---\n",
            "want to monitor the size of the gradients (e.g., using TensorBoard) and perhaps use\n",
            "Gradient Clipping.\n",
            "\n",
            "--- Chunk 11325 ---\n",
            "Gradient Clipping.\n",
            "Moreover, Batch Normalization cannot be used as efficiently with RNNs as with deep\n",
            "\n",
            "--- Chunk 11326 ---\n",
            "feedforward nets. In fact, you cannot use it between time steps, only between recur‐\n",
            "\n",
            "--- Chunk 11327 ---\n",
            "rent layers. To be more precise, it is technically possible to add a BN layer to a mem‐\n",
            "\n",
            "--- Chunk 11328 ---\n",
            "ory cell (as we will see shortly) so that it will be applied at each time step (both on the\n",
            "\n",
            "--- Chunk 11329 ---\n",
            "inputs for that time step and on the hidden state from the previous step). However,\n",
            "\n",
            "--- Chunk 11330 ---\n",
            "the same BN layer will be used at each time step, with the same parameters, regardless\n",
            "\n",
            "--- Chunk 11331 ---\n",
            "of the actual scale and offset of the inputs and hidden state. In practice, this does not\n",
            "\n",
            "--- Chunk 11332 ---\n",
            "yield good results, as was demonstrated by César Laurent et al. in a 2015 paper:3 the\n",
            "\n",
            "--- Chunk 11333 ---\n",
            "authors found that BN was slightly beneficial only when it was applied to the inputs,\n",
            "\n",
            "--- Chunk 11334 ---\n",
            "not to the hidden states. In other words, it was slightly better than nothing when\n",
            "\n",
            "--- Chunk 11335 ---\n",
            "applied between recurrent layers (i.e., vertically in Figure 15-7), but not within recur‐\n",
            "\n",
            "--- Chunk 11336 ---\n",
            "rent layers (i.e., horizontally). In Keras this can be done simply by adding a Batch\n",
            "\n",
            "--- Chunk 11337 ---\n",
            "Normalization layer before each recurrent layer, but don’t expect too much from it.\n",
            "\n",
            "--- Chunk 11338 ---\n",
            "Another form of normalization often works better with RNNs: Layer Normalization.\n",
            "\n",
            "--- Chunk 11339 ---\n",
            "This idea was introduced by Jimmy Lei Ba et al. in a 2016 paper:4 it is very similar to\n",
            "\n",
            "--- Chunk 11340 ---\n",
            "Batch Normalization, but instead of normalizing across the batch dimension, it nor‐\n",
            "\n",
            "--- Chunk 11341 ---\n",
            "malizes across the features dimension. One advantage is that it can compute the\n",
            "\n",
            "--- Chunk 11342 ---\n",
            "required statistics on the fly, at each time step, independently for each instance. This\n",
            "\n",
            "--- Chunk 11343 ---\n",
            "also means that it behaves the same way during training and testing (as opposed to\n",
            "\n",
            "--- Chunk 11344 ---\n",
            "BN), and it does not need to use exponential moving averages to estimate the feature\n",
            "\n",
            "--- Chunk 11345 ---\n",
            "statistics across all instances in the training set. Like BN, Layer Normalization learns a\n",
            "\n",
            "--- Chunk 11346 ---\n",
            "3 César Laurent et al., “Batch Normalized Recurrent Neural Networks,” Proceedings of the IEEE International\n",
            "\n",
            "--- Chunk 11347 ---\n",
            "Conference on Acoustics, Speech, and Signal Processing (2016): 2657–2661.\n",
            "\n",
            "--- Chunk 11348 ---\n",
            "4 Jimmy Lei Ba et al., “Layer Normalization,” arXiv preprint arXiv:1607.06450 (2016).\n",
            "\n",
            "512 | Chapter 15: Processing Sequences Using RNNs and CNNs\n",
            "\n",
            "--- Chunk 11349 ---\n",
            "scale and an offset parameter for each input. In an RNN, it is typically used right after\n",
            "\n",
            "--- Chunk 11350 ---\n",
            "the linear combination of the inputs and the hidden states.\n",
            "Let’s use tf.keras to implement Layer Normalization within a simple memory cell. For\n",
            "\n",
            "--- Chunk 11351 ---\n",
            "this, we need to define a custom memory cell. It is just like a regular layer, except its\n",
            "\n",
            "--- Chunk 11352 ---\n",
            "call() method takes two arguments: the inputs at the current time step and the hid‐\n",
            "\n",
            "--- Chunk 11353 ---\n",
            "den states from the previous time step. Note that the states argument is a list con‐\n",
            "\n",
            "--- Chunk 11354 ---\n",
            "taining one or more tensors. In the case of a simple RNN cell it contains a single\n",
            "\n",
            "--- Chunk 11355 ---\n",
            "tensor equal to the outputs of the previous time step, but other cells may have multi‐\n",
            "\n",
            "--- Chunk 11356 ---\n",
            "ple state tensors (e.g., an LSTMCell has a long-term state and a short-term state, as we\n",
            "\n",
            "--- Chunk 11357 ---\n",
            "will see shortly). A cell must also have a state_size attribute and an output_size\n",
            "\n",
            "--- Chunk 11358 ---\n",
            "attribute. In a simple RNN, both are simply equal to the number of units. The follow‐\n",
            "\n",
            "--- Chunk 11359 ---\n",
            "ing code implements a custom memory cell which will behave like a SimpleRNNCell,\n",
            "except it will also apply Layer Normalization at each time step:\n",
            "\n",
            "--- Chunk 11360 ---\n",
            "class LNSimpleRNNCell(keras.layers.Layer):\n",
            "    def __init__(self, units, activation=\"tanh\", **kwargs):\n",
            "        super().__init__(**kwargs)\n",
            "\n",
            "--- Chunk 11361 ---\n",
            "self.state_size = units\n",
            "        self.output_size = units\n",
            "        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units,\n",
            "\n",
            "--- Chunk 11362 ---\n",
            "activation=None)\n",
            "        self.layer_norm = keras.layers.LayerNormalization()\n",
            "\n",
            "--- Chunk 11363 ---\n",
            "self.activation = keras.activations.get(activation)\n",
            "    def call(self, inputs, states):\n",
            "\n",
            "--- Chunk 11364 ---\n",
            "outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
            "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
            "\n",
            "--- Chunk 11365 ---\n",
            "return norm_outputs, [norm_outputs]\n",
            "\n",
            "--- Chunk 11366 ---\n",
            "The code is quite straightforward.5 Our LNSimpleRNNCell class inherits from the\n",
            "\n",
            "--- Chunk 11367 ---\n",
            "keras.layers.Layer class, just like any custom layer. The constructor takes the num‐\n",
            "\n",
            "--- Chunk 11368 ---\n",
            "ber of units and the desired activation function, and it sets the state_size and\n",
            "\n",
            "--- Chunk 11369 ---\n",
            "output_size attributes, then creates a SimpleRNNCell with no activation function\n",
            "\n",
            "--- Chunk 11370 ---\n",
            "(because we want to perform Layer Normalization after the linear operation but\n",
            "\n",
            "--- Chunk 11371 ---\n",
            "before the activation function). Then the constructor creates the LayerNormaliza\n",
            "\n",
            "--- Chunk 11372 ---\n",
            "tion layer, and finally it fetches the desired activation function. The call() method\n",
            "\n",
            "--- Chunk 11373 ---\n",
            "starts by applying the simple RNN cell, which computes a linear combination of the\n",
            "\n",
            "--- Chunk 11374 ---\n",
            "current inputs and the previous hidden states, and it returns the result twice (indeed,\n",
            "\n",
            "--- Chunk 11375 ---\n",
            "in a SimpleRNNCell, the outputs are just equal to the hidden states: in other words,\n",
            "\n",
            "--- Chunk 11376 ---\n",
            "new_states[0] is equal to outputs, so we can safely ignore new_states in the rest of\n",
            "\n",
            "--- Chunk 11377 ---\n",
            "the call() method). Next, the call() method applies Layer Normalization, followed\n",
            "\n",
            "--- Chunk 11378 ---\n",
            "5 It would have been simpler to inherit from SimpleRNNCell instead so that we wouldn’t have to create an inter‐\n",
            "\n",
            "--- Chunk 11379 ---\n",
            "nal SimpleRNNCell or handle the state_size and output_size attributes, but the goal here was to show how\n",
            "to create a custom cell from scratch.\n",
            "\n",
            "--- Chunk 11380 ---\n",
            "Handling Long Sequences | 513\n",
            "\n",
            "--- Chunk 11381 ---\n",
            "by the activation function. Finally, it returns the outputs twice (once as the outputs,\n",
            "\n",
            "--- Chunk 11382 ---\n",
            "and once as the new hidden states). To use this custom cell, all we need to do is create\n",
            "a keras.layers.RNN layer, passing it a cell instance:\n",
            "\n",
            "--- Chunk 11383 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True,\n",
            "                     input_shape=[None, 1]),\n",
            "\n",
            "--- Chunk 11384 ---\n",
            "keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),\n",
            "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
            "])\n",
            "\n",
            "--- Chunk 11385 ---\n",
            "Similarly, you could create a custom cell to apply dropout between each time step. But\n",
            "\n",
            "--- Chunk 11386 ---\n",
            "there’s a simpler way: all recurrent layers (except for keras.layers.RNN) and all cells\n",
            "\n",
            "--- Chunk 11387 ---\n",
            "provided by Keras have a dropout hyperparameter and a recurrent_dropout hyper‐\n",
            "\n",
            "--- Chunk 11388 ---\n",
            "parameter: the former defines the dropout rate to apply to the inputs (at each time\n",
            "\n",
            "--- Chunk 11389 ---\n",
            "step), and the latter defines the dropout rate for the hidden states (also at each time\n",
            "\n",
            "--- Chunk 11390 ---\n",
            "step). No need to create a custom cell to apply dropout at each time step in an RNN.\n",
            "\n",
            "--- Chunk 11391 ---\n",
            "With these techniques, you can alleviate the unstable gradients problem and train an\n",
            "\n",
            "--- Chunk 11392 ---\n",
            "RNN much more efficiently. Now let’s look at how to deal with the short-term mem‐\n",
            "ory problem.\n",
            "\n",
            "--- Chunk 11393 ---\n",
            "Tackling the Short-Term Memory Problem\n",
            "Due to the transformations that the data goes through when traversing an RNN,\n",
            "\n",
            "--- Chunk 11394 ---\n",
            "some information is lost at each time step. After a while, the RNN’s state contains vir‐\n",
            "\n",
            "--- Chunk 11395 ---\n",
            "tually no trace of the first inputs. This can be a showstopper. Imagine Dory the fish6\n",
            "\n",
            "--- Chunk 11396 ---\n",
            "trying to translate a long sentence; by the time she’s finished reading it, she has no\n",
            "\n",
            "--- Chunk 11397 ---\n",
            "clue how it started. To tackle this problem, various types of cells with long-term\n",
            "\n",
            "--- Chunk 11398 ---\n",
            "memory have been introduced. They have proven so successful that the basic cells are\n",
            "\n",
            "--- Chunk 11399 ---\n",
            "not used much anymore. Let’s first look at the most popular of these long-term mem‐\n",
            "ory cells: the LSTM cell.\n",
            "\n",
            "--- Chunk 11400 ---\n",
            "LSTM cells\n",
            "The Long Short-Term Memory (LSTM) cell was proposed in 19977 by Sepp Hochreiter\n",
            "\n",
            "--- Chunk 11401 ---\n",
            "and Jürgen Schmidhuber and gradually improved over the years by several research‐\n",
            "\n",
            "--- Chunk 11402 ---\n",
            "ers, such as Alex Graves, Haşim Sak,8 and Wojciech Zaremba.9 If you consider the\n",
            "\n",
            "--- Chunk 11403 ---\n",
            "6 A character from the animated movies Finding Nemo and Finding Dory who has short-term memory loss.\n",
            "\n",
            "--- Chunk 11404 ---\n",
            "7 Sepp Hochreiter and Jürgen Schmidhuber, “Long Short-Term Memory,” Neural Computation 9, no. 8 (1997):\n",
            "\n",
            "--- Chunk 11405 ---\n",
            "1735–1780.\n",
            "8 Haşim Sak et al., “Long Short-Term Memory Based Recurrent Neural Network Architectures for Large\n",
            "\n",
            "--- Chunk 11406 ---\n",
            "Vocabulary Speech Recognition,” arXiv preprint arXiv:1402.1128 (2014).\n",
            "\n",
            "--- Chunk 11407 ---\n",
            "9 Wojciech Zaremba et al., “Recurrent Neural Network Regularization,” arXiv preprint arXiv:1409.2329 (2014).\n",
            "\n",
            "--- Chunk 11408 ---\n",
            "514 | Chapter 15: Processing Sequences Using RNNs and CNNs\n",
            "\n",
            "--- Chunk 11409 ---\n",
            "LSTM cell as a black box, it can be used very much like a basic cell, except it will per‐\n",
            "\n",
            "--- Chunk 11410 ---\n",
            "form much better; training will converge faster, and it will detect long-term depen‐\n",
            "\n",
            "--- Chunk 11411 ---\n",
            "dencies in the data. In Keras, you can simply use the LSTM layer instead of the\n",
            "SimpleRNN layer:\n",
            "\n",
            "--- Chunk 11412 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),\n",
            "\n",
            "--- Chunk 11413 ---\n",
            "keras.layers.LSTM(20, return_sequences=True),\n",
            "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
            "])\n",
            "\n",
            "--- Chunk 11414 ---\n",
            "Alternatively, you could use the general-purpose keras.layers.RNN layer, giving it an\n",
            "LSTMCell as an argument:\n",
            "\n",
            "--- Chunk 11415 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.RNN(keras.layers.LSTMCell(20), return_sequences=True,\n",
            "\n",
            "--- Chunk 11416 ---\n",
            "input_shape=[None, 1]),\n",
            "    keras.layers.RNN(keras.layers.LSTMCell(20), return_sequences=True),\n",
            "\n",
            "--- Chunk 11417 ---\n",
            "keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
            "])\n",
            "\n",
            "--- Chunk 11418 ---\n",
            "However, the LSTM layer uses an optimized implementation when running on a GPU\n",
            "\n",
            "--- Chunk 11419 ---\n",
            "(see Chapter 19), so in general it is preferable to use it (the RNN layer is mostly useful\n",
            "when you define custom cells, as we did earlier).\n",
            "\n",
            "--- Chunk 11420 ---\n",
            "So how does an LSTM cell work? Its architecture is shown in Figure 15-9.\n",
            "\n",
            "--- Chunk 11421 ---\n",
            "If you don’t look at what’s inside the box, the LSTM cell looks exactly like a regular\n",
            "\n",
            "--- Chunk 11422 ---\n",
            "cell, except that its state is split into two vectors: h(t) and c(t) (“c” stands for “cell”). You\n",
            "\n",
            "--- Chunk 11423 ---\n",
            "can think of h(t) as the short-term state and c(t) as the long-term state.\n",
            "\n",
            "--- Chunk 11424 ---\n",
            "Handling Long Sequences | 515\n",
            "\n",
            "\n",
            "\n",
            "Figure 15-9. LSTM cell\n",
            "\n",
            "--- Chunk 11425 ---\n",
            "Now let’s open the box! The key idea is that the network can learn what to store in the\n",
            "\n",
            "--- Chunk 11426 ---\n",
            "long-term state, what to throw away, and what to read from it. As the long-term state\n",
            "\n",
            "--- Chunk 11427 ---\n",
            "c(t–1) traverses the network from left to right, you can see that it first goes through a\n",
            "\n",
            "--- Chunk 11428 ---\n",
            "forget gate, dropping some memories, and then it adds some new memories via the\n",
            "\n",
            "--- Chunk 11429 ---\n",
            "addition operation (which adds the memories that were selected by an input gate).\n",
            "\n",
            "--- Chunk 11430 ---\n",
            "The result c(t) is sent straight out, without any further transformation. So, at each time\n",
            "\n",
            "--- Chunk 11431 ---\n",
            "step, some memories are dropped and some memories are added. Moreover, after the\n",
            "\n",
            "--- Chunk 11432 ---\n",
            "addition operation, the long-term state is copied and passed through the tanh func‐\n",
            "\n",
            "--- Chunk 11433 ---\n",
            "tion, and then the result is filtered by the output gate. This produces the short-term\n",
            "\n",
            "--- Chunk 11434 ---\n",
            "state h(t) (which is equal to the cell’s output for this time step, y(t)). Now let’s look at\n",
            "where new memories come from and how the gates work.\n",
            "\n",
            "--- Chunk 11435 ---\n",
            "First, the current input vector x(t) and the previous short-term state h(t–1) are fed to\n",
            "\n",
            "--- Chunk 11436 ---\n",
            "four different fully connected layers. They all serve a different purpose:\n",
            "\n",
            "--- Chunk 11437 ---\n",
            "• The main layer is the one that outputs g(t). It has the usual role of analyzing the\n",
            "\n",
            "--- Chunk 11438 ---\n",
            "current inputs x(t) and the previous (short-term) state h(t–1). In a basic cell, there is\n",
            "\n",
            "--- Chunk 11439 ---\n",
            "nothing other than this layer, and its output goes straight out to y(t) and h(t). In\n",
            "\n",
            "--- Chunk 11440 ---\n",
            "contrast, in an LSTM cell this layer’s output does not go straight out, but instead\n",
            "\n",
            "--- Chunk 11441 ---\n",
            "its most important parts are stored in the long-term state (and the rest is\n",
            "dropped).\n",
            "\n",
            "--- Chunk 11442 ---\n",
            "• The three other layers are gate controllers. Since they use the logistic activation\n",
            "\n",
            "--- Chunk 11443 ---\n",
            "function, their outputs range from 0 to 1. As you can see, their outputs are fed to\n",
            "\n",
            "--- Chunk 11444 ---\n",
            "516 | Chapter 15: Processing Sequences Using RNNs and CNNs\n",
            "\n",
            "--- Chunk 11445 ---\n",
            "element-wise multiplication operations, so if they output 0s they close the gate,\n",
            "and if they output 1s they open it. Specifically:\n",
            "\n",
            "--- Chunk 11446 ---\n",
            "— The forget gate (controlled by f(t)) controls which parts of the long-term state\n",
            "\n",
            "--- Chunk 11447 ---\n",
            "should be erased.\n",
            "— The input gate (controlled by i(t)) controls which parts of g(t) should be added\n",
            "\n",
            "--- Chunk 11448 ---\n",
            "to the long-term state.\n",
            "— Finally, the output gate (controlled by o(t)) controls which parts of the long-\n",
            "\n",
            "--- Chunk 11449 ---\n",
            "term state should be read and output at this time step, both to h(t) and to y(t).\n",
            "\n",
            "--- Chunk 11450 ---\n",
            "In short, an LSTM cell can learn to recognize an important input (that’s the role of the\n",
            "\n",
            "--- Chunk 11451 ---\n",
            "input gate), store it in the long-term state, preserve it for as long as it is needed (that’s\n",
            "\n",
            "--- Chunk 11452 ---\n",
            "the role of the forget gate), and extract it whenever it is needed. This explains why\n",
            "\n",
            "--- Chunk 11453 ---\n",
            "these cells have been amazingly successful at capturing long-term patterns in time\n",
            "series, long texts, audio recordings, and more.\n",
            "\n",
            "--- Chunk 11454 ---\n",
            "Equation 15-3 summarizes how to compute the cell’s long-term state, its short-term\n",
            "\n",
            "--- Chunk 11455 ---\n",
            "state, and its output at each time step for a single instance (the equations for a whole\n",
            "mini-batch are very similar).\n",
            "\n",
            "--- Chunk 11456 ---\n",
            "Equation 15-3. LSTM computations\n",
            "i ⊺\n",
            "\n",
            "t = σ Wxi x t + W ⊺\n",
            "hi h t − 1 + bi\n",
            "\n",
            "f t = σ W ⊺ ⊺\n",
            "x f x t + Wh f h t − 1 + b f\n",
            "\n",
            "o t = σ W ⊺\n",
            "xo x t + W ⊺\n",
            "\n",
            "--- Chunk 11457 ---\n",
            "ho h t − 1 + bo\n",
            "\n",
            "g t = tanh W ⊺ ⊺\n",
            "xg x t + Whg h t − 1 + bg\n",
            "\n",
            "c t = f t ⊗ c t − 1 + i t ⊗ g t\n",
            "\n",
            "y t = h t = o t ⊗ tanh c t\n",
            "\n",
            "In this equation:\n",
            "\n",
            "--- Chunk 11458 ---\n",
            "In this equation:\n",
            "\n",
            "• Wxi, Wxf, Wxo, Wxg are the weight matrices of each of the four layers for their con‐\n",
            "nection to the input vector x(t).\n",
            "\n",
            "--- Chunk 11459 ---\n",
            "• Whi, Whf, Who, and Whg are the weight matrices of each of the four layers for their\n",
            "connection to the previous short-term state h(t–1).\n",
            "\n",
            "--- Chunk 11460 ---\n",
            "• bi, bf, bo, and bg are the bias terms for each of the four layers. Note that Tensor‐\n",
            "\n",
            "--- Chunk 11461 ---\n",
            "Flow initializes bf to a vector full of 1s instead of 0s. This prevents forgetting\n",
            "everything at the beginning of training.\n",
            "\n",
            "--- Chunk 11462 ---\n",
            "Handling Long Sequences | 517\n",
            "\n",
            "--- Chunk 11463 ---\n",
            "Peephole connections\n",
            "In a regular LSTM cell, the gate controllers can look only at the input x(t) and the pre‐\n",
            "\n",
            "--- Chunk 11464 ---\n",
            "vious short-term state h(t–1). It may be a good idea to give them a bit more context by\n",
            "\n",
            "--- Chunk 11465 ---\n",
            "letting them peek at the long-term state as well. This idea was proposed by Felix Gers\n",
            "\n",
            "--- Chunk 11466 ---\n",
            "and Jürgen Schmidhuber in 2000.10 They proposed an LSTM variant with extra con‐\n",
            "\n",
            "--- Chunk 11467 ---\n",
            "nections called peephole connections: the previous long-term state c(t–1) is added as an\n",
            "\n",
            "--- Chunk 11468 ---\n",
            "input to the controllers of the forget gate and the input gate, and the current long-\n",
            "\n",
            "--- Chunk 11469 ---\n",
            "term state c(t) is added as input to the controller of the output gate. This often\n",
            "\n",
            "--- Chunk 11470 ---\n",
            "improves performance, but not always, and there is no clear pattern for which tasks\n",
            "\n",
            "--- Chunk 11471 ---\n",
            "are better off with or without them: you will have to try it on your task and see if it\n",
            "helps.\n",
            "\n",
            "--- Chunk 11472 ---\n",
            "helps.\n",
            "In Keras, the LSTM layer is based on the keras.layers.LSTMCell cell, which does not\n",
            "\n",
            "--- Chunk 11473 ---\n",
            "support peepholes. The experimental tf.keras.experimental.PeepholeLSTMCell\n",
            "\n",
            "--- Chunk 11474 ---\n",
            "does, however, so you can create a keras.layers.RNN layer and pass a PeepholeLSTM\n",
            "Cell to its constructor.\n",
            "\n",
            "--- Chunk 11475 ---\n",
            "There are many other variants of the LSTM cell. One particularly popular variant is\n",
            "the GRU cell, which we will look at now.\n",
            "\n",
            "--- Chunk 11476 ---\n",
            "GRU cells\n",
            "The Gated Recurrent Unit (GRU) cell (see Figure 15-10) was proposed by Kyunghyun\n",
            "\n",
            "--- Chunk 11477 ---\n",
            "Cho et al. in a 2014 paper11 that also introduced the Encoder–Decoder network we\n",
            "discussed earlier.\n",
            "\n",
            "--- Chunk 11478 ---\n",
            "10 F. A. Gers and J. Schmidhuber, “Recurrent Nets That Time and Count,” Proceedings of the IEEE-INNS-ENNS\n",
            "\n",
            "--- Chunk 11479 ---\n",
            "International Joint Conference on Neural Networks (2000): 189–194.\n",
            "\n",
            "--- Chunk 11480 ---\n",
            "11 Kyunghyun Cho et al., “Learning Phrase Representations Using RNN Encoder-Decoder for Statistical\n",
            "\n",
            "--- Chunk 11481 ---\n",
            "Machine Translation,” Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing\n",
            "(2014): 1724–1734.\n",
            "\n",
            "--- Chunk 11482 ---\n",
            "518 | Chapter 15: Processing Sequences Using RNNs and CNNs\n",
            "\n",
            "\n",
            "\n",
            "Figure 15-10. GRU cell\n",
            "\n",
            "--- Chunk 11483 ---\n",
            "The GRU cell is a simplified version of the LSTM cell, and it seems to perform just as\n",
            "\n",
            "--- Chunk 11484 ---\n",
            "well12 (which explains its growing popularity). These are the main simplifications:\n",
            "\n",
            "--- Chunk 11485 ---\n",
            "• Both state vectors are merged into a single vector h(t).\n",
            "• A single gate controller z(t) controls both the forget gate and the input gate. If the\n",
            "\n",
            "--- Chunk 11486 ---\n",
            "gate controller outputs a 1, the forget gate is open (= 1) and the input gate is\n",
            "\n",
            "--- Chunk 11487 ---\n",
            "closed (1 – 1 = 0). If it outputs a 0, the opposite happens. In other words, when‐\n",
            "\n",
            "--- Chunk 11488 ---\n",
            "ever a memory must be stored, the location where it will be stored is erased first.\n",
            "\n",
            "--- Chunk 11489 ---\n",
            "This is actually a frequent variant to the LSTM cell in and of itself.\n",
            "\n",
            "--- Chunk 11490 ---\n",
            "• There is no output gate; the full state vector is output at every time step. How‐\n",
            "\n",
            "--- Chunk 11491 ---\n",
            "ever, there is a new gate controller r(t) that controls which part of the previous\n",
            "state will be shown to the main layer (g(t)).\n",
            "\n",
            "--- Chunk 11492 ---\n",
            "12 A 2015 paper by Klaus Greff et al., “LSTM: A Search Space Odyssey”, seems to show that all LSTM variants\n",
            "perform roughly the same.\n",
            "\n",
            "--- Chunk 11493 ---\n",
            "Handling Long Sequences | 519\n",
            "\n",
            "\n",
            "\n",
            "Equation 15-4 summarizes how to compute the cell’s state at each time step for a sin‐\n",
            "gle instance.\n",
            "\n",
            "--- Chunk 11494 ---\n",
            "Equation 15-4. GRU computations\n",
            "z t = σ W ⊺\n",
            "\n",
            "xz x t + W ⊺\n",
            "hz h t − 1 + bz\n",
            "\n",
            "r t = σ W ⊺ ⊺\n",
            "xr x t + Whr h t − 1 + br\n",
            "\n",
            "--- Chunk 11495 ---\n",
            "g t = tanh W ⊺ ⊺\n",
            "xg x t + Whg r t ⊗ h t − 1 + bg\n",
            "\n",
            "h t = z t ⊗ h t − 1 + 1 − z t ⊗ g t\n",
            "\n",
            "--- Chunk 11496 ---\n",
            "Keras provides a keras.layers.GRU layer (based on the keras.layers.GRUCell\n",
            "\n",
            "--- Chunk 11497 ---\n",
            "memory cell); using it is just a matter of replacing SimpleRNN or LSTM with GRU.\n",
            "\n",
            "--- Chunk 11498 ---\n",
            "LSTM and GRU cells are one of the main reasons behind the success of RNNs. Yet\n",
            "\n",
            "--- Chunk 11499 ---\n",
            "while they can tackle much longer sequences than simple RNNs, they still have a\n",
            "\n",
            "--- Chunk 11500 ---\n",
            "fairly limited short-term memory, and they have a hard time learning long-term pat‐\n",
            "\n",
            "--- Chunk 11501 ---\n",
            "terns in sequences of 100 time steps or more, such as audio samples, long time series,\n",
            "\n",
            "--- Chunk 11502 ---\n",
            "or long sentences. One way to solve this is to shorten the input sequences, for exam‐\n",
            "ple using 1D convolutional layers.\n",
            "\n",
            "--- Chunk 11503 ---\n",
            "Using 1D convolutional layers to process sequences\n",
            "In Chapter 14, we saw that a 2D convolutional layer works by sliding several fairly\n",
            "\n",
            "--- Chunk 11504 ---\n",
            "small kernels (or filters) across an image, producing multiple 2D feature maps (one\n",
            "\n",
            "--- Chunk 11505 ---\n",
            "per kernel). Similarly, a 1D convolutional layer slides several kernels across a\n",
            "\n",
            "--- Chunk 11506 ---\n",
            "sequence, producing a 1D feature map per kernel. Each kernel will learn to detect a\n",
            "\n",
            "--- Chunk 11507 ---\n",
            "single very short sequential pattern (no longer than the kernel size). If you use 10 ker‐\n",
            "\n",
            "--- Chunk 11508 ---\n",
            "nels, then the layer’s output will be composed of 10 1-dimensional sequences (all of\n",
            "\n",
            "--- Chunk 11509 ---\n",
            "the same length), or equivalently you can view this output as a single 10-dimensional\n",
            "\n",
            "--- Chunk 11510 ---\n",
            "sequence. This means that you can build a neural network composed of a mix of\n",
            "\n",
            "--- Chunk 11511 ---\n",
            "recurrent layers and 1D convolutional layers (or even 1D pooling layers). If you use a\n",
            "\n",
            "--- Chunk 11512 ---\n",
            "1D convolutional layer with a stride of 1 and \"same\" padding, then the output\n",
            "\n",
            "--- Chunk 11513 ---\n",
            "sequence will have the same length as the input sequence. But if you use \"valid\"\n",
            "\n",
            "--- Chunk 11514 ---\n",
            "padding or a stride greater than 1, then the output sequence will be shorter than the\n",
            "\n",
            "--- Chunk 11515 ---\n",
            "input sequence, so make sure you adjust the targets accordingly. For example, the fol‐\n",
            "\n",
            "--- Chunk 11516 ---\n",
            "lowing model is the same as earlier, except it starts with a 1D convolutional layer that\n",
            "\n",
            "--- Chunk 11517 ---\n",
            "downsamples the input sequence by a factor of 2, using a stride of 2. The kernel size is\n",
            "\n",
            "--- Chunk 11518 ---\n",
            "larger than the stride, so all inputs will be used to compute the layer’s output, and\n",
            "\n",
            "--- Chunk 11519 ---\n",
            "therefore the model can learn to preserve the useful information, dropping only the\n",
            "\n",
            "--- Chunk 11520 ---\n",
            "unimportant details. By shortening the sequences, the convolutional layer may help\n",
            "\n",
            "--- Chunk 11521 ---\n",
            "the GRU layers detect longer patterns. Note that we must also crop off the first three\n",
            "\n",
            "--- Chunk 11522 ---\n",
            "520 | Chapter 15: Processing Sequences Using RNNs and CNNs\n",
            "\n",
            "--- Chunk 11523 ---\n",
            "time steps in the targets (since the kernel’s size is 4, the first output of the convolu‐\n",
            "\n",
            "--- Chunk 11524 ---\n",
            "tional layer will be based on the input time steps 0 to 3), and downsample the targets\n",
            "by a factor of 2:\n",
            "\n",
            "--- Chunk 11525 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding=\"valid\",\n",
            "\n",
            "--- Chunk 11526 ---\n",
            "input_shape=[None, 1]),\n",
            "    keras.layers.GRU(20, return_sequences=True),\n",
            "    keras.layers.GRU(20, return_sequences=True),\n",
            "\n",
            "--- Chunk 11527 ---\n",
            "keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
            "])\n",
            "\n",
            "--- Chunk 11528 ---\n",
            "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
            "history = model.fit(X_train, Y_train[:, 3::2], epochs=20,\n",
            "\n",
            "--- Chunk 11529 ---\n",
            "validation_data=(X_valid, Y_valid[:, 3::2]))\n",
            "\n",
            "--- Chunk 11530 ---\n",
            "If you train and evaluate this model, you will find that it is the best model so far. The\n",
            "\n",
            "--- Chunk 11531 ---\n",
            "convolutional layer really helps. In fact, it is actually possible to use only 1D convolu‐\n",
            "tional layers and drop the recurrent layers entirely!\n",
            "\n",
            "--- Chunk 11532 ---\n",
            "WaveNet\n",
            "In a 2016 paper,13 Aaron van den Oord and other DeepMind researchers introduced\n",
            "\n",
            "--- Chunk 11533 ---\n",
            "an architecture called WaveNet. They stacked 1D convolutional layers, doubling the\n",
            "\n",
            "--- Chunk 11534 ---\n",
            "dilation rate (how spread apart each neuron’s inputs are) at every layer: the first con‐\n",
            "\n",
            "--- Chunk 11535 ---\n",
            "volutional layer gets a glimpse of just two time steps at a time, while the next one sees\n",
            "\n",
            "--- Chunk 11536 ---\n",
            "four time steps (its receptive field is four time steps long), the next one sees eight time\n",
            "\n",
            "--- Chunk 11537 ---\n",
            "steps, and so on (see Figure 15-11). This way, the lower layers learn short-term pat‐\n",
            "\n",
            "--- Chunk 11538 ---\n",
            "terns, while the higher layers learn long-term patterns. Thanks to the doubling dila‐\n",
            "\n",
            "--- Chunk 11539 ---\n",
            "tion rate, the network can process extremely large sequences very efficiently.\n",
            "\n",
            "--- Chunk 11540 ---\n",
            "13 Aaron van den Oord et al., “WaveNet: A Generative Model for Raw Audio,” arXiv preprint arXiv:1609.03499\n",
            "(2016).\n",
            "\n",
            "Handling Long Sequences | 521\n",
            "\n",
            "--- Chunk 11541 ---\n",
            "Figure 15-11. WaveNet architecture\n",
            "\n",
            "--- Chunk 11542 ---\n",
            "In the WaveNet paper, the authors actually stacked 10 convolutional layers with dila‐\n",
            "\n",
            "--- Chunk 11543 ---\n",
            "tion rates of 1, 2, 4, 8, …, 256, 512, then they stacked another group of 10 identical\n",
            "\n",
            "--- Chunk 11544 ---\n",
            "layers (also with dilation rates 1, 2, 4, 8, …, 256, 512), then again another identical\n",
            "\n",
            "--- Chunk 11545 ---\n",
            "group of 10 layers. They justified this architecture by pointing out that a single stack\n",
            "\n",
            "--- Chunk 11546 ---\n",
            "of 10 convolutional layers with these dilation rates will act like a super-efficient con‐\n",
            "\n",
            "--- Chunk 11547 ---\n",
            "volutional layer with a kernel of size 1,024 (except way faster, more powerful, and\n",
            "\n",
            "--- Chunk 11548 ---\n",
            "using significantly fewer parameters), which is why they stacked 3 such blocks. They\n",
            "\n",
            "--- Chunk 11549 ---\n",
            "also left-padded the input sequences with a number of zeros equal to the dilation rate\n",
            "\n",
            "--- Chunk 11550 ---\n",
            "before every layer, to preserve the same sequence length throughout the network.\n",
            "\n",
            "--- Chunk 11551 ---\n",
            "Here is how to implement a simplified WaveNet to tackle the same sequences as\n",
            "earlier:14\n",
            "\n",
            "--- Chunk 11552 ---\n",
            "model = keras.models.Sequential()\n",
            "model.add(keras.layers.InputLayer(input_shape=[None, 1]))\n",
            "for rate in (1, 2, 4, 8) * 2:\n",
            "\n",
            "--- Chunk 11553 ---\n",
            "model.add(keras.layers.Conv1D(filters=20, kernel_size=2, padding=\"causal\",\n",
            "\n",
            "--- Chunk 11554 ---\n",
            "activation=\"relu\", dilation_rate=rate))\n",
            "model.add(keras.layers.Conv1D(filters=10, kernel_size=1))\n",
            "\n",
            "--- Chunk 11555 ---\n",
            "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
            "history = model.fit(X_train, Y_train, epochs=20,\n",
            "\n",
            "--- Chunk 11556 ---\n",
            "validation_data=(X_valid, Y_valid))\n",
            "\n",
            "--- Chunk 11557 ---\n",
            "This Sequential model starts with an explicit input layer (this is simpler than trying\n",
            "\n",
            "--- Chunk 11558 ---\n",
            "to set input_shape only on the first layer), then continues with a 1D convolutional\n",
            "\n",
            "--- Chunk 11559 ---\n",
            "layer using \"causal\" padding: this ensures that the convolutional layer does not peek\n",
            "\n",
            "--- Chunk 11560 ---\n",
            "into the future when making predictions (it is equivalent to padding the inputs with\n",
            "\n",
            "--- Chunk 11561 ---\n",
            "the right amount of zeros on the left and using \"valid\" padding). We then add\n",
            "\n",
            "--- Chunk 11562 ---\n",
            "14 The complete WaveNet uses a few more tricks, such as skip connections like in a ResNet, and Gated Activation\n",
            "\n",
            "--- Chunk 11563 ---\n",
            "Units similar to those found in a GRU cell. Please see the notebook for more details.\n",
            "\n",
            "--- Chunk 11564 ---\n",
            "522 | Chapter 15: Processing Sequences Using RNNs and CNNs\n",
            "\n",
            "--- Chunk 11565 ---\n",
            "similar pairs of layers using growing dilation rates: 1, 2, 4, 8, and again 1, 2, 4, 8.\n",
            "\n",
            "--- Chunk 11566 ---\n",
            "Finally, we add the output layer: a convolutional layer with 10 filters of size 1 and\n",
            "\n",
            "--- Chunk 11567 ---\n",
            "without any activation function. Thanks to the padding layers, every convolutional\n",
            "\n",
            "--- Chunk 11568 ---\n",
            "layer outputs a sequence of the same length as the input sequences, so the targets we\n",
            "\n",
            "--- Chunk 11569 ---\n",
            "use during training can be the full sequences: no need to crop them or downsample\n",
            "them.\n",
            "\n",
            "--- Chunk 11570 ---\n",
            "them.\n",
            "The last two models offer the best performance so far in forecasting our time series!\n",
            "\n",
            "--- Chunk 11571 ---\n",
            "In the WaveNet paper, the authors achieved state-of-the-art performance on various\n",
            "\n",
            "--- Chunk 11572 ---\n",
            "audio tasks (hence the name of the architecture), including text-to-speech tasks, pro‐\n",
            "\n",
            "--- Chunk 11573 ---\n",
            "ducing incredibly realistic voices across several languages. They also used the model\n",
            "\n",
            "--- Chunk 11574 ---\n",
            "to generate music, one audio sample at a time. This feat is all the more impressive\n",
            "\n",
            "--- Chunk 11575 ---\n",
            "when you realize that a single second of audio can contain tens of thousands of time\n",
            "steps—even LSTMs and GRUs cannot handle such long sequences.\n",
            "\n",
            "--- Chunk 11576 ---\n",
            "In Chapter 16, we will continue to explore RNNs, and we will see how they can tackle\n",
            "various NLP tasks.\n",
            "\n",
            "--- Chunk 11577 ---\n",
            "Exercises\n",
            "1. Can you think of a few applications for a sequence-to-sequence RNN? What\n",
            "\n",
            "--- Chunk 11578 ---\n",
            "about a sequence-to-vector RNN, and a vector-to-sequence RNN?\n",
            "2. How many dimensions must the inputs of an RNN layer have? What does each\n",
            "\n",
            "--- Chunk 11579 ---\n",
            "dimension represent? What about its outputs?\n",
            "3. If you want to build a deep sequence-to-sequence RNN, which RNN layers\n",
            "\n",
            "--- Chunk 11580 ---\n",
            "should have return_sequences=True? What about a sequence-to-vector RNN?\n",
            "\n",
            "--- Chunk 11581 ---\n",
            "4. Suppose you have a daily univariate time series, and you want to forecast the next\n",
            "\n",
            "--- Chunk 11582 ---\n",
            "seven days. Which RNN architecture should you use?\n",
            "5. What are the main difficulties when training RNNs? How can you handle them?\n",
            "\n",
            "--- Chunk 11583 ---\n",
            "6. Can you sketch the LSTM cell’s architecture?\n",
            "7. Why would you want to use 1D convolutional layers in an RNN?\n",
            "\n",
            "--- Chunk 11584 ---\n",
            "8. Which neural network architecture could you use to classify videos?\n",
            "\n",
            "--- Chunk 11585 ---\n",
            "9. Train a classification model for the SketchRNN dataset, available in TensorFlow\n",
            "\n",
            "--- Chunk 11586 ---\n",
            "Datasets.\n",
            "10. Download the Bach chorales dataset and unzip it. It is composed of 382 chorales\n",
            "\n",
            "--- Chunk 11587 ---\n",
            "composed by Johann Sebastian Bach. Each chorale is 100 to 640 time steps long,\n",
            "\n",
            "--- Chunk 11588 ---\n",
            "and each time step contains 4 integers, where each integer corresponds to a note’s\n",
            "\n",
            "--- Chunk 11589 ---\n",
            "index on a piano (except for the value 0, which means that no note is played).\n",
            "\n",
            "--- Chunk 11590 ---\n",
            "Train a model—recurrent, convolutional, or both—that can predict the next time\n",
            "\n",
            "--- Chunk 11591 ---\n",
            "step (four notes), given a sequence of time steps from a chorale. Then use this\n",
            "\n",
            "--- Chunk 11592 ---\n",
            "Exercises | 523\n",
            "\n",
            "--- Chunk 11593 ---\n",
            "model to generate Bach-like music, one note at a time: you can do this by giving\n",
            "\n",
            "--- Chunk 11594 ---\n",
            "the model the start of a chorale and asking it to predict the next time step, then\n",
            "\n",
            "--- Chunk 11595 ---\n",
            "appending these time steps to the input sequence and asking the model for the\n",
            "\n",
            "--- Chunk 11596 ---\n",
            "next note, and so on. Also make sure to check out Google’s Coconet model,\n",
            "which was used for a nice Google doodle about Bach.\n",
            "\n",
            "--- Chunk 11597 ---\n",
            "Solutions to these exercises are available in Appendix A.\n",
            "\n",
            "524 | Chapter 15: Processing Sequences Using RNNs and CNNs\n",
            "\n",
            "--- Chunk 11598 ---\n",
            "CHAPTER 16\n",
            "Natural Language Processing with\n",
            "\n",
            "RNNs and Attention\n",
            "\n",
            "--- Chunk 11599 ---\n",
            "When Alan Turing imagined his famous Turing test1 in 1950, his objective was to\n",
            "\n",
            "--- Chunk 11600 ---\n",
            "evaluate a machine’s ability to match human intelligence. He could have tested for\n",
            "\n",
            "--- Chunk 11601 ---\n",
            "many things, such as the ability to recognize cats in pictures, play chess, compose\n",
            "\n",
            "--- Chunk 11602 ---\n",
            "music, or escape a maze, but, interestingly, he chose a linguistic task. More specifi‐\n",
            "\n",
            "--- Chunk 11603 ---\n",
            "cally, he devised a chatbot capable of fooling its interlocutor into thinking it was\n",
            "\n",
            "--- Chunk 11604 ---\n",
            "human.2 This test does have its weaknesses: a set of hardcoded rules can fool unsus‐\n",
            "\n",
            "--- Chunk 11605 ---\n",
            "pecting or naive humans (e.g., the machine could give vague predefined answers in\n",
            "\n",
            "--- Chunk 11606 ---\n",
            "response to some keywords; it could pretend that it is joking or drunk, to get a pass\n",
            "\n",
            "--- Chunk 11607 ---\n",
            "on its weirdest answers; or it could escape difficult questions by answering them with\n",
            "\n",
            "--- Chunk 11608 ---\n",
            "its own questions), and many aspects of human intelligence are utterly ignored (e.g.,\n",
            "\n",
            "--- Chunk 11609 ---\n",
            "the ability to interpret nonverbal communication such as facial expressions, or to\n",
            "\n",
            "--- Chunk 11610 ---\n",
            "learn a manual task). But the test does highlight the fact that mastering language is\n",
            "\n",
            "--- Chunk 11611 ---\n",
            "arguably Homo sapiens’s greatest cognitive ability. Can we build a machine that can\n",
            "read and write natural language?\n",
            "\n",
            "--- Chunk 11612 ---\n",
            "A common approach for natural language tasks is to use recurrent neural networks.\n",
            "\n",
            "--- Chunk 11613 ---\n",
            "We will therefore continue to explore RNNs (introduced in Chapter 15), starting with\n",
            "\n",
            "--- Chunk 11614 ---\n",
            "a character RNN, trained to predict the next character in a sentence. This will allow us\n",
            "\n",
            "--- Chunk 11615 ---\n",
            "to generate some original text, and in the process we will see how to build a Tensor‐\n",
            "\n",
            "--- Chunk 11616 ---\n",
            "Flow Dataset on a very long sequence. We will first use a stateless RNN (which learns\n",
            "\n",
            "--- Chunk 11617 ---\n",
            "1 Alan Turing, “Computing Machinery and Intelligence,” Mind 49 (1950): 433–460.\n",
            "\n",
            "--- Chunk 11618 ---\n",
            "2 Of course, the word chatbot came much later. Turing called his test the imitation game: machine A and human\n",
            "\n",
            "--- Chunk 11619 ---\n",
            "B chat with human interrogator C via text messages; the interrogator asks questions to figure out which one is\n",
            "\n",
            "--- Chunk 11620 ---\n",
            "the machine (A or B). The machine passes the test if it can fool the interrogator, while the human B must try\n",
            "to help the interrogator.\n",
            "\n",
            "--- Chunk 11621 ---\n",
            "525\n",
            "\n",
            "--- Chunk 11622 ---\n",
            "on random portions of text at each iteration, without any information on the rest of\n",
            "\n",
            "--- Chunk 11623 ---\n",
            "the text), then we will build a stateful RNN (which preserves the hidden state between\n",
            "\n",
            "--- Chunk 11624 ---\n",
            "training iterations and continues reading where it left off, allowing it to learn longer\n",
            "\n",
            "--- Chunk 11625 ---\n",
            "patterns). Next, we will build an RNN to perform sentiment analysis (e.g., reading\n",
            "\n",
            "--- Chunk 11626 ---\n",
            "movie reviews and extracting the rater’s feeling about the movie), this time treating\n",
            "\n",
            "--- Chunk 11627 ---\n",
            "sentences as sequences of words, rather than characters. Then we will show how\n",
            "\n",
            "--- Chunk 11628 ---\n",
            "RNNs can be used to build an Encoder–Decoder architecture capable of performing\n",
            "\n",
            "--- Chunk 11629 ---\n",
            "neural machine translation (NMT). For this, we will use the seq2seq API provided by\n",
            "the TensorFlow Addons project.\n",
            "\n",
            "--- Chunk 11630 ---\n",
            "In the second part of this chapter, we will look at attention mechanisms. As their name\n",
            "\n",
            "--- Chunk 11631 ---\n",
            "suggests, these are neural network components that learn to select the part of the\n",
            "\n",
            "--- Chunk 11632 ---\n",
            "inputs that the rest of the model should focus on at each time step. First we will see\n",
            "\n",
            "--- Chunk 11633 ---\n",
            "how to boost the performance of an RNN-based Encoder–Decoder architecture using\n",
            "\n",
            "--- Chunk 11634 ---\n",
            "attention, then we will drop RNNs altogether and look at a very successful attention-\n",
            "\n",
            "--- Chunk 11635 ---\n",
            "only architecture called the Transformer. Finally, we will take a look at some of the\n",
            "\n",
            "--- Chunk 11636 ---\n",
            "most important advances in NLP in 2018 and 2019, including incredibly powerful\n",
            "language models such as GPT-2 and BERT, both based on Transformers.\n",
            "\n",
            "--- Chunk 11637 ---\n",
            "Let’s start with a simple and fun model that can write like Shakespeare (well, sort of).\n",
            "\n",
            "--- Chunk 11638 ---\n",
            "Generating Shakespearean Text Using a Character RNN\n",
            "In a famous 2015 blog post titled “The Unreasonable Effectiveness of Recurrent Neu‐\n",
            "\n",
            "--- Chunk 11639 ---\n",
            "ral Networks,” Andrej Karpathy showed how to train an RNN to predict the next\n",
            "\n",
            "--- Chunk 11640 ---\n",
            "character in a sentence. This Char-RNN can then be used to generate novel text, one\n",
            "\n",
            "--- Chunk 11641 ---\n",
            "character at a time. Here is a small sample of the text generated by a Char-RNN\n",
            "model after it was trained on all of Shakespeare’s work:\n",
            "\n",
            "--- Chunk 11642 ---\n",
            "PANDARUS:\n",
            "Alas, I think he shall be come approached and the day\n",
            "When little srain would be attain’d into being never fed,\n",
            "\n",
            "--- Chunk 11643 ---\n",
            "And who is but a chain and subjects of his death,\n",
            "I should not sleep.\n",
            "\n",
            "--- Chunk 11644 ---\n",
            "Not exactly a masterpiece, but it is still impressive that the model was able to learn\n",
            "\n",
            "--- Chunk 11645 ---\n",
            "words, grammar, proper punctuation, and more, just by learning to predict the next\n",
            "\n",
            "--- Chunk 11646 ---\n",
            "character in a sentence. Let’s look at how to build a Char-RNN, step by step, starting\n",
            "with the creation of the dataset.\n",
            "\n",
            "--- Chunk 11647 ---\n",
            "526 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "--- Chunk 11648 ---\n",
            "Creating the Training Dataset\n",
            "First, let’s download all of Shakespeare’s work, using Keras’s handy get_file() func‐\n",
            "\n",
            "--- Chunk 11649 ---\n",
            "tion and downloading the data from Andrej Karpathy’s Char-RNN project:\n",
            "\n",
            "--- Chunk 11650 ---\n",
            "shakespeare_url = \"https://homl.info/shakespeare\" # shortcut URL\n",
            "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
            "\n",
            "--- Chunk 11651 ---\n",
            "with open(filepath) as f:\n",
            "    shakespeare_text = f.read()\n",
            "\n",
            "--- Chunk 11652 ---\n",
            "Next, we must encode every character as an integer. One option is to create a custom\n",
            "\n",
            "--- Chunk 11653 ---\n",
            "preprocessing layer, as we did in Chapter 13. But in this case, it will be simpler to use\n",
            "\n",
            "--- Chunk 11654 ---\n",
            "Keras’s Tokenizer class. First we need to fit a tokenizer to the text: it will find all the\n",
            "\n",
            "--- Chunk 11655 ---\n",
            "characters used in the text and map each of them to a different character ID, from 1\n",
            "\n",
            "--- Chunk 11656 ---\n",
            "to the number of distinct characters (it does not start at 0, so we can use that value for\n",
            "masking, as we will see later in this chapter):\n",
            "\n",
            "--- Chunk 11657 ---\n",
            "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
            "tokenizer.fit_on_texts([shakespeare_text])\n",
            "\n",
            "--- Chunk 11658 ---\n",
            "We set char_level=True to get character-level encoding rather than the default\n",
            "\n",
            "--- Chunk 11659 ---\n",
            "word-level encoding. Note that this tokenizer converts the text to lowercase by\n",
            "\n",
            "--- Chunk 11660 ---\n",
            "default (but you can set lower=False if you do not want that). Now the tokenizer can\n",
            "\n",
            "--- Chunk 11661 ---\n",
            "encode a sentence (or a list of sentences) to a list of character IDs and back, and it\n",
            "\n",
            "--- Chunk 11662 ---\n",
            "tells us how many distinct characters there are and the total number of characters in\n",
            "the text:\n",
            "\n",
            "--- Chunk 11663 ---\n",
            ">>> tokenizer.texts_to_sequences([\"First\"])\n",
            "[[20, 6, 9, 8, 3]]\n",
            ">>> tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])\n",
            "['f i r s t']\n",
            "\n",
            "--- Chunk 11664 ---\n",
            "['f i r s t']\n",
            ">>> max_id = len(tokenizer.word_index) # number of distinct characters\n",
            "\n",
            "--- Chunk 11665 ---\n",
            ">>> dataset_size = tokenizer.document_count # total number of characters\n",
            "\n",
            "--- Chunk 11666 ---\n",
            "Let’s encode the full text so each character is represented by its ID (we subtract 1 to\n",
            "get IDs from 0 to 38, rather than from 1 to 39):\n",
            "\n",
            "--- Chunk 11667 ---\n",
            "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1\n",
            "\n",
            "--- Chunk 11668 ---\n",
            "Before we continue, we need to split the dataset into a training set, a validation set,\n",
            "\n",
            "--- Chunk 11669 ---\n",
            "and a test set. We can’t just shuffle all the characters in the text, so how do you split a\n",
            "sequential dataset?\n",
            "\n",
            "--- Chunk 11670 ---\n",
            "How to Split a Sequential Dataset\n",
            "It is very important to avoid any overlap between the training set, the validation set,\n",
            "\n",
            "--- Chunk 11671 ---\n",
            "and the test set. For example, we can take the first 90% of the text for the training set,\n",
            "\n",
            "--- Chunk 11672 ---\n",
            "then the next 5% for the validation set, and the final 5% for the test set. It would also\n",
            "\n",
            "--- Chunk 11673 ---\n",
            "Generating Shakespearean Text Using a Character RNN | 527\n",
            "\n",
            "--- Chunk 11674 ---\n",
            "be a good idea to leave a gap between these sets to avoid the risk of a paragraph over‐\n",
            "lapping over two sets.\n",
            "\n",
            "--- Chunk 11675 ---\n",
            "When dealing with time series, you would in general split across time,: for example,\n",
            "\n",
            "--- Chunk 11676 ---\n",
            "you might take the years 2000 to 2012 for the training set, the years 2013 to 2015 for\n",
            "\n",
            "--- Chunk 11677 ---\n",
            "the validation set, and the years 2016 to 2018 for the test set. However, in some cases\n",
            "\n",
            "--- Chunk 11678 ---\n",
            "you may be able to split along other dimensions, which will give you a longer time\n",
            "\n",
            "--- Chunk 11679 ---\n",
            "period to train on. For example, if you have data about the financial health of 10,000\n",
            "\n",
            "--- Chunk 11680 ---\n",
            "companies from 2000 to 2018, you might be able to split this data across the different\n",
            "\n",
            "--- Chunk 11681 ---\n",
            "companies. It’s very likely that many of these companies will be strongly correlated,\n",
            "\n",
            "--- Chunk 11682 ---\n",
            "though (e.g., whole economic sectors may go up or down jointly), and if you have\n",
            "\n",
            "--- Chunk 11683 ---\n",
            "correlated companies across the training set and the test set your test set will not be as\n",
            "\n",
            "--- Chunk 11684 ---\n",
            "useful, as its measure of the generalization error will be optimistically biased.\n",
            "\n",
            "--- Chunk 11685 ---\n",
            "So, it is often safer to split across time—but this implicitly assumes that the patterns\n",
            "\n",
            "--- Chunk 11686 ---\n",
            "the RNN can learn in the past (in the training set) will still exist in the future. In other\n",
            "\n",
            "--- Chunk 11687 ---\n",
            "words, we assume that the time series is stationary (at least in a wide sense).3 For\n",
            "\n",
            "--- Chunk 11688 ---\n",
            "many time series this assumption is reasonable (e.g., chemical reactions should be\n",
            "\n",
            "--- Chunk 11689 ---\n",
            "fine, since the laws of chemistry don’t change every day), but for many others it is not\n",
            "\n",
            "--- Chunk 11690 ---\n",
            "(e.g., financial markets are notoriously not stationary since patterns disappear as soon\n",
            "\n",
            "--- Chunk 11691 ---\n",
            "as traders spot them and start exploiting them). To make sure the time series is\n",
            "\n",
            "--- Chunk 11692 ---\n",
            "indeed sufficiently stationary, you can plot the model’s errors on the validation set\n",
            "\n",
            "--- Chunk 11693 ---\n",
            "across time: if the model performs much better on the first part of the validation set\n",
            "\n",
            "--- Chunk 11694 ---\n",
            "than on the last part, then the time series may not be stationary enough, and you\n",
            "might be better off training the model on a shorter time span.\n",
            "\n",
            "--- Chunk 11695 ---\n",
            "In short, splitting a time series into a training set, a validation set, and a test set is not\n",
            "\n",
            "--- Chunk 11696 ---\n",
            "a trivial task, and how it’s done will depend strongly on the task at hand.\n",
            "\n",
            "--- Chunk 11697 ---\n",
            "Now back to Shakespeare! Let’s take the first 90% of the text for the training set\n",
            "\n",
            "--- Chunk 11698 ---\n",
            "(keeping the rest for the validation set and the test set), and create a tf.data.Dataset\n",
            "that will return each character one by one from this set:\n",
            "\n",
            "--- Chunk 11699 ---\n",
            "train_size = dataset_size * 90 // 100\n",
            "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
            "\n",
            "--- Chunk 11700 ---\n",
            "Chopping the Sequential Dataset into Multiple Windows\n",
            "The training set now consists of a single sequence of over a million characters, so we\n",
            "\n",
            "--- Chunk 11701 ---\n",
            "can’t just train the neural network directly on it: the RNN would be equivalent to a\n",
            "\n",
            "--- Chunk 11702 ---\n",
            "3 By definition, a stationary time series’s mean, variance, and autocorrelations (i.e., correlations between values\n",
            "\n",
            "--- Chunk 11703 ---\n",
            "in the time series separated by a given interval) do not change over time. This is quite restrictive; for example,\n",
            "\n",
            "--- Chunk 11704 ---\n",
            "it excludes time series with trends or cyclical patterns. RNNs are more tolerant in that they can learn trends\n",
            "and cyclical patterns.\n",
            "\n",
            "--- Chunk 11705 ---\n",
            "528 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "--- Chunk 11706 ---\n",
            "deep net with over a million layers, and we would have a single (very long) instance\n",
            "\n",
            "--- Chunk 11707 ---\n",
            "to train it. Instead, we will use the dataset’s window() method to convert this long\n",
            "\n",
            "--- Chunk 11708 ---\n",
            "sequence of characters into many smaller windows of text. Every instance in the data‐\n",
            "\n",
            "--- Chunk 11709 ---\n",
            "set will be a fairly short substring of the whole text, and the RNN will be unrolled\n",
            "\n",
            "--- Chunk 11710 ---\n",
            "only over the length of these substrings. This is called truncated backpropagation\n",
            "\n",
            "--- Chunk 11711 ---\n",
            "through time. Let’s call the window() method to create a dataset of short text windows:\n",
            "\n",
            "--- Chunk 11712 ---\n",
            "n_steps = 100\n",
            "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
            "\n",
            "--- Chunk 11713 ---\n",
            "dataset = dataset.window(window_length, shift=1, drop_remainder=True)\n",
            "\n",
            "--- Chunk 11714 ---\n",
            "You can try tuning n_steps: it is easier to train RNNs on shorter\n",
            "input sequences, but of course the RNN will not be able to learn\n",
            "\n",
            "--- Chunk 11715 ---\n",
            "any pattern longer than n_steps, so don’t make it too small.\n",
            "\n",
            "--- Chunk 11716 ---\n",
            "By default, the window() method creates nonoverlapping windows, but to get the\n",
            "\n",
            "--- Chunk 11717 ---\n",
            "largest possible training set we use shift=1 so that the first window contains charac‐\n",
            "\n",
            "--- Chunk 11718 ---\n",
            "ters 0 to 100, the second contains characters 1 to 101, and so on. To ensure that all\n",
            "\n",
            "--- Chunk 11719 ---\n",
            "windows are exactly 101 characters long (which will allow us to create batches\n",
            "\n",
            "--- Chunk 11720 ---\n",
            "without having to do any padding), we set drop_remainder=True (otherwise the last\n",
            "\n",
            "--- Chunk 11721 ---\n",
            "100 windows will contain 100 characters, 99 characters, and so on down to 1\n",
            "character).\n",
            "\n",
            "--- Chunk 11722 ---\n",
            "character).\n",
            "The window() method creates a dataset that contains windows, each of which is also\n",
            "\n",
            "--- Chunk 11723 ---\n",
            "represented as a dataset. It’s a nested dataset, analogous to a list of lists. This is useful\n",
            "\n",
            "--- Chunk 11724 ---\n",
            "when you want to transform each window by calling its dataset methods (e.g., to\n",
            "\n",
            "--- Chunk 11725 ---\n",
            "shuffle them or batch them). However, we cannot use a nested dataset directly for\n",
            "\n",
            "--- Chunk 11726 ---\n",
            "training, as our model will expect tensors as input, not datasets. So, we must call the\n",
            "\n",
            "--- Chunk 11727 ---\n",
            "flat_map() method: it converts a nested dataset into a flat dataset (one that does not\n",
            "\n",
            "--- Chunk 11728 ---\n",
            "contain datasets). For example, suppose {1, 2, 3} represents a dataset containing the\n",
            "\n",
            "--- Chunk 11729 ---\n",
            "sequence of tensors 1, 2, and 3. If you flatten the nested dataset {{1, 2}, {3, 4, 5, 6}},\n",
            "\n",
            "--- Chunk 11730 ---\n",
            "you get back the flat dataset {1, 2, 3, 4, 5, 6}. Moreover, the flat_map() method takes\n",
            "\n",
            "--- Chunk 11731 ---\n",
            "a function as an argument, which allows you to transform each dataset in the nested\n",
            "\n",
            "--- Chunk 11732 ---\n",
            "dataset before flattening. For example, if you pass the function lambda ds:\n",
            "\n",
            "--- Chunk 11733 ---\n",
            "ds.batch(2) to flat_map(), then it will transform the nested dataset {{1, 2}, {3, 4, 5,\n",
            "\n",
            "--- Chunk 11734 ---\n",
            "6}} into the flat dataset {[1, 2], [3, 4], [5, 6]}: it’s a dataset of tensors of size 2. With that\n",
            "in mind, we are ready to flatten our dataset:\n",
            "\n",
            "--- Chunk 11735 ---\n",
            "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
            "\n",
            "--- Chunk 11736 ---\n",
            "Notice that we call batch(window_length) on each window: since all windows have\n",
            "\n",
            "--- Chunk 11737 ---\n",
            "exactly that length, we will get a single tensor for each of them. Now the dataset con‐\n",
            "\n",
            "--- Chunk 11738 ---\n",
            "tains consecutive windows of 101 characters each. Since Gradient Descent works best\n",
            "\n",
            "--- Chunk 11739 ---\n",
            "Generating Shakespearean Text Using a Character RNN | 529\n",
            "\n",
            "--- Chunk 11740 ---\n",
            "when the instances in the training set are independent and identically distributed (see\n",
            "\n",
            "--- Chunk 11741 ---\n",
            "Chapter 4), we need to shuffle these windows. Then we can batch the windows and\n",
            "\n",
            "--- Chunk 11742 ---\n",
            "separate the inputs (the first 100 characters) from the target (the last character):\n",
            "\n",
            "--- Chunk 11743 ---\n",
            "batch_size = 32\n",
            "dataset = dataset.shuffle(10000).batch(batch_size)\n",
            "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
            "\n",
            "--- Chunk 11744 ---\n",
            "Figure 16-1 summarizes the dataset preparation steps discussed so far (showing win‐\n",
            "\n",
            "--- Chunk 11745 ---\n",
            "dows of length 11 rather than 101, and a batch size of 3 instead of 32).\n",
            "\n",
            "--- Chunk 11746 ---\n",
            "Figure 16-1. Preparing a dataset of shuffled windows\n",
            "\n",
            "--- Chunk 11747 ---\n",
            "As discussed in Chapter 13, categorical input features should generally be encoded,\n",
            "\n",
            "--- Chunk 11748 ---\n",
            "usually as one-hot vectors or as embeddings. Here, we will encode each character\n",
            "\n",
            "--- Chunk 11749 ---\n",
            "using a one-hot vector because there are fairly few distinct characters (only 39):\n",
            "\n",
            "--- Chunk 11750 ---\n",
            "dataset = dataset.map(\n",
            "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
            "\n",
            "--- Chunk 11751 ---\n",
            "Finally, we just need to add prefetching:\n",
            "dataset = dataset.prefetch(1)\n",
            "\n",
            "--- Chunk 11752 ---\n",
            "That’s it! Preparing the dataset was the hardest part. Now let’s create the model.\n",
            "\n",
            "--- Chunk 11753 ---\n",
            "Building and Training the Char-RNN Model\n",
            "To predict the next character based on the previous 100 characters, we can use an\n",
            "\n",
            "--- Chunk 11754 ---\n",
            "RNN with 2 GRU layers of 128 units each and 20% dropout on both the inputs (drop\n",
            "\n",
            "--- Chunk 11755 ---\n",
            "out) and the hidden states (recurrent_dropout). We can tweak these hyperparame‐\n",
            "\n",
            "--- Chunk 11756 ---\n",
            "ters later, if needed. The output layer is a time-distributed Dense layer like we saw in\n",
            "\n",
            "--- Chunk 11757 ---\n",
            "Chapter 15. This time this layer must have 39 units (max_id) because there are 39 dis‐\n",
            "\n",
            "--- Chunk 11758 ---\n",
            "tinct characters in the text, and we want to output a probability for each possible\n",
            "\n",
            "--- Chunk 11759 ---\n",
            "character (at each time step). The output probabilities should sum up to 1 at each\n",
            "\n",
            "--- Chunk 11760 ---\n",
            "time step, so we apply the softmax activation function to the outputs of the Dense\n",
            "\n",
            "--- Chunk 11761 ---\n",
            "530 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "--- Chunk 11762 ---\n",
            "layer. We can then compile this model, using the \"sparse_categorical_crossen\n",
            "\n",
            "--- Chunk 11763 ---\n",
            "tropy\" loss and an Adam optimizer. Finally, we are ready to train the model for sev‐\n",
            "\n",
            "--- Chunk 11764 ---\n",
            "eral epochs (this may take many hours, depending on your hardware):\n",
            "\n",
            "--- Chunk 11765 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
            "\n",
            "--- Chunk 11766 ---\n",
            "dropout=0.2, recurrent_dropout=0.2),\n",
            "    keras.layers.GRU(128, return_sequences=True,\n",
            "\n",
            "--- Chunk 11767 ---\n",
            "dropout=0.2, recurrent_dropout=0.2),\n",
            "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
            "\n",
            "--- Chunk 11768 ---\n",
            "activation=\"softmax\"))\n",
            "])\n",
            "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
            "\n",
            "--- Chunk 11769 ---\n",
            "history = model.fit(dataset, epochs=20)\n",
            "\n",
            "--- Chunk 11770 ---\n",
            "Using the Char-RNN Model\n",
            "Now we have a model that can predict the next character in text written by Shake‐\n",
            "\n",
            "--- Chunk 11771 ---\n",
            "speare. To feed it some text, we first need to preprocess it like we did earlier, so let’s\n",
            "create a little function for this:\n",
            "\n",
            "--- Chunk 11772 ---\n",
            "def preprocess(texts):\n",
            "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
            "    return tf.one_hot(X, max_id)\n",
            "\n",
            "--- Chunk 11773 ---\n",
            "Now let’s use the model to predict the next letter in some text:\n",
            ">>> X_new = preprocess([\"How are yo\"])\n",
            ">>> Y_pred = model.predict_classes(X_new)\n",
            "\n",
            "--- Chunk 11774 ---\n",
            ">>> tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 1st sentence, last char\n",
            "'u'\n",
            "\n",
            "--- Chunk 11775 ---\n",
            "Success! The model guessed right. Now let’s use this model to generate new text.\n",
            "\n",
            "--- Chunk 11776 ---\n",
            "Generating Fake Shakespearean Text\n",
            "To generate new text using the Char-RNN model, we could feed it some text, make\n",
            "\n",
            "--- Chunk 11777 ---\n",
            "the model predict the most likely next letter, add it at the end of the text, then give the\n",
            "\n",
            "--- Chunk 11778 ---\n",
            "extended text to the model to guess the next letter, and so on. But in practice this\n",
            "\n",
            "--- Chunk 11779 ---\n",
            "often leads to the same words being repeated over and over again. Instead, we can\n",
            "\n",
            "--- Chunk 11780 ---\n",
            "pick the next character randomly, with a probability equal to the estimated probabil‐\n",
            "\n",
            "--- Chunk 11781 ---\n",
            "ity, using TensorFlow’s tf.random.categorical() function. This will generate more\n",
            "\n",
            "--- Chunk 11782 ---\n",
            "diverse and interesting text. The categorical() function samples random class indi‐\n",
            "\n",
            "--- Chunk 11783 ---\n",
            "ces, given the class log probabilities (logits). To have more control over the diversity\n",
            "\n",
            "--- Chunk 11784 ---\n",
            "of the generated text, we can divide the logits by a number called the temperature,\n",
            "\n",
            "--- Chunk 11785 ---\n",
            "which we can tweak as we wish: a temperature close to 0 will favor the high-\n",
            "\n",
            "--- Chunk 11786 ---\n",
            "probability characters, while a very high temperature will give all characters an equal\n",
            "\n",
            "--- Chunk 11787 ---\n",
            "probability. The following next_char() function uses this approach to pick the next\n",
            "character to add to the input text:\n",
            "\n",
            "--- Chunk 11788 ---\n",
            "Generating Shakespearean Text Using a Character RNN | 531\n",
            "\n",
            "--- Chunk 11789 ---\n",
            "def next_char(text, temperature=1):\n",
            "    X_new = preprocess([text])\n",
            "    y_proba = model.predict(X_new)[0, -1:, :]\n",
            "\n",
            "--- Chunk 11790 ---\n",
            "rescaled_logits = tf.math.log(y_proba) / temperature\n",
            "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
            "\n",
            "--- Chunk 11791 ---\n",
            "return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
            "\n",
            "--- Chunk 11792 ---\n",
            "Next, we can write a small function that will repeatedly call next_char() to get the\n",
            "next character and append it to the given text:\n",
            "\n",
            "--- Chunk 11793 ---\n",
            "def complete_text(text, n_chars=50, temperature=1):\n",
            "    for _ in range(n_chars):\n",
            "        text += next_char(text, temperature)\n",
            "    return text\n",
            "\n",
            "--- Chunk 11794 ---\n",
            "We are now ready to generate some text! Let’s try with different temperatures:\n",
            ">>> print(complete_text(\"t\", temperature=0.2))\n",
            "\n",
            "--- Chunk 11795 ---\n",
            "the belly the great and who shall be the belly the\n",
            ">>> print(complete_text(\"w\", temperature=1))\n",
            "thing? or why you gremio.\n",
            "who make which the first\n",
            "\n",
            "--- Chunk 11796 ---\n",
            ">>> print(complete_text(\"w\", temperature=2))\n",
            "th no cce:\n",
            "yeolg-hormer firi. a play asks.\n",
            "fol rusb\n",
            "\n",
            "--- Chunk 11797 ---\n",
            "Apparently our Shakespeare model works best at a temperature close to 1. To gener‐\n",
            "\n",
            "--- Chunk 11798 ---\n",
            "ate more convincing text, you could try using more GRU layers and more neurons per\n",
            "\n",
            "--- Chunk 11799 ---\n",
            "layer, train for longer, and add some regularization (for example, you could set recur\n",
            "\n",
            "--- Chunk 11800 ---\n",
            "rent_dropout=0.3 in the GRU layers). Moreover, the model is currently incapable of\n",
            "\n",
            "--- Chunk 11801 ---\n",
            "learning patterns longer than n_steps, which is just 100 characters. You could try\n",
            "\n",
            "--- Chunk 11802 ---\n",
            "making this window larger, but it will also make training harder, and even LSTM and\n",
            "\n",
            "--- Chunk 11803 ---\n",
            "GRU cells cannot handle very long sequences. Alternatively, you could use a stateful\n",
            "RNN.\n",
            "\n",
            "--- Chunk 11804 ---\n",
            "Stateful RNN\n",
            "Until now, we have used only stateless RNNs: at each training iteration the model\n",
            "\n",
            "--- Chunk 11805 ---\n",
            "starts with a hidden state full of zeros, then it updates this state at each time step, and\n",
            "\n",
            "--- Chunk 11806 ---\n",
            "after the last time step, it throws it away, as it is not needed anymore. What if we told\n",
            "\n",
            "--- Chunk 11807 ---\n",
            "the RNN to preserve this final state after processing one training batch and use it as\n",
            "\n",
            "--- Chunk 11808 ---\n",
            "the initial state for the next training batch? This way the model can learn long-term\n",
            "\n",
            "--- Chunk 11809 ---\n",
            "patterns despite only backpropagating through short sequences. This is called a state‐\n",
            "ful RNN. Let’s see how to build one.\n",
            "\n",
            "--- Chunk 11810 ---\n",
            "First, note that a stateful RNN only makes sense if each input sequence in a batch\n",
            "\n",
            "--- Chunk 11811 ---\n",
            "starts exactly where the corresponding sequence in the previous batch left off. So the\n",
            "\n",
            "--- Chunk 11812 ---\n",
            "first thing we need to do to build a stateful RNN is to use sequential and nonoverlap‐\n",
            "\n",
            "--- Chunk 11813 ---\n",
            "532 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "--- Chunk 11814 ---\n",
            "ping input sequences (rather than the shuffled and overlapping sequences we used to\n",
            "\n",
            "--- Chunk 11815 ---\n",
            "train stateless RNNs). When creating the Dataset, we must therefore use\n",
            "\n",
            "--- Chunk 11816 ---\n",
            "shift=n_steps (instead of shift=1) when calling the window() method. Moreover,\n",
            "\n",
            "--- Chunk 11817 ---\n",
            "we must obviously not call the shuffle() method. Unfortunately, batching is much\n",
            "\n",
            "--- Chunk 11818 ---\n",
            "harder when preparing a dataset for a stateful RNN than it is for a stateless RNN.\n",
            "\n",
            "--- Chunk 11819 ---\n",
            "Indeed, if we were to call batch(32), then 32 consecutive windows would be put in\n",
            "\n",
            "--- Chunk 11820 ---\n",
            "the same batch, and the following batch would not continue each of these window\n",
            "\n",
            "--- Chunk 11821 ---\n",
            "where it left off. The first batch would contain windows 1 to 32 and the second batch\n",
            "\n",
            "--- Chunk 11822 ---\n",
            "would contain windows 33 to 64, so if you consider, say, the first window of each\n",
            "\n",
            "--- Chunk 11823 ---\n",
            "batch (i.e., windows 1 and 33), you can see that they are not consecutive. The simplest\n",
            "\n",
            "--- Chunk 11824 ---\n",
            "solution to this problem is to just use “batches” containing a single window:\n",
            "\n",
            "--- Chunk 11825 ---\n",
            "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
            "dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
            "\n",
            "--- Chunk 11826 ---\n",
            "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
            "dataset = dataset.batch(1)\n",
            "\n",
            "--- Chunk 11827 ---\n",
            "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
            "dataset = dataset.map(\n",
            "\n",
            "--- Chunk 11828 ---\n",
            "lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
            "dataset = dataset.prefetch(1)\n",
            "\n",
            "--- Chunk 11829 ---\n",
            "Figure 16-2 summarizes the first steps.\n",
            "\n",
            "Figure 16-2. Preparing a dataset of consecutive sequence fragments for a stateful RNN\n",
            "\n",
            "--- Chunk 11830 ---\n",
            "Batching is harder, but it is not impossible. For example, we could chop Shakespeare’s\n",
            "\n",
            "--- Chunk 11831 ---\n",
            "text into 32 texts of equal length, create one dataset of consecutive input sequences\n",
            "\n",
            "--- Chunk 11832 ---\n",
            "for each of them, and finally use tf.train.Dataset.zip(datasets).map(lambda\n",
            "\n",
            "--- Chunk 11833 ---\n",
            "*windows: tf.stack(windows)) to create proper consecutive batches, where the nth\n",
            "\n",
            "--- Chunk 11834 ---\n",
            "input sequence in a batch starts off exactly where the nth input sequence ended in the\n",
            "previous batch (see the notebook for the full code).\n",
            "\n",
            "--- Chunk 11835 ---\n",
            "Generating Shakespearean Text Using a Character RNN | 533\n",
            "\n",
            "--- Chunk 11836 ---\n",
            "Now let’s create the stateful RNN. First, we need to set stateful=True when creating\n",
            "\n",
            "--- Chunk 11837 ---\n",
            "every recurrent layer. Second, the stateful RNN needs to know the batch size (since it\n",
            "\n",
            "--- Chunk 11838 ---\n",
            "will preserve a state for each input sequence in the batch), so we must set the\n",
            "\n",
            "--- Chunk 11839 ---\n",
            "batch_input_shape argument in the first layer. Note that we can leave the second\n",
            "dimension unspecified, since the inputs could have any length:\n",
            "\n",
            "--- Chunk 11840 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
            "\n",
            "--- Chunk 11841 ---\n",
            "dropout=0.2, recurrent_dropout=0.2,\n",
            "                     batch_input_shape=[batch_size, None, max_id]),\n",
            "\n",
            "--- Chunk 11842 ---\n",
            "keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
            "                     dropout=0.2, recurrent_dropout=0.2),\n",
            "\n",
            "--- Chunk 11843 ---\n",
            "keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
            "                                                    activation=\"softmax\"))\n",
            "])\n",
            "\n",
            "--- Chunk 11844 ---\n",
            "At the end of each epoch, we need to reset the states before we go back to the begin‐\n",
            "ning of the text. For this, we can use a small callback:\n",
            "\n",
            "--- Chunk 11845 ---\n",
            "class ResetStatesCallback(keras.callbacks.Callback):\n",
            "    def on_epoch_begin(self, epoch, logs):\n",
            "        self.model.reset_states()\n",
            "\n",
            "--- Chunk 11846 ---\n",
            "And now we can compile and fit the model (for more epochs, because each epoch is\n",
            "\n",
            "--- Chunk 11847 ---\n",
            "much shorter than earlier, and there is only one instance per batch):\n",
            "\n",
            "--- Chunk 11848 ---\n",
            "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
            "model.fit(dataset, epochs=50, callbacks=[ResetStatesCallback()])\n",
            "\n",
            "--- Chunk 11849 ---\n",
            "After this model is trained, it will only be possible to use it to make\n",
            "predictions for batches of the same size as were used during train‐\n",
            "\n",
            "--- Chunk 11850 ---\n",
            "ing. To avoid this restriction, create an identical stateless model,\n",
            "and copy the stateful model’s weights to this model.\n",
            "\n",
            "--- Chunk 11851 ---\n",
            "Now that we have built a character-level model, it’s time to look at word-level models\n",
            "\n",
            "--- Chunk 11852 ---\n",
            "and tackle a common natural language processing task: sentiment analysis. In the pro‐\n",
            "\n",
            "--- Chunk 11853 ---\n",
            "cess we will learn how to handle sequences of variable lengths using masking.\n",
            "\n",
            "--- Chunk 11854 ---\n",
            "Sentiment Analysis\n",
            "If MNIST is the “hello world” of computer vision, then the IMDb reviews dataset is\n",
            "\n",
            "--- Chunk 11855 ---\n",
            "the “hello world” of natural language processing: it consists of 50,000 movie reviews\n",
            "\n",
            "--- Chunk 11856 ---\n",
            "in English (25,000 for training, 25,000 for testing) extracted from the famous Internet\n",
            "\n",
            "--- Chunk 11857 ---\n",
            "Movie Database, along with a simple binary target for each review indicating whether\n",
            "\n",
            "--- Chunk 11858 ---\n",
            "it is negative (0) or positive (1). Just like MNIST, the IMDb reviews dataset is popular\n",
            "\n",
            "--- Chunk 11859 ---\n",
            "for good reasons: it is simple enough to be tackled on a laptop in a reasonable amount\n",
            "\n",
            "--- Chunk 11860 ---\n",
            "534 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "--- Chunk 11861 ---\n",
            "of time, but challenging enough to be fun and rewarding. Keras provides a simple\n",
            "function to load it:\n",
            "\n",
            "--- Chunk 11862 ---\n",
            ">>> (X_train, y_train), (X_test, y_test) = keras.datasets.imdb.load_data()\n",
            ">>> X_train[0][:10]\n",
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]\n",
            "\n",
            "--- Chunk 11863 ---\n",
            "Where are the movie reviews? Well, as you can see, the dataset is already prepro‐\n",
            "\n",
            "--- Chunk 11864 ---\n",
            "cessed for you: X_train consists of a list of reviews, each of which is represented as a\n",
            "\n",
            "--- Chunk 11865 ---\n",
            "NumPy array of integers, where each integer represents a word. All punctuation was\n",
            "\n",
            "--- Chunk 11866 ---\n",
            "removed, and then words were converted to lowercase, split by spaces, and finally\n",
            "\n",
            "--- Chunk 11867 ---\n",
            "indexed by frequency (so low integers correspond to frequent words). The integers 0,\n",
            "\n",
            "--- Chunk 11868 ---\n",
            "1, and 2 are special: they represent the padding token, the start-of-sequence (SSS)\n",
            "\n",
            "--- Chunk 11869 ---\n",
            "token, and unknown words, respectively. If you want to visualize a review, you can\n",
            "decode it like this:\n",
            "\n",
            "--- Chunk 11870 ---\n",
            ">>> word_index = keras.datasets.imdb.get_word_index()\n",
            ">>> id_to_word = {id_ + 3: word for word, id_ in word_index.items()}\n",
            "\n",
            "--- Chunk 11871 ---\n",
            ">>> for id_, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
            "...     id_to_word[id_] = token\n",
            "...\n",
            "\n",
            "--- Chunk 11872 ---\n",
            "...\n",
            ">>> \" \".join([id_to_word[id_] for id_ in X_train[0][:10]])\n",
            "'<sos> this film was just brilliant casting location scenery story'\n",
            "\n",
            "--- Chunk 11873 ---\n",
            "In a real project, you will have to preprocess the text yourself. You can do that using\n",
            "\n",
            "--- Chunk 11874 ---\n",
            "the same Tokenizer class we used earlier, but this time setting char_level=False\n",
            "\n",
            "--- Chunk 11875 ---\n",
            "(which is the default). When encoding words, it filters out a lot of characters, includ‐\n",
            "\n",
            "--- Chunk 11876 ---\n",
            "ing most punctuation, line breaks, and tabs (but you can change this by setting the\n",
            "\n",
            "--- Chunk 11877 ---\n",
            "filters argument). Most importantly, it uses spaces to identify word boundaries.\n",
            "\n",
            "--- Chunk 11878 ---\n",
            "This is OK for English and many other scripts (written languages) that use spaces\n",
            "\n",
            "--- Chunk 11879 ---\n",
            "between words, but not all scripts use spaces this way. Chinese does not use spaces\n",
            "\n",
            "--- Chunk 11880 ---\n",
            "between words, Vietnamese uses spaces even within words, and languages such as\n",
            "\n",
            "--- Chunk 11881 ---\n",
            "German often attach multiple words together, without spaces. Even in English, spaces\n",
            "\n",
            "--- Chunk 11882 ---\n",
            "are not always the best way to tokenize text: think of “San Francisco” or\n",
            "“#ILoveDeepLearning.”\n",
            "\n",
            "--- Chunk 11883 ---\n",
            "Fortunately, there are better options! The 2018 paper4 by Taku Kudo introduced an\n",
            "\n",
            "--- Chunk 11884 ---\n",
            "unsupervised learning technique to tokenize and detokenize text at the subword level\n",
            "\n",
            "--- Chunk 11885 ---\n",
            "in a language-independent way, treating spaces like other characters. With this\n",
            "\n",
            "--- Chunk 11886 ---\n",
            "approach, even if your model encounters a word it has never seen before, it can still\n",
            "\n",
            "--- Chunk 11887 ---\n",
            "reasonably guess what it means. For example, it may never have seen the word\n",
            "\n",
            "--- Chunk 11888 ---\n",
            "“smartest” during training, but perhaps it learned the word “smart” and it also\n",
            "\n",
            "--- Chunk 11889 ---\n",
            "learned that the suffix “est” means “the most,” so it can infer the meaning of\n",
            "\n",
            "--- Chunk 11890 ---\n",
            "4 Taku Kudo, “Subword Regularization: Improving Neural Network Translation Models with Multiple Subword\n",
            "\n",
            "--- Chunk 11891 ---\n",
            "Candidates,” arXiv preprint arXiv:1804.10959 (2018).\n",
            "\n",
            "--- Chunk 11892 ---\n",
            "Sentiment Analysis | 535\n",
            "\n",
            "--- Chunk 11893 ---\n",
            "“smartest.” Google’s SentencePiece project provides an open source implementation,\n",
            "described in a paper5 by Taku Kudo and John Richardson.\n",
            "\n",
            "--- Chunk 11894 ---\n",
            "Another option was proposed in an earlier paper6 by Rico Sennrich et al. that\n",
            "\n",
            "--- Chunk 11895 ---\n",
            "explored other ways of creating subword encodings (e.g., using byte pair encoding).\n",
            "\n",
            "--- Chunk 11896 ---\n",
            "Last but not least, the TensorFlow team released the TF.Text library in June 2019,\n",
            "\n",
            "--- Chunk 11897 ---\n",
            "which implements various tokenization strategies, including WordPiece7 (a variant of\n",
            "byte pair encoding).\n",
            "\n",
            "--- Chunk 11898 ---\n",
            "If you want to deploy your model to a mobile device or a web browser, and you don’t\n",
            "\n",
            "--- Chunk 11899 ---\n",
            "want to have to write a different preprocessing function every time, then you will\n",
            "\n",
            "--- Chunk 11900 ---\n",
            "want to handle preprocessing using only TensorFlow operations, so it can be included\n",
            "\n",
            "--- Chunk 11901 ---\n",
            "in the model itself. Let’s see how. First, let’s load the original IMDb reviews, as text\n",
            "\n",
            "--- Chunk 11902 ---\n",
            "(byte strings), using TensorFlow Datasets (introduced in Chapter 13):\n",
            "\n",
            "--- Chunk 11903 ---\n",
            "import tensorflow_datasets as tfds\n",
            "\n",
            "--- Chunk 11904 ---\n",
            "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)\n",
            "train_size = info.splits[\"train\"].num_examples\n",
            "\n",
            "--- Chunk 11905 ---\n",
            "Next, let’s write the preprocessing function:\n",
            "def preprocess(X_batch, y_batch):\n",
            "    X_batch = tf.strings.substr(X_batch, 0, 300)\n",
            "\n",
            "--- Chunk 11906 ---\n",
            "X_batch = tf.strings.regex_replace(X_batch, b\"<br\\\\s*/?>\", b\" \")\n",
            "    X_batch = tf.strings.regex_replace(X_batch, b\"[^a-zA-Z']\", b\" \")\n",
            "\n",
            "--- Chunk 11907 ---\n",
            "X_batch = tf.strings.split(X_batch)\n",
            "    return X_batch.to_tensor(default_value=b\"<pad>\"), y_batch\n",
            "\n",
            "--- Chunk 11908 ---\n",
            "It starts by truncating the reviews, keeping only the first 300 characters of each: this\n",
            "\n",
            "--- Chunk 11909 ---\n",
            "will speed up training, and it won’t impact performance too much because you can\n",
            "\n",
            "--- Chunk 11910 ---\n",
            "generally tell whether a review is positive or not in the first sentence or two. Then it\n",
            "\n",
            "--- Chunk 11911 ---\n",
            "uses regular expressions to replace <br /> tags with spaces, and to replace any charac‐\n",
            "\n",
            "--- Chunk 11912 ---\n",
            "ters other than letters and quotes with spaces. For example, the text \"Well, I\n",
            "\n",
            "--- Chunk 11913 ---\n",
            "can't<br />\" will become \"Well I can't\". Finally, the preprocess() function\n",
            "\n",
            "--- Chunk 11914 ---\n",
            "splits the reviews by the spaces, which returns a ragged tensor, and it converts this\n",
            "\n",
            "--- Chunk 11915 ---\n",
            "ragged tensor to a dense tensor, padding all reviews with the padding token \"<pad>\"\n",
            "so that they all have the same length.\n",
            "\n",
            "--- Chunk 11916 ---\n",
            "5 Taku Kudo and John Richardson, “SentencePiece: A Simple and Language Independent Subword Tokenizer\n",
            "\n",
            "--- Chunk 11917 ---\n",
            "and Detokenizer for Neural Text Processing,” arXiv preprint arXiv:1808.06226 (2018).\n",
            "\n",
            "--- Chunk 11918 ---\n",
            "6 Rico Sennrich et al., “Neural Machine Translation of Rare Words with Subword Units,” Proceedings of the 54th\n",
            "\n",
            "--- Chunk 11919 ---\n",
            "Annual Meeting of the Association for Computational Linguistics 1 (2016): 1715–1725.\n",
            "\n",
            "--- Chunk 11920 ---\n",
            "7 Yonghui Wu et al., “Google’s Neural Machine Translation System: Bridging the Gap Between Human and\n",
            "\n",
            "--- Chunk 11921 ---\n",
            "Machine Translation,” arXiv preprint arXiv:1609.08144 (2016).\n",
            "\n",
            "--- Chunk 11922 ---\n",
            "536 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "--- Chunk 11923 ---\n",
            "Next, we need to construct the vocabulary. This requires going through the whole\n",
            "\n",
            "--- Chunk 11924 ---\n",
            "training set once, applying our preprocess() function, and using a Counter to count\n",
            "the number of occurrences of each word:\n",
            "\n",
            "--- Chunk 11925 ---\n",
            "from collections import Counter\n",
            "vocabulary = Counter()\n",
            "for X_batch, y_batch in datasets[\"train\"].batch(32).map(preprocess):\n",
            "\n",
            "--- Chunk 11926 ---\n",
            "for review in X_batch:\n",
            "        vocabulary.update(list(review.numpy()))\n",
            "\n",
            "--- Chunk 11927 ---\n",
            "Let’s look at the three most common words:\n",
            ">>> vocabulary.most_common()[:3]\n",
            "[(b'<pad>', 215797), (b'the', 61137), (b'a', 38564)]\n",
            "\n",
            "--- Chunk 11928 ---\n",
            "Great! We probably don’t need our model to know all the words in the dictionary to\n",
            "\n",
            "--- Chunk 11929 ---\n",
            "get good performance, though, so let’s truncate the vocabulary, keeping only the\n",
            "10,000 most common words:\n",
            "\n",
            "--- Chunk 11930 ---\n",
            "vocab_size = 10000\n",
            "truncated_vocabulary = [\n",
            "    word for word, count in vocabulary.most_common()[:vocab_size]]\n",
            "\n",
            "--- Chunk 11931 ---\n",
            "Now we need to add a preprocessing step to replace each word with its ID (i.e., its\n",
            "\n",
            "--- Chunk 11932 ---\n",
            "index in the vocabulary). Just like we did in Chapter 13, we will create a lookup table\n",
            "for this, using 1,000 out-of-vocabulary (oov) buckets:\n",
            "\n",
            "--- Chunk 11933 ---\n",
            "words = tf.constant(truncated_vocabulary)\n",
            "word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\n",
            "\n",
            "--- Chunk 11934 ---\n",
            "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
            "num_oov_buckets = 1000\n",
            "\n",
            "--- Chunk 11935 ---\n",
            "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)\n",
            "\n",
            "--- Chunk 11936 ---\n",
            "We can then use this table to look up the IDs of a few words:\n",
            ">>> table.lookup(tf.constant([b\"This movie was faaaaaantastic\".split()]))\n",
            "\n",
            "--- Chunk 11937 ---\n",
            "<tf.Tensor: [...], dtype=int64, numpy=array([[   22,    12,    11, 10054]])>\n",
            "\n",
            "--- Chunk 11938 ---\n",
            "Note that the words “this,” “movie,” and “was” were found in the table, so their IDs\n",
            "\n",
            "--- Chunk 11939 ---\n",
            "are lower than 10,000, while the word “faaaaaantastic” was not found, so it was map‐\n",
            "\n",
            "--- Chunk 11940 ---\n",
            "ped to one of the oov buckets, with an ID greater than or equal to 10,000.\n",
            "\n",
            "--- Chunk 11941 ---\n",
            "TF Transform (introduced in Chapter 13) provides some useful\n",
            "functions to handle such vocabularies. For example, check out the\n",
            "\n",
            "--- Chunk 11942 ---\n",
            "tft.compute_and_apply_vocabulary() function: it will go\n",
            "through the dataset to find all distinct words and build the vocabu‐\n",
            "\n",
            "--- Chunk 11943 ---\n",
            "lary, and it will generate the TF operations required to encode each\n",
            "word using this vocabulary.\n",
            "\n",
            "--- Chunk 11944 ---\n",
            "Now we are ready to create the final training set. We batch the reviews, then convert\n",
            "\n",
            "--- Chunk 11945 ---\n",
            "them to short sequences of words using the preprocess() function, then encode\n",
            "\n",
            "--- Chunk 11946 ---\n",
            "Sentiment Analysis | 537\n",
            "\n",
            "--- Chunk 11947 ---\n",
            "these words using a simple encode_words() function that uses the table we just built,\n",
            "and finally prefetch the next batch:\n",
            "\n",
            "--- Chunk 11948 ---\n",
            "def encode_words(X_batch, y_batch):\n",
            "    return table.lookup(X_batch), y_batch\n",
            "\n",
            "--- Chunk 11949 ---\n",
            "train_set = datasets[\"train\"].batch(32).map(preprocess)\n",
            "train_set = train_set.map(encode_words).prefetch(1)\n",
            "\n",
            "--- Chunk 11950 ---\n",
            "At last we can create the model and train it:\n",
            "embed_size = 128\n",
            "model = keras.models.Sequential([\n",
            "\n",
            "--- Chunk 11951 ---\n",
            "keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size,\n",
            "                           input_shape=[None]),\n",
            "\n",
            "--- Chunk 11952 ---\n",
            "keras.layers.GRU(128, return_sequences=True),\n",
            "    keras.layers.GRU(128),\n",
            "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
            "])\n",
            "\n",
            "--- Chunk 11953 ---\n",
            "])\n",
            "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
            "              metrics=[\"accuracy\"])\n",
            "history = model.fit(train_set, epochs=5)\n",
            "\n",
            "--- Chunk 11954 ---\n",
            "The first layer is an Embedding layer, which will convert word IDs into embeddings\n",
            "\n",
            "--- Chunk 11955 ---\n",
            "(introduced in Chapter 13). The embedding matrix needs to have one row per word\n",
            "\n",
            "--- Chunk 11956 ---\n",
            "ID (vocab_size + num_oov_buckets) and one column per embedding dimension\n",
            "\n",
            "--- Chunk 11957 ---\n",
            "(this example uses 128 dimensions, but this is a hyperparameter you could tune).\n",
            "\n",
            "--- Chunk 11958 ---\n",
            "Whereas the inputs of the model will be 2D tensors of shape [batch size, time steps],\n",
            "\n",
            "--- Chunk 11959 ---\n",
            "the output of the Embedding layer will be a 3D tensor of shape [batch size, time steps,\n",
            "embedding size].\n",
            "\n",
            "--- Chunk 11960 ---\n",
            "embedding size].\n",
            "The rest of the model is fairly straightforward: it is composed of two GRU layers, with\n",
            "\n",
            "--- Chunk 11961 ---\n",
            "the second one returning only the output of the last time step. The output layer is just\n",
            "\n",
            "--- Chunk 11962 ---\n",
            "a single neuron using the sigmoid activation function to output the estimated proba‐\n",
            "\n",
            "--- Chunk 11963 ---\n",
            "bility that the review expresses a positive sentiment regarding the movie. We then\n",
            "\n",
            "--- Chunk 11964 ---\n",
            "compile the model quite simply, and we fit it on the dataset we prepared earlier, for a\n",
            "few epochs.\n",
            "\n",
            "--- Chunk 11965 ---\n",
            "Masking\n",
            "As it stands, the model will need to learn that the padding tokens should be ignored.\n",
            "\n",
            "--- Chunk 11966 ---\n",
            "But we already know that! Why don’t we tell the model to ignore the padding tokens,\n",
            "\n",
            "--- Chunk 11967 ---\n",
            "so that it can focus on the data that actually matters? It’s actually trivial: simply add\n",
            "\n",
            "--- Chunk 11968 ---\n",
            "538 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "--- Chunk 11969 ---\n",
            "mask_zero=True when creating the Embedding layer. This means that padding tokens\n",
            "\n",
            "--- Chunk 11970 ---\n",
            "(whose ID is 0)8 will be ignored by all downstream layers. That’s all!\n",
            "The way this works is that the Embedding layer creates a mask tensor equal to\n",
            "\n",
            "--- Chunk 11971 ---\n",
            "K.not_equal(inputs, 0) (where K = keras.backend): it is a Boolean tensor with\n",
            "\n",
            "--- Chunk 11972 ---\n",
            "the same shape as the inputs, and it is equal to False anywhere the word IDs are 0, or\n",
            "\n",
            "--- Chunk 11973 ---\n",
            "True otherwise. This mask tensor is then automatically propagated by the model to\n",
            "\n",
            "--- Chunk 11974 ---\n",
            "all subsequent layers, as long as the time dimension is preserved. So in this example,\n",
            "\n",
            "--- Chunk 11975 ---\n",
            "both GRU layers will receive this mask automatically, but since the second GRU layer\n",
            "\n",
            "--- Chunk 11976 ---\n",
            "does not return sequences (it only returns the output of the last time step), the mask\n",
            "\n",
            "--- Chunk 11977 ---\n",
            "will not be transmitted to the Dense layer. Each layer may handle the mask differently,\n",
            "\n",
            "--- Chunk 11978 ---\n",
            "but in general they simply ignore masked time steps (i.e., time steps for which the\n",
            "\n",
            "--- Chunk 11979 ---\n",
            "mask is False). For example, when a recurrent layer encounters a masked time step,\n",
            "\n",
            "--- Chunk 11980 ---\n",
            "it simply copies the output from the previous time step. If the mask propagates all the\n",
            "\n",
            "--- Chunk 11981 ---\n",
            "way to the output (in models that output sequences, which is not the case in this\n",
            "\n",
            "--- Chunk 11982 ---\n",
            "example), then it will be applied to the losses as well, so the masked time steps will\n",
            "not contribute to the loss (their loss will be 0).\n",
            "\n",
            "--- Chunk 11983 ---\n",
            "The LSTM and GRU layers have an optimized implementation for\n",
            "GPUs, based on Nvidia’s cuDNN library. However, this implemen‐\n",
            "\n",
            "--- Chunk 11984 ---\n",
            "tation does not support masking. If your model uses a mask, then\n",
            "these layers will fall back to the (much slower) default implementa‐\n",
            "\n",
            "--- Chunk 11985 ---\n",
            "tion. Note that the optimized implementation also requires you to\n",
            "use the default values for several hyperparameters: activation,\n",
            "\n",
            "--- Chunk 11986 ---\n",
            "recurrent_activation, recurrent_dropout, unroll, use_bias,\n",
            "and reset_after.\n",
            "\n",
            "--- Chunk 11987 ---\n",
            "All layers that receive the mask must support masking (or else an exception will be\n",
            "\n",
            "--- Chunk 11988 ---\n",
            "raised). This includes all recurrent layers, as well as the TimeDistributed layer and a\n",
            "\n",
            "--- Chunk 11989 ---\n",
            "few other layers. Any layer that supports masking must have a supports_masking\n",
            "\n",
            "--- Chunk 11990 ---\n",
            "attribute equal to True. If you want to implement your own custom layer with mask‐\n",
            "\n",
            "--- Chunk 11991 ---\n",
            "ing support, you should add a mask argument to the call() method (and obviously\n",
            "make the method use the mask somehow). Additionally, you should set\n",
            "\n",
            "--- Chunk 11992 ---\n",
            "self.supports_masking = True in the constructor. If your layer does not start with\n",
            "\n",
            "--- Chunk 11993 ---\n",
            "an Embedding layer, you may use the keras.layers.Masking layer instead: it sets the\n",
            "\n",
            "--- Chunk 11994 ---\n",
            "mask to K.any(K.not_equal(inputs, 0), axis=-1), meaning that time steps where\n",
            "\n",
            "--- Chunk 11995 ---\n",
            "the last dimension is full of zeros will be masked out in subsequent layers (again, as\n",
            "long as the time dimension exists).\n",
            "\n",
            "--- Chunk 11996 ---\n",
            "8 Their ID is 0 only because they are the most frequent “words” in the dataset. It would probably be a good idea\n",
            "\n",
            "--- Chunk 11997 ---\n",
            "to ensure that the padding tokens are always encoded as 0, even if they are not the most frequent.\n",
            "\n",
            "--- Chunk 11998 ---\n",
            "Sentiment Analysis | 539\n",
            "\n",
            "--- Chunk 11999 ---\n",
            "Using masking layers and automatic mask propagation works best for simple\n",
            "\n",
            "--- Chunk 12000 ---\n",
            "Sequential models. It will not always work for more complex models, such as when\n",
            "\n",
            "--- Chunk 12001 ---\n",
            "you need to mix Conv1D layers with recurrent layers. In such cases, you will need to\n",
            "\n",
            "--- Chunk 12002 ---\n",
            "explicitly compute the mask and pass it to the appropriate layers, using either the\n",
            "\n",
            "--- Chunk 12003 ---\n",
            "Functional API or the Subclassing API. For example, the following model is identical\n",
            "\n",
            "--- Chunk 12004 ---\n",
            "to the previous model, except it is built using the Functional API and handles mask‐\n",
            "ing manually:\n",
            "\n",
            "--- Chunk 12005 ---\n",
            "K = keras.backend\n",
            "inputs = keras.layers.Input(shape=[None])\n",
            "mask = keras.layers.Lambda(lambda inputs: K.not_equal(inputs, 0))(inputs)\n",
            "\n",
            "--- Chunk 12006 ---\n",
            "z = keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size)(inputs)\n",
            "z = keras.layers.GRU(128, return_sequences=True)(z, mask=mask)\n",
            "\n",
            "--- Chunk 12007 ---\n",
            "z = keras.layers.GRU(128)(z, mask=mask)\n",
            "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(z)\n",
            "\n",
            "--- Chunk 12008 ---\n",
            "model = keras.Model(inputs=[inputs], outputs=[outputs])\n",
            "\n",
            "--- Chunk 12009 ---\n",
            "After training for a few epochs, this model will become quite good at judging whether\n",
            "\n",
            "--- Chunk 12010 ---\n",
            "a review is positive or not. If you use the TensorBoard() callback, you can visualize\n",
            "\n",
            "--- Chunk 12011 ---\n",
            "the embeddings in TensorBoard as they are being learned: it is fascinating to see\n",
            "\n",
            "--- Chunk 12012 ---\n",
            "words like “awesome” and “amazing” gradually cluster on one side of the embedding\n",
            "\n",
            "--- Chunk 12013 ---\n",
            "space, while words like “awful” and “terrible” cluster on the other side. Some words\n",
            "\n",
            "--- Chunk 12014 ---\n",
            "are not as positive as you might expect (at least with this model), such as the word\n",
            "\n",
            "--- Chunk 12015 ---\n",
            "“good,” presumably because many negative reviews contain the phrase “not good.” It’s\n",
            "\n",
            "--- Chunk 12016 ---\n",
            "impressive that the model is able to learn useful word embeddings based on just\n",
            "\n",
            "--- Chunk 12017 ---\n",
            "25,000 movie reviews. Imagine how good the embeddings would be if we had billions\n",
            "\n",
            "--- Chunk 12018 ---\n",
            "of reviews to train on! Unfortunately we don’t, but perhaps we can reuse word\n",
            "\n",
            "--- Chunk 12019 ---\n",
            "embeddings trained on some other large text corpus (e.g., Wikipedia articles), even if\n",
            "\n",
            "--- Chunk 12020 ---\n",
            "it is not composed of movie reviews? After all, the word “amazing” generally has the\n",
            "\n",
            "--- Chunk 12021 ---\n",
            "same meaning whether you use it to talk about movies or anything else. Moreover,\n",
            "\n",
            "--- Chunk 12022 ---\n",
            "perhaps embeddings would be useful for sentiment analysis even if they were trained\n",
            "\n",
            "--- Chunk 12023 ---\n",
            "on another task: since words like “awesome” and “amazing” have a similar meaning,\n",
            "\n",
            "--- Chunk 12024 ---\n",
            "they will likely cluster in the embedding space even for other tasks (e.g., predicting\n",
            "\n",
            "--- Chunk 12025 ---\n",
            "the next word in a sentence). If all positive words and all negative words form clus‐\n",
            "\n",
            "--- Chunk 12026 ---\n",
            "ters, then this will be helpful for sentiment analysis. So instead of using so many\n",
            "\n",
            "--- Chunk 12027 ---\n",
            "parameters to learn word embeddings, let’s see if we can’t just reuse pretrained\n",
            "embeddings.\n",
            "\n",
            "--- Chunk 12028 ---\n",
            "Reusing Pretrained Embeddings\n",
            "The TensorFlow Hub project makes it easy to reuse pretrained model components in\n",
            "\n",
            "--- Chunk 12029 ---\n",
            "your own models. These model components are called modules. Simply browse the\n",
            "\n",
            "--- Chunk 12030 ---\n",
            "TF Hub repository, find the one you need, and copy the code example into your\n",
            "\n",
            "--- Chunk 12031 ---\n",
            "project, and the module will be automatically downloaded, along with its pretrained\n",
            "weights, and included in your model. Easy!\n",
            "\n",
            "--- Chunk 12032 ---\n",
            "540 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "--- Chunk 12033 ---\n",
            "For example, let’s use the nnlm-en-dim50 sentence embedding module, version 1, in\n",
            "our sentiment analysis model:\n",
            "\n",
            "import tensorflow_hub as hub\n",
            "\n",
            "--- Chunk 12034 ---\n",
            "model = keras.Sequential([\n",
            "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\",\n",
            "\n",
            "--- Chunk 12035 ---\n",
            "dtype=tf.string, input_shape=[], output_shape=[50]),\n",
            "    keras.layers.Dense(128, activation=\"relu\"),\n",
            "\n",
            "--- Chunk 12036 ---\n",
            "keras.layers.Dense(1, activation=\"sigmoid\")\n",
            "])\n",
            "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
            "              metrics=[\"accuracy\"])\n",
            "\n",
            "--- Chunk 12037 ---\n",
            "The hub.KerasLayer layer downloads the module from the given URL. This particu‐\n",
            "\n",
            "--- Chunk 12038 ---\n",
            "lar module is a sentence encoder: it takes strings as input and encodes each one as a\n",
            "\n",
            "--- Chunk 12039 ---\n",
            "single vector (in this case, a 50-dimensional vector). Internally, it parses the string\n",
            "\n",
            "--- Chunk 12040 ---\n",
            "(splitting words on spaces) and embeds each word using an embedding matrix that\n",
            "\n",
            "--- Chunk 12041 ---\n",
            "was pretrained on a huge corpus: the Google News 7B corpus (seven billion words\n",
            "\n",
            "--- Chunk 12042 ---\n",
            "long!). Then it computes the mean of all the word embeddings, and the result is the\n",
            "\n",
            "--- Chunk 12043 ---\n",
            "sentence embedding.9 We can then add two simple Dense layers to create a good sen‐\n",
            "\n",
            "--- Chunk 12044 ---\n",
            "timent analysis model. By default, a hub.KerasLayer is not trainable, but you can set\n",
            "\n",
            "--- Chunk 12045 ---\n",
            "trainable=True when creating it to change that so that you can fine-tune it for your\n",
            "task.\n",
            "\n",
            "--- Chunk 12046 ---\n",
            "Not all TF Hub modules support TensorFlow 2, so make sure you\n",
            "choose a module that does.\n",
            "\n",
            "--- Chunk 12047 ---\n",
            "Next, we can just load the IMDb reviews dataset—no need to preprocess it (except for\n",
            "batching and prefetching)—and directly train the model:\n",
            "\n",
            "--- Chunk 12048 ---\n",
            "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)\n",
            "train_size = info.splits[\"train\"].num_examples\n",
            "batch_size = 32\n",
            "\n",
            "--- Chunk 12049 ---\n",
            "batch_size = 32\n",
            "train_set = datasets[\"train\"].batch(batch_size).prefetch(1)\n",
            "history = model.fit(train_set, epochs=5)\n",
            "\n",
            "--- Chunk 12050 ---\n",
            "Note that the last part of the TF Hub module URL specified that we wanted version 1\n",
            "\n",
            "--- Chunk 12051 ---\n",
            "of the model. This versioning ensures that if a new module version is released, it will\n",
            "\n",
            "--- Chunk 12052 ---\n",
            "not break our model. Conveniently, if you just enter this URL in a web browser, you\n",
            "\n",
            "--- Chunk 12053 ---\n",
            "9 To be precise, the sentence embedding is equal to the mean word embedding multiplied by the square root of\n",
            "\n",
            "--- Chunk 12054 ---\n",
            "the number of words in the sentence. This compensates for the fact that the mean of n vectors gets shorter as\n",
            "n grows.\n",
            "\n",
            "--- Chunk 12055 ---\n",
            "Sentiment Analysis | 541\n",
            "\n",
            "--- Chunk 12056 ---\n",
            "will get the documentation for this module. By default, TF Hub will cache the down‐\n",
            "\n",
            "--- Chunk 12057 ---\n",
            "loaded files into the local system’s temporary directory. You may prefer to download\n",
            "\n",
            "--- Chunk 12058 ---\n",
            "them into a more permanent directory to avoid having to download them again after\n",
            "\n",
            "--- Chunk 12059 ---\n",
            "every system cleanup. To do that, set the TFHUB_CACHE_DIR environment variable to\n",
            "\n",
            "--- Chunk 12060 ---\n",
            "the directory of your choice (e.g., os.environ[\"TFHUB_CACHE_DIR\"] = \"./\n",
            "my_tfhub_cache\").\n",
            "\n",
            "--- Chunk 12061 ---\n",
            "my_tfhub_cache\").\n",
            "So far, we have looked at time series, text generation using Char-RNN, and sentiment\n",
            "\n",
            "--- Chunk 12062 ---\n",
            "analysis using word-level RNN models, training our own word embeddings or reus‐\n",
            "\n",
            "--- Chunk 12063 ---\n",
            "ing pretrained embeddings. Let’s now look at another important NLP task: neural\n",
            "\n",
            "--- Chunk 12064 ---\n",
            "machine translation (NMT), first using a pure Encoder–Decoder model, then improv‐\n",
            "\n",
            "--- Chunk 12065 ---\n",
            "ing it with attention mechanisms, and finally looking the extraordinary Transformer\n",
            "architecture.\n",
            "\n",
            "--- Chunk 12066 ---\n",
            "An Encoder–Decoder Network for Neural Machine\n",
            "Translation\n",
            "Let’s take a look at a simple neural machine translation model10 that will translate\n",
            "\n",
            "--- Chunk 12067 ---\n",
            "English sentences to French (see Figure 16-3).\n",
            "In short, the English sentences are fed to the encoder, and the decoder outputs the\n",
            "\n",
            "--- Chunk 12068 ---\n",
            "French translations. Note that the French translations are also used as inputs to the\n",
            "\n",
            "--- Chunk 12069 ---\n",
            "decoder, but shifted back by one step. In other words, the decoder is given as input\n",
            "\n",
            "--- Chunk 12070 ---\n",
            "the word that it should have output at the previous step (regardless of what it actually\n",
            "\n",
            "--- Chunk 12071 ---\n",
            "output). For the very first word, it is given the start-of-sequence (SOS) token. The\n",
            "\n",
            "--- Chunk 12072 ---\n",
            "decoder is expected to end the sentence with an end-of-sequence (EOS) token.\n",
            "\n",
            "--- Chunk 12073 ---\n",
            "Note that the English sentences are reversed before they are fed to the encoder. For\n",
            "\n",
            "--- Chunk 12074 ---\n",
            "example, “I drink milk” is reversed to “milk drink I.” This ensures that the beginning\n",
            "\n",
            "--- Chunk 12075 ---\n",
            "of the English sentence will be fed last to the encoder, which is useful because that’s\n",
            "\n",
            "--- Chunk 12076 ---\n",
            "generally the first thing that the decoder needs to translate.\n",
            "Each word is initially represented by its ID (e.g., 288 for the word “milk”). Next, an\n",
            "\n",
            "--- Chunk 12077 ---\n",
            "embedding layer returns the word embedding. These word embeddings are what is\n",
            "actually fed to the encoder and the decoder.\n",
            "\n",
            "--- Chunk 12078 ---\n",
            "10 Ilya Sutskever et al., “Sequence to Sequence Learning with Neural Networks,” arXiv preprint arXiv:1409.3215\n",
            "(2014).\n",
            "\n",
            "--- Chunk 12079 ---\n",
            "542 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "\n",
            "\n",
            "Figure 16-3. A simple machine translation model\n",
            "\n",
            "--- Chunk 12080 ---\n",
            "At each step, the decoder outputs a score for each word in the output vocabulary (i.e.,\n",
            "\n",
            "--- Chunk 12081 ---\n",
            "French), and then the softmax layer turns these scores into probabilities. For exam‐\n",
            "\n",
            "--- Chunk 12082 ---\n",
            "ple, at the first step the word “Je” may have a probability of 20%, “Tu” may have a\n",
            "\n",
            "--- Chunk 12083 ---\n",
            "probability of 1%, and so on. The word with the highest probability is output. This is\n",
            "\n",
            "--- Chunk 12084 ---\n",
            "very much like a regular classification task, so you can train the model using the\n",
            "\n",
            "--- Chunk 12085 ---\n",
            "\"sparse_categorical_crossentropy\" loss, much like we did in the Char-RNN\n",
            "model.\n",
            "\n",
            "--- Chunk 12086 ---\n",
            "model.\n",
            "Note that at inference time (after training), you will not have the target sentence to\n",
            "\n",
            "--- Chunk 12087 ---\n",
            "feed to the decoder. Instead, simply feed the decoder the word that it output at the\n",
            "\n",
            "--- Chunk 12088 ---\n",
            "previous step, as shown in Figure 16-4 (this will require an embedding lookup that is\n",
            "not shown in the diagram).\n",
            "\n",
            "--- Chunk 12089 ---\n",
            "An Encoder–Decoder Network for Neural Machine Translation | 543\n",
            "\n",
            "\n",
            "\n",
            "Figure 16-4. Feeding the previous output word as input at inference time\n",
            "\n",
            "--- Chunk 12090 ---\n",
            "OK, now you have the big picture. Still, there are a few more details to handle if you\n",
            "implement this model:\n",
            "\n",
            "--- Chunk 12091 ---\n",
            "• So far we have assumed that all input sequences (to the encoder and to the\n",
            "\n",
            "--- Chunk 12092 ---\n",
            "decoder) have a constant length. But obviously sentence lengths vary. Since regu‐\n",
            "\n",
            "--- Chunk 12093 ---\n",
            "lar tensors have fixed shapes, they can only contain sentences of the same length.\n",
            "\n",
            "--- Chunk 12094 ---\n",
            "You can use masking to handle this, as discussed earlier. However, if the senten‐\n",
            "\n",
            "--- Chunk 12095 ---\n",
            "ces have very different lengths, you can’t just crop them like we did for sentiment\n",
            "\n",
            "--- Chunk 12096 ---\n",
            "analysis (because we want full translations, not cropped translations). Instead,\n",
            "\n",
            "--- Chunk 12097 ---\n",
            "group sentences into buckets of similar lengths (e.g., a bucket for the 1- to 6-\n",
            "\n",
            "--- Chunk 12098 ---\n",
            "word sentences, another for the 7- to 12-word sentences, and so on), using pad‐\n",
            "\n",
            "--- Chunk 12099 ---\n",
            "ding for the shorter sequences to ensure all sentences in a bucket have the same\n",
            "\n",
            "--- Chunk 12100 ---\n",
            "length (check out the tf.data.experimental.bucket_by_sequence_length()\n",
            "function for this). For example, “I drink milk” becomes “<pad> <pad> <pad>\n",
            "\n",
            "--- Chunk 12101 ---\n",
            "milk drink I.”\n",
            "\n",
            "--- Chunk 12102 ---\n",
            "• We want to ignore any output past the EOS token, so these tokens should not\n",
            "\n",
            "--- Chunk 12103 ---\n",
            "contribute to the loss (they must be masked out). For example, if the model out‐\n",
            "\n",
            "--- Chunk 12104 ---\n",
            "puts “Je bois du lait <eos> oui,” the loss for the last word should be ignored.\n",
            "\n",
            "--- Chunk 12105 ---\n",
            "• When the output vocabulary is large (which is the case here), outputting a proba‐\n",
            "\n",
            "--- Chunk 12106 ---\n",
            "bility for each and every possible word would be terribly slow. If the target\n",
            "\n",
            "--- Chunk 12107 ---\n",
            "vocabulary contains, say, 50,000 French words, then the decoder would output\n",
            "\n",
            "--- Chunk 12108 ---\n",
            "50,000-dimensional vectors, and then computing the softmax function over such\n",
            "\n",
            "--- Chunk 12109 ---\n",
            "a large vector would be very computationally intensive. To avoid this, one solu‐\n",
            "\n",
            "--- Chunk 12110 ---\n",
            "tion is to look only at the logits output by the model for the correct word and for\n",
            "\n",
            "--- Chunk 12111 ---\n",
            "a random sample of incorrect words, then compute an approximation of the loss\n",
            "\n",
            "--- Chunk 12112 ---\n",
            "based only on these logits. This sampled softmax technique was introduced in\n",
            "\n",
            "--- Chunk 12113 ---\n",
            "544 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "--- Chunk 12114 ---\n",
            "2015 by Sébastien Jean et al..11 In TensorFlow you can use the tf.nn.sam\n",
            "\n",
            "--- Chunk 12115 ---\n",
            "pled_softmax_loss() function for this during training and use the normal soft‐\n",
            "\n",
            "--- Chunk 12116 ---\n",
            "max function at inference time (sampled softmax cannot be used at inference\n",
            "time because it requires knowing the target).\n",
            "\n",
            "--- Chunk 12117 ---\n",
            "The TensorFlow Addons project includes many sequence-to-sequence tools to let you\n",
            "\n",
            "--- Chunk 12118 ---\n",
            "easily build production-ready Encoder–Decoders. For example, the following code\n",
            "\n",
            "--- Chunk 12119 ---\n",
            "creates a basic Encoder–Decoder model, similar to the one represented in\n",
            "Figure 16-3:\n",
            "\n",
            "--- Chunk 12120 ---\n",
            "import tensorflow_addons as tfa\n",
            "\n",
            "--- Chunk 12121 ---\n",
            "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
            "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
            "\n",
            "--- Chunk 12122 ---\n",
            "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
            "\n",
            "--- Chunk 12123 ---\n",
            "embeddings = keras.layers.Embedding(vocab_size, embed_size)\n",
            "encoder_embeddings = embeddings(encoder_inputs)\n",
            "\n",
            "--- Chunk 12124 ---\n",
            "decoder_embeddings = embeddings(decoder_inputs)\n",
            "\n",
            "--- Chunk 12125 ---\n",
            "encoder = keras.layers.LSTM(512, return_state=True)\n",
            "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
            "\n",
            "--- Chunk 12126 ---\n",
            "encoder_state = [state_h, state_c]\n",
            "\n",
            "--- Chunk 12127 ---\n",
            "sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
            "\n",
            "--- Chunk 12128 ---\n",
            "decoder_cell = keras.layers.LSTMCell(512)\n",
            "output_layer = keras.layers.Dense(vocab_size)\n",
            "\n",
            "--- Chunk 12129 ---\n",
            "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, sampler,\n",
            "                                                 output_layer=output_layer)\n",
            "\n",
            "--- Chunk 12130 ---\n",
            "final_outputs, final_state, final_sequence_lengths = decoder(\n",
            "    decoder_embeddings, initial_state=encoder_state,\n",
            "\n",
            "--- Chunk 12131 ---\n",
            "sequence_length=sequence_lengths)\n",
            "Y_proba = tf.nn.softmax(final_outputs.rnn_output)\n",
            "\n",
            "--- Chunk 12132 ---\n",
            "model = keras.Model(inputs=[encoder_inputs, decoder_inputs, sequence_lengths],\n",
            "                    outputs=[Y_proba])\n",
            "\n",
            "--- Chunk 12133 ---\n",
            "The code is mostly self-explanatory, but there are a few points to note. First, we set\n",
            "\n",
            "--- Chunk 12134 ---\n",
            "return_state=True when creating the LSTM layer so that we can get its final hidden\n",
            "\n",
            "--- Chunk 12135 ---\n",
            "state and pass it to the decoder. Since we are using an LSTM cell, it actually returns\n",
            "\n",
            "--- Chunk 12136 ---\n",
            "two hidden states (short term and long term). The TrainingSampler is one of several\n",
            "\n",
            "--- Chunk 12137 ---\n",
            "samplers available in TensorFlow Addons: their role is to tell the decoder at each step\n",
            "\n",
            "--- Chunk 12138 ---\n",
            "what it should pretend the previous output was. During inference, this should be the\n",
            "\n",
            "--- Chunk 12139 ---\n",
            "11 Sébastien Jean et al., “On Using Very Large Target Vocabulary for Neural Machine Translation,” Proceedings of\n",
            "\n",
            "--- Chunk 12140 ---\n",
            "the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Con‐\n",
            "\n",
            "--- Chunk 12141 ---\n",
            "ference on Natural Language Processing of the Asian Federation of Natural Language Processing 1 (2015): 1–10.\n",
            "\n",
            "--- Chunk 12142 ---\n",
            "An Encoder–Decoder Network for Neural Machine Translation | 545\n",
            "\n",
            "--- Chunk 12143 ---\n",
            "embedding of the token that was actually output. During training, it should be the\n",
            "\n",
            "--- Chunk 12144 ---\n",
            "embedding of the previous target token: this is why we used the TrainingSampler. In\n",
            "\n",
            "--- Chunk 12145 ---\n",
            "practice, it is often a good idea to start training with the embedding of the target of\n",
            "\n",
            "--- Chunk 12146 ---\n",
            "the previous time step and gradually transition to using the embedding of the actual\n",
            "\n",
            "--- Chunk 12147 ---\n",
            "token that was output at the previous step. This idea was introduced in a 2015 paper12\n",
            "\n",
            "--- Chunk 12148 ---\n",
            "by Samy Bengio et al. The ScheduledEmbeddingTrainingSampler will randomly\n",
            "\n",
            "--- Chunk 12149 ---\n",
            "choose between the target or the actual output, with a probability that you can gradu‐\n",
            "ally change during training.\n",
            "\n",
            "--- Chunk 12150 ---\n",
            "Bidirectional RNNs\n",
            "A each time step, a regular recurrent layer only looks at past and present inputs\n",
            "\n",
            "--- Chunk 12151 ---\n",
            "before generating its output. In other words, it is “causal,” meaning it cannot look into\n",
            "\n",
            "--- Chunk 12152 ---\n",
            "the future. This type of RNN makes sense when forecasting time series, but for many\n",
            "\n",
            "--- Chunk 12153 ---\n",
            "NLP tasks, such as Neural Machine Translation, it is often preferable to look ahead at\n",
            "\n",
            "--- Chunk 12154 ---\n",
            "the next words before encoding a given word. For example, consider the phrases “the\n",
            "\n",
            "--- Chunk 12155 ---\n",
            "Queen of the United Kingdom,” “the queen of hearts,” and “the queen bee”: to prop‐\n",
            "\n",
            "--- Chunk 12156 ---\n",
            "erly encode the word “queen,” you need to look ahead. To implement this, run two\n",
            "\n",
            "--- Chunk 12157 ---\n",
            "recurrent layers on the same inputs, one reading the words from left to right and the\n",
            "\n",
            "--- Chunk 12158 ---\n",
            "other reading them from right to left. Then simply combine their outputs at each\n",
            "\n",
            "--- Chunk 12159 ---\n",
            "time step, typically by concatenating them. This is called a bidirectional recurrent layer\n",
            "(see Figure 16-5).\n",
            "\n",
            "--- Chunk 12160 ---\n",
            "(see Figure 16-5).\n",
            "To implement a bidirectional recurrent layer in Keras, wrap a recurrent layer in a\n",
            "\n",
            "--- Chunk 12161 ---\n",
            "keras.layers.Bidirectional layer. For example, the following code creates a bidir‐\n",
            "ectional GRU layer:\n",
            "\n",
            "--- Chunk 12162 ---\n",
            "keras.layers.Bidirectional(keras.layers.GRU(10, return_sequences=True))\n",
            "\n",
            "--- Chunk 12163 ---\n",
            "The Bidirectional layer will create a clone of the GRU layer (but in\n",
            "the reverse direction), and it will run both and concatenate their\n",
            "\n",
            "--- Chunk 12164 ---\n",
            "outputs. So although the GRU layer has 10 units, the Bidirectional\n",
            "layer will output 20 values per time step.\n",
            "\n",
            "--- Chunk 12165 ---\n",
            "12 Samy Bengio et al., “Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks,” arXiv\n",
            "preprint arXiv:1506.03099 (2015).\n",
            "\n",
            "--- Chunk 12166 ---\n",
            "546 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "\n",
            "\n",
            "Figure 16-5. A bidirectional recurrent layer\n",
            "\n",
            "--- Chunk 12167 ---\n",
            "Beam Search\n",
            "Suppose you train an Encoder–Decoder model, and use it to translate the French sen‐\n",
            "\n",
            "--- Chunk 12168 ---\n",
            "tence “Comment vas-tu?” to English. You are hoping that it will output the proper\n",
            "\n",
            "--- Chunk 12169 ---\n",
            "translation (“How are you?”), but unfortunately it outputs “How will you?” Looking\n",
            "\n",
            "--- Chunk 12170 ---\n",
            "at the training set, you notice many sentences such as “Comment vas-tu jouer?”\n",
            "\n",
            "--- Chunk 12171 ---\n",
            "which translates to “How will you play?” So it wasn’t absurd for the model to output\n",
            "\n",
            "--- Chunk 12172 ---\n",
            "“How will” after seeing “Comment vas.” Unfortunately, in this case it was a mistake,\n",
            "\n",
            "--- Chunk 12173 ---\n",
            "and the model could not go back and fix it, so it tried to complete the sentence as best\n",
            "\n",
            "--- Chunk 12174 ---\n",
            "it could. By greedily outputting the most likely word at every step, it ended up with a\n",
            "\n",
            "--- Chunk 12175 ---\n",
            "suboptimal translation. How can we give the model a chance to go back and fix mis‐\n",
            "\n",
            "--- Chunk 12176 ---\n",
            "takes it made earlier? One of the most common solutions is beam search: it keeps\n",
            "\n",
            "--- Chunk 12177 ---\n",
            "track of a short list of the k most promising sentences (say, the top three), and at each\n",
            "\n",
            "--- Chunk 12178 ---\n",
            "decoder step it tries to extend them by one word, keeping only the k most likely sen‐\n",
            "tences. The parameter k is called the beam width.\n",
            "\n",
            "--- Chunk 12179 ---\n",
            "For example, suppose you use the model to translate the sentence “Comment vas-tu?”\n",
            "\n",
            "--- Chunk 12180 ---\n",
            "using beam search with a beam width of 3. At the first decoder step, the model will\n",
            "\n",
            "--- Chunk 12181 ---\n",
            "output an estimated probability for each possible word. Suppose the top three words\n",
            "\n",
            "--- Chunk 12182 ---\n",
            "are “How” (75% estimated probability), “What” (3%), and “You” (1%). That’s our\n",
            "\n",
            "--- Chunk 12183 ---\n",
            "short list so far. Next, we create three copies of our model and use them to find the\n",
            "\n",
            "--- Chunk 12184 ---\n",
            "next word for each sentence. Each model will output one estimated probability per\n",
            "\n",
            "--- Chunk 12185 ---\n",
            "word in the vocabulary. The first model will try to find the next word in the sentence\n",
            "\n",
            "--- Chunk 12186 ---\n",
            "“How,” and perhaps it will output a probability of 36% for the word “will,” 32% for the\n",
            "\n",
            "--- Chunk 12187 ---\n",
            "word “are,” 16% for the word “do,” and so on. Note that these are actually conditional\n",
            "\n",
            "--- Chunk 12188 ---\n",
            "probabilities, given that the sentence starts with “How.” The second model will try to\n",
            "\n",
            "--- Chunk 12189 ---\n",
            "complete the sentence “What”; it might output a conditional probability of 50% for\n",
            "\n",
            "--- Chunk 12190 ---\n",
            "An Encoder–Decoder Network for Neural Machine Translation | 547\n",
            "\n",
            "--- Chunk 12191 ---\n",
            "the word “are,” and so on. Assuming the vocabulary has 10,000 words, each model\n",
            "will output 10,000 probabilities.\n",
            "\n",
            "--- Chunk 12192 ---\n",
            "Next, we compute the probabilities of each of the 30,000 two-word sentences that\n",
            "\n",
            "--- Chunk 12193 ---\n",
            "these models considered (3 × 10,000). We do this by multiplying the estimated condi‐\n",
            "\n",
            "--- Chunk 12194 ---\n",
            "tional probability of each word by the estimated probability of the sentence it com‐\n",
            "\n",
            "--- Chunk 12195 ---\n",
            "pletes. For example, the estimated probability of the sentence “How” was 75%, while\n",
            "\n",
            "--- Chunk 12196 ---\n",
            "the estimated conditional probability of the word “will” (given that the first word is\n",
            "\n",
            "--- Chunk 12197 ---\n",
            "“How”) was 36%, so the estimated probability of the sentence “How will” is 75% ×\n",
            "\n",
            "--- Chunk 12198 ---\n",
            "36% = 27%. After computing the probabilities of all 30,000 two-word sentences, we\n",
            "\n",
            "--- Chunk 12199 ---\n",
            "keep only the top 3. Perhaps they all start with the word “How”: “How will” (27%),\n",
            "\n",
            "--- Chunk 12200 ---\n",
            "“How are” (24%), and “How do” (12%). Right now, the sentence “How will” is win‐\n",
            "ning, but “How are” has not been eliminated.\n",
            "\n",
            "--- Chunk 12201 ---\n",
            "Then we repeat the same process: we use three models to predict the next word in\n",
            "\n",
            "--- Chunk 12202 ---\n",
            "each of these three sentences, and we compute the probabilities of all 30,000 three-\n",
            "\n",
            "--- Chunk 12203 ---\n",
            "word sentences we considered. Perhaps the top three are now “How are you” (10%),\n",
            "\n",
            "--- Chunk 12204 ---\n",
            "“How do you” (8%), and “How will you” (2%). At the next step we may get “How do\n",
            "\n",
            "--- Chunk 12205 ---\n",
            "you do” (7%), “How are you <eos>” (6%), and “How are you doing” (3%). Notice that\n",
            "\n",
            "--- Chunk 12206 ---\n",
            "“How will” was eliminated, and we now have three perfectly reasonable translations.\n",
            "\n",
            "--- Chunk 12207 ---\n",
            "We boosted our Encoder–Decoder model’s performance without any extra training,\n",
            "simply by using it more wisely.\n",
            "\n",
            "--- Chunk 12208 ---\n",
            "You can implement beam search fairly easily using TensorFlow Addons:\n",
            "\n",
            "--- Chunk 12209 ---\n",
            "beam_width = 10\n",
            "decoder = tfa.seq2seq.beam_search_decoder.BeamSearchDecoder(\n",
            "\n",
            "--- Chunk 12210 ---\n",
            "cell=decoder_cell, beam_width=beam_width, output_layer=output_layer)\n",
            "decoder_initial_state = tfa.seq2seq.beam_search_decoder.tile_batch(\n",
            "\n",
            "--- Chunk 12211 ---\n",
            "encoder_state, multiplier=beam_width)\n",
            "outputs, _, _ = decoder(\n",
            "    embedding_decoder, start_tokens=start_tokens, end_token=end_token,\n",
            "\n",
            "--- Chunk 12212 ---\n",
            "initial_state=decoder_initial_state)\n",
            "\n",
            "--- Chunk 12213 ---\n",
            "We first create a BeamSearchDecoder, which wraps all the decoder clones (in this case\n",
            "\n",
            "--- Chunk 12214 ---\n",
            "10 clones). Then we create one copy of the encoder’s final state for each decoder\n",
            "\n",
            "--- Chunk 12215 ---\n",
            "clone, and we pass these states to the decoder, along with the start and end tokens.\n",
            "\n",
            "--- Chunk 12216 ---\n",
            "With all this, you can get good translations for fairly short sentences (especially if you\n",
            "\n",
            "--- Chunk 12217 ---\n",
            "use pretrained word embeddings). Unfortunately, this model will be really bad at\n",
            "\n",
            "--- Chunk 12218 ---\n",
            "translating long sentences. Once again, the problem comes from the limited short-\n",
            "\n",
            "--- Chunk 12219 ---\n",
            "term memory of RNNs. Attention mechanisms are the game-changing innovation that\n",
            "addressed this problem.\n",
            "\n",
            "--- Chunk 12220 ---\n",
            "548 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "--- Chunk 12221 ---\n",
            "Attention Mechanisms\n",
            "Consider the path from the word “milk” to its translation “lait” in Figure 16-3: it is\n",
            "\n",
            "--- Chunk 12222 ---\n",
            "quite long! This means that a representation of this word (along with all the other\n",
            "\n",
            "--- Chunk 12223 ---\n",
            "words) needs to be carried over many steps before it is actually used. Can’t we make\n",
            "this path shorter?\n",
            "\n",
            "--- Chunk 12224 ---\n",
            "this path shorter?\n",
            "This was the core idea in a groundbreaking 2014 paper13 by Dzmitry Bahdanau et al.\n",
            "\n",
            "--- Chunk 12225 ---\n",
            "They introduced a technique that allowed the decoder to focus on the appropriate\n",
            "\n",
            "--- Chunk 12226 ---\n",
            "words (as encoded by the encoder) at each time step. For example, at the time step\n",
            "\n",
            "--- Chunk 12227 ---\n",
            "where the decoder needs to output the word “lait,” it will focus its attention on the\n",
            "\n",
            "--- Chunk 12228 ---\n",
            "word “milk.” This means that the path from an input word to its translation is now\n",
            "\n",
            "--- Chunk 12229 ---\n",
            "much shorter, so the short-term memory limitations of RNNs have much less impact.\n",
            "\n",
            "--- Chunk 12230 ---\n",
            "Attention mechanisms revolutionized neural machine translation (and NLP in gen‐\n",
            "\n",
            "--- Chunk 12231 ---\n",
            "eral), allowing a significant improvement in the state of the art, especially for long\n",
            "sentences (over 30 words).14\n",
            "\n",
            "--- Chunk 12232 ---\n",
            "Figure 16-6 shows this model’s architecture (slightly simplified, as we will see). On the\n",
            "\n",
            "--- Chunk 12233 ---\n",
            "left, you have the encoder and the decoder. Instead of just sending the encoder’s final\n",
            "\n",
            "--- Chunk 12234 ---\n",
            "hidden state to the decoder (which is still done, although it is not shown in the fig‐\n",
            "\n",
            "--- Chunk 12235 ---\n",
            "ure), we now send all of its outputs to the decoder. At each time step, the decoder’s\n",
            "\n",
            "--- Chunk 12236 ---\n",
            "memory cell computes a weighted sum of all these encoder outputs: this determines\n",
            "\n",
            "--- Chunk 12237 ---\n",
            "which words it will focus on at this step. The weight α(t,i) is the weight of the ith\n",
            "\n",
            "--- Chunk 12238 ---\n",
            "encoder output at the tth decoder time step. For example, if the weight α(3,2) is much\n",
            "\n",
            "--- Chunk 12239 ---\n",
            "larger than the weights α(3,0) and α(3,1), then the decoder will pay much more attention\n",
            "\n",
            "--- Chunk 12240 ---\n",
            "to word number 2 (“milk”) than to the other two words, at least at this time step. The\n",
            "\n",
            "--- Chunk 12241 ---\n",
            "rest of the decoder works just like earlier: at each time step the memory cell receives\n",
            "\n",
            "--- Chunk 12242 ---\n",
            "the inputs we just discussed, plus the hidden state from the previous time step, and\n",
            "\n",
            "--- Chunk 12243 ---\n",
            "finally (although it is not represented in the diagram) it receives the target word from\n",
            "\n",
            "--- Chunk 12244 ---\n",
            "the previous time step (or at inference time, the output from the previous time step).\n",
            "\n",
            "--- Chunk 12245 ---\n",
            "13 Dzmitry Bahdanau et al., “Neural Machine Translation by Jointly Learning to Align and Translate,” arXiv pre‐\n",
            "print arXiv:1409.0473 (2014).\n",
            "\n",
            "--- Chunk 12246 ---\n",
            "14 The most common metric used in NMT is the BiLingual Evaluation Understudy (BLEU) score, which com‐\n",
            "\n",
            "--- Chunk 12247 ---\n",
            "pares each translation produced by the model with several good translations produced by humans: it counts\n",
            "\n",
            "--- Chunk 12248 ---\n",
            "the number of n-grams (sequences of n words) that appear in any of the target translations and adjusts the\n",
            "\n",
            "--- Chunk 12249 ---\n",
            "score to take into account the frequency of the produced n-grams in the target translations.\n",
            "\n",
            "--- Chunk 12250 ---\n",
            "Attention Mechanisms | 549\n",
            "\n",
            "\n",
            "\n",
            "Figure 16-6. Neural machine translation using an Encoder–Decoder network with an\n",
            "attention model\n",
            "\n",
            "--- Chunk 12251 ---\n",
            "But where do these α(t,i) weights come from? It’s actually pretty simple: they are gener‐\n",
            "\n",
            "--- Chunk 12252 ---\n",
            "ated by a type of small neural network called an alignment model (or an attention\n",
            "\n",
            "--- Chunk 12253 ---\n",
            "layer), which is trained jointly with the rest of the Encoder–Decoder model. This\n",
            "\n",
            "--- Chunk 12254 ---\n",
            "alignment model is illustrated on the righthand side of Figure 16-6. It starts with a\n",
            "\n",
            "--- Chunk 12255 ---\n",
            "time-distributed Dense layer15 with a single neuron, which receives as input all the\n",
            "\n",
            "--- Chunk 12256 ---\n",
            "encoder outputs, concatenated with the decoder’s previous hidden state (e.g., h(2)).\n",
            "\n",
            "--- Chunk 12257 ---\n",
            "This layer outputs a score (or energy) for each encoder output (e.g., e(3, 2)): this score\n",
            "\n",
            "--- Chunk 12258 ---\n",
            "measures how well each output is aligned with the decoder’s previous hidden state.\n",
            "\n",
            "--- Chunk 12259 ---\n",
            "Finally, all the scores go through a softmax layer to get a final weight for each encoder\n",
            "\n",
            "--- Chunk 12260 ---\n",
            "output (e.g., α(3,2)). All the weights for a given decoder time step add up to 1 (since the\n",
            "\n",
            "--- Chunk 12261 ---\n",
            "softmax layer is not time-distributed). This particular attention mechanism is called\n",
            "\n",
            "--- Chunk 12262 ---\n",
            "Bahdanau attention (named after the paper’s first author). Since it concatenates the\n",
            "\n",
            "--- Chunk 12263 ---\n",
            "encoder output with the decoder’s previous hidden state, it is sometimes called con‐\n",
            "catenative attention (or additive attention).\n",
            "\n",
            "--- Chunk 12264 ---\n",
            "15 Recall that a time-distributed Dense layer is equivalent to a regular Dense layer that you apply independently\n",
            "\n",
            "--- Chunk 12265 ---\n",
            "at each time step (only much faster).\n",
            "\n",
            "--- Chunk 12266 ---\n",
            "550 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "--- Chunk 12267 ---\n",
            "If the input sentence is n words long, and assuming the output sen‐\n",
            "tence is about as long, then this model will need to compute about\n",
            "\n",
            "--- Chunk 12268 ---\n",
            "n2 weights. Fortunately, this quadratic computational complexity is\n",
            "still tractable because even long sentences don’t have thousands of\n",
            "words.\n",
            "\n",
            "--- Chunk 12269 ---\n",
            "Another common attention mechanism was proposed shortly after, in a 2015 paper16\n",
            "\n",
            "--- Chunk 12270 ---\n",
            "by Minh-Thang Luong et al. Because the goal of the attention mechanism is to meas‐\n",
            "\n",
            "--- Chunk 12271 ---\n",
            "ure the similarity between one of the encoder’s outputs and the decoder’s previous\n",
            "\n",
            "--- Chunk 12272 ---\n",
            "hidden state, the authors proposed to simply compute the dot product (see Chapter 4)\n",
            "\n",
            "--- Chunk 12273 ---\n",
            "of these two vectors, as this is often a fairly good similarity measure, and modern\n",
            "\n",
            "--- Chunk 12274 ---\n",
            "hardware can compute it much faster. For this to be possible, both vectors must have\n",
            "\n",
            "--- Chunk 12275 ---\n",
            "the same dimensionality. This is called Luong attention (again, after the paper’s first\n",
            "\n",
            "--- Chunk 12276 ---\n",
            "author), or sometimes multiplicative attention. The dot product gives a score, and all\n",
            "\n",
            "--- Chunk 12277 ---\n",
            "the scores (at a given decoder time step) go through a softmax layer to give the final\n",
            "\n",
            "--- Chunk 12278 ---\n",
            "weights, just like in Bahdanau attention. Another simplification they proposed was to\n",
            "\n",
            "--- Chunk 12279 ---\n",
            "use the decoder’s hidden state at the current time step rather than at the previous time\n",
            "\n",
            "--- Chunk 12280 ---\n",
            "step (i.e., h(t)) rather than h(t–1)), then to use the output of the attention mechanism\n",
            "\n",
            "--- Chunk 12281 ---\n",
            "(noted � t ) directly to compute the decoder’s predictions (rather than using it to\n",
            "\n",
            "--- Chunk 12282 ---\n",
            "compute the decoder’s current hidden state). They also proposed a variant of the dot\n",
            "\n",
            "--- Chunk 12283 ---\n",
            "product mechanism where the encoder outputs first go through a linear transforma‐\n",
            "\n",
            "--- Chunk 12284 ---\n",
            "tion (i.e., a time-distributed Dense layer without a bias term) before the dot products\n",
            "\n",
            "--- Chunk 12285 ---\n",
            "are computed. This is called the “general” dot product approach. They compared both\n",
            "\n",
            "--- Chunk 12286 ---\n",
            "dot product approaches to the concatenative attention mechanism (adding a rescaling\n",
            "\n",
            "--- Chunk 12287 ---\n",
            "parameter vector v), and they observed that the dot product variants performed bet‐\n",
            "\n",
            "--- Chunk 12288 ---\n",
            "ter than concatenative attention. For this reason, concatenative attention is much less\n",
            "\n",
            "--- Chunk 12289 ---\n",
            "used now. The equations for these three attention mechanisms are summarized in\n",
            "Equation 16-1.\n",
            "\n",
            "--- Chunk 12290 ---\n",
            "16 Minh-Thang Luong et al., “Effective Approaches to Attention-Based Neural Machine Translation,” Proceed‐\n",
            "\n",
            "--- Chunk 12291 ---\n",
            "ings of the 2015 Conference on Empirical Methods in Natural Language Processing (2015): 1412–1421.\n",
            "\n",
            "--- Chunk 12292 ---\n",
            "Attention Mechanisms | 551\n",
            "\n",
            "\n",
            "\n",
            "Equation 16-1. Attention mechanisms\n",
            "� t = ∑α\n",
            "\n",
            "i t, i � i\n",
            "\n",
            "exp e\n",
            "with α t, i\n",
            "\n",
            "t, i =\n",
            "∑i exp e\n",
            "\n",
            "′ t, i′\n",
            "\n",
            "� ⊺\n",
            "t � i dot\n",
            "\n",
            "--- Chunk 12293 ---\n",
            "� ⊺\n",
            "t � i dot\n",
            "\n",
            "and e ⊺\n",
            "t, i = � t �� i general\n",
            "\n",
            "�⊺ tanh � � t ; � i concat\n",
            "\n",
            "--- Chunk 12294 ---\n",
            "Here is how you can add Luong attention to an Encoder–Decoder model using Ten‐\n",
            "sorFlow Addons:\n",
            "\n",
            "--- Chunk 12295 ---\n",
            "attention_mechanism = tfa.seq2seq.attention_wrapper.LuongAttention(\n",
            "    units, encoder_state, memory_sequence_length=encoder_sequence_length)\n",
            "\n",
            "--- Chunk 12296 ---\n",
            "attention_decoder_cell = tfa.seq2seq.attention_wrapper.AttentionWrapper(\n",
            "    decoder_cell, attention_mechanism, attention_layer_size=n_units)\n",
            "\n",
            "--- Chunk 12297 ---\n",
            "We simply wrap the decoder cell in an AttentionWrapper, and we provide the desired\n",
            "attention mechanism (Luong attention in this example).\n",
            "\n",
            "--- Chunk 12298 ---\n",
            "Visual Attention\n",
            "Attention mechanisms are now used for a variety of purposes. One of their first appli‐\n",
            "\n",
            "--- Chunk 12299 ---\n",
            "cations beyond NMT was in generating image captions using visual attention:17 a\n",
            "\n",
            "--- Chunk 12300 ---\n",
            "convolutional neural network first processes the image and outputs some feature\n",
            "\n",
            "--- Chunk 12301 ---\n",
            "maps, then a decoder RNN equipped with an attention mechanism generates the cap‐\n",
            "\n",
            "--- Chunk 12302 ---\n",
            "tion, one word at a time. At each decoder time step (each word), the decoder uses the\n",
            "\n",
            "--- Chunk 12303 ---\n",
            "attention model to focus on just the right part of the image. For example, in\n",
            "\n",
            "--- Chunk 12304 ---\n",
            "Figure 16-7, the model generated the caption “A woman is throwing a frisbee in a\n",
            "\n",
            "--- Chunk 12305 ---\n",
            "park,” and you can see what part of the input image the decoder focused its attention\n",
            "\n",
            "--- Chunk 12306 ---\n",
            "on when it was about to output the word “frisbee”: clearly, most of its attention was\n",
            "focused on the frisbee.\n",
            "\n",
            "--- Chunk 12307 ---\n",
            "17 Kelvin Xu et al., “Show, Attend and Tell: Neural Image Caption Generation with Visual Attention,” Proceedings\n",
            "\n",
            "--- Chunk 12308 ---\n",
            "of the 32nd International Conference on Machine Learning (2015): 2048–2057.\n",
            "\n",
            "--- Chunk 12309 ---\n",
            "552 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "--- Chunk 12310 ---\n",
            "Figure 16-7. Visual attention: an input image (left) and the model’s focus before produc‐\n",
            "ing the word “frisbee” (right)18\n",
            "\n",
            "--- Chunk 12311 ---\n",
            "Explainability\n",
            "One extra benefit of attention mechanisms is that they make it easier to understand\n",
            "\n",
            "--- Chunk 12312 ---\n",
            "what led the model to produce its output. This is called explainability. It can be espe‐\n",
            "\n",
            "--- Chunk 12313 ---\n",
            "cially useful when the model makes a mistake: for example, if an image of a dog walk‐\n",
            "\n",
            "--- Chunk 12314 ---\n",
            "ing in the snow is labeled as “a wolf walking in the snow,” then you can go back and\n",
            "\n",
            "--- Chunk 12315 ---\n",
            "check what the model focused on when it output the word “wolf.” You may find that it\n",
            "\n",
            "--- Chunk 12316 ---\n",
            "was paying attention not only to the dog, but also to the snow, hinting at a possible\n",
            "\n",
            "--- Chunk 12317 ---\n",
            "explanation: perhaps the way the model learned to distinguish dogs from wolves is by\n",
            "\n",
            "--- Chunk 12318 ---\n",
            "checking whether or not there’s a lot of snow around. You can then fix this by training\n",
            "\n",
            "--- Chunk 12319 ---\n",
            "the model with more images of wolves without snow, and dogs with snow. This exam‐\n",
            "\n",
            "--- Chunk 12320 ---\n",
            "ple comes from a great 2016 paper19 by Marco Tulio Ribeiro et al. that uses a different\n",
            "\n",
            "--- Chunk 12321 ---\n",
            "approach to explainability: learning an interpretable model locally around a classi‐\n",
            "fier’s prediction.\n",
            "\n",
            "--- Chunk 12322 ---\n",
            "fier’s prediction.\n",
            "In some applications, explainability is not just a tool to debug a model; it can be a\n",
            "\n",
            "--- Chunk 12323 ---\n",
            "legal requirement (think of a system deciding whether or not it should grant you a\n",
            "loan).\n",
            "\n",
            "--- Chunk 12324 ---\n",
            "18 This is a part of figure 3 from the paper. It is reproduced with the kind authorization of the authors.\n",
            "\n",
            "--- Chunk 12325 ---\n",
            "19 Marco Tulio Ribeiro et al., “‘Why Should I Trust You?’: Explaining the Predictions of Any Classifier,” Proceed‐\n",
            "\n",
            "--- Chunk 12326 ---\n",
            "ings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (2016):\n",
            "1135–1144.\n",
            "\n",
            "Attention Mechanisms | 553\n",
            "\n",
            "--- Chunk 12327 ---\n",
            "Attention mechanisms are so powerful that you can actually build state-of-the-art\n",
            "models using only attention mechanisms.\n",
            "\n",
            "--- Chunk 12328 ---\n",
            "Attention Is All You Need: The Transformer Architecture\n",
            "In a groundbreaking 2017 paper,20 a team of Google researchers suggested that\n",
            "\n",
            "--- Chunk 12329 ---\n",
            "“Attention Is All You Need.” They managed to create an architecture called the Trans‐\n",
            "\n",
            "--- Chunk 12330 ---\n",
            "former, which significantly improved the state of the art in NMT without using any\n",
            "\n",
            "--- Chunk 12331 ---\n",
            "recurrent or convolutional layers,21 just attention mechanisms (plus embedding lay‐\n",
            "\n",
            "--- Chunk 12332 ---\n",
            "ers, dense layers, normalization layers, and a few other bits and pieces). As an extra\n",
            "\n",
            "--- Chunk 12333 ---\n",
            "bonus, this architecture was also much faster to train and easier to parallelize, so they\n",
            "\n",
            "--- Chunk 12334 ---\n",
            "managed to train it at a fraction of the time and cost of the previous state-of-the-art\n",
            "models.\n",
            "\n",
            "--- Chunk 12335 ---\n",
            "models.\n",
            "The Transformer architecture is represented in Figure 16-8.\n",
            "\n",
            "--- Chunk 12336 ---\n",
            "20 Ashish Vaswani et al., “Attention Is All You Need,” Proceedings of the 31st International Conference on Neural\n",
            "\n",
            "--- Chunk 12337 ---\n",
            "Information Processing Systems (2017): 6000–6010.\n",
            "\n",
            "--- Chunk 12338 ---\n",
            "21 Since the Transformer uses time-distributed Dense layers, you could argue that it uses 1D convolutional layers\n",
            "with a kernel size of 1.\n",
            "\n",
            "--- Chunk 12339 ---\n",
            "554 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "\n",
            "\n",
            "Figure 16-8. The Transformer architecture22\n",
            "\n",
            "--- Chunk 12340 ---\n",
            "Let’s walk through this figure:\n",
            "\n",
            "--- Chunk 12341 ---\n",
            "• The lefthand part is the encoder. Just like earlier, it takes as input a batch of sen‐\n",
            "\n",
            "--- Chunk 12342 ---\n",
            "tences represented as sequences of word IDs (the input shape is [batch size, max\n",
            "\n",
            "--- Chunk 12343 ---\n",
            "input sentence length]), and it encodes each word into a 512-dimensional repre‐\n",
            "\n",
            "--- Chunk 12344 ---\n",
            "sentation (so the encoder’s output shape is [batch size, max input sentence length,\n",
            "\n",
            "--- Chunk 12345 ---\n",
            "512]). Note that the top part of the encoder is stacked N times (in the paper,\n",
            "N = 6).\n",
            "\n",
            "--- Chunk 12346 ---\n",
            "22 This is figure 1 from the paper, reproduced with the kind authorization of the authors.\n",
            "\n",
            "Attention Mechanisms | 555\n",
            "\n",
            "--- Chunk 12347 ---\n",
            "• The righthand part is the decoder. During training, it takes the target sentence as\n",
            "\n",
            "--- Chunk 12348 ---\n",
            "input (also represented as a sequence of word IDs), shifted one time step to the\n",
            "\n",
            "--- Chunk 12349 ---\n",
            "right (i.e., a start-of-sequence token is inserted at the beginning). It also receives\n",
            "\n",
            "--- Chunk 12350 ---\n",
            "the outputs of the encoder (i.e., the arrows coming from the left side). Note that\n",
            "\n",
            "--- Chunk 12351 ---\n",
            "the top part of the decoder is also stacked N times, and the encoder stack’s final\n",
            "\n",
            "--- Chunk 12352 ---\n",
            "outputs are fed to the decoder at each of these N levels. Just like earlier, the\n",
            "\n",
            "--- Chunk 12353 ---\n",
            "decoder outputs a probability for each possible next word, at each time step (its\n",
            "\n",
            "--- Chunk 12354 ---\n",
            "output shape is [batch size, max output sentence length, vocabulary length]).\n",
            "\n",
            "--- Chunk 12355 ---\n",
            "• During inference, the decoder cannot be fed targets, so we feed it the previously\n",
            "\n",
            "--- Chunk 12356 ---\n",
            "output words (starting with a start-of-sequence token). So the model needs to be\n",
            "\n",
            "--- Chunk 12357 ---\n",
            "called repeatedly, predicting one more word at every round (which is fed to the\n",
            "\n",
            "--- Chunk 12358 ---\n",
            "decoder at the next round, until the end-of-sequence token is output).\n",
            "\n",
            "--- Chunk 12359 ---\n",
            "• Looking more closely, you can see that you are already familiar with most com‐\n",
            "\n",
            "--- Chunk 12360 ---\n",
            "ponents: there are two embedding layers, 5 × N skip connections, each of them\n",
            "\n",
            "--- Chunk 12361 ---\n",
            "followed by a layer normalization layer, 2 × N “Feed Forward” modules that are\n",
            "\n",
            "--- Chunk 12362 ---\n",
            "composed of two dense layers each (the first one using the ReLU activation func‐\n",
            "\n",
            "--- Chunk 12363 ---\n",
            "tion, the second with no activation function), and finally the output layer is a\n",
            "\n",
            "--- Chunk 12364 ---\n",
            "dense layer using the softmax activation function. All of these layers are time-\n",
            "\n",
            "--- Chunk 12365 ---\n",
            "distributed, so each word is treated independently of all the others. But how can\n",
            "\n",
            "--- Chunk 12366 ---\n",
            "we translate a sentence by only looking at one word at a time? Well, that’s where\n",
            "the new components come in:\n",
            "\n",
            "--- Chunk 12367 ---\n",
            "— The encoder’s Multi-Head Attention layer encodes each word’s relationship\n",
            "\n",
            "--- Chunk 12368 ---\n",
            "with every other word in the same sentence, paying more attention to the\n",
            "\n",
            "--- Chunk 12369 ---\n",
            "most relevant ones. For example, the output of this layer for the word “Queen”\n",
            "in the sentence “They welcomed the Queen of the United Kingdom” will\n",
            "\n",
            "--- Chunk 12370 ---\n",
            "depend on all the words in the sentence, but it will probably pay more atten‐\n",
            "\n",
            "--- Chunk 12371 ---\n",
            "tion to the words “United” and “Kingdom” than to the words “They” or “wel‐\n",
            "comed.” This attention mechanism is called self-attention (the sentence is\n",
            "\n",
            "--- Chunk 12372 ---\n",
            "paying attention to itself). We will discuss exactly how it works shortly. The\n",
            "\n",
            "--- Chunk 12373 ---\n",
            "decoder’s Masked Multi-Head Attention layer does the same thing, but each\n",
            "\n",
            "--- Chunk 12374 ---\n",
            "word is only allowed to attend to words located before it. Finally, the decoder’s\n",
            "\n",
            "--- Chunk 12375 ---\n",
            "upper Multi-Head Attention layer is where the decoder pays attention to the\n",
            "\n",
            "--- Chunk 12376 ---\n",
            "words in the input sentence. For example, the decoder will probably pay close\n",
            "\n",
            "--- Chunk 12377 ---\n",
            "attention to the word “Queen” in the input sentence when it is about to output\n",
            "this word’s translation.\n",
            "\n",
            "--- Chunk 12378 ---\n",
            "— The positional embeddings are simply dense vectors (much like word embed‐\n",
            "\n",
            "--- Chunk 12379 ---\n",
            "dings) that represent the position of a word in the sentence. The nth positional\n",
            "\n",
            "--- Chunk 12380 ---\n",
            "embedding is added to the word embedding of the nth word in each sentence.\n",
            "\n",
            "--- Chunk 12381 ---\n",
            "This gives the model access to each word’s position, which is needed because\n",
            "\n",
            "--- Chunk 12382 ---\n",
            "the Multi-Head Attention layers do not consider the order or the position of\n",
            "\n",
            "--- Chunk 12383 ---\n",
            "the words; they only look at their relationships. Since all the other layers are\n",
            "\n",
            "--- Chunk 12384 ---\n",
            "556 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "--- Chunk 12385 ---\n",
            "time-distributed, they have no way of knowing the position of each word\n",
            "\n",
            "--- Chunk 12386 ---\n",
            "(either relative or absolute). Obviously, the relative and absolute word posi‐\n",
            "\n",
            "--- Chunk 12387 ---\n",
            "tions are important, so we need to give this information to the Transformer\n",
            "somehow, and positional embeddings are a good way to do this.\n",
            "\n",
            "--- Chunk 12388 ---\n",
            "Let’s look a bit closer at both these novel components of the Transformer architecture,\n",
            "starting with the positional embeddings.\n",
            "\n",
            "--- Chunk 12389 ---\n",
            "Positional embeddings\n",
            "A positional embedding is a dense vector that encodes the position of a word within a\n",
            "\n",
            "--- Chunk 12390 ---\n",
            "sentence: the ith positional embedding is simply added to the word embedding of the\n",
            "\n",
            "--- Chunk 12391 ---\n",
            "ith word in the sentence. These positional embeddings can be learned by the model,\n",
            "\n",
            "--- Chunk 12392 ---\n",
            "but in the paper the authors preferred to use fixed positional embeddings, defined\n",
            "\n",
            "--- Chunk 12393 ---\n",
            "using the sine and cosine functions of different frequencies. The positional embed‐\n",
            "\n",
            "--- Chunk 12394 ---\n",
            "ding matrix P is defined in Equation 16-2 and represented at the bottom of\n",
            "\n",
            "--- Chunk 12395 ---\n",
            "Figure 16-9 (transposed), where Pp,i is the ith component of the embedding for the\n",
            "word located at the pth position in the sentence.\n",
            "\n",
            "--- Chunk 12396 ---\n",
            "Equation 16-2. Sine/cosine positional embeddings\n",
            "Pp, 2i = sin p/100002i/d\n",
            "\n",
            "Pp, 2i + 1 = cos p/100002i/d\n",
            "\n",
            "--- Chunk 12397 ---\n",
            "Figure 16-9. Sine/cosine positional embedding matrix (transposed, top) with a focus on\n",
            "two values of i (bottom)\n",
            "\n",
            "Attention Mechanisms | 557\n",
            "\n",
            "--- Chunk 12398 ---\n",
            "This solution gives the same performance as learned positional embeddings do, but it\n",
            "\n",
            "--- Chunk 12399 ---\n",
            "can extend to arbitrarily long sentences, which is why it’s favored. After the positional\n",
            "\n",
            "--- Chunk 12400 ---\n",
            "embeddings are added to the word embeddings, the rest of the model has access to\n",
            "\n",
            "--- Chunk 12401 ---\n",
            "the absolute position of each word in the sentence because there is a unique posi‐\n",
            "\n",
            "--- Chunk 12402 ---\n",
            "tional embedding for each position (e.g., the positional embedding for the word loca‐\n",
            "\n",
            "--- Chunk 12403 ---\n",
            "ted at the 22nd position in a sentence is represented by the vertical dashed line at the\n",
            "\n",
            "--- Chunk 12404 ---\n",
            "bottom left of Figure 16-9, and you can see that it is unique to that position). More‐\n",
            "\n",
            "--- Chunk 12405 ---\n",
            "over, the choice of oscillating functions (sine and cosine) makes it possible for the\n",
            "\n",
            "--- Chunk 12406 ---\n",
            "model to learn relative positions as well. For example, words located 38 words apart\n",
            "\n",
            "--- Chunk 12407 ---\n",
            "(e.g., at positions p = 22 and p = 60) always have the same positional embedding val‐\n",
            "\n",
            "--- Chunk 12408 ---\n",
            "ues in the embedding dimensions i = 100 and i = 101, as you can see in Figure 16-9.\n",
            "\n",
            "--- Chunk 12409 ---\n",
            "This explains why we need both the sine and the cosine for each frequency: if we only\n",
            "\n",
            "--- Chunk 12410 ---\n",
            "used the sine (the blue wave at i = 100), the model would not be able to distinguish\n",
            "positions p = 25 and p = 35 (marked by a cross).\n",
            "\n",
            "--- Chunk 12411 ---\n",
            "There is no PositionalEmbedding layer in TensorFlow, but it is easy to create one.\n",
            "\n",
            "--- Chunk 12412 ---\n",
            "For efficiency reasons, we precompute the positional embedding matrix in the con‐\n",
            "\n",
            "--- Chunk 12413 ---\n",
            "structor (so we need to know the maximum sentence length, max_steps, and the\n",
            "\n",
            "--- Chunk 12414 ---\n",
            "number of dimensions for each word representation, max_dims). Then the call()\n",
            "\n",
            "--- Chunk 12415 ---\n",
            "method crops this embedding matrix to the size of the inputs, and it adds it to the\n",
            "\n",
            "--- Chunk 12416 ---\n",
            "inputs. Since we added an extra first dimension of size 1 when creating the positional\n",
            "\n",
            "--- Chunk 12417 ---\n",
            "embedding matrix, the rules of broadcasting will ensure that the matrix gets added to\n",
            "every sentence in the inputs:\n",
            "\n",
            "--- Chunk 12418 ---\n",
            "class PositionalEncoding(keras.layers.Layer):\n",
            "    def __init__(self, max_steps, max_dims, dtype=tf.float32, **kwargs):\n",
            "\n",
            "--- Chunk 12419 ---\n",
            "super().__init__(dtype=dtype, **kwargs)\n",
            "        if max_dims % 2 == 1: max_dims += 1 # max_dims must be even\n",
            "\n",
            "--- Chunk 12420 ---\n",
            "p, i = np.meshgrid(np.arange(max_steps), np.arange(max_dims // 2))\n",
            "        pos_emb = np.empty((1, max_steps, max_dims))\n",
            "\n",
            "--- Chunk 12421 ---\n",
            "pos_emb[0, :, ::2] = np.sin(p / 10000**(2 * i / max_dims)).T\n",
            "        pos_emb[0, :, 1::2] = np.cos(p / 10000**(2 * i / max_dims)).T\n",
            "\n",
            "--- Chunk 12422 ---\n",
            "self.positional_embedding = tf.constant(pos_emb.astype(self.dtype))\n",
            "    def call(self, inputs):\n",
            "        shape = tf.shape(inputs)\n",
            "\n",
            "--- Chunk 12423 ---\n",
            "return inputs + self.positional_embedding[:, :shape[-2], :shape[-1]]\n",
            "\n",
            "--- Chunk 12424 ---\n",
            "Then we can create the first layers of the Transformer:\n",
            "embed_size = 512; max_steps = 500; vocab_size = 10000\n",
            "\n",
            "--- Chunk 12425 ---\n",
            "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
            "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
            "\n",
            "--- Chunk 12426 ---\n",
            "embeddings = keras.layers.Embedding(vocab_size, embed_size)\n",
            "encoder_embeddings = embeddings(encoder_inputs)\n",
            "\n",
            "--- Chunk 12427 ---\n",
            "decoder_embeddings = embeddings(decoder_inputs)\n",
            "positional_encoding = PositionalEncoding(max_steps, max_dims=embed_size)\n",
            "\n",
            "--- Chunk 12428 ---\n",
            "encoder_in = positional_encoding(encoder_embeddings)\n",
            "decoder_in = positional_encoding(decoder_embeddings)\n",
            "\n",
            "--- Chunk 12429 ---\n",
            "558 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "--- Chunk 12430 ---\n",
            "Now let’s look deeper into the heart of the Transformer model: the Multi-Head Atten‐\n",
            "tion layer.\n",
            "\n",
            "--- Chunk 12431 ---\n",
            "Multi-Head Attention\n",
            "To understand how a Multi-Head Attention layer works, we must first understand the\n",
            "\n",
            "--- Chunk 12432 ---\n",
            "Scaled Dot-Product Attention layer, which it is based on. Let’s suppose the encoder\n",
            "\n",
            "--- Chunk 12433 ---\n",
            "analyzed the input sentence “They played chess,” and it managed to understand that\n",
            "\n",
            "--- Chunk 12434 ---\n",
            "the word “They” is the subject and the word “played” is the verb, so it encoded this\n",
            "\n",
            "--- Chunk 12435 ---\n",
            "information in the representations of these words. Now suppose the decoder has\n",
            "\n",
            "--- Chunk 12436 ---\n",
            "already translated the subject, and it thinks that it should translate the verb next. For\n",
            "\n",
            "--- Chunk 12437 ---\n",
            "this, it needs to fetch the verb from the input sentence. This is analog to a dictionary\n",
            "\n",
            "--- Chunk 12438 ---\n",
            "lookup: it’s as if the encoder created a dictionary {“subject”: “They”, “verb”: “played”,\n",
            "\n",
            "--- Chunk 12439 ---\n",
            "…} and the decoder wanted to look up the value that corresponds to the key “verb.”\n",
            "\n",
            "--- Chunk 12440 ---\n",
            "However, the model does not have discrete tokens to represent the keys (like “subject”\n",
            "\n",
            "--- Chunk 12441 ---\n",
            "or “verb”); it has vectorized representations of these concepts (which it learned dur‐\n",
            "\n",
            "--- Chunk 12442 ---\n",
            "ing training), so the key it will use for the lookup (called the query) will not perfectly\n",
            "\n",
            "--- Chunk 12443 ---\n",
            "match any key in the dictionary. The solution is to compute a similarity measure\n",
            "\n",
            "--- Chunk 12444 ---\n",
            "between the query and each key in the dictionary, and then use the softmax function\n",
            "\n",
            "--- Chunk 12445 ---\n",
            "to convert these similarity scores to weights that add up to 1. If the key that represents\n",
            "\n",
            "--- Chunk 12446 ---\n",
            "the verb is by far the most similar to the query, then that key’s weight will be close to\n",
            "\n",
            "--- Chunk 12447 ---\n",
            "1. Then the model can compute a weighted sum of the corresponding values, so if the\n",
            "\n",
            "--- Chunk 12448 ---\n",
            "weight of the “verb” key is close to 1, then the weighted sum will be very close to the\n",
            "\n",
            "--- Chunk 12449 ---\n",
            "representation of the word “played.” In short, you can think of this whole process as a\n",
            "\n",
            "--- Chunk 12450 ---\n",
            "differentiable dictionary lookup. The similarity measure used by the Transformer is\n",
            "\n",
            "--- Chunk 12451 ---\n",
            "just the dot product, like in Luong attention. In fact, the equation is the same as for\n",
            "\n",
            "--- Chunk 12452 ---\n",
            "Luong attention, except for a scaling factor. The equation is shown in Equation 16-3,\n",
            "in a vectorized form.\n",
            "\n",
            "--- Chunk 12453 ---\n",
            "Equation 16-3. Scaled Dot-Product Attention\n",
            "\n",
            "Attention �,�,� = softmax ��⊺\n",
            "�\n",
            "\n",
            "dkeys\n",
            "\n",
            "In this equation:\n",
            "\n",
            "--- Chunk 12454 ---\n",
            "• Q is a matrix containing one row per query. Its shape is [nqueries, dkeys], where\n",
            "\n",
            "--- Chunk 12455 ---\n",
            "nqueries is the number of queries and dkeys is the number of dimensions of each\n",
            "query and each key.\n",
            "\n",
            "--- Chunk 12456 ---\n",
            "• K is a matrix containing one row per key. Its shape is [nkeys, dkeys], where nkeys is\n",
            "the number of keys and values.\n",
            "\n",
            "Attention Mechanisms | 559\n",
            "\n",
            "--- Chunk 12457 ---\n",
            "• V is a matrix containing one row per value. Its shape is [nkeys, dvalues], where dvalues\n",
            "is the number of each value.\n",
            "\n",
            "--- Chunk 12458 ---\n",
            "• The shape of Q K⊺ is [nqueries, nkeys]: it contains one similarity score for each\n",
            "\n",
            "--- Chunk 12459 ---\n",
            "query/key pair. The output of the softmax function has the same shape, but all\n",
            "\n",
            "--- Chunk 12460 ---\n",
            "rows sum up to 1. The final output has a shape of [nqueries, dvalues]: there is one row\n",
            "\n",
            "--- Chunk 12461 ---\n",
            "per query, where each row represents the query result (a weighted sum of the val‐\n",
            "ues).\n",
            "\n",
            "--- Chunk 12462 ---\n",
            "• The scaling factor scales down the similarity scores to avoid saturating the soft‐\n",
            "max function, which would lead to tiny gradients.\n",
            "\n",
            "--- Chunk 12463 ---\n",
            "• It is possible to mask out some key/value pairs by adding a very large negative\n",
            "\n",
            "--- Chunk 12464 ---\n",
            "value to the corresponding similarity scores, just before computing the softmax.\n",
            "This is useful in the Masked Multi-Head Attention layer.\n",
            "\n",
            "--- Chunk 12465 ---\n",
            "In the encoder, this equation is applied to every input sentence in the batch, with Q,\n",
            "\n",
            "--- Chunk 12466 ---\n",
            "K, and V all equal to the list of words in the input sentence (so each word in the sen‐\n",
            "\n",
            "--- Chunk 12467 ---\n",
            "tence will be compared to every word in the same sentence, including itself). Simi‐\n",
            "\n",
            "--- Chunk 12468 ---\n",
            "larly, in the decoder’s masked attention layer, the equation will be applied to every\n",
            "\n",
            "--- Chunk 12469 ---\n",
            "target sentence in the batch, with Q, K, and V all equal to the list of words in the tar‐\n",
            "\n",
            "--- Chunk 12470 ---\n",
            "get sentence, but this time using a mask to prevent any word from comparing itself to\n",
            "\n",
            "--- Chunk 12471 ---\n",
            "words located after it (at inference time the decoder will only have access to the words\n",
            "\n",
            "--- Chunk 12472 ---\n",
            "it already output, not to future words, so during training we must mask out future\n",
            "\n",
            "--- Chunk 12473 ---\n",
            "output tokens). In the upper attention layer of the decoder, the keys K and values V\n",
            "\n",
            "--- Chunk 12474 ---\n",
            "are simply the list of word encodings produced by the encoder, and the queries Q are\n",
            "the list of word encodings produced by the decoder.\n",
            "\n",
            "--- Chunk 12475 ---\n",
            "The keras.layers.Attention layer implements Scaled Dot-Product Attention, effi‐\n",
            "\n",
            "--- Chunk 12476 ---\n",
            "ciently applying Equation 16-3 to multiple sentences in a batch. Its inputs are just like\n",
            "\n",
            "--- Chunk 12477 ---\n",
            "Q, K, and V, except with an extra batch dimension (the first dimension).\n",
            "\n",
            "--- Chunk 12478 ---\n",
            "In TensorFlow, if A and B are tensors with more than two dimen‐\n",
            "sions—say, of shape [2, 3, 4, 5] and [2, 3, 5, 6] respectively—then\n",
            "\n",
            "--- Chunk 12479 ---\n",
            "tf.matmul(A, B) will treat these tensors as 2 × 3 arrays where each\n",
            "cell contains a matrix, and it will multiply the corresponding matri‐\n",
            "\n",
            "--- Chunk 12480 ---\n",
            "ces: the matrix at the ith row and jth column in A will be multiplied\n",
            "by the matrix at the ith row and jth column in B. Since the product of\n",
            "\n",
            "--- Chunk 12481 ---\n",
            "a 4 × 5 matrix with a 5 × 6 matrix is a 4 × 6 matrix, tf.matmul(A,\n",
            "B) will return an array of shape [2, 3, 4, 6].\n",
            "\n",
            "--- Chunk 12482 ---\n",
            "560 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "--- Chunk 12483 ---\n",
            "If we ignore the skip connections, the layer normalization layers, the Feed Forward\n",
            "\n",
            "--- Chunk 12484 ---\n",
            "blocks, and the fact that this is Scaled Dot-Product Attention, not exactly Multi-Head\n",
            "\n",
            "--- Chunk 12485 ---\n",
            "Attention, then the rest of the Transformer model can be implemented like this:\n",
            "\n",
            "--- Chunk 12486 ---\n",
            "Z = encoder_in\n",
            "for N in range(6):\n",
            "    Z = keras.layers.Attention(use_scale=True)([Z, Z])\n",
            "\n",
            "--- Chunk 12487 ---\n",
            "encoder_outputs = Z\n",
            "Z = decoder_in\n",
            "for N in range(6):\n",
            "    Z = keras.layers.Attention(use_scale=True, causal=True)([Z, Z])\n",
            "\n",
            "--- Chunk 12488 ---\n",
            "Z = keras.layers.Attention(use_scale=True)([Z, encoder_outputs])\n",
            "\n",
            "--- Chunk 12489 ---\n",
            "outputs = keras.layers.TimeDistributed(\n",
            "    keras.layers.Dense(vocab_size, activation=\"softmax\"))(Z)\n",
            "\n",
            "--- Chunk 12490 ---\n",
            "The use_scale=True argument creates an additional parameter that lets the layer\n",
            "\n",
            "--- Chunk 12491 ---\n",
            "learn how to properly downscale the similarity scores. This is a bit different from the\n",
            "\n",
            "--- Chunk 12492 ---\n",
            "Transformer model, which always downscales the similarity scores by the same factor\n",
            "\n",
            "--- Chunk 12493 ---\n",
            "( dkeys). The causal=True argument when creating the second attention layer\n",
            "\n",
            "--- Chunk 12494 ---\n",
            "ensures that each output token only attends to previous output tokens, not future\n",
            "ones.\n",
            "\n",
            "--- Chunk 12495 ---\n",
            "ones.\n",
            "Now it’s time to look at the final piece of the puzzle: what is a Multi-Head Attention\n",
            "layer? Its architecture is shown in Figure 16-10.\n",
            "\n",
            "--- Chunk 12496 ---\n",
            "Attention Mechanisms | 561\n",
            "\n",
            "\n",
            "\n",
            "Figure 16-10. Multi-Head Attention layer architecture23\n",
            "\n",
            "--- Chunk 12497 ---\n",
            "As you can see, it is just a bunch of Scaled Dot-Product Attention layers, each pre‐\n",
            "\n",
            "--- Chunk 12498 ---\n",
            "ceded by a linear transformation of the values, keys, and queries (i.e., a time-\n",
            "\n",
            "--- Chunk 12499 ---\n",
            "distributed Dense layer with no activation function). All the outputs are simply\n",
            "\n",
            "--- Chunk 12500 ---\n",
            "concatenated, and they go through a final linear transformation (again, time-\n",
            "\n",
            "--- Chunk 12501 ---\n",
            "distributed). But why? What is the intuition behind this architecture? Well, consider\n",
            "\n",
            "--- Chunk 12502 ---\n",
            "the word “played” we discussed earlier (in the sentence “They played chess”). The\n",
            "\n",
            "--- Chunk 12503 ---\n",
            "encoder was smart enough to encode the fact that it is a verb. But the word represen‐\n",
            "\n",
            "--- Chunk 12504 ---\n",
            "tation also includes its position in the text, thanks to the positional encodings, and it\n",
            "\n",
            "--- Chunk 12505 ---\n",
            "probably includes many other features that are useful for its translation, such as the\n",
            "\n",
            "--- Chunk 12506 ---\n",
            "fact that it is in the past tense. In short, the word representation encodes many differ‐\n",
            "\n",
            "--- Chunk 12507 ---\n",
            "ent characteristics of the word. If we just used a single Scaled Dot-Product Attention\n",
            "\n",
            "--- Chunk 12508 ---\n",
            "layer, we would only be able to query all of these characteristics in one shot. This is\n",
            "\n",
            "--- Chunk 12509 ---\n",
            "why the Multi-Head Attention layer applies multiple different linear transformations\n",
            "\n",
            "--- Chunk 12510 ---\n",
            "of the values, keys, and queries: this allows the model to apply many different projec‐\n",
            "\n",
            "--- Chunk 12511 ---\n",
            "tions of the word representation into different subspaces, each focusing on a subset of\n",
            "\n",
            "--- Chunk 12512 ---\n",
            "the word’s characteristics. Perhaps one of the linear layers will project the word repre‐\n",
            "\n",
            "--- Chunk 12513 ---\n",
            "sentation into a subspace where all that remains is the information that the word is a\n",
            "\n",
            "--- Chunk 12514 ---\n",
            "23 This is the right part of figure 2 from the paper, reproduced with the kind authorization of the authors.\n",
            "\n",
            "--- Chunk 12515 ---\n",
            "562 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "--- Chunk 12516 ---\n",
            "verb, another linear layer will extract just the fact that it is past tense, and so on. Then\n",
            "\n",
            "--- Chunk 12517 ---\n",
            "the Scaled Dot-Product Attention layers implement the lookup phase, and finally we\n",
            "\n",
            "--- Chunk 12518 ---\n",
            "concatenate all the results and project them back to the original space.\n",
            "\n",
            "--- Chunk 12519 ---\n",
            "At the time of this writing, there is no Transformer class or MultiHeadAttention\n",
            "\n",
            "--- Chunk 12520 ---\n",
            "class available for TensorFlow 2. However, you can check out TensorFlow’s great tuto‐\n",
            "\n",
            "--- Chunk 12521 ---\n",
            "rial for building a Transformer model for language understanding. Moreover, the TF\n",
            "\n",
            "--- Chunk 12522 ---\n",
            "Hub team is currently porting several Transformer-based modules to TensorFlow 2,\n",
            "\n",
            "--- Chunk 12523 ---\n",
            "and they should be available soon. In the meantime, I hope I have demonstrated that\n",
            "\n",
            "--- Chunk 12524 ---\n",
            "it is not that hard to implement a Transformer yourself, and it is certainly a great\n",
            "exercise!\n",
            "\n",
            "--- Chunk 12525 ---\n",
            "Recent Innovations in Language Models\n",
            "The year 2018 has been called the “ImageNet moment for NLP”: progress was\n",
            "\n",
            "--- Chunk 12526 ---\n",
            "astounding, with larger and larger LSTM and Transformer-based architectures\n",
            "\n",
            "--- Chunk 12527 ---\n",
            "trained on immense datasets. I highly recommend you check out the following\n",
            "papers, all published in 2018:\n",
            "\n",
            "--- Chunk 12528 ---\n",
            "• The ELMo paper24 by Matthew Peters introduced Embeddings from Language\n",
            "Models (ELMo): these are contextualized word embeddings learned from the\n",
            "\n",
            "--- Chunk 12529 ---\n",
            "internal states of a deep bidirectional language model. For example, the word\n",
            "\n",
            "--- Chunk 12530 ---\n",
            "“queen” will not have the same embedding in “Queen of the United Kingdom”\n",
            "and in “queen bee.”\n",
            "\n",
            "--- Chunk 12531 ---\n",
            "• The ULMFiT paper25 by Jeremy Howard and Sebastian Ruder demonstrated the\n",
            "\n",
            "--- Chunk 12532 ---\n",
            "effectiveness of unsupervised pretraining for NLP tasks: the authors trained an\n",
            "\n",
            "--- Chunk 12533 ---\n",
            "LSTM language model using self-supervised learning (i.e., generating the labels\n",
            "\n",
            "--- Chunk 12534 ---\n",
            "automatically from the data) on a huge text corpus, then they fine-tuned it on\n",
            "\n",
            "--- Chunk 12535 ---\n",
            "various tasks. Their model outperformed the state of the art on six text classifica‐\n",
            "\n",
            "--- Chunk 12536 ---\n",
            "tion tasks by a large margin (reducing the error rate by 18–24% in most cases).\n",
            "\n",
            "--- Chunk 12537 ---\n",
            "Moreover, they showed that by fine-tuning the pretrained model on just 100\n",
            "\n",
            "--- Chunk 12538 ---\n",
            "labeled examples, they could achieve the same performance as a model trained\n",
            "from scratch on 10,000 examples.\n",
            "\n",
            "--- Chunk 12539 ---\n",
            "• The GPT paper26 by Alec Radford and other OpenAI researchers also demon‐\n",
            "\n",
            "--- Chunk 12540 ---\n",
            "strated the effectiveness of unsupervised pretraining, but this time using a\n",
            "\n",
            "--- Chunk 12541 ---\n",
            "24 Matthew Peters et al., “Deep Contextualized Word Representations,” Proceedings of the 2018 Conference of the\n",
            "\n",
            "--- Chunk 12542 ---\n",
            "North American Chapter of the Association for Computational Linguistics: Human Language Technologies 1\n",
            "(2018): 2227–2237.\n",
            "\n",
            "--- Chunk 12543 ---\n",
            "25 Jeremy Howard and Sebastian Ruder, “Universal Language Model Fine-Tuning for Text Classification,” Pro‐\n",
            "\n",
            "--- Chunk 12544 ---\n",
            "ceedings of the 56th Annual Meeting of the Association for Computational Linguistics 1 (2018): 328–339.\n",
            "\n",
            "--- Chunk 12545 ---\n",
            "26 Alec Radford et al., “Improving Language Understanding by Generative Pre-Training” (2018).\n",
            "\n",
            "Recent Innovations in Language Models | 563\n",
            "\n",
            "--- Chunk 12546 ---\n",
            "Transformer-like architecture. The authors pretrained a large but fairly simple\n",
            "\n",
            "--- Chunk 12547 ---\n",
            "architecture composed of a stack of 12 Transformer modules (using only Masked\n",
            "\n",
            "--- Chunk 12548 ---\n",
            "Multi-Head Attention layers) on a large dataset, once again trained using self-\n",
            "\n",
            "--- Chunk 12549 ---\n",
            "supervised learning. Then they fine-tuned it on various language tasks, using\n",
            "\n",
            "--- Chunk 12550 ---\n",
            "only minor adaptations for each task. The tasks were quite diverse: they included\n",
            "\n",
            "--- Chunk 12551 ---\n",
            "text classification, entailment (whether sentence A entails sentence B),27 similarity\n",
            "\n",
            "--- Chunk 12552 ---\n",
            "(e.g., “Nice weather today” is very similar to “It is sunny”), and question answer‐\n",
            "\n",
            "--- Chunk 12553 ---\n",
            "ing (given a few paragraphs of text giving some context, the model must answer\n",
            "\n",
            "--- Chunk 12554 ---\n",
            "some multiple-choice questions). Just a few months later, in February 2019, Alec\n",
            "\n",
            "--- Chunk 12555 ---\n",
            "Radford, Jeffrey Wu, and other OpenAI researchers published the GPT-2 paper,28\n",
            "\n",
            "--- Chunk 12556 ---\n",
            "which proposed a very similar architecture, but larger still (with over 1.5 billion\n",
            "\n",
            "--- Chunk 12557 ---\n",
            "parameters!) and they showed that it could achieve good performance on many\n",
            "\n",
            "--- Chunk 12558 ---\n",
            "tasks without any fine-tuning. This is called zero-shot learning (ZSL). A smaller\n",
            "\n",
            "--- Chunk 12559 ---\n",
            "version of the GPT-2 model (with “just” 117 million parameters) is available at\n",
            "https://github.com/openai/gpt-2, along with its pretrained weights.\n",
            "\n",
            "--- Chunk 12560 ---\n",
            "• The BERT paper29 by Jacob Devlin and other Google researchers also demon‐\n",
            "\n",
            "--- Chunk 12561 ---\n",
            "strates the effectiveness of self-supervised pretraining on a large corpus, using a\n",
            "\n",
            "--- Chunk 12562 ---\n",
            "similar architecture to GPT but non-masked Multi-Head Attention layers (like in\n",
            "\n",
            "--- Chunk 12563 ---\n",
            "the Transformer’s encoder). This means that the model is naturally bidirectional;\n",
            "\n",
            "--- Chunk 12564 ---\n",
            "hence the B in BERT (Bidirectional Encoder Representations from Transformers).\n",
            "\n",
            "--- Chunk 12565 ---\n",
            "Most importantly, the authors proposed two pretraining tasks that explain most\n",
            "of the model’s strength:\n",
            "Masked language model (MLM)\n",
            "\n",
            "--- Chunk 12566 ---\n",
            "Each word in a sentence has a 15% probability of being masked, and the\n",
            "model is trained to predict the masked words. For example, if the original\n",
            "\n",
            "--- Chunk 12567 ---\n",
            "sentence is “She had fun at the birthday party,” then the model may be given\n",
            "\n",
            "--- Chunk 12568 ---\n",
            "the sentence “She <mask> fun at the <mask> party” and it must predict the\n",
            "words “had” and “birthday” (the other outputs will be ignored). To be more\n",
            "\n",
            "--- Chunk 12569 ---\n",
            "precise, each selected word has an 80% chance of being masked, a 10%\n",
            "chance of being replaced by a random word (to reduce the discrepancy\n",
            "\n",
            "--- Chunk 12570 ---\n",
            "between pretraining and fine-tuning, since the model will not see <mask>\n",
            "\n",
            "--- Chunk 12571 ---\n",
            "tokens during fine-tuning), and a 10% chance of being left alone (to bias the\n",
            "model toward the correct answer).\n",
            "\n",
            "--- Chunk 12572 ---\n",
            "27 For example, the sentence “Jane had a lot of fun at her friend’s birthday party” entails “Jane enjoyed the party,”\n",
            "\n",
            "--- Chunk 12573 ---\n",
            "but it is contradicted by “Everyone hated the party” and it is unrelated to “The Earth is flat.”\n",
            "\n",
            "--- Chunk 12574 ---\n",
            "28 Alec Radford et al., “Language Models Are Unsupervised Multitask Learners” (2019).\n",
            "\n",
            "--- Chunk 12575 ---\n",
            "29 Jacob Devlin et al., “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,”\n",
            "\n",
            "--- Chunk 12576 ---\n",
            "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Lin‐\n",
            "\n",
            "--- Chunk 12577 ---\n",
            "guistics: Human Language Technologies 1 (2019).\n",
            "\n",
            "--- Chunk 12578 ---\n",
            "564 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "--- Chunk 12579 ---\n",
            "Next sentence prediction (NSP)\n",
            "The model is trained to predict whether two sentences are consecutive or\n",
            "\n",
            "--- Chunk 12580 ---\n",
            "not. For example, it should predict that “The dog sleeps” and “It snores\n",
            "loudly” are consecutive sentences, while “The dog sleeps” and “The Earth\n",
            "\n",
            "--- Chunk 12581 ---\n",
            "orbits the Sun” are not consecutive. This is a challenging task, and it signifi‐\n",
            "\n",
            "--- Chunk 12582 ---\n",
            "cantly improves the performance of the model when it is fine-tuned on tasks\n",
            "such as question answering or entailment.\n",
            "\n",
            "--- Chunk 12583 ---\n",
            "As you can see, the main innovations in 2018 and 2019 have been better subword\n",
            "\n",
            "--- Chunk 12584 ---\n",
            "tokenization, shifting from LSTMs to Transformers, and pretraining universal lan‐\n",
            "\n",
            "--- Chunk 12585 ---\n",
            "guage models using self-supervised learning, then fine-tuning them with very few\n",
            "\n",
            "--- Chunk 12586 ---\n",
            "architectural changes (or none at all). Things are moving fast; no one can say what\n",
            "\n",
            "--- Chunk 12587 ---\n",
            "architectures will prevail next year. Today, it’s clearly Transformers, but tomorrow it\n",
            "\n",
            "--- Chunk 12588 ---\n",
            "might be CNNs (e.g., check out the 2018 paper30 by Maha Elbayad et al., where the\n",
            "\n",
            "--- Chunk 12589 ---\n",
            "researchers use masked 2D convolutional layers for sequence-to-sequence tasks). Or\n",
            "\n",
            "--- Chunk 12590 ---\n",
            "it might even be RNNs, if they make a surprise comeback (e.g., check out the 2018\n",
            "\n",
            "--- Chunk 12591 ---\n",
            "paper31 by Shuai Li et al. that shows that by making neurons independent of each\n",
            "\n",
            "--- Chunk 12592 ---\n",
            "other in a given RNN layer, it is possible to train much deeper RNNs capable of learn‐\n",
            "ing much longer sequences).\n",
            "\n",
            "--- Chunk 12593 ---\n",
            "In the next chapter we will discuss how to learn deep representations in an unsuper‐\n",
            "\n",
            "--- Chunk 12594 ---\n",
            "vised way using autoencoders, and we will use generative adversarial networks\n",
            "(GANs) to produce images and more!\n",
            "\n",
            "--- Chunk 12595 ---\n",
            "Exercises\n",
            "1. What are the pros and cons of using a stateful RNN versus a stateless RNN?\n",
            "\n",
            "--- Chunk 12596 ---\n",
            "2. Why do people use Encoder–Decoder RNNs rather than plain sequence-to-\n",
            "\n",
            "--- Chunk 12597 ---\n",
            "sequence RNNs for automatic translation?\n",
            "3. How can you deal with variable-length input sequences? What about variable-\n",
            "\n",
            "--- Chunk 12598 ---\n",
            "length output sequences?\n",
            "4. What is beam search and why would you use it? What tool can you use to imple‐\n",
            "\n",
            "--- Chunk 12599 ---\n",
            "ment it?\n",
            "5. What is an attention mechanism? How does it help?\n",
            "\n",
            "--- Chunk 12600 ---\n",
            "30 Maha Elbayad et al., “Pervasive Attention: 2D Convolutional Neural Networks for Sequence-to-Sequence Pre‐\n",
            "\n",
            "--- Chunk 12601 ---\n",
            "diction,” arXiv preprint arXiv:1808.03867 (2018).\n",
            "\n",
            "--- Chunk 12602 ---\n",
            "31 Shuai Li et al., “Independently Recurrent Neural Network (IndRNN): Building a Longer and Deeper RNN,”\n",
            "\n",
            "--- Chunk 12603 ---\n",
            "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2018): 5457–5466.\n",
            "\n",
            "--- Chunk 12604 ---\n",
            "Exercises | 565\n",
            "\n",
            "\n",
            "\n",
            "6. What is the most important layer in the Transformer architecture? What is its\n",
            "purpose?\n",
            "\n",
            "--- Chunk 12605 ---\n",
            "7. When would you need to use sampled softmax?\n",
            "8. Embedded Reber grammars were used by Hochreiter and Schmidhuber in their\n",
            "\n",
            "--- Chunk 12606 ---\n",
            "paper about LSTMs. They are artificial grammars that produce strings such as\n",
            "“BPBTSXXVPSEPE.” Check out Jenny Orr’s nice introduction to this topic.\n",
            "\n",
            "--- Chunk 12607 ---\n",
            "Choose a particular embedded Reber grammar (such as the one represented on\n",
            "\n",
            "--- Chunk 12608 ---\n",
            "Jenny Orr’s page), then train an RNN to identify whether a string respects that\n",
            "\n",
            "--- Chunk 12609 ---\n",
            "grammar or not. You will first need to write a function capable of generating a\n",
            "\n",
            "--- Chunk 12610 ---\n",
            "training batch containing about 50% strings that respect the grammar, and 50%\n",
            "that don’t.\n",
            "\n",
            "--- Chunk 12611 ---\n",
            "9. Train an Encoder–Decoder model that can convert a date string from one format\n",
            "to another (e.g., from “April 22, 2019” to “2019-04-22”).\n",
            "\n",
            "--- Chunk 12612 ---\n",
            "10. Go through TensorFlow’s Neural Machine Translation with Attention tutorial.\n",
            "\n",
            "--- Chunk 12613 ---\n",
            "11. Use one of the recent language models (e.g., BERT) to generate more convincing\n",
            "\n",
            "--- Chunk 12614 ---\n",
            "Shakespearean text.\n",
            "\n",
            "Solutions to these exercises are available in Appendix A.\n",
            "\n",
            "--- Chunk 12615 ---\n",
            "566 | Chapter 16: Natural Language Processing with RNNs and Attention\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER 17\n",
            "Representation Learning and Generative\n",
            "\n",
            "--- Chunk 12616 ---\n",
            "Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 12617 ---\n",
            "Autoencoders are artificial neural networks capable of learning dense representations\n",
            "\n",
            "--- Chunk 12618 ---\n",
            "of the input data, called latent representations or codings, without any supervision (i.e.,\n",
            "\n",
            "--- Chunk 12619 ---\n",
            "the training set is unlabeled). These codings typically have a much lower dimension‐\n",
            "\n",
            "--- Chunk 12620 ---\n",
            "ality than the input data, making autoencoders useful for dimensionality reduction\n",
            "\n",
            "--- Chunk 12621 ---\n",
            "(see Chapter 8), especially for visualization purposes. Autoencoders also act as feature\n",
            "\n",
            "--- Chunk 12622 ---\n",
            "detectors, and they can be used for unsupervised pretraining of deep neural networks\n",
            "\n",
            "--- Chunk 12623 ---\n",
            "(as we discussed in Chapter 11). Lastly, some autoencoders are generative models: they\n",
            "\n",
            "--- Chunk 12624 ---\n",
            "are capable of randomly generating new data that looks very similar to the training\n",
            "\n",
            "--- Chunk 12625 ---\n",
            "data. For example, you could train an autoencoder on pictures of faces, and it would\n",
            "\n",
            "--- Chunk 12626 ---\n",
            "then be able to generate new faces. However, the generated images are usually fuzzy\n",
            "and not entirely realistic.\n",
            "\n",
            "--- Chunk 12627 ---\n",
            "In contrast, faces generated by generative adversarial networks (GANs) are now so\n",
            "\n",
            "--- Chunk 12628 ---\n",
            "convincing that it is hard to believe that the people they represent do not exist. You\n",
            "\n",
            "--- Chunk 12629 ---\n",
            "can judge so for yourself by visiting https://thispersondoesnotexist.com/, a website that\n",
            "\n",
            "--- Chunk 12630 ---\n",
            "shows faces generated by a recent GAN architecture called StyleGAN (you can also\n",
            "\n",
            "--- Chunk 12631 ---\n",
            "check out https://thisrentaldoesnotexist.com/ to see some generated Airbnb bed‐\n",
            "\n",
            "--- Chunk 12632 ---\n",
            "rooms). GANs are now widely used for super resolution (increasing the resolution of\n",
            "\n",
            "--- Chunk 12633 ---\n",
            "an image), colorization, powerful image editing (e.g., replacing photo bombers with\n",
            "\n",
            "--- Chunk 12634 ---\n",
            "realistic background), turning a simple sketch into a photorealistic image, predicting\n",
            "\n",
            "--- Chunk 12635 ---\n",
            "the next frames in a video, augmenting a dataset (to train other models), generating\n",
            "\n",
            "--- Chunk 12636 ---\n",
            "other types of data (such as text, audio, and time series), identifying the weaknesses in\n",
            "other models and strengthening them, and more.\n",
            "\n",
            "--- Chunk 12637 ---\n",
            "567\n",
            "\n",
            "--- Chunk 12638 ---\n",
            "Autoencoders and GANs are both unsupervised, they both learn dense representa‐\n",
            "\n",
            "--- Chunk 12639 ---\n",
            "tions, they can both be used as generative models, and they have many similar appli‐\n",
            "cations. However, they work very differently:\n",
            "\n",
            "--- Chunk 12640 ---\n",
            "• Autoencoders simply learn to copy their inputs to their outputs. This may sound\n",
            "\n",
            "--- Chunk 12641 ---\n",
            "like a trivial task, but we will see that constraining the network in various ways\n",
            "\n",
            "--- Chunk 12642 ---\n",
            "can make it rather difficult. For example, you can limit the size of the latent rep‐\n",
            "\n",
            "--- Chunk 12643 ---\n",
            "resentations, or you can add noise to the inputs and train the network to recover\n",
            "\n",
            "--- Chunk 12644 ---\n",
            "the original inputs. These constraints prevent the autoencoder from trivially\n",
            "\n",
            "--- Chunk 12645 ---\n",
            "copying the inputs directly to the outputs, which forces it to learn efficient ways\n",
            "\n",
            "--- Chunk 12646 ---\n",
            "of representing the data. In short, the codings are byproducts of the autoencoder\n",
            "learning the identity function under some constraints.\n",
            "\n",
            "--- Chunk 12647 ---\n",
            "• GANs are composed of two neural networks: a generator that tries to generate\n",
            "\n",
            "--- Chunk 12648 ---\n",
            "data that looks similar to the training data, and a discriminator that tries to tell\n",
            "\n",
            "--- Chunk 12649 ---\n",
            "real data from fake data. This architecture is very original in Deep Learning in\n",
            "\n",
            "--- Chunk 12650 ---\n",
            "that the generator and the discriminator compete against each other during\n",
            "\n",
            "--- Chunk 12651 ---\n",
            "training: the generator is often compared to a criminal trying to make realistic\n",
            "\n",
            "--- Chunk 12652 ---\n",
            "counterfeit money, while the discriminator is like the police investigator trying to\n",
            "\n",
            "--- Chunk 12653 ---\n",
            "tell real money from fake. Adversarial training (training competing neural net‐\n",
            "\n",
            "--- Chunk 12654 ---\n",
            "works) is widely considered as one of the most important ideas in recent years. In\n",
            "\n",
            "--- Chunk 12655 ---\n",
            "2016, Yann LeCun even said that it was “the most interesting idea in the last 10\n",
            "years in Machine Learning.”\n",
            "\n",
            "--- Chunk 12656 ---\n",
            "In this chapter we will start by exploring in more depth how autoencoders work and\n",
            "\n",
            "--- Chunk 12657 ---\n",
            "how to use them for dimensionality reduction, feature extraction, unsupervised pre‐\n",
            "\n",
            "--- Chunk 12658 ---\n",
            "training, or as generative models. This will naturally lead us to GANs. We will start by\n",
            "\n",
            "--- Chunk 12659 ---\n",
            "building a simple GAN to generate fake images, but we will see that training is often\n",
            "\n",
            "--- Chunk 12660 ---\n",
            "quite difficult. We will discuss the main difficulties you will encounter with adversa‐\n",
            "\n",
            "--- Chunk 12661 ---\n",
            "rial training, as well as some of the main techniques to work around these difficulties.\n",
            "Let’s start with autoencoders!\n",
            "\n",
            "--- Chunk 12662 ---\n",
            "568 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 12663 ---\n",
            "Efficient Data Representations\n",
            "Which of the following number sequences do you find the easiest to memorize?\n",
            "\n",
            "--- Chunk 12664 ---\n",
            "• 40, 27, 25, 36, 81, 57, 10, 73, 19, 68\n",
            "• 50, 48, 46, 44, 42, 40, 38, 36, 34, 32, 30, 28, 26, 24, 22, 20, 18, 16, 14\n",
            "\n",
            "--- Chunk 12665 ---\n",
            "At first glance, it would seem that the first sequence should be easier, since it is much\n",
            "\n",
            "--- Chunk 12666 ---\n",
            "shorter. However, if you look carefully at the second sequence, you will notice that it\n",
            "\n",
            "--- Chunk 12667 ---\n",
            "is just the list of even numbers from 50 down to 14. Once you notice this pattern, the\n",
            "\n",
            "--- Chunk 12668 ---\n",
            "second sequence becomes much easier to memorize than the first because you only\n",
            "\n",
            "--- Chunk 12669 ---\n",
            "need to remember the pattern (i.e., decreasing even numbers) and the starting and\n",
            "\n",
            "--- Chunk 12670 ---\n",
            "ending numbers (i.e., 50 and 14). Note that if you could quickly and easily memorize\n",
            "\n",
            "--- Chunk 12671 ---\n",
            "very long sequences, you would not care much about the existence of a pattern in the\n",
            "\n",
            "--- Chunk 12672 ---\n",
            "second sequence. You would just learn every number by heart, and that would be\n",
            "\n",
            "--- Chunk 12673 ---\n",
            "that. The fact that it is hard to memorize long sequences is what makes it useful to\n",
            "\n",
            "--- Chunk 12674 ---\n",
            "recognize patterns, and hopefully this clarifies why constraining an autoencoder dur‐\n",
            "\n",
            "--- Chunk 12675 ---\n",
            "ing training pushes it to discover and exploit patterns in the data.\n",
            "The relationship between memory, perception, and pattern matching was famously\n",
            "\n",
            "--- Chunk 12676 ---\n",
            "studied by William Chase and Herbert Simon in the early 1970s.1 They observed that\n",
            "\n",
            "--- Chunk 12677 ---\n",
            "expert chess players were able to memorize the positions of all the pieces in a game by\n",
            "\n",
            "--- Chunk 12678 ---\n",
            "looking at the board for just five seconds, a task that most people would find impossi‐\n",
            "\n",
            "--- Chunk 12679 ---\n",
            "ble. However, this was only the case when the pieces were placed in realistic positions\n",
            "\n",
            "--- Chunk 12680 ---\n",
            "(from actual games), not when the pieces were placed randomly. Chess experts don’t\n",
            "\n",
            "--- Chunk 12681 ---\n",
            "have a much better memory than you and I; they just see chess patterns more easily,\n",
            "\n",
            "--- Chunk 12682 ---\n",
            "thanks to their experience with the game. Noticing patterns helps them store infor‐\n",
            "mation efficiently.\n",
            "\n",
            "--- Chunk 12683 ---\n",
            "mation efficiently.\n",
            "Just like the chess players in this memory experiment, an autoencoder looks at the\n",
            "\n",
            "--- Chunk 12684 ---\n",
            "inputs, converts them to an efficient latent representation, and then spits out some‐\n",
            "\n",
            "--- Chunk 12685 ---\n",
            "thing that (hopefully) looks very close to the inputs. An autoencoder is always com‐\n",
            "\n",
            "--- Chunk 12686 ---\n",
            "posed of two parts: an encoder (or recognition network) that converts the inputs to a\n",
            "\n",
            "--- Chunk 12687 ---\n",
            "latent representation, followed by a decoder (or generative network) that converts the\n",
            "internal representation to the outputs (see Figure 17-1).\n",
            "\n",
            "--- Chunk 12688 ---\n",
            "1 William G. Chase and Herbert A. Simon, “Perception in Chess,” Cognitive Psychology 4, no. 1 (1973): 55–81.\n",
            "\n",
            "Efficient Data Representations | 569\n",
            "\n",
            "--- Chunk 12689 ---\n",
            "Figure 17-1. The chess memory experiment (left) and a simple autoencoder (right)\n",
            "\n",
            "--- Chunk 12690 ---\n",
            "As you can see, an autoencoder typically has the same architecture as a Multi-Layer\n",
            "\n",
            "--- Chunk 12691 ---\n",
            "Perceptron (MLP; see Chapter 10), except that the number of neurons in the output\n",
            "\n",
            "--- Chunk 12692 ---\n",
            "layer must be equal to the number of inputs. In this example, there is just one hidden\n",
            "\n",
            "--- Chunk 12693 ---\n",
            "layer composed of two neurons (the encoder), and one output layer composed of\n",
            "\n",
            "--- Chunk 12694 ---\n",
            "three neurons (the decoder). The outputs are often called the reconstructions because\n",
            "\n",
            "--- Chunk 12695 ---\n",
            "the autoencoder tries to reconstruct the inputs, and the cost function contains a\n",
            "\n",
            "--- Chunk 12696 ---\n",
            "reconstruction loss that penalizes the model when the reconstructions are different\n",
            "from the inputs.\n",
            "\n",
            "--- Chunk 12697 ---\n",
            "from the inputs.\n",
            "Because the internal representation has a lower dimensionality than the input data (it\n",
            "\n",
            "--- Chunk 12698 ---\n",
            "is 2D instead of 3D), the autoencoder is said to be undercomplete. An undercomplete\n",
            "\n",
            "--- Chunk 12699 ---\n",
            "autoencoder cannot trivially copy its inputs to the codings, yet it must find a way to\n",
            "\n",
            "--- Chunk 12700 ---\n",
            "output a copy of its inputs. It is forced to learn the most important features in the\n",
            "input data (and drop the unimportant ones).\n",
            "\n",
            "--- Chunk 12701 ---\n",
            "Let’s see how to implement a very simple undercomplete autoencoder for dimension‐\n",
            "ality reduction.\n",
            "\n",
            "--- Chunk 12702 ---\n",
            "Performing PCA with an Undercomplete Linear\n",
            "Autoencoder\n",
            "If the autoencoder uses only linear activations and the cost function is the mean\n",
            "\n",
            "--- Chunk 12703 ---\n",
            "squared error (MSE), then it ends up performing Principal Component Analysis\n",
            "(PCA; see Chapter 8).\n",
            "\n",
            "--- Chunk 12704 ---\n",
            "The following code builds a simple linear autoencoder to perform PCA on a 3D data‐\n",
            "set, projecting it to 2D:\n",
            "\n",
            "--- Chunk 12705 ---\n",
            "570 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "\n",
            "\n",
            "from tensorflow import keras\n",
            "\n",
            "--- Chunk 12706 ---\n",
            "encoder = keras.models.Sequential([keras.layers.Dense(2, input_shape=[3])])\n",
            "\n",
            "--- Chunk 12707 ---\n",
            "decoder = keras.models.Sequential([keras.layers.Dense(3, input_shape=[2])])\n",
            "autoencoder = keras.models.Sequential([encoder, decoder])\n",
            "\n",
            "--- Chunk 12708 ---\n",
            "autoencoder.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=0.1))\n",
            "\n",
            "--- Chunk 12709 ---\n",
            "This code is really not very different from all the MLPs we built in past chapters, but\n",
            "there are a few things to note:\n",
            "\n",
            "--- Chunk 12710 ---\n",
            "• We organized the autoencoder into two subcomponents: the encoder and the\n",
            "\n",
            "--- Chunk 12711 ---\n",
            "decoder. Both are regular Sequential models with a single Dense layer each, and\n",
            "\n",
            "--- Chunk 12712 ---\n",
            "the autoencoder is a Sequential model containing the encoder followed by the\n",
            "decoder (remember that a model can be used as a layer in another model).\n",
            "\n",
            "--- Chunk 12713 ---\n",
            "• The autoencoder’s number of outputs is equal to the number of inputs (i.e., 3).\n",
            "\n",
            "--- Chunk 12714 ---\n",
            "• To perform simple PCA, we do not use any activation function (i.e., all neurons\n",
            "\n",
            "--- Chunk 12715 ---\n",
            "are linear), and the cost function is the MSE. We will see more complex autoen‐\n",
            "coders shortly.\n",
            "\n",
            "--- Chunk 12716 ---\n",
            "Now let’s train the model on a simple generated 3D dataset and use it to encode that\n",
            "same dataset (i.e., project it to 2D):\n",
            "\n",
            "--- Chunk 12717 ---\n",
            "history = autoencoder.fit(X_train, X_train, epochs=20)\n",
            "codings = encoder.predict(X_train)\n",
            "\n",
            "--- Chunk 12718 ---\n",
            "Note that the same dataset, X_train, is used as both the inputs and the targets.\n",
            "\n",
            "--- Chunk 12719 ---\n",
            "Figure 17-2 shows the original 3D dataset (on the left) and the output of the autoen‐\n",
            "\n",
            "--- Chunk 12720 ---\n",
            "coder’s hidden layer (i.e., the coding layer, on the right). As you can see, the autoen‐\n",
            "\n",
            "--- Chunk 12721 ---\n",
            "coder found the best 2D plane to project the data onto, preserving as much variance\n",
            "in the data as it could (just like PCA).\n",
            "\n",
            "--- Chunk 12722 ---\n",
            "Figure 17-2. PCA performed by an undercomplete linear autoencoder\n",
            "\n",
            "Performing PCA with an Undercomplete Linear Autoencoder | 571\n",
            "\n",
            "--- Chunk 12723 ---\n",
            "You can think of autoencoders as a form of self-supervised learning\n",
            "(i.e., using a supervised learning technique with automatically gen‐\n",
            "\n",
            "--- Chunk 12724 ---\n",
            "erated labels, in this case simply equal to the inputs).\n",
            "\n",
            "--- Chunk 12725 ---\n",
            "Stacked Autoencoders\n",
            "Just like other neural networks we have discussed, autoencoders can have multiple\n",
            "\n",
            "--- Chunk 12726 ---\n",
            "hidden layers. In this case they are called stacked autoencoders (or deep autoencoders).\n",
            "\n",
            "--- Chunk 12727 ---\n",
            "Adding more layers helps the autoencoder learn more complex codings. That said,\n",
            "\n",
            "--- Chunk 12728 ---\n",
            "one must be careful not to make the autoencoder too powerful. Imagine an encoder\n",
            "\n",
            "--- Chunk 12729 ---\n",
            "so powerful that it just learns to map each input to a single arbitrary number (and the\n",
            "\n",
            "--- Chunk 12730 ---\n",
            "decoder learns the reverse mapping). Obviously such an autoencoder will reconstruct\n",
            "\n",
            "--- Chunk 12731 ---\n",
            "the training data perfectly, but it will not have learned any useful data representation\n",
            "\n",
            "--- Chunk 12732 ---\n",
            "in the process (and it is unlikely to generalize well to new instances).\n",
            "\n",
            "--- Chunk 12733 ---\n",
            "The architecture of a stacked autoencoder is typically symmetrical with regard to the\n",
            "\n",
            "--- Chunk 12734 ---\n",
            "central hidden layer (the coding layer). To put it simply, it looks like a sandwich. For\n",
            "\n",
            "--- Chunk 12735 ---\n",
            "example, an autoencoder for MNIST (introduced in Chapter 3) may have 784 inputs,\n",
            "\n",
            "--- Chunk 12736 ---\n",
            "followed by a hidden layer with 100 neurons, then a central hidden layer of 30 neu‐\n",
            "\n",
            "--- Chunk 12737 ---\n",
            "rons, then another hidden layer with 100 neurons, and an output layer with 784 neu‐\n",
            "rons. This stacked autoencoder is represented in Figure 17-3.\n",
            "\n",
            "--- Chunk 12738 ---\n",
            "Figure 17-3. Stacked autoencoder\n",
            "\n",
            "--- Chunk 12739 ---\n",
            "Implementing a Stacked Autoencoder Using Keras\n",
            "You can implement a stacked autoencoder very much like a regular deep MLP. In par‐\n",
            "\n",
            "--- Chunk 12740 ---\n",
            "ticular, the same techniques we used in Chapter 11 for training deep nets can be\n",
            "\n",
            "--- Chunk 12741 ---\n",
            "applied. For example, the following code builds a stacked autoencoder for Fashion\n",
            "\n",
            "--- Chunk 12742 ---\n",
            "572 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 12743 ---\n",
            "MNIST (loaded and normalized as in Chapter 10), using the SELU activation\n",
            "function:\n",
            "\n",
            "--- Chunk 12744 ---\n",
            "stacked_encoder = keras.models.Sequential([\n",
            "    keras.layers.Flatten(input_shape=[28, 28]),\n",
            "    keras.layers.Dense(100, activation=\"selu\"),\n",
            "\n",
            "--- Chunk 12745 ---\n",
            "keras.layers.Dense(30, activation=\"selu\"),\n",
            "])\n",
            "stacked_decoder = keras.models.Sequential([\n",
            "\n",
            "--- Chunk 12746 ---\n",
            "keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
            "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
            "\n",
            "--- Chunk 12747 ---\n",
            "keras.layers.Reshape([28, 28])\n",
            "])\n",
            "stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
            "\n",
            "--- Chunk 12748 ---\n",
            "stacked_ae.compile(loss=\"binary_crossentropy\",\n",
            "                   optimizer=keras.optimizers.SGD(lr=1.5))\n",
            "\n",
            "--- Chunk 12749 ---\n",
            "history = stacked_ae.fit(X_train, X_train, epochs=10,\n",
            "                         validation_data=[X_valid, X_valid])\n",
            "\n",
            "--- Chunk 12750 ---\n",
            "Let’s go through this code:\n",
            "\n",
            "• Just like earlier, we split the autoencoder model into two submodels: the encoder\n",
            "and the decoder.\n",
            "\n",
            "--- Chunk 12751 ---\n",
            "• The encoder takes 28 × 28–pixel grayscale images, flattens them so that each\n",
            "\n",
            "--- Chunk 12752 ---\n",
            "image is represented as a vector of size 784, then processes these vectors through\n",
            "\n",
            "--- Chunk 12753 ---\n",
            "two Dense layers of diminishing sizes (100 units then 30 units), both using the\n",
            "\n",
            "--- Chunk 12754 ---\n",
            "SELU activation function (you may want to add LeCun normal initialization as\n",
            "\n",
            "--- Chunk 12755 ---\n",
            "well, but the network is not very deep so it won’t make a big difference). For each\n",
            "input image, the encoder outputs a vector of size 30.\n",
            "\n",
            "--- Chunk 12756 ---\n",
            "• The decoder takes codings of size 30 (output by the encoder) and processes them\n",
            "\n",
            "--- Chunk 12757 ---\n",
            "through two Dense layers of increasing sizes (100 units then 784 units), and it\n",
            "\n",
            "--- Chunk 12758 ---\n",
            "reshapes the final vectors into 28 × 28 arrays so the decoder’s outputs have the\n",
            "same shape as the encoder’s inputs.\n",
            "\n",
            "--- Chunk 12759 ---\n",
            "• When compiling the stacked autoencoder, we use the binary cross-entropy loss\n",
            "\n",
            "--- Chunk 12760 ---\n",
            "instead of the mean squared error. We are treating the reconstruction task as a\n",
            "\n",
            "--- Chunk 12761 ---\n",
            "multilabel binary classification problem: each pixel intensity represents the prob‐\n",
            "\n",
            "--- Chunk 12762 ---\n",
            "ability that the pixel should be black. Framing it this way (rather than as a regres‐\n",
            "sion problem) tends to make the model converge faster.2\n",
            "\n",
            "--- Chunk 12763 ---\n",
            "• Finally, we train the model using X_train as both the inputs and the targets (and\n",
            "\n",
            "--- Chunk 12764 ---\n",
            "similarly, we use X_valid as both the validation inputs and targets).\n",
            "\n",
            "--- Chunk 12765 ---\n",
            "2 You might be tempted to use the accuracy metric, but it would not work properly, since this metric expects the\n",
            "\n",
            "--- Chunk 12766 ---\n",
            "labels to be either 0 or 1 for each pixel. You can easily work around this problem by creating a custom metric\n",
            "\n",
            "--- Chunk 12767 ---\n",
            "that computes the accuracy after rounding the targets and predictions to 0 or 1.\n",
            "\n",
            "--- Chunk 12768 ---\n",
            "Stacked Autoencoders | 573\n",
            "\n",
            "--- Chunk 12769 ---\n",
            "Visualizing the Reconstructions\n",
            "One way to ensure that an autoencoder is properly trained is to compare the inputs\n",
            "\n",
            "--- Chunk 12770 ---\n",
            "and the outputs: the differences should not be too significant. Let’s plot a few images\n",
            "from the validation set, as well as their reconstructions:\n",
            "\n",
            "--- Chunk 12771 ---\n",
            "def plot_image(image):\n",
            "    plt.imshow(image, cmap=\"binary\")\n",
            "    plt.axis(\"off\")\n",
            "\n",
            "--- Chunk 12772 ---\n",
            "def show_reconstructions(model, n_images=5):\n",
            "    reconstructions = model.predict(X_valid[:n_images])\n",
            "\n",
            "--- Chunk 12773 ---\n",
            "fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
            "    for image_index in range(n_images):\n",
            "        plt.subplot(2, n_images, 1 + image_index)\n",
            "\n",
            "--- Chunk 12774 ---\n",
            "plot_image(X_valid[image_index])\n",
            "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
            "\n",
            "--- Chunk 12775 ---\n",
            "plot_image(reconstructions[image_index])\n",
            "\n",
            "--- Chunk 12776 ---\n",
            "show_reconstructions(stacked_ae)\n",
            "\n",
            "Figure 17-4 shows the resulting images.\n",
            "\n",
            "Figure 17-4. Original images (top) and their reconstructions (bottom)\n",
            "\n",
            "--- Chunk 12777 ---\n",
            "The reconstructions are recognizable, but a bit too lossy. We may need to train the\n",
            "\n",
            "--- Chunk 12778 ---\n",
            "model for longer, or make the encoder and decoder deeper, or make the codings\n",
            "\n",
            "--- Chunk 12779 ---\n",
            "larger. But if we make the network too powerful, it will manage to make perfect\n",
            "\n",
            "--- Chunk 12780 ---\n",
            "reconstructions without having learned any useful patterns in the data. For now, let’s\n",
            "go with this model.\n",
            "\n",
            "--- Chunk 12781 ---\n",
            "Visualizing the Fashion MNIST Dataset\n",
            "Now that we have trained a stacked autoencoder, we can use it to reduce the dataset’s\n",
            "\n",
            "--- Chunk 12782 ---\n",
            "dimensionality. For visualization, this does not give great results compared to other\n",
            "\n",
            "--- Chunk 12783 ---\n",
            "dimensionality reduction algorithms (such as those we discussed in Chapter 8), but\n",
            "\n",
            "--- Chunk 12784 ---\n",
            "one big advantage of autoencoders is that they can handle large datasets, with many\n",
            "\n",
            "--- Chunk 12785 ---\n",
            "instances and many features. So one strategy is to use an autoencoder to reduce the\n",
            "\n",
            "--- Chunk 12786 ---\n",
            "dimensionality down to a reasonable level, then use another dimensionality\n",
            "\n",
            "--- Chunk 12787 ---\n",
            "574 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 12788 ---\n",
            "reduction algorithm for visualization. Let’s use this strategy to visualize Fashion\n",
            "\n",
            "--- Chunk 12789 ---\n",
            "MNIST. First, we use the encoder from our stacked autoencoder to reduce the dimen‐\n",
            "\n",
            "--- Chunk 12790 ---\n",
            "sionality down to 30, then we use Scikit-Learn’s implementation of the t-SNE algo‐\n",
            "rithm to reduce the dimensionality down to 2 for visualization:\n",
            "\n",
            "--- Chunk 12791 ---\n",
            "from sklearn.manifold import TSNE\n",
            "\n",
            "--- Chunk 12792 ---\n",
            "X_valid_compressed = stacked_encoder.predict(X_valid)\n",
            "tsne = TSNE()\n",
            "X_valid_2D = tsne.fit_transform(X_valid_compressed)\n",
            "\n",
            "--- Chunk 12793 ---\n",
            "Now we can plot the dataset:\n",
            "plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid, s=10, cmap=\"tab10\")\n",
            "\n",
            "--- Chunk 12794 ---\n",
            "Figure 17-5 shows the resulting scatterplot (beautified a bit by displaying some of the\n",
            "\n",
            "--- Chunk 12795 ---\n",
            "images). The t-SNE algorithm identified several clusters which match the classes rea‐\n",
            "\n",
            "--- Chunk 12796 ---\n",
            "sonably well (each class is represented with a different color).\n",
            "\n",
            "--- Chunk 12797 ---\n",
            "Figure 17-5. Fashion MNIST visualization using an autoencoder followed by t-SNE\n",
            "\n",
            "--- Chunk 12798 ---\n",
            "So, autoencoders can be used for dimensionality reduction. Another application is for\n",
            "unsupervised pretraining.\n",
            "\n",
            "Stacked Autoencoders | 575\n",
            "\n",
            "--- Chunk 12799 ---\n",
            "Unsupervised Pretraining Using Stacked Autoencoders\n",
            "As we discussed in Chapter 11, if you are tackling a complex supervised task but you\n",
            "\n",
            "--- Chunk 12800 ---\n",
            "do not have a lot of labeled training data, one solution is to find a neural network that\n",
            "\n",
            "--- Chunk 12801 ---\n",
            "performs a similar task and reuse its lower layers. This makes it possible to train a\n",
            "\n",
            "--- Chunk 12802 ---\n",
            "high-performance model using little training data because your neural network won’t\n",
            "\n",
            "--- Chunk 12803 ---\n",
            "have to learn all the low-level features; it will just reuse the feature detectors learned\n",
            "by the existing network.\n",
            "\n",
            "--- Chunk 12804 ---\n",
            "Similarly, if you have a large dataset but most of it is unlabeled, you can first train a\n",
            "\n",
            "--- Chunk 12805 ---\n",
            "stacked autoencoder using all the data, then reuse the lower layers to create a neural\n",
            "\n",
            "--- Chunk 12806 ---\n",
            "network for your actual task and train it using the labeled data. For example,\n",
            "\n",
            "--- Chunk 12807 ---\n",
            "Figure 17-6 shows how to use a stacked autoencoder to perform unsupervised pre‐\n",
            "\n",
            "--- Chunk 12808 ---\n",
            "training for a classification neural network. When training the classifier, if you really\n",
            "\n",
            "--- Chunk 12809 ---\n",
            "don’t have much labeled training data, you may want to freeze the pretrained layers\n",
            "(at least the lower ones).\n",
            "\n",
            "--- Chunk 12810 ---\n",
            "Figure 17-6. Unsupervised pretraining using autoencoders\n",
            "\n",
            "--- Chunk 12811 ---\n",
            "Having plenty of unlabeled data and little labeled data is common.\n",
            "Building a large unlabeled dataset is often cheap (e.g., a simple\n",
            "\n",
            "--- Chunk 12812 ---\n",
            "script can download millions of images off the internet), but label‐\n",
            "ing those images (e.g., classifying them as cute or not) can usually\n",
            "\n",
            "--- Chunk 12813 ---\n",
            "be done reliably only by humans. Labeling instances is time-\n",
            "consuming and costly, so it’s normal to have only a few thousand\n",
            "\n",
            "--- Chunk 12814 ---\n",
            "human-labeled instances.\n",
            "\n",
            "--- Chunk 12815 ---\n",
            "576 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 12816 ---\n",
            "There is nothing special about the implementation: just train an autoencoder using\n",
            "\n",
            "--- Chunk 12817 ---\n",
            "all the training data (labeled plus unlabeled), then reuse its encoder layers to create a\n",
            "\n",
            "--- Chunk 12818 ---\n",
            "new neural network (see the exercises at the end of this chapter for an example).\n",
            "\n",
            "--- Chunk 12819 ---\n",
            "Next, let’s look at a few techniques for training stacked autoencoders.\n",
            "\n",
            "--- Chunk 12820 ---\n",
            "Tying Weights\n",
            "When an autoencoder is neatly symmetrical, like the one we just built, a common\n",
            "\n",
            "--- Chunk 12821 ---\n",
            "technique is to tie the weights of the decoder layers to the weights of the encoder lay‐\n",
            "\n",
            "--- Chunk 12822 ---\n",
            "ers. This halves the number of weights in the model, speeding up training and limit‐\n",
            "\n",
            "--- Chunk 12823 ---\n",
            "ing the risk of overfitting. Specifically, if the autoencoder has a total of N layers (not\n",
            "\n",
            "--- Chunk 12824 ---\n",
            "counting the input layer), and WL represents the connection weights of the Lth layer\n",
            "\n",
            "--- Chunk 12825 ---\n",
            "(e.g., layer 1 is the first hidden layer, layer N/2 is the coding layer, and layer N is the\n",
            "\n",
            "--- Chunk 12826 ---\n",
            "output layer), then the decoder layer weights can be defined simply as: W ⊺\n",
            "\n",
            "--- Chunk 12827 ---\n",
            "N–L+1 = WL\n",
            "(with L = 1, 2, …, N/2).\n",
            "To tie weights between layers using Keras, let’s define a custom layer:\n",
            "\n",
            "--- Chunk 12828 ---\n",
            "class DenseTranspose(keras.layers.Layer):\n",
            "    def __init__(self, dense, activation=None, **kwargs):\n",
            "        self.dense = dense\n",
            "\n",
            "--- Chunk 12829 ---\n",
            "self.activation = keras.activations.get(activation)\n",
            "        super().__init__(**kwargs)\n",
            "    def build(self, batch_input_shape):\n",
            "\n",
            "--- Chunk 12830 ---\n",
            "self.biases = self.add_weight(name=\"bias\", initializer=\"zeros\",\n",
            "                                      shape=[self.dense.input_shape[-1]])\n",
            "\n",
            "--- Chunk 12831 ---\n",
            "super().build(batch_input_shape)\n",
            "    def call(self, inputs):\n",
            "        z = tf.matmul(inputs, self.dense.weights[0], transpose_b=True)\n",
            "\n",
            "--- Chunk 12832 ---\n",
            "return self.activation(z + self.biases)\n",
            "\n",
            "--- Chunk 12833 ---\n",
            "This custom layer acts like a regular Dense layer, but it uses another Dense layer’s\n",
            "\n",
            "--- Chunk 12834 ---\n",
            "weights, transposed (setting transpose_b=True is equivalent to transposing the sec‐\n",
            "\n",
            "--- Chunk 12835 ---\n",
            "ond argument, but it’s more efficient as it performs the transposition on the fly within\n",
            "\n",
            "--- Chunk 12836 ---\n",
            "the matmul() operation). However, it uses its own bias vector. Next, we can build a\n",
            "\n",
            "--- Chunk 12837 ---\n",
            "new stacked autoencoder, much like the previous one, but with the decoder’s Dense\n",
            "layers tied to the encoder’s Dense layers:\n",
            "\n",
            "--- Chunk 12838 ---\n",
            "dense_1 = keras.layers.Dense(100, activation=\"selu\")\n",
            "dense_2 = keras.layers.Dense(30, activation=\"selu\")\n",
            "\n",
            "--- Chunk 12839 ---\n",
            "tied_encoder = keras.models.Sequential([\n",
            "    keras.layers.Flatten(input_shape=[28, 28]),\n",
            "    dense_1,\n",
            "    dense_2\n",
            "])\n",
            "\n",
            "Stacked Autoencoders | 577\n",
            "\n",
            "--- Chunk 12840 ---\n",
            "tied_decoder = keras.models.Sequential([\n",
            "    DenseTranspose(dense_2, activation=\"selu\"),\n",
            "    DenseTranspose(dense_1, activation=\"sigmoid\"),\n",
            "\n",
            "--- Chunk 12841 ---\n",
            "keras.layers.Reshape([28, 28])\n",
            "])\n",
            "\n",
            "--- Chunk 12842 ---\n",
            "tied_ae = keras.models.Sequential([tied_encoder, tied_decoder])\n",
            "\n",
            "--- Chunk 12843 ---\n",
            "This model achieves a very slightly lower reconstruction error than the previous\n",
            "model, with almost half the number of parameters.\n",
            "\n",
            "--- Chunk 12844 ---\n",
            "Training One Autoencoder at a Time\n",
            "Rather than training the whole stacked autoencoder in one go like we just did, it is\n",
            "\n",
            "--- Chunk 12845 ---\n",
            "possible to train one shallow autoencoder at a time, then stack all of them into a sin‐\n",
            "\n",
            "--- Chunk 12846 ---\n",
            "gle stacked autoencoder (hence the name), as shown in Figure 17-7. This technique is\n",
            "\n",
            "--- Chunk 12847 ---\n",
            "not used as much these days, but you may still run into papers that talk about “greedy\n",
            "layerwise training,” so it’s good to know what it means.\n",
            "\n",
            "--- Chunk 12848 ---\n",
            "Figure 17-7. Training one autoencoder at a time\n",
            "\n",
            "--- Chunk 12849 ---\n",
            "During the first phase of training, the first autoencoder learns to reconstruct the\n",
            "\n",
            "--- Chunk 12850 ---\n",
            "inputs. Then we encode the whole training set using this first autoencoder, and this\n",
            "\n",
            "--- Chunk 12851 ---\n",
            "gives us a new (compressed) training set. We then train a second autoencoder on this\n",
            "\n",
            "--- Chunk 12852 ---\n",
            "new dataset. This is the second phase of training. Finally, we build a big sandwich\n",
            "\n",
            "--- Chunk 12853 ---\n",
            "using all these autoencoders, as shown in Figure 17-7 (i.e., we first stack the hidden\n",
            "\n",
            "--- Chunk 12854 ---\n",
            "layers of each autoencoder, then the output layers in reverse order). This gives us the\n",
            "\n",
            "--- Chunk 12855 ---\n",
            "final stacked autoencoder (see the “Training One Autoencoder at a Time” section in\n",
            "\n",
            "--- Chunk 12856 ---\n",
            "the notebook for an implementation). We could easily train more autoencoders this\n",
            "way, building a very deep stacked autoencoder.\n",
            "\n",
            "--- Chunk 12857 ---\n",
            "578 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 12858 ---\n",
            "As we discussed earlier, one of the triggers of the current tsunami of interest in Deep\n",
            "\n",
            "--- Chunk 12859 ---\n",
            "Learning was the discovery in 2006 by Geoffrey Hinton et al. that deep neural net‐\n",
            "\n",
            "--- Chunk 12860 ---\n",
            "works can be pretrained in an unsupervised fashion, using this greedy layerwise\n",
            "\n",
            "--- Chunk 12861 ---\n",
            "approach. They used restricted Boltzmann machines (RBMs; see Appendix E) for this\n",
            "\n",
            "--- Chunk 12862 ---\n",
            "purpose, but in 2007 Yoshua Bengio et al. showed3 that autoencoders worked just as\n",
            "\n",
            "--- Chunk 12863 ---\n",
            "well. For several years this was the only efficient way to train deep nets, until many of\n",
            "\n",
            "--- Chunk 12864 ---\n",
            "the techniques introduced in Chapter 11 made it possible to just train a deep net in\n",
            "one shot.\n",
            "\n",
            "--- Chunk 12865 ---\n",
            "one shot.\n",
            "Autoencoders are not limited to dense networks: you can also build convolutional\n",
            "\n",
            "--- Chunk 12866 ---\n",
            "autoencoders, or even recurrent autoencoders. Let’s look at these now.\n",
            "\n",
            "--- Chunk 12867 ---\n",
            "Convolutional Autoencoders\n",
            "If you are dealing with images, then the autoencoders we have seen so far will not\n",
            "\n",
            "--- Chunk 12868 ---\n",
            "work well (unless the images are very small): as we saw in Chapter 14, convolutional\n",
            "\n",
            "--- Chunk 12869 ---\n",
            "neural networks are far better suited than dense networks to work with images. So if\n",
            "\n",
            "--- Chunk 12870 ---\n",
            "you want to build an autoencoder for images (e.g., for unsupervised pretraining or\n",
            "\n",
            "--- Chunk 12871 ---\n",
            "dimensionality reduction), you will need to build a convolutional autoencoder.4 The\n",
            "\n",
            "--- Chunk 12872 ---\n",
            "encoder is a regular CNN composed of convolutional layers and pooling layers. It\n",
            "\n",
            "--- Chunk 12873 ---\n",
            "typically reduces the spatial dimensionality of the inputs (i.e., height and width) while\n",
            "\n",
            "--- Chunk 12874 ---\n",
            "increasing the depth (i.e., the number of feature maps). The decoder must do the\n",
            "\n",
            "--- Chunk 12875 ---\n",
            "reverse (upscale the image and reduce its depth back to the original dimensions), and\n",
            "\n",
            "--- Chunk 12876 ---\n",
            "for this you can use transpose convolutional layers (alternatively, you could combine\n",
            "\n",
            "--- Chunk 12877 ---\n",
            "upsampling layers with convolutional layers). Here is a simple convolutional autoen‐\n",
            "coder for Fashion MNIST:\n",
            "\n",
            "--- Chunk 12878 ---\n",
            "conv_encoder = keras.models.Sequential([\n",
            "    keras.layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n",
            "\n",
            "--- Chunk 12879 ---\n",
            "keras.layers.Conv2D(16, kernel_size=3, padding=\"same\", activation=\"selu\"),\n",
            "    keras.layers.MaxPool2D(pool_size=2),\n",
            "\n",
            "--- Chunk 12880 ---\n",
            "keras.layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"selu\"),\n",
            "    keras.layers.MaxPool2D(pool_size=2),\n",
            "\n",
            "--- Chunk 12881 ---\n",
            "keras.layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"selu\"),\n",
            "    keras.layers.MaxPool2D(pool_size=2)\n",
            "])\n",
            "\n",
            "--- Chunk 12882 ---\n",
            "])\n",
            "conv_decoder = keras.models.Sequential([\n",
            "    keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding=\"valid\",\n",
            "\n",
            "--- Chunk 12883 ---\n",
            "activation=\"selu\",\n",
            "                                 input_shape=[3, 3, 64]),\n",
            "\n",
            "--- Chunk 12884 ---\n",
            "3 Yoshua Bengio et al., “Greedy Layer-Wise Training of Deep Networks,” Proceedings of the 19th International\n",
            "\n",
            "--- Chunk 12885 ---\n",
            "Conference on Neural Information Processing Systems (2006): 153–160.\n",
            "\n",
            "--- Chunk 12886 ---\n",
            "4 Jonathan Masci et al., “Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction,” Proceed‐\n",
            "\n",
            "--- Chunk 12887 ---\n",
            "ings of the 21st International Conference on Artificial Neural Networks 1 (2011): 52–59.\n",
            "\n",
            "--- Chunk 12888 ---\n",
            "Convolutional Autoencoders | 579\n",
            "\n",
            "--- Chunk 12889 ---\n",
            "keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, padding=\"same\",\n",
            "                                 activation=\"selu\"),\n",
            "\n",
            "--- Chunk 12890 ---\n",
            "keras.layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding=\"same\",\n",
            "                                 activation=\"sigmoid\"),\n",
            "\n",
            "--- Chunk 12891 ---\n",
            "keras.layers.Reshape([28, 28])\n",
            "])\n",
            "conv_ae = keras.models.Sequential([conv_encoder, conv_decoder])\n",
            "\n",
            "--- Chunk 12892 ---\n",
            "Recurrent Autoencoders\n",
            "If you want to build an autoencoder for sequences, such as time series or text (e.g., for\n",
            "\n",
            "--- Chunk 12893 ---\n",
            "unsupervised learning or dimensionality reduction), then recurrent neural networks\n",
            "\n",
            "--- Chunk 12894 ---\n",
            "(see Chapter 15) may be better suited than dense networks. Building a recurrent\n",
            "\n",
            "--- Chunk 12895 ---\n",
            "autoencoder is straightforward: the encoder is typically a sequence-to-vector RNN\n",
            "\n",
            "--- Chunk 12896 ---\n",
            "which compresses the input sequence down to a single vector. The decoder is a\n",
            "vector-to-sequence RNN that does the reverse:\n",
            "\n",
            "--- Chunk 12897 ---\n",
            "recurrent_encoder = keras.models.Sequential([\n",
            "    keras.layers.LSTM(100, return_sequences=True, input_shape=[None, 28]),\n",
            "    keras.layers.LSTM(30)\n",
            "\n",
            "--- Chunk 12898 ---\n",
            "])\n",
            "recurrent_decoder = keras.models.Sequential([\n",
            "    keras.layers.RepeatVector(28, input_shape=[30]),\n",
            "\n",
            "--- Chunk 12899 ---\n",
            "keras.layers.LSTM(100, return_sequences=True),\n",
            "    keras.layers.TimeDistributed(keras.layers.Dense(28, activation=\"sigmoid\"))\n",
            "])\n",
            "\n",
            "--- Chunk 12900 ---\n",
            "])\n",
            "recurrent_ae = keras.models.Sequential([recurrent_encoder, recurrent_decoder])\n",
            "\n",
            "--- Chunk 12901 ---\n",
            "This recurrent autoencoder can process sequences of any length, with 28 dimensions\n",
            "\n",
            "--- Chunk 12902 ---\n",
            "per time step. Conveniently, this means it can process Fashion MNIST images by\n",
            "\n",
            "--- Chunk 12903 ---\n",
            "treating each image as a sequence of rows: at each time step, the RNN will process a\n",
            "\n",
            "--- Chunk 12904 ---\n",
            "single row of 28 pixels. Obviously, you could use a recurrent autoencoder for any\n",
            "\n",
            "--- Chunk 12905 ---\n",
            "kind of sequence. Note that we use a RepeatVector layer as the first layer of the\n",
            "\n",
            "--- Chunk 12906 ---\n",
            "decoder, to ensure that its input vector gets fed to the decoder at each time step.\n",
            "\n",
            "--- Chunk 12907 ---\n",
            "OK, let’s step back for a second. So far we have seen various kinds of autoencoders\n",
            "\n",
            "--- Chunk 12908 ---\n",
            "(basic, stacked, convolutional, and recurrent), and we have looked at how to train\n",
            "\n",
            "--- Chunk 12909 ---\n",
            "them (either in one shot or layer by layer). We also looked at a couple applications:\n",
            "data visualization and unsupervised pretraining.\n",
            "\n",
            "--- Chunk 12910 ---\n",
            "Up to now, in order to force the autoencoder to learn interesting features, we have\n",
            "\n",
            "--- Chunk 12911 ---\n",
            "limited the size of the coding layer, making it undercomplete. There are actually\n",
            "\n",
            "--- Chunk 12912 ---\n",
            "many other kinds of constraints that can be used, including ones that allow the cod‐\n",
            "\n",
            "--- Chunk 12913 ---\n",
            "ing layer to be just as large as the inputs, or even larger, resulting in an overcomplete\n",
            "autoencoder. Let’s look at some of those approaches now.\n",
            "\n",
            "--- Chunk 12914 ---\n",
            "580 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 12915 ---\n",
            "Denoising Autoencoders\n",
            "Another way to force the autoencoder to learn useful features is to add noise to its\n",
            "\n",
            "--- Chunk 12916 ---\n",
            "inputs, training it to recover the original, noise-free inputs. This idea has been around\n",
            "\n",
            "--- Chunk 12917 ---\n",
            "since the 1980s (e.g., it is mentioned in Yann LeCun’s 1987 master’s thesis). In a 2008\n",
            "\n",
            "--- Chunk 12918 ---\n",
            "paper,5 Pascal Vincent et al. showed that autoencoders could also be used for feature\n",
            "\n",
            "--- Chunk 12919 ---\n",
            "extraction. In a 2010 paper,6 Vincent et al. introduced stacked denoising autoencoders.\n",
            "\n",
            "--- Chunk 12920 ---\n",
            "The noise can be pure Gaussian noise added to the inputs, or it can be randomly\n",
            "\n",
            "--- Chunk 12921 ---\n",
            "switched-off inputs, just like in dropout (introduced in Chapter 11). Figure 17-8\n",
            "shows both options.\n",
            "\n",
            "--- Chunk 12922 ---\n",
            "Figure 17-8. Denoising autoencoders, with Gaussian noise (left) or dropout (right)\n",
            "\n",
            "--- Chunk 12923 ---\n",
            "The implementation is straightforward: it is a regular stacked autoencoder with an\n",
            "\n",
            "--- Chunk 12924 ---\n",
            "additional Dropout layer applied to the encoder’s inputs (or you could use a Gaus\n",
            "\n",
            "--- Chunk 12925 ---\n",
            "sianNoise layer instead). Recall that the Dropout layer is only active during training\n",
            "(and so is the GaussianNoise layer):\n",
            "\n",
            "--- Chunk 12926 ---\n",
            "5 Pascal Vincent et al., “Extracting and Composing Robust Features with Denoising Autoencoders,” Proceedings\n",
            "\n",
            "--- Chunk 12927 ---\n",
            "of the 25th International Conference on Machine Learning (2008): 1096–1103.\n",
            "\n",
            "--- Chunk 12928 ---\n",
            "6 Pascal Vincent et al., “Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network\n",
            "\n",
            "--- Chunk 12929 ---\n",
            "with a Local Denoising Criterion,” Journal of Machine Learning Research 11 (2010): 3371–3408.\n",
            "\n",
            "--- Chunk 12930 ---\n",
            "Denoising Autoencoders | 581\n",
            "\n",
            "--- Chunk 12931 ---\n",
            "dropout_encoder = keras.models.Sequential([\n",
            "    keras.layers.Flatten(input_shape=[28, 28]),\n",
            "    keras.layers.Dropout(0.5),\n",
            "\n",
            "--- Chunk 12932 ---\n",
            "keras.layers.Dense(100, activation=\"selu\"),\n",
            "    keras.layers.Dense(30, activation=\"selu\")\n",
            "])\n",
            "dropout_decoder = keras.models.Sequential([\n",
            "\n",
            "--- Chunk 12933 ---\n",
            "keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
            "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
            "\n",
            "--- Chunk 12934 ---\n",
            "keras.layers.Reshape([28, 28])\n",
            "])\n",
            "dropout_ae = keras.models.Sequential([dropout_encoder, dropout_decoder])\n",
            "\n",
            "--- Chunk 12935 ---\n",
            "Figure 17-9 shows a few noisy images (with half the pixels turned off), and the\n",
            "\n",
            "--- Chunk 12936 ---\n",
            "images reconstructed by the dropout-based denoising autoencoder. Notice how the\n",
            "\n",
            "--- Chunk 12937 ---\n",
            "autoencoder guesses details that are actually not in the input, such as the top of the\n",
            "\n",
            "--- Chunk 12938 ---\n",
            "white shirt (bottom row, fourth image). As you can see, not only can denoising\n",
            "\n",
            "--- Chunk 12939 ---\n",
            "autoencoders be used for data visualization or unsupervised pretraining, like the\n",
            "\n",
            "--- Chunk 12940 ---\n",
            "other autoencoders we’ve discussed so far, but they can also be used quite simply and\n",
            "efficiently to remove noise from images.\n",
            "\n",
            "--- Chunk 12941 ---\n",
            "Figure 17-9. Noisy images (top) and their reconstructions (bottom)\n",
            "\n",
            "--- Chunk 12942 ---\n",
            "Sparse Autoencoders\n",
            "Another kind of constraint that often leads to good feature extraction is sparsity: by\n",
            "\n",
            "--- Chunk 12943 ---\n",
            "adding an appropriate term to the cost function, the autoencoder is pushed to reduce\n",
            "\n",
            "--- Chunk 12944 ---\n",
            "the number of active neurons in the coding layer. For example, it may be pushed to\n",
            "\n",
            "--- Chunk 12945 ---\n",
            "have on average only 5% significantly active neurons in the coding layer. This forces\n",
            "\n",
            "--- Chunk 12946 ---\n",
            "the autoencoder to represent each input as a combination of a small number of acti‐\n",
            "\n",
            "--- Chunk 12947 ---\n",
            "vations. As a result, each neuron in the coding layer typically ends up representing a\n",
            "\n",
            "--- Chunk 12948 ---\n",
            "useful feature (if you could speak only a few words per month, you would probably\n",
            "try to make them worth listening to).\n",
            "\n",
            "--- Chunk 12949 ---\n",
            "A simple approach is to use the sigmoid activation function in the coding layer (to\n",
            "\n",
            "--- Chunk 12950 ---\n",
            "constrain the codings to values between 0 and 1), use a large coding layer (e.g., with\n",
            "\n",
            "--- Chunk 12951 ---\n",
            "582 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 12952 ---\n",
            "300 units), and add some ℓ1 regularization to the coding layer’s activations (the\n",
            "decoder is just a regular decoder):\n",
            "\n",
            "--- Chunk 12953 ---\n",
            "sparse_l1_encoder = keras.models.Sequential([\n",
            "    keras.layers.Flatten(input_shape=[28, 28]),\n",
            "    keras.layers.Dense(100, activation=\"selu\"),\n",
            "\n",
            "--- Chunk 12954 ---\n",
            "keras.layers.Dense(300, activation=\"sigmoid\"),\n",
            "    keras.layers.ActivityRegularization(l1=1e-3)\n",
            "])\n",
            "sparse_l1_decoder = keras.models.Sequential([\n",
            "\n",
            "--- Chunk 12955 ---\n",
            "keras.layers.Dense(100, activation=\"selu\", input_shape=[300]),\n",
            "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
            "\n",
            "--- Chunk 12956 ---\n",
            "keras.layers.Reshape([28, 28])\n",
            "])\n",
            "sparse_l1_ae = keras.models.Sequential([sparse_l1_encoder, sparse_l1_decoder])\n",
            "\n",
            "--- Chunk 12957 ---\n",
            "This ActivityRegularization layer just returns its inputs, but as a side effect it adds\n",
            "\n",
            "--- Chunk 12958 ---\n",
            "a training loss equal to the sum of absolute values of its inputs (this layer only has an\n",
            "\n",
            "--- Chunk 12959 ---\n",
            "effect during training). Equivalently, you could remove the ActivityRegularization\n",
            "\n",
            "--- Chunk 12960 ---\n",
            "layer and set activity_regularizer=keras.regularizers.l1(1e-3) in the previous\n",
            "\n",
            "--- Chunk 12961 ---\n",
            "layer. This penalty will encourage the neural network to produce codings close to 0,\n",
            "\n",
            "--- Chunk 12962 ---\n",
            "but since it will also be penalized if it does not reconstruct the inputs correctly, it will\n",
            "\n",
            "--- Chunk 12963 ---\n",
            "have to output at least a few nonzero values. Using the ℓ1 norm rather than the ℓ2\n",
            "\n",
            "--- Chunk 12964 ---\n",
            "norm will push the neural network to preserve the most important codings while\n",
            "\n",
            "--- Chunk 12965 ---\n",
            "eliminating the ones that are not needed for the input image (rather than just reduc‐\n",
            "ing all codings).\n",
            "\n",
            "--- Chunk 12966 ---\n",
            "ing all codings).\n",
            "Another approach, which often yields better results, is to measure the actual sparsity\n",
            "\n",
            "--- Chunk 12967 ---\n",
            "of the coding layer at each training iteration, and penalize the model when the meas‐\n",
            "\n",
            "--- Chunk 12968 ---\n",
            "ured sparsity differs from a target sparsity. We do so by computing the average activa‐\n",
            "\n",
            "--- Chunk 12969 ---\n",
            "tion of each neuron in the coding layer, over the whole training batch. The batch size\n",
            "must not be too small, or else the mean will not be accurate.\n",
            "\n",
            "--- Chunk 12970 ---\n",
            "Once we have the mean activation per neuron, we want to penalize the neurons that\n",
            "\n",
            "--- Chunk 12971 ---\n",
            "are too active, or not active enough, by adding a sparsity loss to the cost function. For\n",
            "\n",
            "--- Chunk 12972 ---\n",
            "example, if we measure that a neuron has an average activation of 0.3, but the target\n",
            "\n",
            "--- Chunk 12973 ---\n",
            "sparsity is 0.1, it must be penalized to activate less. One approach could be simply\n",
            "\n",
            "--- Chunk 12974 ---\n",
            "adding the squared error (0.3 – 0.1)2 to the cost function, but in practice a better\n",
            "\n",
            "--- Chunk 12975 ---\n",
            "approach is to use the Kullback–Leibler (KL) divergence (briefly discussed in Chap‐\n",
            "\n",
            "--- Chunk 12976 ---\n",
            "ter 4), which has much stronger gradients than the mean squared error, as you can\n",
            "see in Figure 17-10.\n",
            "\n",
            "--- Chunk 12977 ---\n",
            "Sparse Autoencoders | 583\n",
            "\n",
            "\n",
            "\n",
            "Figure 17-10. Sparsity loss\n",
            "\n",
            "--- Chunk 12978 ---\n",
            "Given two discrete probability distributions P and Q, the KL divergence between\n",
            "\n",
            "--- Chunk 12979 ---\n",
            "these distributions, noted DKL(P ∥ Q), can be computed using Equation 17-1.\n",
            "\n",
            "--- Chunk 12980 ---\n",
            "Equation 17-1. Kullback–Leibler divergence\n",
            "\n",
            "DKL P ∥ Q = ∑P i log P i\n",
            "i Q i\n",
            "\n",
            "--- Chunk 12981 ---\n",
            "In our case, we want to measure the divergence between the target probability p that a\n",
            "\n",
            "--- Chunk 12982 ---\n",
            "neuron in the coding layer will activate and the actual probability q (i.e., the mean\n",
            "\n",
            "--- Chunk 12983 ---\n",
            "activation over the training batch). So the KL divergence simplifies to Equation 17-2.\n",
            "\n",
            "--- Chunk 12984 ---\n",
            "Equation 17-2. KL divergence between the target sparsity p and the actual sparsity q\n",
            "\n",
            "DKL p ∥ q = p log p\n",
            "q + 1 − p log 1 − p\n",
            "\n",
            "1 − q\n",
            "\n",
            "--- Chunk 12985 ---\n",
            "Once we have computed the sparsity loss for each neuron in the coding layer, we sum\n",
            "\n",
            "--- Chunk 12986 ---\n",
            "up these losses and add the result to the cost function. In order to control the relative\n",
            "\n",
            "--- Chunk 12987 ---\n",
            "importance of the sparsity loss and the reconstruction loss, we can multiply the spar‐\n",
            "\n",
            "--- Chunk 12988 ---\n",
            "sity loss by a sparsity weight hyperparameter. If this weight is too high, the model will\n",
            "\n",
            "--- Chunk 12989 ---\n",
            "stick closely to the target sparsity, but it may not reconstruct the inputs properly,\n",
            "\n",
            "--- Chunk 12990 ---\n",
            "making the model useless. Conversely, if it is too low, the model will mostly ignore\n",
            "\n",
            "--- Chunk 12991 ---\n",
            "the sparsity objective and will not learn any interesting features.\n",
            "\n",
            "--- Chunk 12992 ---\n",
            "584 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 12993 ---\n",
            "We now have all we need to implement a sparse autoencoder based on the KL diver‐\n",
            "\n",
            "--- Chunk 12994 ---\n",
            "gence. First, let’s create a custom regularizer to apply KL divergence regularization:\n",
            "\n",
            "--- Chunk 12995 ---\n",
            "K = keras.backend\n",
            "kl_divergence = keras.losses.kullback_leibler_divergence\n",
            "\n",
            "--- Chunk 12996 ---\n",
            "class KLDivergenceRegularizer(keras.regularizers.Regularizer):\n",
            "    def __init__(self, weight, target=0.1):\n",
            "        self.weight = weight\n",
            "\n",
            "--- Chunk 12997 ---\n",
            "self.target = target\n",
            "    def __call__(self, inputs):\n",
            "        mean_activities = K.mean(inputs, axis=0)\n",
            "        return self.weight * (\n",
            "\n",
            "--- Chunk 12998 ---\n",
            "kl_divergence(self.target, mean_activities) +\n",
            "            kl_divergence(1. - self.target, 1. - mean_activities))\n",
            "\n",
            "--- Chunk 12999 ---\n",
            "Now we can build the sparse autoencoder, using the KLDivergenceRegularizer for\n",
            "the coding layer’s activations:\n",
            "\n",
            "--- Chunk 13000 ---\n",
            "kld_reg = KLDivergenceRegularizer(weight=0.05, target=0.1)\n",
            "sparse_kl_encoder = keras.models.Sequential([\n",
            "\n",
            "--- Chunk 13001 ---\n",
            "keras.layers.Flatten(input_shape=[28, 28]),\n",
            "    keras.layers.Dense(100, activation=\"selu\"),\n",
            "\n",
            "--- Chunk 13002 ---\n",
            "keras.layers.Dense(300, activation=\"sigmoid\", activity_regularizer=kld_reg)\n",
            "])\n",
            "sparse_kl_decoder = keras.models.Sequential([\n",
            "\n",
            "--- Chunk 13003 ---\n",
            "keras.layers.Dense(100, activation=\"selu\", input_shape=[300]),\n",
            "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
            "\n",
            "--- Chunk 13004 ---\n",
            "keras.layers.Reshape([28, 28])\n",
            "])\n",
            "sparse_kl_ae = keras.models.Sequential([sparse_kl_encoder, sparse_kl_decoder])\n",
            "\n",
            "--- Chunk 13005 ---\n",
            "After training this sparse autoencoder on Fashion MNIST, the activations of the neu‐\n",
            "\n",
            "--- Chunk 13006 ---\n",
            "rons in the coding layer are mostly close to 0 (about 70% of all activations are lower\n",
            "\n",
            "--- Chunk 13007 ---\n",
            "than 0.1), and all neurons have a mean activation around 0.1 (about 90% of all neu‐\n",
            "\n",
            "--- Chunk 13008 ---\n",
            "rons have a mean activation between 0.1 and 0.2), as shown in Figure 17-11.\n",
            "\n",
            "--- Chunk 13009 ---\n",
            "Figure 17-11. Distribution of all the activations in the coding layer (left) and distribution\n",
            "of the mean activation per neuron (right)\n",
            "\n",
            "--- Chunk 13010 ---\n",
            "Sparse Autoencoders | 585\n",
            "\n",
            "--- Chunk 13011 ---\n",
            "Variational Autoencoders\n",
            "Another important category of autoencoders was introduced in 2013 by Diederik\n",
            "\n",
            "--- Chunk 13012 ---\n",
            "Kingma and Max Welling and quickly became one of the most popular types of\n",
            "autoencoders: variational autoencoders.7\n",
            "\n",
            "--- Chunk 13013 ---\n",
            "They are quite different from all the autoencoders we have discussed so far, in these\n",
            "particular ways:\n",
            "\n",
            "--- Chunk 13014 ---\n",
            "• They are probabilistic autoencoders, meaning that their outputs are partly deter‐\n",
            "\n",
            "--- Chunk 13015 ---\n",
            "mined by chance, even after training (as opposed to denoising autoencoders,\n",
            "which use randomness only during training).\n",
            "\n",
            "--- Chunk 13016 ---\n",
            "• Most importantly, they are generative autoencoders, meaning that they can gener‐\n",
            "\n",
            "--- Chunk 13017 ---\n",
            "ate new instances that look like they were sampled from the training set.\n",
            "\n",
            "--- Chunk 13018 ---\n",
            "Both these properties make them rather similar to RBMs, but they are easier to train,\n",
            "\n",
            "--- Chunk 13019 ---\n",
            "and the sampling process is much faster (with RBMs you need to wait for the network\n",
            "\n",
            "--- Chunk 13020 ---\n",
            "to stabilize into a “thermal equilibrium” before you can sample a new instance).\n",
            "\n",
            "--- Chunk 13021 ---\n",
            "Indeed, as their name suggests, variational autoencoders perform variational Baye‐\n",
            "\n",
            "--- Chunk 13022 ---\n",
            "sian inference (introduced in Chapter 9), which is an efficient way to perform\n",
            "approximate Bayesian inference.\n",
            "\n",
            "--- Chunk 13023 ---\n",
            "Let’s take a look at how they work. Figure 17-12 (left) shows a variational autoen‐\n",
            "\n",
            "--- Chunk 13024 ---\n",
            "coder. You can recognize the basic structure of all autoencoders, with an encoder fol‐\n",
            "\n",
            "--- Chunk 13025 ---\n",
            "lowed by a decoder (in this example, they both have two hidden layers), but there is a\n",
            "\n",
            "--- Chunk 13026 ---\n",
            "twist: instead of directly producing a coding for a given input, the encoder produces a\n",
            "\n",
            "--- Chunk 13027 ---\n",
            "mean coding μ and a standard deviation σ. The actual coding is then sampled ran‐\n",
            "\n",
            "--- Chunk 13028 ---\n",
            "domly from a Gaussian distribution with mean μ and standard deviation σ. After that\n",
            "\n",
            "--- Chunk 13029 ---\n",
            "the decoder decodes the sampled coding normally. The right part of the diagram\n",
            "\n",
            "--- Chunk 13030 ---\n",
            "shows a training instance going through this autoencoder. First, the encoder pro‐\n",
            "\n",
            "--- Chunk 13031 ---\n",
            "duces μ and σ, then a coding is sampled randomly (notice that it is not exactly located\n",
            "\n",
            "--- Chunk 13032 ---\n",
            "at μ), and finally this coding is decoded; the final output resembles the training\n",
            "instance.\n",
            "\n",
            "--- Chunk 13033 ---\n",
            "7 Diederik Kingma and Max Welling, “Auto-Encoding Variational Bayes,” arXiv preprint arXiv:1312.6114\n",
            "(2013).\n",
            "\n",
            "--- Chunk 13034 ---\n",
            "586 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 13035 ---\n",
            "Figure 17-12. Variational autoencoder (left) and an instance going through it (right)\n",
            "\n",
            "--- Chunk 13036 ---\n",
            "As you can see in the diagram, although the inputs may have a very convoluted distri‐\n",
            "\n",
            "--- Chunk 13037 ---\n",
            "bution, a variational autoencoder tends to produce codings that look as though they\n",
            "\n",
            "--- Chunk 13038 ---\n",
            "were sampled from a simple Gaussian distribution:8 during training, the cost function\n",
            "\n",
            "--- Chunk 13039 ---\n",
            "(discussed next) pushes the codings to gradually migrate within the coding space\n",
            "\n",
            "--- Chunk 13040 ---\n",
            "(also called the latent space) to end up looking like a cloud of Gaussian points. One\n",
            "\n",
            "--- Chunk 13041 ---\n",
            "great consequence is that after training a variational autoencoder, you can very easily\n",
            "\n",
            "--- Chunk 13042 ---\n",
            "generate a new instance: just sample a random coding from the Gaussian distribu‐\n",
            "tion, decode it, and voilà!\n",
            "\n",
            "--- Chunk 13043 ---\n",
            "Now, let’s look at the cost function. It is composed of two parts. The first is the usual\n",
            "\n",
            "--- Chunk 13044 ---\n",
            "reconstruction loss that pushes the autoencoder to reproduce its inputs (we can use\n",
            "\n",
            "--- Chunk 13045 ---\n",
            "cross entropy for this, as discussed earlier). The second is the latent loss that pushes\n",
            "\n",
            "--- Chunk 13046 ---\n",
            "the autoencoder to have codings that look as though they were sampled from a simple\n",
            "\n",
            "--- Chunk 13047 ---\n",
            "Gaussian distribution: it is the KL divergence between the target distribution (i.e., the\n",
            "\n",
            "--- Chunk 13048 ---\n",
            "Gaussian distribution) and the actual distribution of the codings. The math is a bit\n",
            "\n",
            "--- Chunk 13049 ---\n",
            "more complex than with the sparse autoencoder, in particular because of the Gaus‐\n",
            "\n",
            "--- Chunk 13050 ---\n",
            "sian noise, which limits the amount of information that can be transmitted to the\n",
            "\n",
            "--- Chunk 13051 ---\n",
            "coding layer (thus pushing the autoencoder to learn useful features). Luckily, the\n",
            "\n",
            "--- Chunk 13052 ---\n",
            "8 Variational autoencoders are actually more general; the codings are not limited to Gaussian distributions.\n",
            "\n",
            "Variational Autoencoders | 587\n",
            "\n",
            "--- Chunk 13053 ---\n",
            "equations simplify, so the latent loss can be computed quite simply using Equation\n",
            "17-3:9\n",
            "\n",
            "Equation 17-3. Variational autoencoder’s latent loss\n",
            "K\n",
            "\n",
            "--- Chunk 13054 ---\n",
            "ℒ = − 1 ∑ 1 + log σ 2 − σ 2 μ 2\n",
            "2 i = 1 i i − i\n",
            "\n",
            "--- Chunk 13055 ---\n",
            "In this equation, ℒ is the latent loss, n is the codings’ dimensionality, and μi and σi are\n",
            "\n",
            "--- Chunk 13056 ---\n",
            "the mean and standard deviation of the ith component of the codings. The vectors μ\n",
            "\n",
            "--- Chunk 13057 ---\n",
            "and σ (which contain all the μi and σi) are output by the encoder, as shown in\n",
            "Figure 17-12 (left).\n",
            "\n",
            "--- Chunk 13058 ---\n",
            "A common tweak to the variational autoencoder’s architecture is to make the encoder\n",
            "\n",
            "--- Chunk 13059 ---\n",
            "output γ = log(σ2) rather than σ. The latent loss can then be computed as shown in\n",
            "\n",
            "--- Chunk 13060 ---\n",
            "Equation 17-4. This approach is more numerically stable and speeds up training.\n",
            "\n",
            "--- Chunk 13061 ---\n",
            "Equation 17-4. Variational autoencoder’s latent loss, rewritten using γ = log(σ2)\n",
            "K\n",
            "\n",
            "ℒ = − 1\n",
            "2 ∑ 1 + γ\n",
            "\n",
            "i = 1 i − exp γi − μ 2\n",
            "i\n",
            "\n",
            "--- Chunk 13062 ---\n",
            "Let’s start building a variational autoencoder for Fashion MNIST (as shown in\n",
            "\n",
            "--- Chunk 13063 ---\n",
            "Figure 17-12, but using the γ tweak). First, we will need a custom layer to sample the\n",
            "codings, given μ and γ:\n",
            "\n",
            "--- Chunk 13064 ---\n",
            "class Sampling(keras.layers.Layer):\n",
            "    def call(self, inputs):\n",
            "        mean, log_var = inputs\n",
            "\n",
            "--- Chunk 13065 ---\n",
            "return K.random_normal(tf.shape(log_var)) * K.exp(log_var / 2) + mean\n",
            "\n",
            "--- Chunk 13066 ---\n",
            "This Sampling layer takes two inputs: mean (μ) and log_var (γ). It uses the function\n",
            "\n",
            "--- Chunk 13067 ---\n",
            "K.random_normal() to sample a random vector (of the same shape as γ) from the\n",
            "\n",
            "--- Chunk 13068 ---\n",
            "Normal distribution, with mean 0 and standard deviation 1. Then it multiplies it by\n",
            "\n",
            "--- Chunk 13069 ---\n",
            "exp(γ / 2) (which is equal to σ, as you can verify), and finally it adds μ and returns the\n",
            "\n",
            "--- Chunk 13070 ---\n",
            "result. This samples a codings vector from the Normal distribution with mean μ and\n",
            "standard deviation σ.\n",
            "\n",
            "--- Chunk 13071 ---\n",
            "Next, we can create the encoder, using the Functional API because the model is not\n",
            "entirely sequential:\n",
            "\n",
            "--- Chunk 13072 ---\n",
            "9 For more mathematical details, check out the original paper on variational autoencoders, or Carl Doersch’s\n",
            "great tutorial (2016).\n",
            "\n",
            "--- Chunk 13073 ---\n",
            "588 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "\n",
            "\n",
            "codings_size = 10\n",
            "\n",
            "--- Chunk 13074 ---\n",
            "inputs = keras.layers.Input(shape=[28, 28])\n",
            "z = keras.layers.Flatten()(inputs)\n",
            "z = keras.layers.Dense(150, activation=\"selu\")(z)\n",
            "\n",
            "--- Chunk 13075 ---\n",
            "z = keras.layers.Dense(100, activation=\"selu\")(z)\n",
            "codings_mean = keras.layers.Dense(codings_size)(z)  # μ\n",
            "\n",
            "--- Chunk 13076 ---\n",
            "codings_log_var = keras.layers.Dense(codings_size)(z)  # γ\n",
            "codings = Sampling()([codings_mean, codings_log_var])\n",
            "variational_encoder = keras.Model(\n",
            "\n",
            "--- Chunk 13077 ---\n",
            "inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])\n",
            "\n",
            "--- Chunk 13078 ---\n",
            "Note that the Dense layers that output codings_mean (μ) and codings_log_var (γ)\n",
            "\n",
            "--- Chunk 13079 ---\n",
            "have the same inputs (i.e., the outputs of the second Dense layer). We then pass both\n",
            "\n",
            "--- Chunk 13080 ---\n",
            "codings_mean and codings_log_var to the Sampling layer. Finally, the varia\n",
            "\n",
            "--- Chunk 13081 ---\n",
            "tional_encoder model has three outputs, in case you want to inspect the values of\n",
            "\n",
            "--- Chunk 13082 ---\n",
            "codings_mean and codings_log_var. The only output we will use is the last one (cod\n",
            "ings). Now let’s build the decoder:\n",
            "\n",
            "--- Chunk 13083 ---\n",
            "decoder_inputs = keras.layers.Input(shape=[codings_size])\n",
            "x = keras.layers.Dense(100, activation=\"selu\")(decoder_inputs)\n",
            "\n",
            "--- Chunk 13084 ---\n",
            "x = keras.layers.Dense(150, activation=\"selu\")(x)\n",
            "x = keras.layers.Dense(28 * 28, activation=\"sigmoid\")(x)\n",
            "\n",
            "--- Chunk 13085 ---\n",
            "outputs = keras.layers.Reshape([28, 28])(x)\n",
            "variational_decoder = keras.Model(inputs=[decoder_inputs], outputs=[outputs])\n",
            "\n",
            "--- Chunk 13086 ---\n",
            "For this decoder, we could have used the Sequential API instead of the Functional\n",
            "\n",
            "--- Chunk 13087 ---\n",
            "API, since it is really just a simple stack of layers, virtually identical to many of the\n",
            "\n",
            "--- Chunk 13088 ---\n",
            "decoders we have built so far. Finally, let’s build the variational autoencoder model:\n",
            "\n",
            "--- Chunk 13089 ---\n",
            "_, _, codings = variational_encoder(inputs)\n",
            "reconstructions = variational_decoder(codings)\n",
            "\n",
            "--- Chunk 13090 ---\n",
            "variational_ae = keras.Model(inputs=[inputs], outputs=[reconstructions])\n",
            "\n",
            "--- Chunk 13091 ---\n",
            "Note that we ignore the first two outputs of the encoder (we only want to feed the\n",
            "\n",
            "--- Chunk 13092 ---\n",
            "codings to the decoder). Lastly, we must add the latent loss and the reconstruction\n",
            "loss:\n",
            "\n",
            "--- Chunk 13093 ---\n",
            "latent_loss = -0.5 * K.sum(\n",
            "    1 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean),\n",
            "    axis=-1)\n",
            "\n",
            "--- Chunk 13094 ---\n",
            "axis=-1)\n",
            "variational_ae.add_loss(K.mean(latent_loss) / 784.)\n",
            "variational_ae.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
            "\n",
            "--- Chunk 13095 ---\n",
            "We first apply Equation 17-4 to compute the latent loss for each instance in the batch\n",
            "\n",
            "--- Chunk 13096 ---\n",
            "(we sum over the last axis). Then we compute the mean loss over all the instances in\n",
            "\n",
            "--- Chunk 13097 ---\n",
            "the batch, and we divide the result by 784 to ensure it has the appropriate scale com‐\n",
            "\n",
            "--- Chunk 13098 ---\n",
            "pared to the reconstruction loss. Indeed, the variational autoencoder’s reconstruction\n",
            "\n",
            "--- Chunk 13099 ---\n",
            "loss is supposed to be the sum of the pixel reconstruction errors, but when Keras\n",
            "\n",
            "--- Chunk 13100 ---\n",
            "computes the \"binary_crossentropy\" loss, it computes the mean over all 784 pixels,\n",
            "\n",
            "--- Chunk 13101 ---\n",
            "Variational Autoencoders | 589\n",
            "\n",
            "--- Chunk 13102 ---\n",
            "rather than the sum. So, the reconstruction loss is 784 times smaller than we need it\n",
            "\n",
            "--- Chunk 13103 ---\n",
            "to be. We could define a custom loss to compute the sum rather than the mean, but it\n",
            "\n",
            "--- Chunk 13104 ---\n",
            "is simpler to divide the latent loss by 784 (the final loss will be 784 times smaller than\n",
            "\n",
            "--- Chunk 13105 ---\n",
            "it should be, but this just means that we should use a larger learning rate).\n",
            "\n",
            "--- Chunk 13106 ---\n",
            "Note that we use the RMSprop optimizer, which works well in this case. And finally we\n",
            "can train the autoencoder!\n",
            "\n",
            "--- Chunk 13107 ---\n",
            "history = variational_ae.fit(X_train, X_train, epochs=50, batch_size=128,\n",
            "                             validation_data=[X_valid, X_valid])\n",
            "\n",
            "--- Chunk 13108 ---\n",
            "Generating Fashion MNIST Images\n",
            "Now let’s use this variational autoencoder to generate images that look like fashion\n",
            "\n",
            "--- Chunk 13109 ---\n",
            "items. All we need to do is sample random codings from a Gaussian distribution and\n",
            "decode them:\n",
            "\n",
            "--- Chunk 13110 ---\n",
            "codings = tf.random.normal(shape=[12, codings_size])\n",
            "images = variational_decoder(codings).numpy()\n",
            "\n",
            "Figure 17-13 shows the 12 generated images.\n",
            "\n",
            "--- Chunk 13111 ---\n",
            "Figure 17-13. Fashion MNIST images generated by the variational autoencoder\n",
            "\n",
            "--- Chunk 13112 ---\n",
            "The majority of these images look fairly convincing, if a bit too fuzzy. The rest are not\n",
            "\n",
            "--- Chunk 13113 ---\n",
            "great, but don’t be too harsh on the autoencoder—it only had a few minutes to learn!\n",
            "\n",
            "--- Chunk 13114 ---\n",
            "Give it a bit more fine-tuning and training time, and those images should look better.\n",
            "\n",
            "--- Chunk 13115 ---\n",
            "Variational autoencoders make it possible to perform semantic interpolation: instead\n",
            "\n",
            "--- Chunk 13116 ---\n",
            "of interpolating two images at the pixel level (which would look as if the two images\n",
            "\n",
            "--- Chunk 13117 ---\n",
            "were overlaid), we can interpolate at the codings level. We first run both images\n",
            "\n",
            "--- Chunk 13118 ---\n",
            "through the encoder, then we interpolate the two codings we get, and finally we\n",
            "\n",
            "--- Chunk 13119 ---\n",
            "decode the interpolated codings to get the final image. It will look like a regular Fash‐\n",
            "\n",
            "--- Chunk 13120 ---\n",
            "ion MNIST image, but it will be an intermediate between the original images. In the\n",
            "\n",
            "--- Chunk 13121 ---\n",
            "following code example, we take the 12 codings we just generated, we organize them\n",
            "\n",
            "--- Chunk 13122 ---\n",
            "590 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 13123 ---\n",
            "in a 3 × 4 grid, and we use TensorFlow’s tf.image.resize() function to resize this\n",
            "\n",
            "--- Chunk 13124 ---\n",
            "grid to 5 × 7. By default, the resize() function will perform bilinear interpolation, so\n",
            "\n",
            "--- Chunk 13125 ---\n",
            "every other row and column will contain interpolated codings. We then use the\n",
            "decoder to produce all the images:\n",
            "\n",
            "--- Chunk 13126 ---\n",
            "codings_grid = tf.reshape(codings, [1, 3, 4, codings_size])\n",
            "larger_grid = tf.image.resize(codings_grid, size=[5, 7])\n",
            "\n",
            "--- Chunk 13127 ---\n",
            "interpolated_codings = tf.reshape(larger_grid, [-1, codings_size])\n",
            "images = variational_decoder(interpolated_codings).numpy()\n",
            "\n",
            "--- Chunk 13128 ---\n",
            "Figure 17-14 shows the resulting images. The original images are framed, and the rest\n",
            "\n",
            "--- Chunk 13129 ---\n",
            "are the result of semantic interpolation between the nearby images. Notice, for exam‐\n",
            "\n",
            "--- Chunk 13130 ---\n",
            "ple, how the shoe in the fourth row and fifth column is a nice interpolation between\n",
            "the two shoes located above and below it.\n",
            "\n",
            "--- Chunk 13131 ---\n",
            "Figure 17-14. Semantic interpolation\n",
            "\n",
            "--- Chunk 13132 ---\n",
            "For several years, variational autoencoders were quite popular, but GANs eventually\n",
            "\n",
            "--- Chunk 13133 ---\n",
            "took the lead, in particular because they are capable of generating much more realistic\n",
            "and crisp images. So let’s turn our attention to GANs.\n",
            "\n",
            "--- Chunk 13134 ---\n",
            "Variational Autoencoders | 591\n",
            "\n",
            "--- Chunk 13135 ---\n",
            "Generative Adversarial Networks\n",
            "Generative adversarial networks were proposed in a 2014 paper10 by Ian Goodfellow\n",
            "\n",
            "--- Chunk 13136 ---\n",
            "et al., and although the idea got researchers excited almost instantly, it took a few\n",
            "\n",
            "--- Chunk 13137 ---\n",
            "years to overcome some of the difficulties of training GANs. Like many great ideas, it\n",
            "\n",
            "--- Chunk 13138 ---\n",
            "seems simple in hindsight: make neural networks compete against each other in the\n",
            "\n",
            "--- Chunk 13139 ---\n",
            "hope that this competition will push them to excel. As shown in Figure 17-15, a GAN\n",
            "is composed of two neural networks:\n",
            "Generator\n",
            "\n",
            "--- Chunk 13140 ---\n",
            "Takes a random distribution as input (typically Gaussian) and outputs some data\n",
            "\n",
            "--- Chunk 13141 ---\n",
            "—typically, an image. You can think of the random inputs as the latent represen‐\n",
            "\n",
            "--- Chunk 13142 ---\n",
            "tations (i.e., codings) of the image to be generated. So, as you can see, the genera‐\n",
            "\n",
            "--- Chunk 13143 ---\n",
            "tor offers the same functionality as a decoder in a variational autoencoder, and it\n",
            "\n",
            "--- Chunk 13144 ---\n",
            "can be used in the same way to generate new images (just feed it some Gaussian\n",
            "\n",
            "--- Chunk 13145 ---\n",
            "noise, and it outputs a brand-new image). However, it is trained very differently,\n",
            "as we will soon see.\n",
            "\n",
            "--- Chunk 13146 ---\n",
            "Discriminator\n",
            "Takes either a fake image from the generator or a real image from the training set\n",
            "\n",
            "--- Chunk 13147 ---\n",
            "as input, and must guess whether the input image is fake or real.\n",
            "\n",
            "--- Chunk 13148 ---\n",
            "Figure 17-15. A generative adversarial network\n",
            "\n",
            "--- Chunk 13149 ---\n",
            "10 Ian Goodfellow et al., “Generative Adversarial Nets,” Proceedings of the 27th International Conference on Neu‐\n",
            "\n",
            "--- Chunk 13150 ---\n",
            "ral Information Processing Systems 2 (2014): 2672–2680.\n",
            "\n",
            "--- Chunk 13151 ---\n",
            "592 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 13152 ---\n",
            "During training, the generator and the discriminator have opposite goals: the dis‐\n",
            "\n",
            "--- Chunk 13153 ---\n",
            "criminator tries to tell fake images from real images, while the generator tries to pro‐\n",
            "\n",
            "--- Chunk 13154 ---\n",
            "duce images that look real enough to trick the discriminator. Because the GAN is\n",
            "\n",
            "--- Chunk 13155 ---\n",
            "composed of two networks with different objectives, it cannot be trained like a regu‐\n",
            "\n",
            "--- Chunk 13156 ---\n",
            "lar neural network. Each training iteration is divided into two phases:\n",
            "\n",
            "--- Chunk 13157 ---\n",
            "• In the first phase, we train the discriminator. A batch of real images is sampled\n",
            "\n",
            "--- Chunk 13158 ---\n",
            "from the training set and is completed with an equal number of fake images pro‐\n",
            "\n",
            "--- Chunk 13159 ---\n",
            "duced by the generator. The labels are set to 0 for fake images and 1 for real\n",
            "\n",
            "--- Chunk 13160 ---\n",
            "images, and the discriminator is trained on this labeled batch for one step, using\n",
            "\n",
            "--- Chunk 13161 ---\n",
            "the binary cross-entropy loss. Importantly, backpropagation only optimizes the\n",
            "weights of the discriminator during this phase.\n",
            "\n",
            "--- Chunk 13162 ---\n",
            "• In the second phase, we train the generator. We first use it to produce another\n",
            "\n",
            "--- Chunk 13163 ---\n",
            "batch of fake images, and once again the discriminator is used to tell whether the\n",
            "\n",
            "--- Chunk 13164 ---\n",
            "images are fake or real. This time we do not add real images in the batch, and all\n",
            "\n",
            "--- Chunk 13165 ---\n",
            "the labels are set to 1 (real): in other words, we want the generator to produce\n",
            "\n",
            "--- Chunk 13166 ---\n",
            "images that the discriminator will (wrongly) believe to be real! Crucially, the\n",
            "\n",
            "--- Chunk 13167 ---\n",
            "weights of the discriminator are frozen during this step, so backpropagation only\n",
            "affects the weights of the generator.\n",
            "\n",
            "--- Chunk 13168 ---\n",
            "The generator never actually sees any real images, yet it gradually\n",
            "learns to produce convincing fake images! All it gets is the gradi‐\n",
            "\n",
            "--- Chunk 13169 ---\n",
            "ents flowing back through the discriminator. Fortunately, the better\n",
            "the discriminator gets, the more information about the real images\n",
            "\n",
            "--- Chunk 13170 ---\n",
            "is contained in these secondhand gradients, so the generator can\n",
            "make significant progress.\n",
            "\n",
            "--- Chunk 13171 ---\n",
            "Let’s go ahead and build a simple GAN for Fashion MNIST.\n",
            "First, we need to build the generator and the discriminator. The generator is similar\n",
            "\n",
            "--- Chunk 13172 ---\n",
            "to an autoencoder’s decoder, and the discriminator is a regular binary classifier (it\n",
            "\n",
            "--- Chunk 13173 ---\n",
            "takes an image as input and ends with a Dense layer containing a single unit and\n",
            "\n",
            "--- Chunk 13174 ---\n",
            "using the sigmoid activation function). For the second phase of each training itera‐\n",
            "\n",
            "--- Chunk 13175 ---\n",
            "tion, we also need the full GAN model containing the generator followed by the\n",
            "discriminator:\n",
            "\n",
            "--- Chunk 13176 ---\n",
            "codings_size = 30\n",
            "\n",
            "--- Chunk 13177 ---\n",
            "generator = keras.models.Sequential([\n",
            "    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
            "\n",
            "--- Chunk 13178 ---\n",
            "keras.layers.Dense(150, activation=\"selu\"),\n",
            "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
            "    keras.layers.Reshape([28, 28])\n",
            "])\n",
            "\n",
            "--- Chunk 13179 ---\n",
            "Generative Adversarial Networks | 593\n",
            "\n",
            "--- Chunk 13180 ---\n",
            "discriminator = keras.models.Sequential([\n",
            "    keras.layers.Flatten(input_shape=[28, 28]),\n",
            "    keras.layers.Dense(150, activation=\"selu\"),\n",
            "\n",
            "--- Chunk 13181 ---\n",
            "keras.layers.Dense(100, activation=\"selu\"),\n",
            "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
            "])\n",
            "\n",
            "--- Chunk 13182 ---\n",
            "])\n",
            "gan = keras.models.Sequential([generator, discriminator])\n",
            "\n",
            "--- Chunk 13183 ---\n",
            "Next, we need to compile these models. As the discriminator is a binary classifier, we\n",
            "\n",
            "--- Chunk 13184 ---\n",
            "can naturally use the binary cross-entropy loss. The generator will only be trained\n",
            "\n",
            "--- Chunk 13185 ---\n",
            "through the gan model, so we do not need to compile it at all. The gan model is also a\n",
            "\n",
            "--- Chunk 13186 ---\n",
            "binary classifier, so it can use the binary cross-entropy loss. Importantly, the discrimi‐\n",
            "\n",
            "--- Chunk 13187 ---\n",
            "nator should not be trained during the second phase, so we make it non-trainable\n",
            "before compiling the gan model:\n",
            "\n",
            "--- Chunk 13188 ---\n",
            "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
            "discriminator.trainable = False\n",
            "\n",
            "--- Chunk 13189 ---\n",
            "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
            "\n",
            "--- Chunk 13190 ---\n",
            "The trainable attribute is taken into account by Keras only when\n",
            "compiling a model, so after running this code, the discriminator\n",
            "\n",
            "--- Chunk 13191 ---\n",
            "is trainable if we call its fit() method or its train_on_batch()\n",
            "method (which we will be using), while it is not trainable when we\n",
            "\n",
            "--- Chunk 13192 ---\n",
            "call these methods on the gan model.\n",
            "\n",
            "--- Chunk 13193 ---\n",
            "Since the training loop is unusual, we cannot use the regular fit() method. Instead,\n",
            "\n",
            "--- Chunk 13194 ---\n",
            "we will write a custom training loop. For this, we first need to create a Dataset to\n",
            "iterate through the images:\n",
            "\n",
            "--- Chunk 13195 ---\n",
            "batch_size = 32\n",
            "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
            "\n",
            "--- Chunk 13196 ---\n",
            "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n",
            "\n",
            "--- Chunk 13197 ---\n",
            "We are now ready to write the training loop. Let’s wrap it in a train_gan() function:\n",
            "\n",
            "--- Chunk 13198 ---\n",
            "594 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 13199 ---\n",
            "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n",
            "    generator, discriminator = gan.layers\n",
            "    for epoch in range(n_epochs):\n",
            "\n",
            "--- Chunk 13200 ---\n",
            "for X_batch in dataset:\n",
            "            # phase 1 - training the discriminator\n",
            "\n",
            "--- Chunk 13201 ---\n",
            "noise = tf.random.normal(shape=[batch_size, codings_size])\n",
            "            generated_images = generator(noise)\n",
            "\n",
            "--- Chunk 13202 ---\n",
            "X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
            "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
            "\n",
            "--- Chunk 13203 ---\n",
            "discriminator.trainable = True\n",
            "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
            "\n",
            "--- Chunk 13204 ---\n",
            "# phase 2 - training the generator\n",
            "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
            "\n",
            "--- Chunk 13205 ---\n",
            "y2 = tf.constant([[1.]] * batch_size)\n",
            "            discriminator.trainable = False\n",
            "            gan.train_on_batch(noise, y2)\n",
            "\n",
            "--- Chunk 13206 ---\n",
            "train_gan(gan, dataset, batch_size, codings_size)\n",
            "\n",
            "As discussed earlier, you can see the two phases at each iteration:\n",
            "\n",
            "--- Chunk 13207 ---\n",
            "• In phase one we feed Gaussian noise to the generator to produce fake images,\n",
            "\n",
            "--- Chunk 13208 ---\n",
            "and we complete this batch by concatenating an equal number of real images.\n",
            "\n",
            "--- Chunk 13209 ---\n",
            "The targets y1 are set to 0 for fake images and 1 for real images. Then we train\n",
            "\n",
            "--- Chunk 13210 ---\n",
            "the discriminator on this batch. Note that we set the discriminator’s trainable\n",
            "\n",
            "--- Chunk 13211 ---\n",
            "attribute to True: this is only to get rid of a warning that Keras displays when it\n",
            "\n",
            "--- Chunk 13212 ---\n",
            "notices that trainable is now False but was True when the model was compiled\n",
            "(or vice versa).\n",
            "\n",
            "--- Chunk 13213 ---\n",
            "• In phase two, we feed the GAN some Gaussian noise. Its generator will start by\n",
            "\n",
            "--- Chunk 13214 ---\n",
            "producing fake images, then the discriminator will try to guess whether these\n",
            "\n",
            "--- Chunk 13215 ---\n",
            "images are fake or real. We want the discriminator to believe that the fake images\n",
            "\n",
            "--- Chunk 13216 ---\n",
            "are real, so the targets y2 are set to 1. Note that we set the trainable attribute to\n",
            "False, once again to avoid a warning.\n",
            "\n",
            "--- Chunk 13217 ---\n",
            "That’s it! If you display the generated images (see Figure 17-16), you will see that at\n",
            "\n",
            "--- Chunk 13218 ---\n",
            "the end of the first epoch, they already start to look like (very noisy) Fashion MNIST\n",
            "images.\n",
            "\n",
            "--- Chunk 13219 ---\n",
            "images.\n",
            "Unfortunately, the images never really get much better than that, and you may even\n",
            "\n",
            "--- Chunk 13220 ---\n",
            "find epochs where the GAN seems to be forgetting what it learned. Why is that? Well,\n",
            "\n",
            "--- Chunk 13221 ---\n",
            "it turns out that training a GAN can be challenging. Let’s see why.\n",
            "\n",
            "--- Chunk 13222 ---\n",
            "Generative Adversarial Networks | 595\n",
            "\n",
            "\n",
            "\n",
            "Figure 17-16. Images generated by the GAN after one epoch of training\n",
            "\n",
            "--- Chunk 13223 ---\n",
            "The Difficulties of Training GANs\n",
            "During training, the generator and the discriminator constantly try to outsmart each\n",
            "\n",
            "--- Chunk 13224 ---\n",
            "other, in a zero-sum game. As training advances, the game may end up in a state that\n",
            "\n",
            "--- Chunk 13225 ---\n",
            "game theorists call a Nash equilibrium, named after the mathematician John Nash:\n",
            "\n",
            "--- Chunk 13226 ---\n",
            "this is when no player would be better off changing their own strategy, assuming the\n",
            "\n",
            "--- Chunk 13227 ---\n",
            "other players do not change theirs. For example, a Nash equilibrium is reached when\n",
            "\n",
            "--- Chunk 13228 ---\n",
            "everyone drives on the left side of the road: no driver would be better off being the\n",
            "\n",
            "--- Chunk 13229 ---\n",
            "only one to switch sides. Of course, there is a second possible Nash equilibrium:\n",
            "\n",
            "--- Chunk 13230 ---\n",
            "when everyone drives on the right side of the road. Different initial states and dynam‐\n",
            "\n",
            "--- Chunk 13231 ---\n",
            "ics may lead to one equilibrium or the other. In this example, there is a single optimal\n",
            "\n",
            "--- Chunk 13232 ---\n",
            "strategy once an equilibrium is reached (i.e., driving on the same side as everyone\n",
            "\n",
            "--- Chunk 13233 ---\n",
            "else), but a Nash equilibrium can involve multiple competing strategies (e.g., a preda‐\n",
            "\n",
            "--- Chunk 13234 ---\n",
            "tor chases its prey, the prey tries to escape, and neither would be better off changing\n",
            "their strategy).\n",
            "\n",
            "--- Chunk 13235 ---\n",
            "their strategy).\n",
            "So how does this apply to GANs? Well, the authors of the paper demonstrated that a\n",
            "\n",
            "--- Chunk 13236 ---\n",
            "GAN can only reach a single Nash equilibrium: that’s when the generator produces\n",
            "\n",
            "--- Chunk 13237 ---\n",
            "perfectly realistic images, and the discriminator is forced to guess (50% real, 50%\n",
            "\n",
            "--- Chunk 13238 ---\n",
            "fake). This fact is very encouraging: it would seem that you just need to train the\n",
            "\n",
            "--- Chunk 13239 ---\n",
            "GAN for long enough, and it will eventually reach this equilibrium, giving you a per‐\n",
            "\n",
            "--- Chunk 13240 ---\n",
            "fect generator. Unfortunately, it’s not that simple: nothing guarantees that the equili‐\n",
            "brium will ever be reached.\n",
            "\n",
            "--- Chunk 13241 ---\n",
            "596 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 13242 ---\n",
            "The biggest difficulty is called mode collapse: this is when the generator’s outputs\n",
            "\n",
            "--- Chunk 13243 ---\n",
            "gradually become less diverse. How can this happen? Suppose that the generator gets\n",
            "\n",
            "--- Chunk 13244 ---\n",
            "better at producing convincing shoes than any other class. It will fool the discrimina‐\n",
            "\n",
            "--- Chunk 13245 ---\n",
            "tor a bit more with shoes, and this will encourage it to produce even more images of\n",
            "\n",
            "--- Chunk 13246 ---\n",
            "shoes. Gradually, it will forget how to produce anything else. Meanwhile, the only\n",
            "\n",
            "--- Chunk 13247 ---\n",
            "fake images that the discriminator will see will be shoes, so it will also forget how to\n",
            "\n",
            "--- Chunk 13248 ---\n",
            "discriminate fake images of other classes. Eventually, when the discriminator man‐\n",
            "\n",
            "--- Chunk 13249 ---\n",
            "ages to discriminate the fake shoes from the real ones, the generator will be forced to\n",
            "\n",
            "--- Chunk 13250 ---\n",
            "move to another class. It may then become good at shirts, forgetting about shoes, and\n",
            "\n",
            "--- Chunk 13251 ---\n",
            "the discriminator will follow. The GAN may gradually cycle across a few classes,\n",
            "never really becoming very good at any of them.\n",
            "\n",
            "--- Chunk 13252 ---\n",
            "Moreover, because the generator and the discriminator are constantly pushing against\n",
            "\n",
            "--- Chunk 13253 ---\n",
            "each other, their parameters may end up oscillating and becoming unstable. Training\n",
            "\n",
            "--- Chunk 13254 ---\n",
            "may begin properly, then suddenly diverge for no apparent reason, due to these insta‐\n",
            "\n",
            "--- Chunk 13255 ---\n",
            "bilities. And since many factors affect these complex dynamics, GANs are very sensi‐\n",
            "\n",
            "--- Chunk 13256 ---\n",
            "tive to the hyperparameters: you may have to spend a lot of effort fine-tuning them.\n",
            "\n",
            "--- Chunk 13257 ---\n",
            "These problems have kept researchers very busy since 2014: many papers were pub‐\n",
            "\n",
            "--- Chunk 13258 ---\n",
            "lished on this topic, some proposing new cost functions11 (though a 2018 paper12 by\n",
            "\n",
            "--- Chunk 13259 ---\n",
            "Google researchers questions their efficiency) or techniques to stabilize training or to\n",
            "\n",
            "--- Chunk 13260 ---\n",
            "avoid the mode collapse issue. For example, a popular technique called experience\n",
            "\n",
            "--- Chunk 13261 ---\n",
            "replay consists in storing the images produced by the generator at each iteration in a\n",
            "\n",
            "--- Chunk 13262 ---\n",
            "replay buffer (gradually dropping older generated images) and training the discrimi‐\n",
            "\n",
            "--- Chunk 13263 ---\n",
            "nator using real images plus fake images drawn from this buffer (rather than just fake\n",
            "\n",
            "--- Chunk 13264 ---\n",
            "images produced by the current generator). This reduces the chances that the dis‐\n",
            "\n",
            "--- Chunk 13265 ---\n",
            "criminator will overfit the latest generator’s outputs. Another common technique is\n",
            "\n",
            "--- Chunk 13266 ---\n",
            "called mini-batch discrimination: it measures how similar images are across the batch\n",
            "\n",
            "--- Chunk 13267 ---\n",
            "and provides this statistic to the discriminator, so it can easily reject a whole batch of\n",
            "\n",
            "--- Chunk 13268 ---\n",
            "fake images that lack diversity. This encourages the generator to produce a greater\n",
            "\n",
            "--- Chunk 13269 ---\n",
            "variety of images, reducing the chance of mode collapse. Other papers simply pro‐\n",
            "pose specific architectures that happen to perform well.\n",
            "\n",
            "--- Chunk 13270 ---\n",
            "In short, this is still a very active field of research, and the dynamics of GANs are still\n",
            "\n",
            "--- Chunk 13271 ---\n",
            "not perfectly understood. But the good news is that great progress has been made,\n",
            "\n",
            "--- Chunk 13272 ---\n",
            "and some of the results are truly astounding! So let’s look at some of the most success‐\n",
            "\n",
            "--- Chunk 13273 ---\n",
            "ful architectures, starting with deep convolutional GANs, which were the state of the\n",
            "\n",
            "--- Chunk 13274 ---\n",
            "art just a few years ago. Then we will look at two more recent (and more complex)\n",
            "architectures.\n",
            "\n",
            "--- Chunk 13275 ---\n",
            "11 For a nice comparison of the main GAN losses, check out this great GitHub project by Hwalsuk Lee.\n",
            "\n",
            "--- Chunk 13276 ---\n",
            "12 Mario Lucic et al., “Are GANs Created Equal? A Large-Scale Study,” Proceedings of the 32nd International Con‐\n",
            "\n",
            "--- Chunk 13277 ---\n",
            "ference on Neural Information Processing Systems (2018): 698–707.\n",
            "\n",
            "Generative Adversarial Networks | 597\n",
            "\n",
            "--- Chunk 13278 ---\n",
            "Deep Convolutional GANs\n",
            "The original GAN paper in 2014 experimented with convolutional layers, but only\n",
            "\n",
            "--- Chunk 13279 ---\n",
            "tried to generate small images. Soon after, many researchers tried to build GANs\n",
            "\n",
            "--- Chunk 13280 ---\n",
            "based on deeper convolutional nets for larger images. This proved to be tricky, as\n",
            "\n",
            "--- Chunk 13281 ---\n",
            "training was very unstable, but Alec Radford et al. finally succeeded in late 2015, after\n",
            "\n",
            "--- Chunk 13282 ---\n",
            "experimenting with many different architectures and hyperparameters. They called\n",
            "\n",
            "--- Chunk 13283 ---\n",
            "their architecture deep convolutional GANs (DCGANs).13 Here are the main guide‐\n",
            "lines they proposed for building stable convolutional GANs:\n",
            "\n",
            "--- Chunk 13284 ---\n",
            "• Replace any pooling layers with strided convolutions (in the discriminator) and\n",
            "transposed convolutions (in the generator).\n",
            "\n",
            "--- Chunk 13285 ---\n",
            "• Use Batch Normalization in both the generator and the discriminator, except in\n",
            "the generator’s output layer and the discriminator’s input layer.\n",
            "\n",
            "--- Chunk 13286 ---\n",
            "• Remove fully connected hidden layers for deeper architectures.\n",
            "\n",
            "--- Chunk 13287 ---\n",
            "• Use ReLU activation in the generator for all layers except the output layer, which\n",
            "\n",
            "--- Chunk 13288 ---\n",
            "should use tanh.\n",
            "• Use leaky ReLU activation in the discriminator for all layers.\n",
            "\n",
            "--- Chunk 13289 ---\n",
            "These guidelines will work in many cases, but not always, so you may still need to\n",
            "\n",
            "--- Chunk 13290 ---\n",
            "experiment with different hyperparameters (in fact, just changing the random seed\n",
            "\n",
            "--- Chunk 13291 ---\n",
            "and training the same model again will sometimes work). For example, here is a small\n",
            "DCGAN that works reasonably well with Fashion MNIST:\n",
            "\n",
            "--- Chunk 13292 ---\n",
            "13 Alec Radford et al., “Unsupervised Representation Learning with Deep Convolutional Generative Adversarial\n",
            "\n",
            "--- Chunk 13293 ---\n",
            "Networks,” arXiv preprint arXiv:1511.06434 (2015).\n",
            "\n",
            "--- Chunk 13294 ---\n",
            "598 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "\n",
            "\n",
            "codings_size = 100\n",
            "\n",
            "--- Chunk 13295 ---\n",
            "generator = keras.models.Sequential([\n",
            "    keras.layers.Dense(7 * 7 * 128, input_shape=[codings_size]),\n",
            "    keras.layers.Reshape([7, 7, 128]),\n",
            "\n",
            "--- Chunk 13296 ---\n",
            "keras.layers.BatchNormalization(),\n",
            "    keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"same\",\n",
            "\n",
            "--- Chunk 13297 ---\n",
            "activation=\"selu\"),\n",
            "    keras.layers.BatchNormalization(),\n",
            "\n",
            "--- Chunk 13298 ---\n",
            "keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2, padding=\"same\",\n",
            "                                 activation=\"tanh\")\n",
            "])\n",
            "\n",
            "--- Chunk 13299 ---\n",
            "])\n",
            "discriminator = keras.models.Sequential([\n",
            "    keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"same\",\n",
            "\n",
            "--- Chunk 13300 ---\n",
            "activation=keras.layers.LeakyReLU(0.2),\n",
            "                        input_shape=[28, 28, 1]),\n",
            "    keras.layers.Dropout(0.4),\n",
            "\n",
            "--- Chunk 13301 ---\n",
            "keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"same\",\n",
            "                        activation=keras.layers.LeakyReLU(0.2)),\n",
            "\n",
            "--- Chunk 13302 ---\n",
            "keras.layers.Dropout(0.4),\n",
            "    keras.layers.Flatten(),\n",
            "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
            "])\n",
            "\n",
            "--- Chunk 13303 ---\n",
            "])\n",
            "gan = keras.models.Sequential([generator, discriminator])\n",
            "\n",
            "--- Chunk 13304 ---\n",
            "The generator takes codings of size 100, and it projects them to 6272 dimensions (7 *\n",
            "\n",
            "--- Chunk 13305 ---\n",
            "7 * 128), and reshapes the result to get a 7 × 7 × 128 tensor. This tensor is batch nor‐\n",
            "\n",
            "--- Chunk 13306 ---\n",
            "malized and fed to a transposed convolutional layer with a stride of 2, which upsam‐\n",
            "\n",
            "--- Chunk 13307 ---\n",
            "ples it from 7 × 7 to 14 × 14 and reduces its depth from 128 to 64. The result is batch\n",
            "\n",
            "--- Chunk 13308 ---\n",
            "normalized again and fed to another transposed convolutional layer with a stride of 2,\n",
            "\n",
            "--- Chunk 13309 ---\n",
            "which upsamples it from 14 × 14 to 28 × 28 and reduces the depth from 64 to 1. This\n",
            "\n",
            "--- Chunk 13310 ---\n",
            "layer uses the tanh activation function, so the outputs will range from –1 to 1. For this\n",
            "\n",
            "--- Chunk 13311 ---\n",
            "reason, before training the GAN, we need to rescale the training set to that same\n",
            "range. We also need to reshape it to add the channel dimension:\n",
            "\n",
            "--- Chunk 13312 ---\n",
            "X_train = X_train.reshape(-1, 28, 28, 1) * 2. - 1. # reshape and rescale\n",
            "\n",
            "--- Chunk 13313 ---\n",
            "The discriminator looks much like a regular CNN for binary classification, except\n",
            "\n",
            "--- Chunk 13314 ---\n",
            "instead of using max pooling layers to downsample the image, we use strided convo‐\n",
            "\n",
            "--- Chunk 13315 ---\n",
            "lutions (strides=2). Also note that we use the leaky ReLU activation function.\n",
            "\n",
            "--- Chunk 13316 ---\n",
            "Overall, we respected the DCGAN guidelines, except we replaced the BatchNormali\n",
            "\n",
            "--- Chunk 13317 ---\n",
            "zation layers in the discriminator with Dropout layers (otherwise training was unsta‐\n",
            "\n",
            "--- Chunk 13318 ---\n",
            "ble in this case) and we replaced ReLU with SELU in the generator. Feel free to tweak\n",
            "\n",
            "--- Chunk 13319 ---\n",
            "this architecture: you will see how sensitive it is to the hyperparameters (especially\n",
            "the relative learning rates of the two networks).\n",
            "\n",
            "--- Chunk 13320 ---\n",
            "Lastly, to build the dataset, then compile and train this model, we use the exact same\n",
            "\n",
            "--- Chunk 13321 ---\n",
            "code as earlier. After 50 epochs of training, the generator produces images like those\n",
            "\n",
            "--- Chunk 13322 ---\n",
            "Generative Adversarial Networks | 599\n",
            "\n",
            "\n",
            "\n",
            "shown in Figure 17-17. It’s still not perfect, but many of these images are pretty\n",
            "convincing.\n",
            "\n",
            "--- Chunk 13323 ---\n",
            "Figure 17-17. Images generated by the DCGAN after 50 epochs of training\n",
            "\n",
            "--- Chunk 13324 ---\n",
            "If you scale up this architecture and train it on a large dataset of faces, you can get\n",
            "\n",
            "--- Chunk 13325 ---\n",
            "fairly realistic images. In fact, DCGANs can learn quite meaningful latent representa‐\n",
            "\n",
            "--- Chunk 13326 ---\n",
            "tions, as you can see in Figure 17-18: many images were generated, and nine of them\n",
            "\n",
            "--- Chunk 13327 ---\n",
            "were picked manually (top left), including three representing men with glasses, three\n",
            "\n",
            "--- Chunk 13328 ---\n",
            "men without glasses, and three women without glasses. For each of these categories,\n",
            "\n",
            "--- Chunk 13329 ---\n",
            "the codings that were used to generate the images were averaged, and an image was\n",
            "\n",
            "--- Chunk 13330 ---\n",
            "generated based on the resulting mean codings (lower left). In short, each of the three\n",
            "\n",
            "--- Chunk 13331 ---\n",
            "lower-left images represents the mean of the three images located above it. But this is\n",
            "\n",
            "--- Chunk 13332 ---\n",
            "not a simple mean computed at the pixel level (this would result in three overlapping\n",
            "\n",
            "--- Chunk 13333 ---\n",
            "faces), it is a mean computed in the latent space, so the images still look like normal\n",
            "\n",
            "--- Chunk 13334 ---\n",
            "faces. Amazingly, if you compute men with glasses, minus men without glasses, plus\n",
            "\n",
            "--- Chunk 13335 ---\n",
            "women without glasses—where each term corresponds to one of the mean codings—\n",
            "\n",
            "--- Chunk 13336 ---\n",
            "and you generate the image that corresponds to this coding, you get the image at the\n",
            "\n",
            "--- Chunk 13337 ---\n",
            "center of the 3 × 3 grid of faces on the right: a woman with glasses! The eight other\n",
            "\n",
            "--- Chunk 13338 ---\n",
            "images around it were generated based on the same vector plus a bit of noise, to illus‐\n",
            "\n",
            "--- Chunk 13339 ---\n",
            "trate the semantic interpolation capabilities of DCGANs. Being able to do arithmetic\n",
            "on faces feels like science fiction!\n",
            "\n",
            "--- Chunk 13340 ---\n",
            "600 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 13341 ---\n",
            "Figure 17-18. Vector arithmetic for visual concepts (part of figure 7 from the DCGAN\n",
            "paper)14\n",
            "\n",
            "--- Chunk 13342 ---\n",
            "If you add each image’s class as an extra input to both the generator\n",
            "and the discriminator, they will both learn what each class looks\n",
            "\n",
            "--- Chunk 13343 ---\n",
            "like, and thus you will be able to control the class of each image\n",
            "produced by the generator. This is called a conditional GAN15\n",
            "\n",
            "--- Chunk 13344 ---\n",
            "(CGAN).\n",
            "\n",
            "--- Chunk 13345 ---\n",
            "DCGANs aren’t perfect, though. For example, when you try to generate very large\n",
            "\n",
            "--- Chunk 13346 ---\n",
            "images using DCGANs, you often end up with locally convincing features but overall\n",
            "\n",
            "--- Chunk 13347 ---\n",
            "inconsistencies (such as shirts with one sleeve much longer than the other). How can\n",
            "you fix this?\n",
            "\n",
            "--- Chunk 13348 ---\n",
            "Progressive Growing of GANs\n",
            "An important technique was proposed in a 2018 paper16 by Nvidia researchers Tero\n",
            "\n",
            "--- Chunk 13349 ---\n",
            "Karras et al.: they suggested generating small images at the beginning of training,\n",
            "\n",
            "--- Chunk 13350 ---\n",
            "then gradually adding convolutional layers to both the generator and the discrimina‐\n",
            "\n",
            "--- Chunk 13351 ---\n",
            "tor to produce larger and larger images (4 × 4, 8 × 8, 16 × 16, …, 512 × 512, 1,024 ×\n",
            "\n",
            "--- Chunk 13352 ---\n",
            "1,024). This approach resembles greedy layer-wise training of stacked autoencoders.\n",
            "\n",
            "--- Chunk 13353 ---\n",
            "14 Reproduced with the kind authorization of the authors.\n",
            "\n",
            "--- Chunk 13354 ---\n",
            "15 Mehdi Mirza and Simon Osindero, “Conditional Generative Adversarial Nets,” arXiv preprint arXiv:\n",
            "\n",
            "--- Chunk 13355 ---\n",
            "1411.1784 (2014).\n",
            "16 Tero Karras et al., “Progressive Growing of GANs for Improved Quality, Stability, and Variation,” Proceedings\n",
            "\n",
            "--- Chunk 13356 ---\n",
            "of the International Conference on Learning Representations (2018).\n",
            "\n",
            "Generative Adversarial Networks | 601\n",
            "\n",
            "--- Chunk 13357 ---\n",
            "The extra layers get added at the end of the generator and at the beginning of the dis‐\n",
            "criminator, and previously trained layers remain trainable.\n",
            "\n",
            "--- Chunk 13358 ---\n",
            "For example, when growing the generator’s outputs from 4 × 4 to 8 × 8 (see\n",
            "\n",
            "--- Chunk 13359 ---\n",
            "Figure 17-19), an upsampling layer (using nearest neighbor filtering) is added to the\n",
            "\n",
            "--- Chunk 13360 ---\n",
            "existing convolutional layer, so it outputs 8 × 8 feature maps, which are then fed to\n",
            "\n",
            "--- Chunk 13361 ---\n",
            "the new convolutional layer (which uses \"same\" padding and strides of 1, so its out‐\n",
            "\n",
            "--- Chunk 13362 ---\n",
            "puts are also 8 × 8). This new layer is followed by a new output convolutional layer:\n",
            "\n",
            "--- Chunk 13363 ---\n",
            "this is a regular convolutional layer with kernel size 1 that projects the outputs down\n",
            "\n",
            "--- Chunk 13364 ---\n",
            "to the desired number of color channels (e.g., 3). To avoid breaking the trained\n",
            "\n",
            "--- Chunk 13365 ---\n",
            "weights of the first convolutional layer when the new convolutional layer is added, the\n",
            "\n",
            "--- Chunk 13366 ---\n",
            "final output is a weighted sum of the original output layer (which now outputs 8 × 8\n",
            "\n",
            "--- Chunk 13367 ---\n",
            "feature maps) and the new output layer. The weight of the new outputs is α, while the\n",
            "\n",
            "--- Chunk 13368 ---\n",
            "weight of the original outputs is 1 – α, and α is slowly increased from 0 to 1. In other\n",
            "\n",
            "--- Chunk 13369 ---\n",
            "words, the new convolutional layers (represented with dashed lines in Figure 17-19)\n",
            "\n",
            "--- Chunk 13370 ---\n",
            "are gradually faded in, while the original output layer is gradually faded out. A similar\n",
            "\n",
            "--- Chunk 13371 ---\n",
            "fade-in/fade-out technique is used when a new convolutional layer is added to the\n",
            "\n",
            "--- Chunk 13372 ---\n",
            "discriminator (followed by an average pooling layer for downsampling).\n",
            "\n",
            "--- Chunk 13373 ---\n",
            "Figure 17-19. Progressively growing GAN: a GAN generator outputs 4 × 4 color images\n",
            "(left); we extend it to output 8 × 8 images (right)\n",
            "\n",
            "--- Chunk 13374 ---\n",
            "602 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 13375 ---\n",
            "The paper also introduced several other techniques aimed at increasing the diversity\n",
            "\n",
            "--- Chunk 13376 ---\n",
            "of the outputs (to avoid mode collapse) and making training more stable:\n",
            "Minibatch standard deviation layer\n",
            "\n",
            "--- Chunk 13377 ---\n",
            "Added near the end of the discriminator. For each position in the inputs, it com‐\n",
            "\n",
            "--- Chunk 13378 ---\n",
            "putes the standard deviation across all channels and all instances in the batch\n",
            "\n",
            "--- Chunk 13379 ---\n",
            "(S = tf.math.reduce_std(inputs, axis=[0, -1])). These standard deviations\n",
            "are then averaged across all points to get a single value (v = tf.reduce_\n",
            "\n",
            "--- Chunk 13380 ---\n",
            "mean(S)). Finally, an extra feature map is added to each instance in the batch and\n",
            "\n",
            "--- Chunk 13381 ---\n",
            "filled with the computed value (tf.concat([inputs, tf.fill([batch_size,\n",
            "height, width, 1], v)], axis=-1)). How does this help? Well, if the genera‐\n",
            "\n",
            "--- Chunk 13382 ---\n",
            "tor produces images with little variety, then there will be a small standard devia‐\n",
            "\n",
            "--- Chunk 13383 ---\n",
            "tion across feature maps in the discriminator. Thanks to this layer, the\n",
            "\n",
            "--- Chunk 13384 ---\n",
            "discriminator will have easy access to this statistic, making it less likely to be\n",
            "\n",
            "--- Chunk 13385 ---\n",
            "fooled by a generator that produces too little diversity. This will encourage the\n",
            "\n",
            "--- Chunk 13386 ---\n",
            "generator to produce more diverse outputs, reducing the risk of mode collapse.\n",
            "\n",
            "--- Chunk 13387 ---\n",
            "Equalized learning rate\n",
            "Initializes all weights using a simple Gaussian distribution with mean 0 and stan‐\n",
            "\n",
            "--- Chunk 13388 ---\n",
            "dard deviation 1 rather than using He initialization. However, the weights are\n",
            "\n",
            "--- Chunk 13389 ---\n",
            "scaled down at runtime (i.e., every time the layer is executed) by the same factor\n",
            "\n",
            "--- Chunk 13390 ---\n",
            "as in He initialization: they are divided by 2/ninputs, where ninputs is the number\n",
            "\n",
            "--- Chunk 13391 ---\n",
            "of inputs to the layer. The paper demonstrated that this technique significantly\n",
            "\n",
            "--- Chunk 13392 ---\n",
            "improved the GAN’s performance when using RMSProp, Adam, or other adap‐\n",
            "\n",
            "--- Chunk 13393 ---\n",
            "tive gradient optimizers. Indeed, these optimizers normalize the gradient updates\n",
            "\n",
            "--- Chunk 13394 ---\n",
            "by their estimated standard deviation (see Chapter 11), so parameters that have a\n",
            "\n",
            "--- Chunk 13395 ---\n",
            "larger dynamic range17 will take longer to train, while parameters with a small\n",
            "\n",
            "--- Chunk 13396 ---\n",
            "dynamic range may be updated too quickly, leading to instabilities. By rescaling\n",
            "\n",
            "--- Chunk 13397 ---\n",
            "the weights as part of the model itself rather than just rescaling them upon initi‐\n",
            "\n",
            "--- Chunk 13398 ---\n",
            "alization, this approach ensures that the dynamic range is the same for all param‐\n",
            "\n",
            "--- Chunk 13399 ---\n",
            "eters, throughout training, so they all learn at the same speed. This both speeds\n",
            "up and stabilizes training.\n",
            "\n",
            "--- Chunk 13400 ---\n",
            "Pixelwise normalization layer\n",
            "Added after each convolutional layer in the generator. It normalizes each activa‐\n",
            "\n",
            "--- Chunk 13401 ---\n",
            "tion based on all the activations in the same image and at the same location, but\n",
            "\n",
            "--- Chunk 13402 ---\n",
            "across all channels (dividing by the square root of the mean squared activation).\n",
            "\n",
            "--- Chunk 13403 ---\n",
            "In TensorFlow code, this is inputs / tf.sqrt(tf.reduce_mean(tf.square(X),\n",
            "axis=-1, keepdims=True) + 1e-8) (the smoothing term 1e-8 is needed to\n",
            "\n",
            "--- Chunk 13404 ---\n",
            "17 The dynamic range of a variable is the ratio between the highest and the lowest value it may take.\n",
            "\n",
            "Generative Adversarial Networks | 603\n",
            "\n",
            "--- Chunk 13405 ---\n",
            "avoid division by zero). This technique avoids explosions in the activations due\n",
            "\n",
            "--- Chunk 13406 ---\n",
            "to excessive competition between the generator and the discriminator.\n",
            "\n",
            "--- Chunk 13407 ---\n",
            "The combination of all these techniques allowed the authors to generate extremely\n",
            "\n",
            "--- Chunk 13408 ---\n",
            "convincing high-definition images of faces. But what exactly do we call “convincing”?\n",
            "\n",
            "--- Chunk 13409 ---\n",
            "Evaluation is one of the big challenges when working with GANs: although it is possi‐\n",
            "\n",
            "--- Chunk 13410 ---\n",
            "ble to automatically evaluate the diversity of the generated images, judging their qual‐\n",
            "\n",
            "--- Chunk 13411 ---\n",
            "ity is a much trickier and subjective task. One technique is to use human raters, but\n",
            "\n",
            "--- Chunk 13412 ---\n",
            "this is costly and time-consuming. So the authors proposed to measure the similarity\n",
            "\n",
            "--- Chunk 13413 ---\n",
            "between the local image structure of the generated images and the training images,\n",
            "\n",
            "--- Chunk 13414 ---\n",
            "considering every scale. This idea led them to another groundbreaking innovation:\n",
            "StyleGANs.\n",
            "\n",
            "--- Chunk 13415 ---\n",
            "StyleGANs\n",
            "The state of the art in high-resolution image generation was advanced once again by\n",
            "\n",
            "--- Chunk 13416 ---\n",
            "the same Nvidia team in a 2018 paper18 that introduced the popular StyleGAN archi‐\n",
            "\n",
            "--- Chunk 13417 ---\n",
            "tecture. The authors used style transfer techniques in the generator to ensure that the\n",
            "\n",
            "--- Chunk 13418 ---\n",
            "generated images have the same local structure as the training images, at every scale,\n",
            "\n",
            "--- Chunk 13419 ---\n",
            "greatly improving the quality of the generated images. The discriminator and the loss\n",
            "\n",
            "--- Chunk 13420 ---\n",
            "function were not modified, only the generator. Let’s take a look at the StyleGAN. It is\n",
            "composed of two networks (see Figure 17-20):\n",
            "Mapping network\n",
            "\n",
            "--- Chunk 13421 ---\n",
            "An eight-layer MLP that maps the latent representations z (i.e., the codings) to a\n",
            "\n",
            "--- Chunk 13422 ---\n",
            "vector w. This vector is then sent through multiple affine transformations (i.e.,\n",
            "\n",
            "--- Chunk 13423 ---\n",
            "Dense layers with no activation functions, represented by the “A” boxes in\n",
            "\n",
            "--- Chunk 13424 ---\n",
            "Figure 17-20), which produces multiple vectors. These vectors control the style of\n",
            "\n",
            "--- Chunk 13425 ---\n",
            "the generated image at different levels, from fine-grained texture (e.g., hair color)\n",
            "\n",
            "--- Chunk 13426 ---\n",
            "to high-level features (e.g., adult or child). In short, the mapping network maps\n",
            "the codings to multiple style vectors.\n",
            "\n",
            "--- Chunk 13427 ---\n",
            "Synthesis network\n",
            "Responsible for generating the images. It has a constant learned input (to be\n",
            "\n",
            "--- Chunk 13428 ---\n",
            "clear, this input will be constant after training, but during training it keeps getting\n",
            "\n",
            "--- Chunk 13429 ---\n",
            "tweaked by backpropagation). It processes this input through multiple convolu‐\n",
            "\n",
            "--- Chunk 13430 ---\n",
            "tional and upsampling layers, as earlier, but there are two twists: first, some noise\n",
            "\n",
            "--- Chunk 13431 ---\n",
            "is added to the input and to all the outputs of the convolutional layers (before the\n",
            "\n",
            "--- Chunk 13432 ---\n",
            "activation function). Second, each noise layer is followed by an Adaptive Instance\n",
            "\n",
            "--- Chunk 13433 ---\n",
            "Normalization (AdaIN) layer: it standardizes each feature map independently (by\n",
            "\n",
            "--- Chunk 13434 ---\n",
            "18 Tero Karras et al., “A Style-Based Generator Architecture for Generative Adversarial Networks,” arXiv pre‐\n",
            "print arXiv:1812.04948 (2018).\n",
            "\n",
            "--- Chunk 13435 ---\n",
            "604 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 13436 ---\n",
            "subtracting the feature map’s mean and dividing by its standard deviation), then\n",
            "\n",
            "--- Chunk 13437 ---\n",
            "it uses the style vector to determine the scale and offset of each feature map (the\n",
            "\n",
            "--- Chunk 13438 ---\n",
            "style vector contains one scale and one bias term for each feature map).\n",
            "\n",
            "--- Chunk 13439 ---\n",
            "Figure 17-20. StyleGAN’s generator architecture (part of figure 1 from the StyleGAN\n",
            "paper)19\n",
            "\n",
            "--- Chunk 13440 ---\n",
            "The idea of adding noise independently from the codings is very important. Some\n",
            "\n",
            "--- Chunk 13441 ---\n",
            "parts of an image are quite random, such as the exact position of each freckle or hair.\n",
            "\n",
            "--- Chunk 13442 ---\n",
            "In earlier GANs, this randomness had to either come from the codings or be some\n",
            "\n",
            "--- Chunk 13443 ---\n",
            "pseudorandom noise produced by the generator itself. If it came from the codings, it\n",
            "\n",
            "--- Chunk 13444 ---\n",
            "meant that the generator had to dedicate a significant portion of the codings’ repre‐\n",
            "\n",
            "--- Chunk 13445 ---\n",
            "sentational power to store noise: this is quite wasteful. Moreover, the noise had to be\n",
            "\n",
            "--- Chunk 13446 ---\n",
            "19 Reproduced with the kind authorization of the authors.\n",
            "\n",
            "Generative Adversarial Networks | 605\n",
            "\n",
            "--- Chunk 13447 ---\n",
            "able to flow through the network and reach the final layers of the generator: this\n",
            "\n",
            "--- Chunk 13448 ---\n",
            "seems like an unnecessary constraint that probably slowed down training. And\n",
            "\n",
            "--- Chunk 13449 ---\n",
            "finally, some visual artifacts may appear because the same noise was used at different\n",
            "\n",
            "--- Chunk 13450 ---\n",
            "levels. If instead the generator tried to produce its own pseudorandom noise, this\n",
            "\n",
            "--- Chunk 13451 ---\n",
            "noise might not look very convincing, leading to more visual artifacts. Plus, part of\n",
            "\n",
            "--- Chunk 13452 ---\n",
            "the generator’s weights would be dedicated to generating pseudorandom noise, which\n",
            "\n",
            "--- Chunk 13453 ---\n",
            "again seems wasteful. By adding extra noise inputs, all these issues are avoided; the\n",
            "\n",
            "--- Chunk 13454 ---\n",
            "GAN is able to use the provided noise to add the right amount of stochasticity to each\n",
            "part of the image.\n",
            "\n",
            "--- Chunk 13455 ---\n",
            "part of the image.\n",
            "The added noise is different for each level. Each noise input consists of a single fea‐\n",
            "\n",
            "--- Chunk 13456 ---\n",
            "ture map full of Gaussian noise, which is broadcast to all feature maps (of the given\n",
            "\n",
            "--- Chunk 13457 ---\n",
            "level) and scaled using learned per-feature scaling factors (this is represented by the\n",
            "“B” boxes in Figure 17-20) before it is added.\n",
            "\n",
            "--- Chunk 13458 ---\n",
            "Finally, StyleGAN uses a technique called mixing regularization (or style mixing),\n",
            "\n",
            "--- Chunk 13459 ---\n",
            "where a percentage of the generated images are produced using two different codings.\n",
            "\n",
            "--- Chunk 13460 ---\n",
            "Specifically, the codings c1 and c2 are sent through the mapping network, giving two\n",
            "\n",
            "--- Chunk 13461 ---\n",
            "style vectors w1 and w2. Then the synthesis network generates an image based on the\n",
            "\n",
            "--- Chunk 13462 ---\n",
            "styles w1 for the first levels and the styles w2 for the remaining levels. The cutoff level\n",
            "\n",
            "--- Chunk 13463 ---\n",
            "is picked randomly. This prevents the network from assuming that styles at adjacent\n",
            "\n",
            "--- Chunk 13464 ---\n",
            "levels are correlated, which in turn encourages locality in the GAN, meaning that\n",
            "\n",
            "--- Chunk 13465 ---\n",
            "each style vector only affects a limited number of traits in the generated image.\n",
            "\n",
            "--- Chunk 13466 ---\n",
            "There is such a wide variety of GANs out there that it would require a whole book to\n",
            "\n",
            "--- Chunk 13467 ---\n",
            "cover them all. Hopefully this introduction has given you the main ideas, and most\n",
            "\n",
            "--- Chunk 13468 ---\n",
            "importantly the desire to learn more. If you’re struggling with a mathematical con‐\n",
            "\n",
            "--- Chunk 13469 ---\n",
            "cept, there are probably blog posts out there that will help you understand it better.\n",
            "\n",
            "--- Chunk 13470 ---\n",
            "Then go ahead and implement your own GAN, and do not get discouraged if it has\n",
            "\n",
            "--- Chunk 13471 ---\n",
            "trouble learning at first: unfortunately, this is normal, and it will require quite a bit of\n",
            "\n",
            "--- Chunk 13472 ---\n",
            "patience before it works, but the result is worth it. If you’re struggling with an imple‐\n",
            "\n",
            "--- Chunk 13473 ---\n",
            "mentation detail, there are plenty of Keras or TensorFlow implementations that you\n",
            "\n",
            "--- Chunk 13474 ---\n",
            "can look at. In fact, if all you want is to get some amazing results quickly, then you\n",
            "\n",
            "--- Chunk 13475 ---\n",
            "can just use a pretrained model (e.g., there are pretrained StyleGAN models available\n",
            "for Keras).\n",
            "\n",
            "--- Chunk 13476 ---\n",
            "for Keras).\n",
            "In the next chapter we will move to an entirely different branch of Deep Learning:\n",
            "Deep Reinforcement Learning.\n",
            "\n",
            "--- Chunk 13477 ---\n",
            "606 | Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 13478 ---\n",
            "Exercises\n",
            "1. What are the main tasks that autoencoders are used for?\n",
            "\n",
            "--- Chunk 13479 ---\n",
            "2. Suppose you want to train a classifier, and you have plenty of unlabeled training\n",
            "\n",
            "--- Chunk 13480 ---\n",
            "data but only a few thousand labeled instances. How can autoencoders help?\n",
            "How would you proceed?\n",
            "\n",
            "--- Chunk 13481 ---\n",
            "3. If an autoencoder perfectly reconstructs the inputs, is it necessarily a good\n",
            "\n",
            "--- Chunk 13482 ---\n",
            "autoencoder? How can you evaluate the performance of an autoencoder?\n",
            "\n",
            "--- Chunk 13483 ---\n",
            "4. What are undercomplete and overcomplete autoencoders? What is the main risk\n",
            "\n",
            "--- Chunk 13484 ---\n",
            "of an excessively undercomplete autoencoder? What about the main risk of an\n",
            "overcomplete autoencoder?\n",
            "\n",
            "--- Chunk 13485 ---\n",
            "5. How do you tie weights in a stacked autoencoder? What is the point of doing so?\n",
            "\n",
            "--- Chunk 13486 ---\n",
            "6. What is a generative model? Can you name a type of generative autoencoder?\n",
            "7. What is a GAN? Can you name a few tasks where GANs can shine?\n",
            "\n",
            "--- Chunk 13487 ---\n",
            "8. What are the main difficulties when training GANs?\n",
            "9. Try using a denoising autoencoder to pretrain an image classifier. You can use\n",
            "\n",
            "--- Chunk 13488 ---\n",
            "MNIST (the simplest option), or a more complex image dataset such as CIFAR10\n",
            "\n",
            "--- Chunk 13489 ---\n",
            "if you want a bigger challenge. Regardless of the dataset you’re using, follow these\n",
            "steps:\n",
            "\n",
            "--- Chunk 13490 ---\n",
            "steps:\n",
            "• Split the dataset into a training set and a test set. Train a deep denoising\n",
            "\n",
            "--- Chunk 13491 ---\n",
            "autoencoder on the full training set.\n",
            "• Check that the images are fairly well reconstructed. Visualize the images that\n",
            "\n",
            "--- Chunk 13492 ---\n",
            "most activate each neuron in the coding layer.\n",
            "• Build a classification DNN, reusing the lower layers of the autoencoder. Train\n",
            "\n",
            "--- Chunk 13493 ---\n",
            "it using only 500 images from the training set. Does it perform better with or\n",
            "without pretraining?\n",
            "\n",
            "--- Chunk 13494 ---\n",
            "10. Train a variational autoencoder on the image dataset of your choice, and use it to\n",
            "\n",
            "--- Chunk 13495 ---\n",
            "generate images. Alternatively, you can try to find an unlabeled dataset that you\n",
            "are interested in and see if you can generate new samples.\n",
            "\n",
            "--- Chunk 13496 ---\n",
            "11. Train a DCGAN to tackle the image dataset of your choice, and use it to generate\n",
            "\n",
            "--- Chunk 13497 ---\n",
            "images. Add experience replay and see if this helps. Turn it into a conditional\n",
            "GAN where you can control the generated class.\n",
            "\n",
            "--- Chunk 13498 ---\n",
            "Solutions to these exercises are available in Appendix A.\n",
            "\n",
            "Exercises | 607\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER 18\n",
            "Reinforcement Learning\n",
            "\n",
            "--- Chunk 13499 ---\n",
            "Reinforcement Learning (RL) is one of the most exciting fields of Machine Learning\n",
            "\n",
            "--- Chunk 13500 ---\n",
            "today, and also one of the oldest. It has been around since the 1950s, producing many\n",
            "\n",
            "--- Chunk 13501 ---\n",
            "interesting applications over the years,1 particularly in games (e.g., TD-Gammon, a\n",
            "\n",
            "--- Chunk 13502 ---\n",
            "Backgammon-playing program) and in machine control, but seldom making the\n",
            "\n",
            "--- Chunk 13503 ---\n",
            "headline news. But a revolution took place in 2013, when researchers from a British\n",
            "\n",
            "--- Chunk 13504 ---\n",
            "startup called DeepMind demonstrated a system that could learn to play just about\n",
            "\n",
            "--- Chunk 13505 ---\n",
            "any Atari game from scratch,2 eventually outperforming humans3 in most of them,\n",
            "\n",
            "--- Chunk 13506 ---\n",
            "using only raw pixels as inputs and without any prior knowledge of the rules of the\n",
            "\n",
            "--- Chunk 13507 ---\n",
            "games.4 This was the first of a series of amazing feats, culminating in March 2016\n",
            "\n",
            "--- Chunk 13508 ---\n",
            "with the victory of their system AlphaGo against Lee Sedol, a legendary professional\n",
            "\n",
            "--- Chunk 13509 ---\n",
            "player of the game of Go, and in May 2017 against Ke Jie, the world champion. No\n",
            "\n",
            "--- Chunk 13510 ---\n",
            "program had ever come close to beating a master of this game, let alone the world\n",
            "\n",
            "--- Chunk 13511 ---\n",
            "champion. Today the whole field of RL is boiling with new ideas, with a wide range of\n",
            "\n",
            "--- Chunk 13512 ---\n",
            "applications. DeepMind was bought by Google for over $500 million in 2014.\n",
            "\n",
            "--- Chunk 13513 ---\n",
            "So how did DeepMind achieve all this? With hindsight it seems rather simple: they\n",
            "\n",
            "--- Chunk 13514 ---\n",
            "applied the power of Deep Learning to the field of Reinforcement Learning, and it\n",
            "\n",
            "--- Chunk 13515 ---\n",
            "worked beyond their wildest dreams. In this chapter we will first explain what\n",
            "\n",
            "--- Chunk 13516 ---\n",
            "1 For more details, be sure to check out Richard Sutton and Andrew Barto’s book on RL, Reinforcement Learn‐\n",
            "ing: An Introduction (MIT Press).\n",
            "\n",
            "--- Chunk 13517 ---\n",
            "2 Volodymyr Mnih et al., “Playing Atari with Deep Reinforcement Learning,” arXiv preprint arXiv:1312.5602\n",
            "(2013).\n",
            "\n",
            "--- Chunk 13518 ---\n",
            "3 Volodymyr Mnih et al., “Human-Level Control Through Deep Reinforcement Learning,” Nature 518 (2015):\n",
            "529–533.\n",
            "\n",
            "--- Chunk 13519 ---\n",
            "4 Check out the videos of DeepMind’s system learning to play Space Invaders, Breakout, and other video games\n",
            "at https://homl.info/dqn3.\n",
            "\n",
            "609\n",
            "\n",
            "--- Chunk 13520 ---\n",
            "Reinforcement Learning is and what it’s good at, then present two of the most impor‐\n",
            "\n",
            "--- Chunk 13521 ---\n",
            "tant techniques in Deep Reinforcement Learning: policy gradients and deep Q-\n",
            "\n",
            "--- Chunk 13522 ---\n",
            "networks (DQNs), including a discussion of Markov decision processes (MDPs). We\n",
            "\n",
            "--- Chunk 13523 ---\n",
            "will use these techniques to train models to balance a pole on a moving cart; then I’ll\n",
            "\n",
            "--- Chunk 13524 ---\n",
            "introduce the TF-Agents library, which uses state-of-the-art algorithms that greatly\n",
            "\n",
            "--- Chunk 13525 ---\n",
            "simplify building powerful RL systems, and we will use the library to train an agent to\n",
            "\n",
            "--- Chunk 13526 ---\n",
            "play Breakout, the famous Atari game. I’ll close the chapter by taking a look at some\n",
            "of the latest advances in the field.\n",
            "\n",
            "--- Chunk 13527 ---\n",
            "Learning to Optimize Rewards\n",
            "In Reinforcement Learning, a software agent makes observations and takes actions\n",
            "\n",
            "--- Chunk 13528 ---\n",
            "within an environment, and in return it receives rewards. Its objective is to learn to act\n",
            "\n",
            "--- Chunk 13529 ---\n",
            "in a way that will maximize its expected rewards over time. If you don’t mind a bit of\n",
            "\n",
            "--- Chunk 13530 ---\n",
            "anthropomorphism, you can think of positive rewards as pleasure, and negative\n",
            "\n",
            "--- Chunk 13531 ---\n",
            "rewards as pain (the term “reward” is a bit misleading in this case). In short, the agent\n",
            "\n",
            "--- Chunk 13532 ---\n",
            "acts in the environment and learns by trial and error to maximize its pleasure and\n",
            "minimize its pain.\n",
            "\n",
            "--- Chunk 13533 ---\n",
            "minimize its pain.\n",
            "This is quite a broad setting, which can apply to a wide variety of tasks. Here are a few\n",
            "examples (see Figure 18-1):\n",
            "\n",
            "--- Chunk 13534 ---\n",
            "a. The agent can be the program controlling a robot. In this case, the environment\n",
            "\n",
            "--- Chunk 13535 ---\n",
            "is the real world, the agent observes the environment through a set of sensors\n",
            "\n",
            "--- Chunk 13536 ---\n",
            "such as cameras and touch sensors, and its actions consist of sending signals to\n",
            "\n",
            "--- Chunk 13537 ---\n",
            "activate motors. It may be programmed to get positive rewards whenever it\n",
            "\n",
            "--- Chunk 13538 ---\n",
            "approaches the target destination, and negative rewards whenever it wastes time\n",
            "or goes in the wrong direction.\n",
            "\n",
            "--- Chunk 13539 ---\n",
            "b. The agent can be the program controlling Ms. Pac-Man. In this case, the environ‐\n",
            "\n",
            "--- Chunk 13540 ---\n",
            "ment is a simulation of the Atari game, the actions are the nine possible joystick\n",
            "\n",
            "--- Chunk 13541 ---\n",
            "positions (upper left, down, center, and so on), the observations are screenshots,\n",
            "and the rewards are just the game points.\n",
            "\n",
            "--- Chunk 13542 ---\n",
            "c. Similarly, the agent can be the program playing a board game such as Go.\n",
            "\n",
            "--- Chunk 13543 ---\n",
            "d. The agent does not have to control a physically (or virtually) moving thing. For\n",
            "\n",
            "--- Chunk 13544 ---\n",
            "example, it can be a smart thermostat, getting positive rewards whenever it is\n",
            "\n",
            "--- Chunk 13545 ---\n",
            "close to the target temperature and saves energy, and negative rewards when\n",
            "\n",
            "--- Chunk 13546 ---\n",
            "humans need to tweak the temperature, so the agent must learn to anticipate\n",
            "human needs.\n",
            "\n",
            "--- Chunk 13547 ---\n",
            "e. The agent can observe stock market prices and decide how much to buy or sell\n",
            "every second. Rewards are obviously the monetary gains and losses.\n",
            "\n",
            "--- Chunk 13548 ---\n",
            "610 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 13549 ---\n",
            "Figure 18-1. Reinforcement Learning examples: (a) robotics, (b) Ms. Pac-Man, (c) Go\n",
            "player, (d) thermostat, (e) automatic trader5\n",
            "\n",
            "--- Chunk 13550 ---\n",
            "Note that there may not be any positive rewards at all; for example, the agent may\n",
            "\n",
            "--- Chunk 13551 ---\n",
            "move around in a maze, getting a negative reward at every time step, so it had better\n",
            "\n",
            "--- Chunk 13552 ---\n",
            "find the exit as quickly as possible! There are many other examples of tasks to which\n",
            "\n",
            "--- Chunk 13553 ---\n",
            "Reinforcement Learning is well suited, such as self-driving cars, recommender sys‐\n",
            "\n",
            "--- Chunk 13554 ---\n",
            "tems, placing ads on a web page, or controlling where an image classification system\n",
            "should focus its attention.\n",
            "\n",
            "--- Chunk 13555 ---\n",
            "5 Image (a) is from NASA (public domain). (b) is a screenshot from the Ms. Pac-Man game, copyright Atari\n",
            "\n",
            "--- Chunk 13556 ---\n",
            "(fair use in this chapter). Images (c) and (d) are reproduced from Wikipedia. (c) was created by user Stever‐\n",
            "\n",
            "--- Chunk 13557 ---\n",
            "tigo and released under Creative Commons BY-SA 2.0. (d) is in the public domain. (e) was reproduced from\n",
            "\n",
            "--- Chunk 13558 ---\n",
            "Pixabay, released under Creative Commons CC0.\n",
            "\n",
            "--- Chunk 13559 ---\n",
            "Learning to Optimize Rewards | 611\n",
            "\n",
            "--- Chunk 13560 ---\n",
            "Policy Search\n",
            "The algorithm a software agent uses to determine its actions is called its policy. The\n",
            "\n",
            "--- Chunk 13561 ---\n",
            "policy could be a neural network taking observations as inputs and outputting the\n",
            "action to take (see Figure 18-2).\n",
            "\n",
            "--- Chunk 13562 ---\n",
            "Figure 18-2. Reinforcement Learning using a neural network policy\n",
            "\n",
            "--- Chunk 13563 ---\n",
            "The policy can be any algorithm you can think of, and it does not have to be deter‐\n",
            "\n",
            "--- Chunk 13564 ---\n",
            "ministic. In fact, in some cases it does not even have to observe the environment! For\n",
            "\n",
            "--- Chunk 13565 ---\n",
            "example, consider a robotic vacuum cleaner whose reward is the amount of dust it\n",
            "\n",
            "--- Chunk 13566 ---\n",
            "picks up in 30 minutes. Its policy could be to move forward with some probability p\n",
            "\n",
            "--- Chunk 13567 ---\n",
            "every second, or randomly rotate left or right with probability 1 – p. The rotation\n",
            "\n",
            "--- Chunk 13568 ---\n",
            "angle would be a random angle between –r and +r. Since this policy involves some\n",
            "\n",
            "--- Chunk 13569 ---\n",
            "randomness, it is called a stochastic policy. The robot will have an erratic trajectory,\n",
            "\n",
            "--- Chunk 13570 ---\n",
            "which guarantees that it will eventually get to any place it can reach and pick up all\n",
            "\n",
            "--- Chunk 13571 ---\n",
            "the dust. The question is, how much dust will it pick up in 30 minutes?\n",
            "\n",
            "--- Chunk 13572 ---\n",
            "How would you train such a robot? There are just two policy parameters you can\n",
            "\n",
            "--- Chunk 13573 ---\n",
            "tweak: the probability p and the angle range r. One possible learning algorithm could\n",
            "\n",
            "--- Chunk 13574 ---\n",
            "be to try out many different values for these parameters, and pick the combination\n",
            "\n",
            "--- Chunk 13575 ---\n",
            "that performs best (see Figure 18-3). This is an example of policy search, in this case\n",
            "\n",
            "--- Chunk 13576 ---\n",
            "using a brute force approach. When the policy space is too large (which is generally\n",
            "\n",
            "--- Chunk 13577 ---\n",
            "the case), finding a good set of parameters this way is like searching for a needle in a\n",
            "gigantic haystack.\n",
            "\n",
            "--- Chunk 13578 ---\n",
            "gigantic haystack.\n",
            "Another way to explore the policy space is to use genetic algorithms. For example, you\n",
            "\n",
            "--- Chunk 13579 ---\n",
            "could randomly create a first generation of 100 policies and try them out, then “kill”\n",
            "\n",
            "--- Chunk 13580 ---\n",
            "the 80 worst policies6 and make the 20 survivors produce 4 offspring each. An\n",
            "\n",
            "--- Chunk 13581 ---\n",
            "6 It is often better to give the poor performers a slight chance of survival, to preserve some diversity in the “gene\n",
            "pool.”\n",
            "\n",
            "--- Chunk 13582 ---\n",
            "612 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 13583 ---\n",
            "offspring is a copy of its parent7 plus some random variation. The surviving policies\n",
            "\n",
            "--- Chunk 13584 ---\n",
            "plus their offspring together constitute the second generation. You can continue to\n",
            "\n",
            "--- Chunk 13585 ---\n",
            "iterate through generations this way until you find a good policy.8\n",
            "\n",
            "--- Chunk 13586 ---\n",
            "Figure 18-3. Four points in policy space (left) and the agent’s corresponding behavior\n",
            "(right)\n",
            "\n",
            "--- Chunk 13587 ---\n",
            "Yet another approach is to use optimization techniques, by evaluating the gradients of\n",
            "\n",
            "--- Chunk 13588 ---\n",
            "the rewards with regard to the policy parameters, then tweaking these parameters by\n",
            "\n",
            "--- Chunk 13589 ---\n",
            "following the gradients toward higher rewards.9 We will discuss this approach, is\n",
            "\n",
            "--- Chunk 13590 ---\n",
            "called policy gradients (PG), in more detail later in this chapter. Going back to the\n",
            "\n",
            "--- Chunk 13591 ---\n",
            "vacuum cleaner robot, you could slightly increase p and evaluate whether doing so\n",
            "\n",
            "--- Chunk 13592 ---\n",
            "increases the amount of dust picked up by the robot in 30 minutes; if it does, then\n",
            "\n",
            "--- Chunk 13593 ---\n",
            "increase p some more, or else reduce p. We will implement a popular PG algorithm\n",
            "\n",
            "--- Chunk 13594 ---\n",
            "using TensorFlow, but before we do, we need to create an environment for the agent\n",
            "to live in—so it’s time to introduce OpenAI Gym.\n",
            "\n",
            "--- Chunk 13595 ---\n",
            "Introduction to OpenAI Gym\n",
            "One of the challenges of Reinforcement Learning is that in order to train an agent,\n",
            "\n",
            "--- Chunk 13596 ---\n",
            "you first need to have a working environment. If you want to program an agent that\n",
            "\n",
            "--- Chunk 13597 ---\n",
            "7 If there is a single parent, this is called asexual reproduction. With two (or more) parents, it is called sexual\n",
            "\n",
            "--- Chunk 13598 ---\n",
            "reproduction. An offspring’s genome (in this case a set of policy parameters) is randomly composed of parts of\n",
            "its parents’ genomes.\n",
            "\n",
            "--- Chunk 13599 ---\n",
            "8 One interesting example of a genetic algorithm used for Reinforcement Learning is the NeuroEvolution of\n",
            "Augmenting Topologies (NEAT) algorithm.\n",
            "\n",
            "--- Chunk 13600 ---\n",
            "9 This is called Gradient Ascent. It’s just like Gradient Descent but in the opposite direction: maximizing instead\n",
            "of minimizing.\n",
            "\n",
            "--- Chunk 13601 ---\n",
            "Introduction to OpenAI Gym | 613\n",
            "\n",
            "--- Chunk 13602 ---\n",
            "will learn to play an Atari game, you will need an Atari game simulator. If you want to\n",
            "\n",
            "--- Chunk 13603 ---\n",
            "program a walking robot, then the environment is the real world, and you can\n",
            "\n",
            "--- Chunk 13604 ---\n",
            "directly train your robot in that environment, but this has its limits: if the robot falls\n",
            "\n",
            "--- Chunk 13605 ---\n",
            "off a cliff, you can’t just click Undo. You can’t speed up time either; adding more com‐\n",
            "\n",
            "--- Chunk 13606 ---\n",
            "puting power won’t make the robot move any faster. And it’s generally too expensive\n",
            "\n",
            "--- Chunk 13607 ---\n",
            "to train 1,000 robots in parallel. In short, training is hard and slow in the real world,\n",
            "\n",
            "--- Chunk 13608 ---\n",
            "so you generally need a simulated environment at least for bootstrap training. For\n",
            "\n",
            "--- Chunk 13609 ---\n",
            "example, you may use a library like PyBullet or MuJoCo for 3D physics simulation.\n",
            "\n",
            "--- Chunk 13610 ---\n",
            "OpenAI Gym10 is a toolkit that provides a wide variety of simulated environments\n",
            "\n",
            "--- Chunk 13611 ---\n",
            "(Atari games, board games, 2D and 3D physical simulations, and so on), so you can\n",
            "train agents, compare them, or develop new RL algorithms.\n",
            "\n",
            "--- Chunk 13612 ---\n",
            "Before installing the toolkit, if you created an isolated environment using virtualenv,\n",
            "you first need to activate it:\n",
            "\n",
            "--- Chunk 13613 ---\n",
            "$ cd $ML_PATH                # Your ML working directory (e.g., $HOME/ml)\n",
            "$ source my_env/bin/activate # on Linux or MacOS\n",
            "\n",
            "--- Chunk 13614 ---\n",
            "$ .\\my_env\\Scripts\\activate  # on Windows\n",
            "\n",
            "--- Chunk 13615 ---\n",
            "Next, install OpenAI Gym (if you are not using a virtual environment, you will need\n",
            "to add the --user option, or have administrator rights):\n",
            "\n",
            "--- Chunk 13616 ---\n",
            "$ python3 -m pip install -U gym\n",
            "\n",
            "--- Chunk 13617 ---\n",
            "Depending on your system, you may also need to install the Mesa OpenGL Utility\n",
            "\n",
            "--- Chunk 13618 ---\n",
            "(GLU) library (e.g., on Ubuntu 18.04 you need to run apt install libglu1-mesa).\n",
            "\n",
            "--- Chunk 13619 ---\n",
            "This library will be needed to render the first environment. Next, open up a Python\n",
            "\n",
            "--- Chunk 13620 ---\n",
            "shell or a Jupyter notebook and create an environment with make():\n",
            "\n",
            "--- Chunk 13621 ---\n",
            ">>> import gym\n",
            ">>> env = gym.make(\"CartPole-v1\")\n",
            ">>> obs = env.reset()\n",
            ">>> obs\n",
            "array([-0.01258566, -0.00156614,  0.04207708, -0.00180545])\n",
            "\n",
            "--- Chunk 13622 ---\n",
            "Here, we’ve created a CartPole environment. This is a 2D simulation in which a cart\n",
            "\n",
            "--- Chunk 13623 ---\n",
            "can be accelerated left or right in order to balance a pole placed on top of it (see\n",
            "\n",
            "--- Chunk 13624 ---\n",
            "Figure 18-4). You can get the list of all available environments by running\n",
            "\n",
            "--- Chunk 13625 ---\n",
            "gym.envs.registry.all(). After the environment is created, you must initialize it\n",
            "\n",
            "--- Chunk 13626 ---\n",
            "using the reset() method. This returns the first observation. Observations depend\n",
            "\n",
            "--- Chunk 13627 ---\n",
            "on the type of environment. For the CartPole environment, each observation is a 1D\n",
            "\n",
            "--- Chunk 13628 ---\n",
            "NumPy array containing four floats: these floats represent the cart’s horizontal\n",
            "\n",
            "--- Chunk 13629 ---\n",
            "10 OpenAI is an artificial intelligence research company, funded in part by Elon Musk. Its stated goal is to pro‐\n",
            "\n",
            "--- Chunk 13630 ---\n",
            "mote and develop friendly AIs that will benefit humanity (rather than exterminate it).\n",
            "\n",
            "--- Chunk 13631 ---\n",
            "614 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 13632 ---\n",
            "position (0.0 = center), its velocity (positive means right), the angle of the pole (0.0 =\n",
            "\n",
            "--- Chunk 13633 ---\n",
            "vertical), and its angular velocity (positive means clockwise).\n",
            "Now let’s display this environment by calling its render() method (see Figure 18-4).\n",
            "\n",
            "--- Chunk 13634 ---\n",
            "On Windows, this requires first installing an X Server, such as VcXsrv or Xming:\n",
            "\n",
            "--- Chunk 13635 ---\n",
            ">>> env.render()\n",
            "True\n",
            "\n",
            "Figure 18-4. The CartPole environment\n",
            "\n",
            "--- Chunk 13636 ---\n",
            "If you are using a headless server (i.e., without a screen), such as a\n",
            "virtual machine on the cloud, rendering will fail. The only way to\n",
            "\n",
            "--- Chunk 13637 ---\n",
            "avoid this is to use a fake X server such as Xvfb or Xdummy. For\n",
            "example, you can install Xvfb (apt install xvfb on Ubuntu or\n",
            "\n",
            "--- Chunk 13638 ---\n",
            "Debian) and start Python using the following command: xvfb-run\n",
            "-s \"-screen 0 1400x900x24\" python3. Alternatively, install Xvfb\n",
            "\n",
            "--- Chunk 13639 ---\n",
            "and the pyvirtualdisplay library (which wraps Xvfb) and run\n",
            "pyvirtualdisplay.Display(visible=0, size=(1400,\n",
            "\n",
            "--- Chunk 13640 ---\n",
            "900)).start() at the beginning of your program.\n",
            "\n",
            "--- Chunk 13641 ---\n",
            "If you want render() to return the rendered image as a NumPy array, you can set\n",
            "\n",
            "--- Chunk 13642 ---\n",
            "mode=\"rgb_array\" (oddly, this environment will render the environment to screen as\n",
            "well):\n",
            "\n",
            "--- Chunk 13643 ---\n",
            ">>> img = env.render(mode=\"rgb_array\")\n",
            ">>> img.shape  # height, width, channels (3 = Red, Green, Blue)\n",
            "(800, 1200, 3)\n",
            "\n",
            "--- Chunk 13644 ---\n",
            "Let’s ask the environment what actions are possible:\n",
            ">>> env.action_space\n",
            "Discrete(2)\n",
            "\n",
            "--- Chunk 13645 ---\n",
            "Discrete(2) means that the possible actions are integers 0 and 1, which represent\n",
            "\n",
            "--- Chunk 13646 ---\n",
            "accelerating left (0) or right (1). Other environments may have additional discrete\n",
            "\n",
            "--- Chunk 13647 ---\n",
            "Introduction to OpenAI Gym | 615\n",
            "\n",
            "--- Chunk 13648 ---\n",
            "actions, or other kinds of actions (e.g., continuous). Since the pole is leaning toward\n",
            "\n",
            "--- Chunk 13649 ---\n",
            "the right (obs[2] > 0), let’s accelerate the cart toward the right:\n",
            "\n",
            "--- Chunk 13650 ---\n",
            ">>> action = 1  # accelerate right\n",
            ">>> obs, reward, done, info = env.step(action)\n",
            ">>> obs\n",
            "\n",
            "--- Chunk 13651 ---\n",
            ">>> obs\n",
            "array([-0.01261699,  0.19292789,  0.04204097, -0.28092127])\n",
            ">>> reward\n",
            "1.0\n",
            ">>> done\n",
            "False\n",
            ">>> info\n",
            "{}\n",
            "\n",
            "--- Chunk 13652 ---\n",
            "The step() method executes the given action and returns four values:\n",
            "obs\n",
            "\n",
            "--- Chunk 13653 ---\n",
            "This is the new observation. The cart is now moving toward the right (obs[1] >\n",
            "\n",
            "--- Chunk 13654 ---\n",
            "0). The pole is still tilted toward the right (obs[2] > 0), but its angular velocity is\n",
            "\n",
            "--- Chunk 13655 ---\n",
            "now negative (obs[3] < 0), so it will likely be tilted toward the left after the next\n",
            "step.\n",
            "\n",
            "--- Chunk 13656 ---\n",
            "reward\n",
            "In this environment, you get a reward of 1.0 at every step, no matter what you do,\n",
            "\n",
            "--- Chunk 13657 ---\n",
            "so the goal is to keep the episode running as long as possible.\n",
            "\n",
            "--- Chunk 13658 ---\n",
            "done\n",
            "This value will be True when the episode is over. This will happen when the pole\n",
            "\n",
            "--- Chunk 13659 ---\n",
            "tilts too much, or goes off the screen, or after 200 steps (in this last case, you have\n",
            "\n",
            "--- Chunk 13660 ---\n",
            "won). After that, the environment must be reset before it can be used again.\n",
            "\n",
            "--- Chunk 13661 ---\n",
            "info\n",
            "This environment-specific dictionary can provide some extra information that\n",
            "\n",
            "--- Chunk 13662 ---\n",
            "you may find useful for debugging or for training. For example, in some games it\n",
            "may indicate how many lives the agent has.\n",
            "\n",
            "--- Chunk 13663 ---\n",
            "Once you have finished using an environment, you should call its\n",
            "close() method to free resources.\n",
            "\n",
            "616 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 13664 ---\n",
            "Let’s hardcode a simple policy that accelerates left when the pole is leaning toward the\n",
            "\n",
            "--- Chunk 13665 ---\n",
            "left and accelerates right when the pole is leaning toward the right. We will run this\n",
            "policy to see the average rewards it gets over 500 episodes:\n",
            "\n",
            "--- Chunk 13666 ---\n",
            "def basic_policy(obs):\n",
            "    angle = obs[2]\n",
            "    return 0 if angle < 0 else 1\n",
            "\n",
            "--- Chunk 13667 ---\n",
            "totals = []\n",
            "for episode in range(500):\n",
            "    episode_rewards = 0\n",
            "    obs = env.reset()\n",
            "    for step in range(200):\n",
            "        action = basic_policy(obs)\n",
            "\n",
            "--- Chunk 13668 ---\n",
            "obs, reward, done, info = env.step(action)\n",
            "        episode_rewards += reward\n",
            "        if done:\n",
            "            break\n",
            "\n",
            "--- Chunk 13669 ---\n",
            "break\n",
            "    totals.append(episode_rewards)\n",
            "\n",
            "--- Chunk 13670 ---\n",
            "This code is hopefully self-explanatory. Let’s look at the result:\n",
            ">>> import numpy as np\n",
            "\n",
            "--- Chunk 13671 ---\n",
            ">>> np.mean(totals), np.std(totals), np.min(totals), np.max(totals)\n",
            "(41.718, 8.858356280936096, 24.0, 68.0)\n",
            "\n",
            "--- Chunk 13672 ---\n",
            "Even with 500 tries, this policy never managed to keep the pole upright for more than\n",
            "\n",
            "--- Chunk 13673 ---\n",
            "68 consecutive steps. Not great. If you look at the simulation in the Jupyter note‐\n",
            "\n",
            "--- Chunk 13674 ---\n",
            "books, you will see that the cart oscillates left and right more and more strongly until\n",
            "\n",
            "--- Chunk 13675 ---\n",
            "the pole tilts too much. Let’s see if a neural network can come up with a better policy.\n",
            "\n",
            "--- Chunk 13676 ---\n",
            "Neural Network Policies\n",
            "Let’s create a neural network policy. Just like with the policy we hardcoded earlier, this\n",
            "\n",
            "--- Chunk 13677 ---\n",
            "neural network will take an observation as input, and it will output the action to be\n",
            "\n",
            "--- Chunk 13678 ---\n",
            "executed. More precisely, it will estimate a probability for each action, and then we\n",
            "\n",
            "--- Chunk 13679 ---\n",
            "will select an action randomly, according to the estimated probabilities (see\n",
            "\n",
            "--- Chunk 13680 ---\n",
            "Figure 18-5). In the case of the CartPole environment, there are just two possible\n",
            "\n",
            "--- Chunk 13681 ---\n",
            "actions (left or right), so we only need one output neuron. It will output the probabil‐\n",
            "\n",
            "--- Chunk 13682 ---\n",
            "ity p of action 0 (left), and of course the probability of action 1 (right) will be 1 – p.\n",
            "\n",
            "--- Chunk 13683 ---\n",
            "For example, if it outputs 0.7, then we will pick action 0 with 70% probability, or\n",
            "action 1 with 30% probability.\n",
            "\n",
            "--- Chunk 13684 ---\n",
            "Neural Network Policies | 617\n",
            "\n",
            "\n",
            "\n",
            "Figure 18-5. Neural network policy\n",
            "\n",
            "--- Chunk 13685 ---\n",
            "You may wonder why we are picking a random action based on the probabilities\n",
            "\n",
            "--- Chunk 13686 ---\n",
            "given by the neural network, rather than just picking the action with the highest\n",
            "\n",
            "--- Chunk 13687 ---\n",
            "score. This approach lets the agent find the right balance between exploring new\n",
            "\n",
            "--- Chunk 13688 ---\n",
            "actions and exploiting the actions that are known to work well. Here’s an analogy:\n",
            "\n",
            "--- Chunk 13689 ---\n",
            "suppose you go to a restaurant for the first time, and all the dishes look equally\n",
            "\n",
            "--- Chunk 13690 ---\n",
            "appealing, so you randomly pick one. If it turns out to be good, you can increase the\n",
            "\n",
            "--- Chunk 13691 ---\n",
            "probability that you’ll order it next time, but you shouldn’t increase that probability\n",
            "\n",
            "--- Chunk 13692 ---\n",
            "up to 100%, or else you will never try out the other dishes, some of which may be\n",
            "even better than the one you tried.\n",
            "\n",
            "--- Chunk 13693 ---\n",
            "Also note that in this particular environment, the past actions and observations can\n",
            "\n",
            "--- Chunk 13694 ---\n",
            "safely be ignored, since each observation contains the environment’s full state. If there\n",
            "\n",
            "--- Chunk 13695 ---\n",
            "were some hidden state, then you might need to consider past actions and observa‐\n",
            "\n",
            "--- Chunk 13696 ---\n",
            "tions as well. For example, if the environment only revealed the position of the cart\n",
            "\n",
            "--- Chunk 13697 ---\n",
            "but not its velocity, you would have to consider not only the current observation but\n",
            "\n",
            "--- Chunk 13698 ---\n",
            "also the previous observation in order to estimate the current velocity. Another exam‐\n",
            "\n",
            "--- Chunk 13699 ---\n",
            "ple is when the observations are noisy; in that case, you generally want to use the past\n",
            "\n",
            "--- Chunk 13700 ---\n",
            "few observations to estimate the most likely current state. The CartPole problem is\n",
            "\n",
            "--- Chunk 13701 ---\n",
            "thus as simple as can be; the observations are noise-free, and they contain the envi‐\n",
            "ronment’s full state.\n",
            "\n",
            "--- Chunk 13702 ---\n",
            "618 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 13703 ---\n",
            "Here is the code to build this neural network policy using tf.keras:\n",
            "import tensorflow as tf\n",
            "from tensorflow import keras\n",
            "\n",
            "--- Chunk 13704 ---\n",
            "n_inputs = 4 # == env.observation_space.shape[0]\n",
            "\n",
            "--- Chunk 13705 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.Dense(5, activation=\"elu\", input_shape=[n_inputs]),\n",
            "\n",
            "--- Chunk 13706 ---\n",
            "keras.layers.Dense(1, activation=\"sigmoid\"),\n",
            "])\n",
            "\n",
            "--- Chunk 13707 ---\n",
            "After the imports, we use a simple Sequential model to define the policy network.\n",
            "\n",
            "--- Chunk 13708 ---\n",
            "The number of inputs is the size of the observation space (which in the case of Cart‐\n",
            "\n",
            "--- Chunk 13709 ---\n",
            "Pole is 4), and we have just five hidden units because it’s a simple problem. Finally, we\n",
            "\n",
            "--- Chunk 13710 ---\n",
            "want to output a single probability (the probability of going left), so we have a single\n",
            "\n",
            "--- Chunk 13711 ---\n",
            "output neuron using the sigmoid activation function. If there were more than two\n",
            "\n",
            "--- Chunk 13712 ---\n",
            "possible actions, there would be one output neuron per action, and we would use the\n",
            "softmax activation function instead.\n",
            "\n",
            "--- Chunk 13713 ---\n",
            "OK, we now have a neural network policy that will take observations and output\n",
            "action probabilities. But how do we train it?\n",
            "\n",
            "--- Chunk 13714 ---\n",
            "Evaluating Actions: The Credit Assignment Problem\n",
            "If we knew what the best action was at each step, we could train the neural network as\n",
            "\n",
            "--- Chunk 13715 ---\n",
            "usual, by minimizing the cross entropy between the estimated probability distribu‐\n",
            "\n",
            "--- Chunk 13716 ---\n",
            "tion and the target probability distribution. It would just be regular supervised learn‐\n",
            "\n",
            "--- Chunk 13717 ---\n",
            "ing. However, in Reinforcement Learning the only guidance the agent gets is through\n",
            "\n",
            "--- Chunk 13718 ---\n",
            "rewards, and rewards are typically sparse and delayed. For example, if the agent man‐\n",
            "\n",
            "--- Chunk 13719 ---\n",
            "ages to balance the pole for 100 steps, how can it know which of the 100 actions it\n",
            "\n",
            "--- Chunk 13720 ---\n",
            "took were good, and which of them were bad? All it knows is that the pole fell after\n",
            "\n",
            "--- Chunk 13721 ---\n",
            "the last action, but surely this last action is not entirely responsible. This is called the\n",
            "\n",
            "--- Chunk 13722 ---\n",
            "credit assignment problem: when the agent gets a reward, it is hard for it to know\n",
            "\n",
            "--- Chunk 13723 ---\n",
            "which actions should get credited (or blamed) for it. Think of a dog that gets rewar‐\n",
            "\n",
            "--- Chunk 13724 ---\n",
            "ded hours after it behaved well; will it understand what it is being rewarded for?\n",
            "\n",
            "--- Chunk 13725 ---\n",
            "To tackle this problem, a common strategy is to evaluate an action based on the sum\n",
            "\n",
            "--- Chunk 13726 ---\n",
            "of all the rewards that come after it, usually applying a discount factor γ (gamma) at\n",
            "\n",
            "--- Chunk 13727 ---\n",
            "each step. This sum of discounted rewards is called the action’s return. Consider the\n",
            "\n",
            "--- Chunk 13728 ---\n",
            "example in Figure 18-6). If an agent decides to go right three times in a row and gets\n",
            "\n",
            "--- Chunk 13729 ---\n",
            "+10 reward after the first step, 0 after the second step, and finally –50 after the third\n",
            "\n",
            "--- Chunk 13730 ---\n",
            "step, then assuming we use a discount factor γ = 0.8, the first action will have a return\n",
            "\n",
            "--- Chunk 13731 ---\n",
            "of 10 + γ × 0 + γ2 × (–50) = –22. If the discount factor is close to 0, then future\n",
            "\n",
            "--- Chunk 13732 ---\n",
            "rewards won’t count for much compared to immediate rewards. Conversely, if the\n",
            "\n",
            "--- Chunk 13733 ---\n",
            "discount factor is close to 1, then rewards far into the future will count almost as\n",
            "\n",
            "--- Chunk 13734 ---\n",
            "Evaluating Actions: The Credit Assignment Problem | 619\n",
            "\n",
            "--- Chunk 13735 ---\n",
            "much as immediate rewards. Typical discount factors vary from 0.9 to 0.99. With a\n",
            "\n",
            "--- Chunk 13736 ---\n",
            "discount factor of 0.95, rewards 13 steps into the future count roughly for half as\n",
            "\n",
            "--- Chunk 13737 ---\n",
            "much as immediate rewards (since 0.9513 ≈ 0.5), while with a discount factor of 0.99,\n",
            "\n",
            "--- Chunk 13738 ---\n",
            "rewards 69 steps into the future count for half as much as immediate rewards. In the\n",
            "\n",
            "--- Chunk 13739 ---\n",
            "CartPole environment, actions have fairly short-term effects, so choosing a discount\n",
            "factor of 0.95 seems reasonable.\n",
            "\n",
            "--- Chunk 13740 ---\n",
            "Figure 18-6. Computing an action’s return: the sum of discounted future rewards\n",
            "\n",
            "--- Chunk 13741 ---\n",
            "Of course, a good action may be followed by several bad actions that cause the pole to\n",
            "\n",
            "--- Chunk 13742 ---\n",
            "fall quickly, resulting in the good action getting a low return (similarly, a good actor\n",
            "\n",
            "--- Chunk 13743 ---\n",
            "may sometimes star in a terrible movie). However, if we play the game enough times,\n",
            "\n",
            "--- Chunk 13744 ---\n",
            "on average good actions will get a higher return than bad ones. We want to estimate\n",
            "\n",
            "--- Chunk 13745 ---\n",
            "how much better or worse an action is, compared to the other possible actions, on\n",
            "\n",
            "--- Chunk 13746 ---\n",
            "average. This is called the action advantage. For this, we must run many episodes and\n",
            "\n",
            "--- Chunk 13747 ---\n",
            "normalize all the action returns (by subtracting the mean and dividing by the stan‐\n",
            "\n",
            "--- Chunk 13748 ---\n",
            "dard deviation). After that, we can reasonably assume that actions with a negative\n",
            "\n",
            "--- Chunk 13749 ---\n",
            "advantage were bad while actions with a positive advantage were good. Perfect—now\n",
            "\n",
            "--- Chunk 13750 ---\n",
            "that we have a way to evaluate each action, we are ready to train our first agent using\n",
            "policy gradients. Let’s see how.\n",
            "\n",
            "--- Chunk 13751 ---\n",
            "Policy Gradients\n",
            "As discussed earlier, PG algorithms optimize the parameters of a policy by following\n",
            "\n",
            "--- Chunk 13752 ---\n",
            "the gradients toward higher rewards. One popular class of PG algorithms, called\n",
            "\n",
            "--- Chunk 13753 ---\n",
            "620 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "\n",
            "\n",
            "REINFORCE algorithms, was introduced back in 199211 by Ronald Williams. Here is\n",
            "one common variant:\n",
            "\n",
            "--- Chunk 13754 ---\n",
            "1. First, let the neural network policy play the game several times, and at each step,\n",
            "\n",
            "--- Chunk 13755 ---\n",
            "compute the gradients that would make the chosen action even more likely—but\n",
            "don’t apply these gradients yet.\n",
            "\n",
            "--- Chunk 13756 ---\n",
            "2. Once you have run several episodes, compute each action’s advantage (using the\n",
            "method described in the previous section).\n",
            "\n",
            "--- Chunk 13757 ---\n",
            "3. If an action’s advantage is positive, it means that the action was probably good,\n",
            "\n",
            "--- Chunk 13758 ---\n",
            "and you want to apply the gradients computed earlier to make the action even\n",
            "\n",
            "--- Chunk 13759 ---\n",
            "more likely to be chosen in the future. However, if the action’s advantage is nega‐\n",
            "\n",
            "--- Chunk 13760 ---\n",
            "tive, it means the action was probably bad, and you want to apply the opposite\n",
            "\n",
            "--- Chunk 13761 ---\n",
            "gradients to make this action slightly less likely in the future. The solution is sim‐\n",
            "\n",
            "--- Chunk 13762 ---\n",
            "ply to multiply each gradient vector by the corresponding action’s advantage.\n",
            "\n",
            "--- Chunk 13763 ---\n",
            "4. Finally, compute the mean of all the resulting gradient vectors, and use it to per‐\n",
            "form a Gradient Descent step.\n",
            "\n",
            "--- Chunk 13764 ---\n",
            "Let’s use tf.keras to implement this algorithm. We will train the neural network policy\n",
            "\n",
            "--- Chunk 13765 ---\n",
            "we built earlier so that it learns to balance the pole on the cart. First, we need a func‐\n",
            "\n",
            "--- Chunk 13766 ---\n",
            "tion that will play one step. We will pretend for now that whatever action it takes is\n",
            "\n",
            "--- Chunk 13767 ---\n",
            "the right one so that we can compute the loss and its gradients (these gradients will\n",
            "\n",
            "--- Chunk 13768 ---\n",
            "just be saved for a while, and we will modify them later depending on how good or\n",
            "bad the action turned out to be):\n",
            "\n",
            "--- Chunk 13769 ---\n",
            "def play_one_step(env, obs, model, loss_fn):\n",
            "    with tf.GradientTape() as tape:\n",
            "        left_proba = model(obs[np.newaxis])\n",
            "\n",
            "--- Chunk 13770 ---\n",
            "action = (tf.random.uniform([1, 1]) > left_proba)\n",
            "        y_target = tf.constant([[1.]]) - tf.cast(action, tf.float32)\n",
            "\n",
            "--- Chunk 13771 ---\n",
            "loss = tf.reduce_mean(loss_fn(y_target, left_proba))\n",
            "    grads = tape.gradient(loss, model.trainable_variables)\n",
            "\n",
            "--- Chunk 13772 ---\n",
            "obs, reward, done, info = env.step(int(action[0, 0].numpy()))\n",
            "    return obs, reward, done, grads\n",
            "\n",
            "--- Chunk 13773 ---\n",
            "Let’s walk though this function:\n",
            "\n",
            "--- Chunk 13774 ---\n",
            "• Within the GradientTape block (see Chapter 12), we start by calling the model,\n",
            "\n",
            "--- Chunk 13775 ---\n",
            "giving it a single observation (we reshape the observation so it becomes a batch\n",
            "\n",
            "--- Chunk 13776 ---\n",
            "containing a single instance, as the model expects a batch). This outputs the\n",
            "probability of going left.\n",
            "\n",
            "--- Chunk 13777 ---\n",
            "11 Ronald J. Williams, “Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement\n",
            "\n",
            "--- Chunk 13778 ---\n",
            "Leaning,” Machine Learning 8 (1992) : 229–256.\n",
            "\n",
            "--- Chunk 13779 ---\n",
            "Policy Gradients | 621\n",
            "\n",
            "--- Chunk 13780 ---\n",
            "• Next, we sample a random float between 0 and 1, and we check whether it is\n",
            "\n",
            "--- Chunk 13781 ---\n",
            "greater than left_proba. The action will be False with probability left_proba,\n",
            "\n",
            "--- Chunk 13782 ---\n",
            "or True with probability 1 - left_proba. Once we cast this Boolean to a num‐\n",
            "\n",
            "--- Chunk 13783 ---\n",
            "ber, the action will be 0 (left) or 1 (right) with the appropriate probabilities.\n",
            "\n",
            "--- Chunk 13784 ---\n",
            "• Next, we define the target probability of going left: it is 1 minus the action (cast\n",
            "\n",
            "--- Chunk 13785 ---\n",
            "to a float). If the action is 0 (left), then the target probability of going left will be\n",
            "\n",
            "--- Chunk 13786 ---\n",
            "1. If the action is 1 (right), then the target probability will be 0.\n",
            "\n",
            "--- Chunk 13787 ---\n",
            "• Then we compute the loss using the given loss function, and we use the tape to\n",
            "\n",
            "--- Chunk 13788 ---\n",
            "compute the gradient of the loss with regard to the model’s trainable variables.\n",
            "\n",
            "--- Chunk 13789 ---\n",
            "Again, these gradients will be tweaked later, before we apply them, depending on\n",
            "how good or bad the action turned out to be.\n",
            "\n",
            "--- Chunk 13790 ---\n",
            "• Finally, we play the selected action, and we return the new observation, the\n",
            "\n",
            "--- Chunk 13791 ---\n",
            "reward, whether the episode is ended or not, and of course the gradients that we\n",
            "just computed.\n",
            "\n",
            "--- Chunk 13792 ---\n",
            "Now let’s create another function that will rely on the play_one_step() function to\n",
            "\n",
            "--- Chunk 13793 ---\n",
            "play multiple episodes, returning all the rewards and gradients for each episode and\n",
            "each step:\n",
            "\n",
            "--- Chunk 13794 ---\n",
            "def play_multiple_episodes(env, n_episodes, n_max_steps, model, loss_fn):\n",
            "    all_rewards = []\n",
            "    all_grads = []\n",
            "\n",
            "--- Chunk 13795 ---\n",
            "all_grads = []\n",
            "    for episode in range(n_episodes):\n",
            "        current_rewards = []\n",
            "        current_grads = []\n",
            "        obs = env.reset()\n",
            "\n",
            "--- Chunk 13796 ---\n",
            "for step in range(n_max_steps):\n",
            "            obs, reward, done, grads = play_one_step(env, obs, model, loss_fn)\n",
            "\n",
            "--- Chunk 13797 ---\n",
            "current_rewards.append(reward)\n",
            "            current_grads.append(grads)\n",
            "            if done:\n",
            "                break\n",
            "\n",
            "--- Chunk 13798 ---\n",
            "all_rewards.append(current_rewards)\n",
            "        all_grads.append(current_grads)\n",
            "    return all_rewards, all_grads\n",
            "\n",
            "--- Chunk 13799 ---\n",
            "This code returns a list of reward lists (one reward list per episode, containing one\n",
            "\n",
            "--- Chunk 13800 ---\n",
            "reward per step), as well as a list of gradient lists (one gradient list per episode, each\n",
            "\n",
            "--- Chunk 13801 ---\n",
            "containing one tuple of gradients per step and each tuple containing one gradient\n",
            "tensor per trainable variable).\n",
            "\n",
            "--- Chunk 13802 ---\n",
            "The algorithm will use the play_multiple_episodes() function to play the game\n",
            "\n",
            "--- Chunk 13803 ---\n",
            "several times (e.g., 10 times), then it will go back and look at all the rewards, discount\n",
            "\n",
            "--- Chunk 13804 ---\n",
            "them, and normalize them. To do that, we need a couple more functions: the first will\n",
            "\n",
            "--- Chunk 13805 ---\n",
            "compute the sum of future discounted rewards at each step, and the second will\n",
            "\n",
            "--- Chunk 13806 ---\n",
            "622 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 13807 ---\n",
            "normalize all these discounted rewards (returns) across many episodes by subtracting\n",
            "the mean and dividing by the standard deviation:\n",
            "\n",
            "--- Chunk 13808 ---\n",
            "def discount_rewards(rewards, discount_factor):\n",
            "    discounted = np.array(rewards)\n",
            "    for step in range(len(rewards) - 2, -1, -1):\n",
            "\n",
            "--- Chunk 13809 ---\n",
            "discounted[step] += discounted[step + 1] * discount_factor\n",
            "    return discounted\n",
            "\n",
            "--- Chunk 13810 ---\n",
            "def discount_and_normalize_rewards(all_rewards, discount_factor):\n",
            "    all_discounted_rewards = [discount_rewards(rewards, discount_factor)\n",
            "\n",
            "--- Chunk 13811 ---\n",
            "for rewards in all_rewards]\n",
            "    flat_rewards = np.concatenate(all_discounted_rewards)\n",
            "\n",
            "--- Chunk 13812 ---\n",
            "reward_mean = flat_rewards.mean()\n",
            "    reward_std = flat_rewards.std()\n",
            "    return [(discounted_rewards - reward_mean) / reward_std\n",
            "\n",
            "--- Chunk 13813 ---\n",
            "for discounted_rewards in all_discounted_rewards]\n",
            "\n",
            "--- Chunk 13814 ---\n",
            "Let’s check that this works:\n",
            ">>> discount_rewards([10, 0, -50], discount_factor=0.8)\n",
            "array([-22, -40, -50])\n",
            "\n",
            "--- Chunk 13815 ---\n",
            ">>> discount_and_normalize_rewards([[10, 0, -50], [10, 20]],\n",
            "...                                discount_factor=0.8)\n",
            "...\n",
            "\n",
            "--- Chunk 13816 ---\n",
            "...\n",
            "[array([-0.28435071, -0.86597718, -1.18910299]),\n",
            " array([1.26665318, 1.0727777 ])]\n",
            "\n",
            "--- Chunk 13817 ---\n",
            "The call to discount_rewards() returns exactly what we expect (see Figure 18-6).\n",
            "\n",
            "--- Chunk 13818 ---\n",
            "You can verify that the function discount_and_normalize_rewards() does indeed\n",
            "\n",
            "--- Chunk 13819 ---\n",
            "return the normalized action advantages for each action in both episodes. Notice that\n",
            "\n",
            "--- Chunk 13820 ---\n",
            "the first episode was much worse than the second, so its normalized advantages are\n",
            "\n",
            "--- Chunk 13821 ---\n",
            "all negative; all actions from the first episode would be considered bad, and con‐\n",
            "\n",
            "--- Chunk 13822 ---\n",
            "versely all actions from the second episode would be considered good.\n",
            "\n",
            "--- Chunk 13823 ---\n",
            "We are almost ready to run the algorithm! Now let’s define the hyperparameters. We\n",
            "\n",
            "--- Chunk 13824 ---\n",
            "will run 150 training iterations, playing 10 episodes per iteration, and each episode\n",
            "\n",
            "--- Chunk 13825 ---\n",
            "will last at most 200 steps. We will use a discount factor of 0.95:\n",
            "\n",
            "--- Chunk 13826 ---\n",
            "n_iterations = 150\n",
            "n_episodes_per_update = 10\n",
            "n_max_steps = 200\n",
            "discount_factor = 0.95\n",
            "\n",
            "--- Chunk 13827 ---\n",
            "We also need an optimizer and the loss function. A regular Adam optimizer with\n",
            "\n",
            "--- Chunk 13828 ---\n",
            "learning rate 0.01 will do just fine, and we will use the binary cross-entropy loss func‐\n",
            "\n",
            "--- Chunk 13829 ---\n",
            "tion because we are training a binary classifier (there are two possible actions: left or\n",
            "right):\n",
            "\n",
            "--- Chunk 13830 ---\n",
            "optimizer = keras.optimizers.Adam(lr=0.01)\n",
            "loss_fn = keras.losses.binary_crossentropy\n",
            "\n",
            "Policy Gradients | 623\n",
            "\n",
            "--- Chunk 13831 ---\n",
            "We are now ready to build and run the training loop!\n",
            "for iteration in range(n_iterations):\n",
            "    all_rewards, all_grads = play_multiple_episodes(\n",
            "\n",
            "--- Chunk 13832 ---\n",
            "env, n_episodes_per_update, n_max_steps, model, loss_fn)\n",
            "    all_final_rewards = discount_and_normalize_rewards(all_rewards,\n",
            "\n",
            "--- Chunk 13833 ---\n",
            "discount_factor)\n",
            "    all_mean_grads = []\n",
            "\n",
            "--- Chunk 13834 ---\n",
            "for var_index in range(len(model.trainable_variables)):\n",
            "        mean_grads = tf.reduce_mean(\n",
            "\n",
            "--- Chunk 13835 ---\n",
            "[final_reward * all_grads[episode_index][step][var_index]\n",
            "             for episode_index, final_rewards in enumerate(all_final_rewards)\n",
            "\n",
            "--- Chunk 13836 ---\n",
            "for step, final_reward in enumerate(final_rewards)], axis=0)\n",
            "        all_mean_grads.append(mean_grads)\n",
            "\n",
            "--- Chunk 13837 ---\n",
            "optimizer.apply_gradients(zip(all_mean_grads, model.trainable_variables))\n",
            "\n",
            "--- Chunk 13838 ---\n",
            "Let’s walk through this code:\n",
            "\n",
            "--- Chunk 13839 ---\n",
            "• At each training iteration, this loop calls the play_multiple_episodes() func‐\n",
            "\n",
            "--- Chunk 13840 ---\n",
            "tion, which plays the game 10 times and returns all the rewards and gradients for\n",
            "every episode and step.\n",
            "\n",
            "--- Chunk 13841 ---\n",
            "• Then we call the discount_and_normalize_rewards() to compute each action’s\n",
            "\n",
            "--- Chunk 13842 ---\n",
            "normalized advantage (which in the code we call the final_reward). This pro‐\n",
            "\n",
            "--- Chunk 13843 ---\n",
            "vides a measure of how good or bad each action actually was, in hindsight.\n",
            "\n",
            "--- Chunk 13844 ---\n",
            "• Next, we go through each trainable variable, and for each of them we compute\n",
            "\n",
            "--- Chunk 13845 ---\n",
            "the weighted mean of the gradients for that variable over all episodes and all\n",
            "steps, weighted by the final_reward.\n",
            "\n",
            "--- Chunk 13846 ---\n",
            "• Finally, we apply these mean gradients using the optimizer: the model’s trainable\n",
            "\n",
            "--- Chunk 13847 ---\n",
            "variables will be tweaked, and hopefully the policy will be a bit better.\n",
            "\n",
            "--- Chunk 13848 ---\n",
            "And we’re done! This code will train the neural network policy, and it will success‐\n",
            "\n",
            "--- Chunk 13849 ---\n",
            "fully learn to balance the pole on the cart (you can try it out in the “Policy Gradients”\n",
            "\n",
            "--- Chunk 13850 ---\n",
            "section of the Jupyter notebook). The mean reward per episode will get very close to\n",
            "\n",
            "--- Chunk 13851 ---\n",
            "200 (which is the maximum by default with this environment). Success!\n",
            "\n",
            "--- Chunk 13852 ---\n",
            "Researchers try to find algorithms that work well even when the\n",
            "agent initially knows nothing about the environment. However,\n",
            "\n",
            "--- Chunk 13853 ---\n",
            "unless you are writing a paper, you should not hesitate to inject\n",
            "prior knowledge into the agent, as it will speed up training dramat‐\n",
            "\n",
            "--- Chunk 13854 ---\n",
            "ically. For example, since you know that the pole should be as verti‐\n",
            "cal as possible, you could add negative rewards proportional to the\n",
            "\n",
            "--- Chunk 13855 ---\n",
            "pole’s angle. This will make the rewards much less sparse and speed\n",
            "up training. Also, if you already have a reasonably good policy (e.g.,\n",
            "\n",
            "--- Chunk 13856 ---\n",
            "hardcoded), you may want to train the neural network to imitate it\n",
            "before using policy gradients to improve it.\n",
            "\n",
            "--- Chunk 13857 ---\n",
            "624 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 13858 ---\n",
            "The simple policy gradients algorithm we just trained solved the CartPole task, but it\n",
            "\n",
            "--- Chunk 13859 ---\n",
            "would not scale well to larger and more complex tasks. Indeed, it is highly sample\n",
            "\n",
            "--- Chunk 13860 ---\n",
            "inefficient, meaning it needs to explore the game for a very long time before it can\n",
            "\n",
            "--- Chunk 13861 ---\n",
            "make significant progress. This is due to the fact that it must run multiple episodes to\n",
            "\n",
            "--- Chunk 13862 ---\n",
            "estimate the advantage of each action, as we have seen. However, it is the foundation\n",
            "\n",
            "--- Chunk 13863 ---\n",
            "of more powerful algorithms, such as Actor-Critic algorithms (which we will discuss\n",
            "briefly at the end of this chapter).\n",
            "\n",
            "--- Chunk 13864 ---\n",
            "We will now look at another popular family of algorithms. Whereas PG algorithms\n",
            "\n",
            "--- Chunk 13865 ---\n",
            "directly try to optimize the policy to increase rewards, the algorithms we will look at\n",
            "\n",
            "--- Chunk 13866 ---\n",
            "now are less direct: the agent learns to estimate the expected return for each state, or\n",
            "\n",
            "--- Chunk 13867 ---\n",
            "for each action in each state, then it uses this knowledge to decide how to act. To\n",
            "\n",
            "--- Chunk 13868 ---\n",
            "understand these algorithms, we must first introduce Markov decision processes.\n",
            "\n",
            "--- Chunk 13869 ---\n",
            "Markov Decision Processes\n",
            "In the early 20th century, the mathematician Andrey Markov studied stochastic pro‐\n",
            "\n",
            "--- Chunk 13870 ---\n",
            "cesses with no memory, called Markov chains. Such a process has a fixed number of\n",
            "\n",
            "--- Chunk 13871 ---\n",
            "states, and it randomly evolves from one state to another at each step. The probability\n",
            "\n",
            "--- Chunk 13872 ---\n",
            "for it to evolve from a state s to a state s′ is fixed, and it depends only on the pair (s, s\n",
            "\n",
            "--- Chunk 13873 ---\n",
            "′), not on past states (this is why we say that the system has no memory).\n",
            "Figure 18-7 shows an example of a Markov chain with four states.\n",
            "\n",
            "--- Chunk 13874 ---\n",
            "Figure 18-7. Example of a Markov chain\n",
            "\n",
            "--- Chunk 13875 ---\n",
            "Suppose that the process starts in state s0, and there is a 70% chance that it will\n",
            "\n",
            "--- Chunk 13876 ---\n",
            "remain in that state at the next step. Eventually it is bound to leave that state and\n",
            "\n",
            "--- Chunk 13877 ---\n",
            "never come back because no other state points back to s0. If it goes to state s1, it will\n",
            "\n",
            "--- Chunk 13878 ---\n",
            "then most likely go to state s2 (90% probability), then immediately back to state s1\n",
            "\n",
            "--- Chunk 13879 ---\n",
            "Markov Decision Processes | 625\n",
            "\n",
            "--- Chunk 13880 ---\n",
            "(with 100% probability). It may alternate a number of times between these two states,\n",
            "\n",
            "--- Chunk 13881 ---\n",
            "but eventually it will fall into state s3 and remain there forever (this is a terminal\n",
            "\n",
            "--- Chunk 13882 ---\n",
            "state). Markov chains can have very different dynamics, and they are heavily used in\n",
            "thermodynamics, chemistry, statistics, and much more.\n",
            "\n",
            "--- Chunk 13883 ---\n",
            "Markov decision processes were first described in the 1950s by Richard Bellman.12\n",
            "\n",
            "--- Chunk 13884 ---\n",
            "They resemble Markov chains but with a twist: at each step, an agent can choose one\n",
            "\n",
            "--- Chunk 13885 ---\n",
            "of several possible actions, and the transition probabilities depend on the chosen\n",
            "\n",
            "--- Chunk 13886 ---\n",
            "action. Moreover, some state transitions return some reward (positive or negative),\n",
            "\n",
            "--- Chunk 13887 ---\n",
            "and the agent’s goal is to find a policy that will maximize reward over time.\n",
            "\n",
            "--- Chunk 13888 ---\n",
            "For example, the MDP represented in Figure 18-8 has three states (represented by cir‐\n",
            "\n",
            "--- Chunk 13889 ---\n",
            "cles) and up to three possible discrete actions at each step (represented by diamonds).\n",
            "\n",
            "--- Chunk 13890 ---\n",
            "Figure 18-8. Example of a Markov decision process\n",
            "\n",
            "--- Chunk 13891 ---\n",
            "If it starts in state s0, the agent can choose between actions a0, a1, or a2. If it chooses\n",
            "\n",
            "--- Chunk 13892 ---\n",
            "action a1, it just remains in state s0 with certainty, and without any reward. It can thus\n",
            "\n",
            "--- Chunk 13893 ---\n",
            "decide to stay there forever if it wants to. But if it chooses action a0, it has a 70% prob‐\n",
            "\n",
            "--- Chunk 13894 ---\n",
            "ability of gaining a reward of +10 and remaining in state s0. It can then try again and\n",
            "\n",
            "--- Chunk 13895 ---\n",
            "again to gain as much reward as possible, but at one point it is going to end up\n",
            "\n",
            "--- Chunk 13896 ---\n",
            "instead in state s1. In state s1 it has only two possible actions: a0 or a2. It can choose to\n",
            "\n",
            "--- Chunk 13897 ---\n",
            "stay put by repeatedly choosing action a0, or it can choose to move on to state s2 and\n",
            "\n",
            "--- Chunk 13898 ---\n",
            "get a negative reward of –50 (ouch). In state s2 it has no other choice than to take\n",
            "\n",
            "--- Chunk 13899 ---\n",
            "action a1, which will most likely lead it back to state s0, gaining a reward of +40 on the\n",
            "\n",
            "--- Chunk 13900 ---\n",
            "12 Richard Bellman, “A Markovian Decision Process,” Journal of Mathematics and Mechanics 6, no. 5 (1957):\n",
            "679–684.\n",
            "\n",
            "--- Chunk 13901 ---\n",
            "626 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 13902 ---\n",
            "way. You get the picture. By looking at this MDP, can you guess which strategy will\n",
            "\n",
            "--- Chunk 13903 ---\n",
            "gain the most reward over time? In state s0 it is clear that action a0 is the best option,\n",
            "\n",
            "--- Chunk 13904 ---\n",
            "and in state s2 the agent has no choice but to take action a1, but in state s1 it is not\n",
            "\n",
            "--- Chunk 13905 ---\n",
            "obvious whether the agent should stay put (a0) or go through the fire (a2).\n",
            "\n",
            "--- Chunk 13906 ---\n",
            "Bellman found a way to estimate the optimal state value of any state s, noted V*(s),\n",
            "\n",
            "--- Chunk 13907 ---\n",
            "which is the sum of all discounted future rewards the agent can expect on average\n",
            "\n",
            "--- Chunk 13908 ---\n",
            "after it reaches a state s, assuming it acts optimally. He showed that if the agent acts\n",
            "\n",
            "--- Chunk 13909 ---\n",
            "optimally, then the Bellman Optimality Equation applies (see Equation 18-1). This\n",
            "\n",
            "--- Chunk 13910 ---\n",
            "recursive equation says that if the agent acts optimally, then the optimal value of the\n",
            "\n",
            "--- Chunk 13911 ---\n",
            "current state is equal to the reward it will get on average after taking one optimal\n",
            "\n",
            "--- Chunk 13912 ---\n",
            "action, plus the expected optimal value of all possible next states that this action can\n",
            "lead to.\n",
            "\n",
            "--- Chunk 13913 ---\n",
            "Equation 18-1. Bellman Optimality Equation\n",
            "V* s = maxa ∑s T s, a, s′ R s, a, s′ + γ · V* s′ for all s\n",
            "\n",
            "In this equation:\n",
            "\n",
            "--- Chunk 13914 ---\n",
            "• T(s, a, s′) is the transition probability from state s to state s′, given that the agent\n",
            "\n",
            "--- Chunk 13915 ---\n",
            "chose action a. For example, in Figure 18-8, T(s2, a1, s0) = 0.8.\n",
            "\n",
            "--- Chunk 13916 ---\n",
            "• R(s, a, s′) is the reward that the agent gets when it goes from state s to state s′,\n",
            "\n",
            "--- Chunk 13917 ---\n",
            "given that the agent chose action a. For example, in Figure 18-8, R(s2, a1,\n",
            "s0) = +40.\n",
            "\n",
            "--- Chunk 13918 ---\n",
            "• γ is the discount factor.\n",
            "\n",
            "--- Chunk 13919 ---\n",
            "This equation leads directly to an algorithm that can precisely estimate the optimal\n",
            "\n",
            "--- Chunk 13920 ---\n",
            "state value of every possible state: you first initialize all the state value estimates to\n",
            "\n",
            "--- Chunk 13921 ---\n",
            "zero, and then you iteratively update them using the Value Iteration algorithm (see\n",
            "\n",
            "--- Chunk 13922 ---\n",
            "Equation 18-2). A remarkable result is that, given enough time, these estimates are\n",
            "\n",
            "--- Chunk 13923 ---\n",
            "guaranteed to converge to the optimal state values, corresponding to the optimal\n",
            "policy.\n",
            "\n",
            "--- Chunk 13924 ---\n",
            "Equation 18-2. Value Iteration algorithm\n",
            "Vk + 1 s max\n",
            "\n",
            "a ∑T s, a, s′ R s, a, s′ + γ · Vk s′ for all s\n",
            "s′\n",
            "\n",
            "--- Chunk 13925 ---\n",
            "In this equation, Vk(s) is the estimated value of state s at the kth iteration of the\n",
            "algorithm.\n",
            "\n",
            "Markov Decision Processes | 627\n",
            "\n",
            "--- Chunk 13926 ---\n",
            "This algorithm is an example of Dynamic Programming, which\n",
            "breaks down a complex problem into tractable subproblems that\n",
            "can be tackled iteratively.\n",
            "\n",
            "--- Chunk 13927 ---\n",
            "Knowing the optimal state values can be useful, in particular to evaluate a policy, but\n",
            "\n",
            "--- Chunk 13928 ---\n",
            "it does not give us the optimal policy for the agent. Luckily, Bellman found a very\n",
            "\n",
            "--- Chunk 13929 ---\n",
            "similar algorithm to estimate the optimal state-action values, generally called Q-\n",
            "\n",
            "--- Chunk 13930 ---\n",
            "Values (Quality Values). The optimal Q-Value of the state-action pair (s, a), noted\n",
            "\n",
            "--- Chunk 13931 ---\n",
            "Q*(s, a), is the sum of discounted future rewards the agent can expect on average\n",
            "\n",
            "--- Chunk 13932 ---\n",
            "after it reaches the state s and chooses action a, but before it sees the outcome of this\n",
            "action, assuming it acts optimally after that action.\n",
            "\n",
            "--- Chunk 13933 ---\n",
            "Here is how it works: once again, you start by initializing all the Q-Value estimates to\n",
            "\n",
            "--- Chunk 13934 ---\n",
            "zero, then you update them using the Q-Value Iteration algorithm (see Equation\n",
            "18-3).\n",
            "\n",
            "--- Chunk 13935 ---\n",
            "Equation 18-3. Q-Value Iteration algorithm\n",
            "\n",
            "Qk + 1 s, a ∑T s, a, s′ R s, a, s′ + γ · max Q\n",
            "a k s′, a′ for all s′a\n",
            "\n",
            "s′ ′\n",
            "\n",
            "--- Chunk 13936 ---\n",
            "Once you have the optimal Q-Values, defining the optimal policy, noted π*(s), is triv‐\n",
            "\n",
            "--- Chunk 13937 ---\n",
            "ial: when the agent is in state s, it should choose the action with the highest Q-Value\n",
            "for that state: π* s = argmax Q* s, a .\n",
            "\n",
            "--- Chunk 13938 ---\n",
            "a\n",
            "\n",
            "Let’s apply this algorithm to the MDP represented in Figure 18-8. First, we need to\n",
            "define the MDP:\n",
            "\n",
            "--- Chunk 13939 ---\n",
            "transition_probabilities = [ # shape=[s, a, s']\n",
            "        [[0.7, 0.3, 0.0], [1.0, 0.0, 0.0], [0.8, 0.2, 0.0]],\n",
            "\n",
            "--- Chunk 13940 ---\n",
            "[[0.0, 1.0, 0.0], None, [0.0, 0.0, 1.0]],\n",
            "        [None, [0.8, 0.1, 0.1], None]]\n",
            "rewards = [ # shape=[s, a, s']\n",
            "\n",
            "--- Chunk 13941 ---\n",
            "[[+10, 0, 0], [0, 0, 0], [0, 0, 0]],\n",
            "        [[0, 0, 0], [0, 0, 0], [0, 0, -50]],\n",
            "        [[0, 0, 0], [+40, 0, 0], [0, 0, 0]]]\n",
            "\n",
            "--- Chunk 13942 ---\n",
            "possible_actions = [[0, 1, 2], [0, 2], [1]]\n",
            "\n",
            "--- Chunk 13943 ---\n",
            "For example, to know the transition probability from s2 to s0 after playing action a1,\n",
            "\n",
            "--- Chunk 13944 ---\n",
            "we will look up transition_probabilities[2][1][0] (which is 0.8). Similarly, to\n",
            "\n",
            "--- Chunk 13945 ---\n",
            "get the corresponding reward, we will look up rewards[2][1][0] (which is +40).\n",
            "\n",
            "--- Chunk 13946 ---\n",
            "And to get the list of possible actions in s2, we will look up possible_actions[2] (in\n",
            "\n",
            "--- Chunk 13947 ---\n",
            "this case, only action a1 is possible). Next, we must initialize all the Q-Values to 0\n",
            "\n",
            "--- Chunk 13948 ---\n",
            "(except for the the impossible actions, for which we set the Q-Values to –∞):\n",
            "\n",
            "--- Chunk 13949 ---\n",
            "628 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 13950 ---\n",
            "Q_values = np.full((3, 3), -np.inf) # -np.inf for impossible actions\n",
            "for state, actions in enumerate(possible_actions):\n",
            "\n",
            "--- Chunk 13951 ---\n",
            "Q_values[state, actions] = 0.0  # for all possible actions\n",
            "\n",
            "--- Chunk 13952 ---\n",
            "Now let’s run the Q-Value Iteration algorithm. It applies Equation 18-3 repeatedly, to\n",
            "all Q-Values, for every state and every possible action:\n",
            "\n",
            "--- Chunk 13953 ---\n",
            "gamma = 0.90 # the discount factor\n",
            "\n",
            "--- Chunk 13954 ---\n",
            "for iteration in range(50):\n",
            "    Q_prev = Q_values.copy()\n",
            "    for s in range(3):\n",
            "        for a in possible_actions[s]:\n",
            "\n",
            "--- Chunk 13955 ---\n",
            "Q_values[s, a] = np.sum([\n",
            "                    transition_probabilities[s][a][sp]\n",
            "\n",
            "--- Chunk 13956 ---\n",
            "* (rewards[s][a][sp] + gamma * np.max(Q_prev[sp]))\n",
            "                for sp in range(3)])\n",
            "\n",
            "--- Chunk 13957 ---\n",
            "That’s it! The resulting Q-Values look like this:\n",
            ">>> Q_values\n",
            "array([[18.91891892, 17.02702702, 13.62162162],\n",
            "\n",
            "--- Chunk 13958 ---\n",
            "[ 0.        ,        -inf, -4.87971488],\n",
            "       [       -inf, 50.13365013,        -inf]])\n",
            "\n",
            "--- Chunk 13959 ---\n",
            "For example, when the agent is in state s0 and it chooses action a1, the expected sum\n",
            "of discounted future rewards is approximately 17.0.\n",
            "\n",
            "--- Chunk 13960 ---\n",
            "For each state, let’s look at the action that has the highest Q-Value:\n",
            "\n",
            "--- Chunk 13961 ---\n",
            ">>> np.argmax(Q_values, axis=1) # optimal action for each state\n",
            "array([0, 0, 1])\n",
            "\n",
            "--- Chunk 13962 ---\n",
            "This gives us the optimal policy for this MDP, when using a discount factor of 0.90: in\n",
            "\n",
            "--- Chunk 13963 ---\n",
            "state s0 choose action a0; in state s1 choose action a0 (i.e., stay put); and in state s2\n",
            "\n",
            "--- Chunk 13964 ---\n",
            "choose action a1 (the only possible action). Interestingly, if we increase the discount\n",
            "\n",
            "--- Chunk 13965 ---\n",
            "factor to 0.95, the optimal policy changes: in state s1 the best action becomes a2 (go\n",
            "\n",
            "--- Chunk 13966 ---\n",
            "through the fire!). This makes sense because the more you value future rewards, the\n",
            "\n",
            "--- Chunk 13967 ---\n",
            "more you are willing to put up with some pain now for the promise of future bliss.\n",
            "\n",
            "--- Chunk 13968 ---\n",
            "Temporal Difference Learning\n",
            "Reinforcement Learning problems with discrete actions can often be modeled as\n",
            "\n",
            "--- Chunk 13969 ---\n",
            "Markov decision processes, but the agent initially has no idea what the transition\n",
            "\n",
            "--- Chunk 13970 ---\n",
            "probabilities are (it does not know T(s, a, s′)), and it does not know what the rewards\n",
            "\n",
            "--- Chunk 13971 ---\n",
            "are going to be either (it does not know R(s, a, s′)). It must experience each state and\n",
            "\n",
            "--- Chunk 13972 ---\n",
            "each transition at least once to know the rewards, and it must experience them multi‐\n",
            "\n",
            "--- Chunk 13973 ---\n",
            "ple times if it is to have a reasonable estimate of the transition probabilities.\n",
            "\n",
            "--- Chunk 13974 ---\n",
            "The Temporal Difference Learning (TD Learning) algorithm is very similar to the\n",
            "\n",
            "--- Chunk 13975 ---\n",
            "Value Iteration algorithm, but tweaked to take into account the fact that the agent has\n",
            "\n",
            "--- Chunk 13976 ---\n",
            "Temporal Difference Learning | 629\n",
            "\n",
            "--- Chunk 13977 ---\n",
            "only partial knowledge of the MDP. In general we assume that the agent initially\n",
            "\n",
            "--- Chunk 13978 ---\n",
            "knows only the possible states and actions, and nothing more. The agent uses an\n",
            "\n",
            "--- Chunk 13979 ---\n",
            "exploration policy—for example, a purely random policy—to explore the MDP, and as\n",
            "\n",
            "--- Chunk 13980 ---\n",
            "it progresses, the TD Learning algorithm updates the estimates of the state values\n",
            "\n",
            "--- Chunk 13981 ---\n",
            "based on the transitions and rewards that are actually observed (see Equation 18-4).\n",
            "\n",
            "--- Chunk 13982 ---\n",
            "Equation 18-4. TD Learning algorithm\n",
            "Vk + 1 s 1 − α Vk s + α r + γ · Vk s′\n",
            "or, equivalently: \n",
            "Vk + 1 s Vk s + α · δk s, r, s′\n",
            "\n",
            "--- Chunk 13983 ---\n",
            "with δk s, r, s′ = r + γ · Vk s′ − Vk s\n",
            "\n",
            "--- Chunk 13984 ---\n",
            "In this equation:\n",
            "\n",
            "• α is the learning rate (e.g., 0.01).\n",
            "• r + γ · Vk(s′) is called the TD target.\n",
            "• δk(s, r, s′) is called the TD error.\n",
            "\n",
            "--- Chunk 13985 ---\n",
            "A more concise way of writing the first form of this equation is to use the notation\n",
            "\n",
            "--- Chunk 13986 ---\n",
            "a b, which means ak+1 ← (1 – α) · ak + α ·bk. So, the first line of Equation 18-4 can\n",
            "\n",
            "--- Chunk 13987 ---\n",
            "α\n",
            "be rewritten like this: V s r + γ · V s′ .\n",
            "\n",
            "α\n",
            "\n",
            "--- Chunk 13988 ---\n",
            "TD Learning has many similarities with Stochastic Gradient\n",
            "Descent, in particular the fact that it handles one sample at a time.\n",
            "\n",
            "--- Chunk 13989 ---\n",
            "Moreover, just like Stochastic GD, it can only truly converge if you\n",
            "gradually reduce the learning rate (otherwise it will keep bouncing\n",
            "\n",
            "--- Chunk 13990 ---\n",
            "around the optimum Q-Values).\n",
            "\n",
            "--- Chunk 13991 ---\n",
            "For each state s, this algorithm simply keeps track of a running average of the imme‐\n",
            "\n",
            "--- Chunk 13992 ---\n",
            "diate rewards the agent gets upon leaving that state, plus the rewards it expects to get\n",
            "later (assuming it acts optimally).\n",
            "\n",
            "--- Chunk 13993 ---\n",
            "Q-Learning\n",
            "Similarly, the Q-Learning algorithm is an adaptation of the Q-Value Iteration algo‐\n",
            "\n",
            "--- Chunk 13994 ---\n",
            "rithm to the situation where the transition probabilities and the rewards are initially\n",
            "\n",
            "--- Chunk 13995 ---\n",
            "unknown (see Equation 18-5). Q-Learning works by watching an agent play (e.g.,\n",
            "\n",
            "--- Chunk 13996 ---\n",
            "randomly) and gradually improving its estimates of the Q-Values. Once it has\n",
            "\n",
            "--- Chunk 13997 ---\n",
            "630 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 13998 ---\n",
            "accurate Q-Value estimates (or close enough), then the optimal policy is choosing the\n",
            "action that has the highest Q-Value (i.e., the greedy policy).\n",
            "\n",
            "--- Chunk 13999 ---\n",
            "Equation 18-5. Q-Learning algorithm\n",
            "\n",
            "Q s, a r + γ · max   Q s′, a′\n",
            "α a′\n",
            "\n",
            "--- Chunk 14000 ---\n",
            "For each state-action pair (s, a), this algorithm keeps track of a running average of the\n",
            "\n",
            "--- Chunk 14001 ---\n",
            "rewards r the agent gets upon leaving the state s with action a, plus the sum of dis‐\n",
            "\n",
            "--- Chunk 14002 ---\n",
            "counted future rewards it expects to get. To estimate this sum, we take the maximum\n",
            "\n",
            "--- Chunk 14003 ---\n",
            "of the Q-Value estimates for the next state s′, since we assume that the target policy\n",
            "would act optimally from then on.\n",
            "\n",
            "--- Chunk 14004 ---\n",
            "Let’s implement the Q-Learning algorithm. First, we will need to make an agent\n",
            "\n",
            "--- Chunk 14005 ---\n",
            "explore the environment. For this, we need a step function so that the agent can exe‐\n",
            "cute one action and get the resulting state and reward:\n",
            "\n",
            "--- Chunk 14006 ---\n",
            "def step(state, action):\n",
            "    probas = transition_probabilities[state][action]\n",
            "    next_state = np.random.choice([0, 1, 2], p=probas)\n",
            "\n",
            "--- Chunk 14007 ---\n",
            "reward = rewards[state][action][next_state]\n",
            "    return next_state, reward\n",
            "\n",
            "--- Chunk 14008 ---\n",
            "Now let’s implement the agent’s exploration policy. Since the state space is pretty\n",
            "\n",
            "--- Chunk 14009 ---\n",
            "small, a simple random policy will be sufficient. If we run the algorithm for long\n",
            "\n",
            "--- Chunk 14010 ---\n",
            "enough, the agent will visit every state many times, and it will also try every possible\n",
            "action many times:\n",
            "\n",
            "--- Chunk 14011 ---\n",
            "def exploration_policy(state):\n",
            "    return np.random.choice(possible_actions[state])\n",
            "\n",
            "--- Chunk 14012 ---\n",
            "Next, after we initialize the Q-Values just like earlier, we are ready to run the Q-\n",
            "\n",
            "--- Chunk 14013 ---\n",
            "Learning algorithm with learning rate decay (using power scheduling, introduced in\n",
            "Chapter 11):\n",
            "\n",
            "--- Chunk 14014 ---\n",
            "alpha0 = 0.05 # initial learning rate\n",
            "decay = 0.005 # learning rate decay\n",
            "gamma = 0.90 # discount factor\n",
            "state = 0 # initial state\n",
            "\n",
            "--- Chunk 14015 ---\n",
            "for iteration in range(10000):\n",
            "    action = exploration_policy(state)\n",
            "    next_state, reward = step(state, action)\n",
            "\n",
            "--- Chunk 14016 ---\n",
            "next_value = np.max(Q_values[next_state])\n",
            "    alpha = alpha0 / (1 + iteration * decay)\n",
            "    Q_values[state, action] *= 1 - alpha\n",
            "\n",
            "--- Chunk 14017 ---\n",
            "Q_values[state, action] += alpha * (reward + gamma * next_value)\n",
            "    state = next_state\n",
            "\n",
            "--- Chunk 14018 ---\n",
            "Q-Learning | 631\n",
            "\n",
            "--- Chunk 14019 ---\n",
            "This algorithm will converge to the optimal Q-Values, but it will take many iterations,\n",
            "\n",
            "--- Chunk 14020 ---\n",
            "and possibly quite a lot of hyperparameter tuning. As you can see in Figure 18-9, the\n",
            "\n",
            "--- Chunk 14021 ---\n",
            "Q-Value Iteration algorithm (left) converges very quickly, in fewer than 20 iterations,\n",
            "\n",
            "--- Chunk 14022 ---\n",
            "while the Q-Learning algorithm (right) takes about 8,000 iterations to converge.\n",
            "\n",
            "--- Chunk 14023 ---\n",
            "Obviously, not knowing the transition probabilities or the rewards makes finding the\n",
            "optimal policy significantly harder!\n",
            "\n",
            "--- Chunk 14024 ---\n",
            "Figure 18-9. The Q-Value Iteration algorithm (left) versus the Q-Learning algorithm\n",
            "(right)\n",
            "\n",
            "--- Chunk 14025 ---\n",
            "The Q-Learning algorithm is called an off-policy algorithm because the policy being\n",
            "\n",
            "--- Chunk 14026 ---\n",
            "trained is not necessarily the one being executed: in the previous code example, the\n",
            "\n",
            "--- Chunk 14027 ---\n",
            "policy being executed (the exploration policy) is completely random, while the policy\n",
            "\n",
            "--- Chunk 14028 ---\n",
            "being trained will always choose the actions with the highest Q-Values. Conversely,\n",
            "\n",
            "--- Chunk 14029 ---\n",
            "the Policy Gradients algorithm is an on-policy algorithm: it explores the world using\n",
            "\n",
            "--- Chunk 14030 ---\n",
            "the policy being trained. It is somewhat surprising that Q-Learning is capable of\n",
            "\n",
            "--- Chunk 14031 ---\n",
            "learning the optimal policy by just watching an agent act randomly (imagine learning\n",
            "\n",
            "--- Chunk 14032 ---\n",
            "to play golf when your teacher is a drunk monkey). Can we do better?\n",
            "\n",
            "--- Chunk 14033 ---\n",
            "Exploration Policies\n",
            "Of course, Q-Learning can work only if the exploration policy explores the MDP\n",
            "\n",
            "--- Chunk 14034 ---\n",
            "thoroughly enough. Although a purely random policy is guaranteed to eventually\n",
            "\n",
            "--- Chunk 14035 ---\n",
            "visit every state and every transition many times, it may take an extremely long time\n",
            "\n",
            "--- Chunk 14036 ---\n",
            "to do so. Therefore, a better option is to use the ε-greedy policy (ε is epsilon): at each\n",
            "\n",
            "--- Chunk 14037 ---\n",
            "step it acts randomly with probability ε, or greedily with probability 1–ε (i.e., choos‐\n",
            "\n",
            "--- Chunk 14038 ---\n",
            "ing the action with the highest Q-Value). The advantage of the ε-greedy policy (com‐\n",
            "\n",
            "--- Chunk 14039 ---\n",
            "pared to a completely random policy) is that it will spend more and more time\n",
            "\n",
            "--- Chunk 14040 ---\n",
            "exploring the interesting parts of the environment, as the Q-Value estimates get better\n",
            "\n",
            "--- Chunk 14041 ---\n",
            "and better, while still spending some time visiting unknown regions of the MDP. It is\n",
            "\n",
            "--- Chunk 14042 ---\n",
            "quite common to start with a high value for ε (e.g., 1.0) and then gradually reduce it\n",
            "(e.g., down to 0.05).\n",
            "\n",
            "--- Chunk 14043 ---\n",
            "632 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 14044 ---\n",
            "Alternatively, rather than relying only on chance for exploration, another approach is\n",
            "\n",
            "--- Chunk 14045 ---\n",
            "to encourage the exploration policy to try actions that it has not tried much before.\n",
            "\n",
            "--- Chunk 14046 ---\n",
            "This can be implemented as a bonus added to the Q-Value estimates, as shown in\n",
            "Equation 18-6.\n",
            "\n",
            "--- Chunk 14047 ---\n",
            "Equation 18-6. Q-Learning using an exploration function\n",
            "\n",
            "Q s, a r + γ · max   f Q s′, a′ , N s′, a′\n",
            "α a′\n",
            "\n",
            "In this equation:\n",
            "\n",
            "--- Chunk 14048 ---\n",
            "• N(s′, a′) counts the number of times the action a′ was chosen in state s′.\n",
            "\n",
            "--- Chunk 14049 ---\n",
            "• f(Q, N) is an exploration function, such as f(Q, N) = Q + κ/(1 + N), where κ is a\n",
            "\n",
            "--- Chunk 14050 ---\n",
            "curiosity hyperparameter that measures how much the agent is attracted to the\n",
            "unknown.\n",
            "\n",
            "--- Chunk 14051 ---\n",
            "Approximate Q-Learning and Deep Q-Learning\n",
            "The main problem with Q-Learning is that it does not scale well to large (or even\n",
            "\n",
            "--- Chunk 14052 ---\n",
            "medium) MDPs with many states and actions. For example, suppose you wanted to\n",
            "\n",
            "--- Chunk 14053 ---\n",
            "use Q-Learning to train an agent to play Ms. Pac-Man (see Figure 18-1). There are\n",
            "\n",
            "--- Chunk 14054 ---\n",
            "about 150 pellets that Ms. Pac-Man can eat, each of which can be present or absent\n",
            "\n",
            "--- Chunk 14055 ---\n",
            "(i.e., already eaten). So, the number of possible states is greater than 2150 ≈ 1045. And if\n",
            "\n",
            "--- Chunk 14056 ---\n",
            "you add all the possible combinations of positions for all the ghosts and Ms. Pac-\n",
            "\n",
            "--- Chunk 14057 ---\n",
            "Man, the number of possible states becomes larger than the number of atoms in our\n",
            "\n",
            "--- Chunk 14058 ---\n",
            "planet, so there’s absolutely no way you can keep track of an estimate for every single\n",
            "Q-Value.\n",
            "\n",
            "--- Chunk 14059 ---\n",
            "Q-Value.\n",
            "The solution is to find a function Qθ(s, a) that approximates the Q-Value of any state-\n",
            "\n",
            "--- Chunk 14060 ---\n",
            "action pair (s, a) using a manageable number of parameters (given by the parameter\n",
            "\n",
            "--- Chunk 14061 ---\n",
            "vector θ). This is called Approximate Q-Learning. For years it was recommended to\n",
            "\n",
            "--- Chunk 14062 ---\n",
            "use linear combinations of handcrafted features extracted from the state (e.g., dis‐\n",
            "\n",
            "--- Chunk 14063 ---\n",
            "tance of the closest ghosts, their directions, and so on) to estimate Q-Values, but in\n",
            "\n",
            "--- Chunk 14064 ---\n",
            "2013, DeepMind showed that using deep neural networks can work much better,\n",
            "\n",
            "--- Chunk 14065 ---\n",
            "especially for complex problems, and it does not require any feature engineering. A\n",
            "\n",
            "--- Chunk 14066 ---\n",
            "DNN used to estimate Q-Values is called a Deep Q-Network (DQN), and using a\n",
            "DQN for Approximate Q-Learning is called Deep Q-Learning.\n",
            "\n",
            "--- Chunk 14067 ---\n",
            "Now, how can we train a DQN? Well, consider the approximate Q-Value computed\n",
            "\n",
            "--- Chunk 14068 ---\n",
            "by the DQN for a given state-action pair (s, a). Thanks to Bellman, we know we want\n",
            "\n",
            "--- Chunk 14069 ---\n",
            "this approximate Q-Value to be as close as possible to the reward r that we actually\n",
            "\n",
            "--- Chunk 14070 ---\n",
            "observe after playing action a in state s, plus the discounted value of playing optimally\n",
            "\n",
            "--- Chunk 14071 ---\n",
            "Q-Learning | 633\n",
            "\n",
            "--- Chunk 14072 ---\n",
            "from then on. To estimate this sum of future discounted rewards, we can simply exe‐\n",
            "\n",
            "--- Chunk 14073 ---\n",
            "cute the DQN on the next state s′ and for all possible actions a′. We get an approxi‐\n",
            "\n",
            "--- Chunk 14074 ---\n",
            "mate future Q-Value for each possible action. We then pick the highest (since we\n",
            "\n",
            "--- Chunk 14075 ---\n",
            "assume we will be playing optimally) and discount it, and this gives us an estimate of\n",
            "\n",
            "--- Chunk 14076 ---\n",
            "the sum of future discounted rewards. By summing the reward r and the future dis‐\n",
            "\n",
            "--- Chunk 14077 ---\n",
            "counted value estimate, we get a target Q-Value y(s, a) for the state-action pair (s, a),\n",
            "as shown in Equation 18-7.\n",
            "\n",
            "--- Chunk 14078 ---\n",
            "Equation 18-7. Target Q-Value\n",
            "\n",
            "Qtarget s, a = r + γ · max   Qθ s′, a′\n",
            "a′\n",
            "\n",
            "--- Chunk 14079 ---\n",
            "With this target Q-Value, we can run a training step using any Gradient Descent algo‐\n",
            "\n",
            "--- Chunk 14080 ---\n",
            "rithm. Specifically, we generally try to minimize the squared error between the esti‐\n",
            "\n",
            "--- Chunk 14081 ---\n",
            "mated Q-Value Q(s, a) and the target Q-Value (or the Huber loss to reduce the\n",
            "\n",
            "--- Chunk 14082 ---\n",
            "algorithm’s sensitivity to large errors). And that’s all for the basic Deep Q-Learning\n",
            "\n",
            "--- Chunk 14083 ---\n",
            "algorithm! Let’s see how to implement it to solve the CartPole environment.\n",
            "\n",
            "--- Chunk 14084 ---\n",
            "Implementing Deep Q-Learning\n",
            "The first thing we need is a Deep Q-Network. In theory, you need a neural net that\n",
            "\n",
            "--- Chunk 14085 ---\n",
            "takes a state-action pair and outputs an approximate Q-Value, but in practice it’s\n",
            "\n",
            "--- Chunk 14086 ---\n",
            "much more efficient to use a neural net that takes a state and outputs one approxi‐\n",
            "\n",
            "--- Chunk 14087 ---\n",
            "mate Q-Value for each possible action. To solve the CartPole environment, we do not\n",
            "\n",
            "--- Chunk 14088 ---\n",
            "need a very complicated neural net; a couple of hidden layers will do:\n",
            "\n",
            "--- Chunk 14089 ---\n",
            "env = gym.make(\"CartPole-v0\")\n",
            "input_shape = [4] # == env.observation_space.shape\n",
            "n_outputs = 2 # == env.action_space.n\n",
            "\n",
            "--- Chunk 14090 ---\n",
            "model = keras.models.Sequential([\n",
            "    keras.layers.Dense(32, activation=\"elu\", input_shape=input_shape),\n",
            "\n",
            "--- Chunk 14091 ---\n",
            "keras.layers.Dense(32, activation=\"elu\"),\n",
            "    keras.layers.Dense(n_outputs)\n",
            "])\n",
            "\n",
            "--- Chunk 14092 ---\n",
            "To select an action using this DQN, we pick the action with the largest predicted Q-\n",
            "\n",
            "--- Chunk 14093 ---\n",
            "Value. To ensure that the agent explores the environment, we will use an ε-greedy\n",
            "policy (i.e., we will choose a random action with probability ε):\n",
            "\n",
            "--- Chunk 14094 ---\n",
            "def epsilon_greedy_policy(state, epsilon=0):\n",
            "    if np.random.rand() < epsilon:\n",
            "        return np.random.randint(2)\n",
            "    else:\n",
            "\n",
            "--- Chunk 14095 ---\n",
            "else:\n",
            "        Q_values = model.predict(state[np.newaxis])\n",
            "        return np.argmax(Q_values[0])\n",
            "\n",
            "--- Chunk 14096 ---\n",
            "634 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 14097 ---\n",
            "Instead of training the DQN based only on the latest experiences, we will store all\n",
            "\n",
            "--- Chunk 14098 ---\n",
            "experiences in a replay buffer (or replay memory), and we will sample a random train‐\n",
            "\n",
            "--- Chunk 14099 ---\n",
            "ing batch from it at each training iteration. This helps reduce the correlations\n",
            "\n",
            "--- Chunk 14100 ---\n",
            "between the experiences in a training batch, which tremendously helps training. For\n",
            "this, we will just use a deque list:\n",
            "\n",
            "--- Chunk 14101 ---\n",
            "from collections import deque\n",
            "\n",
            "replay_buffer = deque(maxlen=2000)\n",
            "\n",
            "--- Chunk 14102 ---\n",
            "A deque is a linked list, where each element points to the next one\n",
            "and to the previous one. It makes inserting and deleting items very\n",
            "\n",
            "--- Chunk 14103 ---\n",
            "fast, but the longer the deque is, the slower random access will be.\n",
            "If you need a very large replay buffer, use a circular buffer; see the\n",
            "\n",
            "--- Chunk 14104 ---\n",
            "“Deque vs Rotating List” section of the notebook for an\n",
            "implementation.\n",
            "\n",
            "--- Chunk 14105 ---\n",
            "Each experience will be composed of five elements: a state, the action the agent took,\n",
            "\n",
            "--- Chunk 14106 ---\n",
            "the resulting reward, the next state it reached, and finally a Boolean indicating\n",
            "\n",
            "--- Chunk 14107 ---\n",
            "whether the episode ended at that point (done). We will need a small function to sam‐\n",
            "\n",
            "--- Chunk 14108 ---\n",
            "ple a random batch of experiences from the replay buffer. It will return five NumPy\n",
            "arrays corresponding to the five experience elements:\n",
            "\n",
            "--- Chunk 14109 ---\n",
            "def sample_experiences(batch_size):\n",
            "    indices = np.random.randint(len(replay_buffer), size=batch_size)\n",
            "\n",
            "--- Chunk 14110 ---\n",
            "batch = [replay_buffer[index] for index in indices]\n",
            "    states, actions, rewards, next_states, dones = [\n",
            "\n",
            "--- Chunk 14111 ---\n",
            "np.array([experience[field_index] for experience in batch])\n",
            "        for field_index in range(5)]\n",
            "\n",
            "--- Chunk 14112 ---\n",
            "return states, actions, rewards, next_states, dones\n",
            "\n",
            "--- Chunk 14113 ---\n",
            "Let’s also create a function that will play a single step using the ε-greedy policy, then\n",
            "store the resulting experience in the replay buffer:\n",
            "\n",
            "--- Chunk 14114 ---\n",
            "def play_one_step(env, state, epsilon):\n",
            "    action = epsilon_greedy_policy(state, epsilon)\n",
            "    next_state, reward, done, info = env.step(action)\n",
            "\n",
            "--- Chunk 14115 ---\n",
            "replay_buffer.append((state, action, reward, next_state, done))\n",
            "    return next_state, reward, done, info\n",
            "\n",
            "--- Chunk 14116 ---\n",
            "Finally, let’s create one last function that will sample a batch of experiences from the\n",
            "\n",
            "--- Chunk 14117 ---\n",
            "replay buffer and train the DQN by performing a single Gradient Descent step on this\n",
            "batch:\n",
            "\n",
            "--- Chunk 14118 ---\n",
            "batch_size = 32\n",
            "discount_factor = 0.95\n",
            "optimizer = keras.optimizers.Adam(lr=1e-3)\n",
            "loss_fn = keras.losses.mean_squared_error\n",
            "\n",
            "--- Chunk 14119 ---\n",
            "Implementing Deep Q-Learning | 635\n",
            "\n",
            "--- Chunk 14120 ---\n",
            "def training_step(batch_size):\n",
            "    experiences = sample_experiences(batch_size)\n",
            "    states, actions, rewards, next_states, dones = experiences\n",
            "\n",
            "--- Chunk 14121 ---\n",
            "next_Q_values = model.predict(next_states)\n",
            "    max_next_Q_values = np.max(next_Q_values, axis=1)\n",
            "    target_Q_values = (rewards +\n",
            "\n",
            "--- Chunk 14122 ---\n",
            "(1 - dones) * discount_factor * max_next_Q_values)\n",
            "    mask = tf.one_hot(actions, n_outputs)\n",
            "\n",
            "--- Chunk 14123 ---\n",
            "with tf.GradientTape() as tape:\n",
            "        all_Q_values = model(states)\n",
            "        Q_values = tf.reduce_sum(all_Q_values * mask, axis=1, keepdims=True)\n",
            "\n",
            "--- Chunk 14124 ---\n",
            "loss = tf.reduce_mean(loss_fn(target_Q_values, Q_values))\n",
            "    grads = tape.gradient(loss, model.trainable_variables)\n",
            "\n",
            "--- Chunk 14125 ---\n",
            "optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
            "\n",
            "--- Chunk 14126 ---\n",
            "Let’s go through this code:\n",
            "\n",
            "• First we define some hyperparameters, and we create the optimizer and the loss\n",
            "function.\n",
            "\n",
            "--- Chunk 14127 ---\n",
            "• Then we create the training_step() function. It starts by sampling a batch of\n",
            "\n",
            "--- Chunk 14128 ---\n",
            "experiences, then it uses the DQN to predict the Q-Value for each possible action\n",
            "\n",
            "--- Chunk 14129 ---\n",
            "in each experience’s next state. Since we assume that the agent will be playing\n",
            "\n",
            "--- Chunk 14130 ---\n",
            "optimally, we only keep the maximum Q-Value for each next state. Next, we use\n",
            "\n",
            "--- Chunk 14131 ---\n",
            "Equation 18-7 to compute the target Q-Value for each experience’s state-action\n",
            "pair.\n",
            "\n",
            "--- Chunk 14132 ---\n",
            "• Next, we want to use the DQN to compute the Q-Value for each experienced\n",
            "\n",
            "--- Chunk 14133 ---\n",
            "state-action pair. However, the DQN will also output the Q-Values for the other\n",
            "\n",
            "--- Chunk 14134 ---\n",
            "possible actions, not just for the action that was actually chosen by the agent. So\n",
            "\n",
            "--- Chunk 14135 ---\n",
            "we need to mask out all the Q-Values we do not need. The tf.one_hot() func‐\n",
            "\n",
            "--- Chunk 14136 ---\n",
            "tion makes it easy to convert an array of action indices into such a mask. For\n",
            "\n",
            "--- Chunk 14137 ---\n",
            "example, if the first three experiences contain actions 1, 1, 0, respectively, then\n",
            "\n",
            "--- Chunk 14138 ---\n",
            "the mask will start with [[0, 1], [0, 1], [1, 0],...]. We can then multiply\n",
            "\n",
            "--- Chunk 14139 ---\n",
            "the DQN’s output with this mask, and this will zero out all the Q-Values we do\n",
            "\n",
            "--- Chunk 14140 ---\n",
            "not want. We then sum over axis 1 to get rid of all the zeros, keeping only the Q-\n",
            "\n",
            "--- Chunk 14141 ---\n",
            "Values of the experienced state-action pairs. This gives us the Q_values tensor,\n",
            "containing one predicted Q-Value for each experience in the batch.\n",
            "\n",
            "--- Chunk 14142 ---\n",
            "• Then we compute the loss: it is the mean squared error between the target and\n",
            "predicted Q-Values for the experienced state-action pairs.\n",
            "\n",
            "--- Chunk 14143 ---\n",
            "• Finally, we perform a Gradient Descent step to minimize the loss with regard to\n",
            "the model’s trainable variables.\n",
            "\n",
            "--- Chunk 14144 ---\n",
            "This was the hardest part. Now training the model is straightforward:\n",
            "\n",
            "636 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 14145 ---\n",
            "for episode in range(600):\n",
            "    obs = env.reset()\n",
            "    for step in range(200):\n",
            "        epsilon = max(1 - episode / 500, 0.01)\n",
            "\n",
            "--- Chunk 14146 ---\n",
            "obs, reward, done, info = play_one_step(env, obs, epsilon)\n",
            "        if done:\n",
            "            break\n",
            "    if episode > 50:\n",
            "\n",
            "--- Chunk 14147 ---\n",
            "training_step(batch_size)\n",
            "\n",
            "--- Chunk 14148 ---\n",
            "We run 600 episodes, each for a maximum of 200 steps. At each step, we first com‐\n",
            "\n",
            "--- Chunk 14149 ---\n",
            "pute the epsilon value for the ε-greedy policy: it will go from 1 down to 0.01, line‐\n",
            "\n",
            "--- Chunk 14150 ---\n",
            "arly, in a bit under 500 episodes. Then we call the play_one_step() function, which\n",
            "\n",
            "--- Chunk 14151 ---\n",
            "will use the ε-greedy policy to pick an action, then execute it and record the experi‐\n",
            "\n",
            "--- Chunk 14152 ---\n",
            "ence in the replay buffer. If the episode is done, we exit the loop. Finally, if we are past\n",
            "\n",
            "--- Chunk 14153 ---\n",
            "the 50th episode, we call the training_step() function to train the model on one\n",
            "\n",
            "--- Chunk 14154 ---\n",
            "batch sampled from the replay buffer. The reason we play 50 episodes without train‐\n",
            "\n",
            "--- Chunk 14155 ---\n",
            "ing is to give the replay buffer some time to fill up (if we don’t wait enough, then\n",
            "\n",
            "--- Chunk 14156 ---\n",
            "there will not be enough diversity in the replay buffer). And that’s it, we just imple‐\n",
            "mented the Deep Q-Learning algorithm!\n",
            "\n",
            "--- Chunk 14157 ---\n",
            "Figure 18-10 shows the total rewards the agent got during each episode.\n",
            "\n",
            "--- Chunk 14158 ---\n",
            "Figure 18-10. Learning curve of the Deep Q-Learning algorithm\n",
            "\n",
            "--- Chunk 14159 ---\n",
            "As you can see, the algorithm made no apparent progress at all for almost 300 epi‐\n",
            "\n",
            "--- Chunk 14160 ---\n",
            "sodes (in part because ε was very high at the beginning), then its performance sud‐\n",
            "\n",
            "--- Chunk 14161 ---\n",
            "denly skyrocketed up to 200 (which is the maximum possible performance in this\n",
            "\n",
            "--- Chunk 14162 ---\n",
            "environment). That’s great news: the algorithm worked fine, and it actually ran much\n",
            "\n",
            "--- Chunk 14163 ---\n",
            "faster than the Policy Gradient algorithm! But wait… just a few episodes later, it for‐\n",
            "\n",
            "--- Chunk 14164 ---\n",
            "got everything it knew, and its performance dropped below 25! This is called\n",
            "\n",
            "--- Chunk 14165 ---\n",
            "Implementing Deep Q-Learning | 637\n",
            "\n",
            "--- Chunk 14166 ---\n",
            "catastrophic forgetting, and it is one of the big problems facing virtually all RL algo‐\n",
            "\n",
            "--- Chunk 14167 ---\n",
            "rithms: as the agent explores the environment, it updates its policy, but what it learns\n",
            "\n",
            "--- Chunk 14168 ---\n",
            "in one part of the environment may break what it learned earlier in other parts of the\n",
            "\n",
            "--- Chunk 14169 ---\n",
            "environment. The experiences are quite correlated, and the learning environment\n",
            "\n",
            "--- Chunk 14170 ---\n",
            "keeps changing—this is not ideal for Gradient Descent! If you increase the size of the\n",
            "\n",
            "--- Chunk 14171 ---\n",
            "replay buffer, the algorithm will be less subject to this problem. Reducing the learning\n",
            "\n",
            "--- Chunk 14172 ---\n",
            "rate may also help. But the truth is, Reinforcement Learning is hard: training is often\n",
            "\n",
            "--- Chunk 14173 ---\n",
            "unstable, and you may need to try many hyperparameter values and random seeds\n",
            "\n",
            "--- Chunk 14174 ---\n",
            "before you find a combination that works well. For example, if you try changing the\n",
            "\n",
            "--- Chunk 14175 ---\n",
            "number of neurons per layer in the preceding from 32 to 30 or 34, the performance\n",
            "\n",
            "--- Chunk 14176 ---\n",
            "will never go above 100 (the DQN may be more stable with one hidden layer instead\n",
            "of two).\n",
            "\n",
            "--- Chunk 14177 ---\n",
            "Reinforcement Learning is notoriously difficult, largely because of\n",
            "the training instabilities and the huge sensitivity to the choice of\n",
            "\n",
            "--- Chunk 14178 ---\n",
            "hyperparameter values and random seeds.13 As the researcher\n",
            "Andrej Karpathy put it: “[Supervised learning] wants to work. […]\n",
            "\n",
            "--- Chunk 14179 ---\n",
            "RL must be forced to work.” You will need time, patience, persever‐\n",
            "ance, and perhaps a bit of luck too. This is a major reason RL is not\n",
            "\n",
            "--- Chunk 14180 ---\n",
            "as widely adopted as regular Deep Learning (e.g., convolutional\n",
            "nets). But there are a few real-world applications, beyond AlphaGo\n",
            "\n",
            "--- Chunk 14181 ---\n",
            "and Atari games: for example, Google uses RL to optimize its data‐\n",
            "center costs, and it is used in some robotics applications, for hyper‐\n",
            "\n",
            "--- Chunk 14182 ---\n",
            "parameter tuning, and in recommender systems.\n",
            "\n",
            "--- Chunk 14183 ---\n",
            "You might wonder why we didn’t plot the loss. It turns out that loss is a poor indicator\n",
            "\n",
            "--- Chunk 14184 ---\n",
            "of the model’s performance. The loss might go down, yet the agent might perform\n",
            "\n",
            "--- Chunk 14185 ---\n",
            "worse (e.g., this can happen when the agent gets stuck in one small region of the envi‐\n",
            "\n",
            "--- Chunk 14186 ---\n",
            "ronment, and the DQN starts overfitting this region). Conversely, the loss could go\n",
            "\n",
            "--- Chunk 14187 ---\n",
            "up, yet the agent might perform better (e.g., if the DQN was underestimating the Q-\n",
            "\n",
            "--- Chunk 14188 ---\n",
            "Values, and it starts correctly increasing its predictions, the agent will likely perform\n",
            "\n",
            "--- Chunk 14189 ---\n",
            "better, getting more rewards, but the loss might increase because the DQN also sets\n",
            "the targets, which will be larger too).\n",
            "\n",
            "--- Chunk 14190 ---\n",
            "The basic Deep Q-Learning algorithm we’ve been using so far would be too unstable\n",
            "\n",
            "--- Chunk 14191 ---\n",
            "to learn to play Atari games. So how did DeepMind do it? Well, they tweaked the\n",
            "algorithm!\n",
            "\n",
            "--- Chunk 14192 ---\n",
            "13 A great 2018 post by Alex Irpan nicely lays out RL’s biggest difficulties and limitations.\n",
            "\n",
            "638 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 14193 ---\n",
            "Deep Q-Learning Variants\n",
            "Let’s look at a few variants of the Deep Q-Learning algorithm that can stabilize and\n",
            "speed up training.\n",
            "\n",
            "--- Chunk 14194 ---\n",
            "Fixed Q-Value Targets\n",
            "In the basic Deep Q-Learning algorithm, the model is used both to make predictions\n",
            "\n",
            "--- Chunk 14195 ---\n",
            "and to set its own targets. This can lead to a situation analogous to a dog chasing its\n",
            "\n",
            "--- Chunk 14196 ---\n",
            "own tail. This feedback loop can make the network unstable: it can diverge, oscillate,\n",
            "\n",
            "--- Chunk 14197 ---\n",
            "freeze, and so on. To solve this problem, in their 2013 paper the DeepMind research‐\n",
            "\n",
            "--- Chunk 14198 ---\n",
            "ers used two DQNs instead of one: the first is the online model, which learns at each\n",
            "\n",
            "--- Chunk 14199 ---\n",
            "step and is used to move the agent around, and the other is the target model used only\n",
            "\n",
            "--- Chunk 14200 ---\n",
            "to define the targets. The target model is just a clone of the online model:\n",
            "\n",
            "--- Chunk 14201 ---\n",
            "target = keras.models.clone_model(model)\n",
            "target.set_weights(model.get_weights())\n",
            "\n",
            "--- Chunk 14202 ---\n",
            "Then, in the training_step() function, we just need to change one line to use the\n",
            "\n",
            "--- Chunk 14203 ---\n",
            "target model instead of the online model when computing the Q-Values of the next\n",
            "states:\n",
            "\n",
            "--- Chunk 14204 ---\n",
            "next_Q_values = target.predict(next_states)\n",
            "\n",
            "--- Chunk 14205 ---\n",
            "Finally, in the training loop, we must copy the weights of the online model to the tar‐\n",
            "get model, at regular intervals (e.g., every 50 episodes):\n",
            "\n",
            "--- Chunk 14206 ---\n",
            "if episode % 50 == 0:\n",
            "    target.set_weights(model.get_weights())\n",
            "\n",
            "--- Chunk 14207 ---\n",
            "Since the target model is updated much less often than the online model, the Q-Value\n",
            "\n",
            "--- Chunk 14208 ---\n",
            "targets are more stable, the feedback loop we discussed earlier is dampened, and its\n",
            "\n",
            "--- Chunk 14209 ---\n",
            "effects are less severe. This approach was one of the DeepMind researchers’ main\n",
            "\n",
            "--- Chunk 14210 ---\n",
            "contributions in their 2013 paper, allowing agents to learn to play Atari games from\n",
            "\n",
            "--- Chunk 14211 ---\n",
            "raw pixels. To stabilize training, they used a tiny learning rate of 0.00025, they upda‐\n",
            "\n",
            "--- Chunk 14212 ---\n",
            "ted the target model only every 10,000 steps (instead of the 50 in the previous code\n",
            "\n",
            "--- Chunk 14213 ---\n",
            "example), and they used a very large replay buffer of 1 million experiences. They\n",
            "\n",
            "--- Chunk 14214 ---\n",
            "decreased epsilon very slowly, from 1 to 0.1 in 1 million steps, and they let the algo‐\n",
            "rithm run for 50 million steps.\n",
            "\n",
            "--- Chunk 14215 ---\n",
            "Later in this chapter, we will use the TF-Agents library to train a DQN agent to play\n",
            "\n",
            "--- Chunk 14216 ---\n",
            "Breakout using these hyperparameters, but before we get there, let’s take a look at\n",
            "\n",
            "--- Chunk 14217 ---\n",
            "another DQN variant that managed to beat the state of the art once more.\n",
            "\n",
            "--- Chunk 14218 ---\n",
            "Deep Q-Learning Variants | 639\n",
            "\n",
            "--- Chunk 14219 ---\n",
            "Double DQN\n",
            "In a 2015 paper,14 DeepMind researchers tweaked their DQN algorithm, increasing\n",
            "\n",
            "--- Chunk 14220 ---\n",
            "its performance and somewhat stabilizing training. They called this variant Double\n",
            "\n",
            "--- Chunk 14221 ---\n",
            "DQN. The update was based on the observation that the target network is prone to\n",
            "\n",
            "--- Chunk 14222 ---\n",
            "overestimating Q-Values. Indeed, suppose all actions are equally good: the Q-Values\n",
            "\n",
            "--- Chunk 14223 ---\n",
            "estimated by the target model should be identical, but since they are approximations,\n",
            "\n",
            "--- Chunk 14224 ---\n",
            "some may be slightly greater than others, by pure chance. The target model will\n",
            "\n",
            "--- Chunk 14225 ---\n",
            "always select the largest Q-Value, which will be slightly greater than the mean Q-\n",
            "\n",
            "--- Chunk 14226 ---\n",
            "Value, most likely overestimating the true Q-Value (a bit like counting the height of\n",
            "\n",
            "--- Chunk 14227 ---\n",
            "the tallest random wave when measuring the depth of a pool). To fix this, they pro‐\n",
            "\n",
            "--- Chunk 14228 ---\n",
            "posed using the online model instead of the target model when selecting the best\n",
            "\n",
            "--- Chunk 14229 ---\n",
            "actions for the next states, and using the target model only to estimate the Q-Values\n",
            "\n",
            "--- Chunk 14230 ---\n",
            "for these best actions. Here is the updated training_step() function:\n",
            "\n",
            "--- Chunk 14231 ---\n",
            "def training_step(batch_size):\n",
            "    experiences = sample_experiences(batch_size)\n",
            "    states, actions, rewards, next_states, dones = experiences\n",
            "\n",
            "--- Chunk 14232 ---\n",
            "next_Q_values = model.predict(next_states)\n",
            "    best_next_actions = np.argmax(next_Q_values, axis=1)\n",
            "\n",
            "--- Chunk 14233 ---\n",
            "next_mask = tf.one_hot(best_next_actions, n_outputs).numpy()\n",
            "    next_best_Q_values = (target.predict(next_states) * next_mask).sum(axis=1)\n",
            "\n",
            "--- Chunk 14234 ---\n",
            "target_Q_values = (rewards +\n",
            "                       (1 - dones) * discount_factor * next_best_Q_values)\n",
            "    mask = tf.one_hot(actions, n_outputs)\n",
            "\n",
            "--- Chunk 14235 ---\n",
            "[...] # the rest is the same as earlier\n",
            "\n",
            "--- Chunk 14236 ---\n",
            "Just a few months later, another improvement to the DQN algorithm was proposed.\n",
            "\n",
            "--- Chunk 14237 ---\n",
            "Prioritized Experience Replay\n",
            "Instead of sampling experiences uniformly from the replay buffer, why not sample\n",
            "\n",
            "--- Chunk 14238 ---\n",
            "important experiences more frequently? This idea is called importance sampling (IS)\n",
            "\n",
            "--- Chunk 14239 ---\n",
            "or prioritized experience replay (PER), and it was introduced in a 2015 paper15 by\n",
            "DeepMind researchers (once again!).\n",
            "\n",
            "--- Chunk 14240 ---\n",
            "More specifically, experiences are considered “important” if they are likely to lead to\n",
            "\n",
            "--- Chunk 14241 ---\n",
            "fast learning progress. But how can we estimate this? One reasonable approach is to\n",
            "\n",
            "--- Chunk 14242 ---\n",
            "measure the magnitude of the TD error δ = r + γ·V(s′) – V(s). A large TD error indi‐\n",
            "\n",
            "--- Chunk 14243 ---\n",
            "cates that a transition (s, r, s′) is very surprising, and thus probably worth learning\n",
            "\n",
            "--- Chunk 14244 ---\n",
            "14 Hado van Hasselt et al., “Deep Reinforcement Learning with Double Q-Learning,” Proceedings of the 30th\n",
            "\n",
            "--- Chunk 14245 ---\n",
            "AAAI Conference on Artificial Intelligence (2015): 2094–2100.\n",
            "\n",
            "--- Chunk 14246 ---\n",
            "15 Tom Schaul et al., “Prioritized Experience Replay,” arXiv preprint arXiv:1511.05952 (2015).\n",
            "\n",
            "640 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 14247 ---\n",
            "from.16 When an experience is recorded in the replay buffer, its priority is set to a very\n",
            "\n",
            "--- Chunk 14248 ---\n",
            "large value, to ensure that it gets sampled at least once. However, once it is sampled\n",
            "\n",
            "--- Chunk 14249 ---\n",
            "(and every time it is sampled), the TD error δ is computed, and this experience’s pri‐\n",
            "\n",
            "--- Chunk 14250 ---\n",
            "ority is set to p = |δ| (plus a small constant to ensure that every experience has a non-\n",
            "\n",
            "--- Chunk 14251 ---\n",
            "zero probability of being sampled). The probability P of sampling an experience with\n",
            "\n",
            "--- Chunk 14252 ---\n",
            "priority p is proportional to pζ, where ζ is a hyperparameter that controls how greedy\n",
            "\n",
            "--- Chunk 14253 ---\n",
            "we want importance sampling to be: when ζ = 0, we just get uniform sampling, and\n",
            "\n",
            "--- Chunk 14254 ---\n",
            "when ζ = 1, we get full-blown importance sampling. In the paper, the authors used ζ =\n",
            "0.6, but the optimal value will depend on the task.\n",
            "\n",
            "--- Chunk 14255 ---\n",
            "There’s one catch, though: since the samples will be biased toward important experi‐\n",
            "\n",
            "--- Chunk 14256 ---\n",
            "ences, we must compensate for this bias during training by downweighting the expe‐\n",
            "\n",
            "--- Chunk 14257 ---\n",
            "riences according to their importance, or else the model will just overfit the\n",
            "\n",
            "--- Chunk 14258 ---\n",
            "important experiences. To be clear, we want important experiences to be sampled\n",
            "\n",
            "--- Chunk 14259 ---\n",
            "more often, but this also means we must give them a lower weight during training. To\n",
            "\n",
            "--- Chunk 14260 ---\n",
            "do this, we define each experience’s training weight as w = (n P)–β, where n is the\n",
            "\n",
            "--- Chunk 14261 ---\n",
            "number of experiences in the replay buffer, and β is a hyperparameter that controls\n",
            "\n",
            "--- Chunk 14262 ---\n",
            "how much we want to compensate for the importance sampling bias (0 means not at\n",
            "\n",
            "--- Chunk 14263 ---\n",
            "all, while 1 means entirely). In the paper, the authors used β = 0.4 at the beginning of\n",
            "\n",
            "--- Chunk 14264 ---\n",
            "training and linearly increased it to β = 1 by the end of training. Again, the optimal\n",
            "\n",
            "--- Chunk 14265 ---\n",
            "value will depend on the task, but if you increase one, you will usually want to\n",
            "increase the other as well.\n",
            "\n",
            "--- Chunk 14266 ---\n",
            "Now let’s look at one last important variant of the DQN algorithm.\n",
            "\n",
            "--- Chunk 14267 ---\n",
            "Dueling DQN\n",
            "The Dueling DQN algorithm (DDQN, not to be confused with Double DQN,\n",
            "\n",
            "--- Chunk 14268 ---\n",
            "although both techniques can easily be combined) was introduced in yet another\n",
            "\n",
            "--- Chunk 14269 ---\n",
            "2015 paper17 by DeepMind researchers. To understand how it works, we must first\n",
            "\n",
            "--- Chunk 14270 ---\n",
            "note that the Q-Value of a state-action pair (s, a) can be expressed as Q(s, a) = V(s) +\n",
            "\n",
            "--- Chunk 14271 ---\n",
            "A(s, a), where V(s) is the value of state s and A(s, a) is the advantage of taking the\n",
            "\n",
            "--- Chunk 14272 ---\n",
            "action a in state s, compared to all other possible actions in that state. Moreover, the\n",
            "\n",
            "--- Chunk 14273 ---\n",
            "value of a state is equal to the Q-Value of the best action a* for that state (since we\n",
            "\n",
            "--- Chunk 14274 ---\n",
            "assume the optimal policy will pick the best action), so V(s) = Q(s, a*), which implies\n",
            "\n",
            "--- Chunk 14275 ---\n",
            "that A(s, a*) = 0. In a Dueling DQN, the model estimates both the value of the state\n",
            "\n",
            "--- Chunk 14276 ---\n",
            "and the advantage of each possible action. Since the best action should have an\n",
            "\n",
            "--- Chunk 14277 ---\n",
            "advantage of 0, the model subtracts the maximum predicted advantage from all pre‐\n",
            "\n",
            "--- Chunk 14278 ---\n",
            "16 It could also just be that the rewards are noisy, in which case there are better methods for estimating an expe‐\n",
            "\n",
            "--- Chunk 14279 ---\n",
            "rience’s importance (see the paper for some examples).\n",
            "\n",
            "--- Chunk 14280 ---\n",
            "17 Ziyu Wang et al., “Dueling Network Architectures for Deep Reinforcement Learning,” arXiv preprint arXiv:\n",
            "1511.06581 (2015).\n",
            "\n",
            "--- Chunk 14281 ---\n",
            "Deep Q-Learning Variants | 641\n",
            "\n",
            "\n",
            "\n",
            "dicted advantages. Here is a simple Dueling DQN model, implemented using the\n",
            "Functional API:\n",
            "\n",
            "--- Chunk 14282 ---\n",
            "K = keras.backend\n",
            "input_states = keras.layers.Input(shape=[4])\n",
            "hidden1 = keras.layers.Dense(32, activation=\"elu\")(input_states)\n",
            "\n",
            "--- Chunk 14283 ---\n",
            "hidden2 = keras.layers.Dense(32, activation=\"elu\")(hidden1)\n",
            "state_values = keras.layers.Dense(1)(hidden2)\n",
            "\n",
            "--- Chunk 14284 ---\n",
            "raw_advantages = keras.layers.Dense(n_outputs)(hidden2)\n",
            "advantages = raw_advantages - K.max(raw_advantages, axis=1, keepdims=True)\n",
            "\n",
            "--- Chunk 14285 ---\n",
            "Q_values = state_values + advantages\n",
            "model = keras.Model(inputs=[input_states], outputs=[Q_values])\n",
            "\n",
            "--- Chunk 14286 ---\n",
            "The rest of the algorithm is just the same as earlier. In fact, you can build a Double\n",
            "\n",
            "--- Chunk 14287 ---\n",
            "Dueling DQN and combine it with prioritized experience replay! More generally,\n",
            "\n",
            "--- Chunk 14288 ---\n",
            "many RL techniques can be combined, as DeepMind demonstrated in a 2017 paper.18\n",
            "\n",
            "--- Chunk 14289 ---\n",
            "The paper’s authors combined six different techniques into an agent called Rainbow,\n",
            "which largely outperformed the state of the art.\n",
            "\n",
            "--- Chunk 14290 ---\n",
            "Unfortunately, implementing all of these techniques, debugging them, fine-tuning\n",
            "\n",
            "--- Chunk 14291 ---\n",
            "them, and of course training the models can require a huge amount of work. So\n",
            "\n",
            "--- Chunk 14292 ---\n",
            "instead of reinventing the wheel, it is often best to reuse scalable and well-tested libra‐\n",
            "ries, such as TF-Agents.\n",
            "\n",
            "--- Chunk 14293 ---\n",
            "The TF-Agents Library\n",
            "The TF-Agents library is a Reinforcement Learning library based on TensorFlow,\n",
            "\n",
            "--- Chunk 14294 ---\n",
            "developed at Google and open sourced in 2018. Just like OpenAI Gym, it provides\n",
            "\n",
            "--- Chunk 14295 ---\n",
            "many off-the-shelf environments (including wrappers for all OpenAI Gym environ‐\n",
            "\n",
            "--- Chunk 14296 ---\n",
            "ments), plus it supports the PyBullet library (for 3D physics simulation), DeepMind’s\n",
            "\n",
            "--- Chunk 14297 ---\n",
            "DM Control library (based on MuJoCo’s physics engine), and Unity’s ML-Agents\n",
            "\n",
            "--- Chunk 14298 ---\n",
            "library (simulating many 3D environments). It also implements many RL algorithms,\n",
            "\n",
            "--- Chunk 14299 ---\n",
            "including REINFORCE, DQN, and DDQN, as well as various RL components such\n",
            "\n",
            "--- Chunk 14300 ---\n",
            "as efficient replay buffers and metrics. It is fast, scalable, easy to use, and customiza‐\n",
            "\n",
            "--- Chunk 14301 ---\n",
            "ble: you can create your own environments and neural nets, and you can customize\n",
            "\n",
            "--- Chunk 14302 ---\n",
            "pretty much any component. In this section we will use TF-Agents to train an agent\n",
            "\n",
            "--- Chunk 14303 ---\n",
            "to play Breakout, the famous Atari game (see Figure 18-1119), using the DQN algo‐\n",
            "rithm (you can easily switch to another algorithm if you prefer).\n",
            "\n",
            "--- Chunk 14304 ---\n",
            "18 Matteo Hessel et al., “Rainbow: Combining Improvements in Deep Reinforcement Learning,” arXiv preprint\n",
            "arXiv:1710.02298 (2017): 3215–3222.\n",
            "\n",
            "--- Chunk 14305 ---\n",
            "19 If you don’t know this game, it’s simple: a ball bounces around and breaks bricks when it touches them. You\n",
            "\n",
            "--- Chunk 14306 ---\n",
            "control a paddle near the bottom of the screen. The paddle can go left or right, and you must get the ball to\n",
            "\n",
            "--- Chunk 14307 ---\n",
            "break every brick, while preventing it from touching the bottom of the screen.\n",
            "\n",
            "--- Chunk 14308 ---\n",
            "642 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "\n",
            "\n",
            "Figure 18-11. The famous Breakout game\n",
            "\n",
            "--- Chunk 14309 ---\n",
            "Installing TF-Agents\n",
            "Let’s start by installing TF-Agents. This can be done using pip (as always, if you are\n",
            "\n",
            "--- Chunk 14310 ---\n",
            "using a virtual environment, make sure to activate it first; if not, you will need to use\n",
            "the --user option, or have administrator rights):\n",
            "\n",
            "--- Chunk 14311 ---\n",
            "$ python3 -m pip install -U tf-agents\n",
            "\n",
            "--- Chunk 14312 ---\n",
            "At the time of this writing, TF-Agents is still quite new and\n",
            "improving every day, so the API may change a bit by the time you\n",
            "\n",
            "--- Chunk 14313 ---\n",
            "read this—but the big picture should remain the same, as well as\n",
            "most of the code. If anything breaks, I will update the Jupyter note‐\n",
            "\n",
            "--- Chunk 14314 ---\n",
            "book accordingly, so make sure to check it out.\n",
            "\n",
            "--- Chunk 14315 ---\n",
            "Next, let’s create a TF-Agents environment that will just wrap OpenAI GGym’s Break‐\n",
            "\n",
            "--- Chunk 14316 ---\n",
            "out environment. For this, you must first install OpenAI Gym’s Atari dependencies:\n",
            "\n",
            "--- Chunk 14317 ---\n",
            "$ python3 -m pip install -U 'gym[atari]'\n",
            "\n",
            "--- Chunk 14318 ---\n",
            "Among other libraries, this command will install atari-py, which is a Python inter‐\n",
            "\n",
            "--- Chunk 14319 ---\n",
            "face for the Arcade Learning Environment (ALE), a framework built on top of the\n",
            "Atari 2600 emulator Stella.\n",
            "\n",
            "--- Chunk 14320 ---\n",
            "TF-Agents Environments\n",
            "If everything went well, you should be able to import TF-Agents and create a Break‐\n",
            "out environment:\n",
            "\n",
            "--- Chunk 14321 ---\n",
            ">>> from tf_agents.environments import suite_gym\n",
            ">>> env = suite_gym.load(\"Breakout-v4\")\n",
            ">>> env\n",
            "\n",
            "--- Chunk 14322 ---\n",
            ">>> env\n",
            "<tf_agents.environments.wrappers.TimeLimit at 0x10c523c18>\n",
            "\n",
            "--- Chunk 14323 ---\n",
            "The TF-Agents Library | 643\n",
            "\n",
            "\n",
            "\n",
            "This is just a wrapper around an OpenAI Gym environment, which you can access\n",
            "through the gym attribute:\n",
            "\n",
            "--- Chunk 14324 ---\n",
            ">>> env.gym\n",
            "<gym.envs.atari.atari_env.AtariEnv at 0x24dcab940>\n",
            "\n",
            "--- Chunk 14325 ---\n",
            "TF-Agents environments are very similar to OpenAI Gym environments, but there\n",
            "\n",
            "--- Chunk 14326 ---\n",
            "are a few differences. First, the reset() method does not return an observation;\n",
            "\n",
            "--- Chunk 14327 ---\n",
            "instead it returns a TimeStep object that wraps the observation, as well as some extra\n",
            "information:\n",
            "\n",
            "--- Chunk 14328 ---\n",
            ">>> env.reset()\n",
            "TimeStep(step_type=array(0, dtype=int32),\n",
            "         reward=array(0., dtype=float32),\n",
            "         discount=array(1., dtype=float32),\n",
            "\n",
            "--- Chunk 14329 ---\n",
            "observation=array([[[0., 0., 0.], [0., 0., 0.],...]]], dtype=float32))\n",
            "\n",
            "--- Chunk 14330 ---\n",
            "The step() method returns a TimeStep object as well:\n",
            ">>> env.step(1) # Fire\n",
            "TimeStep(step_type=array(1, dtype=int32),\n",
            "\n",
            "--- Chunk 14331 ---\n",
            "reward=array(0., dtype=float32),\n",
            "         discount=array(1., dtype=float32),\n",
            "\n",
            "--- Chunk 14332 ---\n",
            "observation=array([[[0., 0., 0.], [0., 0., 0.],...]]], dtype=float32))\n",
            "\n",
            "--- Chunk 14333 ---\n",
            "The reward and observation attributes are self-explanatory, and they are the same as\n",
            "\n",
            "--- Chunk 14334 ---\n",
            "for OpenAI Gym (except the reward is represented as a NumPy array). The\n",
            "\n",
            "--- Chunk 14335 ---\n",
            "step_type attribute is equal to 0 for the first time step in the episode, 1 for intermedi‐\n",
            "\n",
            "--- Chunk 14336 ---\n",
            "ate time steps, and 2 for the final time step. You can call the time step’s is_last()\n",
            "\n",
            "--- Chunk 14337 ---\n",
            "method to check whether it is the final one or not. Lastly, the discount attribute indi‐\n",
            "\n",
            "--- Chunk 14338 ---\n",
            "cates the discount factor to use at this time step. In this example it is equal to 1, so\n",
            "\n",
            "--- Chunk 14339 ---\n",
            "there will be no discount at all. You can define the discount factor by setting the dis\n",
            "count parameter when loading the environment.\n",
            "\n",
            "--- Chunk 14340 ---\n",
            "At any time, you can access the environment’s current time step by\n",
            "calling its current_time_step() method.\n",
            "\n",
            "--- Chunk 14341 ---\n",
            "Environment Specifications\n",
            "Conveniently, a TF-Agents environment provides the specifications of the observa‐\n",
            "\n",
            "--- Chunk 14342 ---\n",
            "tions, actions, and time steps, including their shapes, data types, and names, as well as\n",
            "their minimum and maximum values:\n",
            "\n",
            "--- Chunk 14343 ---\n",
            "644 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 14344 ---\n",
            ">>> env.observation_spec()\n",
            "BoundedArraySpec(shape=(210, 160, 3), dtype=dtype('float32'), name=None,\n",
            "\n",
            "--- Chunk 14345 ---\n",
            "minimum=[[[0. 0. 0.], [0. 0. 0.],...]],\n",
            "                 maximum=[[[255., 255., 255.], [255., 255., 255.], ...]])\n",
            "\n",
            "--- Chunk 14346 ---\n",
            ">>> env.action_spec()\n",
            "BoundedArraySpec(shape=(), dtype=dtype('int64'), name=None,\n",
            "                 minimum=0, maximum=3)\n",
            ">>> env.time_step_spec()\n",
            "\n",
            "--- Chunk 14347 ---\n",
            "TimeStep(step_type=ArraySpec(shape=(), dtype=dtype('int32'), name='step_type'),\n",
            "\n",
            "--- Chunk 14348 ---\n",
            "reward=ArraySpec(shape=(), dtype=dtype('float32'), name='reward'),\n",
            "\n",
            "--- Chunk 14349 ---\n",
            "discount=BoundedArraySpec(shape=(), ..., minimum=0.0, maximum=1.0),\n",
            "         observation=BoundedArraySpec(shape=(210, 160, 3), ...))\n",
            "\n",
            "--- Chunk 14350 ---\n",
            "As you can see, the observations are simply screenshots of the Atari screen, repre‐\n",
            "\n",
            "--- Chunk 14351 ---\n",
            "sented as NumPy arrays of shape [210, 160, 3]. To render an environment, you can\n",
            "\n",
            "--- Chunk 14352 ---\n",
            "call env.render(mode=\"human\"), and if you want to get back the image in the form of\n",
            "\n",
            "--- Chunk 14353 ---\n",
            "a NumPy array, just call env.render(mode=\"rgb_array\") (unlike in OpenAI Gym,\n",
            "this is the default mode).\n",
            "\n",
            "--- Chunk 14354 ---\n",
            "There are four actions available. Gym’s Atari environments have an extra method that\n",
            "you can call to know what each action corresponds to:\n",
            "\n",
            "--- Chunk 14355 ---\n",
            ">>> env.gym.get_action_meanings()\n",
            "['NOOP', 'FIRE', 'RIGHT', 'LEFT']\n",
            "\n",
            "--- Chunk 14356 ---\n",
            "Specs can be instances of a specification class, nested lists, or dic‐\n",
            "tionaries of specs. If the specification is nested, then the specified\n",
            "\n",
            "--- Chunk 14357 ---\n",
            "object must match the specification’s nested structure. For example,\n",
            "if the observation spec is {\"sensors\": ArraySpec(shape=[2]),\n",
            "\n",
            "--- Chunk 14358 ---\n",
            "\"camera\": ArraySpec(shape=[100, 100])}, then a valid observa‐\n",
            "tion would be {\"sensors\": np.array([1.5, 3.5]), \"camera\":\n",
            "\n",
            "--- Chunk 14359 ---\n",
            "np.array(...)}. The tf.nest package provides tools to handle\n",
            "such nested structures (a.k.a. nests).\n",
            "\n",
            "--- Chunk 14360 ---\n",
            "The observations are quite large, so we will downsample them and also convert them\n",
            "\n",
            "--- Chunk 14361 ---\n",
            "to grayscale. This will speed up training and use less RAM. For this, we can use an\n",
            "environment wrapper.\n",
            "\n",
            "--- Chunk 14362 ---\n",
            "Environment Wrappers and Atari Preprocessing\n",
            "TF-Agents provides several environment wrappers in the tf_agents.environ\n",
            "\n",
            "--- Chunk 14363 ---\n",
            "ments.wrappers package. As their name suggests, they wrap an environment, for‐\n",
            "\n",
            "--- Chunk 14364 ---\n",
            "warding every call to it, but also adding some extra functionality. Here are some of\n",
            "the available wrappers:\n",
            "ActionClipWrapper\n",
            "\n",
            "--- Chunk 14365 ---\n",
            "Clips the actions to the action spec.\n",
            "\n",
            "The TF-Agents Library | 645\n",
            "\n",
            "--- Chunk 14366 ---\n",
            "ActionDiscretizeWrapper\n",
            "Quantizes a continuous action space to a discrete action space. For example, if\n",
            "\n",
            "--- Chunk 14367 ---\n",
            "the original environment’s action space is the continuous range from –1.0 to\n",
            "\n",
            "--- Chunk 14368 ---\n",
            "+1.0, but you want to use an algorithm that only supports discrete action spaces,\n",
            "\n",
            "--- Chunk 14369 ---\n",
            "such as a DQN, then you can wrap the environment using discrete_env =\n",
            "ActionDiscretizeWrapper(env, num_actions=5), and the new discrete_env\n",
            "\n",
            "--- Chunk 14370 ---\n",
            "will have a discrete action space with five possible actions: 0, 1, 2, 3, 4. These\n",
            "\n",
            "--- Chunk 14371 ---\n",
            "actions correspond to the actions –1.0, –0.5, 0.0, 0.5, and 1.0 in the original envi‐\n",
            "ronment.\n",
            "\n",
            "--- Chunk 14372 ---\n",
            "ActionRepeat\n",
            "Repeats each action over n steps, while accumulating the rewards. In many envi‐\n",
            "ronments, this can speed up training significantly.\n",
            "\n",
            "--- Chunk 14373 ---\n",
            "RunStats\n",
            "Records environment statistics such as the number of steps and the number of\n",
            "episodes.\n",
            "\n",
            "--- Chunk 14374 ---\n",
            "TimeLimit\n",
            "Interrupts the environment if it runs for longer than a maximum number of\n",
            "steps.\n",
            "\n",
            "VideoWrapper\n",
            "Records a video of the environment.\n",
            "\n",
            "--- Chunk 14375 ---\n",
            "To create a wrapped environment, you must create a wrapper, passing the wrapped\n",
            "\n",
            "--- Chunk 14376 ---\n",
            "environment to the constructor. That’s all! For example, the following code will wrap\n",
            "\n",
            "--- Chunk 14377 ---\n",
            "our environment in an ActionRepeat wrapper so that every action is repeated four\n",
            "times:\n",
            "\n",
            "--- Chunk 14378 ---\n",
            "from tf_agents.environments.wrappers import ActionRepeat\n",
            "\n",
            "repeating_env = ActionRepeat(env, times=4)\n",
            "\n",
            "--- Chunk 14379 ---\n",
            "OpenAI Gym has some environment wrappers of its own in the gym.wrappers pack‐\n",
            "\n",
            "--- Chunk 14380 ---\n",
            "age. They are meant to wrap Gym environments, though, not TF-Agents environ‐\n",
            "ments, so to use them you must first wrap the Gym environment with a Gym\n",
            "\n",
            "--- Chunk 14381 ---\n",
            "wrapper, then wrap the resulting environment with a TF-Agents wrapper. The\n",
            "\n",
            "--- Chunk 14382 ---\n",
            "suite_gym.wrap_env() function will do this for you, provided you give it a Gym\n",
            "\n",
            "--- Chunk 14383 ---\n",
            "environment and a list of Gym wrappers and/or a list of TF-Agents wrappers. Alter‐\n",
            "\n",
            "--- Chunk 14384 ---\n",
            "natively, the suite_gym.load() function will both create the Gym environment and\n",
            "\n",
            "--- Chunk 14385 ---\n",
            "wrap it for you, if you give it some wrappers. Each wrapper will be created without\n",
            "\n",
            "--- Chunk 14386 ---\n",
            "any arguments, so if you want to set some arguments, you must pass a lambda. For\n",
            "\n",
            "--- Chunk 14387 ---\n",
            "example, the following code creates a Breakout environment that will run for a maxi‐\n",
            "\n",
            "--- Chunk 14388 ---\n",
            "mum of 10,000 steps during each episode, and each action will be repeated four\n",
            "times:\n",
            "\n",
            "--- Chunk 14389 ---\n",
            "646 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "\n",
            "\n",
            "from gym.wrappers import TimeLimit\n",
            "\n",
            "--- Chunk 14390 ---\n",
            "limited_repeating_env = suite_gym.load(\n",
            "    \"Breakout-v4\",\n",
            "    gym_env_wrappers=[lambda env: TimeLimit(env, max_episode_steps=10000)],\n",
            "\n",
            "--- Chunk 14391 ---\n",
            "env_wrappers=[lambda env: ActionRepeat(env, times=4)])\n",
            "\n",
            "--- Chunk 14392 ---\n",
            "For Atari environments, some standard preprocessing steps are applied in most\n",
            "\n",
            "--- Chunk 14393 ---\n",
            "papers that use them, so TF-Agents provides a handy AtariPreprocessing wrapper\n",
            "\n",
            "--- Chunk 14394 ---\n",
            "that implements them. Here is the list of preprocessing steps it supports:\n",
            "Grayscale and downsampling\n",
            "\n",
            "--- Chunk 14395 ---\n",
            "Observations are converted to grayscale and downsampled (by default to 84 × 84\n",
            "pixels).\n",
            "\n",
            "--- Chunk 14396 ---\n",
            "Max pooling\n",
            "The last two frames of the game are max-pooled using a 1 × 1 filter. This is to\n",
            "\n",
            "--- Chunk 14397 ---\n",
            "remove the flickering that occurs in some Atari games due to the limited number\n",
            "of sprites that the Atari 2600 could display in each frame.\n",
            "\n",
            "--- Chunk 14398 ---\n",
            "Frame skipping\n",
            "The agent only gets to see every n frames of the game (by default n = 4), and its\n",
            "\n",
            "--- Chunk 14399 ---\n",
            "actions are repeated for each frame, collecting all the rewards. This effectively\n",
            "\n",
            "--- Chunk 14400 ---\n",
            "speeds up the game from the perspective of the agent, and it also speeds up train‐\n",
            "ing because rewards are less delayed.\n",
            "\n",
            "--- Chunk 14401 ---\n",
            "End on life lost\n",
            "In some games, the rewards are just based on the score, so the agent gets no\n",
            "\n",
            "--- Chunk 14402 ---\n",
            "immediate penalty for losing a life. One solution is to end the game immediately\n",
            "\n",
            "--- Chunk 14403 ---\n",
            "whenever a life is lost. There is some debate over the actual benefits of this strat‐\n",
            "egy, so it is off by default.\n",
            "\n",
            "--- Chunk 14404 ---\n",
            "Since the default Atari environment already applies random frame skipping and\n",
            "max pooling, we will need to load the raw, nonskipping variant called\n",
            "\n",
            "--- Chunk 14405 ---\n",
            "\"BreakoutNoFrameskip-v4\". Moreover, a single frame from the Breakout game is\n",
            "\n",
            "--- Chunk 14406 ---\n",
            "insufficient to know the direction and speed of the ball, which will make it very diffi‐\n",
            "\n",
            "--- Chunk 14407 ---\n",
            "cult for the agent to play the game properly (unless it is an RNN agent, which pre‐\n",
            "\n",
            "--- Chunk 14408 ---\n",
            "serves some internal state between steps). One way to handle this is to use an\n",
            "\n",
            "--- Chunk 14409 ---\n",
            "environment wrapper that will output observations composed of multiple frames\n",
            "\n",
            "--- Chunk 14410 ---\n",
            "stacked on top of each other along the channels dimension. This strategy is imple‐\n",
            "\n",
            "--- Chunk 14411 ---\n",
            "mented by the FrameStack4 wrapper, which returns stacks of four frames. Let’s create\n",
            "the wrapped Atari environment!\n",
            "\n",
            "--- Chunk 14412 ---\n",
            "The TF-Agents Library | 647\n",
            "\n",
            "--- Chunk 14413 ---\n",
            "from tf_agents.environments import suite_atari\n",
            "from tf_agents.environments.atari_preprocessing import AtariPreprocessing\n",
            "\n",
            "--- Chunk 14414 ---\n",
            "from tf_agents.environments.atari_wrappers import FrameStack4\n",
            "\n",
            "--- Chunk 14415 ---\n",
            "max_episode_steps = 27000 # <=> 108k ALE frames since 1 step = 4 frames\n",
            "environment_name = \"BreakoutNoFrameskip-v4\"\n",
            "\n",
            "--- Chunk 14416 ---\n",
            "env = suite_atari.load(\n",
            "    environment_name,\n",
            "    max_episode_steps=max_episode_steps,\n",
            "    gym_env_wrappers=[AtariPreprocessing, FrameStack4])\n",
            "\n",
            "--- Chunk 14417 ---\n",
            "The result of all this preprocessing is shown in Figure 18-12. You can see that the res‐\n",
            "\n",
            "--- Chunk 14418 ---\n",
            "olution is much lower, but sufficient to play the game. Moreover, frames are stacked\n",
            "\n",
            "--- Chunk 14419 ---\n",
            "along the channels dimension, so red represents the frame from three steps ago,\n",
            "\n",
            "--- Chunk 14420 ---\n",
            "green is two steps ago, blue is the previous frame, and pink is the current frame.20\n",
            "\n",
            "--- Chunk 14421 ---\n",
            "From this single observation, the agent can see that the ball is going toward the\n",
            "\n",
            "--- Chunk 14422 ---\n",
            "lower-left corner, and that it should continue to move the paddle to the left (as it did\n",
            "in the previous steps).\n",
            "\n",
            "--- Chunk 14423 ---\n",
            "Figure 18-12. Preprocessed Breakout observation\n",
            "\n",
            "--- Chunk 14424 ---\n",
            "Lastly, we can wrap the environment inside a TFPyEnvironment:\n",
            "from tf_agents.environments.tf_py_environment import TFPyEnvironment\n",
            "\n",
            "--- Chunk 14425 ---\n",
            "tf_env = TFPyEnvironment(env)\n",
            "\n",
            "--- Chunk 14426 ---\n",
            "This will make the environment usable from within a TensorFlow graph (under the\n",
            "\n",
            "--- Chunk 14427 ---\n",
            "hood, this class relies on tf.py_function(), which allows a graph to call arbitrary\n",
            "\n",
            "--- Chunk 14428 ---\n",
            "20 Since there are only three primary colors, you cannot just display an image with four color channels. For this\n",
            "\n",
            "--- Chunk 14429 ---\n",
            "reason, I combined the last channel with the first three to get the RGB image represented here. Pink is actually\n",
            "\n",
            "--- Chunk 14430 ---\n",
            "a mix of blue and red, but the agent sees four independent channels.\n",
            "\n",
            "--- Chunk 14431 ---\n",
            "648 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 14432 ---\n",
            "Python code). Thanks to the TFPyEnvironment class, TF-Agents supports both pure\n",
            "\n",
            "--- Chunk 14433 ---\n",
            "Python environments and TensorFlow-based environments. More generally, TF-\n",
            "\n",
            "--- Chunk 14434 ---\n",
            "Agents supports and provides both pure Python and TensorFlow-based components\n",
            "(agents, replay buffers, metrics, and so on).\n",
            "\n",
            "--- Chunk 14435 ---\n",
            "Now that we have a nice Breakout environment, with all the appropriate preprocess‐\n",
            "\n",
            "--- Chunk 14436 ---\n",
            "ing and TensorFlow support, we must create the DQN agent and the other compo‐\n",
            "\n",
            "--- Chunk 14437 ---\n",
            "nents we will need to train it. Let’s look at the architecture of the system we will build.\n",
            "\n",
            "--- Chunk 14438 ---\n",
            "Training Architecture\n",
            "A TF-Agents training program is usually split into two parts that run in parallel, as\n",
            "\n",
            "--- Chunk 14439 ---\n",
            "you can see in Figure 18-13: on the left, a driver explores the environment using a\n",
            "\n",
            "--- Chunk 14440 ---\n",
            "collect policy to choose actions, and it collects trajectories (i.e., experiences), sending\n",
            "\n",
            "--- Chunk 14441 ---\n",
            "them to an observer, which saves them to a replay buffer; on the right, an agent pulls\n",
            "\n",
            "--- Chunk 14442 ---\n",
            "batches of trajectories from the replay buffer and trains some networks, which the col‐\n",
            "\n",
            "--- Chunk 14443 ---\n",
            "lect policy uses. In short, the left part explores the environment and collects trajecto‐\n",
            "\n",
            "--- Chunk 14444 ---\n",
            "ries, while the right part learns and updates the collect policy.\n",
            "\n",
            "--- Chunk 14445 ---\n",
            "Figure 18-13. A typical TF-Agents training architecture\n",
            "\n",
            "This figure begs a few questions, which I’ll attempt to answer here:\n",
            "\n",
            "--- Chunk 14446 ---\n",
            "• Why are there multiple environments? Instead of exploring a single environ‐\n",
            "\n",
            "--- Chunk 14447 ---\n",
            "ment, you generally want the driver to explore multiple copies of the environ‐\n",
            "\n",
            "--- Chunk 14448 ---\n",
            "ment in parallel, taking advantage of the power of all your CPU cores, keeping\n",
            "\n",
            "--- Chunk 14449 ---\n",
            "The TF-Agents Library | 649\n",
            "\n",
            "\n",
            "\n",
            "the training GPUs busy, and providing less-correlated trajectories to the training\n",
            "algorithm.\n",
            "\n",
            "--- Chunk 14450 ---\n",
            "• What is a trajectory? It is a concise representation of a transition from one time\n",
            "\n",
            "--- Chunk 14451 ---\n",
            "step to the next, or a sequence of consecutive transitions from time step n to time\n",
            "\n",
            "--- Chunk 14452 ---\n",
            "step n + t. The trajectories collected by the driver are passed to the observer,\n",
            "\n",
            "--- Chunk 14453 ---\n",
            "which saves them in the replay buffer, and they are later sampled by the agent\n",
            "and used for training.\n",
            "\n",
            "--- Chunk 14454 ---\n",
            "• Why do we need an observer? Can’t the driver save the trajectories directly?\n",
            "\n",
            "--- Chunk 14455 ---\n",
            "Indeed, it could, but this would make the architecture less flexible. For example,\n",
            "\n",
            "--- Chunk 14456 ---\n",
            "what if you don’t want to use a replay buffer? What if you want to use the trajec‐\n",
            "\n",
            "--- Chunk 14457 ---\n",
            "tories for something else, like computing metrics? In fact, an observer is just any\n",
            "\n",
            "--- Chunk 14458 ---\n",
            "function that takes a trajectory as an argument. You can use an observer to save\n",
            "\n",
            "--- Chunk 14459 ---\n",
            "the trajectories to a replay buffer, or to save them to a TFRecord file (see Chap‐\n",
            "\n",
            "--- Chunk 14460 ---\n",
            "ter 13), or to compute metrics, or for anything else. Moreover, you can pass mul‐\n",
            "\n",
            "--- Chunk 14461 ---\n",
            "tiple observers to the driver, and it will broadcast the trajectories to all of them.\n",
            "\n",
            "--- Chunk 14462 ---\n",
            "Although this architecture is the most common, you can customize\n",
            "it as you please, and even replace some components with your own.\n",
            "\n",
            "--- Chunk 14463 ---\n",
            "In fact, unless you are researching new RL algorithms, you will\n",
            "most likely want to use a custom environment for your task. For\n",
            "\n",
            "--- Chunk 14464 ---\n",
            "this, you just need to create a custom class that inherits from the\n",
            "PyEnvironment class in the tf_agents.environments.py_environ\n",
            "\n",
            "--- Chunk 14465 ---\n",
            "ment package and overrides the appropriate methods, such as\n",
            "action_spec(), observation_spec(), _reset(), and _step() (see\n",
            "\n",
            "--- Chunk 14466 ---\n",
            "the “Creating a Custom TF_Agents Environment” section of the\n",
            "notebook for an example).\n",
            "\n",
            "--- Chunk 14467 ---\n",
            "Now we will create all these components: first the Deep Q-Network, then the DQN\n",
            "\n",
            "--- Chunk 14468 ---\n",
            "agent (which will take care of creating the collect policy), then the replay buffer and\n",
            "\n",
            "--- Chunk 14469 ---\n",
            "the observer to write to it, then a few training metrics, then the driver, and finally the\n",
            "\n",
            "--- Chunk 14470 ---\n",
            "dataset. Once we have all the components in place, we will populate the replay buffer\n",
            "\n",
            "--- Chunk 14471 ---\n",
            "with some initial trajectories, then we will run the main training loop. So, let’s start by\n",
            "creating the Deep Q-Network.\n",
            "\n",
            "--- Chunk 14472 ---\n",
            "Creating the Deep Q-Network\n",
            "The TF-Agents library provides many networks in the tf_agents.networks package\n",
            "\n",
            "--- Chunk 14473 ---\n",
            "and its subpackages. We will use the tf_agents.networks.q_network.QNetwork\n",
            "class:\n",
            "\n",
            "--- Chunk 14474 ---\n",
            "650 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "\n",
            "\n",
            "from tf_agents.networks.q_network import QNetwork\n",
            "\n",
            "--- Chunk 14475 ---\n",
            "preprocessing_layer = keras.layers.Lambda(\n",
            "                          lambda obs: tf.cast(obs, np.float32) / 255.)\n",
            "\n",
            "--- Chunk 14476 ---\n",
            "conv_layer_params=[(32, (8, 8), 4), (64, (4, 4), 2), (64, (3, 3), 1)]\n",
            "fc_layer_params=[512]\n",
            "\n",
            "--- Chunk 14477 ---\n",
            "q_net = QNetwork(\n",
            "    tf_env.observation_spec(),\n",
            "    tf_env.action_spec(),\n",
            "    preprocessing_layers=preprocessing_layer,\n",
            "\n",
            "--- Chunk 14478 ---\n",
            "conv_layer_params=conv_layer_params,\n",
            "    fc_layer_params=fc_layer_params)\n",
            "\n",
            "--- Chunk 14479 ---\n",
            "This QNetwork takes an observation as input and outputs one Q-Value per action, so\n",
            "\n",
            "--- Chunk 14480 ---\n",
            "we must give it the specifications of the observations and the actions. It starts with a\n",
            "\n",
            "--- Chunk 14481 ---\n",
            "preprocessing layer: a simple Lambda layer that casts the observations to 32-bit floats\n",
            "\n",
            "--- Chunk 14482 ---\n",
            "and normalizes them (the values will range from 0.0 to 1.0). The observations contain\n",
            "\n",
            "--- Chunk 14483 ---\n",
            "unsigned bytes, which use 4 times less space than 32-bit floats, which is why we did\n",
            "\n",
            "--- Chunk 14484 ---\n",
            "not cast the observations to 32-bit floats earlier; we want to save RAM in the replay\n",
            "\n",
            "--- Chunk 14485 ---\n",
            "buffer. Next, the network applies three convolutional layers: the first has 32 8 × 8 fil‐\n",
            "\n",
            "--- Chunk 14486 ---\n",
            "ters and uses a stride of 4, the second has 64 4 × 4 filters and a stride of 2, and the\n",
            "\n",
            "--- Chunk 14487 ---\n",
            "third has 64 3 × 3 filters and a stride of 1. Lastly, it applies a dense layer with 512\n",
            "\n",
            "--- Chunk 14488 ---\n",
            "units, followed by a dense output layer with 4 units, one per Q-Value to output (i.e.,\n",
            "\n",
            "--- Chunk 14489 ---\n",
            "one per action). All convolutional layers and all dense layers except the output layer\n",
            "\n",
            "--- Chunk 14490 ---\n",
            "use the ReLU activation function by default (you can change this by setting the acti\n",
            "\n",
            "--- Chunk 14491 ---\n",
            "vation_fn argument). The output layer does not use any activation function.\n",
            "\n",
            "--- Chunk 14492 ---\n",
            "Under the hood, a QNetwork is composed of two parts: an encoding network that pro‐\n",
            "\n",
            "--- Chunk 14493 ---\n",
            "cesses the observations, followed by a dense output layer that outputs one Q-Value\n",
            "\n",
            "--- Chunk 14494 ---\n",
            "per action. TF-Agent’s EncodingNetwork class implements a neural network architec‐\n",
            "ture found in various agents (see Figure 18-14).\n",
            "\n",
            "--- Chunk 14495 ---\n",
            "It may have one or more inputs. For example, if each observation is composed of\n",
            "\n",
            "--- Chunk 14496 ---\n",
            "some sensor data plus an image from a camera, you will have two inputs. Each input\n",
            "\n",
            "--- Chunk 14497 ---\n",
            "may require some preprocessing steps, in which case you can specify a list of Keras\n",
            "\n",
            "--- Chunk 14498 ---\n",
            "layers via the preprocessing_layers argument, with one preprocessing layer per\n",
            "\n",
            "--- Chunk 14499 ---\n",
            "input, and the network will apply each layer to the corresponding input (if an input\n",
            "\n",
            "--- Chunk 14500 ---\n",
            "requires multiple layers of preprocessing, you can pass a whole model, since a Keras\n",
            "\n",
            "--- Chunk 14501 ---\n",
            "model can always be used as a layer). If there are two inputs or more, you must also\n",
            "\n",
            "--- Chunk 14502 ---\n",
            "pass an extra layer via the preprocessing_combiner argument, to combine the out‐\n",
            "puts from the preprocessing layers into a single output.\n",
            "\n",
            "--- Chunk 14503 ---\n",
            "Next, the encoding network will optionally apply a list of convolutions sequentially,\n",
            "\n",
            "--- Chunk 14504 ---\n",
            "provided you specify their parameters via the conv_layer_params argument. This\n",
            "\n",
            "--- Chunk 14505 ---\n",
            "must be a list composed of 3-tuples (one per convolutional layer) indicating the\n",
            "\n",
            "--- Chunk 14506 ---\n",
            "The TF-Agents Library | 651\n",
            "\n",
            "--- Chunk 14507 ---\n",
            "number of filters, the kernel size, and the stride. After these convolutional layers, the\n",
            "\n",
            "--- Chunk 14508 ---\n",
            "encoding network will optionally apply a sequence of dense layers, if you set the\n",
            "\n",
            "--- Chunk 14509 ---\n",
            "fc_layer_params argument: it must be a list containing the number of neurons for\n",
            "\n",
            "--- Chunk 14510 ---\n",
            "each dense layer. Optionally, you can also pass a list of dropout rates (one per dense\n",
            "\n",
            "--- Chunk 14511 ---\n",
            "layer) via the dropout_layer_params argument if you want to apply dropout after\n",
            "\n",
            "--- Chunk 14512 ---\n",
            "each dense layer. The QNetwork takes the output of this encoding network and passes\n",
            "it to the dense output layer (with one unit per action).\n",
            "\n",
            "--- Chunk 14513 ---\n",
            "Figure 18-14. Architecture of an encoding network\n",
            "\n",
            "--- Chunk 14514 ---\n",
            "The QNetwork class is flexible enough to build many different\n",
            "architectures, but you can always build your own network class if\n",
            "\n",
            "--- Chunk 14515 ---\n",
            "you need extra flexibility: extend the tf_agents.networks.Net\n",
            "work class and implement it like a regular custom Keras layer. The\n",
            "\n",
            "--- Chunk 14516 ---\n",
            "tf_agents.networks.Network class is a subclass of the keras.lay\n",
            "ers.Layer class that adds some functionality required by some\n",
            "\n",
            "--- Chunk 14517 ---\n",
            "agents, such as the possibility to easily create shallow copies of the\n",
            "network (i.e., copying the network’s architecture, but not its\n",
            "\n",
            "--- Chunk 14518 ---\n",
            "weights). For example, the DQNAgent uses this to create a copy of\n",
            "the online model.\n",
            "\n",
            "--- Chunk 14519 ---\n",
            "Now that we have the DQN, we are ready to build the DQN agent.\n",
            "\n",
            "--- Chunk 14520 ---\n",
            "Creating the DQN Agent\n",
            "The TF-Agents library implements many types of agents, located in the tf_agents\n",
            "\n",
            "--- Chunk 14521 ---\n",
            ".agents package and its subpackages. We will use the tf_agents.agents\n",
            ".dqn.dqn_agent.DqnAgent class:\n",
            "\n",
            "--- Chunk 14522 ---\n",
            "652 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "\n",
            "\n",
            "from tf_agents.agents.dqn.dqn_agent import DqnAgent\n",
            "\n",
            "--- Chunk 14523 ---\n",
            "train_step = tf.Variable(0)\n",
            "update_period = 4 # train the model every 4 steps\n",
            "\n",
            "--- Chunk 14524 ---\n",
            "optimizer = keras.optimizers.RMSprop(lr=2.5e-4, rho=0.95, momentum=0.0,\n",
            "                                     epsilon=0.00001, centered=True)\n",
            "\n",
            "--- Chunk 14525 ---\n",
            "epsilon_fn = keras.optimizers.schedules.PolynomialDecay(\n",
            "    initial_learning_rate=1.0, # initial ε\n",
            "\n",
            "--- Chunk 14526 ---\n",
            "decay_steps=250000 // update_period, # <=> 1,000,000 ALE frames\n",
            "    end_learning_rate=0.01) # final ε\n",
            "agent = DqnAgent(tf_env.time_step_spec(),\n",
            "\n",
            "--- Chunk 14527 ---\n",
            "tf_env.action_spec(),\n",
            "                 q_network=q_net,\n",
            "                 optimizer=optimizer,\n",
            "\n",
            "--- Chunk 14528 ---\n",
            "target_update_period=2000, # <=> 32,000 ALE frames\n",
            "                 td_errors_loss_fn=keras.losses.Huber(reduction=\"none\"),\n",
            "\n",
            "--- Chunk 14529 ---\n",
            "gamma=0.99, # discount factor\n",
            "                 train_step_counter=train_step,\n",
            "\n",
            "--- Chunk 14530 ---\n",
            "epsilon_greedy=lambda: epsilon_fn(train_step))\n",
            "agent.initialize()\n",
            "\n",
            "--- Chunk 14531 ---\n",
            "Let’s walk through this code:\n",
            "\n",
            "--- Chunk 14532 ---\n",
            "• We first create a variable that will count the number of training steps.\n",
            "\n",
            "--- Chunk 14533 ---\n",
            "• Then we build the optimizer, using the same hyperparameters as in the 2015\n",
            "\n",
            "--- Chunk 14534 ---\n",
            "DQN paper.\n",
            "• Next, we create a PolynomialDecay object that will compute the ε value for the ε-\n",
            "\n",
            "--- Chunk 14535 ---\n",
            "greedy collect policy, given the current training step (it is normally used to decay\n",
            "\n",
            "--- Chunk 14536 ---\n",
            "the learning rate, hence the names of the arguments, but it will work just fine to\n",
            "\n",
            "--- Chunk 14537 ---\n",
            "decay any other value). It will go from 1.0 down to 0.01 (the value used during in\n",
            "\n",
            "--- Chunk 14538 ---\n",
            "the 2015 DQN paper) in 1 million ALE frames, which corresponds to 250,000\n",
            "\n",
            "--- Chunk 14539 ---\n",
            "steps, since we use frame skipping with a period of 4. Moreover, we will train the\n",
            "\n",
            "--- Chunk 14540 ---\n",
            "agent every 4 steps (i.e., 16 ALE frames), so ε will actually decay over 62,500\n",
            "training steps.\n",
            "\n",
            "--- Chunk 14541 ---\n",
            "• We then build the DQNAgent, passing it the time step and action specs, the QNet\n",
            "\n",
            "--- Chunk 14542 ---\n",
            "work to train, the optimizer, the number of training steps between target model\n",
            "\n",
            "--- Chunk 14543 ---\n",
            "updates, the loss function to use, the discount factor, the train_step variable,\n",
            "\n",
            "--- Chunk 14544 ---\n",
            "and a function that returns the ε value (it must take no argument, which is why\n",
            "we need a lambda to pass the train_step).\n",
            "\n",
            "--- Chunk 14545 ---\n",
            "Note that the loss function must return an error per instance, not the mean error,\n",
            "which is why we set reduction=\"none\".\n",
            "\n",
            "--- Chunk 14546 ---\n",
            "• Lastly, we initialize the agent.\n",
            "\n",
            "Next, let’s build the replay buffer and the observer that will write to it.\n",
            "\n",
            "The TF-Agents Library | 653\n",
            "\n",
            "--- Chunk 14547 ---\n",
            "Creating the Replay Buffer and the Corresponding Observer\n",
            "The TF-Agents library provides various replay buffer implementations in the\n",
            "\n",
            "--- Chunk 14548 ---\n",
            "tf_agents.replay_buffers package. Some are purely written in Python (their mod‐\n",
            "\n",
            "--- Chunk 14549 ---\n",
            "ule names start with py_), and others are written based on TensorFlow (their module\n",
            "\n",
            "--- Chunk 14550 ---\n",
            "names start with tf_). We will use the TFUniformReplayBuffer class in the\n",
            "tf_agents.replay_buffers.tf_uniform_replay_buffer package. It provides a\n",
            "\n",
            "--- Chunk 14551 ---\n",
            "high-performance implementation of a replay buffer with uniform sampling:21\n",
            "\n",
            "--- Chunk 14552 ---\n",
            "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
            "\n",
            "--- Chunk 14553 ---\n",
            "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
            "    data_spec=agent.collect_data_spec,\n",
            "    batch_size=tf_env.batch_size,\n",
            "\n",
            "--- Chunk 14554 ---\n",
            "max_length=1000000)\n",
            "\n",
            "--- Chunk 14555 ---\n",
            "Let’s look at each of these arguments:\n",
            "data_spec\n",
            "\n",
            "--- Chunk 14556 ---\n",
            "The specification of the data that will be saved in the replay buffer. The DQN\n",
            "\n",
            "--- Chunk 14557 ---\n",
            "agent knowns what the collected data will look like, and it makes the data spec\n",
            "\n",
            "--- Chunk 14558 ---\n",
            "available via its collect_data_spec attribute, so that’s what we give the replay\n",
            "buffer.\n",
            "\n",
            "--- Chunk 14559 ---\n",
            "batch_size\n",
            "The number of trajectories that will be added at each step. In our case, it will be\n",
            "\n",
            "--- Chunk 14560 ---\n",
            "one, since the driver will just execute one action per step and collect one trajec‐\n",
            "\n",
            "--- Chunk 14561 ---\n",
            "tory. If the environment were a batched environment, meaning an environment\n",
            "\n",
            "--- Chunk 14562 ---\n",
            "that takes a batch of actions at each step and returns a batch of observations, then\n",
            "\n",
            "--- Chunk 14563 ---\n",
            "the driver would have to save a batch of trajectories at each step. Since we are\n",
            "\n",
            "--- Chunk 14564 ---\n",
            "using a TensorFlow replay buffer, it needs to know the size of the batches it will\n",
            "\n",
            "--- Chunk 14565 ---\n",
            "handle (to build the computation graph). An example of a batched environment\n",
            "is the ParallelPyEnvironment (from the tf_agents.environments.paral\n",
            "\n",
            "--- Chunk 14566 ---\n",
            "lel_py_environment package): it runs multiple environments in parallel in sepa‐\n",
            "\n",
            "--- Chunk 14567 ---\n",
            "rate processes (they can be different as long as they have the same action and\n",
            "\n",
            "--- Chunk 14568 ---\n",
            "observation specs), and at each step it takes a batch of actions and executes them\n",
            "\n",
            "--- Chunk 14569 ---\n",
            "in the environments (one action per environment), then it returns all the result‐\n",
            "ing observations.\n",
            "\n",
            "--- Chunk 14570 ---\n",
            "21 At the time of this writing, there is no prioritized experience replay buffer yet, but one will likely be open\n",
            "sourced soon.\n",
            "\n",
            "--- Chunk 14571 ---\n",
            "654 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 14572 ---\n",
            "max_length\n",
            "The maximum size of the replay buffer. We created a large replay buffer that can\n",
            "\n",
            "--- Chunk 14573 ---\n",
            "store one million trajectories (as was done in the 2015 DQN paper). This will\n",
            "require a lot of RAM.\n",
            "\n",
            "--- Chunk 14574 ---\n",
            "When we store two consecutive trajectories, they contain two con‐\n",
            "secutive observations with four frames each (since we used the Fra\n",
            "\n",
            "--- Chunk 14575 ---\n",
            "meStack4 wrapper), and unfortunately three of the four frames in\n",
            "the second observation are redundant (they are already present in\n",
            "\n",
            "--- Chunk 14576 ---\n",
            "the first observation). In other words, we are using about four\n",
            "times more RAM than necessary. To avoid this, you can instead use\n",
            "\n",
            "--- Chunk 14577 ---\n",
            "a PyHashedReplayBuffer from the tf_agents.replay_buf\n",
            "fers.py_hashed_replay_buffer package: it deduplicates data in\n",
            "\n",
            "--- Chunk 14578 ---\n",
            "the stored trajectories along the last axis of the observations.\n",
            "\n",
            "--- Chunk 14579 ---\n",
            "Now we can create the observer that will write the trajectories to the replay buffer. An\n",
            "\n",
            "--- Chunk 14580 ---\n",
            "observer is just a function (or a callable object) that takes a trajectory argument, so we\n",
            "\n",
            "--- Chunk 14581 ---\n",
            "can directly use the add_method() method (bound to the replay_buffer object) as\n",
            "our observer:\n",
            "\n",
            "--- Chunk 14582 ---\n",
            "replay_buffer_observer = replay_buffer.add_batch\n",
            "\n",
            "--- Chunk 14583 ---\n",
            "If you wanted to create your own observer, you could write any function with a\n",
            "\n",
            "--- Chunk 14584 ---\n",
            "trajectory argument. If it must have a state, you can write a class with a\n",
            "\n",
            "--- Chunk 14585 ---\n",
            "__call__(self, trajectory) method. For example, here is a simple observer that\n",
            "\n",
            "--- Chunk 14586 ---\n",
            "will increment a counter every time it is called (except when the trajectory represents\n",
            "\n",
            "--- Chunk 14587 ---\n",
            "a boundary between two episodes, which does not count as a step), and every 100\n",
            "\n",
            "--- Chunk 14588 ---\n",
            "increments it displays the progress up to a given total (the carriage return \\r along\n",
            "\n",
            "--- Chunk 14589 ---\n",
            "with end=\"\" ensures that the displayed counter remains on the same line):\n",
            "\n",
            "--- Chunk 14590 ---\n",
            "class ShowProgress:\n",
            "    def __init__(self, total):\n",
            "        self.counter = 0\n",
            "        self.total = total\n",
            "    def __call__(self, trajectory):\n",
            "\n",
            "--- Chunk 14591 ---\n",
            "if not trajectory.is_boundary():\n",
            "            self.counter += 1\n",
            "        if self.counter % 100 == 0:\n",
            "\n",
            "--- Chunk 14592 ---\n",
            "print(\"\\r{}/{}\".format(self.counter, self.total), end=\"\")\n",
            "\n",
            "--- Chunk 14593 ---\n",
            "Now let’s create a few training metrics.\n",
            "\n",
            "--- Chunk 14594 ---\n",
            "Creating Training Metrics\n",
            "TF-Agents implements several RL metrics in the tf_agents.metrics package, some\n",
            "\n",
            "--- Chunk 14595 ---\n",
            "purely in Python and some based on TensorFlow. Let’s create a few of them in order\n",
            "\n",
            "--- Chunk 14596 ---\n",
            "The TF-Agents Library | 655\n",
            "\n",
            "--- Chunk 14597 ---\n",
            "to count the number of episodes, the number of steps taken, and most importantly\n",
            "the average return per episode and the average episode length:\n",
            "\n",
            "--- Chunk 14598 ---\n",
            "from tf_agents.metrics import tf_metrics\n",
            "\n",
            "--- Chunk 14599 ---\n",
            "train_metrics = [\n",
            "    tf_metrics.NumberOfEpisodes(),\n",
            "    tf_metrics.EnvironmentSteps(),\n",
            "    tf_metrics.AverageReturnMetric(),\n",
            "\n",
            "--- Chunk 14600 ---\n",
            "tf_metrics.AverageEpisodeLengthMetric(),\n",
            "]\n",
            "\n",
            "--- Chunk 14601 ---\n",
            "Discounting the rewards makes sense for training or to implement\n",
            "a policy, as it makes it possible to balance the importance of imme‐\n",
            "\n",
            "--- Chunk 14602 ---\n",
            "diate rewards with future rewards. However, once an episode is\n",
            "over, we can evaluate how good it was overalls by summing the\n",
            "\n",
            "--- Chunk 14603 ---\n",
            "undiscounted rewards. For this reason, the AverageReturnMetric\n",
            "computes the sum of undiscounted rewards for each episode, and it\n",
            "\n",
            "--- Chunk 14604 ---\n",
            "keeps track of the streaming mean of these sums over all the epi‐\n",
            "sodes it encounters.\n",
            "\n",
            "--- Chunk 14605 ---\n",
            "At any time, you can get the value of each of these metrics by calling its result()\n",
            "\n",
            "--- Chunk 14606 ---\n",
            "method (e.g., train_metrics[0].result()). Alternatively, you can log all metrics by\n",
            "\n",
            "--- Chunk 14607 ---\n",
            "calling log_metrics(train_metrics) (this function is located in the\n",
            "tf_agents.eval.metric_utils package):\n",
            "\n",
            "--- Chunk 14608 ---\n",
            ">>> from tf_agents.eval.metric_utils import log_metrics\n",
            ">>> import logging\n",
            ">>> logging.get_logger().set_level(logging.INFO)\n",
            "\n",
            "--- Chunk 14609 ---\n",
            ">>> log_metrics(train_metrics)\n",
            "[...]\n",
            "NumberOfEpisodes = 0\n",
            "EnvironmentSteps = 0\n",
            "AverageReturn = 0.0\n",
            "AverageEpisodeLength = 0.0\n",
            "\n",
            "--- Chunk 14610 ---\n",
            "Next, let’s create the collect driver.\n",
            "\n",
            "--- Chunk 14611 ---\n",
            "Creating the Collect Driver\n",
            "As we explored in Figure 18-13, a driver is an object that explores an environment\n",
            "\n",
            "--- Chunk 14612 ---\n",
            "using a given policy, collects experiences, and broadcasts them to some observers. At\n",
            "each step, the following things happen:\n",
            "\n",
            "--- Chunk 14613 ---\n",
            "• The driver passes the current time step to the collect policy, which uses this time\n",
            "\n",
            "--- Chunk 14614 ---\n",
            "step to choose an action and returns an action step object containing the action.\n",
            "\n",
            "--- Chunk 14615 ---\n",
            "656 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "\n",
            "\n",
            "• The driver then passes the action to the environment, which returns the next\n",
            "time step.\n",
            "\n",
            "--- Chunk 14616 ---\n",
            "• Finally, the driver creates a trajectory object to represent this transition and\n",
            "broadcasts it to all the observers.\n",
            "\n",
            "--- Chunk 14617 ---\n",
            "Some policies, such as RNN policies, are stateful: they choose an action based on both\n",
            "\n",
            "--- Chunk 14618 ---\n",
            "the given time step and their own internal state. Stateful policies return their own\n",
            "\n",
            "--- Chunk 14619 ---\n",
            "state in the action step, along with the chosen action. The driver will then pass this\n",
            "\n",
            "--- Chunk 14620 ---\n",
            "state back to the policy at the next time step. Moreover, the driver saves the policy\n",
            "\n",
            "--- Chunk 14621 ---\n",
            "state to the trajectory (in the policy_info field), so it ends up in the replay buffer.\n",
            "\n",
            "--- Chunk 14622 ---\n",
            "This is essential when training a stateful policy: when the agent samples a trajectory, it\n",
            "\n",
            "--- Chunk 14623 ---\n",
            "must set the policy’s state to the state it was in at the time of the sampled time step.\n",
            "\n",
            "--- Chunk 14624 ---\n",
            "Also, as discussed earlier, the environment may be a batched environment, in which\n",
            "\n",
            "--- Chunk 14625 ---\n",
            "case the driver passes a batched time step to the policy (i.e., a time step object contain‐\n",
            "\n",
            "--- Chunk 14626 ---\n",
            "ing a batch of observations, a batch of step types, a batch of rewards, and a batch of\n",
            "\n",
            "--- Chunk 14627 ---\n",
            "discounts, all four batches of the same size). The driver also passes a batch of previous\n",
            "\n",
            "--- Chunk 14628 ---\n",
            "policy states. The policy then returns a batched action step containing a batch of\n",
            "\n",
            "--- Chunk 14629 ---\n",
            "actions and a batch of policy states. Finally, the driver creates a batched trajectory (i.e.,\n",
            "\n",
            "--- Chunk 14630 ---\n",
            "a trajectory containing a batch of step types, a batch of observations, a batch of\n",
            "\n",
            "--- Chunk 14631 ---\n",
            "actions, a batch of rewards, and more generally a batch for each trajectory attribute,\n",
            "with all batches of the same size).\n",
            "\n",
            "--- Chunk 14632 ---\n",
            "There are two main driver classes: DynamicStepDriver and DynamicEpisodeDriver.\n",
            "\n",
            "--- Chunk 14633 ---\n",
            "The first one collects experiences for a given number of steps, while the second col‐\n",
            "\n",
            "--- Chunk 14634 ---\n",
            "lects experiences for a given number of episodes. We want to collect experiences for\n",
            "\n",
            "--- Chunk 14635 ---\n",
            "four steps for each training iteration (as was done in the 2015 DQN paper), so let’s\n",
            "create a DynamicStepDriver:\n",
            "\n",
            "--- Chunk 14636 ---\n",
            "from tf_agents.drivers.dynamic_step_driver import DynamicStepDriver\n",
            "\n",
            "--- Chunk 14637 ---\n",
            "collect_driver = DynamicStepDriver(\n",
            "    tf_env,\n",
            "    agent.collect_policy,\n",
            "    observers=[replay_buffer_observer] + training_metrics,\n",
            "\n",
            "--- Chunk 14638 ---\n",
            "num_steps=update_period) # collect 4 steps for each training iteration\n",
            "\n",
            "--- Chunk 14639 ---\n",
            "We give it the environment to play with, the agent’s collect policy, a list of observers\n",
            "\n",
            "--- Chunk 14640 ---\n",
            "(including the replay buffer observer and the training metrics), and finally the num‐\n",
            "\n",
            "--- Chunk 14641 ---\n",
            "ber of steps to run (in this case, four). We could now run it by calling its run()\n",
            "\n",
            "--- Chunk 14642 ---\n",
            "method, but it’s best to warm up the replay buffer with experiences collected using a\n",
            "\n",
            "--- Chunk 14643 ---\n",
            "purely random policy. For this, we can use the RandomTFPolicy class and create a sec‐\n",
            "\n",
            "--- Chunk 14644 ---\n",
            "ond driver that will run this policy for 20,000 steps (which is equivalent to 80,000\n",
            "\n",
            "--- Chunk 14645 ---\n",
            "simulator frames, as was done in the 2015 DQN paper). We can use our ShowPro\n",
            "gress observer to display the progress:\n",
            "\n",
            "--- Chunk 14646 ---\n",
            "The TF-Agents Library | 657\n",
            "\n",
            "\n",
            "\n",
            "from tf_agents.policies.random_tf_policy import RandomTFPolicy\n",
            "\n",
            "--- Chunk 14647 ---\n",
            "initial_collect_policy = RandomTFPolicy(tf_env.time_step_spec(),\n",
            "                                        tf_env.action_spec())\n",
            "\n",
            "--- Chunk 14648 ---\n",
            "init_driver = DynamicStepDriver(\n",
            "    tf_env,\n",
            "    initial_collect_policy,\n",
            "    observers=[replay_buffer.add_batch, ShowProgress(20000)],\n",
            "\n",
            "--- Chunk 14649 ---\n",
            "num_steps=20000) # <=> 80,000 ALE frames\n",
            "final_time_step, final_policy_state = init_driver.run()\n",
            "\n",
            "--- Chunk 14650 ---\n",
            "We’re almost ready to run the training loop! We just need one last component: the\n",
            "dataset.\n",
            "\n",
            "--- Chunk 14651 ---\n",
            "Creating the Dataset\n",
            "To sample a batch of trajectories from the replay buffer, call its get_next() method.\n",
            "\n",
            "--- Chunk 14652 ---\n",
            "This returns the batch of trajectories plus a BufferInfo object that contains the sam‐\n",
            "\n",
            "--- Chunk 14653 ---\n",
            "ple identifiers and their sampling probabilities (this may be useful for some algo‐\n",
            "\n",
            "--- Chunk 14654 ---\n",
            "rithms, such as PER). For example, the following code will sample a small batch of\n",
            "\n",
            "--- Chunk 14655 ---\n",
            "two trajectories (subepisodes), each containing three consecutive steps. These\n",
            "\n",
            "--- Chunk 14656 ---\n",
            "subepisodes are shown in Figure 18-15 (each row contains three consecutive steps\n",
            "from an episode):\n",
            "\n",
            "--- Chunk 14657 ---\n",
            ">>> trajectories, buffer_info = replay_buffer.get_next(\n",
            "...     sample_batch_size=2, num_steps=3)\n",
            "...\n",
            ">>> trajectories._fields\n",
            "\n",
            "--- Chunk 14658 ---\n",
            "('step_type', 'observation', 'action', 'policy_info',\n",
            " 'next_step_type', 'reward', 'discount')\n",
            ">>> trajectories.observation.shape\n",
            "\n",
            "--- Chunk 14659 ---\n",
            "TensorShape([2, 3, 84, 84, 4])\n",
            ">>> trajectories.step_type.numpy()\n",
            "array([[1, 1, 1],\n",
            "       [1, 1, 1]], dtype=int32)\n",
            "\n",
            "--- Chunk 14660 ---\n",
            "The trajectories object is a named tuple, with seven fields. Each field contains a\n",
            "\n",
            "--- Chunk 14661 ---\n",
            "tensor whose first two dimensions are 2 and 3 (since there are two trajectories, each\n",
            "\n",
            "--- Chunk 14662 ---\n",
            "with three steps). This explains why the shape of the observation field is [2, 3, 84, 84,\n",
            "\n",
            "--- Chunk 14663 ---\n",
            "4]: that’s two trajectories, each with three steps, and each step’s observation is 84 × 84\n",
            "\n",
            "--- Chunk 14664 ---\n",
            "× 4. Similarly, the step_type tensor has a shape of [2, 3]: in this example, both trajec‐\n",
            "\n",
            "--- Chunk 14665 ---\n",
            "tories contain three consecutive steps in the middle on an episode (types 1, 1, 1). In\n",
            "\n",
            "--- Chunk 14666 ---\n",
            "the second trajectory, you can barely see the ball at the lower left of the first observa‐\n",
            "\n",
            "--- Chunk 14667 ---\n",
            "tion, and it disappears in the next two observations, so the agent is about to lose a life,\n",
            "\n",
            "--- Chunk 14668 ---\n",
            "but the episode will not end immediately because it still has several lives left.\n",
            "\n",
            "--- Chunk 14669 ---\n",
            "658 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "\n",
            "\n",
            "Figure 18-15. Two trajectories containing three consecutive steps each\n",
            "\n",
            "--- Chunk 14670 ---\n",
            "Each trajectory is a concise representation of a sequence of consecutive time steps\n",
            "\n",
            "--- Chunk 14671 ---\n",
            "and action steps, designed to avoid redundancy. How so? Well, as you can see in\n",
            "\n",
            "--- Chunk 14672 ---\n",
            "Figure 18-16, transition n is composed of time step n, action step n, and time step n +\n",
            "\n",
            "--- Chunk 14673 ---\n",
            "1, while transition n + 1 is composed of time step n + 1, action step n + 1, and time\n",
            "\n",
            "--- Chunk 14674 ---\n",
            "step n + 2. If we just stored these two transitions directly in the replay buffer, the time\n",
            "\n",
            "--- Chunk 14675 ---\n",
            "step n + 1 would be duplicated. To avoid this duplication, the nth trajectory step\n",
            "\n",
            "--- Chunk 14676 ---\n",
            "includes only the type and observation from time step n (not its reward and dis‐\n",
            "\n",
            "--- Chunk 14677 ---\n",
            "count), and it does not contain the observation from time step n + 1 (however, it does\n",
            "\n",
            "--- Chunk 14678 ---\n",
            "contain a copy of the next time step’s type; that’s the only duplication).\n",
            "\n",
            "--- Chunk 14679 ---\n",
            "The TF-Agents Library | 659\n",
            "\n",
            "\n",
            "\n",
            "Figure 18-16. Trajectories, transitions, time steps, and action steps\n",
            "\n",
            "--- Chunk 14680 ---\n",
            "So if you have a batch of trajectories where each trajectory has t + 1 steps (from time\n",
            "\n",
            "--- Chunk 14681 ---\n",
            "step n to time step n + t), then it contains all the data from time step n to time step n\n",
            "\n",
            "--- Chunk 14682 ---\n",
            "+ t, except for the reward and discount from time step n (but it contains the reward\n",
            "\n",
            "--- Chunk 14683 ---\n",
            "and discount of time step n + t + 1). This represents t transitions (n to n + 1, n + 1 to\n",
            "n + 2, …, n + t – 1 to n + t).\n",
            "\n",
            "--- Chunk 14684 ---\n",
            "The to_transition() function in the tf_agents.trajectories.trajectory mod‐\n",
            "\n",
            "--- Chunk 14685 ---\n",
            "ule converts a batched trajectory into a list containing a batched time_step, a batched\n",
            "\n",
            "--- Chunk 14686 ---\n",
            "action_step, and a batched next_time_step. Notice that the second dimension is 2\n",
            "\n",
            "--- Chunk 14687 ---\n",
            "instead of 3, since there are t transitions between t + 1 time steps (don’t worry if\n",
            "you’re a bit confused; you’ll get the hang of it):\n",
            "\n",
            "--- Chunk 14688 ---\n",
            ">>> from tf_agents.trajectories.trajectory import to_transition\n",
            ">>> time_steps, action_steps, next_time_steps = to_transition(trajectories)\n",
            "\n",
            "--- Chunk 14689 ---\n",
            ">>> time_steps.observation.shape\n",
            "TensorShape([2, 2, 84, 84, 4]) # 3 time steps = 2 transitions\n",
            "\n",
            "--- Chunk 14690 ---\n",
            "A sampled trajectory may actually overlap two (or more) episodes!\n",
            "In this case, it will contain boundary transitions, meaning transi‐\n",
            "\n",
            "--- Chunk 14691 ---\n",
            "tions with a step_type equal to 2 (end) and a next_step_type\n",
            "equal to 0 (start). Of course, TF-Agents properly handles such tra‐\n",
            "\n",
            "--- Chunk 14692 ---\n",
            "jectories (e.g., by resetting the policy state when encountering a\n",
            "boundary). The trajectory’s is_boundary() method returns a ten‐\n",
            "\n",
            "--- Chunk 14693 ---\n",
            "sor indicating whether each step is a boundary or not.\n",
            "\n",
            "--- Chunk 14694 ---\n",
            "660 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 14695 ---\n",
            "For our main training loop, instead of calling the get_next() method, we will use a\n",
            "\n",
            "--- Chunk 14696 ---\n",
            "tf.data.Dataset. This way, we can benefit from the power of the Data API (e.g., par‐\n",
            "\n",
            "--- Chunk 14697 ---\n",
            "allelism and prefetching). For this, we call the replay buffer’s as_dataset() method:\n",
            "\n",
            "--- Chunk 14698 ---\n",
            "dataset = replay_buffer.as_dataset(\n",
            "    sample_batch_size=64,\n",
            "    num_steps=2,\n",
            "    num_parallel_calls=3).prefetch(3)\n",
            "\n",
            "--- Chunk 14699 ---\n",
            "We will sample batches of 64 trajectories at each training step (as in the 2015 DQN\n",
            "\n",
            "--- Chunk 14700 ---\n",
            "paper), each with 2 steps (i.e., 2 steps = 1 full transition, including the next step’s\n",
            "\n",
            "--- Chunk 14701 ---\n",
            "observation). This dataset will process three elements in parallel, and prefetch three\n",
            "batches.\n",
            "\n",
            "--- Chunk 14702 ---\n",
            "For on-policy algorithms such as Policy Gradients, each experience\n",
            "should be sampled once, used from training, and then discarded. In\n",
            "\n",
            "--- Chunk 14703 ---\n",
            "this case, you can still use a replay buffer, but instead of using a\n",
            "Dataset, you would call the replay buffer’s gather_all() method\n",
            "\n",
            "--- Chunk 14704 ---\n",
            "at each training iteration to get a tensor containing all the trajecto‐\n",
            "ries recorded so far, then use them to perform a training step, and\n",
            "\n",
            "--- Chunk 14705 ---\n",
            "finally clear the replay buffer by calling its clear() method.\n",
            "\n",
            "--- Chunk 14706 ---\n",
            "Now that we have all the components in place, we are ready to train the model!\n",
            "\n",
            "--- Chunk 14707 ---\n",
            "Creating the Training Loop\n",
            "To speed up training, we will convert the main functions to TensorFlow Functions.\n",
            "\n",
            "--- Chunk 14708 ---\n",
            "For this we will use the tf_agents.utils.common.function() function, which wraps\n",
            "tf.function(), with some extra experimental options:\n",
            "\n",
            "--- Chunk 14709 ---\n",
            "from tf_agents.utils.common import function\n",
            "\n",
            "collect_driver.run = function(collect_driver.run)\n",
            "agent.train = function(agent.train)\n",
            "\n",
            "--- Chunk 14710 ---\n",
            "Let’s create a small function that will run the main training loop for n_iterations:\n",
            "def train_agent(n_iterations):\n",
            "    time_step = None\n",
            "\n",
            "--- Chunk 14711 ---\n",
            "policy_state = agent.collect_policy.get_initial_state(tf_env.batch_size)\n",
            "    iterator = iter(dataset)\n",
            "    for iteration in range(n_iterations):\n",
            "\n",
            "--- Chunk 14712 ---\n",
            "time_step, policy_state = collect_driver.run(time_step, policy_state)\n",
            "        trajectories, buffer_info = next(iterator)\n",
            "\n",
            "--- Chunk 14713 ---\n",
            "train_loss = agent.train(trajectories)\n",
            "        print(\"\\r{} loss:{:.5f}\".format(\n",
            "            iteration, train_loss.loss.numpy()), end=\"\")\n",
            "\n",
            "--- Chunk 14714 ---\n",
            "if iteration % 1000 == 0:\n",
            "            log_metrics(train_metrics)\n",
            "\n",
            "--- Chunk 14715 ---\n",
            "The TF-Agents Library | 661\n",
            "\n",
            "--- Chunk 14716 ---\n",
            "The function first asks the collect policy for its initial state (given the environment\n",
            "\n",
            "--- Chunk 14717 ---\n",
            "batch size, which is 1 in this case). Since the policy is stateless, this returns an empty\n",
            "\n",
            "--- Chunk 14718 ---\n",
            "tuple (so we could have written policy_state = ()). Next, we create an iterator over\n",
            "\n",
            "--- Chunk 14719 ---\n",
            "the dataset, and we run the training loop. At each iteration, we call the driver’s run()\n",
            "\n",
            "--- Chunk 14720 ---\n",
            "method, passing it the current time step (initially None) and the current policy state. It\n",
            "\n",
            "--- Chunk 14721 ---\n",
            "will run the collect policy and collect experience for four steps (as we configured ear‐\n",
            "\n",
            "--- Chunk 14722 ---\n",
            "lier), broadcasting the collected trajectories to the replay buffer and the metrics. Next,\n",
            "\n",
            "--- Chunk 14723 ---\n",
            "we sample one batch of trajectories from the dataset, and we pass it to the agent’s\n",
            "\n",
            "--- Chunk 14724 ---\n",
            "train() method. It returns a train_loss object which may vary depending on the\n",
            "\n",
            "--- Chunk 14725 ---\n",
            "type of agent. Next, we display the iteration number and the training loss, and every\n",
            "\n",
            "--- Chunk 14726 ---\n",
            "1,000 iterations we log all the metrics. Now you can just call train_agent() for some\n",
            "\n",
            "--- Chunk 14727 ---\n",
            "number of iterations, and see the agent gradually learn to play Breakout!\n",
            "\n",
            "--- Chunk 14728 ---\n",
            "train_agent(10000000)\n",
            "\n",
            "--- Chunk 14729 ---\n",
            "This will take a lot of computing power and a lot of patience (it may take hours, or\n",
            "\n",
            "--- Chunk 14730 ---\n",
            "even days, depending on your hardware), plus you may need to run the algorithm\n",
            "\n",
            "--- Chunk 14731 ---\n",
            "several times with different random seeds to get good results, but once it’s done, the\n",
            "\n",
            "--- Chunk 14732 ---\n",
            "agent will be superhuman (at least at Breakout). You can also try training this DQN\n",
            "\n",
            "--- Chunk 14733 ---\n",
            "agent on other Atari games: it can achieve superhuman skill at most action games,\n",
            "but it is not so good at games with long-running storylines.22\n",
            "\n",
            "--- Chunk 14734 ---\n",
            "Overview of Some Popular RL Algorithms\n",
            "Before we finish this chapter, let’s take a quick look at a few popular RL algorithms:\n",
            "\n",
            "--- Chunk 14735 ---\n",
            "Actor-Critic algorithms\n",
            "\n",
            "--- Chunk 14736 ---\n",
            "A family of RL algorithms that combine Policy Gradients with Deep Q-\n",
            "Networks. An Actor-Critic agent contains two neural networks: a policy net and\n",
            "\n",
            "--- Chunk 14737 ---\n",
            "a DQN. The DQN is trained normally, by learning from the agent’s experiences.\n",
            "\n",
            "--- Chunk 14738 ---\n",
            "The policy net learns differently (and much faster) than in regular PG: instead of\n",
            "\n",
            "--- Chunk 14739 ---\n",
            "estimating the value of each action by going through multiple episodes, then\n",
            "\n",
            "--- Chunk 14740 ---\n",
            "summing the future discounted rewards for each action, and finally normalizing\n",
            "\n",
            "--- Chunk 14741 ---\n",
            "them, the agent (actor) relies on the action values estimated by the DQN (critic).\n",
            "\n",
            "--- Chunk 14742 ---\n",
            "It’s a bit like an athlete (the agent) learning with the help of a coach (the DQN).\n",
            "\n",
            "--- Chunk 14743 ---\n",
            "Asynchronous Advantage Actor-Critic23 (A3C)\n",
            "An important Actor-Critic variant introduced by DeepMind researchers in 2016,\n",
            "\n",
            "--- Chunk 14744 ---\n",
            "where multiple agents learn in parallel, exploring different copies of the environ‐\n",
            "\n",
            "--- Chunk 14745 ---\n",
            "22 For a comparison of this algorithm’s performance on various Atari games, see figure 3 in DeepMind’s 2015\n",
            "paper.\n",
            "\n",
            "--- Chunk 14746 ---\n",
            "23 Volodymyr Mnih et al., “Asynchonous Methods for Deep Reinforcement Learning,” Proceedings of the 33rd\n",
            "\n",
            "--- Chunk 14747 ---\n",
            "International Conference on Machine Learning (2016): 1928–1937.\n",
            "\n",
            "--- Chunk 14748 ---\n",
            "662 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 14749 ---\n",
            "ment. At regular intervals, but asynchronously (hence the name), each agent\n",
            "\n",
            "--- Chunk 14750 ---\n",
            "pushes some weight updates to a master network, then it pulls the latest weights\n",
            "\n",
            "--- Chunk 14751 ---\n",
            "from that network. Each agent thus contributes to improving the master network\n",
            "\n",
            "--- Chunk 14752 ---\n",
            "and benefits from what the other agents have learned. Moreover, instead of esti‐\n",
            "\n",
            "--- Chunk 14753 ---\n",
            "mating the Q-Values, the DQN estimates the advantage of each action (hence the\n",
            "second A in the name), which stabilizes training.\n",
            "\n",
            "--- Chunk 14754 ---\n",
            "Advantage Actor-Critic (A2C)\n",
            "A variant of the A3C algorithm that removes the asynchronicity. All model\n",
            "\n",
            "--- Chunk 14755 ---\n",
            "updates are synchronous, so gradient updates are performed over larger batches,\n",
            "which allows the model to better utilize the power of the GPU.\n",
            "\n",
            "--- Chunk 14756 ---\n",
            "Soft Actor-Critic24 (SAC)\n",
            "An Actor-Critic variant proposed in 2018 by Tuomas Haarnoja and other UC\n",
            "\n",
            "--- Chunk 14757 ---\n",
            "Berkeley researchers. It learns not only rewards, but also to maximize the entropy\n",
            "\n",
            "--- Chunk 14758 ---\n",
            "of its actions. In other words, it tries to be as unpredictable as possible while still\n",
            "\n",
            "--- Chunk 14759 ---\n",
            "getting as many rewards as possible. This encourages the agent to explore the\n",
            "\n",
            "--- Chunk 14760 ---\n",
            "environment, which speeds up training, and makes it less likely to repeatedly exe‐\n",
            "\n",
            "--- Chunk 14761 ---\n",
            "cute the same action when the DQN produces imperfect estimates. This algo‐\n",
            "rithm has demonstrated an amazing sample efficiency (contrary to all the\n",
            "\n",
            "--- Chunk 14762 ---\n",
            "previous algorithms, which learn very slowly). SAC is available in TF-Agents.\n",
            "\n",
            "--- Chunk 14763 ---\n",
            "Proximal Policy Optimization (PPO)25\n",
            "\n",
            "--- Chunk 14764 ---\n",
            "An algorithm based on A2C that clips the loss function to avoid excessively large\n",
            "\n",
            "--- Chunk 14765 ---\n",
            "weight updates (which often lead to training instabilities). PPO is a simplification\n",
            "\n",
            "--- Chunk 14766 ---\n",
            "of the previous Trust Region Policy Optimization26 (TRPO) algorithm, also by\n",
            "\n",
            "--- Chunk 14767 ---\n",
            "John Schulman and other OpenAI researchers. OpenAI made the news in April\n",
            "2019 with their AI called OpenAI Five, based on the PPO algorithm, which\n",
            "\n",
            "--- Chunk 14768 ---\n",
            "defeated the world champions at the multiplayer game Dota 2. PPO is also avail‐\n",
            "able in TF-Agents.\n",
            "\n",
            "--- Chunk 14769 ---\n",
            "24 Tuomas Haarnoja et al., “Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with\n",
            "\n",
            "--- Chunk 14770 ---\n",
            "a Stochastic Actor,” Proceedings of the 35th International Conference on Machine Learning (2018): 1856–1865.\n",
            "\n",
            "--- Chunk 14771 ---\n",
            "25 John Schulman et al., “Proximal Policy Optimization Algorithms,” arXiv preprint arXiv:1707.06347 (2017).\n",
            "\n",
            "--- Chunk 14772 ---\n",
            "26 John Schulman et al., “Trust Region Policy Optimization,” Proceedings of the 32nd International Conference on\n",
            "\n",
            "--- Chunk 14773 ---\n",
            "Machine Learning (2015): 1889–1897.\n",
            "\n",
            "Overview of Some Popular RL Algorithms | 663\n",
            "\n",
            "\n",
            "\n",
            "Curiosity-based exploration27\n",
            "\n",
            "--- Chunk 14774 ---\n",
            "A recurring problem in RL is the sparsity of the rewards, which makes learning\n",
            "\n",
            "--- Chunk 14775 ---\n",
            "very slow and inefficient. Deepak Pathak and other UC Berkeley researchers have\n",
            "\n",
            "--- Chunk 14776 ---\n",
            "proposed an exciting way to tackle this issue: why not ignore the rewards, and\n",
            "\n",
            "--- Chunk 14777 ---\n",
            "just make the agent extremely curious to explore the environment? The rewards\n",
            "\n",
            "--- Chunk 14778 ---\n",
            "thus become intrinsic to the agent, rather than coming from the environment.\n",
            "\n",
            "--- Chunk 14779 ---\n",
            "Similarly, stimulating curiosity in a child is more likely to give good results than\n",
            "\n",
            "--- Chunk 14780 ---\n",
            "purely rewarding the child for getting good grades. How does this work? The\n",
            "\n",
            "--- Chunk 14781 ---\n",
            "agent continuously tries to predict the outcome of its actions, and it seeks situa‐\n",
            "\n",
            "--- Chunk 14782 ---\n",
            "tions where the outcome does not match its predictions. In other words, it wants\n",
            "\n",
            "--- Chunk 14783 ---\n",
            "to be surprised. If the outcome is predictable (boring), it goes elsewhere. How‐\n",
            "\n",
            "--- Chunk 14784 ---\n",
            "ever, if the outcome is unpredictable but the agent notices that it has no control\n",
            "\n",
            "--- Chunk 14785 ---\n",
            "over it, it also gets bored after a while. With only curiosity, the authors succeeded\n",
            "\n",
            "--- Chunk 14786 ---\n",
            "in training an agent at many video games: even though the agent gets no penalty\n",
            "\n",
            "--- Chunk 14787 ---\n",
            "for losing, the game starts over, which is boring so it learns to avoid it.\n",
            "\n",
            "--- Chunk 14788 ---\n",
            "We covered many topics in this chapter: Policy Gradients, Markov chains, Markov\n",
            "\n",
            "--- Chunk 14789 ---\n",
            "decision processes, Q-Learning, Approximate Q-Learning, and Deep Q-Learning and\n",
            "\n",
            "--- Chunk 14790 ---\n",
            "its main variants (fixed Q-Value targets, Double DQN, Dueling DQN, and prioritized\n",
            "\n",
            "--- Chunk 14791 ---\n",
            "experience replay). We discussed how to use TF-Agents to train agents at scale, and\n",
            "\n",
            "--- Chunk 14792 ---\n",
            "finally we took a quick look at a few other popular algorithms. Reinforcement Learn‐\n",
            "\n",
            "--- Chunk 14793 ---\n",
            "ing is a huge and exciting field, with new ideas and algorithms popping out every day,\n",
            "\n",
            "--- Chunk 14794 ---\n",
            "so I hope this chapter sparked your curiosity: there is a whole world to explore!\n",
            "\n",
            "--- Chunk 14795 ---\n",
            "Exercises\n",
            "1. How would you define Reinforcement Learning? How is it different from regular\n",
            "\n",
            "--- Chunk 14796 ---\n",
            "supervised or unsupervised learning?\n",
            "2. Can you think of three possible applications of RL that were not mentioned in\n",
            "\n",
            "--- Chunk 14797 ---\n",
            "this chapter? For each of them, what is the environment? What is the agent?\n",
            "What are some possible actions? What are the rewards?\n",
            "\n",
            "--- Chunk 14798 ---\n",
            "3. What is the discount factor? Can the optimal policy change if you modify the dis‐\n",
            "count factor?\n",
            "\n",
            "--- Chunk 14799 ---\n",
            "4. How do you measure the performance of a Reinforcement Learning agent?\n",
            "\n",
            "--- Chunk 14800 ---\n",
            "5. What is the credit assignment problem? When does it occur? How can you allevi‐\n",
            "\n",
            "--- Chunk 14801 ---\n",
            "ate it?\n",
            "6. What is the point of using a replay buffer?\n",
            "\n",
            "--- Chunk 14802 ---\n",
            "27 Deepak Pathak et al., “Curiosity-Driven Exploration by Self-Supervised Prediction,” Proceedings of the 34th\n",
            "\n",
            "--- Chunk 14803 ---\n",
            "International Conference on Machine Learning (2017): 2778–2787.\n",
            "\n",
            "--- Chunk 14804 ---\n",
            "664 | Chapter 18: Reinforcement Learning\n",
            "\n",
            "--- Chunk 14805 ---\n",
            "7. What is an off-policy RL algorithm?\n",
            "8. Use policy gradients to solve OpenAI Gym’s LunarLander-v2 environment. You\n",
            "\n",
            "--- Chunk 14806 ---\n",
            "will need to install the Box2D dependencies (python3 -m pip install -U\n",
            "gym[box2d]).\n",
            "\n",
            "--- Chunk 14807 ---\n",
            "9. Use TF-Agents to train an agent that can achieve a superhuman level at\n",
            "SpaceInvaders-v4 using any of the available algorithms.\n",
            "\n",
            "--- Chunk 14808 ---\n",
            "10. If you have about $100 to spare, you can purchase a Raspberry Pi 3 plus some\n",
            "\n",
            "--- Chunk 14809 ---\n",
            "cheap robotics components, install TensorFlow on the Pi, and go wild! For an\n",
            "\n",
            "--- Chunk 14810 ---\n",
            "example, check out this fun post by Lukas Biewald, or take a look at GoPiGo or\n",
            "\n",
            "--- Chunk 14811 ---\n",
            "BrickPi. Start with simple goals, like making the robot turn around to find the\n",
            "\n",
            "--- Chunk 14812 ---\n",
            "brightest angle (if it has a light sensor) or the closest object (if it has a sonar sen‐\n",
            "\n",
            "--- Chunk 14813 ---\n",
            "sor), and move in that direction. Then you can start using Deep Learning: for\n",
            "\n",
            "--- Chunk 14814 ---\n",
            "example, if the robot has a camera, you can try to implement an object detection\n",
            "\n",
            "--- Chunk 14815 ---\n",
            "algorithm so it detects people and moves toward them. You can also try to use RL\n",
            "\n",
            "--- Chunk 14816 ---\n",
            "to make the agent learn on its own how to use the motors to achieve that goal.\n",
            "Have fun!\n",
            "\n",
            "--- Chunk 14817 ---\n",
            "Solutions to these exercises are available in Appendix A.\n",
            "\n",
            "Exercises | 665\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER 19\n",
            "Training and Deploying TensorFlow\n",
            "\n",
            "Models at Scale\n",
            "\n",
            "--- Chunk 14818 ---\n",
            "Once you have a beautiful model that makes amazing predictions, what do you do\n",
            "\n",
            "--- Chunk 14819 ---\n",
            "with it? Well, you need to put it in production! This could be as simple as running the\n",
            "\n",
            "--- Chunk 14820 ---\n",
            "model on a batch of data and perhaps writing a script that runs this model every\n",
            "\n",
            "--- Chunk 14821 ---\n",
            "night. However, it is often much more involved. Various parts of your infrastructure\n",
            "\n",
            "--- Chunk 14822 ---\n",
            "may need to use this model on live data, in which case you probably want to wrap\n",
            "\n",
            "--- Chunk 14823 ---\n",
            "your model in a web service: this way, any part of your infrastructure can query your\n",
            "\n",
            "--- Chunk 14824 ---\n",
            "model at any time using a simple REST API (or some other protocol), as we discussed\n",
            "\n",
            "--- Chunk 14825 ---\n",
            "in Chapter 2. But as time passes, you need to regularly retrain your model on fresh\n",
            "\n",
            "--- Chunk 14826 ---\n",
            "data and push the updated version to production. You must handle model versioning,\n",
            "\n",
            "--- Chunk 14827 ---\n",
            "gracefully transition from one model to the next, possibly roll back to the previous\n",
            "\n",
            "--- Chunk 14828 ---\n",
            "model in case of problems, and perhaps run multiple different models in parallel to\n",
            "\n",
            "--- Chunk 14829 ---\n",
            "perform A/B experiments.1 If your product becomes successful, your service may start\n",
            "\n",
            "--- Chunk 14830 ---\n",
            "to get plenty of queries per second (QPS), and it must scale up to support the load. A\n",
            "\n",
            "--- Chunk 14831 ---\n",
            "great solution to scale up your service, as we will see in this chapter, is to use TF Serv‐\n",
            "\n",
            "--- Chunk 14832 ---\n",
            "ing, either on your own hardware infrastructure or via a cloud service such as Google\n",
            "\n",
            "--- Chunk 14833 ---\n",
            "Cloud AI Platform. It will take care of efficiently serving your model, handle graceful\n",
            "\n",
            "--- Chunk 14834 ---\n",
            "model transitions, and more. If you use the cloud platform, you will also get many\n",
            "extra features, such as powerful monitoring tools.\n",
            "\n",
            "--- Chunk 14835 ---\n",
            "Moreover, if you have a lot of training data, and compute-intensive models, then\n",
            "\n",
            "--- Chunk 14836 ---\n",
            "training time may be prohibitively long. If your product needs to adapt to changes\n",
            "\n",
            "--- Chunk 14837 ---\n",
            "quickly, then a long training time can be a showstopper (e.g., think of a news\n",
            "\n",
            "--- Chunk 14838 ---\n",
            "1 An A/B experiment consists in testing two different versions of your product on different subsets of users in\n",
            "\n",
            "--- Chunk 14839 ---\n",
            "order to check which version works best and get other insights.\n",
            "\n",
            "--- Chunk 14840 ---\n",
            "667\n",
            "\n",
            "--- Chunk 14841 ---\n",
            "recommendation system promoting news from last week). Perhaps even more impor‐\n",
            "\n",
            "--- Chunk 14842 ---\n",
            "tantly, a long training time will prevent you from experimenting with new ideas. In\n",
            "\n",
            "--- Chunk 14843 ---\n",
            "Machine Learning (as in many other fields), it is hard to know in advance which ideas\n",
            "\n",
            "--- Chunk 14844 ---\n",
            "will work, so you should try out as many as possible, as fast as possible. One way to\n",
            "\n",
            "--- Chunk 14845 ---\n",
            "speed up training is to use hardware accelerators such as GPUs or TPUs. To go even\n",
            "\n",
            "--- Chunk 14846 ---\n",
            "faster, you can train a model across multiple machines, each equipped with multiple\n",
            "\n",
            "--- Chunk 14847 ---\n",
            "hardware accelerators. TensorFlow’s simple yet powerful Distribution Strategies API\n",
            "makes this easy, as we will see.\n",
            "\n",
            "--- Chunk 14848 ---\n",
            "In this chapter we will look at how to deploy models, first to TF Serving, then to Goo‐\n",
            "\n",
            "--- Chunk 14849 ---\n",
            "gle Cloud AI Platform. We will also take a quick look at deploying models to mobile\n",
            "\n",
            "--- Chunk 14850 ---\n",
            "apps, embedded devices, and web apps. Lastly, we will discuss how to speed up com‐\n",
            "\n",
            "--- Chunk 14851 ---\n",
            "putations using GPUs and how to train models across multiple devices and servers\n",
            "\n",
            "--- Chunk 14852 ---\n",
            "using the Distribution Strategies API. That’s a lot of topics to discuss, so let’s get\n",
            "started!\n",
            "\n",
            "--- Chunk 14853 ---\n",
            "Serving a TensorFlow Model\n",
            "Once you have trained a TensorFlow model, you can easily use it in any Python code:\n",
            "\n",
            "--- Chunk 14854 ---\n",
            "if it’s a tf.keras model, just call its predict() method! But as your infrastructure\n",
            "\n",
            "--- Chunk 14855 ---\n",
            "grows, there comes a point where it is preferable to wrap your model in a small ser‐\n",
            "\n",
            "--- Chunk 14856 ---\n",
            "vice whose sole role is to make predictions and have the rest of the infrastructure\n",
            "\n",
            "--- Chunk 14857 ---\n",
            "query it (e.g., via a REST or gRPC API).2 This decouples your model from the rest of\n",
            "\n",
            "--- Chunk 14858 ---\n",
            "the infrastructure, making it possible to easily switch model versions or scale the ser‐\n",
            "\n",
            "--- Chunk 14859 ---\n",
            "vice up as needed (independently from the rest of your infrastructure), perform A/B\n",
            "\n",
            "--- Chunk 14860 ---\n",
            "experiments, and ensure that all your software components rely on the same model\n",
            "\n",
            "--- Chunk 14861 ---\n",
            "versions. It also simplifies testing and development, and more. You could create your\n",
            "\n",
            "--- Chunk 14862 ---\n",
            "own microservice using any technology you want (e.g., using the Flask library), but\n",
            "why reinvent the wheel when you can just use TF Serving?\n",
            "\n",
            "--- Chunk 14863 ---\n",
            "Using TensorFlow Serving\n",
            "TF Serving is a very efficient, battle-tested model server that’s written in C++. It can\n",
            "\n",
            "--- Chunk 14864 ---\n",
            "sustain a high load, serve multiple versions of your models and watch a model reposi‐\n",
            "\n",
            "--- Chunk 14865 ---\n",
            "tory to automatically deploy the latest versions, and more (see Figure 19-1).\n",
            "\n",
            "--- Chunk 14866 ---\n",
            "2 A REST (or RESTful) API is an API that uses standard HTTP verbs, such as GET, POST, PUT, and DELETE,\n",
            "\n",
            "--- Chunk 14867 ---\n",
            "and uses JSON inputs and outputs. The gRPC protocol is more complex but more efficient. Data is exchanged\n",
            "using protocol buffers (see Chapter 13).\n",
            "\n",
            "--- Chunk 14868 ---\n",
            "668 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 14869 ---\n",
            "Figure 19-1. TF Serving can serve multiple models and automatically deploy the latest\n",
            "version of each model\n",
            "\n",
            "--- Chunk 14870 ---\n",
            "So let’s suppose you have trained an MNIST model using tf.keras, and you want to\n",
            "\n",
            "--- Chunk 14871 ---\n",
            "deploy it to TF Serving. The first thing you have to do is export this model to Tensor‐\n",
            "Flow’s SavedModel format.\n",
            "\n",
            "--- Chunk 14872 ---\n",
            "Exporting SavedModels\n",
            "TensorFlow provides a simple tf.saved_model.save() function to export models to\n",
            "\n",
            "--- Chunk 14873 ---\n",
            "the SavedModel format. All you need to do is give it the model, specifying its name\n",
            "\n",
            "--- Chunk 14874 ---\n",
            "and version number, and the function will save the model’s computation graph and its\n",
            "weights:\n",
            "\n",
            "--- Chunk 14875 ---\n",
            "model = keras.models.Sequential([...])\n",
            "model.compile([...])\n",
            "history = model.fit([...])\n",
            "\n",
            "--- Chunk 14876 ---\n",
            "model_version = \"0001\"\n",
            "model_name = \"my_mnist_model\"\n",
            "model_path = os.path.join(model_name, model_version)\n",
            "tf.saved_model.save(model, model_path)\n",
            "\n",
            "--- Chunk 14877 ---\n",
            "Alternatively, you can just use the model’s save() method (model.save(model_\n",
            "\n",
            "--- Chunk 14878 ---\n",
            "path)): as long as the file’s extension is not .h5, the model will be saved using the\n",
            "SavedModel format instead of the HDF5 format.\n",
            "\n",
            "--- Chunk 14879 ---\n",
            "It’s usually a good idea to include all the preprocessing layers in the final model you\n",
            "\n",
            "--- Chunk 14880 ---\n",
            "export so that it can ingest data in its natural form once it is deployed to production.\n",
            "\n",
            "--- Chunk 14881 ---\n",
            "This avoids having to take care of preprocessing separately within the application that\n",
            "\n",
            "--- Chunk 14882 ---\n",
            "uses the model. Bundling the preprocessing steps within the model also makes it sim‐\n",
            "\n",
            "--- Chunk 14883 ---\n",
            "pler to update them later on and limits the risk of mismatch between a model and the\n",
            "preprocessing steps it requires.\n",
            "\n",
            "--- Chunk 14884 ---\n",
            "Serving a TensorFlow Model | 669\n",
            "\n",
            "--- Chunk 14885 ---\n",
            "Since a SavedModel saves the computation graph, it can only be\n",
            "used with models that are based exclusively on TensorFlow opera‐\n",
            "\n",
            "--- Chunk 14886 ---\n",
            "tions, excluding the tf.py_function() operation (which wraps\n",
            "arbitrary Python code). It also excludes dynamic tf.keras models\n",
            "\n",
            "--- Chunk 14887 ---\n",
            "(see Appendix G), since these models cannot be converted to com‐\n",
            "putation graphs. Dynamic models need to be served using other\n",
            "tools (e.g., Flask).\n",
            "\n",
            "--- Chunk 14888 ---\n",
            "A SavedModel represents a version of your model. It is stored as a directory contain‐\n",
            "\n",
            "--- Chunk 14889 ---\n",
            "ing a saved_model.pb file, which defines the computation graph (represented as a seri‐\n",
            "\n",
            "--- Chunk 14890 ---\n",
            "alized protocol buffer), and a variables subdirectory containing the variable values.\n",
            "\n",
            "--- Chunk 14891 ---\n",
            "For models containing a large number of weights, these variable values may be split\n",
            "\n",
            "--- Chunk 14892 ---\n",
            "across multiple files. A SavedModel also includes an assets subdirectory that may con‐\n",
            "\n",
            "--- Chunk 14893 ---\n",
            "tain additional data, such as vocabulary files, class names, or some example instances\n",
            "\n",
            "--- Chunk 14894 ---\n",
            "for this model. The directory structure is as follows (in this example, we don’t use\n",
            "assets):\n",
            "\n",
            "--- Chunk 14895 ---\n",
            "my_mnist_model\n",
            "└── 0001\n",
            "    ├── assets\n",
            "    ├── saved_model.pb\n",
            "    └── variables\n",
            "        ├── variables.data-00000-of-00001\n",
            "\n",
            "--- Chunk 14896 ---\n",
            "└── variables.index\n",
            "\n",
            "--- Chunk 14897 ---\n",
            "As you might expect, you can load a SavedModel using the tf.saved_model.load()\n",
            "\n",
            "--- Chunk 14898 ---\n",
            "function. However, the returned object is not a Keras model: it represents the Saved‐\n",
            "\n",
            "--- Chunk 14899 ---\n",
            "Model, including its computation graph and variable values. You can use it like a\n",
            "\n",
            "--- Chunk 14900 ---\n",
            "function, and it will make predictions (make sure to pass the inputs as tensors of the\n",
            "appropriate type):\n",
            "\n",
            "--- Chunk 14901 ---\n",
            "saved_model = tf.saved_model.load(model_path)\n",
            "y_pred = saved_model(tf.constant(X_new, dtype=tf.float32))\n",
            "\n",
            "--- Chunk 14902 ---\n",
            "Alternatively, you can load this SavedModel directly to a Keras model using the\n",
            "keras.models.load_model() function:\n",
            "\n",
            "--- Chunk 14903 ---\n",
            "model = keras.models.load_model(model_path)\n",
            "y_pred = model.predict(tf.constant(X_new, dtype=tf.float32))\n",
            "\n",
            "--- Chunk 14904 ---\n",
            "TensorFlow also comes with a small saved_model_cli command-line tool to inspect\n",
            "SavedModels:\n",
            "\n",
            "--- Chunk 14905 ---\n",
            "$ export ML_PATH=\"$HOME/ml\" # point to this project, wherever it is\n",
            "$ cd $ML_PATH\n",
            "$ saved_model_cli show --dir my_mnist_model/0001 --all\n",
            "\n",
            "--- Chunk 14906 ---\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "signature_def['__saved_model_init_op']:\n",
            "  [...]\n",
            "\n",
            "--- Chunk 14907 ---\n",
            "670 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 14908 ---\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['flatten_input'] tensor_info:\n",
            "\n",
            "--- Chunk 14909 ---\n",
            "dtype: DT_FLOAT\n",
            "        shape: (-1, 28, 28)\n",
            "        name: serving_default_flatten_input:0\n",
            "\n",
            "--- Chunk 14910 ---\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_1'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "\n",
            "--- Chunk 14911 ---\n",
            "shape: (-1, 10)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "\n",
            "--- Chunk 14912 ---\n",
            "A SavedModel contains one or more metagraphs. A metagraph is a computation\n",
            "\n",
            "--- Chunk 14913 ---\n",
            "graph plus some function signature definitions (including their input and output\n",
            "\n",
            "--- Chunk 14914 ---\n",
            "names, types, and shapes). Each metagraph is identified by a set of tags. For example,\n",
            "\n",
            "--- Chunk 14915 ---\n",
            "you may want to have a metagraph containing the full computation graph, including\n",
            "\n",
            "--- Chunk 14916 ---\n",
            "the training operations (this one may be tagged \"train\", for example), and another\n",
            "\n",
            "--- Chunk 14917 ---\n",
            "metagraph containing a pruned computation graph with only the prediction opera‐\n",
            "\n",
            "--- Chunk 14918 ---\n",
            "tions, including some GPU-specific operations (this metagraph may be tagged\n",
            "\"serve\", \"gpu\"). However, when you pass a tf.keras model to the\n",
            "\n",
            "--- Chunk 14919 ---\n",
            "tf.saved_model.save() function, by default the function saves a much simpler\n",
            "\n",
            "--- Chunk 14920 ---\n",
            "SavedModel: it saves a single metagraph tagged \"serve\", which contains two signa‐\n",
            "\n",
            "--- Chunk 14921 ---\n",
            "ture definitions, an initialization function (called __saved_model_init_op, which\n",
            "\n",
            "--- Chunk 14922 ---\n",
            "you do not need to worry about) and a default serving function (called serv\n",
            "\n",
            "--- Chunk 14923 ---\n",
            "ing_default). When saving a tf.keras model, the default serving function corre‐\n",
            "\n",
            "--- Chunk 14924 ---\n",
            "sponds to the model’s call() function, which of course makes predictions.\n",
            "\n",
            "--- Chunk 14925 ---\n",
            "The saved_model_cli tool can also be used to make predictions (for testing, not\n",
            "\n",
            "--- Chunk 14926 ---\n",
            "really for production). Suppose you have a NumPy array (X_new) containing three\n",
            "\n",
            "--- Chunk 14927 ---\n",
            "images of handwritten digits that you want to make predictions for. You first need to\n",
            "export them to NumPy’s npy format:\n",
            "\n",
            "--- Chunk 14928 ---\n",
            "np.save(\"my_mnist_tests.npy\", X_new)\n",
            "\n",
            "--- Chunk 14929 ---\n",
            "Next, use the saved_model_cli command like this:\n",
            "$ saved_model_cli run --dir my_mnist_model/0001 --tag_set serve \\\n",
            "\n",
            "--- Chunk 14930 ---\n",
            "--signature_def serving_default \\\n",
            "                      --inputs flatten_input=my_mnist_tests.npy\n",
            "\n",
            "--- Chunk 14931 ---\n",
            "[...] Result for output key dense_1:\n",
            "[[1.1739199e-04 1.1239604e-07 6.0210604e-04 [...] 3.9471846e-04]\n",
            "\n",
            "--- Chunk 14932 ---\n",
            "[1.2294615e-03 2.9207937e-05 9.8599273e-01 [...] 1.1113169e-07]\n",
            " [6.4066830e-05 9.6359509e-01 9.0598064e-03 [...] 4.2495009e-04]]\n",
            "\n",
            "--- Chunk 14933 ---\n",
            "The tool’s output contains the 10 class probabilities of each of the 3 instances. Great!\n",
            "\n",
            "--- Chunk 14934 ---\n",
            "Now that you have a working SavedModel, the next step is to install TF Serving.\n",
            "\n",
            "--- Chunk 14935 ---\n",
            "Serving a TensorFlow Model | 671\n",
            "\n",
            "--- Chunk 14936 ---\n",
            "Installing TensorFlow Serving\n",
            "There are many ways to install TF Serving: using a Docker image,3 using the system’s\n",
            "\n",
            "--- Chunk 14937 ---\n",
            "package manager, installing from source, and more. Let’s use the Docker option,\n",
            "\n",
            "--- Chunk 14938 ---\n",
            "which is highly recommended by the TensorFlow team as it is simple to install, it will\n",
            "\n",
            "--- Chunk 14939 ---\n",
            "not mess with your system, and it offers high performance. You first need to install\n",
            "Docker. Then download the official TF Serving Docker image:\n",
            "\n",
            "--- Chunk 14940 ---\n",
            "$ docker pull tensorflow/serving\n",
            "\n",
            "--- Chunk 14941 ---\n",
            "Now you can create a Docker container to run this image:\n",
            "$ docker run -it --rm -p 8500:8500 -p 8501:8501 \\\n",
            "\n",
            "--- Chunk 14942 ---\n",
            "-v \"$ML_PATH/my_mnist_model:/models/my_mnist_model\" \\\n",
            "             -e MODEL_NAME=my_mnist_model \\\n",
            "             tensorflow/serving\n",
            "[...]\n",
            "\n",
            "--- Chunk 14943 ---\n",
            "[...]\n",
            "2019-06-01 [...] loaded servable version {name: my_mnist_model version: 1}\n",
            "2019-06-01 [...] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
            "\n",
            "--- Chunk 14944 ---\n",
            "2019-06-01 [...] Exporting HTTP/REST API at:localhost:8501 ...\n",
            "[evhttp_server.cc : 237] RAW: Entering the event loop ...\n",
            "\n",
            "--- Chunk 14945 ---\n",
            "That’s it! TF Serving is running. It loaded our MNIST model (version 1), and it is\n",
            "\n",
            "--- Chunk 14946 ---\n",
            "serving it through both gRPC (on port 8500) and REST (on port 8501). Here is what\n",
            "all the command-line options mean:\n",
            "-it\n",
            "\n",
            "--- Chunk 14947 ---\n",
            "Makes the container interactive (so you can press Ctrl-C to stop it) and displays\n",
            "the server’s output.\n",
            "\n",
            "--- Chunk 14948 ---\n",
            "--rm\n",
            "Deletes the container when you stop it (no need to clutter your machine with\n",
            "interrupted containers). However, it does not delete the image.\n",
            "\n",
            "--- Chunk 14949 ---\n",
            "-p 8500:8500\n",
            "Makes the Docker engine forward the host’s TCP port 8500 to the container’s\n",
            "\n",
            "--- Chunk 14950 ---\n",
            "TCP port 8500. By default, TF Serving uses this port to serve the gRPC API.\n",
            "\n",
            "--- Chunk 14951 ---\n",
            "-p 8501:8501\n",
            "Forwards the host’s TCP port 8501 to the container’s TCP port 8501. By default,\n",
            "TF Serving uses this port to serve the REST API.\n",
            "\n",
            "--- Chunk 14952 ---\n",
            "3 If you are not familiar with Docker, it allows you to easily download a set of applications packaged in a Docker\n",
            "\n",
            "--- Chunk 14953 ---\n",
            "image (including all their dependencies and usually some good default configuration) and then run them on\n",
            "\n",
            "--- Chunk 14954 ---\n",
            "your system using a Docker engine. When you run an image, the engine creates a Docker container that keeps\n",
            "\n",
            "--- Chunk 14955 ---\n",
            "the applications well isolated from your own system (but you can give it some limited access if you want). It is\n",
            "\n",
            "--- Chunk 14956 ---\n",
            "similar to a virtual machine, but much faster and more lightweight, as the container relies directly on the\n",
            "\n",
            "--- Chunk 14957 ---\n",
            "host’s kernel. This means that the image does not need to include or run its own kernel.\n",
            "\n",
            "--- Chunk 14958 ---\n",
            "672 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 14959 ---\n",
            "-v \"$ML_PATH/my_mnist_model:/models/my_mnist_model\"\n",
            "Makes the host’s $ML_PATH/my_mnist_model directory available to the container\n",
            "\n",
            "--- Chunk 14960 ---\n",
            "at the path /models/mnist_model. On Windows, you may need to replace / with \\\n",
            "in the host path (but not in the container path).\n",
            "\n",
            "--- Chunk 14961 ---\n",
            "-e MODEL_NAME=my_mnist_model\n",
            "Sets the container’s MODEL_NAME environment variable, so TF Serving knows\n",
            "\n",
            "--- Chunk 14962 ---\n",
            "which model to serve. By default, it will look for models in the /models directory,\n",
            "and it will automatically serve the latest version it finds.\n",
            "\n",
            "--- Chunk 14963 ---\n",
            "tensorflow/serving\n",
            "This is the name of the image to run.\n",
            "\n",
            "--- Chunk 14964 ---\n",
            "Now let’s go back to Python and query this server, first using the REST API, then the\n",
            "gRPC API.\n",
            "\n",
            "--- Chunk 14965 ---\n",
            "Querying TF Serving through the REST API\n",
            "Let’s start by creating the query. It must contain the name of the function signature\n",
            "\n",
            "--- Chunk 14966 ---\n",
            "you want to call, and of course the input data:\n",
            "\n",
            "--- Chunk 14967 ---\n",
            "import json\n",
            "\n",
            "input_data_json = json.dumps({\n",
            "    \"signature_name\": \"serving_default\",\n",
            "    \"instances\": X_new.tolist(),\n",
            "})\n",
            "\n",
            "--- Chunk 14968 ---\n",
            "Note that the JSON format is 100% text-based, so the X_new NumPy array had to be\n",
            "converted to a Python list and then formatted as JSON:\n",
            "\n",
            "--- Chunk 14969 ---\n",
            ">>> input_data_json\n",
            "'{\"signature_name\": \"serving_default\", \"instances\": [[[0.0, 0.0, 0.0, [...]\n",
            "\n",
            "--- Chunk 14970 ---\n",
            "0.3294117647058824, 0.725490196078431, [...very long], 0.0, 0.0, 0.0, 0.0]]]}'\n",
            "\n",
            "--- Chunk 14971 ---\n",
            "Now let’s send the input data to TF Serving by sending an HTTP POST request. This\n",
            "\n",
            "--- Chunk 14972 ---\n",
            "can be done easily using the requests library (it is not part of Python’s standard\n",
            "library, so you will need to install it first, e.g., using pip):\n",
            "\n",
            "--- Chunk 14973 ---\n",
            "import requests\n",
            "\n",
            "--- Chunk 14974 ---\n",
            "SERVER_URL = 'http://localhost:8501/v1/models/my_mnist_model:predict'\n",
            "response = requests.post(SERVER_URL, data=input_data_json)\n",
            "\n",
            "--- Chunk 14975 ---\n",
            "response.raise_for_status() # raise an exception in case of error\n",
            "response = response.json()\n",
            "\n",
            "--- Chunk 14976 ---\n",
            "The response is a dictionary containing a single \"predictions\" key. The correspond‐\n",
            "\n",
            "--- Chunk 14977 ---\n",
            "ing value is the list of predictions. This list is a Python list, so let’s convert it to a\n",
            "\n",
            "--- Chunk 14978 ---\n",
            "NumPy array and round the floats it contains to the second decimal:\n",
            "\n",
            "--- Chunk 14979 ---\n",
            "Serving a TensorFlow Model | 673\n",
            "\n",
            "--- Chunk 14980 ---\n",
            ">>> y_proba = np.array(response[\"predictions\"])\n",
            ">>> y_proba.round(2)\n",
            "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
            "\n",
            "--- Chunk 14981 ---\n",
            "[0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
            "       [0.  , 0.96, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.01, 0.  ]])\n",
            "\n",
            "--- Chunk 14982 ---\n",
            "Hurray, we have the predictions! The model is close to 100% confident that the first\n",
            "\n",
            "--- Chunk 14983 ---\n",
            "image is a 7, 99% confident that the second image is a 2, and 96% confident that the\n",
            "third image is a 1.\n",
            "\n",
            "--- Chunk 14984 ---\n",
            "third image is a 1.\n",
            "The REST API is nice and simple, and it works well when the input and output data\n",
            "\n",
            "--- Chunk 14985 ---\n",
            "are not too large. Moreover, just about any client application can make REST queries\n",
            "\n",
            "--- Chunk 14986 ---\n",
            "without additional dependencies, whereas other protocols are not always so readily\n",
            "\n",
            "--- Chunk 14987 ---\n",
            "available. However, it is based on JSON, which is text-based and fairly verbose. For\n",
            "\n",
            "--- Chunk 14988 ---\n",
            "example, we had to convert the NumPy array to a Python list, and every float ended\n",
            "\n",
            "--- Chunk 14989 ---\n",
            "up represented as a string. This is very inefficient, both in terms of serialization/\n",
            "\n",
            "--- Chunk 14990 ---\n",
            "deserialization time (to convert all the floats to strings and back) and in terms of pay‐\n",
            "\n",
            "--- Chunk 14991 ---\n",
            "load size: many floats end up being represented using over 15 characters, which\n",
            "\n",
            "--- Chunk 14992 ---\n",
            "translates to over 120 bits for 32-bit floats! This will result in high latency and band‐\n",
            "\n",
            "--- Chunk 14993 ---\n",
            "width usage when transferring large NumPy arrays.4 So let’s use gRPC instead.\n",
            "\n",
            "--- Chunk 14994 ---\n",
            "When transferring large amounts of data, it is much better to use\n",
            "the gRPC API (if the client supports it), as it is based on a compact\n",
            "\n",
            "--- Chunk 14995 ---\n",
            "binary format and an efficient communication protocol (based on\n",
            "HTTP/2 framing).\n",
            "\n",
            "--- Chunk 14996 ---\n",
            "Querying TF Serving through the gRPC API\n",
            "The gRPC API expects a serialized PredictRequest protocol buffer as input, and it\n",
            "\n",
            "--- Chunk 14997 ---\n",
            "outputs a serialized PredictResponse protocol buffer. These protobufs are part of the\n",
            "\n",
            "--- Chunk 14998 ---\n",
            "tensorflow-serving-api library, which you must install (e.g., using pip). First, let’s\n",
            "create the request:\n",
            "\n",
            "--- Chunk 14999 ---\n",
            "from tensorflow_serving.apis.predict_pb2 import PredictRequest\n",
            "\n",
            "--- Chunk 15000 ---\n",
            "request = PredictRequest()\n",
            "request.model_spec.name = model_name\n",
            "request.model_spec.signature_name = \"serving_default\"\n",
            "\n",
            "--- Chunk 15001 ---\n",
            "input_name = model.input_names[0]\n",
            "request.inputs[input_name].CopyFrom(tf.make_tensor_proto(X_new))\n",
            "\n",
            "--- Chunk 15002 ---\n",
            "This code creates a PredictRequest protocol buffer and fills in the required fields,\n",
            "\n",
            "--- Chunk 15003 ---\n",
            "including the model name (defined earlier), the signature name of the function we\n",
            "\n",
            "--- Chunk 15004 ---\n",
            "4 To be fair, this can be mitigated by serializing the data first and encoding it to Base64 before creating the REST\n",
            "\n",
            "--- Chunk 15005 ---\n",
            "request. Moreover, REST requests can be compressed using gzip, which reduces the payload size significantly.\n",
            "\n",
            "--- Chunk 15006 ---\n",
            "674 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 15007 ---\n",
            "want to call, and finally the input data, in the form of a Tensor protocol buffer. The\n",
            "\n",
            "--- Chunk 15008 ---\n",
            "tf.make_tensor_proto() function creates a Tensor protocol buffer based on the\n",
            "given tensor or NumPy array, in this case X_new.\n",
            "\n",
            "--- Chunk 15009 ---\n",
            "Next, we’ll send the request to the server and get its response (for this you will need\n",
            "the grpcio library, which you can install using pip):\n",
            "\n",
            "--- Chunk 15010 ---\n",
            "import grpc\n",
            "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
            "\n",
            "--- Chunk 15011 ---\n",
            "channel = grpc.insecure_channel('localhost:8500')\n",
            "predict_service = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
            "\n",
            "--- Chunk 15012 ---\n",
            "response = predict_service.Predict(request, timeout=10.0)\n",
            "\n",
            "--- Chunk 15013 ---\n",
            "The code is quite straightforward: after the imports, we create a gRPC communica‐\n",
            "\n",
            "--- Chunk 15014 ---\n",
            "tion channel to localhost on TCP port 8500, then we create a gRPC service over this\n",
            "\n",
            "--- Chunk 15015 ---\n",
            "channel and use it to send a request, with a 10-second timeout (not that the call is\n",
            "\n",
            "--- Chunk 15016 ---\n",
            "synchronous: it will block until it receives the response or the timeout period\n",
            "\n",
            "--- Chunk 15017 ---\n",
            "expires). In this example the channel is insecure (no encryption, no authentication),\n",
            "\n",
            "--- Chunk 15018 ---\n",
            "but gRPC and TensorFlow Serving also support secure channels over SSL/TLS.\n",
            "Next, let’s convert the PredictResponse protocol buffer to a tensor:\n",
            "\n",
            "--- Chunk 15019 ---\n",
            "output_name = model.output_names[0]\n",
            "outputs_proto = response.outputs[output_name]\n",
            "y_proba = tf.make_ndarray(outputs_proto)\n",
            "\n",
            "--- Chunk 15020 ---\n",
            "If you run this code and print y_proba.numpy().round(2), you will get the exact\n",
            "\n",
            "--- Chunk 15021 ---\n",
            "same estimated class probabilities as earlier. And that’s all there is to it: in just a few\n",
            "\n",
            "--- Chunk 15022 ---\n",
            "lines of code, you can now access your TensorFlow model remotely, using either\n",
            "REST or gRPC.\n",
            "\n",
            "--- Chunk 15023 ---\n",
            "Deploying a new model version\n",
            "Now let’s create a new model version and export a SavedModel to the\n",
            "my_mnist_model/0002 directory, just like earlier:\n",
            "\n",
            "--- Chunk 15024 ---\n",
            "model = keras.models.Sequential([...])\n",
            "model.compile([...])\n",
            "history = model.fit([...])\n",
            "\n",
            "--- Chunk 15025 ---\n",
            "model_version = \"0002\"\n",
            "model_name = \"my_mnist_model\"\n",
            "model_path = os.path.join(model_name, model_version)\n",
            "tf.saved_model.save(model, model_path)\n",
            "\n",
            "--- Chunk 15026 ---\n",
            "At regular intervals (the delay is configurable), TensorFlow Serving checks for new\n",
            "\n",
            "--- Chunk 15027 ---\n",
            "model versions. If it finds one, it will automatically handle the transition gracefully:\n",
            "\n",
            "--- Chunk 15028 ---\n",
            "by default, it will answer pending requests (if any) with the previous model version,\n",
            "\n",
            "--- Chunk 15029 ---\n",
            "Serving a TensorFlow Model | 675\n",
            "\n",
            "--- Chunk 15030 ---\n",
            "while handling new requests with the new version.5 As soon as every pending request\n",
            "\n",
            "--- Chunk 15031 ---\n",
            "has been answered, the previous model version is unloaded. You can see this at work\n",
            "in the TensorFlow Serving logs:\n",
            "\n",
            "--- Chunk 15032 ---\n",
            "[...]\n",
            "reserved resources to load servable {name: my_mnist_model version: 2}\n",
            "[...]\n",
            "Reading SavedModel from: /models/my_mnist_model/0002\n",
            "\n",
            "--- Chunk 15033 ---\n",
            "Reading meta graph with tags { serve }\n",
            "Successfully loaded servable version {name: my_mnist_model version: 2}\n",
            "\n",
            "--- Chunk 15034 ---\n",
            "Quiescing servable version {name: my_mnist_model version: 1}\n",
            "Done quiescing servable version {name: my_mnist_model version: 1}\n",
            "\n",
            "--- Chunk 15035 ---\n",
            "Unloading servable version {name: my_mnist_model version: 1}\n",
            "\n",
            "--- Chunk 15036 ---\n",
            "This approach offers a smooth transition, but it may use too much RAM (especially\n",
            "\n",
            "--- Chunk 15037 ---\n",
            "GPU RAM, which is generally the most limited). In this case, you can configure TF\n",
            "\n",
            "--- Chunk 15038 ---\n",
            "Serving so that it handles all pending requests with the previous model version and\n",
            "\n",
            "--- Chunk 15039 ---\n",
            "unloads it before loading and using the new model version. This configuration will\n",
            "\n",
            "--- Chunk 15040 ---\n",
            "avoid having two model versions loaded at the same time, but the service will be\n",
            "unavailable for a short period.\n",
            "\n",
            "--- Chunk 15041 ---\n",
            "As you can see, TF Serving makes it quite simple to deploy new models. Moreover, if\n",
            "\n",
            "--- Chunk 15042 ---\n",
            "you discover that version 2 does not work as well as you expected, then rolling back\n",
            "\n",
            "--- Chunk 15043 ---\n",
            "to version 1 is as simple as removing the my_mnist_model/0002 directory.\n",
            "\n",
            "--- Chunk 15044 ---\n",
            "Another great feature of TF Serving is its automatic batching capa‐\n",
            "bility, which you can activate using the --enable_batching option\n",
            "\n",
            "--- Chunk 15045 ---\n",
            "upon startup. When TF Serving receives multiple requests within a\n",
            "short period of time (the delay is configurable), it will automatically\n",
            "\n",
            "--- Chunk 15046 ---\n",
            "batch them together before using the model. This offers a signifi‐\n",
            "cant performance boost by leveraging the power of the GPU. Once\n",
            "\n",
            "--- Chunk 15047 ---\n",
            "the model returns the predictions, TF Serving dispatches each pre‐\n",
            "diction to the right client. You can trade a bit of latency for a\n",
            "\n",
            "--- Chunk 15048 ---\n",
            "greater throughput by increasing the batching delay (see the\n",
            "--batching_parameters_file option).\n",
            "\n",
            "--- Chunk 15049 ---\n",
            "If you expect to get many queries per second, you will want to deploy TF Serving on\n",
            "\n",
            "--- Chunk 15050 ---\n",
            "multiple servers and load-balance the queries (see Figure 19-2). This will require\n",
            "\n",
            "--- Chunk 15051 ---\n",
            "deploying and managing many TF Serving containers across these servers. One way\n",
            "\n",
            "--- Chunk 15052 ---\n",
            "to handle that is to use a tool such as Kubernetes, which is an open source system for\n",
            "\n",
            "--- Chunk 15053 ---\n",
            "simplifying container orchestration across many servers. If you do not want to pur‐\n",
            "\n",
            "--- Chunk 15054 ---\n",
            "5 If the SavedModel contains some example instances in the assets/extra directory, you can configure TF Serv‐\n",
            "\n",
            "--- Chunk 15055 ---\n",
            "ing to execute the model on these instances before starting to serve new requests with it. This is called model\n",
            "\n",
            "--- Chunk 15056 ---\n",
            "warmup: it will ensure that everything is properly loaded, avoiding long response times for the first requests.\n",
            "\n",
            "--- Chunk 15057 ---\n",
            "676 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 15058 ---\n",
            "chase, maintain, and upgrade all the hardware infrastructure, you will want to use\n",
            "\n",
            "--- Chunk 15059 ---\n",
            "virtual machines on a cloud platform such as Amazon AWS, Microsoft Azure, Google\n",
            "\n",
            "--- Chunk 15060 ---\n",
            "Cloud Platform, IBM Cloud, Alibaba Cloud, Oracle Cloud, or some other Platform-\n",
            "\n",
            "--- Chunk 15061 ---\n",
            "as-a-Service (PaaS). Managing all the virtual machines, handling container orchestra‐\n",
            "\n",
            "--- Chunk 15062 ---\n",
            "tion (even with the help of Kubernetes), taking care of TF Serving configuration,\n",
            "\n",
            "--- Chunk 15063 ---\n",
            "tuning and monitoring—all of this can be a full-time job. Fortunately, some service\n",
            "\n",
            "--- Chunk 15064 ---\n",
            "providers can take care of all this for you. In this chapter we will use Google Cloud AI\n",
            "\n",
            "--- Chunk 15065 ---\n",
            "Platform because it’s the only platform with TPUs today, it supports TensorFlow 2, it\n",
            "\n",
            "--- Chunk 15066 ---\n",
            "offers a nice suite of AI services (e.g., AutoML, Vision API, Natural Language API),\n",
            "\n",
            "--- Chunk 15067 ---\n",
            "and it is the one I have the most experience with. But there are several other provid‐\n",
            "\n",
            "--- Chunk 15068 ---\n",
            "ers in this space, such as Amazon AWS SageMaker and Microsoft AI Platform, which\n",
            "are also capable of serving TensorFlow models.\n",
            "\n",
            "--- Chunk 15069 ---\n",
            "Figure 19-2. Scaling up TF Serving with load balancing\n",
            "\n",
            "Now let’s see how to serve our wonderful MNIST model on the cloud!\n",
            "\n",
            "--- Chunk 15070 ---\n",
            "Creating a Prediction Service on GCP AI Platform\n",
            "Before you can deploy a model, there’s a little bit of setup to take care of:\n",
            "\n",
            "--- Chunk 15071 ---\n",
            "1. Log in to your Google account, and then go to the Google Cloud Platform (GCP)\n",
            "\n",
            "--- Chunk 15072 ---\n",
            "console (see Figure 19-3). If you don’t have a Google account, you’ll have to cre‐\n",
            "ate one.\n",
            "\n",
            "--- Chunk 15073 ---\n",
            "2. If it is your first time using GCP, you will have to read and accept the terms and\n",
            "\n",
            "--- Chunk 15074 ---\n",
            "conditions. Click Tour Console if you want. At the time of this writing, new users\n",
            "\n",
            "--- Chunk 15075 ---\n",
            "are offered a free trial, including $300 worth of GCP credit that you can use over\n",
            "\n",
            "--- Chunk 15076 ---\n",
            "the course of 12 months. You will only need a small portion of that to pay for the\n",
            "\n",
            "--- Chunk 15077 ---\n",
            "services you will use in this chapter. Upon signing up for the free trial, you will\n",
            "\n",
            "--- Chunk 15078 ---\n",
            "still need to create a payment profile and enter your credit card number: it is used\n",
            "\n",
            "--- Chunk 15079 ---\n",
            "for verification purposes (probably to avoid people using the free trial multiple\n",
            "\n",
            "--- Chunk 15080 ---\n",
            "times), but you will not be billed. Activate and upgrade your account if requested.\n",
            "\n",
            "--- Chunk 15081 ---\n",
            "Serving a TensorFlow Model | 677\n",
            "\n",
            "\n",
            "\n",
            "Figure 19-3. Google Cloud Platform console\n",
            "\n",
            "--- Chunk 15082 ---\n",
            "3. If you have used GCP before and your free trial has expired, then the services you\n",
            "\n",
            "--- Chunk 15083 ---\n",
            "will use in this chapter will cost you some money. It should not be too much,\n",
            "\n",
            "--- Chunk 15084 ---\n",
            "especially if you remember to turn off the services when you do not need them\n",
            "\n",
            "--- Chunk 15085 ---\n",
            "anymore. Make sure you understand and agree to the pricing conditions before\n",
            "\n",
            "--- Chunk 15086 ---\n",
            "you run any service. I hereby decline any responsibility if services end up costing\n",
            "\n",
            "--- Chunk 15087 ---\n",
            "more than you expected! Also make sure your billing account is active. To check,\n",
            "\n",
            "--- Chunk 15088 ---\n",
            "open the navigation menu on the left and click Billing, and make sure you have\n",
            "set up a payment method and that the billing account is active.\n",
            "\n",
            "--- Chunk 15089 ---\n",
            "4. Every resource in GCP belongs to a project. This includes all the virtual\n",
            "\n",
            "--- Chunk 15090 ---\n",
            "machines you may use, the files you store, and the training jobs you run. When\n",
            "\n",
            "--- Chunk 15091 ---\n",
            "you create an account, GCP automatically creates a project for you, called “My\n",
            "\n",
            "--- Chunk 15092 ---\n",
            "First Project.” If you want, you can change its display name by going to the\n",
            "\n",
            "--- Chunk 15093 ---\n",
            "project settings: in the navigation menu (on the left of the screen), select IAM &\n",
            "\n",
            "--- Chunk 15094 ---\n",
            "admin → Settings, change the project’s display name, and click Save. Note that\n",
            "\n",
            "--- Chunk 15095 ---\n",
            "the project also has a unique ID and number. You can choose the project ID\n",
            "\n",
            "--- Chunk 15096 ---\n",
            "when you create a project, but you cannot change it later. The project number is\n",
            "\n",
            "--- Chunk 15097 ---\n",
            "automatically generated and cannot be changed. If you want to create a new\n",
            "\n",
            "--- Chunk 15098 ---\n",
            "project, click the project name at the top of the page, then click New Project and\n",
            "\n",
            "--- Chunk 15099 ---\n",
            "enter the project ID. Make sure billing is active for this new project.\n",
            "\n",
            "--- Chunk 15100 ---\n",
            "678 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 15101 ---\n",
            "Always set an alarm to remind yourself to turn services off\n",
            "when you know you will only need them for a few hours, or\n",
            "\n",
            "--- Chunk 15102 ---\n",
            "else you might leave them running for days or months, incur‐\n",
            "ring potentially significant costs.\n",
            "\n",
            "--- Chunk 15103 ---\n",
            "5. Now that you have a GCP account with billing activated, you can start using the\n",
            "\n",
            "--- Chunk 15104 ---\n",
            "services. The first one you will need is Google Cloud Storage (GCS): this is where\n",
            "\n",
            "--- Chunk 15105 ---\n",
            "you will put the SavedModels, the training data, and more. In the navigation\n",
            "\n",
            "--- Chunk 15106 ---\n",
            "menu, scroll down to the Storage section, and click Storage → Browser. All your\n",
            "\n",
            "--- Chunk 15107 ---\n",
            "files will go in one or more buckets. Click Create Bucket and choose the bucket\n",
            "\n",
            "--- Chunk 15108 ---\n",
            "name (you may need to activate the Storage API first). GCS uses a single world‐\n",
            "\n",
            "--- Chunk 15109 ---\n",
            "wide namespace for buckets, so simple names like “machine-learning” will most\n",
            "\n",
            "--- Chunk 15110 ---\n",
            "likely not be available. Make sure the bucket name conforms to DNS naming\n",
            "\n",
            "--- Chunk 15111 ---\n",
            "conventions, as it may be used in DNS records. Moreover, bucket names are pub‐\n",
            "\n",
            "--- Chunk 15112 ---\n",
            "lic, so do not put anything private in there. It is common to use your domain\n",
            "\n",
            "--- Chunk 15113 ---\n",
            "name or your company name as a prefix to ensure uniqueness, or simply use a\n",
            "random number as part of the name. Choose the location where you want the\n",
            "\n",
            "--- Chunk 15114 ---\n",
            "bucket to be hosted, and the rest of the options should be fine by default. Then\n",
            "click Create.\n",
            "\n",
            "--- Chunk 15115 ---\n",
            "6. Upload the my_mnist_model folder you created earlier (including one or more\n",
            "\n",
            "--- Chunk 15116 ---\n",
            "versions) to your bucket. To do this, just go to the GCS Browser, click the bucket,\n",
            "\n",
            "--- Chunk 15117 ---\n",
            "then drag and drop the my_mnist_model folder from your system to the bucket\n",
            "\n",
            "--- Chunk 15118 ---\n",
            "(see Figure 19-4). Alternatively, you can click “Upload folder” and select the\n",
            "\n",
            "--- Chunk 15119 ---\n",
            "my_mnist_model folder to upload. By default, the maximum size for a SavedMo‐\n",
            "del is 250 MB, but it is possible to request a higher quota.\n",
            "\n",
            "--- Chunk 15120 ---\n",
            "Figure 19-4. Uploading a SavedModel to Google Cloud Storage\n",
            "\n",
            "Serving a TensorFlow Model | 679\n",
            "\n",
            "--- Chunk 15121 ---\n",
            "7. Now you need to configure AI Platform (formerly known as ML Engine) so that\n",
            "\n",
            "--- Chunk 15122 ---\n",
            "it knows which models and versions you want to use. In the navigation menu,\n",
            "\n",
            "--- Chunk 15123 ---\n",
            "scroll down to the Artificial Intelligence section, and click AI Platform → Models.\n",
            "\n",
            "--- Chunk 15124 ---\n",
            "Click Activate API (it takes a few minutes), then click “Create model.” Fill in the\n",
            "model details (see Figure 19-5) and click Create.\n",
            "\n",
            "--- Chunk 15125 ---\n",
            "Figure 19-5. Creating a new model on Google Cloud AI Platform\n",
            "\n",
            "--- Chunk 15126 ---\n",
            "8. Now that you have a model on AI Platform, you need to create a model version.\n",
            "\n",
            "--- Chunk 15127 ---\n",
            "In the list of models, click the model you just created, then click “Create version”\n",
            "\n",
            "--- Chunk 15128 ---\n",
            "and fill in the version details (see Figure 19-6): set the name, description, Python\n",
            "\n",
            "--- Chunk 15129 ---\n",
            "version (3.5 or above), framework (TensorFlow), framework version (2.0 if avail‐\n",
            "\n",
            "--- Chunk 15130 ---\n",
            "able, or 1.13),6 ML runtime version (2.0, if available or 1.13), machine type\n",
            "\n",
            "--- Chunk 15131 ---\n",
            "(choose “Single core CPU” for now), model path on GCS (this is the full path to\n",
            "\n",
            "--- Chunk 15132 ---\n",
            "the actual version folder, e.g., gs://my-mnist-model-bucket/my_mnist_model/\n",
            "0002/), scaling (choose automatic), and minimum number of TF Serving con‐\n",
            "\n",
            "--- Chunk 15133 ---\n",
            "tainers to have running at all times (leave this field empty). Then click Save.\n",
            "\n",
            "--- Chunk 15134 ---\n",
            "6 At the time of this writing, TensorFlow version 2 is not available yet on AI Platform, but that’s OK: you can\n",
            "\n",
            "--- Chunk 15135 ---\n",
            "use 1.13, and it will run your TF 2 SavedModels just fine.\n",
            "\n",
            "--- Chunk 15136 ---\n",
            "680 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "\n",
            "\n",
            "Figure 19-6. Creating a new model version on Google Cloud AI Platform\n",
            "\n",
            "--- Chunk 15137 ---\n",
            "Congratulations, you have deployed your first model on the cloud! Because you\n",
            "\n",
            "--- Chunk 15138 ---\n",
            "selected automatic scaling, AI Platform will start more TF Serving containers when\n",
            "\n",
            "--- Chunk 15139 ---\n",
            "the number of queries per second increases, and it will load-balance the queries\n",
            "\n",
            "--- Chunk 15140 ---\n",
            "between them. If the QPS goes down, it will stop containers automatically. The cost is\n",
            "\n",
            "--- Chunk 15141 ---\n",
            "therefore directly linked to the QPS (as well as the type of machine you choose and\n",
            "\n",
            "--- Chunk 15142 ---\n",
            "the amount of data you store on GCS). This pricing model is particularly useful for\n",
            "\n",
            "--- Chunk 15143 ---\n",
            "occasional users and for services with important usage spikes, as well as for startups:\n",
            "the price remains low until the startup actually starts up.\n",
            "\n",
            "--- Chunk 15144 ---\n",
            "If you do not use the prediction service, AI Platform will stop all\n",
            "containers. This means you will only pay for the amount of storage\n",
            "\n",
            "--- Chunk 15145 ---\n",
            "you use (a few cents per gigabyte per month). Note that when you\n",
            "query the service, AI Platform will need to start up a TF Serving\n",
            "\n",
            "--- Chunk 15146 ---\n",
            "container, which will take a few seconds. If this delay is unaccepta‐\n",
            "ble, you will have to set the minimum number of TF Serving con‐\n",
            "\n",
            "--- Chunk 15147 ---\n",
            "tainers to 1 when creating the model version. Of course, this means\n",
            "at least one machine will run constantly, so the monthly fee will be\n",
            "higher.\n",
            "\n",
            "--- Chunk 15148 ---\n",
            "Now let’s query this prediction service!\n",
            "\n",
            "Serving a TensorFlow Model | 681\n",
            "\n",
            "--- Chunk 15149 ---\n",
            "Using the Prediction Service\n",
            "Under the hood, AI Platform just runs TF Serving, so in principle you could use the\n",
            "\n",
            "--- Chunk 15150 ---\n",
            "same code as earlier, if you knew which URL to query. There’s just one problem: GCP\n",
            "\n",
            "--- Chunk 15151 ---\n",
            "also takes care of encryption and authentication. Encryption is based on SSL/TLS,\n",
            "\n",
            "--- Chunk 15152 ---\n",
            "and authentication is token-based: a secret authentication token must be sent to the\n",
            "\n",
            "--- Chunk 15153 ---\n",
            "server in every request. So before your code can use the prediction service (or any\n",
            "\n",
            "--- Chunk 15154 ---\n",
            "other GCP service), it must obtain a token. We will see how to do this shortly, but\n",
            "\n",
            "--- Chunk 15155 ---\n",
            "first you need to configure authentication and give your application the appropriate\n",
            "access rights on GCP. You have two options for authentication:\n",
            "\n",
            "--- Chunk 15156 ---\n",
            "• Your application (i.e., the client code that will query the prediction service) could\n",
            "\n",
            "--- Chunk 15157 ---\n",
            "authenticate using user credentials with your own Google login and password.\n",
            "\n",
            "--- Chunk 15158 ---\n",
            "Using user credentials would give your application the exact same rights as on\n",
            "\n",
            "--- Chunk 15159 ---\n",
            "GCP, which is certainly way more than it needs. Moreover, you would have to\n",
            "\n",
            "--- Chunk 15160 ---\n",
            "deploy your credentials in your application, so anyone with access could steal\n",
            "\n",
            "--- Chunk 15161 ---\n",
            "your credentials and fully access your GCP account. In short, do not choose this\n",
            "\n",
            "--- Chunk 15162 ---\n",
            "option; it is only needed in very rare cases (e.g., when your application needs to\n",
            "access its user’s GCP account).\n",
            "\n",
            "--- Chunk 15163 ---\n",
            "• The client code can authenticate with a service account. This is an account that\n",
            "\n",
            "--- Chunk 15164 ---\n",
            "represents an application, not a user. It is generally given very restricted access\n",
            "\n",
            "--- Chunk 15165 ---\n",
            "rights: strictly what it needs, and no more. This is the recommended option.\n",
            "\n",
            "--- Chunk 15166 ---\n",
            "So, let’s create a service account for your application: in the navigation menu, go to\n",
            "\n",
            "--- Chunk 15167 ---\n",
            "IAM & admin → Service accounts, then click Create Service Account, fill in the form\n",
            "\n",
            "--- Chunk 15168 ---\n",
            "(service account name, ID, description), and click Create (see Figure 19-7). Next, you\n",
            "\n",
            "--- Chunk 15169 ---\n",
            "must give this account some access rights. Select the ML Engine Developer role: this\n",
            "\n",
            "--- Chunk 15170 ---\n",
            "will allow the service account to make predictions, and not much more. Optionally,\n",
            "\n",
            "--- Chunk 15171 ---\n",
            "you can grant some users access to the service account (this is useful when your GCP\n",
            "\n",
            "--- Chunk 15172 ---\n",
            "user account is part of an organization, and you wish to authorize other users in the\n",
            "\n",
            "--- Chunk 15173 ---\n",
            "organization to deploy applications that will be based on this service account or to\n",
            "\n",
            "--- Chunk 15174 ---\n",
            "manage the service account itself). Next, click Create Key to export the service\n",
            "\n",
            "--- Chunk 15175 ---\n",
            "account’s private key, choose JSON, and click Create. This will download the private\n",
            "key in the form of a JSON file. Make sure to keep it private!\n",
            "\n",
            "--- Chunk 15176 ---\n",
            "682 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "\n",
            "\n",
            "Figure 19-7. Creating a new service account in Google IAM\n",
            "\n",
            "--- Chunk 15177 ---\n",
            "Great! Now let’s write a small script that will query the prediction service. Google\n",
            "provides several libraries to simplify access to its services:\n",
            "\n",
            "--- Chunk 15178 ---\n",
            "Google API Client Library\n",
            "\n",
            "--- Chunk 15179 ---\n",
            "This is a fairly thin layer on top of OAuth 2.0 (for the authentication) and REST.\n",
            "\n",
            "--- Chunk 15180 ---\n",
            "You can use it with all GCP services, including AI Platform. You can install it\n",
            "using pip: the library is called google-api-python-client.\n",
            "\n",
            "--- Chunk 15181 ---\n",
            "Google Cloud Client Libraries\n",
            "These are a bit more high-level: each one is dedicated to a particular service, such\n",
            "\n",
            "--- Chunk 15182 ---\n",
            "as GCS, Google BigQuery, Google Cloud Natural Language, and Google Cloud\n",
            "\n",
            "--- Chunk 15183 ---\n",
            "Vision. All these libraries can be installed using pip (e.g., the GCS Client Library\n",
            "\n",
            "--- Chunk 15184 ---\n",
            "is called google-cloud-storage). When a client library is available for a given\n",
            "\n",
            "--- Chunk 15185 ---\n",
            "service, it is recommended to use it rather than the Google API Client Library, as\n",
            "\n",
            "--- Chunk 15186 ---\n",
            "it implements all the best practices and will often use gRPC rather than REST, for\n",
            "better performance.\n",
            "\n",
            "--- Chunk 15187 ---\n",
            "At the time of this writing there is no client library for AI Platform, so we will use the\n",
            "\n",
            "--- Chunk 15188 ---\n",
            "Google API Client Library. It will need to use the service account’s private key; you\n",
            "\n",
            "--- Chunk 15189 ---\n",
            "can tell it where it is by setting the GOOGLE_APPLICATION_CREDENTIALS environment\n",
            "\n",
            "--- Chunk 15190 ---\n",
            "variable, either before starting the script or within the script like this:\n",
            "\n",
            "--- Chunk 15191 ---\n",
            "import os\n",
            "\n",
            "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"my_service_account_key.json\"\n",
            "\n",
            "Serving a TensorFlow Model | 683\n",
            "\n",
            "--- Chunk 15192 ---\n",
            "If you deploy your application to a virtual machine on Google\n",
            "Cloud Engine (GCE), or within a container using Google Cloud\n",
            "\n",
            "--- Chunk 15193 ---\n",
            "Kubernetes Engine, or as a web application on Google Cloud App\n",
            "Engine, or as a microservice on Google Cloud Functions, and if the\n",
            "\n",
            "--- Chunk 15194 ---\n",
            "GOOGLE_APPLICATION_CREDENTIALS environment variable is not\n",
            "set, then the library will use the default service account for the host\n",
            "\n",
            "--- Chunk 15195 ---\n",
            "service (e.g., the default GCE service account, if your application\n",
            "runs on GCE).\n",
            "\n",
            "--- Chunk 15196 ---\n",
            "Next, you must create a resource object that wraps access to the prediction service:7\n",
            "\n",
            "import googleapiclient.discovery\n",
            "\n",
            "--- Chunk 15197 ---\n",
            "project_id = \"onyx-smoke-242003\" # change this to your project ID\n",
            "model_id = \"my_mnist_model\"\n",
            "\n",
            "--- Chunk 15198 ---\n",
            "model_path = \"projects/{}/models/{}\".format(project_id, model_id)\n",
            "ml_resource = googleapiclient.discovery.build(\"ml\", \"v1\").projects()\n",
            "\n",
            "--- Chunk 15199 ---\n",
            "Note that you can append /versions/0001 (or any other version number) to the\n",
            "\n",
            "--- Chunk 15200 ---\n",
            "model_path to specify the version you want to query: this can be useful for A/B test‐\n",
            "\n",
            "--- Chunk 15201 ---\n",
            "ing or for testing a new version on a small group of users before releasing it widely\n",
            "\n",
            "--- Chunk 15202 ---\n",
            "(this is called a canary). Next, let’s write a small function that will use the resource\n",
            "\n",
            "--- Chunk 15203 ---\n",
            "object to call the prediction service and get the predictions back:\n",
            "\n",
            "--- Chunk 15204 ---\n",
            "def predict(X):\n",
            "    input_data_json = {\"signature_name\": \"serving_default\",\n",
            "                       \"instances\": X.tolist()}\n",
            "\n",
            "--- Chunk 15205 ---\n",
            "request = ml_resource.predict(name=model_path, body=input_data_json)\n",
            "    response = request.execute()\n",
            "    if \"error\" in response:\n",
            "\n",
            "--- Chunk 15206 ---\n",
            "raise RuntimeError(response[\"error\"])\n",
            "    return np.array([pred[output_name] for pred in response[\"predictions\"]])\n",
            "\n",
            "--- Chunk 15207 ---\n",
            "The function takes a NumPy array containing the input images and prepares a dictio‐\n",
            "\n",
            "--- Chunk 15208 ---\n",
            "nary that the client library will convert to the JSON format (as we did earlier). Then it\n",
            "\n",
            "--- Chunk 15209 ---\n",
            "prepares a prediction request, and executes it; it raises an exception if the response\n",
            "\n",
            "--- Chunk 15210 ---\n",
            "contains an error, or else it extracts the predictions for each instance and bundles\n",
            "them in a NumPy array. Let’s see if it works:\n",
            "\n",
            "--- Chunk 15211 ---\n",
            ">>> Y_probas = predict(X_new)\n",
            ">>> np.round(Y_probas, 2)\n",
            "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
            "\n",
            "--- Chunk 15212 ---\n",
            "[0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
            "       [0.  , 0.96, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.01, 0.  ]])\n",
            "\n",
            "--- Chunk 15213 ---\n",
            "7 If you get an error saying that module google.appengine was not found, set cache_discovery=False in the\n",
            "\n",
            "--- Chunk 15214 ---\n",
            "call to the build() method; see https://stackoverflow.com/q/55561354.\n",
            "\n",
            "--- Chunk 15215 ---\n",
            "684 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 15216 ---\n",
            "Yes! You now have a nice prediction service running on the cloud that can automati‐\n",
            "\n",
            "--- Chunk 15217 ---\n",
            "cally scale up to any number of QPS, plus you can query it from anywhere securely.\n",
            "\n",
            "--- Chunk 15218 ---\n",
            "Moreover, it costs you close to nothing when you don’t use it: you’ll pay just a few\n",
            "\n",
            "--- Chunk 15219 ---\n",
            "cents per month per gigabyte used on GCS. And you can also get detailed logs and\n",
            "metrics using Google Stackdriver.\n",
            "\n",
            "--- Chunk 15220 ---\n",
            "But what if you want to deploy your model to a mobile app? Or to an embedded\n",
            "device?\n",
            "\n",
            "--- Chunk 15221 ---\n",
            "Deploying a Model to a Mobile or Embedded Device\n",
            "If you need to deploy your model to a mobile or embedded device, a large model may\n",
            "\n",
            "--- Chunk 15222 ---\n",
            "simply take too long to download and use too much RAM and CPU, all of which will\n",
            "\n",
            "--- Chunk 15223 ---\n",
            "make your app unresponsive, heat the device, and drain its battery. To avoid this, you\n",
            "\n",
            "--- Chunk 15224 ---\n",
            "need to make a mobile-friendly, lightweight, and efficient model, without sacrificing\n",
            "\n",
            "--- Chunk 15225 ---\n",
            "too much of its accuracy. The TFLite library provides several tools8 to help you\n",
            "\n",
            "--- Chunk 15226 ---\n",
            "deploy your models to mobile and embedded devices, with three main objectives:\n",
            "\n",
            "--- Chunk 15227 ---\n",
            "• Reduce the model size, to shorten download time and reduce RAM usage.\n",
            "• Reduce the amount of computations needed for each prediction, to reduce\n",
            "\n",
            "--- Chunk 15228 ---\n",
            "latency, battery usage, and heating.\n",
            "• Adapt the model to device-specific constraints.\n",
            "\n",
            "--- Chunk 15229 ---\n",
            "To reduce the model size, TFLite’s model converter can take a SavedModel and com‐\n",
            "\n",
            "--- Chunk 15230 ---\n",
            "press it to a much lighter format based on FlatBuffers. This is an efficient cross-\n",
            "\n",
            "--- Chunk 15231 ---\n",
            "platform serialization library (a bit like protocol buffers) initially created by Google\n",
            "\n",
            "--- Chunk 15232 ---\n",
            "for gaming. It is designed so you can load FlatBuffers straight to RAM without any\n",
            "\n",
            "--- Chunk 15233 ---\n",
            "preprocessing: this reduces the loading time and memory footprint. Once the model\n",
            "\n",
            "--- Chunk 15234 ---\n",
            "is loaded into a mobile or embedded device, the TFLite interpreter will execute it to\n",
            "\n",
            "--- Chunk 15235 ---\n",
            "make predictions. Here is how you can convert a SavedModel to a FlatBuffer and save\n",
            "it to a .tflite file:\n",
            "\n",
            "--- Chunk 15236 ---\n",
            "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
            "tflite_model = converter.convert()\n",
            "\n",
            "--- Chunk 15237 ---\n",
            "with open(\"converted_model.tflite\", \"wb\") as f:\n",
            "    f.write(tflite_model)\n",
            "\n",
            "--- Chunk 15238 ---\n",
            "You can also save a tf.keras model directly to a FlatBuffer using\n",
            "from_keras_model().\n",
            "\n",
            "--- Chunk 15239 ---\n",
            "8 Also check out TensorFlow’s Graph Transform Tools for modifying and optimizing computational graphs.\n",
            "\n",
            "--- Chunk 15240 ---\n",
            "Deploying a Model to a Mobile or Embedded Device | 685\n",
            "\n",
            "--- Chunk 15241 ---\n",
            "The converter also optimizes the model, both to shrink it and to reduce its latency. It\n",
            "\n",
            "--- Chunk 15242 ---\n",
            "prunes all the operations that are not needed to make predictions (such as training\n",
            "\n",
            "--- Chunk 15243 ---\n",
            "operations), and it optimizes computations whenever possible; for example, 3×a +\n",
            "\n",
            "--- Chunk 15244 ---\n",
            "4×a + 5×a will be converted to (3 + 4 + 5)×a. It also tries to fuse operations whenever\n",
            "\n",
            "--- Chunk 15245 ---\n",
            "possible. For example, Batch Normalization layers end up folded into the previous\n",
            "\n",
            "--- Chunk 15246 ---\n",
            "layer’s addition and multiplication operations, whenever possible. To get a good idea\n",
            "\n",
            "--- Chunk 15247 ---\n",
            "of how much TFLite can optimize a model, download one of the pretrained TFLite\n",
            "\n",
            "--- Chunk 15248 ---\n",
            "models, unzip the archive, then open the excellent Netron graph visualization tool\n",
            "\n",
            "--- Chunk 15249 ---\n",
            "and upload the .pb file to view the original model. It’s a big, complex graph, right?\n",
            "\n",
            "--- Chunk 15250 ---\n",
            "Next, open the optimized .tflite model and marvel at its beauty!\n",
            "Another way you can reduce the model size (other than simply using smaller neural\n",
            "\n",
            "--- Chunk 15251 ---\n",
            "network architectures) is by using smaller bit-widths: for example, if you use half-\n",
            "\n",
            "--- Chunk 15252 ---\n",
            "floats (16 bits) rather than regular floats (32 bits), the model size will shrink by a fac‐\n",
            "\n",
            "--- Chunk 15253 ---\n",
            "tor of 2, at the cost of a (generally small) accuracy drop. Moreover, training will be\n",
            "faster, and you will use roughly half the amount of GPU RAM.\n",
            "\n",
            "--- Chunk 15254 ---\n",
            "TFLite’s converter can go further than that, by quantizing the model weights down to\n",
            "\n",
            "--- Chunk 15255 ---\n",
            "fixed-point, 8-bit integers! This leads to a fourfold size reduction compared to using\n",
            "\n",
            "--- Chunk 15256 ---\n",
            "32-bit floats. The simplest approach is called post-training quantization: it just quanti‐\n",
            "\n",
            "--- Chunk 15257 ---\n",
            "zes the weights after training, using a fairly basic but efficient symmetrical quantiza‐\n",
            "\n",
            "--- Chunk 15258 ---\n",
            "tion technique. It finds the maximum absolute weight value, m, then it maps the\n",
            "\n",
            "--- Chunk 15259 ---\n",
            "floating-point range –m to +m to the fixed-point (integer) range –127 to +127. For\n",
            "\n",
            "--- Chunk 15260 ---\n",
            "example (see Figure 19-8), if the weights range from –1.5 to +0.8, then the bytes –127,\n",
            "\n",
            "--- Chunk 15261 ---\n",
            "0, and +127 will correspond to the floats –1.5, 0.0, and +1.5, respectively. Note that\n",
            "\n",
            "--- Chunk 15262 ---\n",
            "0.0 always maps to 0 when using symmetrical quantization (also note that the byte\n",
            "\n",
            "--- Chunk 15263 ---\n",
            "values +68 to +127 will not be used, since they map to floats greater than +0.8).\n",
            "\n",
            "--- Chunk 15264 ---\n",
            "Figure 19-8. From 32-bit floats to 8-bit integers, using symmetrical quantization\n",
            "\n",
            "--- Chunk 15265 ---\n",
            "To perform this post-training quantization, simply add OPTIMIZE_FOR_SIZE to the list\n",
            "of converter optimizations before calling the convert() method:\n",
            "\n",
            "--- Chunk 15266 ---\n",
            "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
            "\n",
            "--- Chunk 15267 ---\n",
            "This technique dramatically reduces the model’s size, so it’s much faster to download\n",
            "\n",
            "--- Chunk 15268 ---\n",
            "and store. However, at runtime the quantized weights get converted back to floats\n",
            "\n",
            "--- Chunk 15269 ---\n",
            "before they are used (these recovered floats are not perfectly identical to the original\n",
            "\n",
            "--- Chunk 15270 ---\n",
            "686 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 15271 ---\n",
            "floats, but not too far off, so the accuracy loss is usually acceptable). To avoid recom‐\n",
            "\n",
            "--- Chunk 15272 ---\n",
            "puting them all the time, the recovered floats are cached, so there is no reduction of\n",
            "RAM usage. And there is no reduction either in compute speed.\n",
            "\n",
            "--- Chunk 15273 ---\n",
            "The most effective way to reduce latency and power consumption is to also quantize\n",
            "\n",
            "--- Chunk 15274 ---\n",
            "the activations so that the computations can be done entirely with integers, without\n",
            "\n",
            "--- Chunk 15275 ---\n",
            "the need for any floating-point operations. Even when using the same bit-width (e.g.,\n",
            "\n",
            "--- Chunk 15276 ---\n",
            "32-bit integers instead of 32-bit floats), integer computations use less CPU cycles,\n",
            "\n",
            "--- Chunk 15277 ---\n",
            "consume less energy, and produce less heat. And if you also reduce the bit-width (e.g.,\n",
            "\n",
            "--- Chunk 15278 ---\n",
            "down to 8-bit integers), you can get huge speedups. Moreover, some neural network\n",
            "\n",
            "--- Chunk 15279 ---\n",
            "accelerator devices (such as the Edge TPU) can only process integers, so full quanti‐\n",
            "\n",
            "--- Chunk 15280 ---\n",
            "zation of both weights and activations is compulsory. This can be done post-training;\n",
            "\n",
            "--- Chunk 15281 ---\n",
            "it requires a calibration step to find the maximum absolute value of the activations, so\n",
            "\n",
            "--- Chunk 15282 ---\n",
            "you need to provide a representative sample of training data to TFLite (it does not\n",
            "\n",
            "--- Chunk 15283 ---\n",
            "need to be huge), and it will process the data through the model and measure the\n",
            "\n",
            "--- Chunk 15284 ---\n",
            "activation statistics required for quantization (this step is typically fast).\n",
            "\n",
            "--- Chunk 15285 ---\n",
            "The main problem with quantization is that it loses a bit of accuracy: it is equivalent\n",
            "\n",
            "--- Chunk 15286 ---\n",
            "to adding noise to the weights and activations. If the accuracy drop is too severe, then\n",
            "\n",
            "--- Chunk 15287 ---\n",
            "you may need to use quantization-aware training. This means adding fake quantiza‐\n",
            "\n",
            "--- Chunk 15288 ---\n",
            "tion operations to the model so it can learn to ignore the quantization noise during\n",
            "\n",
            "--- Chunk 15289 ---\n",
            "training; the final weights will then be more robust to quantization. Moreover, the\n",
            "\n",
            "--- Chunk 15290 ---\n",
            "calibration step can be taken care of automatically during training, which simplifies\n",
            "the whole process.\n",
            "\n",
            "--- Chunk 15291 ---\n",
            "the whole process.\n",
            "I have explained the core concepts of TFLite, but going all the way to coding a mobile\n",
            "\n",
            "--- Chunk 15292 ---\n",
            "app or an embedded program would require a whole other book. Fortunately, one\n",
            "\n",
            "--- Chunk 15293 ---\n",
            "exists: if you want to learn more about building TensorFlow applications for mobile\n",
            "\n",
            "--- Chunk 15294 ---\n",
            "and embedded devices, check out the O’Reilly book TinyML: Machine Learning with\n",
            "\n",
            "--- Chunk 15295 ---\n",
            "TensorFlow on Arduino and Ultra-Low Power Micro-Controllers, by Pete Warden (who\n",
            "leads the TFLite team) and Daniel Situnayake.\n",
            "\n",
            "--- Chunk 15296 ---\n",
            "Deploying a Model to a Mobile or Embedded Device | 687\n",
            "\n",
            "--- Chunk 15297 ---\n",
            "TensorFlow in the Browser\n",
            "What if you want to use your model in a website, running directly in the user’s\n",
            "\n",
            "--- Chunk 15298 ---\n",
            "browser? This can be useful in many scenarios, such as:\n",
            "\n",
            "--- Chunk 15299 ---\n",
            "• When your web application is often used in situations where the user’s connec‐\n",
            "\n",
            "--- Chunk 15300 ---\n",
            "tivity is intermittent or slow (e.g., a website for hikers), so running the model\n",
            "\n",
            "--- Chunk 15301 ---\n",
            "directly on the client side is the only way to make your website reliable.\n",
            "\n",
            "--- Chunk 15302 ---\n",
            "• When you need the model’s responses to be as fast as possible (e.g., for an online\n",
            "\n",
            "--- Chunk 15303 ---\n",
            "game). Removing the need to query the server to make predictions will definitely\n",
            "reduce the latency and make the website much more responsive.\n",
            "\n",
            "--- Chunk 15304 ---\n",
            "• When your web service makes predictions based on some private user data, and\n",
            "\n",
            "--- Chunk 15305 ---\n",
            "you want to protect the user’s privacy by making the predictions on the client\n",
            "side so that the private data never has to leave the user’s machine.9\n",
            "\n",
            "--- Chunk 15306 ---\n",
            "For all these scenarios, you can export your model to a special format that can be\n",
            "\n",
            "--- Chunk 15307 ---\n",
            "loaded by the TensorFlow.js JavaScript library. This library can then use your model\n",
            "\n",
            "--- Chunk 15308 ---\n",
            "to make predictions directly in the user’s browser. The TensorFlow.js project includes\n",
            "\n",
            "--- Chunk 15309 ---\n",
            "a tensorflowjs_converter tool that can convert a TensorFlow SavedModel or a\n",
            "\n",
            "--- Chunk 15310 ---\n",
            "Keras model file to the TensorFlow.js Layers format: this is a directory containing a set\n",
            "\n",
            "--- Chunk 15311 ---\n",
            "of sharded weight files in binary format and a model.json file that describes the mod‐\n",
            "\n",
            "--- Chunk 15312 ---\n",
            "el’s architecture and links to the weight files. This format is optimized to be downloa‐\n",
            "\n",
            "--- Chunk 15313 ---\n",
            "ded efficiently on the web. Users can then download the model and run predictions in\n",
            "\n",
            "--- Chunk 15314 ---\n",
            "the browser using the TensorFlow.js library. Here is a code snippet to give you an idea\n",
            "of what the JavaScript API looks like:\n",
            "\n",
            "--- Chunk 15315 ---\n",
            "import * as tf from '@tensorflow/tfjs';\n",
            "const model = await tf.loadLayersModel('https://example.com/tfjs/model.json');\n",
            "\n",
            "--- Chunk 15316 ---\n",
            "const image = tf.fromPixels(webcamElement);\n",
            "const prediction = model.predict(image);\n",
            "\n",
            "--- Chunk 15317 ---\n",
            "Once again, doing justice to this topic would require a whole book. If you want to\n",
            "\n",
            "--- Chunk 15318 ---\n",
            "learn more about TensorFlow.js, check out the O’Reilly book Practical Deep Learning\n",
            "\n",
            "--- Chunk 15319 ---\n",
            "for Cloud, Mobile, and Edge, by Anirudh Koul, Siddha Ganju, and Meher Kasam.\n",
            "\n",
            "--- Chunk 15320 ---\n",
            "Next, we will see how to use GPUs to speed up computations!\n",
            "\n",
            "9 If you’re interested in this topic, check out federated learning.\n",
            "\n",
            "--- Chunk 15321 ---\n",
            "688 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 15322 ---\n",
            "Using GPUs to Speed Up Computations\n",
            "In Chapter 11 we discussed several techniques that can considerably speed up train‐\n",
            "\n",
            "--- Chunk 15323 ---\n",
            "ing: better weight initialization, Batch Normalization, sophisticated optimizers, and\n",
            "\n",
            "--- Chunk 15324 ---\n",
            "so on. But even with all of these techniques, training a large neural network on a sin‐\n",
            "gle machine with a single CPU can take days or even weeks.\n",
            "\n",
            "--- Chunk 15325 ---\n",
            "In this section we will look at how to speed up your models by using GPUs. We will\n",
            "\n",
            "--- Chunk 15326 ---\n",
            "also see how to split the computations across multiple devices, including the CPU\n",
            "\n",
            "--- Chunk 15327 ---\n",
            "and multiple GPU devices (see Figure 19-9). For now we will run everything on a sin‐\n",
            "\n",
            "--- Chunk 15328 ---\n",
            "gle machine, but later in this chapter we will discuss how to distribute computations\n",
            "across multiple servers.\n",
            "\n",
            "--- Chunk 15329 ---\n",
            "Figure 19-9. Executing a TensorFlow graph across multiple devices in parallel\n",
            "\n",
            "--- Chunk 15330 ---\n",
            "Thanks to GPUs, instead of waiting for days or weeks for a training algorithm to\n",
            "\n",
            "--- Chunk 15331 ---\n",
            "complete, you may end up waiting for just a few minutes or hours. Not only does this\n",
            "\n",
            "--- Chunk 15332 ---\n",
            "save an enormous amount of time, but it also means that you can experiment with\n",
            "\n",
            "--- Chunk 15333 ---\n",
            "various models much more easily and frequently retrain your models on fresh data.\n",
            "\n",
            "--- Chunk 15334 ---\n",
            "You can often get a major performance boost simply by adding\n",
            "GPU cards to a single machine. In fact, in many cases this will suf‐\n",
            "\n",
            "--- Chunk 15335 ---\n",
            "fice; you won’t need to use multiple machines at all. For example,\n",
            "you can typically train a neural network just as fast using four\n",
            "\n",
            "--- Chunk 15336 ---\n",
            "GPUs on a single machine rather than eight GPUs across multiple\n",
            "machines, due to the extra delay imposed by network communica‐\n",
            "\n",
            "--- Chunk 15337 ---\n",
            "tions in a distributed setup. Similarly, using a single powerful GPU\n",
            "is often preferable to using multiple slower GPUs.\n",
            "\n",
            "--- Chunk 15338 ---\n",
            "Using GPUs to Speed Up Computations | 689\n",
            "\n",
            "--- Chunk 15339 ---\n",
            "The first step is to get your hands on a GPU. There are two options for this: you can\n",
            "\n",
            "--- Chunk 15340 ---\n",
            "either purchase your own GPU(s), or you can use GPU-equipped virtual machines\n",
            "on the cloud. Let’s start with the first option.\n",
            "\n",
            "--- Chunk 15341 ---\n",
            "Getting Your Own GPU\n",
            "If you choose to purchase a GPU card, then take some time to make the right choice.\n",
            "\n",
            "--- Chunk 15342 ---\n",
            "Tim Dettmers wrote an excellent blog post to help you choose, and he updates it reg‐\n",
            "\n",
            "--- Chunk 15343 ---\n",
            "ularly: I encourage you to read it carefully. At the time of this writing, TensorFlow\n",
            "\n",
            "--- Chunk 15344 ---\n",
            "only supports Nvidia cards with CUDA Compute Capability 3.5+ (as well as Google’s\n",
            "\n",
            "--- Chunk 15345 ---\n",
            "TPUs, of course), but it may extend its support to other manufacturers. Moreover,\n",
            "\n",
            "--- Chunk 15346 ---\n",
            "although TPUs are currently only available on GCP, it is highly likely that TPU-like\n",
            "\n",
            "--- Chunk 15347 ---\n",
            "cards will be available for sale in the near future, and TensorFlow may support them.\n",
            "\n",
            "--- Chunk 15348 ---\n",
            "In short, make sure to check TensorFlow’s documentation to see what devices are\n",
            "supported at this point.\n",
            "\n",
            "--- Chunk 15349 ---\n",
            "If you go for an Nvidia GPU card, you will need to install the appropriate Nvidia\n",
            "\n",
            "--- Chunk 15350 ---\n",
            "drivers and several Nvidia libraries.10 These include the Compute Unified Device\n",
            "\n",
            "--- Chunk 15351 ---\n",
            "Architecture library (CUDA), which allows developers to use CUDA-enabled GPUs\n",
            "\n",
            "--- Chunk 15352 ---\n",
            "for all sorts of computations (not just graphics acceleration), and the CUDA Deep\n",
            "\n",
            "--- Chunk 15353 ---\n",
            "Neural Network library (cuDNN), a GPU-accelerated library of primitives for DNNs.\n",
            "\n",
            "--- Chunk 15354 ---\n",
            "cuDNN provides optimized implementations of common DNN computations such\n",
            "\n",
            "--- Chunk 15355 ---\n",
            "as activation layers, normalization, forward and backward convolutions, and pooling\n",
            "\n",
            "--- Chunk 15356 ---\n",
            "(see Chapter 14). It is part of Nvidia’s Deep Learning SDK (note that you’ll need to\n",
            "\n",
            "--- Chunk 15357 ---\n",
            "create an Nvidia developer account in order to download it). TensorFlow uses CUDA\n",
            "and cuDNN to control the GPU cards and accelerate computations (see\n",
            "\n",
            "--- Chunk 15358 ---\n",
            "Figure 19-10).\n",
            "\n",
            "--- Chunk 15359 ---\n",
            "Figure 19-10. TensorFlow uses CUDA and cuDNN to control GPUs and boost DNNs\n",
            "\n",
            "--- Chunk 15360 ---\n",
            "10 Please check the docs for detailed and up-to-date installation instructions, as they change quite often.\n",
            "\n",
            "--- Chunk 15361 ---\n",
            "690 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 15362 ---\n",
            "Once you have installed the GPU card(s) and all the required drivers and libraries,\n",
            "\n",
            "--- Chunk 15363 ---\n",
            "you can use the nvidia-smi command to check that CUDA is properly installed. It\n",
            "\n",
            "--- Chunk 15364 ---\n",
            "lists the available GPU cards, as well as processes running on each card:\n",
            "\n",
            "--- Chunk 15365 ---\n",
            "$ nvidia-smi\n",
            "Sun Jun  2 10:05:22 2019\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "--- Chunk 15366 ---\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "\n",
            "--- Chunk 15367 ---\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "\n",
            "--- Chunk 15368 ---\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "\n",
            "--- Chunk 15369 ---\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "\n",
            "--- Chunk 15370 ---\n",
            "|===============================+======================+======================|\n",
            "\n",
            "--- Chunk 15371 ---\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "\n",
            "--- Chunk 15372 ---\n",
            "| N/A   61C    P8    17W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "\n",
            "--- Chunk 15373 ---\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "\n",
            "--- Chunk 15374 ---\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "--- Chunk 15375 ---\n",
            "| Processes:                                                       GPU Memory |\n",
            "\n",
            "--- Chunk 15376 ---\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "\n",
            "--- Chunk 15377 ---\n",
            "|=============================================================================|\n",
            "\n",
            "--- Chunk 15378 ---\n",
            "|  No running processes found                                                 |\n",
            "\n",
            "--- Chunk 15379 ---\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "--- Chunk 15380 ---\n",
            "At the time of this writing, you’ll also need to install the GPU version of TensorFlow\n",
            "\n",
            "--- Chunk 15381 ---\n",
            "(i.e., the tensorflow-gpu library); however, there is ongoing work to have a unified\n",
            "\n",
            "--- Chunk 15382 ---\n",
            "installation procedure for both CPU-only and GPU machines, so please check the\n",
            "\n",
            "--- Chunk 15383 ---\n",
            "installation documentation to see which library you should install. In any case, since\n",
            "\n",
            "--- Chunk 15384 ---\n",
            "installing every required library correctly is a bit long and tricky (and all hell breaks\n",
            "\n",
            "--- Chunk 15385 ---\n",
            "loose if you do not install the correct library versions), TensorFlow provides a Docker\n",
            "\n",
            "--- Chunk 15386 ---\n",
            "image with everything you need inside. However, in order for the Docker container\n",
            "\n",
            "--- Chunk 15387 ---\n",
            "to have access to the GPU, you will still need to install the Nvidia drivers on the host\n",
            "machine.\n",
            "\n",
            "--- Chunk 15388 ---\n",
            "machine.\n",
            "To check that TensorFlow actually sees the GPUs, run the following tests:\n",
            "\n",
            "--- Chunk 15389 ---\n",
            ">>> import tensorflow as tf\n",
            ">>> tf.test.is_gpu_available()\n",
            "True\n",
            ">>> tf.test.gpu_device_name()\n",
            "'/device:GPU:0'\n",
            "\n",
            "--- Chunk 15390 ---\n",
            "'/device:GPU:0'\n",
            ">>> tf.config.experimental.list_physical_devices(device_type='GPU')\n",
            "\n",
            "--- Chunk 15391 ---\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "\n",
            "--- Chunk 15392 ---\n",
            "The is_gpu_available() function checks whether at least one GPU is available. The\n",
            "\n",
            "--- Chunk 15393 ---\n",
            "gpu_device_name() function gives the first GPU’s name: by default, operations will\n",
            "\n",
            "--- Chunk 15394 ---\n",
            "Using GPUs to Speed Up Computations | 691\n",
            "\n",
            "--- Chunk 15395 ---\n",
            "run on this GPU. The list_physical_devices() function returns the list of all avail‐\n",
            "able GPU devices (just one in this example).11\n",
            "\n",
            "--- Chunk 15396 ---\n",
            "Now, what if you don’t want to invest time and money in getting your own GPU\n",
            "card? Just use a GPU VM on the cloud!\n",
            "\n",
            "--- Chunk 15397 ---\n",
            "Using a GPU-Equipped Virtual Machine\n",
            "All major cloud platforms now offer GPU VMs, some preconfigured with all the driv‐\n",
            "\n",
            "--- Chunk 15398 ---\n",
            "ers and libraries you need (including TensorFlow). Google Cloud Platform enforces\n",
            "\n",
            "--- Chunk 15399 ---\n",
            "various GPU quotas, both worldwide and per region: you cannot just create thou‐\n",
            "\n",
            "--- Chunk 15400 ---\n",
            "sands of GPU VMs without prior authorization from Google.12 By default, the world‐\n",
            "\n",
            "--- Chunk 15401 ---\n",
            "wide GPU quota is zero, so you cannot use any GPU VMs. Therefore, the very first\n",
            "\n",
            "--- Chunk 15402 ---\n",
            "thing you need to do is to request a higher worldwide quota. In the GCP console,\n",
            "\n",
            "--- Chunk 15403 ---\n",
            "open the navigation menu and go to IAM & admin → Quotas. Click Metric, click\n",
            "\n",
            "--- Chunk 15404 ---\n",
            "None to uncheck all locations, then search for “GPU” and select “GPUs (all regions)”\n",
            "\n",
            "--- Chunk 15405 ---\n",
            "to see the corresponding quota. If this quota’s value is zero (or just insufficient for\n",
            "\n",
            "--- Chunk 15406 ---\n",
            "your needs), then check the box next to it (it should be the only selected one) and\n",
            "\n",
            "--- Chunk 15407 ---\n",
            "click “Edit quotas.” Fill in the requested information, then click “Submit request.” It\n",
            "\n",
            "--- Chunk 15408 ---\n",
            "may take a few hours (or up to a few days) for your quota request to be processed and\n",
            "\n",
            "--- Chunk 15409 ---\n",
            "(generally) accepted. By default, there is also a quota of one GPU per region and per\n",
            "\n",
            "--- Chunk 15410 ---\n",
            "GPU type. You can request to increase these quotas too: click Metric, select None to\n",
            "\n",
            "--- Chunk 15411 ---\n",
            "uncheck all metrics, search for “GPU,” and select the type of GPU you want (e.g.,\n",
            "\n",
            "--- Chunk 15412 ---\n",
            "NVIDIA P4 GPUs). Then click the Location drop-down menu, click None to\n",
            "\n",
            "--- Chunk 15413 ---\n",
            "uncheck all metrics, and click the location you want; check the boxes next to the\n",
            "\n",
            "--- Chunk 15414 ---\n",
            "quota(s) you want to change, and click “Edit quotas” to file a request.\n",
            "\n",
            "--- Chunk 15415 ---\n",
            "Once your GPU quota requests are approved, you can in no time create a VM equip‐\n",
            "\n",
            "--- Chunk 15416 ---\n",
            "ped with one or more GPUs by using Google Cloud AI Platform’s Deep Learning VM\n",
            "\n",
            "--- Chunk 15417 ---\n",
            "Images: go to https://homl.info/dlvm, click View Console, then click “Launch on Com‐\n",
            "\n",
            "--- Chunk 15418 ---\n",
            "pute Engine” and fill in the VM configuration form. Note that some locations do not\n",
            "\n",
            "--- Chunk 15419 ---\n",
            "have all types of GPUs, and some have no GPUs at all (change the location to see the\n",
            "\n",
            "--- Chunk 15420 ---\n",
            "types of GPUs available, if any). Make sure to select TensorFlow 2.0 as the framework,\n",
            "\n",
            "--- Chunk 15421 ---\n",
            "and check “Install NVIDIA GPU driver automatically on first startup.” It is also a\n",
            "\n",
            "--- Chunk 15422 ---\n",
            "good idea to check “Enable access to JupyterLab via URL instead of SSH”: this will\n",
            "\n",
            "--- Chunk 15423 ---\n",
            "make it very easy to start a Jupyter notebook running on this GPU VM, powered by\n",
            "\n",
            "--- Chunk 15424 ---\n",
            "11 Many code examples in this chapter use experimental APIs. They are very likely to be moved to the core API\n",
            "\n",
            "--- Chunk 15425 ---\n",
            "in future versions. So if an experimental function fails, try simply removing the word experimental, and\n",
            "\n",
            "--- Chunk 15426 ---\n",
            "hopefully it will work. If not, then perhaps the API has changed a bit; please check the Jupyter notebook, as I\n",
            "\n",
            "--- Chunk 15427 ---\n",
            "will ensure it contains the correct code.\n",
            "\n",
            "--- Chunk 15428 ---\n",
            "12 Presumably, these quotas are meant to stop bad guys who might be tempted to use GCP with stolen credit\n",
            "cards to mine cryptocurrencies.\n",
            "\n",
            "--- Chunk 15429 ---\n",
            "692 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 15430 ---\n",
            "JupyterLab (this is an alternative web interface to run Jupyter notebooks). Once the\n",
            "\n",
            "--- Chunk 15431 ---\n",
            "VM is created, scroll down the navigation menu to the Artificial Intelligence section,\n",
            "\n",
            "--- Chunk 15432 ---\n",
            "then click AI Platform → Notebooks. Once the Notebook instance appears in the list\n",
            "\n",
            "--- Chunk 15433 ---\n",
            "(this may take a few minutes, so click Refresh once in a while until it appears), click\n",
            "\n",
            "--- Chunk 15434 ---\n",
            "its Open JupyterLab link. This will run JupyterLab on the VM and connect your\n",
            "\n",
            "--- Chunk 15435 ---\n",
            "browser to it. You can create notebooks and run any code you want on this VM, and\n",
            "benefit from its GPUs!\n",
            "\n",
            "--- Chunk 15436 ---\n",
            "But if you just want to run some quick tests or easily share notebooks with your col‐\n",
            "leagues, then you should try Colaboratory.\n",
            "\n",
            "--- Chunk 15437 ---\n",
            "Colaboratory\n",
            "The simplest and cheapest way to access a GPU VM is to use Colaboratory (or Colab,\n",
            "\n",
            "--- Chunk 15438 ---\n",
            "for short). It’s free! Just go to https://colab.research.google.com/ and create a new\n",
            "\n",
            "--- Chunk 15439 ---\n",
            "Python 3 notebook: this will create a Jupyter notebook, stored on your Google Drive\n",
            "\n",
            "--- Chunk 15440 ---\n",
            "(alternatively, you can open any notebook on GitHub, or on Google Drive, or you can\n",
            "\n",
            "--- Chunk 15441 ---\n",
            "even upload your own notebooks). Colab’s user interface is similar to Jupyter’s, except\n",
            "\n",
            "--- Chunk 15442 ---\n",
            "you can share and use the notebooks like regular Google Docs, and there are a few\n",
            "\n",
            "--- Chunk 15443 ---\n",
            "other minor differences (e.g., you can create handy widgets using special comments\n",
            "in your code).\n",
            "\n",
            "--- Chunk 15444 ---\n",
            "in your code).\n",
            "When you open a Colab notebook, it runs on a free Google VM dedicated to that\n",
            "\n",
            "--- Chunk 15445 ---\n",
            "notebook, called a Colab Runtime (see Figure 19-11). By default the Runtime is CPU-\n",
            "\n",
            "--- Chunk 15446 ---\n",
            "only, but you can change this by going to Runtime → “Change runtime type,” select‐\n",
            "\n",
            "--- Chunk 15447 ---\n",
            "ing GPU in the “Hardware accelerator” drop-down menu, then clicking Save. In fact,\n",
            "\n",
            "--- Chunk 15448 ---\n",
            "you could even select TPU! (Yes, you can actually use a TPU for free; we will talk\n",
            "\n",
            "--- Chunk 15449 ---\n",
            "about TPUs later in this chapter, though, so for now just select GPU.)\n",
            "\n",
            "--- Chunk 15450 ---\n",
            "Using GPUs to Speed Up Computations | 693\n",
            "\n",
            "\n",
            "\n",
            "Figure 19-11. Colab Runtimes and notebooks\n",
            "\n",
            "--- Chunk 15451 ---\n",
            "Colab does have some restrictions: first, there is a limit to the number of Colab note‐\n",
            "\n",
            "--- Chunk 15452 ---\n",
            "books you can run simultaneously (currently 5 per Runtime type). Moreover, as the\n",
            "\n",
            "--- Chunk 15453 ---\n",
            "FAQ states, “Colaboratory is intended for interactive use. Long-running background\n",
            "\n",
            "--- Chunk 15454 ---\n",
            "computations, particularly on GPUs, may be stopped. Please do not use Colaboratory\n",
            "\n",
            "--- Chunk 15455 ---\n",
            "for cryptocurrency mining.” Also, the web interface will automatically disconnect\n",
            "\n",
            "--- Chunk 15456 ---\n",
            "from the Colab Runtime if you leave it unattended for a while (~30 minutes). When\n",
            "\n",
            "--- Chunk 15457 ---\n",
            "you reconnect to the Colab Runtime, it may have been reset, so make sure you always\n",
            "\n",
            "--- Chunk 15458 ---\n",
            "export any data you care about (e.g., download it or save it to Google Drive). Even if\n",
            "\n",
            "--- Chunk 15459 ---\n",
            "you never disconnect, the Colab Runtime will automatically shut down after 12\n",
            "\n",
            "--- Chunk 15460 ---\n",
            "hours, as it is not meant for long-running computations. Despite these limitations, it’s\n",
            "\n",
            "--- Chunk 15461 ---\n",
            "a fantastic tool to run tests easily, get quick results, and collaborate with your\n",
            "colleagues.\n",
            "\n",
            "--- Chunk 15462 ---\n",
            "Managing the GPU RAM\n",
            "By default TensorFlow automatically grabs all the RAM in all available GPUs the first\n",
            "\n",
            "--- Chunk 15463 ---\n",
            "time you run a computation. It does this to limit GPU RAM fragmentation. This\n",
            "\n",
            "--- Chunk 15464 ---\n",
            "means that if you try to start a second TensorFlow program (or any program that\n",
            "\n",
            "--- Chunk 15465 ---\n",
            "requires the GPU), it will quickly run out of RAM. This does not happen as often as\n",
            "\n",
            "--- Chunk 15466 ---\n",
            "you might think, as you will most often have a single TensorFlow program running\n",
            "\n",
            "--- Chunk 15467 ---\n",
            "on a machine: usually a training script, a TF Serving node, or a Jupyter notebook. If\n",
            "\n",
            "--- Chunk 15468 ---\n",
            "you need to run multiple programs for some reason (e.g., to train two different mod‐\n",
            "\n",
            "--- Chunk 15469 ---\n",
            "els in parallel on the same machine), then you will need to split the GPU RAM\n",
            "between these processes more evenly.\n",
            "\n",
            "--- Chunk 15470 ---\n",
            "If you have multiple GPU cards on your machine, a simple solution is to assign each\n",
            "\n",
            "--- Chunk 15471 ---\n",
            "of them to a single process. To do this, you can set the CUDA_VISIBLE_DEVICES\n",
            "\n",
            "--- Chunk 15472 ---\n",
            "environment variable so that each process only sees the appropriate GPU card(s).\n",
            "\n",
            "--- Chunk 15473 ---\n",
            "Also set the CUDA_DEVICE_ORDER environment variable to PCI_BUS_ID to ensure that\n",
            "\n",
            "--- Chunk 15474 ---\n",
            "694 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 15475 ---\n",
            "each ID always refers to the same GPU card. For example, if you have four GPU\n",
            "\n",
            "--- Chunk 15476 ---\n",
            "cards, you could start two programs, assigning two GPUs to each of them, by execut‐\n",
            "ing commands like the following in two separate terminal windows:\n",
            "\n",
            "--- Chunk 15477 ---\n",
            "$ CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=0,1 python3 program_1.py\n",
            "# and in another terminal:\n",
            "\n",
            "--- Chunk 15478 ---\n",
            "$ CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=3,2 python3 program_2.py\n",
            "\n",
            "--- Chunk 15479 ---\n",
            "Program 1 will then only see GPU cards 0 and 1, named /gpu:0 and /gpu:1 respec‐\n",
            "\n",
            "--- Chunk 15480 ---\n",
            "tively, and program 2 will only see GPU cards 2 and 3, named /gpu:1 and /gpu:0\n",
            "\n",
            "--- Chunk 15481 ---\n",
            "respectively (note the order). Everything will work fine (see Figure 19-12). Of course,\n",
            "\n",
            "--- Chunk 15482 ---\n",
            "you can also define these environment variables in Python by setting os.envi\n",
            "\n",
            "--- Chunk 15483 ---\n",
            "ron[\"CUDA_DEVICE_ORDER\"] and os.environ[\"CUDA_VISIBLE_DEVICES\"], as long as\n",
            "you do so before using TensorFlow.\n",
            "\n",
            "--- Chunk 15484 ---\n",
            "Figure 19-12. Each program gets two GPUs\n",
            "\n",
            "--- Chunk 15485 ---\n",
            "Another option is to tell TensorFlow to grab only a specific amount of GPU RAM.\n",
            "\n",
            "--- Chunk 15486 ---\n",
            "This must be done immediately after importing TensorFlow. For example, to make\n",
            "\n",
            "--- Chunk 15487 ---\n",
            "TensorFlow grab only 2 GiB of RAM on each GPU, you must create a virtual GPU\n",
            "\n",
            "--- Chunk 15488 ---\n",
            "device (also called a logical GPU device) for each physical GPU device and set its\n",
            "memory limit to 2 GiB (i.e., 2,048 MiB):\n",
            "\n",
            "--- Chunk 15489 ---\n",
            "for gpu in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
            "    tf.config.experimental.set_virtual_device_configuration(\n",
            "        gpu,\n",
            "\n",
            "--- Chunk 15490 ---\n",
            "gpu,\n",
            "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])\n",
            "\n",
            "--- Chunk 15491 ---\n",
            "Now (supposing you have four GPUs, each with at least 4 GiB of RAM) two programs\n",
            "\n",
            "--- Chunk 15492 ---\n",
            "like this one can run in parallel, each using all four GPU cards (see Figure 19-13).\n",
            "\n",
            "--- Chunk 15493 ---\n",
            "Using GPUs to Speed Up Computations | 695\n",
            "\n",
            "\n",
            "\n",
            "Figure 19-13. Each program gets all four GPUs, but with only 2 GiB of RAM on each\n",
            "GPU\n",
            "\n",
            "--- Chunk 15494 ---\n",
            "If you run the nvidia-smi command while both programs are running, you should\n",
            "see that each process holds 2 GiB of RAM on each card:\n",
            "\n",
            "--- Chunk 15495 ---\n",
            "$ nvidia-smi\n",
            "[...]\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "--- Chunk 15496 ---\n",
            "| Processes:                                                       GPU Memory |\n",
            "\n",
            "--- Chunk 15497 ---\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "\n",
            "--- Chunk 15498 ---\n",
            "|=============================================================================|\n",
            "\n",
            "--- Chunk 15499 ---\n",
            "|    0      2373      C   /usr/bin/python3                            2241MiB |\n",
            "\n",
            "--- Chunk 15500 ---\n",
            "|    0      2533      C   /usr/bin/python3                            2241MiB |\n",
            "\n",
            "--- Chunk 15501 ---\n",
            "|    1      2373      C   /usr/bin/python3                            2241MiB |\n",
            "\n",
            "--- Chunk 15502 ---\n",
            "|    1      2533      C   /usr/bin/python3                            2241MiB |\n",
            "[...]\n",
            "\n",
            "--- Chunk 15503 ---\n",
            "Yet another option is to tell TensorFlow to grab memory only when it needs it (this\n",
            "also must be done immediately after importing TensorFlow):\n",
            "\n",
            "--- Chunk 15504 ---\n",
            "for gpu in tf.config.experimental.list_physical_devices(\"GPU\"):\n",
            "    tf.config.experimental.set_memory_growth(gpu, True)\n",
            "\n",
            "--- Chunk 15505 ---\n",
            "Another way to do this is to set the TF_FORCE_GPU_ALLOW_GROWTH environment vari‐\n",
            "\n",
            "--- Chunk 15506 ---\n",
            "able to true. With this option, TensorFlow will never release memory once it has\n",
            "\n",
            "--- Chunk 15507 ---\n",
            "grabbed it (again, to avoid memory fragmentation), except of course when the pro‐\n",
            "\n",
            "--- Chunk 15508 ---\n",
            "gram ends. It can be harder to guarantee deterministic behavior using this option\n",
            "\n",
            "--- Chunk 15509 ---\n",
            "(e.g., one program may crash because another program’s memory usage went through\n",
            "\n",
            "--- Chunk 15510 ---\n",
            "the roof), so in production you’ll probably want to stick with one of the previous\n",
            "\n",
            "--- Chunk 15511 ---\n",
            "options. However, there are some cases where it is very useful: for example, when you\n",
            "\n",
            "--- Chunk 15512 ---\n",
            "use a machine to run multiple Jupyter notebooks, several of which use TensorFlow.\n",
            "\n",
            "--- Chunk 15513 ---\n",
            "This is why the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set to true in\n",
            "Colab Runtimes.\n",
            "\n",
            "--- Chunk 15514 ---\n",
            "Colab Runtimes.\n",
            "Lastly, in some cases you may want to split a GPU into two or more virtual GPUs—\n",
            "\n",
            "--- Chunk 15515 ---\n",
            "for example, if you want to test a distribution algorithm (this is a handy way to try\n",
            "\n",
            "--- Chunk 15516 ---\n",
            "out the code examples in the rest of this chapter even if you have a single GPU, such\n",
            "\n",
            "--- Chunk 15517 ---\n",
            "696 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 15518 ---\n",
            "as in a Colab Runtime). The following code splits the first GPU into two virtual devi‐\n",
            "\n",
            "--- Chunk 15519 ---\n",
            "ces, with 2 GiB of RAM each (again, this must be done immediately after importing\n",
            "TensorFlow):\n",
            "\n",
            "--- Chunk 15520 ---\n",
            "physical_gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
            "tf.config.experimental.set_virtual_device_configuration(\n",
            "    physical_gpus[0],\n",
            "\n",
            "--- Chunk 15521 ---\n",
            "[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048),\n",
            "\n",
            "--- Chunk 15522 ---\n",
            "tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])\n",
            "\n",
            "--- Chunk 15523 ---\n",
            "These two virtual devices will then be called /gpu:0 and /gpu:1, and you can place\n",
            "\n",
            "--- Chunk 15524 ---\n",
            "operations and variables on each of them as if they were really two independent\n",
            "\n",
            "--- Chunk 15525 ---\n",
            "GPUs. Now let’s see how TensorFlow decides which devices it should place variables\n",
            "and execute operations on.\n",
            "\n",
            "--- Chunk 15526 ---\n",
            "Placing Operations and Variables on Devices\n",
            "The TensorFlow whitepaper13 presents a friendly dynamic placer algorithm that auto‐\n",
            "\n",
            "--- Chunk 15527 ---\n",
            "magically distributes operations across all available devices, taking into account\n",
            "\n",
            "--- Chunk 15528 ---\n",
            "things like the measured computation time in previous runs of the graph, estimations\n",
            "\n",
            "--- Chunk 15529 ---\n",
            "of the size of the input and output tensors for each operation, the amount of RAM\n",
            "\n",
            "--- Chunk 15530 ---\n",
            "available in each device, communication delay when transferring data into and out of\n",
            "\n",
            "--- Chunk 15531 ---\n",
            "devices, and hints and constraints from the user. In practice this algorithm turned out\n",
            "\n",
            "--- Chunk 15532 ---\n",
            "to be less efficient than a small set of placement rules specified by the user, so the Ten‐\n",
            "sorFlow team ended up dropping the dynamic placer.\n",
            "\n",
            "--- Chunk 15533 ---\n",
            "That said, tf.keras and tf.data generally do a good job of placing operations and vari‐\n",
            "\n",
            "--- Chunk 15534 ---\n",
            "ables where they belong (e.g., heavy computations on the GPU, and data preprocess‐\n",
            "\n",
            "--- Chunk 15535 ---\n",
            "ing on the CPU). But you can also place operations and variables manually on each\n",
            "device, if you want more control:\n",
            "\n",
            "--- Chunk 15536 ---\n",
            "• As just mentioned, you generally want to place the data preprocessing operations\n",
            "on the CPU, and place the neural network operations on the GPUs.\n",
            "\n",
            "--- Chunk 15537 ---\n",
            "• GPUs usually have a fairly limited communication bandwidth, so it is important\n",
            "to avoid unnecessary data transfers in and out of the GPUs.\n",
            "\n",
            "--- Chunk 15538 ---\n",
            "• Adding more CPU RAM to a machine is simple and fairly cheap, so there’s usu‐\n",
            "\n",
            "--- Chunk 15539 ---\n",
            "ally plenty of it, whereas the GPU RAM is baked into the GPU: it is an expensive\n",
            "\n",
            "--- Chunk 15540 ---\n",
            "and thus limited resource, so if a variable is not needed in the next few training\n",
            "\n",
            "--- Chunk 15541 ---\n",
            "steps, it should probably be placed on the CPU (e.g., datasets generally belong on\n",
            "the CPU).\n",
            "\n",
            "--- Chunk 15542 ---\n",
            "13 Martín Abadi et al., “TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems”\n",
            "Google Research whitepaper (2015).\n",
            "\n",
            "--- Chunk 15543 ---\n",
            "Using GPUs to Speed Up Computations | 697\n",
            "\n",
            "--- Chunk 15544 ---\n",
            "By default, all variables and all operations will be placed on the first GPU\n",
            "\n",
            "--- Chunk 15545 ---\n",
            "(named /gpu:0), except for variables and operations that don’t have a GPU kernel:14\n",
            "\n",
            "--- Chunk 15546 ---\n",
            "these are placed on the CPU (named /cpu:0). A tensor or variable’s device attribute\n",
            "tells you which device it was placed on:15\n",
            "\n",
            "--- Chunk 15547 ---\n",
            ">>> a = tf.Variable(42.0)\n",
            ">>> a.device\n",
            "'/job:localhost/replica:0/task:0/device:GPU:0'\n",
            ">>> b = tf.Variable(42)\n",
            ">>> b.device\n",
            "\n",
            "--- Chunk 15548 ---\n",
            ">>> b.device\n",
            "'/job:localhost/replica:0/task:0/device:CPU:0'\n",
            "\n",
            "--- Chunk 15549 ---\n",
            "You can safely ignore the prefix /job:localhost/replica:0/task:0 for now (it\n",
            "\n",
            "--- Chunk 15550 ---\n",
            "allows you to place operations on other machines when using a TensorFlow cluster;\n",
            "\n",
            "--- Chunk 15551 ---\n",
            "we will talk about jobs, replicas, and tasks later in this chapter). As you can see, the\n",
            "\n",
            "--- Chunk 15552 ---\n",
            "first variable was placed on GPU 0, which is the default device. However, the second\n",
            "\n",
            "--- Chunk 15553 ---\n",
            "variable was placed on the CPU: this is because there are no GPU kernels for integer\n",
            "\n",
            "--- Chunk 15554 ---\n",
            "variables (or for operations involving integer tensors), so TensorFlow fell back to the\n",
            "CPU.\n",
            "\n",
            "--- Chunk 15555 ---\n",
            "CPU.\n",
            "If you want to place an operation on a different device than the default one, use a\n",
            "tf.device() context:\n",
            "\n",
            "--- Chunk 15556 ---\n",
            ">>> with tf.device(\"/cpu:0\"):\n",
            "...     c = tf.Variable(42.0)\n",
            "...\n",
            ">>> c.device\n",
            "'/job:localhost/replica:0/task:0/device:CPU:0'\n",
            "\n",
            "--- Chunk 15557 ---\n",
            "The CPU is always treated as a single device (/cpu:0), even if your\n",
            "machine has multiple CPU cores. Any operation placed on the\n",
            "\n",
            "--- Chunk 15558 ---\n",
            "CPU may run in parallel across multiple cores if it has a multi‐\n",
            "threaded kernel.\n",
            "\n",
            "--- Chunk 15559 ---\n",
            "If you explicitly try to place an operation or variable on a device that does not exist or\n",
            "\n",
            "--- Chunk 15560 ---\n",
            "for which there is no kernel, then you will get an exception. However, in some cases\n",
            "\n",
            "--- Chunk 15561 ---\n",
            "you may prefer to fall back to the CPU; for example, if your program may run both\n",
            "\n",
            "--- Chunk 15562 ---\n",
            "on CPU-only machines and on GPU machines, you may want TensorFlow to ignore\n",
            "\n",
            "--- Chunk 15563 ---\n",
            "your tf.device(\"/gpu:*\") on CPU-only machines. To do this, you can call tf.con\n",
            "\n",
            "--- Chunk 15564 ---\n",
            "fig.set_soft_device_placement(True) just after importing TensorFlow: when a\n",
            "\n",
            "--- Chunk 15565 ---\n",
            "14 As we saw in Chapter 12, a kernel is a variable or operation’s implementation for a specific data type and\n",
            "\n",
            "--- Chunk 15566 ---\n",
            "device type. For example, there is a GPU kernel for the float32 tf.matmul() operation, but there is no GPU\n",
            "\n",
            "--- Chunk 15567 ---\n",
            "kernel for int32 tf.matmul() (only a CPU kernel).\n",
            "\n",
            "--- Chunk 15568 ---\n",
            "15 You can also use tf.debugging.set_log_device_placement(True) to log all device placements.\n",
            "\n",
            "--- Chunk 15569 ---\n",
            "698 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 15570 ---\n",
            "placement request fails, TensorFlow will fall back to its default placement rules (i.e.,\n",
            "\n",
            "--- Chunk 15571 ---\n",
            "GPU 0 by default if it exists and there is a GPU kernel, and CPU 0 otherwise).\n",
            "\n",
            "--- Chunk 15572 ---\n",
            "Now how exactly will TensorFlow execute all these operations across multiple\n",
            "devices?\n",
            "\n",
            "--- Chunk 15573 ---\n",
            "Parallel Execution Across Multiple Devices\n",
            "As we saw in Chapter 12, one of the benefits of using TF Functions is parallelism.\n",
            "\n",
            "--- Chunk 15574 ---\n",
            "Let’s look at this a bit more closely. When TensorFlow runs a TF Function, it starts by\n",
            "\n",
            "--- Chunk 15575 ---\n",
            "analyzing its graph to find the list of operations that need to be evaluated, and it\n",
            "\n",
            "--- Chunk 15576 ---\n",
            "counts how many dependencies each of them has. TensorFlow then adds each opera‐\n",
            "\n",
            "--- Chunk 15577 ---\n",
            "tion with zero dependencies (i.e., each source operation) to the evaluation queue of\n",
            "\n",
            "--- Chunk 15578 ---\n",
            "this operation’s device (see Figure 19-14). Once an operation has been evaluated, the\n",
            "\n",
            "--- Chunk 15579 ---\n",
            "dependency counter of each operation that depends on it is decremented. Once an\n",
            "\n",
            "--- Chunk 15580 ---\n",
            "operation’s dependency counter reaches zero, it is pushed to the evaluation queue of\n",
            "\n",
            "--- Chunk 15581 ---\n",
            "its device. And once all the nodes that TensorFlow needs have been evaluated, it\n",
            "returns their outputs.\n",
            "\n",
            "--- Chunk 15582 ---\n",
            "Figure 19-14. Parallelized execution of a TensorFlow graph\n",
            "\n",
            "--- Chunk 15583 ---\n",
            "Operations in the CPU’s evaluation queue are dispatched to a thread pool called the\n",
            "\n",
            "--- Chunk 15584 ---\n",
            "inter-op thread pool. If the CPU has multiple cores, then these operations will effec‐\n",
            "\n",
            "--- Chunk 15585 ---\n",
            "tively be evaluated in parallel. Some operations have multithreaded CPU kernels:\n",
            "\n",
            "--- Chunk 15586 ---\n",
            "these kernels split their tasks into multiple suboperations, which are placed in\n",
            "\n",
            "--- Chunk 15587 ---\n",
            "another evaluation queue and dispatched to a second thread pool called the intra-op\n",
            "\n",
            "--- Chunk 15588 ---\n",
            "Using GPUs to Speed Up Computations | 699\n",
            "\n",
            "--- Chunk 15589 ---\n",
            "thread pool (shared by all multithreaded CPU kernels). In short, multiple operations\n",
            "\n",
            "--- Chunk 15590 ---\n",
            "and suboperations may be evaluated in parallel on different CPU cores.\n",
            "\n",
            "--- Chunk 15591 ---\n",
            "For the GPU, things are a bit simpler. Operations in a GPU’s evaluation queue are\n",
            "\n",
            "--- Chunk 15592 ---\n",
            "evaluated sequentially. However, most operations have multithreaded GPU kernels,\n",
            "\n",
            "--- Chunk 15593 ---\n",
            "typically implemented by libraries that TensorFlow depends on, such as CUDA and\n",
            "\n",
            "--- Chunk 15594 ---\n",
            "cuDNN. These implementations have their own thread pools, and they typically\n",
            "\n",
            "--- Chunk 15595 ---\n",
            "exploit as many GPU threads as they can (which is the reason why there is no need\n",
            "\n",
            "--- Chunk 15596 ---\n",
            "for an inter-op thread pool in GPUs: each operation already floods most GPU\n",
            "threads).\n",
            "\n",
            "--- Chunk 15597 ---\n",
            "threads).\n",
            "For example, in Figure 19-14, operations A, B, and C are source ops, so they can\n",
            "\n",
            "--- Chunk 15598 ---\n",
            "immediately be evaluated. Operations A and B are placed on the CPU, so they are\n",
            "\n",
            "--- Chunk 15599 ---\n",
            "sent to the CPU’s evaluation queue, then they are dispatched to the inter-op thread\n",
            "\n",
            "--- Chunk 15600 ---\n",
            "pool and immediately evaluated in parallel. Operation A happens to have a multi‐\n",
            "\n",
            "--- Chunk 15601 ---\n",
            "threaded kernel; its computations are split into three parts, which are executed in par‐\n",
            "\n",
            "--- Chunk 15602 ---\n",
            "allel by the intra-op thread pool. Operation C goes to GPU 0’s evaluation queue, and\n",
            "\n",
            "--- Chunk 15603 ---\n",
            "in this example its GPU kernel happens to use cuDNN, which manages its own intra-\n",
            "\n",
            "--- Chunk 15604 ---\n",
            "op thread pool and runs the operation across many GPU threads in parallel. Suppose\n",
            "\n",
            "--- Chunk 15605 ---\n",
            "C finishes first. The dependency counters of D and E are decremented and they reach\n",
            "\n",
            "--- Chunk 15606 ---\n",
            "zero, so both operations are pushed to GPU 0’s evaluation queue, and they are exe‐\n",
            "\n",
            "--- Chunk 15607 ---\n",
            "cuted sequentially. Note that C only gets evaluated once, even though both D and E\n",
            "\n",
            "--- Chunk 15608 ---\n",
            "depend on it. Suppose B finishes next. Then F’s dependency counter is decremented\n",
            "\n",
            "--- Chunk 15609 ---\n",
            "from 4 to 3, and since that’s not 0, it does not run yet. Once A, D, and E are finished,\n",
            "\n",
            "--- Chunk 15610 ---\n",
            "then F’s dependency counter reaches 0, and it is pushed to the CPU’s evaluation\n",
            "\n",
            "--- Chunk 15611 ---\n",
            "queue and evaluated. Finally, TensorFlow returns the requested outputs.\n",
            "\n",
            "--- Chunk 15612 ---\n",
            "An extra bit of magic that TensorFlow performs is when the TF Function modifies a\n",
            "\n",
            "--- Chunk 15613 ---\n",
            "stateful resource, such as a variable: it ensures that the order of execution matches the\n",
            "\n",
            "--- Chunk 15614 ---\n",
            "order in the code, even if there is no explicit dependency between the statements. For\n",
            "\n",
            "--- Chunk 15615 ---\n",
            "example, if your TF Function contains v.assign_add(1) followed by v.assign(v *\n",
            "\n",
            "--- Chunk 15616 ---\n",
            "2), TensorFlow will ensure that these operations are executed in that order.\n",
            "\n",
            "--- Chunk 15617 ---\n",
            "You can control the number of threads in the inter-op thread\n",
            "pool by calling tf.config.threading.set_inter_op_parallel\n",
            "\n",
            "--- Chunk 15618 ---\n",
            "ism_threads(). To set the number of intra-op threads, use\n",
            "tf.config.threading.set_intra_op_parallelism_threads().\n",
            "\n",
            "--- Chunk 15619 ---\n",
            "This is useful if you want do not want TensorFlow to use all the\n",
            "CPU cores or if you want it to be single-threaded.16\n",
            "\n",
            "--- Chunk 15620 ---\n",
            "16 This can be useful if you want to guarantee perfect reproducibility, as I explain in this video, based on TF 1.\n",
            "\n",
            "--- Chunk 15621 ---\n",
            "700 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 15622 ---\n",
            "With that, you have all you need to run any operation on any device, and exploit the\n",
            "power of your GPUs! Here are some of the things you could do:\n",
            "\n",
            "--- Chunk 15623 ---\n",
            "• You could train several models in parallel, each on its own GPU: just write a\n",
            "training script for each model and run them in parallel, setting\n",
            "\n",
            "--- Chunk 15624 ---\n",
            "CUDA_DEVICE_ORDER and CUDA_VISIBLE_DEVICES so that each script only sees a\n",
            "\n",
            "--- Chunk 15625 ---\n",
            "single GPU device. This is great for hyperparameter tuning, as you can train in\n",
            "\n",
            "--- Chunk 15626 ---\n",
            "parallel multiple models with different hyperparameters. If you have a single\n",
            "\n",
            "--- Chunk 15627 ---\n",
            "machine with two GPUs, and it takes one hour to train one model on one GPU,\n",
            "\n",
            "--- Chunk 15628 ---\n",
            "then training two models in parallel, each on its own dedicated GPU, will take\n",
            "just one hour. Simple!\n",
            "\n",
            "--- Chunk 15629 ---\n",
            "• You could train a model on a single GPU and perform all the preprocessing in\n",
            "\n",
            "--- Chunk 15630 ---\n",
            "parallel on the CPU, using the dataset’s prefetch() method17 to prepare the next\n",
            "\n",
            "--- Chunk 15631 ---\n",
            "few batches in advance so that they are ready when the GPU needs them (see\n",
            "Chapter 13).\n",
            "\n",
            "--- Chunk 15632 ---\n",
            "• If your model takes two images as input and processes them using two CNNs\n",
            "\n",
            "--- Chunk 15633 ---\n",
            "before joining their outputs, then it will probably run much faster if you place\n",
            "each CNN on a different GPU.\n",
            "\n",
            "--- Chunk 15634 ---\n",
            "• You can create an efficient ensemble: just place a different trained model on each\n",
            "\n",
            "--- Chunk 15635 ---\n",
            "GPU so that you can get all the predictions much faster to produce the ensem‐\n",
            "ble’s final prediction.\n",
            "\n",
            "--- Chunk 15636 ---\n",
            "But what if you want to train a single model across multiple GPUs?\n",
            "\n",
            "--- Chunk 15637 ---\n",
            "Training Models Across Multiple Devices\n",
            "There are two main approaches to training a single model across multiple devices:\n",
            "\n",
            "--- Chunk 15638 ---\n",
            "model parallelism, where the model is split across the devices, and data parallelism,\n",
            "\n",
            "--- Chunk 15639 ---\n",
            "where the model is replicated across every device, and each replica is trained on a\n",
            "\n",
            "--- Chunk 15640 ---\n",
            "subset of the data. Let’s look at these two options closely before we train a model on\n",
            "multiple GPUs.\n",
            "\n",
            "--- Chunk 15641 ---\n",
            "Model Parallelism\n",
            "So far we have trained each neural network on a single device. What if we want to\n",
            "\n",
            "--- Chunk 15642 ---\n",
            "train a single neural network across multiple devices? This requires chopping the\n",
            "\n",
            "--- Chunk 15643 ---\n",
            "model into separate chunks and running each chunk on a different device.\n",
            "\n",
            "--- Chunk 15644 ---\n",
            "17 At the time of this writing it only prefetches the data to the CPU RAM, but you can use tf.data.experimen\n",
            "\n",
            "--- Chunk 15645 ---\n",
            "tal.prefetch_to_device() to make it prefetch the data and push it to the device of your choice so that the\n",
            "\n",
            "--- Chunk 15646 ---\n",
            "GPU does not waste time waiting for the data to be transferred.\n",
            "\n",
            "--- Chunk 15647 ---\n",
            "Training Models Across Multiple Devices | 701\n",
            "\n",
            "--- Chunk 15648 ---\n",
            "Unfortunately, such model parallelism turns out to be pretty tricky, and it really\n",
            "\n",
            "--- Chunk 15649 ---\n",
            "depends on the architecture of your neural network. For fully connected networks,\n",
            "\n",
            "--- Chunk 15650 ---\n",
            "there is generally not much to be gained from this approach (see Figure 19-15). Intui‐\n",
            "\n",
            "--- Chunk 15651 ---\n",
            "tively, it may seem that an easy way to split the model is to place each layer on a dif‐\n",
            "\n",
            "--- Chunk 15652 ---\n",
            "ferent device, but this does not work because each layer needs to wait for the output\n",
            "\n",
            "--- Chunk 15653 ---\n",
            "of the previous layer before it can do anything. So perhaps you can slice it vertically—\n",
            "\n",
            "--- Chunk 15654 ---\n",
            "for example, with the left half of each layer on one device, and the right part on\n",
            "\n",
            "--- Chunk 15655 ---\n",
            "another device? This is slightly better, since both halves of each layer can indeed work\n",
            "\n",
            "--- Chunk 15656 ---\n",
            "in parallel, but the problem is that each half of the next layer requires the output of\n",
            "\n",
            "--- Chunk 15657 ---\n",
            "both halves, so there will be a lot of cross-device communication (represented by the\n",
            "\n",
            "--- Chunk 15658 ---\n",
            "dashed arrows). This is likely to completely cancel out the benefit of the parallel com‐\n",
            "\n",
            "--- Chunk 15659 ---\n",
            "putation, since cross-device communication is slow (especially when the devices are\n",
            "located on different machines).\n",
            "\n",
            "--- Chunk 15660 ---\n",
            "Figure 19-15. Splitting a fully connected neural network\n",
            "\n",
            "--- Chunk 15661 ---\n",
            "Some neural network architectures, such as convolutional neural networks (see\n",
            "\n",
            "--- Chunk 15662 ---\n",
            "Chapter 14), contain layers that are only partially connected to the lower layers, so it\n",
            "\n",
            "--- Chunk 15663 ---\n",
            "is much easier to distribute chunks across devices in an efficient way (Figure 19-16).\n",
            "\n",
            "--- Chunk 15664 ---\n",
            "702 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "\n",
            "\n",
            "Figure 19-16. Splitting a partially connected neural network\n",
            "\n",
            "--- Chunk 15665 ---\n",
            "Deep recurrent neural networks (see Chapter 15) can be split a bit more efficiently\n",
            "\n",
            "--- Chunk 15666 ---\n",
            "across multiple GPUs. If you split the network horizontally by placing each layer on a\n",
            "\n",
            "--- Chunk 15667 ---\n",
            "different device, and you feed the network with an input sequence to process, then at\n",
            "\n",
            "--- Chunk 15668 ---\n",
            "the first time step only one device will be active (working on the sequence’s first\n",
            "\n",
            "--- Chunk 15669 ---\n",
            "value), at the second step two will be active (the second layer will be handling the out‐\n",
            "\n",
            "--- Chunk 15670 ---\n",
            "put of the first layer for the first value, while the first layer will be handling the second\n",
            "\n",
            "--- Chunk 15671 ---\n",
            "value), and by the time the signal propagates to the output layer, all devices will be\n",
            "\n",
            "--- Chunk 15672 ---\n",
            "active simultaneously (Figure 19-17). There is still a lot of cross-device communica‐\n",
            "\n",
            "--- Chunk 15673 ---\n",
            "tion going on, but since each cell may be fairly complex, the benefit of running multi‐\n",
            "\n",
            "--- Chunk 15674 ---\n",
            "ple cells in parallel may (in theory) outweigh the communication penalty. However,\n",
            "\n",
            "--- Chunk 15675 ---\n",
            "in practice a regular stack of LSTM layers running on a single GPU actually runs much\n",
            "faster.\n",
            "\n",
            "--- Chunk 15676 ---\n",
            "Training Models Across Multiple Devices | 703\n",
            "\n",
            "\n",
            "\n",
            "Figure 19-17. Splitting a deep recurrent neural network\n",
            "\n",
            "--- Chunk 15677 ---\n",
            "In short, model parallelism may speed up running or training some types of neural\n",
            "\n",
            "--- Chunk 15678 ---\n",
            "networks, but not all, and it requires special care and tuning, such as making sure\n",
            "\n",
            "--- Chunk 15679 ---\n",
            "that devices that need to communicate the most run on the same machine.18 Let’s look\n",
            "\n",
            "--- Chunk 15680 ---\n",
            "at a much simpler and generally more efficient option: data parallelism.\n",
            "\n",
            "--- Chunk 15681 ---\n",
            "Data Parallelism\n",
            "Another way to parallelize the training of a neural network is to replicate it on every\n",
            "\n",
            "--- Chunk 15682 ---\n",
            "device and run each training step simultaneously on all replicas, using a different\n",
            "\n",
            "--- Chunk 15683 ---\n",
            "mini-batch for each. The gradients computed by each replica are then averaged, and\n",
            "\n",
            "--- Chunk 15684 ---\n",
            "the result is used to update the model parameters. This is called data parallelism.\n",
            "\n",
            "--- Chunk 15685 ---\n",
            "There are many variants of this idea, so let’s look at the most important ones.\n",
            "\n",
            "--- Chunk 15686 ---\n",
            "Data parallelism using the mirrored strategy\n",
            "Arguably the simplest approach is to completely mirror all the model parameters\n",
            "\n",
            "--- Chunk 15687 ---\n",
            "across all the GPUs and always apply the exact same parameter updates on every\n",
            "\n",
            "--- Chunk 15688 ---\n",
            "GPU. This way, all replicas always remain perfectly identical. This is called the mir‐\n",
            "\n",
            "--- Chunk 15689 ---\n",
            "rored strategy, and it turns out to be quite efficient, especially when using a single\n",
            "machine (see Figure 19-18).\n",
            "\n",
            "--- Chunk 15690 ---\n",
            "18 If you are interested in going further with model parallelism, check out Mesh TensorFlow.\n",
            "\n",
            "--- Chunk 15691 ---\n",
            "704 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "\n",
            "\n",
            "Figure 19-18. Data parallelism using the mirrored strategy\n",
            "\n",
            "--- Chunk 15692 ---\n",
            "The tricky part when using this approach is to efficiently compute the mean of all the\n",
            "\n",
            "--- Chunk 15693 ---\n",
            "gradients from all the GPUs and distribute the result across all the GPUs. This can be\n",
            "\n",
            "--- Chunk 15694 ---\n",
            "done using an AllReduce algorithm, a class of algorithms where multiple nodes col‐\n",
            "\n",
            "--- Chunk 15695 ---\n",
            "laborate to efficiently perform a reduce operation (such as computing the mean, sum,\n",
            "\n",
            "--- Chunk 15696 ---\n",
            "and max), while ensuring that all nodes obtain the same final result. Fortunately,\n",
            "\n",
            "--- Chunk 15697 ---\n",
            "there are off-the-shelf implementations of such algorithms, as we will see.\n",
            "\n",
            "--- Chunk 15698 ---\n",
            "Data parallelism with centralized parameters\n",
            "Another approach is to store the model parameters outside of the GPU devices per‐\n",
            "\n",
            "--- Chunk 15699 ---\n",
            "forming the computations (called workers), for example on the CPU (see\n",
            "\n",
            "--- Chunk 15700 ---\n",
            "Figure 19-19). In a distributed setup, you may place all the parameters on one or\n",
            "\n",
            "--- Chunk 15701 ---\n",
            "more CPU-only servers called parameter servers, whose only role is to host and\n",
            "update the parameters.\n",
            "\n",
            "--- Chunk 15702 ---\n",
            "Training Models Across Multiple Devices | 705\n",
            "\n",
            "\n",
            "\n",
            "Figure 19-19. Data parallelism with centralized parameters\n",
            "\n",
            "--- Chunk 15703 ---\n",
            "Whereas the mirrored strategy imposes synchronous weight updates across all GPUs,\n",
            "\n",
            "--- Chunk 15704 ---\n",
            "this centralized approach allows either synchronous or asynchronous updates. Let’s\n",
            "see the pros and cons of both options.\n",
            "\n",
            "--- Chunk 15705 ---\n",
            "Synchronous updates.    With synchronous updates, the aggregator waits until all gradi‐\n",
            "\n",
            "--- Chunk 15706 ---\n",
            "ents are available before it computes the average gradients and passes them to the\n",
            "\n",
            "--- Chunk 15707 ---\n",
            "optimizer, which will update the model parameters. Once a replica has finished com‐\n",
            "\n",
            "--- Chunk 15708 ---\n",
            "puting its gradients, it must wait for the parameters to be updated before it can pro‐\n",
            "\n",
            "--- Chunk 15709 ---\n",
            "ceed to the next mini-batch. The downside is that some devices may be slower than\n",
            "\n",
            "--- Chunk 15710 ---\n",
            "others, so all other devices will have to wait for them at every step. Moreover, the\n",
            "\n",
            "--- Chunk 15711 ---\n",
            "parameters will be copied to every device almost at the same time (immediately after\n",
            "\n",
            "--- Chunk 15712 ---\n",
            "the gradients are applied), which may saturate the parameter servers’ bandwidth.\n",
            "\n",
            "--- Chunk 15713 ---\n",
            "To reduce the waiting time at each step, you could ignore the gradi‐\n",
            "ents from the slowest few replicas (typically ~10%). For example,\n",
            "\n",
            "--- Chunk 15714 ---\n",
            "you could run 20 replicas, but only aggregate the gradients from\n",
            "the fastest 18 replicas at each step, and just ignore the gradients\n",
            "\n",
            "--- Chunk 15715 ---\n",
            "from the last 2. As soon as the parameters are updated, the first 18\n",
            "replicas can start working again immediately, without having to\n",
            "\n",
            "--- Chunk 15716 ---\n",
            "wait for the 2 slowest replicas. This setup is generally described as\n",
            "having 18 replicas plus 2 spare replicas.19\n",
            "\n",
            "--- Chunk 15717 ---\n",
            "19 This name is slightly confusing because it sounds like some replicas are special, doing nothing. In reality, all\n",
            "\n",
            "--- Chunk 15718 ---\n",
            "replicas are equivalent: they all work hard to be among the fastest at each training step, and the losers vary at\n",
            "\n",
            "--- Chunk 15719 ---\n",
            "every step (unless some devices are really slower than others). However, it does mean that if a server crashes,\n",
            "training will continue just fine.\n",
            "\n",
            "--- Chunk 15720 ---\n",
            "706 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 15721 ---\n",
            "Asynchronous updates.    With asynchronous updates, whenever a replica has finished\n",
            "\n",
            "--- Chunk 15722 ---\n",
            "computing the gradients, it immediately uses them to update the model parameters.\n",
            "\n",
            "--- Chunk 15723 ---\n",
            "There is no aggregation (it removes the “mean” step in Figure 19-19) and no synchro‐\n",
            "\n",
            "--- Chunk 15724 ---\n",
            "nization. Replicas work independently of the other replicas. Since there is no waiting\n",
            "\n",
            "--- Chunk 15725 ---\n",
            "for the other replicas, this approach runs more training steps per minute. Moreover,\n",
            "\n",
            "--- Chunk 15726 ---\n",
            "although the parameters still need to be copied to every device at every step, this hap‐\n",
            "\n",
            "--- Chunk 15727 ---\n",
            "pens at different times for each replica, so the risk of bandwidth saturation is reduced.\n",
            "\n",
            "--- Chunk 15728 ---\n",
            "Data parallelism with asynchronous updates is an attractive choice because of its sim‐\n",
            "\n",
            "--- Chunk 15729 ---\n",
            "plicity, the absence of synchronization delay, and a better use of the bandwidth. How‐\n",
            "\n",
            "--- Chunk 15730 ---\n",
            "ever, although it works reasonably well in practice, it is almost surprising that it\n",
            "\n",
            "--- Chunk 15731 ---\n",
            "works at all! Indeed, by the time a replica has finished computing the gradients based\n",
            "\n",
            "--- Chunk 15732 ---\n",
            "on some parameter values, these parameters will have been updated several times by\n",
            "\n",
            "--- Chunk 15733 ---\n",
            "other replicas (on average N – 1 times, if there are N replicas), and there is no guaran‐\n",
            "\n",
            "--- Chunk 15734 ---\n",
            "tee that the computed gradients will still be pointing in the right direction (see\n",
            "\n",
            "--- Chunk 15735 ---\n",
            "Figure 19-20). When gradients are severely out-of-date, they are called stale gradients:\n",
            "\n",
            "--- Chunk 15736 ---\n",
            "they can slow down convergence, introducing noise and wobble effects (the learning\n",
            "\n",
            "--- Chunk 15737 ---\n",
            "curve may contain temporary oscillations), or they can even make the training algo‐\n",
            "rithm diverge.\n",
            "\n",
            "--- Chunk 15738 ---\n",
            "Figure 19-20. Stale gradients when using asynchronous updates\n",
            "\n",
            "There are a few ways you can reduce the effect of stale gradients:\n",
            "\n",
            "--- Chunk 15739 ---\n",
            "• Reduce the learning rate.\n",
            "• Drop stale gradients or scale them down.\n",
            "• Adjust the mini-batch size.\n",
            "\n",
            "Training Models Across Multiple Devices | 707\n",
            "\n",
            "--- Chunk 15740 ---\n",
            "• Start the first few epochs using just one replica (this is called the warmup phase).\n",
            "\n",
            "--- Chunk 15741 ---\n",
            "Stale gradients tend to be more damaging at the beginning of training, when gra‐\n",
            "\n",
            "--- Chunk 15742 ---\n",
            "dients are typically large and the parameters have not settled into a valley of the\n",
            "\n",
            "--- Chunk 15743 ---\n",
            "cost function yet, so different replicas may push the parameters in quite different\n",
            "directions.\n",
            "\n",
            "--- Chunk 15744 ---\n",
            "A paper published by the Google Brain team in 201620 benchmarked various\n",
            "\n",
            "--- Chunk 15745 ---\n",
            "approaches and found that using synchronous updates with a few spare replicas was\n",
            "\n",
            "--- Chunk 15746 ---\n",
            "more efficient than using asynchronous updates, not only converging faster but also\n",
            "\n",
            "--- Chunk 15747 ---\n",
            "producing a better model. However, this is still an active area of research, so you\n",
            "should not rule out asynchronous updates just yet.\n",
            "\n",
            "--- Chunk 15748 ---\n",
            "Bandwidth saturation\n",
            "Whether you use synchronous or asynchronous updates, data parallelism with cen‐\n",
            "\n",
            "--- Chunk 15749 ---\n",
            "tralized parameters still requires communicating the model parameters from the\n",
            "\n",
            "--- Chunk 15750 ---\n",
            "parameter servers to every replica at the beginning of each training step, and the gra‐\n",
            "\n",
            "--- Chunk 15751 ---\n",
            "dients in the other direction at the end of each training step. Similarly, when using the\n",
            "\n",
            "--- Chunk 15752 ---\n",
            "mirrored strategy, the gradients produced by each GPU will need to be shared with\n",
            "\n",
            "--- Chunk 15753 ---\n",
            "every other GPU. Unfortunately, there always comes a point where adding an extra\n",
            "\n",
            "--- Chunk 15754 ---\n",
            "GPU will not improve performance at all because the time spent moving the data into\n",
            "\n",
            "--- Chunk 15755 ---\n",
            "and out of GPU RAM (and across the network in a distributed setup) will outweigh\n",
            "\n",
            "--- Chunk 15756 ---\n",
            "the speedup obtained by splitting the computation load. At that point, adding more\n",
            "\n",
            "--- Chunk 15757 ---\n",
            "GPUs will just worsen the bandwidth saturation and actually slow down training.\n",
            "\n",
            "--- Chunk 15758 ---\n",
            "For some models, typically relatively small and trained on a very\n",
            "large training set, you are often better off training the model on a\n",
            "\n",
            "--- Chunk 15759 ---\n",
            "single machine with a single powerful GPU with a large memory\n",
            "bandwidth.\n",
            "\n",
            "--- Chunk 15760 ---\n",
            "Saturation is more severe for large dense models, since they have a lot of parameters\n",
            "\n",
            "--- Chunk 15761 ---\n",
            "and gradients to transfer. It is less severe for small models (but the parallelization gain\n",
            "\n",
            "--- Chunk 15762 ---\n",
            "is limited) and for large sparse models, where the gradients are typically mostly zeros\n",
            "\n",
            "--- Chunk 15763 ---\n",
            "and so can be communicated efficiently. Jeff Dean, initiator and lead of the Google\n",
            "\n",
            "--- Chunk 15764 ---\n",
            "Brain project, reported typical speedups of 25–40× when distributing computations\n",
            "\n",
            "--- Chunk 15765 ---\n",
            "across 50 GPUs for dense models, and a 300× speedup for sparser models trained\n",
            "\n",
            "--- Chunk 15766 ---\n",
            "across 500 GPUs. As you can see, sparse models really do scale better. Here are a few\n",
            "concrete examples:\n",
            "\n",
            "--- Chunk 15767 ---\n",
            "20 Jianmin Chen et al., “Revisiting Distributed Synchronous SGD,” arXiv preprint arXiv:1604.00981 (2016).\n",
            "\n",
            "--- Chunk 15768 ---\n",
            "708 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 15769 ---\n",
            "• Neural machine translation: 6× speedup on 8 GPUs\n",
            "• Inception/ImageNet: 32× speedup on 50 GPUs\n",
            "• RankBrain: 300× speedup on 500 GPUs\n",
            "\n",
            "--- Chunk 15770 ---\n",
            "Beyond a few dozen GPUs for a dense model or few hundred GPUs for a sparse\n",
            "\n",
            "--- Chunk 15771 ---\n",
            "model, saturation kicks in and performance degrades. There is plenty of research\n",
            "\n",
            "--- Chunk 15772 ---\n",
            "going on to solve this problem (exploring peer-to-peer architectures rather than cen‐\n",
            "\n",
            "--- Chunk 15773 ---\n",
            "tralized parameter servers, using lossy model compression, optimizing when and\n",
            "\n",
            "--- Chunk 15774 ---\n",
            "what the replicas need to communicate, and so on), so there will likely be a lot of pro‐\n",
            "\n",
            "--- Chunk 15775 ---\n",
            "gress in parallelizing neural networks in the next few years.\n",
            "In the meantime, to reduce the saturation problem, you probably want to use a few\n",
            "\n",
            "--- Chunk 15776 ---\n",
            "powerful GPUs rather than plenty of weak GPUs, and you should also group your\n",
            "\n",
            "--- Chunk 15777 ---\n",
            "GPUs on few and very well interconnected servers. You can also try dropping the\n",
            "\n",
            "--- Chunk 15778 ---\n",
            "float precision from 32 bits (tf.float32) to 16 bits (tf.bfloat16). This will cut in\n",
            "\n",
            "--- Chunk 15779 ---\n",
            "half the amount of data to transfer, often without much impact on the convergence\n",
            "\n",
            "--- Chunk 15780 ---\n",
            "rate or the model’s performance. Lastly, if you are using centralized parameters, you\n",
            "\n",
            "--- Chunk 15781 ---\n",
            "can shard (split) the parameters across multiple parameter servers: adding more\n",
            "\n",
            "--- Chunk 15782 ---\n",
            "parameter servers will reduce the network load on each server and limit the risk of\n",
            "bandwidth saturation.\n",
            "\n",
            "--- Chunk 15783 ---\n",
            "OK, now let’s train a model across multiple GPUs!\n",
            "\n",
            "--- Chunk 15784 ---\n",
            "Training at Scale Using the Distribution Strategies API\n",
            "Many models can be trained quite well on a single GPU, or even on a CPU. But if\n",
            "\n",
            "--- Chunk 15785 ---\n",
            "training is too slow, you can try distributing it across multiple GPUs on the same\n",
            "\n",
            "--- Chunk 15786 ---\n",
            "machine. If that’s still too slow, try using more powerful GPUs, or add more GPUs to\n",
            "\n",
            "--- Chunk 15787 ---\n",
            "the machine. If your model performs heavy computations (such as large matrix mul‐\n",
            "\n",
            "--- Chunk 15788 ---\n",
            "tiplications), then it will run much faster on powerful GPUs, and you could even try\n",
            "\n",
            "--- Chunk 15789 ---\n",
            "to use TPUs on Google Cloud AI Platform, which will usually run even faster for such\n",
            "\n",
            "--- Chunk 15790 ---\n",
            "models. But if you can’t fit any more GPUs on the same machine, and if TPUs aren’t\n",
            "\n",
            "--- Chunk 15791 ---\n",
            "for you (e.g., perhaps your model doesn’t benefit much from TPUs, or perhaps you\n",
            "\n",
            "--- Chunk 15792 ---\n",
            "want to use your own hardware infrastructure), then you can try training it across\n",
            "\n",
            "--- Chunk 15793 ---\n",
            "several servers, each with multiple GPUs (if this is still not enough, as a last resort you\n",
            "\n",
            "--- Chunk 15794 ---\n",
            "can try adding some model parallelism, but this requires a lot more effort). In this\n",
            "\n",
            "--- Chunk 15795 ---\n",
            "section we will see how to train models at scale, starting with multiple GPUs on the\n",
            "\n",
            "--- Chunk 15796 ---\n",
            "same machine (or TPUs) and then moving on to multiple GPUs across multiple\n",
            "machines.\n",
            "\n",
            "--- Chunk 15797 ---\n",
            "machines.\n",
            "Luckily, TensorFlow comes with a very simple API that takes care of all the complex‐\n",
            "\n",
            "--- Chunk 15798 ---\n",
            "ity for you: the Distribution Strategies API. To train a Keras model across all available\n",
            "\n",
            "--- Chunk 15799 ---\n",
            "GPUs (on a single machine, for now) using data parallelism with the mirrored\n",
            "\n",
            "--- Chunk 15800 ---\n",
            "Training Models Across Multiple Devices | 709\n",
            "\n",
            "--- Chunk 15801 ---\n",
            "strategy, create a MirroredStrategy object, call its scope() method to get a distribu‐\n",
            "\n",
            "--- Chunk 15802 ---\n",
            "tion context, and wrap the creation and compilation of your model inside that con‐\n",
            "text. Then call the model’s fit() method normally:\n",
            "\n",
            "--- Chunk 15803 ---\n",
            "distribution = tf.distribute.MirroredStrategy()\n",
            "\n",
            "--- Chunk 15804 ---\n",
            "with distribution.scope():\n",
            "    mirrored_model = keras.models.Sequential([...])\n",
            "    mirrored_model.compile([...])\n",
            "\n",
            "--- Chunk 15805 ---\n",
            "batch_size = 100 # must be divisible by the number of replicas\n",
            "history = mirrored_model.fit(X_train, y_train, epochs=10)\n",
            "\n",
            "--- Chunk 15806 ---\n",
            "Under the hood, tf.keras is distribution-aware, so in this MirroredStrategy context it\n",
            "\n",
            "--- Chunk 15807 ---\n",
            "knows that it must replicate all variables and operations across all available GPU\n",
            "\n",
            "--- Chunk 15808 ---\n",
            "devices. Note that the fit() method will automatically split each training batch\n",
            "\n",
            "--- Chunk 15809 ---\n",
            "across all the replicas, so it’s important that the batch size be divisible by the number\n",
            "\n",
            "--- Chunk 15810 ---\n",
            "of replicas. And that’s all! Training will generally be significantly faster than using a\n",
            "single device, and the code change was really minimal.\n",
            "\n",
            "--- Chunk 15811 ---\n",
            "Once you have finished training your model, you can use it to make predictions effi‐\n",
            "\n",
            "--- Chunk 15812 ---\n",
            "ciently: call the predict() method, and it will automatically split the batch across all\n",
            "\n",
            "--- Chunk 15813 ---\n",
            "replicas, making predictions in parallel (again, the batch size must be divisible by the\n",
            "\n",
            "--- Chunk 15814 ---\n",
            "number of replicas). If you call the model’s save() method, it will be saved as a regu‐\n",
            "\n",
            "--- Chunk 15815 ---\n",
            "lar model, not as a mirrored model with multiple replicas. So when you load it, it will\n",
            "\n",
            "--- Chunk 15816 ---\n",
            "run like a regular model, on a single device (by default GPU 0, or the CPU if there are\n",
            "\n",
            "--- Chunk 15817 ---\n",
            "no GPUs). If you want to load a model and run it on all available devices, you must\n",
            "call keras.models.load_model() within a distribution context:\n",
            "\n",
            "--- Chunk 15818 ---\n",
            "with distribution.scope():\n",
            "    mirrored_model = keras.models.load_model(\"my_mnist_model.h5\")\n",
            "\n",
            "--- Chunk 15819 ---\n",
            "If you only want to use a subset of all the available GPU devices, you can pass the list\n",
            "to the MirroredStrategy’s constructor:\n",
            "\n",
            "--- Chunk 15820 ---\n",
            "distribution = tf.distribute.MirroredStrategy([\"/gpu:0\", \"/gpu:1\"])\n",
            "\n",
            "--- Chunk 15821 ---\n",
            "By default, the MirroredStrategy class uses the NVIDIA Collective Communications\n",
            "\n",
            "--- Chunk 15822 ---\n",
            "Library (NCCL) for the AllReduce mean operation, but you can change it by setting\n",
            "\n",
            "--- Chunk 15823 ---\n",
            "the cross_device_ops argument to an instance of the tf.distribute.Hierarchical\n",
            "\n",
            "--- Chunk 15824 ---\n",
            "CopyAllReduce class, or an instance of the tf.distribute.ReductionToOneDevice\n",
            "\n",
            "--- Chunk 15825 ---\n",
            "class. The default NCCL option is based on the tf.distribute.NcclAllReduce class,\n",
            "\n",
            "--- Chunk 15826 ---\n",
            "which is usually faster, but this depends on the number and types of GPUs, so you\n",
            "may want to give the alternatives a try.21\n",
            "\n",
            "--- Chunk 15827 ---\n",
            "21 For more details on AllReduce algorithms, read this great post by Yuichiro Ueno, and this page on scaling\n",
            "with NCCL.\n",
            "\n",
            "--- Chunk 15828 ---\n",
            "710 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 15829 ---\n",
            "If you want to try using data parallelism with centralized parameters, replace the\n",
            "MirroredStrategy with the CentralStorageStrategy:\n",
            "\n",
            "--- Chunk 15830 ---\n",
            "distribution = tf.distribute.experimental.CentralStorageStrategy()\n",
            "\n",
            "--- Chunk 15831 ---\n",
            "You can optionally set the compute_devices argument to specify the list of devices\n",
            "\n",
            "--- Chunk 15832 ---\n",
            "you want to use as workers (by default it will use all available GPUs), and you can\n",
            "\n",
            "--- Chunk 15833 ---\n",
            "optionally set the parameter_device argument to specify the device you want to store\n",
            "\n",
            "--- Chunk 15834 ---\n",
            "the parameters on (by default it will use the CPU, or the GPU if there is just one).\n",
            "\n",
            "--- Chunk 15835 ---\n",
            "Now let’s see how to train a model across a cluster of TensorFlow servers!\n",
            "\n",
            "--- Chunk 15836 ---\n",
            "Training a Model on a TensorFlow Cluster\n",
            "A TensorFlow cluster is a group of TensorFlow processes running in parallel, usually\n",
            "\n",
            "--- Chunk 15837 ---\n",
            "on different machines, and talking to each other to complete some work—for exam‐\n",
            "\n",
            "--- Chunk 15838 ---\n",
            "ple, training or executing a neural network. Each TF process in the cluster is called a\n",
            "\n",
            "--- Chunk 15839 ---\n",
            "task, or a TF server. It has an IP address, a port, and a type (also called its role or its\n",
            "\n",
            "--- Chunk 15840 ---\n",
            "job). The type can be either \"worker\", \"chief\", \"ps\" (parameter server), or\n",
            "\"evaluator\":\n",
            "\n",
            "--- Chunk 15841 ---\n",
            "• Each worker performs computations, usually on a machine with one or more\n",
            "GPUs.\n",
            "\n",
            "--- Chunk 15842 ---\n",
            "• The chief performs computations as well (it is a worker), but it also handles extra\n",
            "\n",
            "--- Chunk 15843 ---\n",
            "work such as writing TensorBoard logs or saving checkpoints. There is a single\n",
            "\n",
            "--- Chunk 15844 ---\n",
            "chief in a cluster. If no chief is specified, then the first worker is the chief.\n",
            "\n",
            "--- Chunk 15845 ---\n",
            "• A parameter server only keeps track of variable values, and it is usually on a CPU-\n",
            "\n",
            "--- Chunk 15846 ---\n",
            "only machine. This type of task is only used with the ParameterServerStrategy.\n",
            "\n",
            "--- Chunk 15847 ---\n",
            "• An evaluator obviously takes care of evaluation.\n",
            "\n",
            "--- Chunk 15848 ---\n",
            "To start a TensorFlow cluster, you must first specify it. This means defining each\n",
            "\n",
            "--- Chunk 15849 ---\n",
            "task’s IP address, TCP port, and type. For example, the following cluster specification\n",
            "\n",
            "--- Chunk 15850 ---\n",
            "defines a cluster with three tasks (two workers and one parameter server; see\n",
            "\n",
            "--- Chunk 15851 ---\n",
            "Figure 19-21). The cluster spec is a dictionary with one key per job, and the values are\n",
            "lists of task addresses (IP:port):\n",
            "\n",
            "--- Chunk 15852 ---\n",
            "cluster_spec = {\n",
            "    \"worker\": [\n",
            "        \"machine-a.example.com:2222\",  # /job:worker/task:0\n",
            "\n",
            "--- Chunk 15853 ---\n",
            "\"machine-b.example.com:2222\"   # /job:worker/task:1\n",
            "    ],\n",
            "    \"ps\": [\"machine-a.example.com:2221\"] # /job:ps/task:0\n",
            "}\n",
            "\n",
            "--- Chunk 15854 ---\n",
            "Training Models Across Multiple Devices | 711\n",
            "\n",
            "\n",
            "\n",
            "Figure 19-21. TensorFlow cluster\n",
            "\n",
            "--- Chunk 15855 ---\n",
            "In general there will be a single task per machine, but as this example shows, you can\n",
            "\n",
            "--- Chunk 15856 ---\n",
            "configure multiple tasks on the same machine if you want (if they share the same\n",
            "\n",
            "--- Chunk 15857 ---\n",
            "GPUs, make sure the RAM is split appropriately, as discussed earlier).\n",
            "\n",
            "--- Chunk 15858 ---\n",
            "By default, every task in the cluster may communicate with every\n",
            "other task, so make sure to configure your firewall to authorize all\n",
            "\n",
            "--- Chunk 15859 ---\n",
            "communications between these machines on these ports (it’s usu‐\n",
            "ally simpler if you use the same port on every machine).\n",
            "\n",
            "--- Chunk 15860 ---\n",
            "When you start a task, you must give it the cluster spec, and you must also tell it what\n",
            "\n",
            "--- Chunk 15861 ---\n",
            "its type and index are (e.g., worker 0). The simplest way to specify everything at once\n",
            "\n",
            "--- Chunk 15862 ---\n",
            "(both the cluster spec and the current task’s type and index) is to set the TF_CONFIG\n",
            "\n",
            "--- Chunk 15863 ---\n",
            "environment variable before starting TensorFlow. It must be a JSON-encoded dictio‐\n",
            "\n",
            "--- Chunk 15864 ---\n",
            "nary containing a cluster specification (under the \"cluster\" key) and the type and\n",
            "\n",
            "--- Chunk 15865 ---\n",
            "index of the current task (under the \"task\" key). For example, the following TF_CON\n",
            "\n",
            "--- Chunk 15866 ---\n",
            "FIG environment variable uses the cluster we just defined and specifies that the task\n",
            "to start is the first worker:\n",
            "\n",
            "--- Chunk 15867 ---\n",
            "import os\n",
            "import json\n",
            "\n",
            "os.environ[\"TF_CONFIG\"] = json.dumps({\n",
            "    \"cluster\": cluster_spec,\n",
            "    \"task\": {\"type\": \"worker\", \"index\": 0}\n",
            "})\n",
            "\n",
            "--- Chunk 15868 ---\n",
            "712 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 15869 ---\n",
            "In general you want to define the TF_CONFIG environment variable\n",
            "outside of Python, so the code does not need to include the current\n",
            "\n",
            "--- Chunk 15870 ---\n",
            "task’s type and index (this makes it possible to use the same code\n",
            "across all workers).\n",
            "\n",
            "--- Chunk 15871 ---\n",
            "Now let’s train a model on a cluster! We will start with the mirrored strategy—it’s sur‐\n",
            "\n",
            "--- Chunk 15872 ---\n",
            "prisingly simple! First, you need to set the TF_CONFIG environment variable appropri‐\n",
            "\n",
            "--- Chunk 15873 ---\n",
            "ately for each task. There should be no parameter server (remove the “ps” key in the\n",
            "\n",
            "--- Chunk 15874 ---\n",
            "cluster spec), and in general you will want a single worker per machine. Make extra\n",
            "\n",
            "--- Chunk 15875 ---\n",
            "sure you set a different task index for each task. Finally, run the following training\n",
            "code on every worker:\n",
            "\n",
            "--- Chunk 15876 ---\n",
            "distribution = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
            "\n",
            "--- Chunk 15877 ---\n",
            "with distribution.scope():\n",
            "    mirrored_model = keras.models.Sequential([...])\n",
            "    mirrored_model.compile([...])\n",
            "\n",
            "--- Chunk 15878 ---\n",
            "batch_size = 100 # must be divisible by the number of replicas\n",
            "history = mirrored_model.fit(X_train, y_train, epochs=10)\n",
            "\n",
            "--- Chunk 15879 ---\n",
            "Yes, that’s exactly the same code we used earlier, except this time we are using the\n",
            "\n",
            "--- Chunk 15880 ---\n",
            "MultiWorkerMirroredStrategy (in future versions, the MirroredStrategy will prob‐\n",
            "\n",
            "--- Chunk 15881 ---\n",
            "ably handle both the single machine and multimachine cases). When you start this\n",
            "\n",
            "--- Chunk 15882 ---\n",
            "script on the first workers, they will remain blocked at the AllReduce step, but as soon\n",
            "\n",
            "--- Chunk 15883 ---\n",
            "as the last worker starts up training will begin, and you will see them all advancing at\n",
            "exactly the same rate (since they synchronize at each step).\n",
            "\n",
            "--- Chunk 15884 ---\n",
            "You can choose from two AllReduce implementations for this distribution strategy: a\n",
            "\n",
            "--- Chunk 15885 ---\n",
            "ring AllReduce algorithm based on gRPC for the network communications, and\n",
            "\n",
            "--- Chunk 15886 ---\n",
            "NCCL’s implementation. The best algorithm to use depends on the number of work‐\n",
            "\n",
            "--- Chunk 15887 ---\n",
            "ers, the number and types of GPUs, and the network. By default, TensorFlow will\n",
            "\n",
            "--- Chunk 15888 ---\n",
            "apply some heuristics to select the right algorithm for you, but if you want to force\n",
            "\n",
            "--- Chunk 15889 ---\n",
            "one algorithm, pass CollectiveCommunication.RING or CollectiveCommunica\n",
            "tion.NCCL (from tf.distribute.experimental) to the strategy’s constructor.\n",
            "\n",
            "--- Chunk 15890 ---\n",
            "If you prefer to implement asynchronous data parallelism with parameter servers,\n",
            "\n",
            "--- Chunk 15891 ---\n",
            "change the strategy to ParameterServerStrategy, add one or more parameter\n",
            "\n",
            "--- Chunk 15892 ---\n",
            "servers, and configure TF_CONFIG appropriately for each task. Note that although the\n",
            "\n",
            "--- Chunk 15893 ---\n",
            "workers will work asynchronously, the replicas on each worker will work\n",
            "synchronously.\n",
            "\n",
            "--- Chunk 15894 ---\n",
            "synchronously.\n",
            "Lastly, if you have access to TPUs on Google Cloud, you can create a TPUStrategy\n",
            "like this (then use it like the other strategies):\n",
            "\n",
            "--- Chunk 15895 ---\n",
            "Training Models Across Multiple Devices | 713\n",
            "\n",
            "--- Chunk 15896 ---\n",
            "resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
            "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
            "\n",
            "--- Chunk 15897 ---\n",
            "tpu_strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
            "\n",
            "--- Chunk 15898 ---\n",
            "If you are a researcher, you may be eligible to use TPUs for free; see\n",
            "https://tensorflow.org/tfrc for more details.\n",
            "\n",
            "--- Chunk 15899 ---\n",
            "You can now train models across multiple GPUs and multiple servers: give yourself a\n",
            "\n",
            "--- Chunk 15900 ---\n",
            "pat on the back! If you want to train a large model, you will need many GPUs, across\n",
            "\n",
            "--- Chunk 15901 ---\n",
            "many servers, which will require either buying a lot of hardware or managing a lot of\n",
            "\n",
            "--- Chunk 15902 ---\n",
            "cloud VMs. In many cases, it’s going to be less hassle and less expensive to use a cloud\n",
            "\n",
            "--- Chunk 15903 ---\n",
            "service that takes care of provisioning and managing all this infrastructure for you,\n",
            "just when you need it. Let’s see how to do that on GCP.\n",
            "\n",
            "--- Chunk 15904 ---\n",
            "Running Large Training Jobs on Google Cloud AI Platform\n",
            "If you decide to use Google AI Platform, you can deploy a training job with the same\n",
            "\n",
            "--- Chunk 15905 ---\n",
            "training code as you would run on your own TF cluster, and the platform will take\n",
            "\n",
            "--- Chunk 15906 ---\n",
            "care of provisioning and configuring as many GPU VMs as you desire (within your\n",
            "quotas).\n",
            "\n",
            "--- Chunk 15907 ---\n",
            "quotas).\n",
            "To start the job, you will need the gcloud command-line tool, which is part of the\n",
            "\n",
            "--- Chunk 15908 ---\n",
            "Google Cloud SDK. You can either install the SDK on your own machine, or just use\n",
            "\n",
            "--- Chunk 15909 ---\n",
            "the Google Cloud Shell on GCP. This is a terminal you can use directly in your web\n",
            "\n",
            "--- Chunk 15910 ---\n",
            "browser; it runs on a free Linux VM (Debian), with the SDK already installed and\n",
            "\n",
            "--- Chunk 15911 ---\n",
            "preconfigured for you. The Cloud Shell is available anywhere in GCP: just click the\n",
            "\n",
            "--- Chunk 15912 ---\n",
            "Activate Cloud Shell icon at the top right of the page (see Figure 19-22).\n",
            "\n",
            "--- Chunk 15913 ---\n",
            "Figure 19-22. Activating the Google Cloud Shell\n",
            "\n",
            "--- Chunk 15914 ---\n",
            "If you prefer to install the SDK on your machine, once you have installed it, you need\n",
            "\n",
            "--- Chunk 15915 ---\n",
            "to initialize it by running gcloud init: you will need to log in to GCP and grant\n",
            "\n",
            "--- Chunk 15916 ---\n",
            "access to your GCP resources, then select the GCP project you want to use (if you\n",
            "\n",
            "--- Chunk 15917 ---\n",
            "have more than one), as well as the region where you want the job to run. The gcloud\n",
            "\n",
            "--- Chunk 15918 ---\n",
            "command gives you access to every GCP feature, including the ones we used earlier.\n",
            "\n",
            "--- Chunk 15919 ---\n",
            "You don’t have to go through the web interface every time; you can write scripts that\n",
            "\n",
            "--- Chunk 15920 ---\n",
            "start or stop VMs for you, deploy models, or perform any other GCP action.\n",
            "\n",
            "--- Chunk 15921 ---\n",
            "714 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 15922 ---\n",
            "Before you can run the training job, you need to write the training code, exactly like\n",
            "\n",
            "--- Chunk 15923 ---\n",
            "you did earlier for a distributed setup (e.g., using the ParameterServerStrategy). AI\n",
            "\n",
            "--- Chunk 15924 ---\n",
            "Platform will take care of setting TF_CONFIG for you on each VM. Once that’s done,\n",
            "\n",
            "--- Chunk 15925 ---\n",
            "you can deploy it and run it on a TF cluster with a command line like this:\n",
            "\n",
            "--- Chunk 15926 ---\n",
            "$ gcloud ai-platform jobs submit training my_job_20190531_164700 \\\n",
            "    --region asia-southeast1 \\\n",
            "    --scale-tier PREMIUM_1 \\\n",
            "\n",
            "--- Chunk 15927 ---\n",
            "--runtime-version 2.0 \\\n",
            "    --python-version 3.5 \\\n",
            "    --package-path /my_project/src/trainer \\\n",
            "    --module-name trainer.task \\\n",
            "\n",
            "--- Chunk 15928 ---\n",
            "--staging-bucket gs://my-staging-bucket \\\n",
            "    --job-dir gs://my-mnist-model-bucket/trained_model \\\n",
            "    --\n",
            "\n",
            "--- Chunk 15929 ---\n",
            "--\n",
            "    --my-extra-argument1 foo --my-extra-argument2 bar\n",
            "\n",
            "--- Chunk 15930 ---\n",
            "Let’s go through these options. The command will start a training job named\n",
            "\n",
            "--- Chunk 15931 ---\n",
            "my_job_20190531_164700, in the asia-southeast1 region, using a PREMIUM_1 scale\n",
            "\n",
            "--- Chunk 15932 ---\n",
            "tier: this corresponds to 20 workers (including a chief) and 11 parameter servers\n",
            "\n",
            "--- Chunk 15933 ---\n",
            "(check out the other available scale tiers). All these VMs will be based on AI Plat‐\n",
            "\n",
            "--- Chunk 15934 ---\n",
            "form’s 2.0 runtime (a VM configuration that includes TensorFlow 2.0 and many other\n",
            "\n",
            "--- Chunk 15935 ---\n",
            "packages)22 and Python 3.5. The training code is located in the /my_project/src/trainer\n",
            "\n",
            "--- Chunk 15936 ---\n",
            "directory, and the gcloud command will automatically bundle it into a pip package\n",
            "\n",
            "--- Chunk 15937 ---\n",
            "and upload it to GCS at gs://my-staging-bucket. Next, AI Platform will start several\n",
            "\n",
            "--- Chunk 15938 ---\n",
            "VMs, deploy the package to them, and run the trainer.task module. Lastly, the --\n",
            "\n",
            "--- Chunk 15939 ---\n",
            "job-dir argument and the extra arguments (i.e., all the arguments located after the\n",
            "\n",
            "--- Chunk 15940 ---\n",
            "-- separator) will be passed to the training program: the chief task will usually use the\n",
            "\n",
            "--- Chunk 15941 ---\n",
            "--job-dir argument to find out where to save the final model on GCS, in this case at\n",
            "\n",
            "--- Chunk 15942 ---\n",
            "gs://my-mnist-model-bucket/trained_model. And that’s it! In the GCP console, you can\n",
            "\n",
            "--- Chunk 15943 ---\n",
            "then open the navigation menu, scroll down to the Artificial Intelligence section, and\n",
            "\n",
            "--- Chunk 15944 ---\n",
            "open AI Platform → Jobs. You should see your job running, and if you click it you\n",
            "\n",
            "--- Chunk 15945 ---\n",
            "will see graphs showing the CPU, GPU, and RAM utilization for every task. You can\n",
            "click View Logs to access the detailed logs using Stackdriver.\n",
            "\n",
            "--- Chunk 15946 ---\n",
            "If you place the training data on GCS, you can create a\n",
            "tf.data.TextLineDataset or tf.data.TFRecordDataset to access\n",
            "\n",
            "--- Chunk 15947 ---\n",
            "it: just use the GCS paths as the filenames (e.g., gs://my-data-\n",
            "bucket/my_data_001.csv). These datasets rely on the tf.io.gfile\n",
            "\n",
            "--- Chunk 15948 ---\n",
            "package to access files: it supports both local files and GCS files\n",
            "(but make sure the service account you use has access to GCS).\n",
            "\n",
            "--- Chunk 15949 ---\n",
            "22 At the time of this writing, the 2.0 runtime is not yet available, but it should be ready by the time you read\n",
            "\n",
            "--- Chunk 15950 ---\n",
            "this. Check out the list of available runtimes.\n",
            "\n",
            "--- Chunk 15951 ---\n",
            "Training Models Across Multiple Devices | 715\n",
            "\n",
            "--- Chunk 15952 ---\n",
            "If you want to explore a few hyperparameter values, you can simply run multiple jobs\n",
            "\n",
            "--- Chunk 15953 ---\n",
            "and specify the hyperparameter values using the extra arguments for your tasks.\n",
            "\n",
            "--- Chunk 15954 ---\n",
            "However, if you want to explore many hyperparameters efficiently, it’s a good idea to\n",
            "use AI Platform’s hyperparameter tuning service instead.\n",
            "\n",
            "--- Chunk 15955 ---\n",
            "Black Box Hyperparameter Tuning on AI Platform\n",
            "AI Platform provides a powerful Bayesian optimization hyperparameter tuning ser‐\n",
            "\n",
            "--- Chunk 15956 ---\n",
            "vice called Google Vizier.23 To use it, you need to pass a YAML configuration file\n",
            "\n",
            "--- Chunk 15957 ---\n",
            "when creating the job (--config tuning.yaml). For example, it may look like this:\n",
            "\n",
            "--- Chunk 15958 ---\n",
            "trainingInput:\n",
            "  hyperparameters:\n",
            "    goal: MAXIMIZE\n",
            "    hyperparameterMetricTag: accuracy\n",
            "    maxTrials: 10\n",
            "    maxParallelTrials: 2\n",
            "    params:\n",
            "\n",
            "--- Chunk 15959 ---\n",
            "params:\n",
            "      - parameterName: n_layers\n",
            "        type: INTEGER\n",
            "        minValue: 10\n",
            "        maxValue: 100\n",
            "        scaleType: UNIT_LINEAR_SCALE\n",
            "\n",
            "--- Chunk 15960 ---\n",
            "- parameterName: momentum\n",
            "        type: DOUBLE\n",
            "        minValue: 0.1\n",
            "        maxValue: 1.0\n",
            "        scaleType: UNIT_LOG_SCALE\n",
            "\n",
            "--- Chunk 15961 ---\n",
            "This tells AI Platform that we want to maximize the metric named \"accuracy\", the\n",
            "\n",
            "--- Chunk 15962 ---\n",
            "job will run a maximum of 10 trials (each trial will run our training code to train the\n",
            "\n",
            "--- Chunk 15963 ---\n",
            "model from scratch), and it will run a maximum of 2 trials in parallel. We want it to\n",
            "\n",
            "--- Chunk 15964 ---\n",
            "tune two hyperparameters: the n_layers hyperparameter (an integer between 10 and\n",
            "\n",
            "--- Chunk 15965 ---\n",
            "100) and the momentum hyperparameter (a float between 0.1 and 1.0). The scaleType\n",
            "\n",
            "--- Chunk 15966 ---\n",
            "argument specifies the prior for the hyperparameter value: UNIT_LINEAR_SCALE\n",
            "\n",
            "--- Chunk 15967 ---\n",
            "means a flat prior (i.e., no a priori preference), while UNIT_LOG_SCALE says we have a\n",
            "\n",
            "--- Chunk 15968 ---\n",
            "prior belief that the optimal value lies closer to the max value (the other possible prior\n",
            "\n",
            "--- Chunk 15969 ---\n",
            "is UNIT_REVERSE_LOG_SCALE, when we believe the optimal value to be close to the min\n",
            "value).\n",
            "\n",
            "--- Chunk 15970 ---\n",
            "value).\n",
            "The n_layers and momentum arguments will be passed as command-line arguments\n",
            "\n",
            "--- Chunk 15971 ---\n",
            "to the training code, and of course it is expected to use them. The question is, how\n",
            "\n",
            "--- Chunk 15972 ---\n",
            "will the training code communicate the metric back to the AI Platform so that it can\n",
            "\n",
            "--- Chunk 15973 ---\n",
            "23 Daniel Golovin et al., “Google Vizier: A Service for Black-Box Optimization,” Proceedings of the 23rd ACM\n",
            "\n",
            "--- Chunk 15974 ---\n",
            "SIGKDD International Conference on Knowledge Discovery and Data Mining (2017): 1487–1495.\n",
            "\n",
            "--- Chunk 15975 ---\n",
            "716 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "--- Chunk 15976 ---\n",
            "decide which hyperparameter values to use during the next trial? Well, AI Platform\n",
            "\n",
            "--- Chunk 15977 ---\n",
            "just monitors the output directory (specified via --job-dir) for any event file (intro‐\n",
            "\n",
            "--- Chunk 15978 ---\n",
            "duced in Chapter 10) containing summaries for a metric named \"accuracy\" (or\n",
            "\n",
            "--- Chunk 15979 ---\n",
            "whatever metric name is specified as the hyperparameterMetricTag), and it reads\n",
            "\n",
            "--- Chunk 15980 ---\n",
            "those values. So your training code simply has to use the TensorBoard() callback\n",
            "\n",
            "--- Chunk 15981 ---\n",
            "(which you will want to do anyway for monitoring), and you’re good to go!\n",
            "\n",
            "--- Chunk 15982 ---\n",
            "Once the job is finished, all the hyperparameter values used in each trial and the\n",
            "\n",
            "--- Chunk 15983 ---\n",
            "resulting accuracy will be available in the job’s output (available via the AI Platform →\n",
            "Jobs page).\n",
            "\n",
            "--- Chunk 15984 ---\n",
            "AI Platform jobs can also be used to efficiently execute your model\n",
            "on large amounts of data: each worker can read part of the data\n",
            "\n",
            "--- Chunk 15985 ---\n",
            "from GCS, make predictions, and save them to GCS.\n",
            "\n",
            "--- Chunk 15986 ---\n",
            "Now you have all the tools and knowledge you need to create state-of-the-art neural\n",
            "\n",
            "--- Chunk 15987 ---\n",
            "net architectures and train them at scale using various distribution strategies, on your\n",
            "\n",
            "--- Chunk 15988 ---\n",
            "own infrastructure or on the cloud—and you can even perform powerful Bayesian\n",
            "optimization to fine-tune the hyperparameters!\n",
            "\n",
            "--- Chunk 15989 ---\n",
            "Exercises\n",
            "1. What does a SavedModel contain? How do you inspect its content?\n",
            "\n",
            "--- Chunk 15990 ---\n",
            "2. When should you use TF Serving? What are its main features? What are some\n",
            "\n",
            "--- Chunk 15991 ---\n",
            "tools you can use to deploy it?\n",
            "3. How do you deploy a model across multiple TF Serving instances?\n",
            "\n",
            "--- Chunk 15992 ---\n",
            "4. When should you use the gRPC API rather than the REST API to query a model\n",
            "\n",
            "--- Chunk 15993 ---\n",
            "served by TF Serving?\n",
            "5. What are the different ways TFLite reduces a model’s size to make it run on a\n",
            "\n",
            "--- Chunk 15994 ---\n",
            "mobile or embedded device?\n",
            "6. What is quantization-aware training, and why would you need it?\n",
            "\n",
            "--- Chunk 15995 ---\n",
            "7. What are model parallelism and data parallelism? Why is the latter generally\n",
            "\n",
            "--- Chunk 15996 ---\n",
            "recommended?\n",
            "8. When training a model across multiple servers, what distribution strategies can\n",
            "\n",
            "--- Chunk 15997 ---\n",
            "you use? How do you choose which one to use?\n",
            "9. Train a model (any model you like) and deploy it to TF Serving or Google Cloud\n",
            "\n",
            "--- Chunk 15998 ---\n",
            "AI Platform. Write the client code to query it using the REST API or the gRPC\n",
            "\n",
            "Exercises | 717\n",
            "\n",
            "--- Chunk 15999 ---\n",
            "API. Update the model and deploy the new version. Your client code will now\n",
            "query the new version. Roll back to the first version.\n",
            "\n",
            "--- Chunk 16000 ---\n",
            "10. Train any model across multiple GPUs on the same machine using the Mirrored\n",
            "\n",
            "--- Chunk 16001 ---\n",
            "Strategy (if you do not have access to GPUs, you can use Colaboratory with a\n",
            "\n",
            "--- Chunk 16002 ---\n",
            "GPU Runtime and create two virtual GPUs). Train the model again using the\n",
            "CentralStorageStrategy and compare the training time.\n",
            "\n",
            "--- Chunk 16003 ---\n",
            "11. Train a small model on Google Cloud AI Platform, using black box hyperpara‐\n",
            "meter tuning.\n",
            "\n",
            "--- Chunk 16004 ---\n",
            "Thank You!\n",
            "Before we close the last chapter of this book, I would like to thank you for reading it\n",
            "\n",
            "--- Chunk 16005 ---\n",
            "up to the last paragraph. I truly hope that you had as much pleasure reading this book\n",
            "\n",
            "--- Chunk 16006 ---\n",
            "as I had writing it, and that it will be useful for your projects, big or small.\n",
            "\n",
            "--- Chunk 16007 ---\n",
            "If you find errors, please send feedback. More generally, I would love to know what\n",
            "\n",
            "--- Chunk 16008 ---\n",
            "you think, so please don’t hesitate to contact me via O’Reilly, through the ageron/\n",
            "handson-ml2 GitHub project, or on Twitter at @aureliengeron.\n",
            "\n",
            "--- Chunk 16009 ---\n",
            "Going forward, my best advice to you is to practice and practice: try going through all\n",
            "\n",
            "--- Chunk 16010 ---\n",
            "the exercises (if you have not done so already), play with the Jupyter notebooks, join\n",
            "\n",
            "--- Chunk 16011 ---\n",
            "Kaggle.com or some other ML community, watch ML courses, read papers, attend\n",
            "\n",
            "--- Chunk 16012 ---\n",
            "conferences, and meet experts. It also helps tremendously to have a concrete project\n",
            "\n",
            "--- Chunk 16013 ---\n",
            "to work on, whether it is for work or for fun (ideally for both), so if there’s anything\n",
            "\n",
            "--- Chunk 16014 ---\n",
            "you have always dreamt of building, give it a shot! Work incrementally; don’t shoot\n",
            "\n",
            "--- Chunk 16015 ---\n",
            "for the moon right away, but stay focused on your project and build it piece by piece.\n",
            "\n",
            "--- Chunk 16016 ---\n",
            "It will require patience and perseverance, but when you have a walking robot, or a\n",
            "\n",
            "--- Chunk 16017 ---\n",
            "working chatbot, or whatever else you fancy to build, it will be immensely rewarding.\n",
            "\n",
            "--- Chunk 16018 ---\n",
            "My greatest hope is that this book will inspire you to build a wonderful ML applica‐\n",
            "tion that will benefit all of us! What will it be?\n",
            "\n",
            "--- Chunk 16019 ---\n",
            "—Aurélien Géron, June 17, 2019\n",
            "\n",
            "718 | Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
            "\n",
            "\n",
            "\n",
            "APPENDIX A\n",
            "Exercise Solutions\n",
            "\n",
            "--- Chunk 16020 ---\n",
            "Solutions to the coding exercises are available in the online Jupyter\n",
            "notebooks at https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 16021 ---\n",
            "Chapter 1: The Machine Learning Landscape\n",
            "1. Machine Learning is about building systems that can learn from data. Learning\n",
            "\n",
            "--- Chunk 16022 ---\n",
            "means getting better at some task, given some performance measure.\n",
            "2. Machine Learning is great for complex problems for which we have no algorith‐\n",
            "\n",
            "--- Chunk 16023 ---\n",
            "mic solution, to replace long lists of hand-tuned rules, to build systems that adapt\n",
            "\n",
            "--- Chunk 16024 ---\n",
            "to fluctuating environments, and finally to help humans learn (e.g., data mining).\n",
            "\n",
            "--- Chunk 16025 ---\n",
            "3. A labeled training set is a training set that contains the desired solution (a.k.a. a\n",
            "label) for each instance.\n",
            "\n",
            "--- Chunk 16026 ---\n",
            "4. The two most common supervised tasks are regression and classification.\n",
            "\n",
            "--- Chunk 16027 ---\n",
            "5. Common unsupervised tasks include clustering, visualization, dimensionality\n",
            "\n",
            "--- Chunk 16028 ---\n",
            "reduction, and association rule learning.\n",
            "6. Reinforcement Learning is likely to perform best if we want a robot to learn to\n",
            "\n",
            "--- Chunk 16029 ---\n",
            "walk in various unknown terrains, since this is typically the type of problem that\n",
            "\n",
            "--- Chunk 16030 ---\n",
            "Reinforcement Learning tackles. It might be possible to express the problem as a\n",
            "\n",
            "--- Chunk 16031 ---\n",
            "supervised or semisupervised learning problem, but it would be less natural.\n",
            "\n",
            "--- Chunk 16032 ---\n",
            "7. If you don’t know how to define the groups, then you can use a clustering algo‐\n",
            "\n",
            "--- Chunk 16033 ---\n",
            "rithm (unsupervised learning) to segment your customers into clusters of similar\n",
            "\n",
            "--- Chunk 16034 ---\n",
            "customers. However, if you know what groups you would like to have, then you\n",
            "\n",
            "--- Chunk 16035 ---\n",
            "719\n",
            "\n",
            "--- Chunk 16036 ---\n",
            "can feed many examples of each group to a classification algorithm (supervised\n",
            "learning), and it will classify all your customers into these groups.\n",
            "\n",
            "--- Chunk 16037 ---\n",
            "8. Spam detection is a typical supervised learning problem: the algorithm is fed\n",
            "many emails along with their labels (spam or not spam).\n",
            "\n",
            "--- Chunk 16038 ---\n",
            "9. An online learning system can learn incrementally, as opposed to a batch learn‐\n",
            "\n",
            "--- Chunk 16039 ---\n",
            "ing system. This makes it capable of adapting rapidly to both changing data and\n",
            "autonomous systems, and of training on very large quantities of data.\n",
            "\n",
            "--- Chunk 16040 ---\n",
            "10. Out-of-core algorithms can handle vast quantities of data that cannot fit in a\n",
            "\n",
            "--- Chunk 16041 ---\n",
            "computer’s main memory. An out-of-core learning algorithm chops the data into\n",
            "\n",
            "--- Chunk 16042 ---\n",
            "mini-batches and uses online learning techniques to learn from these mini-\n",
            "batches.\n",
            "\n",
            "--- Chunk 16043 ---\n",
            "11. An instance-based learning system learns the training data by heart; then, when\n",
            "\n",
            "--- Chunk 16044 ---\n",
            "given a new instance, it uses a similarity measure to find the most similar learned\n",
            "instances and uses them to make predictions.\n",
            "\n",
            "--- Chunk 16045 ---\n",
            "12. A model has one or more model parameters that determine what it will predict\n",
            "\n",
            "--- Chunk 16046 ---\n",
            "given a new instance (e.g., the slope of a linear model). A learning algorithm tries\n",
            "\n",
            "--- Chunk 16047 ---\n",
            "to find optimal values for these parameters such that the model generalizes well\n",
            "\n",
            "--- Chunk 16048 ---\n",
            "to new instances. A hyperparameter is a parameter of the learning algorithm\n",
            "itself, not of the model (e.g., the amount of regularization to apply).\n",
            "\n",
            "--- Chunk 16049 ---\n",
            "13. Model-based learning algorithms search for an optimal value for the model\n",
            "\n",
            "--- Chunk 16050 ---\n",
            "parameters such that the model will generalize well to new instances. We usually\n",
            "\n",
            "--- Chunk 16051 ---\n",
            "train such systems by minimizing a cost function that measures how bad the sys‐\n",
            "\n",
            "--- Chunk 16052 ---\n",
            "tem is at making predictions on the training data, plus a penalty for model com‐\n",
            "\n",
            "--- Chunk 16053 ---\n",
            "plexity if the model is regularized. To make predictions, we feed the new\n",
            "\n",
            "--- Chunk 16054 ---\n",
            "instance’s features into the model’s prediction function, using the parameter val‐\n",
            "ues found by the learning algorithm.\n",
            "\n",
            "--- Chunk 16055 ---\n",
            "14. Some of the main challenges in Machine Learning are the lack of data, poor data\n",
            "\n",
            "--- Chunk 16056 ---\n",
            "quality, nonrepresentative data, uninformative features, excessively simple mod‐\n",
            "\n",
            "--- Chunk 16057 ---\n",
            "els that underfit the training data, and excessively complex models that overfit\n",
            "the data.\n",
            "\n",
            "--- Chunk 16058 ---\n",
            "15. If a model performs great on the training data but generalizes poorly to new\n",
            "\n",
            "--- Chunk 16059 ---\n",
            "instances, the model is likely overfitting the training data (or we got extremely\n",
            "\n",
            "--- Chunk 16060 ---\n",
            "lucky on the training data). Possible solutions to overfitting are getting more\n",
            "\n",
            "--- Chunk 16061 ---\n",
            "data, simplifying the model (selecting a simpler algorithm, reducing the number\n",
            "\n",
            "--- Chunk 16062 ---\n",
            "of parameters or features used, or regularizing the model), or reducing the noise\n",
            "in the training data.\n",
            "\n",
            "--- Chunk 16063 ---\n",
            "16. A test set is used to estimate the generalization error that a model will make on\n",
            "new instances, before the model is launched in production.\n",
            "\n",
            "--- Chunk 16064 ---\n",
            "720 | Appendix A: Exercise Solutions\n",
            "\n",
            "--- Chunk 16065 ---\n",
            "17. A validation set is used to compare models. It makes it possible to select the best\n",
            "model and tune the hyperparameters.\n",
            "\n",
            "--- Chunk 16066 ---\n",
            "18. The train-dev set is used when there is a risk of mismatch between the training\n",
            "\n",
            "--- Chunk 16067 ---\n",
            "data and the data used in the validation and test datasets (which should always be\n",
            "\n",
            "--- Chunk 16068 ---\n",
            "as close as possible to the data used once the model is in production). The train-\n",
            "\n",
            "--- Chunk 16069 ---\n",
            "dev set is a part of the training set that’s held out (the model is not trained on it).\n",
            "\n",
            "--- Chunk 16070 ---\n",
            "The model is trained on the rest of the training set, and evaluated on both the\n",
            "\n",
            "--- Chunk 16071 ---\n",
            "train-dev set and the validation set. If the model performs well on the training set\n",
            "\n",
            "--- Chunk 16072 ---\n",
            "but not on the train-dev set, then the model is likely overfitting the training set. If\n",
            "\n",
            "--- Chunk 16073 ---\n",
            "it performs well on both the training set and the train-dev set, but not on the val‐\n",
            "\n",
            "--- Chunk 16074 ---\n",
            "idation set, then there is probably a significant data mismatch between the train‐\n",
            "\n",
            "--- Chunk 16075 ---\n",
            "ing data and the validation + test data, and you should try to improve the\n",
            "training data to make it look more like the validation + test data.\n",
            "\n",
            "--- Chunk 16076 ---\n",
            "19. If you tune hyperparameters using the test set, you risk overfitting the test set,\n",
            "\n",
            "--- Chunk 16077 ---\n",
            "and the generalization error you measure will be optimistic (you may launch a\n",
            "model that performs worse than you expect).\n",
            "\n",
            "--- Chunk 16078 ---\n",
            "Chapter 2: End-to-End Machine Learning Project\n",
            "See the Jupyter notebooks available at https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 16079 ---\n",
            "Chapter 3: Classification\n",
            "See the Jupyter notebooks available at https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 16080 ---\n",
            "Chapter 4: Training Models\n",
            "1. If you have a training set with millions of features you can use Stochastic Gradi‐\n",
            "\n",
            "--- Chunk 16081 ---\n",
            "ent Descent or Mini-batch Gradient Descent, and perhaps Batch Gradient\n",
            "\n",
            "--- Chunk 16082 ---\n",
            "Descent if the training set fits in memory. But you cannot use the Normal Equa‐\n",
            "\n",
            "--- Chunk 16083 ---\n",
            "tion or the SVD approach because the computational complexity grows quickly\n",
            "(more than quadratically) with the number of features.\n",
            "\n",
            "--- Chunk 16084 ---\n",
            "2. If the features in your training set have very different scales, the cost function will\n",
            "\n",
            "--- Chunk 16085 ---\n",
            "have the shape of an elongated bowl, so the Gradient Descent algorithms will take\n",
            "\n",
            "--- Chunk 16086 ---\n",
            "a long time to converge. To solve this you should scale the data before training\n",
            "\n",
            "--- Chunk 16087 ---\n",
            "the model. Note that the Normal Equation or SVD approach will work just fine\n",
            "\n",
            "--- Chunk 16088 ---\n",
            "without scaling. Moreover, regularized models may converge to a suboptimal sol‐\n",
            "\n",
            "--- Chunk 16089 ---\n",
            "ution if the features are not scaled: since regularization penalizes large weights,\n",
            "\n",
            "--- Chunk 16090 ---\n",
            "features with smaller values will tend to be ignored compared to features with\n",
            "larger values.\n",
            "\n",
            "--- Chunk 16091 ---\n",
            "Exercise Solutions | 721\n",
            "\n",
            "--- Chunk 16092 ---\n",
            "3. Gradient Descent cannot get stuck in a local minimum when training a Logistic\n",
            "Regression model because the cost function is convex.1\n",
            "\n",
            "--- Chunk 16093 ---\n",
            "4. If the optimization problem is convex (such as Linear Regression or Logistic\n",
            "\n",
            "--- Chunk 16094 ---\n",
            "Regression), and assuming the learning rate is not too high, then all Gradient\n",
            "\n",
            "--- Chunk 16095 ---\n",
            "Descent algorithms will approach the global optimum and end up producing\n",
            "\n",
            "--- Chunk 16096 ---\n",
            "fairly similar models. However, unless you gradually reduce the learning rate,\n",
            "\n",
            "--- Chunk 16097 ---\n",
            "Stochastic GD and Mini-batch GD will never truly converge; instead, they will\n",
            "\n",
            "--- Chunk 16098 ---\n",
            "keep jumping back and forth around the global optimum. This means that even\n",
            "\n",
            "--- Chunk 16099 ---\n",
            "if you let them run for a very long time, these Gradient Descent algorithms will\n",
            "produce slightly different models.\n",
            "\n",
            "--- Chunk 16100 ---\n",
            "5. If the validation error consistently goes up after every epoch, then one possibility\n",
            "\n",
            "--- Chunk 16101 ---\n",
            "is that the learning rate is too high and the algorithm is diverging. If the training\n",
            "\n",
            "--- Chunk 16102 ---\n",
            "error also goes up, then this is clearly the problem and you should reduce the\n",
            "\n",
            "--- Chunk 16103 ---\n",
            "learning rate. However, if the training error is not going up, then your model is\n",
            "overfitting the training set and you should stop training.\n",
            "\n",
            "--- Chunk 16104 ---\n",
            "6. Due to their random nature, neither Stochastic Gradient Descent nor Mini-batch\n",
            "\n",
            "--- Chunk 16105 ---\n",
            "Gradient Descent is guaranteed to make progress at every single training itera‐\n",
            "\n",
            "--- Chunk 16106 ---\n",
            "tion. So if you immediately stop training when the validation error goes up, you\n",
            "\n",
            "--- Chunk 16107 ---\n",
            "may stop much too early, before the optimum is reached. A better option is to\n",
            "\n",
            "--- Chunk 16108 ---\n",
            "save the model at regular intervals; then, when it has not improved for a long\n",
            "\n",
            "--- Chunk 16109 ---\n",
            "time (meaning it will probably never beat the record), you can revert to the best\n",
            "saved model.\n",
            "\n",
            "--- Chunk 16110 ---\n",
            "7. Stochastic Gradient Descent has the fastest training iteration since it considers\n",
            "\n",
            "--- Chunk 16111 ---\n",
            "only one training instance at a time, so it is generally the first to reach the vicinity\n",
            "\n",
            "--- Chunk 16112 ---\n",
            "of the global optimum (or Mini-batch GD with a very small mini-batch size).\n",
            "However, only Batch Gradient Descent will actually converge, given enough\n",
            "\n",
            "--- Chunk 16113 ---\n",
            "training time. As mentioned, Stochastic GD and Mini-batch GD will bounce\n",
            "around the optimum, unless you gradually reduce the learning rate.\n",
            "\n",
            "--- Chunk 16114 ---\n",
            "8. If the validation error is much higher than the training error, this is likely because\n",
            "\n",
            "--- Chunk 16115 ---\n",
            "your model is overfitting the training set. One way to try to fix this is to reduce\n",
            "\n",
            "--- Chunk 16116 ---\n",
            "the polynomial degree: a model with fewer degrees of freedom is less likely to\n",
            "\n",
            "--- Chunk 16117 ---\n",
            "overfit. Another thing you can try is to regularize the model—for example, by\n",
            "\n",
            "--- Chunk 16118 ---\n",
            "adding an ℓ2 penalty (Ridge) or an ℓ1 penalty (Lasso) to the cost function. This\n",
            "\n",
            "--- Chunk 16119 ---\n",
            "will also reduce the degrees of freedom of the model. Lastly, you can try to\n",
            "increase the size of the training set.\n",
            "\n",
            "--- Chunk 16120 ---\n",
            "1 If you draw a straight line between any two points on the curve, the line never crosses the curve.\n",
            "\n",
            "722 | Appendix A: Exercise Solutions\n",
            "\n",
            "--- Chunk 16121 ---\n",
            "9. If both the training error and the validation error are almost equal and fairly\n",
            "\n",
            "--- Chunk 16122 ---\n",
            "high, the model is likely underfitting the training set, which means it has a high\n",
            "bias. You should try reducing the regularization hyperparameter α.\n",
            "\n",
            "--- Chunk 16123 ---\n",
            "10. Let’s see:\n",
            "• A model with some regularization typically performs better than a model\n",
            "\n",
            "--- Chunk 16124 ---\n",
            "without any regularization, so you should generally prefer Ridge Regression\n",
            "over plain Linear Regression.\n",
            "\n",
            "--- Chunk 16125 ---\n",
            "• Lasso Regression uses an ℓ1 penalty, which tends to push the weights down to\n",
            "\n",
            "--- Chunk 16126 ---\n",
            "exactly zero. This leads to sparse models, where all weights are zero except for\n",
            "\n",
            "--- Chunk 16127 ---\n",
            "the most important weights. This is a way to perform feature selection auto‐\n",
            "\n",
            "--- Chunk 16128 ---\n",
            "matically, which is good if you suspect that only a few features actually matter.\n",
            "When you are not sure, you should prefer Ridge Regression.\n",
            "\n",
            "--- Chunk 16129 ---\n",
            "• Elastic Net is generally preferred over Lasso since Lasso may behave erratically\n",
            "\n",
            "--- Chunk 16130 ---\n",
            "in some cases (when several features are strongly correlated or when there are\n",
            "\n",
            "--- Chunk 16131 ---\n",
            "more features than training instances). However, it does add an extra hyper‐\n",
            "\n",
            "--- Chunk 16132 ---\n",
            "parameter to tune. If you want Lasso without the erratic behavior, you can just\n",
            "use Elastic Net with an l1_ratio close to 1.\n",
            "\n",
            "--- Chunk 16133 ---\n",
            "11. If you want to classify pictures as outdoor/indoor and daytime/nighttime, since\n",
            "\n",
            "--- Chunk 16134 ---\n",
            "these are not exclusive classes (i.e., all four combinations are possible) you should\n",
            "train two Logistic Regression classifiers.\n",
            "\n",
            "--- Chunk 16135 ---\n",
            "12. See the Jupyter notebooks available at https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 16136 ---\n",
            "Chapter 5: Support Vector Machines\n",
            "1. The fundamental idea behind Support Vector Machines is to fit the widest possi‐\n",
            "\n",
            "--- Chunk 16137 ---\n",
            "ble “street” between the classes. In other words, the goal is to have the largest pos‐\n",
            "\n",
            "--- Chunk 16138 ---\n",
            "sible margin between the decision boundary that separates the two classes and\n",
            "\n",
            "--- Chunk 16139 ---\n",
            "the training instances. When performing soft margin classification, the SVM\n",
            "\n",
            "--- Chunk 16140 ---\n",
            "searches for a compromise between perfectly separating the two classes and hav‐\n",
            "\n",
            "--- Chunk 16141 ---\n",
            "ing the widest possible street (i.e., a few instances may end up on the street).\n",
            "\n",
            "--- Chunk 16142 ---\n",
            "Another key idea is to use kernels when training on nonlinear datasets.\n",
            "\n",
            "--- Chunk 16143 ---\n",
            "2. After training an SVM, a support vector is any instance located on the “street” (see\n",
            "\n",
            "--- Chunk 16144 ---\n",
            "the previous answer), including its border. The decision boundary is entirely\n",
            "\n",
            "--- Chunk 16145 ---\n",
            "determined by the support vectors. Any instance that is not a support vector (i.e.,\n",
            "\n",
            "--- Chunk 16146 ---\n",
            "is off the street) has no influence whatsoever; you could remove them, add more\n",
            "\n",
            "--- Chunk 16147 ---\n",
            "instances, or move them around, and as long as they stay off the street they won’t\n",
            "\n",
            "--- Chunk 16148 ---\n",
            "affect the decision boundary. Computing the predictions only involves the sup‐\n",
            "port vectors, not the whole training set.\n",
            "\n",
            "--- Chunk 16149 ---\n",
            "Exercise Solutions | 723\n",
            "\n",
            "--- Chunk 16150 ---\n",
            "3. SVMs try to fit the largest possible “street” between the classes (see the first\n",
            "\n",
            "--- Chunk 16151 ---\n",
            "answer), so if the training set is not scaled, the SVM will tend to neglect small\n",
            "features (see Figure 5-2).\n",
            "\n",
            "--- Chunk 16152 ---\n",
            "4. An SVM classifier can output the distance between the test instance and the deci‐\n",
            "\n",
            "--- Chunk 16153 ---\n",
            "sion boundary, and you can use this as a confidence score. However, this score\n",
            "\n",
            "--- Chunk 16154 ---\n",
            "cannot be directly converted into an estimation of the class probability. If you set\n",
            "\n",
            "--- Chunk 16155 ---\n",
            "probability=True when creating an SVM in Scikit-Learn, then after training it\n",
            "\n",
            "--- Chunk 16156 ---\n",
            "will calibrate the probabilities using Logistic Regression on the SVM’s scores\n",
            "\n",
            "--- Chunk 16157 ---\n",
            "(trained by an additional five-fold cross-validation on the training data). This\n",
            "\n",
            "--- Chunk 16158 ---\n",
            "will add the predict_proba() and predict_log_proba() methods to the SVM.\n",
            "\n",
            "--- Chunk 16159 ---\n",
            "5. This question applies only to linear SVMs since kernelized SVMs can only use\n",
            "\n",
            "--- Chunk 16160 ---\n",
            "the dual form. The computational complexity of the primal form of the SVM\n",
            "\n",
            "--- Chunk 16161 ---\n",
            "problem is proportional to the number of training instances m, while the compu‐\n",
            "\n",
            "--- Chunk 16162 ---\n",
            "tational complexity of the dual form is proportional to a number between m2 and\n",
            "\n",
            "--- Chunk 16163 ---\n",
            "m3. So if there are millions of instances, you should definitely use the primal\n",
            "form, because the dual form will be much too slow.\n",
            "\n",
            "--- Chunk 16164 ---\n",
            "6. If an SVM classifier trained with an RBF kernel underfits the training set, there\n",
            "\n",
            "--- Chunk 16165 ---\n",
            "might be too much regularization. To decrease it, you need to increase gamma or C\n",
            "(or both).\n",
            "\n",
            "--- Chunk 16166 ---\n",
            "7. Let’s call the QP parameters for the hard margin problem H′, f′, A′, and b′ (see\n",
            "\n",
            "--- Chunk 16167 ---\n",
            "“Quadratic Programming” on page 167). The QP parameters for the soft margin\n",
            "\n",
            "--- Chunk 16168 ---\n",
            "problem have m additional parameters (np = n + 1 + m) and m additional con‐\n",
            "straints (nc = 2m). They can be defined like so:\n",
            "\n",
            "--- Chunk 16169 ---\n",
            "• H is equal to H′, plus m columns of 0s on the right and m rows of 0s at the\n",
            "\n",
            "--- Chunk 16170 ---\n",
            "H′ 0 ⋯\n",
            "bottom: H = 0 0\n",
            "\n",
            "⋮ ⋱\n",
            "• f is equal to f′ with m additional elements, all equal to the value of the hyper‐\n",
            "\n",
            "--- Chunk 16171 ---\n",
            "parameter C.\n",
            "• b is equal to b′ with m additional elements, all equal to 0.\n",
            "\n",
            "--- Chunk 16172 ---\n",
            "• A is equal to A′, with an extra m × m identity matrix Im appended to the right,\n",
            "\n",
            "--- Chunk 16173 ---\n",
            "A′ I\n",
            "–*I*m just below it, and the rest filled with 0s: A = m\n",
            "\n",
            "0 −Im\n",
            "\n",
            "--- Chunk 16174 ---\n",
            "0 −Im\n",
            "\n",
            "For the solutions to exercises 8, 9, and 10, please see the Jupyter notebooks available\n",
            "at https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 16175 ---\n",
            "724 | Appendix A: Exercise Solutions\n",
            "\n",
            "--- Chunk 16176 ---\n",
            "Chapter 6: Decision Trees\n",
            "1. The depth of a well-balanced binary tree containing m leaves is equal to log2(m),2\n",
            "\n",
            "--- Chunk 16177 ---\n",
            "rounded up. A binary Decision Tree (one that makes only binary decisions, as is\n",
            "\n",
            "--- Chunk 16178 ---\n",
            "the case with all trees in Scikit-Learn) will end up more or less well balanced at\n",
            "\n",
            "--- Chunk 16179 ---\n",
            "the end of training, with one leaf per training instance if it is trained without\n",
            "\n",
            "--- Chunk 16180 ---\n",
            "restrictions. Thus, if the training set contains one million instances, the Decision\n",
            "\n",
            "--- Chunk 16181 ---\n",
            "Tree will have a depth of log2(106) ≈ 20 (actually a bit more since the tree will\n",
            "generally not be perfectly well balanced).\n",
            "\n",
            "--- Chunk 16182 ---\n",
            "2. A node’s Gini impurity is generally lower than its parent’s. This is due to the\n",
            "\n",
            "--- Chunk 16183 ---\n",
            "CART training algorithm’s cost function, which splits each node in a way that\n",
            "\n",
            "--- Chunk 16184 ---\n",
            "minimizes the weighted sum of its children’s Gini impurities. However, it is possi‐\n",
            "\n",
            "--- Chunk 16185 ---\n",
            "ble for a node to have a higher Gini impurity than its parent, as long as this\n",
            "\n",
            "--- Chunk 16186 ---\n",
            "increase is more than compensated for by a decrease in the other child’s impurity.\n",
            "\n",
            "--- Chunk 16187 ---\n",
            "For example, consider a node containing four instances of class A and one of\n",
            "\n",
            "--- Chunk 16188 ---\n",
            "class B. Its Gini impurity is 1 – (1/5)2 – (4/5)2 = 0.32. Now suppose the dataset is\n",
            "\n",
            "--- Chunk 16189 ---\n",
            "one-dimensional and the instances are lined up in the following order: A, B, A,\n",
            "\n",
            "--- Chunk 16190 ---\n",
            "A, A. You can verify that the algorithm will split this node after the second\n",
            "\n",
            "--- Chunk 16191 ---\n",
            "instance, producing one child node with instances A, B, and the other child node\n",
            "\n",
            "--- Chunk 16192 ---\n",
            "with instances A, A, A. The first child node’s Gini impurity is 1 – (1/2)2 – (1/2)2 =\n",
            "\n",
            "--- Chunk 16193 ---\n",
            "0.5, which is higher than its parent’s. This is compensated for by the fact that the\n",
            "\n",
            "--- Chunk 16194 ---\n",
            "other node is pure, so its overall weighted Gini impurity is 2/5 × 0.5 + 3/5 × 0 =\n",
            "0.2, which is lower than the parent’s Gini impurity.\n",
            "\n",
            "--- Chunk 16195 ---\n",
            "3. If a Decision Tree is overfitting the training set, it may be a good idea to decrease\n",
            "\n",
            "--- Chunk 16196 ---\n",
            "max_depth, since this will constrain the model, regularizing it.\n",
            "\n",
            "--- Chunk 16197 ---\n",
            "4. Decision Trees don’t care whether or not the training data is scaled or centered;\n",
            "\n",
            "--- Chunk 16198 ---\n",
            "that’s one of the nice things about them. So if a Decision Tree underfits the train‐\n",
            "\n",
            "--- Chunk 16199 ---\n",
            "ing set, scaling the input features will just be a waste of time.\n",
            "\n",
            "--- Chunk 16200 ---\n",
            "5. The computational complexity of training a Decision Tree is O(n × m log(m)). So\n",
            "\n",
            "--- Chunk 16201 ---\n",
            "if you multiply the training set size by 10, the training time will be multiplied by\n",
            "\n",
            "--- Chunk 16202 ---\n",
            "K = (n × 10m × log(10m)) / (n × m × log(m)) = 10 × log(10m) / log(m). If m =\n",
            "\n",
            "--- Chunk 16203 ---\n",
            "106, then K ≈ 11.7, so you can expect the training time to be roughly 11.7 hours.\n",
            "\n",
            "--- Chunk 16204 ---\n",
            "6. Presorting the training set speeds up training only if the dataset is smaller than a\n",
            "\n",
            "--- Chunk 16205 ---\n",
            "few thousand instances. If it contains 100,000 instances, setting presort=True\n",
            "will considerably slow down training.\n",
            "\n",
            "--- Chunk 16206 ---\n",
            "For the solutions to exercises 7 and 8, please see the Jupyter notebooks available at\n",
            "https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 16207 ---\n",
            "2 log2 is the binary log; log2(m) = log(m) / log(2).\n",
            "\n",
            "Exercise Solutions | 725\n",
            "\n",
            "--- Chunk 16208 ---\n",
            "Chapter 7: Ensemble Learning and Random Forests\n",
            "1. If you have trained five different models and they all achieve 95% precision, you\n",
            "\n",
            "--- Chunk 16209 ---\n",
            "can try combining them into a voting ensemble, which will often give you even\n",
            "\n",
            "--- Chunk 16210 ---\n",
            "better results. It works better if the models are very different (e.g., an SVM classi‐\n",
            "\n",
            "--- Chunk 16211 ---\n",
            "fier, a Decision Tree classifier, a Logistic Regression classifier, and so on). It is\n",
            "\n",
            "--- Chunk 16212 ---\n",
            "even better if they are trained on different training instances (that’s the whole\n",
            "\n",
            "--- Chunk 16213 ---\n",
            "point of bagging and pasting ensembles), but if not this will still be effective as\n",
            "long as the models are very different.\n",
            "\n",
            "--- Chunk 16214 ---\n",
            "2. A hard voting classifier just counts the votes of each classifier in the ensemble\n",
            "\n",
            "--- Chunk 16215 ---\n",
            "and picks the class that gets the most votes. A soft voting classifier computes the\n",
            "\n",
            "--- Chunk 16216 ---\n",
            "average estimated class probability for each class and picks the class with the\n",
            "\n",
            "--- Chunk 16217 ---\n",
            "highest probability. This gives high-confidence votes more weight and often per‐\n",
            "\n",
            "--- Chunk 16218 ---\n",
            "forms better, but it works only if every classifier is able to estimate class probabil‐\n",
            "\n",
            "--- Chunk 16219 ---\n",
            "ities (e.g., for the SVM classifiers in Scikit-Learn you must set\n",
            "probability=True).\n",
            "\n",
            "--- Chunk 16220 ---\n",
            "3. It is quite possible to speed up training of a bagging ensemble by distributing it\n",
            "\n",
            "--- Chunk 16221 ---\n",
            "across multiple servers, since each predictor in the ensemble is independent of\n",
            "\n",
            "--- Chunk 16222 ---\n",
            "the others. The same goes for pasting ensembles and Random Forests, for the\n",
            "\n",
            "--- Chunk 16223 ---\n",
            "same reason. However, each predictor in a boosting ensemble is built based on\n",
            "\n",
            "--- Chunk 16224 ---\n",
            "the previous predictor, so training is necessarily sequential, and you will not gain\n",
            "\n",
            "--- Chunk 16225 ---\n",
            "anything by distributing training across multiple servers. Regarding stacking\n",
            "\n",
            "--- Chunk 16226 ---\n",
            "ensembles, all the predictors in a given layer are independent of each other, so\n",
            "\n",
            "--- Chunk 16227 ---\n",
            "they can be trained in parallel on multiple servers. However, the predictors in one\n",
            "\n",
            "--- Chunk 16228 ---\n",
            "layer can only be trained after the predictors in the previous layer have all been\n",
            "trained.\n",
            "\n",
            "--- Chunk 16229 ---\n",
            "4. With out-of-bag evaluation, each predictor in a bagging ensemble is evaluated\n",
            "\n",
            "--- Chunk 16230 ---\n",
            "using instances that it was not trained on (they were held out). This makes it pos‐\n",
            "\n",
            "--- Chunk 16231 ---\n",
            "sible to have a fairly unbiased evaluation of the ensemble without the need for an\n",
            "\n",
            "--- Chunk 16232 ---\n",
            "additional validation set. Thus, you have more instances available for training,\n",
            "and your ensemble can perform slightly better.\n",
            "\n",
            "--- Chunk 16233 ---\n",
            "5. When you are growing a tree in a Random Forest, only a random subset of the\n",
            "\n",
            "--- Chunk 16234 ---\n",
            "features is considered for splitting at each node. This is true as well for Extra-\n",
            "\n",
            "--- Chunk 16235 ---\n",
            "Trees, but they go one step further: rather than searching for the best possible\n",
            "\n",
            "--- Chunk 16236 ---\n",
            "thresholds, like regular Decision Trees do, they use random thresholds for each\n",
            "\n",
            "--- Chunk 16237 ---\n",
            "feature. This extra randomness acts like a form of regularization: if a Random\n",
            "\n",
            "--- Chunk 16238 ---\n",
            "Forest overfits the training data, Extra-Trees might perform better. Moreover,\n",
            "\n",
            "--- Chunk 16239 ---\n",
            "since Extra-Trees don’t search for the best possible thresholds, they are much\n",
            "\n",
            "--- Chunk 16240 ---\n",
            "faster to train than Random Forests. However, they are neither faster nor slower\n",
            "than Random Forests when making predictions.\n",
            "\n",
            "--- Chunk 16241 ---\n",
            "726 | Appendix A: Exercise Solutions\n",
            "\n",
            "--- Chunk 16242 ---\n",
            "6. If your AdaBoost ensemble underfits the training data, you can try increasing the\n",
            "\n",
            "--- Chunk 16243 ---\n",
            "number of estimators or reducing the regularization hyperparameters of the base\n",
            "estimator. You may also try slightly increasing the learning rate.\n",
            "\n",
            "--- Chunk 16244 ---\n",
            "7. If your Gradient Boosting ensemble overfits the training set, you should try\n",
            "\n",
            "--- Chunk 16245 ---\n",
            "decreasing the learning rate. You could also use early stopping to find the right\n",
            "number of predictors (you probably have too many).\n",
            "\n",
            "--- Chunk 16246 ---\n",
            "For the solutions to exercises 8 and 9, please see the Jupyter notebooks available at\n",
            "https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 16247 ---\n",
            "Chapter 8: Dimensionality Reduction\n",
            "1. The main motivations for dimensionality reduction are:\n",
            "\n",
            "--- Chunk 16248 ---\n",
            "• To speed up a subsequent training algorithm (in some cases it may even\n",
            "remove noise and redundant features, making the training algorithm perform\n",
            "\n",
            "--- Chunk 16249 ---\n",
            "better)\n",
            "\n",
            "--- Chunk 16250 ---\n",
            "• To visualize the data and gain insights on the most important features\n",
            "• To save space (compression)\n",
            "\n",
            "--- Chunk 16251 ---\n",
            "The main drawbacks are:\n",
            "• Some information is lost, possibly degrading the performance of subsequent\n",
            "\n",
            "--- Chunk 16252 ---\n",
            "training algorithms.\n",
            "• It can be computationally intensive.\n",
            "• It adds some complexity to your Machine Learning pipelines.\n",
            "\n",
            "--- Chunk 16253 ---\n",
            "• Transformed features are often hard to interpret.\n",
            "\n",
            "--- Chunk 16254 ---\n",
            "2. The curse of dimensionality refers to the fact that many problems that do not\n",
            "\n",
            "--- Chunk 16255 ---\n",
            "exist in low-dimensional space arise in high-dimensional space. In Machine\n",
            "Learning, one common manifestation is the fact that randomly sampled high-\n",
            "\n",
            "--- Chunk 16256 ---\n",
            "dimensional vectors are generally very sparse, increasing the risk of overfitting\n",
            "\n",
            "--- Chunk 16257 ---\n",
            "and making it very difficult to identify patterns in the data without having plenty\n",
            "of training data.\n",
            "\n",
            "--- Chunk 16258 ---\n",
            "3. Once a dataset’s dimensionality has been reduced using one of the algorithms we\n",
            "\n",
            "--- Chunk 16259 ---\n",
            "discussed, it is almost always impossible to perfectly reverse the operation,\n",
            "\n",
            "--- Chunk 16260 ---\n",
            "because some information gets lost during dimensionality reduction. Moreover,\n",
            "\n",
            "--- Chunk 16261 ---\n",
            "while some algorithms (such as PCA) have a simple reverse transformation\n",
            "\n",
            "--- Chunk 16262 ---\n",
            "procedure that can reconstruct a dataset relatively similar to the original, other\n",
            "algorithms (such as T-SNE) do not.\n",
            "\n",
            "--- Chunk 16263 ---\n",
            "Exercise Solutions | 727\n",
            "\n",
            "--- Chunk 16264 ---\n",
            "4. PCA can be used to significantly reduce the dimensionality of most datasets, even\n",
            "\n",
            "--- Chunk 16265 ---\n",
            "if they are highly nonlinear, because it can at least get rid of useless dimensions.\n",
            "\n",
            "--- Chunk 16266 ---\n",
            "However, if there are no useless dimensions—as in a Swiss roll dataset—then\n",
            "\n",
            "--- Chunk 16267 ---\n",
            "reducing dimensionality with PCA will lose too much information. You want to\n",
            "unroll the Swiss roll, not squash it.\n",
            "\n",
            "--- Chunk 16268 ---\n",
            "5. That’s a trick question: it depends on the dataset. Let’s look at two extreme exam‐\n",
            "\n",
            "--- Chunk 16269 ---\n",
            "ples. First, suppose the dataset is composed of points that are almost perfectly\n",
            "\n",
            "--- Chunk 16270 ---\n",
            "aligned. In this case, PCA can reduce the dataset down to just one dimension\n",
            "\n",
            "--- Chunk 16271 ---\n",
            "while still preserving 95% of the variance. Now imagine that the dataset is com‐\n",
            "\n",
            "--- Chunk 16272 ---\n",
            "posed of perfectly random points, scattered all around the 1,000 dimensions. In\n",
            "\n",
            "--- Chunk 16273 ---\n",
            "this case roughly 950 dimensions are required to preserve 95% of the variance. So\n",
            "\n",
            "--- Chunk 16274 ---\n",
            "the answer is, it depends on the dataset, and it could be any number between 1\n",
            "\n",
            "--- Chunk 16275 ---\n",
            "and 950. Plotting the explained variance as a function of the number of dimen‐\n",
            "\n",
            "--- Chunk 16276 ---\n",
            "sions is one way to get a rough idea of the dataset’s intrinsic dimensionality.\n",
            "\n",
            "--- Chunk 16277 ---\n",
            "6. Regular PCA is the default, but it works only if the dataset fits in memory. Incre‐\n",
            "\n",
            "--- Chunk 16278 ---\n",
            "mental PCA is useful for large datasets that don’t fit in memory, but it is slower\n",
            "\n",
            "--- Chunk 16279 ---\n",
            "than regular PCA, so if the dataset fits in memory you should prefer regular\n",
            "\n",
            "--- Chunk 16280 ---\n",
            "PCA. Incremental PCA is also useful for online tasks, when you need to apply\n",
            "\n",
            "--- Chunk 16281 ---\n",
            "PCA on the fly, every time a new instance arrives. Randomized PCA is useful\n",
            "\n",
            "--- Chunk 16282 ---\n",
            "when you want to considerably reduce dimensionality and the dataset fits in\n",
            "\n",
            "--- Chunk 16283 ---\n",
            "memory; in this case, it is much faster than regular PCA. Finally, Kernel PCA is\n",
            "useful for nonlinear datasets.\n",
            "\n",
            "--- Chunk 16284 ---\n",
            "7. Intuitively, a dimensionality reduction algorithm performs well if it eliminates a\n",
            "\n",
            "--- Chunk 16285 ---\n",
            "lot of dimensions from the dataset without losing too much information. One\n",
            "\n",
            "--- Chunk 16286 ---\n",
            "way to measure this is to apply the reverse transformation and measure the\n",
            "\n",
            "--- Chunk 16287 ---\n",
            "reconstruction error. However, not all dimensionality reduction algorithms pro‐\n",
            "\n",
            "--- Chunk 16288 ---\n",
            "vide a reverse transformation. Alternatively, if you are using dimensionality\n",
            "\n",
            "--- Chunk 16289 ---\n",
            "reduction as a preprocessing step before another Machine Learning algorithm\n",
            "\n",
            "--- Chunk 16290 ---\n",
            "(e.g., a Random Forest classifier), then you can simply measure the performance\n",
            "\n",
            "--- Chunk 16291 ---\n",
            "of that second algorithm; if dimensionality reduction did not lose too much\n",
            "\n",
            "--- Chunk 16292 ---\n",
            "information, then the algorithm should perform just as well as when using the\n",
            "original dataset.\n",
            "\n",
            "--- Chunk 16293 ---\n",
            "8. It can absolutely make sense to chain two different dimensionality reduction\n",
            "\n",
            "--- Chunk 16294 ---\n",
            "algorithms. A common example is using PCA to quickly get rid of a large num‐\n",
            "\n",
            "--- Chunk 16295 ---\n",
            "ber of useless dimensions, then applying another much slower dimensionality\n",
            "\n",
            "--- Chunk 16296 ---\n",
            "reduction algorithm, such as LLE. This two-step approach will likely yield the\n",
            "same performance as using LLE only, but in a fraction of the time.\n",
            "\n",
            "--- Chunk 16297 ---\n",
            "For the solutions to exercises 9 and 10, please see the Jupyter notebooks available at\n",
            "https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 16298 ---\n",
            "728 | Appendix A: Exercise Solutions\n",
            "\n",
            "--- Chunk 16299 ---\n",
            "Chapter 9: Unsupervised Learning Techniques\n",
            "1. In Machine Learning, clustering is the unsupervised task of grouping similar\n",
            "\n",
            "--- Chunk 16300 ---\n",
            "instances together. The notion of similarity depends on the task at hand: for\n",
            "\n",
            "--- Chunk 16301 ---\n",
            "example, in some cases two nearby instances will be considered similar, while in\n",
            "\n",
            "--- Chunk 16302 ---\n",
            "others similar instances may be far apart as long as they belong to the same\n",
            "densely packed group. Popular clustering algorithms include K-Means,\n",
            "\n",
            "--- Chunk 16303 ---\n",
            "DBSCAN, agglomerative clustering, BIRCH, Mean-Shift, affinity propagation,\n",
            "and spectral clustering.\n",
            "\n",
            "--- Chunk 16304 ---\n",
            "2. The main applications of clustering algorithms include data analysis, customer\n",
            "\n",
            "--- Chunk 16305 ---\n",
            "segmentation, recommender systems, search engines, image segmentation, semi-\n",
            "\n",
            "--- Chunk 16306 ---\n",
            "supervised learning, dimensionality reduction, anomaly detection, and novelty\n",
            "detection.\n",
            "\n",
            "--- Chunk 16307 ---\n",
            "3. The elbow rule is a simple technique to select the number of clusters when using\n",
            "\n",
            "--- Chunk 16308 ---\n",
            "K-Means: just plot the inertia (the mean squared distance from each instance to\n",
            "\n",
            "--- Chunk 16309 ---\n",
            "its nearest centroid) as a function of the number of clusters, and find the point in\n",
            "\n",
            "--- Chunk 16310 ---\n",
            "the curve where the inertia stops dropping fast (the “elbow”). This is generally\n",
            "\n",
            "--- Chunk 16311 ---\n",
            "close to the optimal number of clusters. Another approach is to plot the silhou‐\n",
            "\n",
            "--- Chunk 16312 ---\n",
            "ette score as a function of the number of clusters. There will often be a peak, and\n",
            "\n",
            "--- Chunk 16313 ---\n",
            "the optimal number of clusters is generally nearby. The silhouette score is the\n",
            "\n",
            "--- Chunk 16314 ---\n",
            "mean silhouette coefficient over all instances. This coefficient varies from +1 for\n",
            "\n",
            "--- Chunk 16315 ---\n",
            "instances that are well inside their cluster and far from other clusters, to –1 for\n",
            "\n",
            "--- Chunk 16316 ---\n",
            "instances that are very close to another cluster. You may also plot the silhouette\n",
            "diagrams and perform a more thorough analysis.\n",
            "\n",
            "--- Chunk 16317 ---\n",
            "4. Labeling a dataset is costly and time-consuming. Therefore, it is common to have\n",
            "\n",
            "--- Chunk 16318 ---\n",
            "plenty of unlabeled instances, but few labeled instances. Label propagation is a\n",
            "\n",
            "--- Chunk 16319 ---\n",
            "technique that consists in copying some (or all) of the labels from the labeled\n",
            "\n",
            "--- Chunk 16320 ---\n",
            "instances to similar unlabeled instances. This can greatly extend the number of\n",
            "\n",
            "--- Chunk 16321 ---\n",
            "labeled instances, and thereby allow a supervised algorithm to reach better per‐\n",
            "\n",
            "--- Chunk 16322 ---\n",
            "formance (this is a form of semi-supervised learning). One approach is to use a\n",
            "\n",
            "--- Chunk 16323 ---\n",
            "clustering algorithm such as K-Means on all the instances, then for each cluster\n",
            "\n",
            "--- Chunk 16324 ---\n",
            "find the most common label or the label of the most representative instance (i.e.,\n",
            "\n",
            "--- Chunk 16325 ---\n",
            "the one closest to the centroid) and propagate it to the unlabeled instances in the\n",
            "same cluster.\n",
            "\n",
            "--- Chunk 16326 ---\n",
            "5. K-Means and BIRCH scale well to large datasets. DBSCAN and Mean-Shift look\n",
            "for regions of high density.\n",
            "\n",
            "--- Chunk 16327 ---\n",
            "6. Active learning is useful whenever you have plenty of unlabeled instances but\n",
            "\n",
            "--- Chunk 16328 ---\n",
            "labeling is costly. In this case (which is very common), rather than randomly\n",
            "\n",
            "--- Chunk 16329 ---\n",
            "selecting instances to label, it is often preferable to perform active learning,\n",
            "\n",
            "--- Chunk 16330 ---\n",
            "where human experts interact with the learning algorithm, providing labels for\n",
            "\n",
            "--- Chunk 16331 ---\n",
            "Exercise Solutions | 729\n",
            "\n",
            "--- Chunk 16332 ---\n",
            "specific instances when the algorithm requests them. A common approach is\n",
            "\n",
            "--- Chunk 16333 ---\n",
            "uncertainty sampling (see the description in “Active Learning” on page 255).\n",
            "\n",
            "--- Chunk 16334 ---\n",
            "7. Many people use the terms anomaly detection and novelty detection interchangea‐\n",
            "\n",
            "--- Chunk 16335 ---\n",
            "bly, but they are not exactly the same. In anomaly detection, the algorithm is\n",
            "\n",
            "--- Chunk 16336 ---\n",
            "trained on a dataset that may contain outliers, and the goal is typically to identify\n",
            "\n",
            "--- Chunk 16337 ---\n",
            "these outliers (within the training set), as well as outliers among new instances.\n",
            "\n",
            "--- Chunk 16338 ---\n",
            "In novelty detection, the algorithm is trained on a dataset that is presumed to be\n",
            "\n",
            "--- Chunk 16339 ---\n",
            "“clean,” and the objective is to detect novelties strictly among new instances.\n",
            "\n",
            "--- Chunk 16340 ---\n",
            "Some algorithms work best for anomaly detection (e.g., Isolation Forest), while\n",
            "others are better suited for novelty detection (e.g., one-class SVM).\n",
            "\n",
            "--- Chunk 16341 ---\n",
            "8. A Gaussian mixture model (GMM) is a probabilistic model that assumes that the\n",
            "\n",
            "--- Chunk 16342 ---\n",
            "instances were generated from a mixture of several Gaussian distributions whose\n",
            "\n",
            "--- Chunk 16343 ---\n",
            "parameters are unknown. In other words, the assumption is that the data is grou‐\n",
            "\n",
            "--- Chunk 16344 ---\n",
            "ped into a finite number of clusters, each with an ellipsoidal shape (but the clus‐\n",
            "\n",
            "--- Chunk 16345 ---\n",
            "ters may have different ellipsoidal shapes, sizes, orientations, and densities), and\n",
            "\n",
            "--- Chunk 16346 ---\n",
            "we don’t know which cluster each instance belongs to. This model is useful for\n",
            "density estimation, clustering, and anomaly detection.\n",
            "\n",
            "--- Chunk 16347 ---\n",
            "9. One way to find the right number of clusters when using a Gaussian mixture\n",
            "\n",
            "--- Chunk 16348 ---\n",
            "model is to plot the Bayesian information criterion (BIC) or the Akaike informa‐\n",
            "\n",
            "--- Chunk 16349 ---\n",
            "tion criterion (AIC) as a function of the number of clusters, then choose the\n",
            "\n",
            "--- Chunk 16350 ---\n",
            "number of clusters that minimizes the BIC or AIC. Another technique is to use a\n",
            "\n",
            "--- Chunk 16351 ---\n",
            "Bayesian Gaussian mixture model, which automatically selects the number of\n",
            "clusters.\n",
            "\n",
            "--- Chunk 16352 ---\n",
            "For the solutions to exercises 10 to 13, please see the Jupyter notebooks available at\n",
            "https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 16353 ---\n",
            "Chapter 10: Introduction to Artificial Neural Networks\n",
            "with Keras\n",
            "\n",
            "--- Chunk 16354 ---\n",
            "1. Visit the TensorFlow Playground and play around with it, as described in this\n",
            "exercise.\n",
            "\n",
            "--- Chunk 16355 ---\n",
            "2. Here is a neural network based on the original artificial neurons that computes A\n",
            "\n",
            "--- Chunk 16356 ---\n",
            "⊕ B (where ⊕ represents the exclusive OR), using the fact that A ⊕ B = (A ∧ ¬ B)\n",
            "\n",
            "--- Chunk 16357 ---\n",
            "∨ (¬ A ∧ B). There are other solutions—for example, using the fact that A ⊕ B =\n",
            "\n",
            "--- Chunk 16358 ---\n",
            "(A ∨ B) ∧ ¬(A ∧ B), or the fact that A ⊕ B = (A ∨ B) ∧ (¬ A ∨ ∧ B), and so on.\n",
            "\n",
            "--- Chunk 16359 ---\n",
            "730 | Appendix A: Exercise Solutions\n",
            "\n",
            "--- Chunk 16360 ---\n",
            "3. A classical Perceptron will converge only if the dataset is linearly separable, and it\n",
            "\n",
            "--- Chunk 16361 ---\n",
            "won’t be able to estimate class probabilities. In contrast, a Logistic Regression\n",
            "\n",
            "--- Chunk 16362 ---\n",
            "classifier will converge to a good solution even if the dataset is not linearly sepa‐\n",
            "\n",
            "--- Chunk 16363 ---\n",
            "rable, and it will output class probabilities. If you change the Perceptron’s activa‐\n",
            "\n",
            "--- Chunk 16364 ---\n",
            "tion function to the logistic activation function (or the softmax activation\n",
            "\n",
            "--- Chunk 16365 ---\n",
            "function if there are multiple neurons), and if you train it using Gradient Descent\n",
            "\n",
            "--- Chunk 16366 ---\n",
            "(or some other optimization algorithm minimizing the cost function, typically\n",
            "\n",
            "--- Chunk 16367 ---\n",
            "cross entropy), then it becomes equivalent to a Logistic Regression classifier.\n",
            "\n",
            "--- Chunk 16368 ---\n",
            "4. The logistic activation function was a key ingredient in training the first MLPs\n",
            "\n",
            "--- Chunk 16369 ---\n",
            "because its derivative is always nonzero, so Gradient Descent can always roll\n",
            "\n",
            "--- Chunk 16370 ---\n",
            "down the slope. When the activation function is a step function, Gradient\n",
            "Descent cannot move, as there is no slope at all.\n",
            "\n",
            "--- Chunk 16371 ---\n",
            "5. Popular activation functions include the step function, the logistic (sigmoid)\n",
            "\n",
            "--- Chunk 16372 ---\n",
            "function, the hyperbolic tangent (tanh) function, and the Rectified Linear Unit\n",
            "\n",
            "--- Chunk 16373 ---\n",
            "(ReLU) function (see Figure 10-8). See Chapter 11 for other examples, such as\n",
            "ELU and variants of the ReLU function.\n",
            "\n",
            "--- Chunk 16374 ---\n",
            "6. Considering the MLP described in the question, composed of one input layer\n",
            "\n",
            "--- Chunk 16375 ---\n",
            "with 10 passthrough neurons, followed by one hidden layer with 50 artificial neu‐\n",
            "\n",
            "--- Chunk 16376 ---\n",
            "rons, and finally one output layer with 3 artificial neurons, where all artificial\n",
            "\n",
            "--- Chunk 16377 ---\n",
            "neurons use the ReLU activation function: ..The shape of the input matrix X is m\n",
            "× 10, where m represents the training batch size.\n",
            "\n",
            "--- Chunk 16378 ---\n",
            "a. The shape of the hidden layer’s weight vector Wh is 10 × 50, and the length of\n",
            "\n",
            "--- Chunk 16379 ---\n",
            "its bias vector bh is 50.\n",
            "b. The shape of the output layer’s weight vector Wo is 50 × 3, and the length of its\n",
            "\n",
            "--- Chunk 16380 ---\n",
            "bias vector bo is 3.\n",
            "c. The shape of the network’s output matrix Y is m × 3.\n",
            "\n",
            "--- Chunk 16381 ---\n",
            "d. Y* = ReLU(ReLU(X Wh + bh) Wo + bo). Recall that the ReLU function just sets\n",
            "\n",
            "--- Chunk 16382 ---\n",
            "every negative number in the matrix to zero. Also note that when you are\n",
            "\n",
            "--- Chunk 16383 ---\n",
            "adding a bias vector to a matrix, it is added to every single row in the matrix,\n",
            "which is called broadcasting.\n",
            "\n",
            "--- Chunk 16384 ---\n",
            "Exercise Solutions | 731\n",
            "\n",
            "--- Chunk 16385 ---\n",
            "7. To classify email into spam or ham, you just need one neuron in the output layer\n",
            "\n",
            "--- Chunk 16386 ---\n",
            "of a neural network—for example, indicating the probability that the email is\n",
            "\n",
            "--- Chunk 16387 ---\n",
            "spam. You would typically use the logistic activation function in the output layer\n",
            "\n",
            "--- Chunk 16388 ---\n",
            "when estimating a probability. If instead you want to tackle MNIST, you need 10\n",
            "\n",
            "--- Chunk 16389 ---\n",
            "neurons in the output layer, and you must replace the logistic function with the\n",
            "\n",
            "--- Chunk 16390 ---\n",
            "softmax activation function, which can handle multiple classes, outputting one\n",
            "\n",
            "--- Chunk 16391 ---\n",
            "probability per class. If you want your neural network to predict housing prices\n",
            "\n",
            "--- Chunk 16392 ---\n",
            "like in Chapter 2, then you need one output neuron, using no activation function\n",
            "at all in the output layer.3\n",
            "\n",
            "--- Chunk 16393 ---\n",
            "8. Backpropagation is a technique used to train artificial neural networks. It first\n",
            "\n",
            "--- Chunk 16394 ---\n",
            "computes the gradients of the cost function with regard to every model parame‐\n",
            "\n",
            "--- Chunk 16395 ---\n",
            "ter (all the weights and biases), then it performs a Gradient Descent step using\n",
            "\n",
            "--- Chunk 16396 ---\n",
            "these gradients. This backpropagation step is typically performed thousands or\n",
            "\n",
            "--- Chunk 16397 ---\n",
            "millions of times, using many training batches, until the model parameters con‐\n",
            "\n",
            "--- Chunk 16398 ---\n",
            "verge to values that (hopefully) minimize the cost function. To compute the gra‐\n",
            "\n",
            "--- Chunk 16399 ---\n",
            "dients, backpropagation uses reverse-mode autodiff (although it wasn’t called\n",
            "\n",
            "--- Chunk 16400 ---\n",
            "that when backpropagation was invented, and it has been reinvented several\n",
            "\n",
            "--- Chunk 16401 ---\n",
            "times). Reverse-mode autodiff performs a forward pass through a computation\n",
            "\n",
            "--- Chunk 16402 ---\n",
            "graph, computing every node’s value for the current training batch, and then it\n",
            "\n",
            "--- Chunk 16403 ---\n",
            "performs a reverse pass, computing all the gradients at once (see Appendix D for\n",
            "\n",
            "--- Chunk 16404 ---\n",
            "more details). So what’s the difference? Well, backpropagation refers to the whole\n",
            "\n",
            "--- Chunk 16405 ---\n",
            "process of training an artificial neural network using multiple backpropagation\n",
            "\n",
            "--- Chunk 16406 ---\n",
            "steps, each of which computes gradients and uses them to perform a Gradient\n",
            "\n",
            "--- Chunk 16407 ---\n",
            "Descent step. In contrast, reverse-mode autodiff is just a technique to compute\n",
            "gradients efficiently, and it happens to be used by backpropagation.\n",
            "\n",
            "--- Chunk 16408 ---\n",
            "9. Here is a list of all the hyperparameters you can tweak in a basic MLP: the num‐\n",
            "\n",
            "--- Chunk 16409 ---\n",
            "ber of hidden layers, the number of neurons in each hidden layer, and the activa‐\n",
            "\n",
            "--- Chunk 16410 ---\n",
            "tion function used in each hidden layer and in the output layer.4 In general, the\n",
            "\n",
            "--- Chunk 16411 ---\n",
            "ReLU activation function (or one of its variants; see Chapter 11) is a good default\n",
            "\n",
            "--- Chunk 16412 ---\n",
            "for the hidden layers. For the output layer, in general you will want the logistic\n",
            "\n",
            "--- Chunk 16413 ---\n",
            "activation function for binary classification, the softmax activation function for\n",
            "\n",
            "--- Chunk 16414 ---\n",
            "multiclass classification, or no activation function for regression.\n",
            "\n",
            "--- Chunk 16415 ---\n",
            "3 When the values to predict can vary by many orders of magnitude, you may want to predict the logarithm of\n",
            "\n",
            "--- Chunk 16416 ---\n",
            "the target value rather than the target value directly. Simply computing the exponential of the neural network’s\n",
            "\n",
            "--- Chunk 16417 ---\n",
            "output will give you the estimated value (since exp(log v) = v).\n",
            "\n",
            "--- Chunk 16418 ---\n",
            "4 In Chapter 11 we discuss many techniques that introduce additional hyperparameters: type of weight initiali‐\n",
            "\n",
            "--- Chunk 16419 ---\n",
            "zation, activation function hyperparameters (e.g., the amount of leak in leaky ReLU), Gradient Clipping thres‐\n",
            "\n",
            "--- Chunk 16420 ---\n",
            "hold, type of optimizer and its hyperparameters (e.g., the momentum hyperparameter when using a\n",
            "\n",
            "--- Chunk 16421 ---\n",
            "MomentumOptimizer), type of regularization for each layer and regularization hyperparameters (e.g., dropout\n",
            "rate when using dropout), and so on.\n",
            "\n",
            "--- Chunk 16422 ---\n",
            "732 | Appendix A: Exercise Solutions\n",
            "\n",
            "--- Chunk 16423 ---\n",
            "If the MLP overfits the training data, you can try reducing the number of hidden\n",
            "layers and reducing the number of neurons per hidden layer.\n",
            "\n",
            "--- Chunk 16424 ---\n",
            "10. See the Jupyter notebooks available at https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 16425 ---\n",
            "Chapter 11: Training Deep Neural Networks\n",
            "1. No, all weights should be sampled independently; they should not all have the\n",
            "\n",
            "--- Chunk 16426 ---\n",
            "same initial value. One important goal of sampling weights randomly is to break\n",
            "\n",
            "--- Chunk 16427 ---\n",
            "symmetry: if all the weights have the same initial value, even if that value is not\n",
            "\n",
            "--- Chunk 16428 ---\n",
            "zero, then symmetry is not broken (i.e., all neurons in a given layer are equiva‐\n",
            "\n",
            "--- Chunk 16429 ---\n",
            "lent), and backpropagation will be unable to break it. Concretely, this means that\n",
            "\n",
            "--- Chunk 16430 ---\n",
            "all the neurons in any given layer will always have the same weights. It’s like hav‐\n",
            "\n",
            "--- Chunk 16431 ---\n",
            "ing just one neuron per layer, and much slower. It is virtually impossible for such\n",
            "a configuration to converge to a good solution.\n",
            "\n",
            "--- Chunk 16432 ---\n",
            "2. It is perfectly fine to initialize the bias terms to zero. Some people like to initialize\n",
            "\n",
            "--- Chunk 16433 ---\n",
            "them just like weights, and that’s okay too; it does not make much difference.\n",
            "\n",
            "--- Chunk 16434 ---\n",
            "3. A few advantages of the SELU function over the ReLU function are:\n",
            "• It can take on negative values, so the average output of the neurons in any\n",
            "\n",
            "--- Chunk 16435 ---\n",
            "given layer is typically closer to zero than when using the ReLU activation\n",
            "\n",
            "--- Chunk 16436 ---\n",
            "function (which never outputs negative values). This helps alleviate the vanish‐\n",
            "ing gradients problem.\n",
            "\n",
            "--- Chunk 16437 ---\n",
            "• It always has a nonzero derivative, which avoids the dying units issue that can\n",
            "affect ReLU units.\n",
            "\n",
            "--- Chunk 16438 ---\n",
            "• When the conditions are right (i.e., if the model is sequential, and the weights\n",
            "\n",
            "--- Chunk 16439 ---\n",
            "are initialized using LeCun initialization, and the inputs are standardized, and\n",
            "\n",
            "--- Chunk 16440 ---\n",
            "there’s no incompatible layer or regularization, such as dropout or ℓ1 regulari‐\n",
            "\n",
            "--- Chunk 16441 ---\n",
            "zation), then the SELU activation function ensures the model is self-\n",
            "normalized, which solves the exploding/vanishing gradients problems.\n",
            "\n",
            "--- Chunk 16442 ---\n",
            "4. The SELU activation function is a good default. If you need the neural network to\n",
            "\n",
            "--- Chunk 16443 ---\n",
            "be as fast as possible, you can use one of the leaky ReLU variants instead (e.g., a\n",
            "\n",
            "--- Chunk 16444 ---\n",
            "simple leaky ReLU using the default hyperparameter value). The simplicity of the\n",
            "\n",
            "--- Chunk 16445 ---\n",
            "ReLU activation function makes it many people’s preferred option, despite the\n",
            "\n",
            "--- Chunk 16446 ---\n",
            "fact that it is generally outperformed by SELU and leaky ReLU. However, the\n",
            "\n",
            "--- Chunk 16447 ---\n",
            "ReLU activation function’s ability to output precisely zero can be useful in some\n",
            "\n",
            "--- Chunk 16448 ---\n",
            "cases (e.g., see Chapter 17). Moreover, it can sometimes benefit from optimized\n",
            "\n",
            "--- Chunk 16449 ---\n",
            "implementation as well as from hardware acceleration. The hyperbolic tangent\n",
            "\n",
            "--- Chunk 16450 ---\n",
            "(tanh) can be useful in the output layer if you need to output a number between\n",
            "\n",
            "--- Chunk 16451 ---\n",
            "–1 and 1, but nowadays it is not used much in hidden layers (except in recurrent\n",
            "\n",
            "--- Chunk 16452 ---\n",
            "Exercise Solutions | 733\n",
            "\n",
            "--- Chunk 16453 ---\n",
            "nets). The logistic activation function is also useful in the output layer when you\n",
            "\n",
            "--- Chunk 16454 ---\n",
            "need to estimate a probability (e.g., for binary classification), but is rarely used in\n",
            "\n",
            "--- Chunk 16455 ---\n",
            "hidden layers (there are exceptions—for example, for the coding layer of varia‐\n",
            "\n",
            "--- Chunk 16456 ---\n",
            "tional autoencoders; see Chapter 17). Finally, the softmax activation function is\n",
            "\n",
            "--- Chunk 16457 ---\n",
            "useful in the output layer to output probabilities for mutually exclusive classes,\n",
            "but it is rarely (if ever) used in hidden layers.\n",
            "\n",
            "--- Chunk 16458 ---\n",
            "5. If you set the momentum hyperparameter too close to 1 (e.g., 0.99999) when using\n",
            "\n",
            "--- Chunk 16459 ---\n",
            "an SGD optimizer, then the algorithm will likely pick up a lot of speed, hopefully\n",
            "\n",
            "--- Chunk 16460 ---\n",
            "moving roughly toward the global minimum, but its momentum will carry it\n",
            "\n",
            "--- Chunk 16461 ---\n",
            "right past the minimum. Then it will slow down and come back, accelerate again,\n",
            "\n",
            "--- Chunk 16462 ---\n",
            "overshoot again, and so on. It may oscillate this way many times before converg‐\n",
            "\n",
            "--- Chunk 16463 ---\n",
            "ing, so overall it will take much longer to converge than with a smaller momentum\n",
            "value.\n",
            "\n",
            "--- Chunk 16464 ---\n",
            "6. One way to produce a sparse model (i.e., with most weights equal to zero) is to\n",
            "\n",
            "--- Chunk 16465 ---\n",
            "train the model normally, then zero out tiny weights. For more sparsity, you can\n",
            "\n",
            "--- Chunk 16466 ---\n",
            "apply ℓ1 regularization during training, which pushes the optimizer toward spar‐\n",
            "\n",
            "--- Chunk 16467 ---\n",
            "sity. A third option is to use the TensorFlow Model Optimization Toolkit.\n",
            "\n",
            "--- Chunk 16468 ---\n",
            "7. Yes, dropout does slow down training, in general roughly by a factor of two.\n",
            "\n",
            "--- Chunk 16469 ---\n",
            "However, it has no impact on inference speed since it is only turned on during\n",
            "\n",
            "--- Chunk 16470 ---\n",
            "training. MC Dropout is exactly like dropout during training, but it is still active\n",
            "\n",
            "--- Chunk 16471 ---\n",
            "during inference, so each inference is slowed down slightly. More importantly,\n",
            "\n",
            "--- Chunk 16472 ---\n",
            "when using MC Dropout you generally want to run inference 10 times or more\n",
            "\n",
            "--- Chunk 16473 ---\n",
            "to get better predictions. This means that making predictions is slowed down by\n",
            "a factor of 10 or more.\n",
            "\n",
            "--- Chunk 16474 ---\n",
            "For the solutions to exercises 8, 9, and 10, please see the Jupyter notebooks available\n",
            "at https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 16475 ---\n",
            "Chapter 12: Custom Models and Training with TensorFlow\n",
            "1. TensorFlow is an open-source library for numerical computation, particularly\n",
            "\n",
            "--- Chunk 16476 ---\n",
            "well suited and fine-tuned for large-scale Machine Learning. Its core is similar to\n",
            "\n",
            "--- Chunk 16477 ---\n",
            "NumPy, but it also features GPU support, support for distributed computing,\n",
            "\n",
            "--- Chunk 16478 ---\n",
            "computation graph analysis and optimization capabilities (with a portable graph\n",
            "\n",
            "--- Chunk 16479 ---\n",
            "format that allows you to train a TensorFlow model in one environment and run\n",
            "\n",
            "--- Chunk 16480 ---\n",
            "it in another), an optimization API based on reverse-mode autodiff, and several\n",
            "\n",
            "--- Chunk 16481 ---\n",
            "powerful APIs such as tf.keras, tf.data, tf.image, tf.signal, and more. Other popu‐\n",
            "\n",
            "--- Chunk 16482 ---\n",
            "lar Deep Learning libraries include PyTorch, MXNet, Microsoft Cognitive Tool‐\n",
            "kit, Theano, Caffe2, and Chainer.\n",
            "\n",
            "--- Chunk 16483 ---\n",
            "2. Although TensorFlow offers most of the functionalities provided by NumPy, it is\n",
            "\n",
            "--- Chunk 16484 ---\n",
            "not a drop-in replacement, for a few reasons. First, the names of the functions are\n",
            "\n",
            "--- Chunk 16485 ---\n",
            "734 | Appendix A: Exercise Solutions\n",
            "\n",
            "--- Chunk 16486 ---\n",
            "not always the same (for example, tf.reduce_sum() versus np.sum()). Second,\n",
            "\n",
            "--- Chunk 16487 ---\n",
            "some functions do not behave in exactly the same way (for example, tf.trans\n",
            "\n",
            "--- Chunk 16488 ---\n",
            "pose() creates a transposed copy of a tensor, while NumPy’s T attribute creates a\n",
            "\n",
            "--- Chunk 16489 ---\n",
            "transposed view, without actually copying any data). Lastly, NumPy arrays are\n",
            "\n",
            "--- Chunk 16490 ---\n",
            "mutable, while TensorFlow tensors are not (but you can use a tf.Variable if you\n",
            "need a mutable object).\n",
            "\n",
            "--- Chunk 16491 ---\n",
            "3. Both tf.range(10) and tf.constant(np.arange(10)) return a one-\n",
            "dimensional tensor containing the integers 0 to 9. However, the former uses 32-\n",
            "\n",
            "--- Chunk 16492 ---\n",
            "bit integers while the latter uses 64-bit integers. Indeed, TensorFlow defaults to\n",
            "32 bits, while NumPy defaults to 64 bits.\n",
            "\n",
            "--- Chunk 16493 ---\n",
            "4. Beyond regular tensors, TensorFlow offers several other data structures, includ‐\n",
            "\n",
            "--- Chunk 16494 ---\n",
            "ing sparse tensors, tensor arrays, ragged tensors, queues, string tensors, and sets.\n",
            "\n",
            "--- Chunk 16495 ---\n",
            "The last two are actually represented as regular tensors, but TensorFlow provides\n",
            "special functions to manipulate them (in tf.strings and tf.sets).\n",
            "\n",
            "--- Chunk 16496 ---\n",
            "5. When you want to define a custom loss function, in general you can just imple‐\n",
            "\n",
            "--- Chunk 16497 ---\n",
            "ment it as a regular Python function. However, if your custom loss function must\n",
            "\n",
            "--- Chunk 16498 ---\n",
            "support some hyperparameters (or any other state), then you should subclass the\n",
            "\n",
            "--- Chunk 16499 ---\n",
            "keras.losses.Loss class and implement the __init__() and call() methods. If\n",
            "\n",
            "--- Chunk 16500 ---\n",
            "you want the loss function’s hyperparameters to be saved along with the model,\n",
            "then you must also implement the get_config() method.\n",
            "\n",
            "--- Chunk 16501 ---\n",
            "6. Much like custom loss functions, most metrics can be defined as regular Python\n",
            "\n",
            "--- Chunk 16502 ---\n",
            "functions. But if you want your custom metric to support some hyperparameters\n",
            "\n",
            "--- Chunk 16503 ---\n",
            "(or any other state), then you should subclass the keras.metrics.Metric class.\n",
            "\n",
            "--- Chunk 16504 ---\n",
            "Moreover, if computing the metric over a whole epoch is not equivalent to com‐\n",
            "\n",
            "--- Chunk 16505 ---\n",
            "puting the mean metric over all batches in that epoch (e.g., as for the precision\n",
            "\n",
            "--- Chunk 16506 ---\n",
            "and recall metrics), then you should subclass the keras.metrics.Metric class\n",
            "\n",
            "--- Chunk 16507 ---\n",
            "and implement the __init__(), update_state(), and result() methods to keep\n",
            "track of a running metric during each epoch. You should also implement the\n",
            "\n",
            "--- Chunk 16508 ---\n",
            "reset_states() method unless all it needs to do is reset all variables to 0.0. If\n",
            "\n",
            "--- Chunk 16509 ---\n",
            "you want the state to be saved along with the model, then you should implement\n",
            "the get_config() method as well.\n",
            "\n",
            "--- Chunk 16510 ---\n",
            "7. You should distinguish the internal components of your model (i.e., layers or\n",
            "\n",
            "--- Chunk 16511 ---\n",
            "reusable blocks of layers) from the model itself (i.e., the object you will train).\n",
            "\n",
            "--- Chunk 16512 ---\n",
            "The former should subclass the keras.layers.Layer class, while the latter\n",
            "should subclass the keras.models.Model class.\n",
            "\n",
            "--- Chunk 16513 ---\n",
            "8. Writing your own custom training loop is fairly advanced, so you should only do\n",
            "\n",
            "--- Chunk 16514 ---\n",
            "it if you really need to. Keras provides several tools to customize training without\n",
            "\n",
            "--- Chunk 16515 ---\n",
            "having to write a custom training loop: callbacks, custom regularizers, custom\n",
            "\n",
            "--- Chunk 16516 ---\n",
            "constraints, custom losses, and so on. You should use these instead of writing a\n",
            "\n",
            "--- Chunk 16517 ---\n",
            "custom training loop whenever possible: writing a custom training loop is more\n",
            "\n",
            "--- Chunk 16518 ---\n",
            "Exercise Solutions | 735\n",
            "\n",
            "--- Chunk 16519 ---\n",
            "error-prone, and it will be harder to reuse the custom code you write. However,\n",
            "\n",
            "--- Chunk 16520 ---\n",
            "in some cases writing a custom training loop is necessary—for example, if you\n",
            "\n",
            "--- Chunk 16521 ---\n",
            "want to use different optimizers for different parts of your neural network, like in\n",
            "\n",
            "--- Chunk 16522 ---\n",
            "the Wide & Deep paper. A custom training loop can also be useful when debug‐\n",
            "ging, or when trying to understand exactly how training works.\n",
            "\n",
            "--- Chunk 16523 ---\n",
            "9. Custom Keras components should be convertible to TF Functions, which means\n",
            "\n",
            "--- Chunk 16524 ---\n",
            "they should stick to TF operations as much as possible and respect all the rules\n",
            "\n",
            "--- Chunk 16525 ---\n",
            "listed in “TF Function Rules” on page 409. If you absolutely need to include arbi‐\n",
            "\n",
            "--- Chunk 16526 ---\n",
            "trary Python code in a custom component, you can either wrap it in a\n",
            "tf.py_function() operation (but this will reduce performance and limit your\n",
            "\n",
            "--- Chunk 16527 ---\n",
            "model’s portability) or set dynamic=True when creating the custom layer or\n",
            "model (or set run_eagerly=True when calling the model’s compile() method).\n",
            "\n",
            "--- Chunk 16528 ---\n",
            "10. Please refer to “TF Function Rules” on page 409 for the list of rules to respect\n",
            "when creating a TF Function.\n",
            "\n",
            "--- Chunk 16529 ---\n",
            "11. Creating a dynamic Keras model can be useful for debugging, as it will not com‐\n",
            "\n",
            "--- Chunk 16530 ---\n",
            "pile any custom component to a TF Function, and you can use any Python\n",
            "\n",
            "--- Chunk 16531 ---\n",
            "debugger to debug your code. It can also be useful if you want to include arbi‐\n",
            "\n",
            "--- Chunk 16532 ---\n",
            "trary Python code in your model (or in your training code), including calls to\n",
            "\n",
            "--- Chunk 16533 ---\n",
            "external libraries. To make a model dynamic, you must set dynamic=True when\n",
            "\n",
            "--- Chunk 16534 ---\n",
            "creating it. Alternatively, you can set run_eagerly=True when calling the model’s\n",
            "\n",
            "--- Chunk 16535 ---\n",
            "compile() method. Making a model dynamic prevents Keras from using any of\n",
            "\n",
            "--- Chunk 16536 ---\n",
            "TensorFlow’s graph features, so it will slow down training and inference, and you\n",
            "\n",
            "--- Chunk 16537 ---\n",
            "will not have the possibility to export the computation graph, which will limit\n",
            "your model’s portability.\n",
            "\n",
            "--- Chunk 16538 ---\n",
            "For the solutions to exercises 12 and 13, please see the Jupyter notebooks available at\n",
            "https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 16539 ---\n",
            "Chapter 13: Loading and Preprocessing Data with\n",
            "TensorFlow\n",
            "\n",
            "--- Chunk 16540 ---\n",
            "1. Ingesting a large dataset and preprocessing it efficiently can be a complex engi‐\n",
            "\n",
            "--- Chunk 16541 ---\n",
            "neering challenge. The Data API makes it fairly simple. It offers many features,\n",
            "\n",
            "--- Chunk 16542 ---\n",
            "including loading data from various sources (such as text or binary files), reading\n",
            "\n",
            "--- Chunk 16543 ---\n",
            "data in parallel from multiple sources, transforming it, interleaving the records,\n",
            "shuffling the data, batching it, and prefetching it.\n",
            "\n",
            "--- Chunk 16544 ---\n",
            "2. Splitting a large dataset into multiple files makes it possible to shuffle it at a\n",
            "\n",
            "--- Chunk 16545 ---\n",
            "coarse level before shuffling it at a finer level using a shuffling buffer. It also\n",
            "\n",
            "--- Chunk 16546 ---\n",
            "makes it possible to handle huge datasets that do not fit on a single machine. It’s\n",
            "\n",
            "--- Chunk 16547 ---\n",
            "also simpler to manipulate thousands of small files rather than one huge file; for\n",
            "\n",
            "--- Chunk 16548 ---\n",
            "736 | Appendix A: Exercise Solutions\n",
            "\n",
            "--- Chunk 16549 ---\n",
            "example, it’s easier to split the data into multiple subsets. Lastly, if the data is split\n",
            "\n",
            "--- Chunk 16550 ---\n",
            "across multiple files spread across multiple servers, it is possible to download sev‐\n",
            "\n",
            "--- Chunk 16551 ---\n",
            "eral files from different servers simultaneously, which improves the bandwidth\n",
            "usage.\n",
            "\n",
            "--- Chunk 16552 ---\n",
            "3. You can use TensorBoard to visualize profiling data: if the GPU is not fully uti‐\n",
            "\n",
            "--- Chunk 16553 ---\n",
            "lized then your input pipeline is likely to be the bottleneck. You can fix it by mak‐\n",
            "\n",
            "--- Chunk 16554 ---\n",
            "ing sure it reads and preprocesses the data in multiple threads in parallel, and\n",
            "\n",
            "--- Chunk 16555 ---\n",
            "ensuring it prefetches a few batches. If this is insufficient to get your GPU to\n",
            "\n",
            "--- Chunk 16556 ---\n",
            "100% usage during training, make sure your preprocessing code is optimized.\n",
            "\n",
            "--- Chunk 16557 ---\n",
            "You can also try saving the dataset into multiple TFRecord files, and if necessary\n",
            "\n",
            "--- Chunk 16558 ---\n",
            "perform some of the preprocessing ahead of time so that it does not need to be\n",
            "\n",
            "--- Chunk 16559 ---\n",
            "done on the fly during training (TF Transform can help with this). If necessary,\n",
            "\n",
            "--- Chunk 16560 ---\n",
            "use a machine with more CPU and RAM, and ensure that the GPU bandwidth is\n",
            "large enough.\n",
            "\n",
            "--- Chunk 16561 ---\n",
            "4. A TFRecord file is composed of a sequence of arbitrary binary records: you can\n",
            "\n",
            "--- Chunk 16562 ---\n",
            "store absolutely any binary data you want in each record. However, in practice\n",
            "\n",
            "--- Chunk 16563 ---\n",
            "most TFRecord files contain sequences of serialized protocol buffers. This makes\n",
            "\n",
            "--- Chunk 16564 ---\n",
            "it possible to benefit from the advantages of protocol buffers, such as the fact that\n",
            "\n",
            "--- Chunk 16565 ---\n",
            "they can be read easily across multiple platforms and languages and their defini‐\n",
            "tion can be updated later in a backward-compatible way.\n",
            "\n",
            "--- Chunk 16566 ---\n",
            "5. The Example protobuf format has the advantage that TensorFlow provides some\n",
            "\n",
            "--- Chunk 16567 ---\n",
            "operations to parse it (the tf.io.parse*example() functions) without you hav‐\n",
            "\n",
            "--- Chunk 16568 ---\n",
            "ing to define your own format. It is sufficiently flexible to represent instances in\n",
            "\n",
            "--- Chunk 16569 ---\n",
            "most datasets. However, if it does not cover your use case, you can define your\n",
            "\n",
            "--- Chunk 16570 ---\n",
            "own protocol buffer, compile it using protoc (setting the --descriptor_set_out\n",
            "\n",
            "--- Chunk 16571 ---\n",
            "and --include_imports arguments to export the protobuf descriptor), and use\n",
            "\n",
            "--- Chunk 16572 ---\n",
            "the tf.io.decode_proto() function to parse the serialized protobufs (see the\n",
            "\n",
            "--- Chunk 16573 ---\n",
            "“Custom protobuf ” section of the notebook for an example). It’s more compli‐\n",
            "\n",
            "--- Chunk 16574 ---\n",
            "cated, and it requires deploying the descriptor along with the model, but it can be\n",
            "done.\n",
            "\n",
            "--- Chunk 16575 ---\n",
            "6. When using TFRecords, you will generally want to activate compression if the\n",
            "\n",
            "--- Chunk 16576 ---\n",
            "TFRecord files will need to be downloaded by the training script, as compression\n",
            "\n",
            "--- Chunk 16577 ---\n",
            "will make files smaller and thus reduce download time. But if the files are located\n",
            "\n",
            "--- Chunk 16578 ---\n",
            "on the same machine as the training script, it’s usually preferable to leave com‐\n",
            "pression off, to avoid wasting CPU for decompression.\n",
            "\n",
            "--- Chunk 16579 ---\n",
            "7. Let’s look at the pros and cons of each preprocessing option:\n",
            "• If you preprocess the data when creating the data files, the training script will\n",
            "\n",
            "--- Chunk 16580 ---\n",
            "run faster, since it will not have to perform preprocessing on the fly. In some\n",
            "\n",
            "--- Chunk 16581 ---\n",
            "cases, the preprocessed data will also be much smaller than the original data, so\n",
            "\n",
            "--- Chunk 16582 ---\n",
            "you can save some space and speed up downloads. It may also be helpful to\n",
            "\n",
            "--- Chunk 16583 ---\n",
            "Exercise Solutions | 737\n",
            "\n",
            "--- Chunk 16584 ---\n",
            "materialize the preprocessed data, for example to inspect it or archive it. How‐\n",
            "\n",
            "--- Chunk 16585 ---\n",
            "ever, this approach has a few cons. First, it’s not easy to experiment with vari‐\n",
            "\n",
            "--- Chunk 16586 ---\n",
            "ous preprocessing logics if you need to generate a preprocessed dataset for\n",
            "\n",
            "--- Chunk 16587 ---\n",
            "each variant. Second, if you want to perform data augmentation, you have to\n",
            "\n",
            "--- Chunk 16588 ---\n",
            "materialize many variants of your dataset, which will use a large amount of\n",
            "\n",
            "--- Chunk 16589 ---\n",
            "disk space and take a lot of time to generate. Lastly, the trained model will\n",
            "\n",
            "--- Chunk 16590 ---\n",
            "expect preprocessed data, so you will have to add preprocessing code in your\n",
            "application before it calls the model.\n",
            "\n",
            "--- Chunk 16591 ---\n",
            "• If the data is preprocessed with the tf.data pipeline, it’s much easier to tweak\n",
            "\n",
            "--- Chunk 16592 ---\n",
            "the preprocessing logic and apply data augmentation. Also, tf.data makes it\n",
            "\n",
            "--- Chunk 16593 ---\n",
            "easy to build highly efficient preprocessing pipelines (e.g., with multithreading\n",
            "\n",
            "--- Chunk 16594 ---\n",
            "and prefetching). However, preprocessing the data this way will slow down\n",
            "\n",
            "--- Chunk 16595 ---\n",
            "training. Moreover, each training instance will be preprocessed once per epoch\n",
            "\n",
            "--- Chunk 16596 ---\n",
            "rather than just once if the data was preprocessed when creating the data files.\n",
            "Lastly, the trained model will still expect preprocessed data.\n",
            "\n",
            "--- Chunk 16597 ---\n",
            "• If you add preprocessing layers to your model, you will only have to write the\n",
            "\n",
            "--- Chunk 16598 ---\n",
            "preprocessing code once for both training and inference. If your model needs\n",
            "\n",
            "--- Chunk 16599 ---\n",
            "to be deployed to many different platforms, you will not need to write the pre‐\n",
            "\n",
            "--- Chunk 16600 ---\n",
            "processing code multiple times. Plus, you will not run the risk of using the\n",
            "\n",
            "--- Chunk 16601 ---\n",
            "wrong preprocessing logic for your model, since it will be part of the model.\n",
            "\n",
            "--- Chunk 16602 ---\n",
            "On the downside, preprocessing the data will slow down training, and each\n",
            "training instance will be preprocessed once per epoch. Moreover, by default\n",
            "\n",
            "--- Chunk 16603 ---\n",
            "the preprocessing operations will run on the GPU for the current batch (you\n",
            "\n",
            "--- Chunk 16604 ---\n",
            "will not benefit from parallel preprocessing on the CPU, and prefetching). For‐\n",
            "\n",
            "--- Chunk 16605 ---\n",
            "tunately, the upcoming Keras preprocessing layers should be able to lift the\n",
            "\n",
            "--- Chunk 16606 ---\n",
            "preprocessing operations from the preprocessing layers and run them as part\n",
            "\n",
            "--- Chunk 16607 ---\n",
            "of the tf.data pipeline, so you will benefit from multithreaded execution on the\n",
            "CPU and prefetching.\n",
            "\n",
            "--- Chunk 16608 ---\n",
            "• Lastly, using TF Transform for preprocessing gives you many of the benefits\n",
            "\n",
            "--- Chunk 16609 ---\n",
            "from the previous options: the preprocessed data is materialized, each instance\n",
            "\n",
            "--- Chunk 16610 ---\n",
            "is preprocessed just once (speeding up training), and preprocessing layers get\n",
            "\n",
            "--- Chunk 16611 ---\n",
            "generated automatically so you only need to write the preprocessing code\n",
            "once. The main drawback is the fact that you need to learn how to use this\n",
            "\n",
            "--- Chunk 16612 ---\n",
            "tool.\n",
            "\n",
            "--- Chunk 16613 ---\n",
            "8. Let’s look at how to encode categorical features and text:\n",
            "• To encode a categorical feature that has a natural order, such as a movie rating\n",
            "\n",
            "--- Chunk 16614 ---\n",
            "(e.g., “bad,” “average,” “good”), the simplest option is to use ordinal encoding:\n",
            "\n",
            "--- Chunk 16615 ---\n",
            "sort the categories in their natural order and map each category to its rank\n",
            "\n",
            "--- Chunk 16616 ---\n",
            "(e.g., “bad” maps to 0, “average” maps to 1, and “good” maps to 2). However,\n",
            "\n",
            "--- Chunk 16617 ---\n",
            "most categorical features don’t have such a natural order. For example, there’s\n",
            "\n",
            "--- Chunk 16618 ---\n",
            "738 | Appendix A: Exercise Solutions\n",
            "\n",
            "--- Chunk 16619 ---\n",
            "no natural order for professions or countries. In this case, you can use one-hot\n",
            "encoding or, if there are many categories, embeddings.\n",
            "\n",
            "--- Chunk 16620 ---\n",
            "• For text, one option is to use a bag-of-words representation: a sentence is rep‐\n",
            "\n",
            "--- Chunk 16621 ---\n",
            "resented by a vector counting the counts of each possible word. Since common\n",
            "\n",
            "--- Chunk 16622 ---\n",
            "words are usually not very important, you’ll want to use TF-IDF to reduce\n",
            "\n",
            "--- Chunk 16623 ---\n",
            "their weight. Instead of counting words, it is also common to count n-grams,\n",
            "\n",
            "--- Chunk 16624 ---\n",
            "which are sequences of n consecutive words—nice and simple. Alternatively,\n",
            "you can encode each word using word embeddings, possibly pretrained.\n",
            "\n",
            "--- Chunk 16625 ---\n",
            "Rather than encoding words, it is also possible to encode each letter, or sub‐\n",
            "\n",
            "--- Chunk 16626 ---\n",
            "word tokens (e.g., splitting “smartest” into “smart” and “est”). These last two\n",
            "options are discussed in Chapter 16.\n",
            "\n",
            "--- Chunk 16627 ---\n",
            "For the solutions to exercises 9 and 10, please see the Jupyter notebooks available at\n",
            "https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 16628 ---\n",
            "Chapter 14: Deep Computer Vision Using Convolutional\n",
            "Neural Networks\n",
            "\n",
            "--- Chunk 16629 ---\n",
            "1. These are the main advantages of a CNN over a fully connected DNN for image\n",
            "classification:\n",
            "\n",
            "--- Chunk 16630 ---\n",
            "classification:\n",
            "• Because consecutive layers are only partially connected and because it heavily\n",
            "\n",
            "--- Chunk 16631 ---\n",
            "reuses its weights, a CNN has many fewer parameters than a fully connected\n",
            "\n",
            "--- Chunk 16632 ---\n",
            "DNN, which makes it much faster to train, reduces the risk of overfitting, and\n",
            "requires much less training data.\n",
            "\n",
            "--- Chunk 16633 ---\n",
            "• When a CNN has learned a kernel that can detect a particular feature, it can\n",
            "\n",
            "--- Chunk 16634 ---\n",
            "detect that feature anywhere in the image. In contrast, when a DNN learns a\n",
            "\n",
            "--- Chunk 16635 ---\n",
            "feature in one location, it can detect it only in that particular location. Since\n",
            "\n",
            "--- Chunk 16636 ---\n",
            "images typically have very repetitive features, CNNs are able to generalize\n",
            "\n",
            "--- Chunk 16637 ---\n",
            "much better than DNNs for image processing tasks such as classification, using\n",
            "fewer training examples.\n",
            "\n",
            "--- Chunk 16638 ---\n",
            "• Finally, a DNN has no prior knowledge of how pixels are organized; it does not\n",
            "\n",
            "--- Chunk 16639 ---\n",
            "know that nearby pixels are close. A CNN’s architecture embeds this prior\n",
            "\n",
            "--- Chunk 16640 ---\n",
            "knowledge. Lower layers typically identify features in small areas of the images,\n",
            "\n",
            "--- Chunk 16641 ---\n",
            "while higher layers combine the lower-level features into larger features. This\n",
            "\n",
            "--- Chunk 16642 ---\n",
            "works well with most natural images, giving CNNs a decisive head start com‐\n",
            "pared to DNNs.\n",
            "\n",
            "--- Chunk 16643 ---\n",
            "2. Let’s compute how many parameters the CNN has. Since its first convolutional\n",
            "\n",
            "--- Chunk 16644 ---\n",
            "layer has 3 × 3 kernels, and the input has three channels (red, green, and blue),\n",
            "\n",
            "--- Chunk 16645 ---\n",
            "each feature map has 3 × 3 × 3 weights, plus a bias term. That’s 28 parameters per\n",
            "\n",
            "--- Chunk 16646 ---\n",
            "Exercise Solutions | 739\n",
            "\n",
            "--- Chunk 16647 ---\n",
            "feature map. Since this first convolutional layer has 100 feature maps, it has a\n",
            "\n",
            "--- Chunk 16648 ---\n",
            "total of 2,800 parameters. The second convolutional layer has 3 × 3 kernels and\n",
            "\n",
            "--- Chunk 16649 ---\n",
            "its input is the set of 100 feature maps of the previous layer, so each feature map\n",
            "\n",
            "--- Chunk 16650 ---\n",
            "has 3 × 3 × 100 = 900 weights, plus a bias term. Since it has 200 feature maps, this\n",
            "\n",
            "--- Chunk 16651 ---\n",
            "layer has 901 × 200 = 180,200 parameters. Finally, the third and last convolu‐\n",
            "\n",
            "--- Chunk 16652 ---\n",
            "tional layer also has 3 × 3 kernels, and its input is the set of 200 feature maps of\n",
            "\n",
            "--- Chunk 16653 ---\n",
            "the previous layers, so each feature map has 3 × 3 × 200 = 1,800 weights, plus a\n",
            "\n",
            "--- Chunk 16654 ---\n",
            "bias term. Since it has 400 feature maps, this layer has a total of 1,801 × 400 =\n",
            "\n",
            "--- Chunk 16655 ---\n",
            "720,400 parameters. All in all, the CNN has 2,800 + 180,200 + 720,400 = 903,400\n",
            "parameters.\n",
            "\n",
            "--- Chunk 16656 ---\n",
            "parameters.\n",
            "Now let’s compute how much RAM this neural network will require (at least)\n",
            "\n",
            "--- Chunk 16657 ---\n",
            "when making a prediction for a single instance. First let’s compute the feature\n",
            "\n",
            "--- Chunk 16658 ---\n",
            "map size for each layer. Since we are using a stride of 2 and \"same\" padding, the\n",
            "\n",
            "--- Chunk 16659 ---\n",
            "horizontal and vertical dimensions of the feature maps are divided by 2 at each\n",
            "\n",
            "--- Chunk 16660 ---\n",
            "layer (rounding up if necessary). So, as the input channels are 200 × 300 pixels,\n",
            "\n",
            "--- Chunk 16661 ---\n",
            "the first layer’s feature maps are 100 × 150, the second layer’s feature maps are 50\n",
            "\n",
            "--- Chunk 16662 ---\n",
            "× 75, and the third layer’s feature maps are 25 × 38. Since 32 bits is 4 bytes and\n",
            "\n",
            "--- Chunk 16663 ---\n",
            "the first convolutional layer has 100 feature maps, this first layer takes up 4 × 100\n",
            "\n",
            "--- Chunk 16664 ---\n",
            "× 150 × 100 = 6 million bytes (6 MB). The second layer takes up 4 × 50 × 75 ×\n",
            "\n",
            "--- Chunk 16665 ---\n",
            "200 = 3 million bytes (3 MB). Finally, the third layer takes up 4 × 25 × 38 × 400 =\n",
            "\n",
            "--- Chunk 16666 ---\n",
            "1,520,000 bytes (about 1.5 MB). However, once a layer has been computed, the\n",
            "\n",
            "--- Chunk 16667 ---\n",
            "memory occupied by the previous layer can be released, so if everything is well\n",
            "\n",
            "--- Chunk 16668 ---\n",
            "optimized, only 6 + 3 = 9 million bytes (9 MB) of RAM will be required (when\n",
            "\n",
            "--- Chunk 16669 ---\n",
            "the second layer has just been computed, but the memory occupied by the first\n",
            "\n",
            "--- Chunk 16670 ---\n",
            "layer has not been released yet). But wait, you also need to add the memory occu‐\n",
            "\n",
            "--- Chunk 16671 ---\n",
            "pied by the CNN’s parameters! We computed earlier that it has 903,400 parame‐\n",
            "\n",
            "--- Chunk 16672 ---\n",
            "ters, each using up 4 bytes, so this adds 3,613,600 bytes (about 3.6 MB). The total\n",
            "\n",
            "--- Chunk 16673 ---\n",
            "RAM required is therefore (at least) 12,613,600 bytes (about 12.6 MB).\n",
            "Lastly, let’s compute the minimum amount of RAM required when training the\n",
            "\n",
            "--- Chunk 16674 ---\n",
            "CNN on a mini-batch of 50 images. During training TensorFlow uses backpropa‐\n",
            "\n",
            "--- Chunk 16675 ---\n",
            "gation, which requires keeping all values computed during the forward pass until\n",
            "\n",
            "--- Chunk 16676 ---\n",
            "the reverse pass begins. So we must compute the total RAM required by all layers\n",
            "\n",
            "--- Chunk 16677 ---\n",
            "for a single instance and multiply that by 50. At this point, let’s start counting in\n",
            "\n",
            "--- Chunk 16678 ---\n",
            "megabytes rather than bytes. We computed before that the three layers require\n",
            "\n",
            "--- Chunk 16679 ---\n",
            "respectively 6, 3, and 1.5 MB for each instance. That’s a total of 10.5 MB per\n",
            "\n",
            "--- Chunk 16680 ---\n",
            "instance, so for 50 instances the total RAM required is 525 MB. Add to that the\n",
            "\n",
            "--- Chunk 16681 ---\n",
            "RAM required by the input images, which is 50 × 4 × 200 × 300 × 3 = 36 million\n",
            "\n",
            "--- Chunk 16682 ---\n",
            "bytes (36 MB), plus the RAM required for the model parameters, which is about\n",
            "\n",
            "--- Chunk 16683 ---\n",
            "3.6 MB (computed earlier), plus some RAM for the gradients (we will neglect this\n",
            "\n",
            "--- Chunk 16684 ---\n",
            "since it can be released gradually as backpropagation goes down the layers during\n",
            "\n",
            "--- Chunk 16685 ---\n",
            "the reverse pass). We are up to a total of roughly 525 + 36 + 3.6 = 564.6 MB, and\n",
            "that’s really an optimistic bare minimum.\n",
            "\n",
            "--- Chunk 16686 ---\n",
            "740 | Appendix A: Exercise Solutions\n",
            "\n",
            "--- Chunk 16687 ---\n",
            "3. If your GPU runs out of memory while training a CNN, here are five things you\n",
            "\n",
            "--- Chunk 16688 ---\n",
            "could try to solve the problem (other than purchasing a GPU with more RAM):\n",
            "• Reduce the mini-batch size.\n",
            "\n",
            "--- Chunk 16689 ---\n",
            "• Reduce dimensionality using a larger stride in one or more layers.\n",
            "• Remove one or more layers.\n",
            "• Use 16-bit floats instead of 32-bit floats.\n",
            "\n",
            "--- Chunk 16690 ---\n",
            "• Distribute the CNN across multiple devices.\n",
            "\n",
            "--- Chunk 16691 ---\n",
            "4. A max pooling layer has no parameters at all, whereas a convolutional layer has\n",
            "quite a few (see the previous questions).\n",
            "\n",
            "--- Chunk 16692 ---\n",
            "5. A local response normalization layer makes the neurons that most strongly acti‐\n",
            "\n",
            "--- Chunk 16693 ---\n",
            "vate inhibit neurons at the same location but in neighboring feature maps, which\n",
            "\n",
            "--- Chunk 16694 ---\n",
            "encourages different feature maps to specialize and pushes them apart, forcing\n",
            "\n",
            "--- Chunk 16695 ---\n",
            "them to explore a wider range of features. It is typically used in the lower layers to\n",
            "\n",
            "--- Chunk 16696 ---\n",
            "have a larger pool of low-level features that the upper layers can build upon.\n",
            "\n",
            "--- Chunk 16697 ---\n",
            "6. The main innovations in AlexNet compared to LeNet-5 are that it is much larger\n",
            "\n",
            "--- Chunk 16698 ---\n",
            "and deeper, and it stacks convolutional layers directly on top of each other,\n",
            "\n",
            "--- Chunk 16699 ---\n",
            "instead of stacking a pooling layer on top of each convolutional layer. The main\n",
            "\n",
            "--- Chunk 16700 ---\n",
            "innovation in GoogLeNet is the introduction of inception modules, which make it\n",
            "\n",
            "--- Chunk 16701 ---\n",
            "possible to have a much deeper net than previous CNN architectures, with fewer\n",
            "\n",
            "--- Chunk 16702 ---\n",
            "parameters. ResNet’s main innovation is the introduction of skip connections,\n",
            "\n",
            "--- Chunk 16703 ---\n",
            "which make it possible to go well beyond 100 layers. Arguably, its simplicity and\n",
            "\n",
            "--- Chunk 16704 ---\n",
            "consistency are also rather innovative. SENet’s main innovation was the idea of\n",
            "\n",
            "--- Chunk 16705 ---\n",
            "using an SE block (a two-layer dense network) after every inception module in\n",
            "\n",
            "--- Chunk 16706 ---\n",
            "an inception network or every residual unit in a ResNet to recalibrate the relative\n",
            "\n",
            "--- Chunk 16707 ---\n",
            "importance of feature maps. Finally, Xception’s main innovation was the use of\n",
            "\n",
            "--- Chunk 16708 ---\n",
            "depthwise separable convolutional layers, which look at spatial patterns and\n",
            "depthwise patterns separately.\n",
            "\n",
            "--- Chunk 16709 ---\n",
            "7. Fully convolutional networks are neural networks composed exclusively of con‐\n",
            "\n",
            "--- Chunk 16710 ---\n",
            "volutional and pooling layers. FCNs can efficiently process images of any width\n",
            "\n",
            "--- Chunk 16711 ---\n",
            "and height (at least above the minimum size). They are most useful for object\n",
            "\n",
            "--- Chunk 16712 ---\n",
            "detection and semantic segmentation because they only need to look at the image\n",
            "\n",
            "--- Chunk 16713 ---\n",
            "once (instead of having to run a CNN multiple times on different parts of the\n",
            "\n",
            "--- Chunk 16714 ---\n",
            "image). If you have a CNN with some dense layers on top, you can convert these\n",
            "\n",
            "--- Chunk 16715 ---\n",
            "dense layers to convolutional layers to create an FCN: just replace the lowest\n",
            "\n",
            "--- Chunk 16716 ---\n",
            "dense layer with a convolutional layer with a kernel size equal to the layer’s input\n",
            "\n",
            "--- Chunk 16717 ---\n",
            "size, with one filter per neuron in the dense layer, and using \"valid\" padding.\n",
            "\n",
            "--- Chunk 16718 ---\n",
            "Generally the stride should be 1, but you can set it to a higher value if you want.\n",
            "\n",
            "--- Chunk 16719 ---\n",
            "The activation function should be the same as the dense layer’s. The other dense\n",
            "\n",
            "--- Chunk 16720 ---\n",
            "layers should be converted the same way, but using 1 × 1 filters. It is actually pos‐\n",
            "\n",
            "--- Chunk 16721 ---\n",
            "Exercise Solutions | 741\n",
            "\n",
            "\n",
            "\n",
            "sible to convert a trained CNN this way by appropriately reshaping the dense lay‐\n",
            "ers’ weight matrices.\n",
            "\n",
            "--- Chunk 16722 ---\n",
            "8. The main technical difficulty of semantic segmentation is the fact that a lot of the\n",
            "\n",
            "--- Chunk 16723 ---\n",
            "spatial information gets lost in a CNN as the signal flows through each layer,\n",
            "\n",
            "--- Chunk 16724 ---\n",
            "especially in pooling layers and layers with a stride greater than 1. This spatial\n",
            "\n",
            "--- Chunk 16725 ---\n",
            "information needs to be restored somehow to accurately predict the class of each\n",
            "pixel.\n",
            "\n",
            "--- Chunk 16726 ---\n",
            "For the solutions to exercises 9 to 12, please see the Jupyter notebooks available at\n",
            "https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 16727 ---\n",
            "Chapter 15: Processing Sequences Using RNNs and CNNs\n",
            "1. Here are a few RNN applications:\n",
            "\n",
            "--- Chunk 16728 ---\n",
            "• For a sequence-to-sequence RNN: predicting the weather (or any other time\n",
            "\n",
            "--- Chunk 16729 ---\n",
            "series), machine translation (using an Encoder–Decoder architecture), video\n",
            "\n",
            "--- Chunk 16730 ---\n",
            "captioning, speech to text, music generation (or other sequence generation),\n",
            "identifying the chords of a song\n",
            "\n",
            "--- Chunk 16731 ---\n",
            "• For a sequence-to-vector RNN: classifying music samples by music genre, ana‐\n",
            "\n",
            "--- Chunk 16732 ---\n",
            "lyzing the sentiment of a book review, predicting what word an aphasic patient\n",
            "\n",
            "--- Chunk 16733 ---\n",
            "is thinking of based on readings from brain implants, predicting the probabil‐\n",
            "\n",
            "--- Chunk 16734 ---\n",
            "ity that a user will want to watch a movie based on their watch history (this is\n",
            "\n",
            "--- Chunk 16735 ---\n",
            "one of many possible implementations of collaborative filtering for a recom‐\n",
            "mender system)\n",
            "\n",
            "--- Chunk 16736 ---\n",
            "• For a vector-to-sequence RNN: image captioning, creating a music playlist\n",
            "\n",
            "--- Chunk 16737 ---\n",
            "based on an embedding of the current artist, generating a melody based on a\n",
            "\n",
            "--- Chunk 16738 ---\n",
            "set of parameters, locating pedestrians in a picture (e.g., a video frame from a\n",
            "self-driving car’s camera)\n",
            "\n",
            "--- Chunk 16739 ---\n",
            "2. An RNN layer must have three-dimensional inputs: the first dimension is the\n",
            "\n",
            "--- Chunk 16740 ---\n",
            "batch dimension (its size is the batch size), the second dimension represents the\n",
            "\n",
            "--- Chunk 16741 ---\n",
            "time (its size is the number of time steps), and the third dimension holds the\n",
            "\n",
            "--- Chunk 16742 ---\n",
            "inputs at each time step (its size is the number of input features per time step).\n",
            "\n",
            "--- Chunk 16743 ---\n",
            "For example, if you want to process a batch containing 5 time series of 10 time\n",
            "\n",
            "--- Chunk 16744 ---\n",
            "steps each, with 2 values per time step (e.g., the temperature and the wind speed),\n",
            "\n",
            "--- Chunk 16745 ---\n",
            "the shape will be [5, 10, 2]. The outputs are also three-dimensional, with the\n",
            "\n",
            "--- Chunk 16746 ---\n",
            "same first two dimensions, but the last dimension is equal to the number of\n",
            "\n",
            "--- Chunk 16747 ---\n",
            "neurons. For example, if an RNN layer with 32 neurons processes the batch we\n",
            "just discussed, the output will have a shape of [5, 10, 32].\n",
            "\n",
            "--- Chunk 16748 ---\n",
            "742 | Appendix A: Exercise Solutions\n",
            "\n",
            "--- Chunk 16749 ---\n",
            "3. To build a deep sequence-to-sequence RNN using Keras, you must set\n",
            "return_sequences=True for all RNN layers. To build a sequence-to-vector RNN,\n",
            "\n",
            "--- Chunk 16750 ---\n",
            "you must set return_sequences=True for all RNN layers except for the top RNN\n",
            "\n",
            "--- Chunk 16751 ---\n",
            "layer, which must have return_sequences=False (or do not set this argument at\n",
            "all, since False is the default).\n",
            "\n",
            "--- Chunk 16752 ---\n",
            "4. If you have a daily univariate time series, and you want to forecast the next seven\n",
            "\n",
            "--- Chunk 16753 ---\n",
            "days, the simplest RNN architecture you can use is a stack of RNN layers (all with\n",
            "\n",
            "--- Chunk 16754 ---\n",
            "return_sequences=True except for the top RNN layer), using seven neurons in\n",
            "the output RNN layer. You can then train this model using random windows\n",
            "\n",
            "--- Chunk 16755 ---\n",
            "from the time series (e.g., sequences of 30 consecutive days as the inputs, and a\n",
            "\n",
            "--- Chunk 16756 ---\n",
            "vector containing the values of the next 7 days as the target). This is a sequence-\n",
            "\n",
            "--- Chunk 16757 ---\n",
            "to-vector RNN. Alternatively, you could set return_sequences=True for all RNN\n",
            "\n",
            "--- Chunk 16758 ---\n",
            "layers to create a sequence-to-sequence RNN. You can train this model using\n",
            "\n",
            "--- Chunk 16759 ---\n",
            "random windows from the time series, with sequences of the same length as the\n",
            "\n",
            "--- Chunk 16760 ---\n",
            "inputs as the targets. Each target sequence should have seven values per time step\n",
            "\n",
            "--- Chunk 16761 ---\n",
            "(e.g., for time step t, the target should be a vector containing the values at time\n",
            "steps t + 1 to t + 7).\n",
            "\n",
            "--- Chunk 16762 ---\n",
            "5. The two main difficulties when training RNNs are unstable gradients (exploding\n",
            "\n",
            "--- Chunk 16763 ---\n",
            "or vanishing) and a very limited short-term memory. These problems both get\n",
            "\n",
            "--- Chunk 16764 ---\n",
            "worse when dealing with long sequences. To alleviate the unstable gradients\n",
            "\n",
            "--- Chunk 16765 ---\n",
            "problem, you can use a smaller learning rate, use a saturating activation function\n",
            "\n",
            "--- Chunk 16766 ---\n",
            "such as the hyperbolic tangent (which is the default), and possibly use gradient\n",
            "\n",
            "--- Chunk 16767 ---\n",
            "clipping, Layer Normalization, or dropout at each time step. To tackle the limited\n",
            "\n",
            "--- Chunk 16768 ---\n",
            "short-term memory problem, you can use LSTM or GRU layers (this also helps with\n",
            "the unstable gradients problem).\n",
            "\n",
            "--- Chunk 16769 ---\n",
            "6. An LSTM cell’s architecture looks complicated, but it’s actually not too hard if\n",
            "\n",
            "--- Chunk 16770 ---\n",
            "you understand the underlying logic. The cell has a short-term state vector and a\n",
            "\n",
            "--- Chunk 16771 ---\n",
            "long-term state vector. At each time step, the inputs and the previous short-term\n",
            "\n",
            "--- Chunk 16772 ---\n",
            "state are fed to a simple RNN cell and three gates: the forget gate decides what to\n",
            "\n",
            "--- Chunk 16773 ---\n",
            "remove from the long-term state, the input gate decides which part of the output\n",
            "\n",
            "--- Chunk 16774 ---\n",
            "of the simple RNN cell should be added to the long-term state, and the output\n",
            "\n",
            "--- Chunk 16775 ---\n",
            "gate decides which part of the long-term state should be output at this time step\n",
            "\n",
            "--- Chunk 16776 ---\n",
            "(after going through the tanh activation function). The new short-term state is\n",
            "equal to the output of the cell. See Figure 15-9.\n",
            "\n",
            "--- Chunk 16777 ---\n",
            "7. An RNN layer is fundamentally sequential: in order to compute the outputs at\n",
            "\n",
            "--- Chunk 16778 ---\n",
            "time step t, it has to first compute the outputs at all earlier time steps. This makes\n",
            "\n",
            "--- Chunk 16779 ---\n",
            "it impossible to parallelize. On the other hand, a 1D convolutional layer lends\n",
            "\n",
            "--- Chunk 16780 ---\n",
            "itself well to parallelization since it does not hold a state between time steps. In\n",
            "\n",
            "--- Chunk 16781 ---\n",
            "other words, it has no memory: the output at any time step can be computed\n",
            "\n",
            "--- Chunk 16782 ---\n",
            "based only on a small window of values from the inputs without having to know\n",
            "\n",
            "--- Chunk 16783 ---\n",
            "all the past values. Moreover, since a 1D convolutional layer is not recurrent, it\n",
            "\n",
            "--- Chunk 16784 ---\n",
            "Exercise Solutions | 743\n",
            "\n",
            "--- Chunk 16785 ---\n",
            "suffers less from unstable gradients. One or more 1D convolutional layers can be\n",
            "\n",
            "--- Chunk 16786 ---\n",
            "useful in an RNN to efficiently preprocess the inputs, for example to reduce their\n",
            "\n",
            "--- Chunk 16787 ---\n",
            "temporal resolution (downsampling) and thereby help the RNN layers detect\n",
            "\n",
            "--- Chunk 16788 ---\n",
            "long-term patterns. In fact, it is possible to use only convolutional layers, for\n",
            "example by building a WaveNet architecture.\n",
            "\n",
            "--- Chunk 16789 ---\n",
            "8. To classify videos based on their visual content, one possible architecture could\n",
            "\n",
            "--- Chunk 16790 ---\n",
            "be to take (say) one frame per second, then run every frame through the same\n",
            "\n",
            "--- Chunk 16791 ---\n",
            "convolutional neural network (e.g., a pretrained Xception model, possibly frozen\n",
            "\n",
            "--- Chunk 16792 ---\n",
            "if your dataset is not large), feed the sequence of outputs from the CNN to a\n",
            "\n",
            "--- Chunk 16793 ---\n",
            "sequence-to-vector RNN, and finally run its output through a softmax layer, giv‐\n",
            "\n",
            "--- Chunk 16794 ---\n",
            "ing you all the class probabilities. For training you would use cross entropy as the\n",
            "\n",
            "--- Chunk 16795 ---\n",
            "cost function. If you wanted to use the audio for classification as well, you could\n",
            "\n",
            "--- Chunk 16796 ---\n",
            "use a stack of strided 1D convolutional layers to reduce the temporal resolution\n",
            "\n",
            "--- Chunk 16797 ---\n",
            "from thousands of audio frames per second to just one per second (to match the\n",
            "\n",
            "--- Chunk 16798 ---\n",
            "number of images per second), and concatenate the output sequence to the\n",
            "inputs of the sequence-to-vector RNN (along the last dimension).\n",
            "\n",
            "--- Chunk 16799 ---\n",
            "For the solutions to exercises 9 and 10, please see the Jupyter notebooks available at\n",
            "https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 16800 ---\n",
            "Chapter 16: Natural Language Processing with RNNs and\n",
            "Attention\n",
            "\n",
            "--- Chunk 16801 ---\n",
            "1. Stateless RNNs can only capture patterns whose length is less than, or equal to,\n",
            "\n",
            "--- Chunk 16802 ---\n",
            "the size of the windows the RNN is trained on. Conversely, stateful RNNs can\n",
            "\n",
            "--- Chunk 16803 ---\n",
            "capture longer-term patterns. However, implementing a stateful RNN is much\n",
            "\n",
            "--- Chunk 16804 ---\n",
            "harder—especially preparing the dataset properly. Moreover, stateful RNNs do\n",
            "\n",
            "--- Chunk 16805 ---\n",
            "not always work better, in part because consecutive batches are not independent\n",
            "\n",
            "--- Chunk 16806 ---\n",
            "and identically distributed (IID). Gradient Descent is not fond of non-IID\n",
            "datasets.\n",
            "\n",
            "--- Chunk 16807 ---\n",
            "2. In general, if you translate a sentence one word at a time, the result will be terri‐\n",
            "\n",
            "--- Chunk 16808 ---\n",
            "ble. For example, the French sentence “Je vous en prie” means “You are welcome,”\n",
            "\n",
            "--- Chunk 16809 ---\n",
            "but if you translate it one word at a time, you get “I you in pray.” Huh? It is much\n",
            "\n",
            "--- Chunk 16810 ---\n",
            "better to read the whole sentence first and then translate it. A plain sequence-to-\n",
            "\n",
            "--- Chunk 16811 ---\n",
            "sequence RNN would start translating a sentence immediately after reading the\n",
            "\n",
            "--- Chunk 16812 ---\n",
            "first word, while an Encoder–Decoder RNN will first read the whole sentence\n",
            "\n",
            "--- Chunk 16813 ---\n",
            "and then translate it. That said, one could imagine a plain sequence-to-sequence\n",
            "\n",
            "--- Chunk 16814 ---\n",
            "RNN that would output silence whenever it is unsure about what to say next (just\n",
            "\n",
            "--- Chunk 16815 ---\n",
            "like human translators do when they must translate a live broadcast).\n",
            "\n",
            "--- Chunk 16816 ---\n",
            "3. Variable-length input sequences can be handled by padding the shorter sequen‐\n",
            "\n",
            "--- Chunk 16817 ---\n",
            "ces so that all sequences in a batch have the same length, and using masking to\n",
            "\n",
            "--- Chunk 16818 ---\n",
            "744 | Appendix A: Exercise Solutions\n",
            "\n",
            "--- Chunk 16819 ---\n",
            "ensure the RNN ignores the padding token. For better performance, you may\n",
            "\n",
            "--- Chunk 16820 ---\n",
            "also want to create batches containing sequences of similar sizes. Ragged tensors\n",
            "\n",
            "--- Chunk 16821 ---\n",
            "can hold sequences of variable lengths, and tf.keras will likely support them even‐\n",
            "\n",
            "--- Chunk 16822 ---\n",
            "tually, which will greatly simplify handling variable-length input sequences (at\n",
            "\n",
            "--- Chunk 16823 ---\n",
            "the time of this writing, it is not the case yet). Regarding variable-length output\n",
            "\n",
            "--- Chunk 16824 ---\n",
            "sequences, if the length of the output sequence is known in advance (e.g., if you\n",
            "\n",
            "--- Chunk 16825 ---\n",
            "know that it is the same as the input sequence), then you just need to configure\n",
            "\n",
            "--- Chunk 16826 ---\n",
            "the loss function so that it ignores tokens that come after the end of the sequence.\n",
            "\n",
            "--- Chunk 16827 ---\n",
            "Similarly, the code that will use the model should ignore tokens beyond the end\n",
            "\n",
            "--- Chunk 16828 ---\n",
            "of the sequence. But generally the length of the output sequence is not known\n",
            "\n",
            "--- Chunk 16829 ---\n",
            "ahead of time, so the solution is to train the model so that it outputs an end-of-\n",
            "sequence token at the end of each sequence.\n",
            "\n",
            "--- Chunk 16830 ---\n",
            "4. Beam search is a technique used to improve the performance of a trained\n",
            "\n",
            "--- Chunk 16831 ---\n",
            "Encoder–Decoder model, for example in a neural machine translation system.\n",
            "\n",
            "--- Chunk 16832 ---\n",
            "The algorithm keeps track of a short list of the k most promising output senten‐\n",
            "\n",
            "--- Chunk 16833 ---\n",
            "ces (say, the top three), and at each decoder step it tries to extend them by one\n",
            "\n",
            "--- Chunk 16834 ---\n",
            "word; then it keeps only the k most likely sentences. The parameter k is called the\n",
            "\n",
            "--- Chunk 16835 ---\n",
            "beam width: the larger it is, the more CPU and RAM will be used, but also the\n",
            "\n",
            "--- Chunk 16836 ---\n",
            "more accurate the system will be. Instead of greedily choosing the most likely\n",
            "\n",
            "--- Chunk 16837 ---\n",
            "next word at each step to extend a single sentence, this technique allows the sys‐\n",
            "\n",
            "--- Chunk 16838 ---\n",
            "tem to explore several promising sentences simultaneously. Moreover, this tech‐\n",
            "\n",
            "--- Chunk 16839 ---\n",
            "nique lends itself well to parallelization. You can implement beam search fairly\n",
            "easily using TensorFlow Addons.\n",
            "\n",
            "--- Chunk 16840 ---\n",
            "5. An attention mechanism is a technique initially used in Encoder–Decoder mod‐\n",
            "\n",
            "--- Chunk 16841 ---\n",
            "els to give the decoder more direct access to the input sequence, allowing it to\n",
            "\n",
            "--- Chunk 16842 ---\n",
            "deal with longer input sequences. At each decoder time step, the current decod‐\n",
            "\n",
            "--- Chunk 16843 ---\n",
            "er’s state and the full output of the encoder are processed by an alignment model\n",
            "\n",
            "--- Chunk 16844 ---\n",
            "that outputs an alignment score for each input time step. This score indicates\n",
            "\n",
            "--- Chunk 16845 ---\n",
            "which part of the input is most relevant to the current decoder time step. The\n",
            "\n",
            "--- Chunk 16846 ---\n",
            "weighted sum of the encoder output (weighted by their alignment score) is then\n",
            "\n",
            "--- Chunk 16847 ---\n",
            "fed to the decoder, which produces the next decoder state and the output for this\n",
            "\n",
            "--- Chunk 16848 ---\n",
            "time step. The main benefit of using an attention mechanism is the fact that the\n",
            "\n",
            "--- Chunk 16849 ---\n",
            "Encoder–Decoder model can successfully process longer input sequences.\n",
            "\n",
            "--- Chunk 16850 ---\n",
            "Another benefit is that the alignment scores makes the model easier to debug and\n",
            "\n",
            "--- Chunk 16851 ---\n",
            "interpret: for example, if the model makes a mistake, you can look at which part\n",
            "\n",
            "--- Chunk 16852 ---\n",
            "of the input it was paying attention to, and this can help diagnose the issue. An\n",
            "\n",
            "--- Chunk 16853 ---\n",
            "attention mechanism is also at the core of the Transformer architecture, in the\n",
            "Multi-Head Attention layers. See the next answer.\n",
            "\n",
            "--- Chunk 16854 ---\n",
            "6. The most important layer in the Transformer architecture is the Multi-Head\n",
            "\n",
            "--- Chunk 16855 ---\n",
            "Attention layer (the original Transformer architecture contains 18 of them,\n",
            "\n",
            "--- Chunk 16856 ---\n",
            "including 6 Masked Multi-Head Attention layers). It is at the core of language\n",
            "\n",
            "--- Chunk 16857 ---\n",
            "Exercise Solutions | 745\n",
            "\n",
            "--- Chunk 16858 ---\n",
            "models such as BERT and GPT-2. Its purpose is to allow the model to identify\n",
            "\n",
            "--- Chunk 16859 ---\n",
            "which words are most aligned with each other, and then improve each word’s\n",
            "representation using these contextual clues.\n",
            "\n",
            "--- Chunk 16860 ---\n",
            "7. Sampled softmax is used when training a classification model when there are\n",
            "\n",
            "--- Chunk 16861 ---\n",
            "many classes (e.g., thousands). It computes an approximation of the cross-\n",
            "\n",
            "--- Chunk 16862 ---\n",
            "entropy loss based on the logit predicted by the model for the correct class, and\n",
            "\n",
            "--- Chunk 16863 ---\n",
            "the predicted logits for a sample of incorrect words. This speeds up training con‐\n",
            "\n",
            "--- Chunk 16864 ---\n",
            "siderably compared to computing the softmax over all logits and then estimating\n",
            "\n",
            "--- Chunk 16865 ---\n",
            "the cross-entropy loss. After training, the model can be used normally, using the\n",
            "\n",
            "--- Chunk 16866 ---\n",
            "regular softmax function to compute all the class probabilities based on all the\n",
            "logits.\n",
            "\n",
            "--- Chunk 16867 ---\n",
            "For the solutions to exercises 8 to 11, please see the Jupyter notebooks available at\n",
            "https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 16868 ---\n",
            "Chapter 17: Representation Learning and Generative\n",
            "Learning Using Autoencoders and GANs\n",
            "\n",
            "--- Chunk 16869 ---\n",
            "1. Here are some of the main tasks that autoencoders are used for:\n",
            "• Feature extraction\n",
            "• Unsupervised pretraining\n",
            "• Dimensionality reduction\n",
            "\n",
            "--- Chunk 16870 ---\n",
            "• Generative models\n",
            "• Anomaly detection (an autoencoder is generally bad at reconstructing outliers)\n",
            "\n",
            "--- Chunk 16871 ---\n",
            "2. If you want to train a classifier and you have plenty of unlabeled training data but\n",
            "\n",
            "--- Chunk 16872 ---\n",
            "only a few thousand labeled instances, then you could first train a deep autoen‐\n",
            "\n",
            "--- Chunk 16873 ---\n",
            "coder on the full dataset (labeled + unlabeled), then reuse its lower half for the\n",
            "\n",
            "--- Chunk 16874 ---\n",
            "classifier (i.e., reuse the layers up to the codings layer, included) and train the\n",
            "\n",
            "--- Chunk 16875 ---\n",
            "classifier using the labeled data. If you have little labeled data, you probably want\n",
            "to freeze the reused layers when training the classifier.\n",
            "\n",
            "--- Chunk 16876 ---\n",
            "3. The fact that an autoencoder perfectly reconstructs its inputs does not necessarily\n",
            "\n",
            "--- Chunk 16877 ---\n",
            "mean that it is a good autoencoder; perhaps it is simply an overcomplete autoen‐\n",
            "\n",
            "--- Chunk 16878 ---\n",
            "coder that learned to copy its inputs to the codings layer and then to the outputs.\n",
            "\n",
            "--- Chunk 16879 ---\n",
            "In fact, even if the codings layer contained a single neuron, it would be possible\n",
            "\n",
            "--- Chunk 16880 ---\n",
            "for a very deep autoencoder to learn to map each training instance to a different\n",
            "\n",
            "--- Chunk 16881 ---\n",
            "coding (e.g., the first instance could be mapped to 0.001, the second to 0.002, the\n",
            "\n",
            "--- Chunk 16882 ---\n",
            "third to 0.003, and so on), and it could learn “by heart” to reconstruct the right\n",
            "\n",
            "--- Chunk 16883 ---\n",
            "training instance for each coding. It would perfectly reconstruct its inputs\n",
            "\n",
            "--- Chunk 16884 ---\n",
            "746 | Appendix A: Exercise Solutions\n",
            "\n",
            "--- Chunk 16885 ---\n",
            "without really learning any useful pattern in the data. In practice such a mapping\n",
            "\n",
            "--- Chunk 16886 ---\n",
            "is unlikely to happen, but it illustrates the fact that perfect reconstructions are not\n",
            "\n",
            "--- Chunk 16887 ---\n",
            "a guarantee that the autoencoder learned anything useful. However, if it produces\n",
            "\n",
            "--- Chunk 16888 ---\n",
            "very bad reconstructions, then it is almost guaranteed to be a bad autoencoder.\n",
            "\n",
            "--- Chunk 16889 ---\n",
            "To evaluate the performance of an autoencoder, one option is to measure the\n",
            "\n",
            "--- Chunk 16890 ---\n",
            "reconstruction loss (e.g., compute the MSE, or the mean square of the outputs\n",
            "\n",
            "--- Chunk 16891 ---\n",
            "minus the inputs). Again, a high reconstruction loss is a good sign that the\n",
            "\n",
            "--- Chunk 16892 ---\n",
            "autoencoder is bad, but a low reconstruction loss is not a guarantee that it is\n",
            "\n",
            "--- Chunk 16893 ---\n",
            "good. You should also evaluate the autoencoder according to what it will be used\n",
            "\n",
            "--- Chunk 16894 ---\n",
            "for. For example, if you are using it for unsupervised pretraining of a classifier,\n",
            "then you should also evaluate the classifier’s performance.\n",
            "\n",
            "--- Chunk 16895 ---\n",
            "4. An undercomplete autoencoder is one whose codings layer is smaller than the\n",
            "\n",
            "--- Chunk 16896 ---\n",
            "input and output layers. If it is larger, then it is an overcomplete autoencoder.\n",
            "\n",
            "--- Chunk 16897 ---\n",
            "The main risk of an excessively undercomplete autoencoder is that it may fail to\n",
            "\n",
            "--- Chunk 16898 ---\n",
            "reconstruct the inputs. The main risk of an overcomplete autoencoder is that it\n",
            "\n",
            "--- Chunk 16899 ---\n",
            "may just copy the inputs to the outputs, without learning any useful features.\n",
            "\n",
            "--- Chunk 16900 ---\n",
            "5. To tie the weights of an encoder layer and its corresponding decoder layer, you\n",
            "\n",
            "--- Chunk 16901 ---\n",
            "simply make the decoder weights equal to the transpose of the encoder weights.\n",
            "\n",
            "--- Chunk 16902 ---\n",
            "This reduces the number of parameters in the model by half, often making train‐\n",
            "\n",
            "--- Chunk 16903 ---\n",
            "ing converge faster with less training data and reducing the risk of overfitting the\n",
            "training set.\n",
            "\n",
            "--- Chunk 16904 ---\n",
            "6. A generative model is a model capable of randomly generating outputs that\n",
            "\n",
            "--- Chunk 16905 ---\n",
            "resemble the training instances. For example, once trained successfully on the\n",
            "\n",
            "--- Chunk 16906 ---\n",
            "MNIST dataset, a generative model can be used to randomly generate realistic\n",
            "\n",
            "--- Chunk 16907 ---\n",
            "images of digits. The output distribution is typically similar to the training data.\n",
            "\n",
            "--- Chunk 16908 ---\n",
            "For example, since MNIST contains many images of each digit, the generative\n",
            "model would output roughly the same number of images of each digit. Some\n",
            "\n",
            "--- Chunk 16909 ---\n",
            "generative models can be parametrized—for example, to generate only some\n",
            "kinds of outputs. An example of a generative autoencoder is the variational\n",
            "\n",
            "--- Chunk 16910 ---\n",
            "autoencoder.\n",
            "\n",
            "--- Chunk 16911 ---\n",
            "7. A generative adversarial network is a neural network architecture composed of\n",
            "\n",
            "--- Chunk 16912 ---\n",
            "two parts, the generator and the discriminator, which have opposing objectives.\n",
            "\n",
            "--- Chunk 16913 ---\n",
            "The generator’s goal is to generate instances similar to those in the training set, to\n",
            "\n",
            "--- Chunk 16914 ---\n",
            "fool the discriminator. The discriminator must distinguish the real instances\n",
            "\n",
            "--- Chunk 16915 ---\n",
            "from the generated ones. At each training iteration, the discriminator is trained\n",
            "\n",
            "--- Chunk 16916 ---\n",
            "like a normal binary classifier, then the generator is trained to maximize the\n",
            "\n",
            "--- Chunk 16917 ---\n",
            "discriminator’s error. GANs are used for advanced image processing tasks such as\n",
            "\n",
            "--- Chunk 16918 ---\n",
            "super resolution, colorization, image editing (replacing objects with realistic\n",
            "\n",
            "--- Chunk 16919 ---\n",
            "background), turning a simple sketch into a photorealistic image, or predicting\n",
            "\n",
            "--- Chunk 16920 ---\n",
            "the next frames in a video. They are also used to augment a dataset (to train other\n",
            "\n",
            "--- Chunk 16921 ---\n",
            "Exercise Solutions | 747\n",
            "\n",
            "--- Chunk 16922 ---\n",
            "models), to generate other types of data (such as text, audio, and time series), and\n",
            "to identify the weaknesses in other models and strengthen them.\n",
            "\n",
            "--- Chunk 16923 ---\n",
            "8. Training GANs is notoriously difficult, because of the complex dynamics\n",
            "\n",
            "--- Chunk 16924 ---\n",
            "between the generator and the discriminator. The biggest difficulty is mode col‐\n",
            "\n",
            "--- Chunk 16925 ---\n",
            "lapse, where the generator produces outputs with very little diversity. Moreover,\n",
            "\n",
            "--- Chunk 16926 ---\n",
            "training can be terribly unstable: it may start out fine and then suddenly start\n",
            "\n",
            "--- Chunk 16927 ---\n",
            "oscillating or diverging, without any apparent reason. GANs are also very sensi‐\n",
            "tive to the choice of hyperparameters.\n",
            "\n",
            "--- Chunk 16928 ---\n",
            "For the solutions to exercises 9, 10, and 11, please see the Jupyter notebooks available\n",
            "at https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 16929 ---\n",
            "Chapter 18: Reinforcement Learning\n",
            "1. Reinforcement Learning is an area of Machine Learning aimed at creating agents\n",
            "\n",
            "--- Chunk 16930 ---\n",
            "capable of taking actions in an environment in a way that maximizes rewards\n",
            "\n",
            "--- Chunk 16931 ---\n",
            "over time. There are many differences between RL and regular supervised and\n",
            "unsupervised learning. Here are a few:\n",
            "\n",
            "--- Chunk 16932 ---\n",
            "• In supervised and unsupervised learning, the goal is generally to find patterns\n",
            "\n",
            "--- Chunk 16933 ---\n",
            "in the data and use them to make predictions. In Reinforcement Learning, the\n",
            "goal is to find a good policy.\n",
            "\n",
            "--- Chunk 16934 ---\n",
            "• Unlike in supervised learning, the agent is not explicitly given the “right”\n",
            "answer. It must learn by trial and error.\n",
            "\n",
            "--- Chunk 16935 ---\n",
            "• Unlike in unsupervised learning, there is a form of supervision, through\n",
            "\n",
            "--- Chunk 16936 ---\n",
            "rewards. We do not tell the agent how to perform the task, but we do tell it\n",
            "when it is making progress or when it is failing.\n",
            "\n",
            "--- Chunk 16937 ---\n",
            "• A Reinforcement Learning agent needs to find the right balance between\n",
            "exploring the environment, looking for new ways of getting rewards, and\n",
            "\n",
            "--- Chunk 16938 ---\n",
            "exploiting sources of rewards that it already knows. In contrast, supervised and\n",
            "\n",
            "--- Chunk 16939 ---\n",
            "unsupervised learning systems generally don’t need to worry about explora‐\n",
            "tion; they just feed on the training data they are given.\n",
            "\n",
            "--- Chunk 16940 ---\n",
            "• In supervised and unsupervised learning, training instances are typically inde‐\n",
            "\n",
            "--- Chunk 16941 ---\n",
            "pendent (in fact, they are generally shuffled). In Reinforcement Learning, con‐\n",
            "\n",
            "--- Chunk 16942 ---\n",
            "secutive observations are generally not independent. An agent may remain in\n",
            "\n",
            "--- Chunk 16943 ---\n",
            "the same region of the environment for a while before it moves on, so consecu‐\n",
            "\n",
            "--- Chunk 16944 ---\n",
            "tive observations will be very correlated. In some cases a replay memory\n",
            "\n",
            "--- Chunk 16945 ---\n",
            "(buffer) is used to ensure that the training algorithm gets fairly independent\n",
            "observations.\n",
            "\n",
            "--- Chunk 16946 ---\n",
            "748 | Appendix A: Exercise Solutions\n",
            "\n",
            "--- Chunk 16947 ---\n",
            "2. Here are a few possible applications of Reinforcement Learning, other than those\n",
            "mentioned in Chapter 18:\n",
            "Music personalization\n",
            "\n",
            "--- Chunk 16948 ---\n",
            "The environment is a user’s personalized web radio. The agent is the software\n",
            "\n",
            "--- Chunk 16949 ---\n",
            "deciding what song to play next for that user. Its possible actions are to play\n",
            "\n",
            "--- Chunk 16950 ---\n",
            "any song in the catalog (it must try to choose a song the user will enjoy) or to\n",
            "\n",
            "--- Chunk 16951 ---\n",
            "play an advertisement (it must try to choose an ad that the user will be inter‐\n",
            "\n",
            "--- Chunk 16952 ---\n",
            "ested in). It gets a small reward every time the user listens to a song, a larger\n",
            "\n",
            "--- Chunk 16953 ---\n",
            "reward every time the user listens to an ad, a negative reward when the user\n",
            "skips a song or an ad, and a very negative reward if the user leaves.\n",
            "\n",
            "--- Chunk 16954 ---\n",
            "Marketing\n",
            "The environment is your company’s marketing department. The agent is the\n",
            "\n",
            "--- Chunk 16955 ---\n",
            "software that defines which customers a mailing campaign should be sent to,\n",
            "\n",
            "--- Chunk 16956 ---\n",
            "given their profile and purchase history (for each customer it has two possi‐\n",
            "\n",
            "--- Chunk 16957 ---\n",
            "ble actions: send or don’t send). It gets a negative reward for the cost of the\n",
            "\n",
            "--- Chunk 16958 ---\n",
            "mailing campaign, and a positive reward for estimated revenue generated\n",
            "from this campaign.\n",
            "\n",
            "--- Chunk 16959 ---\n",
            "Product delivery\n",
            "Let the agent control a fleet of delivery trucks, deciding what they should\n",
            "\n",
            "--- Chunk 16960 ---\n",
            "pick up at the depots, where they should go, what they should drop off, and\n",
            "\n",
            "--- Chunk 16961 ---\n",
            "so on. It will get positive rewards for each product delivered on time, and\n",
            "negative rewards for late deliveries.\n",
            "\n",
            "--- Chunk 16962 ---\n",
            "3. When estimating the value of an action, Reinforcement Learning algorithms typ‐\n",
            "\n",
            "--- Chunk 16963 ---\n",
            "ically sum all the rewards that this action led to, giving more weight to immediate\n",
            "\n",
            "--- Chunk 16964 ---\n",
            "rewards and less weight to later rewards (considering that an action has more\n",
            "\n",
            "--- Chunk 16965 ---\n",
            "influence on the near future than on the distant future). To model this, a discount\n",
            "\n",
            "--- Chunk 16966 ---\n",
            "factor is typically applied at each time step. For example, with a discount factor of\n",
            "\n",
            "--- Chunk 16967 ---\n",
            "0.9, a reward of 100 that is received two time steps later is counted as only 0.92 ×\n",
            "\n",
            "--- Chunk 16968 ---\n",
            "100 = 81 when you are estimating the value of the action. You can think of the\n",
            "\n",
            "--- Chunk 16969 ---\n",
            "discount factor as a measure of how much the future is valued relative to the\n",
            "\n",
            "--- Chunk 16970 ---\n",
            "present: if it is very close to 1, then the future is valued almost as much as the\n",
            "\n",
            "--- Chunk 16971 ---\n",
            "present; if it is close to 0, then only immediate rewards matter. Of course, this\n",
            "\n",
            "--- Chunk 16972 ---\n",
            "impacts the optimal policy tremendously: if you value the future, you may be\n",
            "\n",
            "--- Chunk 16973 ---\n",
            "willing to put up with a lot of immediate pain for the prospect of eventual\n",
            "\n",
            "--- Chunk 16974 ---\n",
            "rewards, while if you don’t value the future, you will just grab any immediate\n",
            "reward you can find, never investing in the future.\n",
            "\n",
            "--- Chunk 16975 ---\n",
            "4. To measure the performance of a Reinforcement Learning agent, you can simply\n",
            "\n",
            "--- Chunk 16976 ---\n",
            "sum up the rewards it gets. In a simulated environment, you can run many epi‐\n",
            "\n",
            "--- Chunk 16977 ---\n",
            "sodes and look at the total rewards it gets on average (and possibly look at the\n",
            "min, max, standard deviation, and so on).\n",
            "\n",
            "--- Chunk 16978 ---\n",
            "Exercise Solutions | 749\n",
            "\n",
            "--- Chunk 16979 ---\n",
            "5. The credit assignment problem is the fact that when a Reinforcement Learning\n",
            "\n",
            "--- Chunk 16980 ---\n",
            "agent receives a reward, it has no direct way of knowing which of its previous\n",
            "\n",
            "--- Chunk 16981 ---\n",
            "actions contributed to this reward. It typically occurs when there is a large delay\n",
            "\n",
            "--- Chunk 16982 ---\n",
            "between an action and the resulting reward (e.g., during a game of Atari’s Pong,\n",
            "\n",
            "--- Chunk 16983 ---\n",
            "there may be a few dozen time steps between the moment the agent hits the ball\n",
            "\n",
            "--- Chunk 16984 ---\n",
            "and the moment it wins the point). One way to alleviate it is to provide the agent\n",
            "\n",
            "--- Chunk 16985 ---\n",
            "with shorter-term rewards, when possible. This usually requires prior knowledge\n",
            "\n",
            "--- Chunk 16986 ---\n",
            "about the task. For example, if we want to build an agent that will learn to play\n",
            "\n",
            "--- Chunk 16987 ---\n",
            "chess, instead of giving it a reward only when it wins the game, we could give it a\n",
            "reward every time it captures one of the opponent’s pieces.\n",
            "\n",
            "--- Chunk 16988 ---\n",
            "6. An agent can often remain in the same region of its environment for a while, so\n",
            "\n",
            "--- Chunk 16989 ---\n",
            "all of its experiences will be very similar for that period of time. This can intro‐\n",
            "\n",
            "--- Chunk 16990 ---\n",
            "duce some bias in the learning algorithm. It may tune its policy for this region of\n",
            "\n",
            "--- Chunk 16991 ---\n",
            "the environment, but it will not perform well as soon as it moves out of this\n",
            "\n",
            "--- Chunk 16992 ---\n",
            "region. To solve this problem, you can use a replay memory; instead of using\n",
            "\n",
            "--- Chunk 16993 ---\n",
            "only the most immediate experiences for learning, the agent will learn based on a\n",
            "\n",
            "--- Chunk 16994 ---\n",
            "buffer of its past experiences, recent and not so recent (perhaps this is why we\n",
            "\n",
            "--- Chunk 16995 ---\n",
            "dream at night: to replay our experiences of the day and better learn from them?).\n",
            "\n",
            "--- Chunk 16996 ---\n",
            "7. An off-policy RL algorithm learns the value of the optimal policy (i.e., the sum of\n",
            "\n",
            "--- Chunk 16997 ---\n",
            "discounted rewards that can be expected for each state if the agent acts optimally)\n",
            "\n",
            "--- Chunk 16998 ---\n",
            "while the agent follows a different policy. Q-Learning is a good example of such\n",
            "\n",
            "--- Chunk 16999 ---\n",
            "an algorithm. In contrast, an on-policy algorithm learns the value of the policy\n",
            "\n",
            "--- Chunk 17000 ---\n",
            "that the agent actually executes, including both exploration and exploitation.\n",
            "\n",
            "--- Chunk 17001 ---\n",
            "For the solutions to exercises 8, 9, and 10, please see the Jupyter notebooks available\n",
            "at https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 17002 ---\n",
            "Chapter 19: Training and Deploying TensorFlow Models\n",
            "at Scale\n",
            "\n",
            "--- Chunk 17003 ---\n",
            "1. A SavedModel contains a TensorFlow model, including its architecture (a com‐\n",
            "\n",
            "--- Chunk 17004 ---\n",
            "putation graph) and its weights. It is stored as a directory containing a\n",
            "\n",
            "--- Chunk 17005 ---\n",
            "saved_model.pb file, which defines the computation graph (represented as a seri‐\n",
            "\n",
            "--- Chunk 17006 ---\n",
            "alized protocol buffer), and a variables subdirectory containing the variable val‐\n",
            "\n",
            "--- Chunk 17007 ---\n",
            "ues. For models containing a large number of weights, these variable values may\n",
            "\n",
            "--- Chunk 17008 ---\n",
            "be split across multiple files. A SavedModel also includes an assets subdirectory\n",
            "\n",
            "--- Chunk 17009 ---\n",
            "that may contain additional data, such as vocabulary files, class names, or some\n",
            "\n",
            "--- Chunk 17010 ---\n",
            "example instances for this model. To be more accurate, a SavedModel can con‐\n",
            "\n",
            "--- Chunk 17011 ---\n",
            "tain one or more metagraphs. A metagraph is a computation graph plus some\n",
            "\n",
            "--- Chunk 17012 ---\n",
            "function signature definitions (including their input and output names, types,\n",
            "\n",
            "--- Chunk 17013 ---\n",
            "and shapes). Each metagraph is identified by a set of tags. To inspect a SavedMo‐\n",
            "\n",
            "--- Chunk 17014 ---\n",
            "750 | Appendix A: Exercise Solutions\n",
            "\n",
            "--- Chunk 17015 ---\n",
            "del, you can use the command-line tool saved_model_cli or just load it using\n",
            "tf.saved_model.load() and inspect it in Python.\n",
            "\n",
            "--- Chunk 17016 ---\n",
            "2. TF Serving allows you to deploy multiple TensorFlow models (or multiple ver‐\n",
            "\n",
            "--- Chunk 17017 ---\n",
            "sions of the same model) and make them accessible to all your applications easily\n",
            "\n",
            "--- Chunk 17018 ---\n",
            "via a REST API or a gRPC API. Using your models directly in your applications\n",
            "\n",
            "--- Chunk 17019 ---\n",
            "would make it harder to deploy a new version of a model across all applications.\n",
            "\n",
            "--- Chunk 17020 ---\n",
            "Implementing your own microservice to wrap a TF model would require extra\n",
            "\n",
            "--- Chunk 17021 ---\n",
            "work, and it would be hard to match TF Serving’s features. TF Serving has many\n",
            "\n",
            "--- Chunk 17022 ---\n",
            "features: it can monitor a directory and autodeploy the models that are placed\n",
            "\n",
            "--- Chunk 17023 ---\n",
            "there, and you won’t have to change or even restart any of your applications to\n",
            "\n",
            "--- Chunk 17024 ---\n",
            "benefit from the new model versions; it’s fast, well tested, and scales very well;\n",
            "\n",
            "--- Chunk 17025 ---\n",
            "and it supports A/B testing of experimental models and deploying a new model\n",
            "\n",
            "--- Chunk 17026 ---\n",
            "version to just a subset of your users (in this case the model is called a canary).\n",
            "\n",
            "--- Chunk 17027 ---\n",
            "TF Serving is also capable of grouping individual requests into batches to run\n",
            "\n",
            "--- Chunk 17028 ---\n",
            "them jointly on the GPU. To deploy TF Serving, you can install it from source,\n",
            "\n",
            "--- Chunk 17029 ---\n",
            "but it is much simpler to install it using a Docker image. To deploy a cluster of TF\n",
            "\n",
            "--- Chunk 17030 ---\n",
            "Serving Docker images, you can use an orchestration tool such as Kubernetes, or\n",
            "use a fully hosted solution such as Google Cloud AI Platform.\n",
            "\n",
            "--- Chunk 17031 ---\n",
            "3. To deploy a model across multiple TF Serving instances, all you need to do is\n",
            "\n",
            "--- Chunk 17032 ---\n",
            "configure these TF Serving instances to monitor the same models directory, and\n",
            "then export your new model as a SavedModel into a subdirectory.\n",
            "\n",
            "--- Chunk 17033 ---\n",
            "4. The gRPC API is more efficient than the REST API. However, its client libraries\n",
            "\n",
            "--- Chunk 17034 ---\n",
            "are not as widely available, and if you activate compression when using the REST\n",
            "\n",
            "--- Chunk 17035 ---\n",
            "API, you can get almost the same performance. So, the gRPC API is most useful\n",
            "\n",
            "--- Chunk 17036 ---\n",
            "when you need the highest possible performance and the clients are not limited\n",
            "to the REST API.\n",
            "\n",
            "--- Chunk 17037 ---\n",
            "5. To reduce a model’s size so it can run on a mobile or embedded device, TFLite\n",
            "uses several techniques:\n",
            "\n",
            "--- Chunk 17038 ---\n",
            "• It provides a converter which can optimize a SavedModel: it shrinks the model\n",
            "\n",
            "--- Chunk 17039 ---\n",
            "and reduces its latency. To do this, it prunes all the operations that are not\n",
            "\n",
            "--- Chunk 17040 ---\n",
            "needed to make predictions (such as training operations), and it optimizes and\n",
            "fuses operations whenever possible.\n",
            "\n",
            "--- Chunk 17041 ---\n",
            "• The converter can also perform post-training quantization: this technique dra‐\n",
            "\n",
            "--- Chunk 17042 ---\n",
            "matically reduces the model’s size, so it’s much faster to download and store.\n",
            "\n",
            "--- Chunk 17043 ---\n",
            "• It saves the optimized model using the FlatBuffer format, which can be loaded\n",
            "\n",
            "--- Chunk 17044 ---\n",
            "to RAM directly, without parsing. This reduces the loading time and memory\n",
            "footprint.\n",
            "\n",
            "--- Chunk 17045 ---\n",
            "Exercise Solutions | 751\n",
            "\n",
            "--- Chunk 17046 ---\n",
            "6. Quantization-aware training consists in adding fake quantization operations to\n",
            "\n",
            "--- Chunk 17047 ---\n",
            "the model during training. This allows the model to learn to ignore the quantiza‐\n",
            "tion noise; the final weights will be more robust to quantization.\n",
            "\n",
            "--- Chunk 17048 ---\n",
            "7. Model parallelism means chopping your model into multiple parts and running\n",
            "\n",
            "--- Chunk 17049 ---\n",
            "them in parallel across multiple devices, hopefully speeding up the model during\n",
            "\n",
            "--- Chunk 17050 ---\n",
            "training or inference. Data parallelism means creating multiple exact replicas of\n",
            "\n",
            "--- Chunk 17051 ---\n",
            "your model and deploying them across multiple devices. At each iteration during\n",
            "\n",
            "--- Chunk 17052 ---\n",
            "training, each replica is given a different batch of data, and it computes the gradi‐\n",
            "\n",
            "--- Chunk 17053 ---\n",
            "ents of the loss with regard to the model parameters. In synchronous data paral‐\n",
            "\n",
            "--- Chunk 17054 ---\n",
            "lelism, the gradients from all replicas are then aggregated and the optimizer\n",
            "\n",
            "--- Chunk 17055 ---\n",
            "performs a Gradient Descent step. The parameters may be centralized (e.g., on\n",
            "\n",
            "--- Chunk 17056 ---\n",
            "parameter servers) or replicated across all replicas and kept in sync using AllRe‐\n",
            "\n",
            "--- Chunk 17057 ---\n",
            "duce. In asynchronous data parallelism, the parameters are centralized and the\n",
            "\n",
            "--- Chunk 17058 ---\n",
            "replicas run independently from each other, each updating the central parame‐\n",
            "\n",
            "--- Chunk 17059 ---\n",
            "ters directly at the end of each training iteration, without having to wait for the\n",
            "\n",
            "--- Chunk 17060 ---\n",
            "other replicas. To speed up training, data parallelism turns out to work better\n",
            "\n",
            "--- Chunk 17061 ---\n",
            "than model parallelism, in general. This is mostly because it requires less com‐\n",
            "\n",
            "--- Chunk 17062 ---\n",
            "munication across devices. Moreover, it is much easier to implement, and it\n",
            "\n",
            "--- Chunk 17063 ---\n",
            "works the same way for any model, whereas model parallelism requires analyzing\n",
            "the model to determine the best way to chop it into pieces.\n",
            "\n",
            "--- Chunk 17064 ---\n",
            "8. When training a model across multiple servers, you can use the following distri‐\n",
            "bution strategies:\n",
            "\n",
            "--- Chunk 17065 ---\n",
            "bution strategies:\n",
            "• The MultiWorkerMirroredStrategy performs mirrored data parallelism. The\n",
            "\n",
            "--- Chunk 17066 ---\n",
            "model is replicated across all available servers and devices, and each replica\n",
            "\n",
            "--- Chunk 17067 ---\n",
            "gets a different batch of data at each training iteration and computes its own\n",
            "\n",
            "--- Chunk 17068 ---\n",
            "gradients. The mean of the gradients is computed and shared across all replicas\n",
            "\n",
            "--- Chunk 17069 ---\n",
            "using a distributed AllReduce implementation (NCCL by default), and all rep‐\n",
            "\n",
            "--- Chunk 17070 ---\n",
            "licas perform the same Gradient Descent step. This strategy is the simplest to\n",
            "\n",
            "--- Chunk 17071 ---\n",
            "use since all servers and devices are treated in exactly the same way, and it per‐\n",
            "\n",
            "--- Chunk 17072 ---\n",
            "forms fairly well. In general, you should use this strategy. Its main limitation is\n",
            "that it requires the model to fit in RAM on every replica.\n",
            "\n",
            "--- Chunk 17073 ---\n",
            "• The ParameterServerStrategy performs asynchronous data parallelism. The\n",
            "\n",
            "--- Chunk 17074 ---\n",
            "model is replicated across all devices on all workers, and the parameters are\n",
            "\n",
            "--- Chunk 17075 ---\n",
            "sharded across all parameter servers. Each worker has its own training loop,\n",
            "\n",
            "--- Chunk 17076 ---\n",
            "running asynchronously with the other workers; at each training iteration,\n",
            "\n",
            "--- Chunk 17077 ---\n",
            "each worker gets its own batch of data and fetches the latest version of the\n",
            "\n",
            "--- Chunk 17078 ---\n",
            "model parameters from the parameter servers, then it computes the gradients\n",
            "\n",
            "--- Chunk 17079 ---\n",
            "of the loss with regard to these parameters, and it sends them to the parameter\n",
            "\n",
            "--- Chunk 17080 ---\n",
            "servers. Lastly, the parameter servers perform a Gradient Descent step using\n",
            "\n",
            "--- Chunk 17081 ---\n",
            "these gradients. This strategy is generally slower than the previous strategy,\n",
            "\n",
            "--- Chunk 17082 ---\n",
            "752 | Appendix A: Exercise Solutions\n",
            "\n",
            "--- Chunk 17083 ---\n",
            "and a bit harder to deploy, since it requires managing parameter servers. How‐\n",
            "ever, it is useful to train huge models that don’t fit in GPU RAM.\n",
            "\n",
            "--- Chunk 17084 ---\n",
            "For the solutions to exercises 9, 10, and 11, please see the Jupyter notebooks available\n",
            "at https://github.com/ageron/handson-ml2.\n",
            "\n",
            "--- Chunk 17085 ---\n",
            "Exercise Solutions | 753\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "APPENDIX B\n",
            "Machine Learning Project Checklist\n",
            "\n",
            "--- Chunk 17086 ---\n",
            "This checklist can guide you through your Machine Learning projects. There are\n",
            "eight main steps:\n",
            "\n",
            "--- Chunk 17087 ---\n",
            "1. Frame the problem and look at the big picture.\n",
            "2. Get the data.\n",
            "3. Explore the data to gain insights.\n",
            "\n",
            "--- Chunk 17088 ---\n",
            "4. Prepare the data to better expose the underlying data patterns to Machine Learn‐\n",
            "\n",
            "--- Chunk 17089 ---\n",
            "ing algorithms.\n",
            "5. Explore many different models and shortlist the best ones.\n",
            "6. Fine-tune your models and combine them into a great solution.\n",
            "\n",
            "--- Chunk 17090 ---\n",
            "7. Present your solution.\n",
            "8. Launch, monitor, and maintain your system.\n",
            "\n",
            "--- Chunk 17091 ---\n",
            "Obviously, you should feel free to adapt this checklist to your needs.\n",
            "\n",
            "--- Chunk 17092 ---\n",
            "Frame the Problem and Look at the Big Picture\n",
            "1. Define the objective in business terms.\n",
            "2. How will your solution be used?\n",
            "\n",
            "--- Chunk 17093 ---\n",
            "3. What are the current solutions/workarounds (if any)?\n",
            "4. How should you frame this problem (supervised/unsupervised, online/offline,\n",
            "\n",
            "--- Chunk 17094 ---\n",
            "etc.)?\n",
            "5. How should performance be measured?\n",
            "6. Is the performance measure aligned with the business objective?\n",
            "\n",
            "755\n",
            "\n",
            "--- Chunk 17095 ---\n",
            "755\n",
            "\n",
            "\n",
            "\n",
            "7. What would be the minimum performance needed to reach the business objec‐\n",
            "tive?\n",
            "\n",
            "--- Chunk 17096 ---\n",
            "8. What are comparable problems? Can you reuse experience or tools?\n",
            "9. Is human expertise available?\n",
            "\n",
            "--- Chunk 17097 ---\n",
            "10. How would you solve the problem manually?\n",
            "11. List the assumptions you (or others) have made so far.\n",
            "12. Verify assumptions if possible.\n",
            "\n",
            "--- Chunk 17098 ---\n",
            "Get the Data\n",
            "Note: automate as much as possible so you can easily get fresh data.\n",
            "\n",
            "--- Chunk 17099 ---\n",
            "1. List the data you need and how much you need.\n",
            "2. Find and document where you can get that data.\n",
            "3. Check how much space it will take.\n",
            "\n",
            "--- Chunk 17100 ---\n",
            "4. Check legal obligations, and get authorization if necessary.\n",
            "5. Get access authorizations.\n",
            "6. Create a workspace (with enough storage space).\n",
            "\n",
            "--- Chunk 17101 ---\n",
            "7. Get the data.\n",
            "8. Convert the data to a format you can easily manipulate (without changing the\n",
            "\n",
            "--- Chunk 17102 ---\n",
            "data itself).\n",
            "9. Ensure sensitive information is deleted or protected (e.g., anonymized).\n",
            "\n",
            "--- Chunk 17103 ---\n",
            "10. Check the size and type of data (time series, sample, geographical, etc.).\n",
            "\n",
            "--- Chunk 17104 ---\n",
            "11. Sample a test set, put it aside, and never look at it (no data snooping!).\n",
            "\n",
            "--- Chunk 17105 ---\n",
            "Explore the Data\n",
            "Note: try to get insights from a field expert for these steps.\n",
            "\n",
            "--- Chunk 17106 ---\n",
            "1. Create a copy of the data for exploration (sampling it down to a manageable size\n",
            "if necessary).\n",
            "\n",
            "--- Chunk 17107 ---\n",
            "2. Create a Jupyter notebook to keep a record of your data exploration.\n",
            "3. Study each attribute and its characteristics:\n",
            "\n",
            "--- Chunk 17108 ---\n",
            "• Name\n",
            "• Type (categorical, int/float, bounded/unbounded, text, structured, etc.)\n",
            "\n",
            "756 | Appendix B: Machine Learning Project Checklist\n",
            "\n",
            "--- Chunk 17109 ---\n",
            "• % of missing values\n",
            "• Noisiness and type of noise (stochastic, outliers, rounding errors, etc.)\n",
            "• Usefulness for the task\n",
            "\n",
            "--- Chunk 17110 ---\n",
            "• Type of distribution (Gaussian, uniform, logarithmic, etc.)\n",
            "\n",
            "--- Chunk 17111 ---\n",
            "4. For supervised learning tasks, identify the target attribute(s).\n",
            "5. Visualize the data.\n",
            "6. Study the correlations between attributes.\n",
            "\n",
            "--- Chunk 17112 ---\n",
            "7. Study how you would solve the problem manually.\n",
            "8. Identify the promising transformations you may want to apply.\n",
            "\n",
            "--- Chunk 17113 ---\n",
            "9. Identify extra data that would be useful (go back to “Get the Data” on page 756).\n",
            "\n",
            "--- Chunk 17114 ---\n",
            "10. Document what you have learned.\n",
            "\n",
            "Prepare the Data\n",
            "Notes:\n",
            "\n",
            "--- Chunk 17115 ---\n",
            "• Work on copies of the data (keep the original dataset intact).\n",
            "• Write functions for all data transformations you apply, for five reasons:\n",
            "\n",
            "--- Chunk 17116 ---\n",
            "— So you can easily prepare the data the next time you get a fresh dataset\n",
            "— So you can apply these transformations in future projects\n",
            "\n",
            "--- Chunk 17117 ---\n",
            "— To clean and prepare the test set\n",
            "— To clean and prepare new data instances once your solution is live\n",
            "\n",
            "--- Chunk 17118 ---\n",
            "— To make it easy to treat your preparation choices as hyperparameters\n",
            "\n",
            "--- Chunk 17119 ---\n",
            "1. Data cleaning:\n",
            "• Fix or remove outliers (optional).\n",
            "• Fill in missing values (e.g., with zero, mean, median…) or drop their rows (or\n",
            "\n",
            "columns).\n",
            "\n",
            "--- Chunk 17120 ---\n",
            "columns).\n",
            "\n",
            "2. Feature selection (optional):\n",
            "• Drop the attributes that provide no useful information for the task.\n",
            "\n",
            "--- Chunk 17121 ---\n",
            "3. Feature engineering, where appropriate:\n",
            "• Discretize continuous features.\n",
            "\n",
            "Machine Learning Project Checklist | 757\n",
            "\n",
            "--- Chunk 17122 ---\n",
            "• Decompose features (e.g., categorical, date/time, etc.).\n",
            "• Add promising transformations of features (e.g., log(x), sqrt(x), x2, etc.).\n",
            "\n",
            "--- Chunk 17123 ---\n",
            "• Aggregate features into promising new features.\n",
            "\n",
            "--- Chunk 17124 ---\n",
            "4. Feature scaling:\n",
            "• Standardize or normalize features.\n",
            "\n",
            "Shortlist Promising Models\n",
            "Notes:\n",
            "\n",
            "--- Chunk 17125 ---\n",
            "• If the data is huge, you may want to sample smaller training sets so you can train\n",
            "\n",
            "--- Chunk 17126 ---\n",
            "many different models in a reasonable time (be aware that this penalizes complex\n",
            "models such as large neural nets or Random Forests).\n",
            "\n",
            "--- Chunk 17127 ---\n",
            "• Once again, try to automate these steps as much as possible.\n",
            "\n",
            "--- Chunk 17128 ---\n",
            "1. Train many quick-and-dirty models from different categories (e.g., linear, naive\n",
            "\n",
            "--- Chunk 17129 ---\n",
            "Bayes, SVM, Random Forest, neural net, etc.) using standard parameters.\n",
            "\n",
            "--- Chunk 17130 ---\n",
            "2. Measure and compare their performance.\n",
            "• For each model, use N-fold cross-validation and compute the mean and stan‐\n",
            "\n",
            "--- Chunk 17131 ---\n",
            "dard deviation of the performance measure on the N folds.\n",
            "\n",
            "--- Chunk 17132 ---\n",
            "3. Analyze the most significant variables for each algorithm.\n",
            "4. Analyze the types of errors the models make.\n",
            "\n",
            "--- Chunk 17133 ---\n",
            "• What data would a human have used to avoid these errors?\n",
            "\n",
            "--- Chunk 17134 ---\n",
            "5. Perform a quick round of feature selection and engineering.\n",
            "6. Perform one or two more quick iterations of the five previous steps.\n",
            "\n",
            "--- Chunk 17135 ---\n",
            "7. Shortlist the top three to five most promising models, preferring models that\n",
            "\n",
            "--- Chunk 17136 ---\n",
            "make different types of errors.\n",
            "\n",
            "Fine-Tune the System\n",
            "Notes:\n",
            "\n",
            "--- Chunk 17137 ---\n",
            "• You will want to use as much data as possible for this step, especially as you move\n",
            "toward the end of fine-tuning.\n",
            "\n",
            "--- Chunk 17138 ---\n",
            "758 | Appendix B: Machine Learning Project Checklist\n",
            "\n",
            "\n",
            "\n",
            "• As always, automate what you can.\n",
            "\n",
            "--- Chunk 17139 ---\n",
            "1. Fine-tune the hyperparameters using cross-validation:\n",
            "• Treat your data transformation choices as hyperparameters, especially when\n",
            "\n",
            "--- Chunk 17140 ---\n",
            "you are not sure about them (e.g., if you’re not sure whether to replace missing\n",
            "\n",
            "--- Chunk 17141 ---\n",
            "values with zeros or with the median value, or to just drop the rows).\n",
            "\n",
            "--- Chunk 17142 ---\n",
            "• Unless there are very few hyperparameter values to explore, prefer random\n",
            "\n",
            "--- Chunk 17143 ---\n",
            "search over grid search. If training is very long, you may prefer a Bayesian\n",
            "\n",
            "--- Chunk 17144 ---\n",
            "optimization approach (e.g., using Gaussian process priors, as described by\n",
            "Jasper Snoek et al.).1\n",
            "\n",
            "--- Chunk 17145 ---\n",
            "2. Try Ensemble methods. Combining your best models will often produce better\n",
            "performance than running them individually.\n",
            "\n",
            "--- Chunk 17146 ---\n",
            "3. Once you are confident about your final model, measure its performance on the\n",
            "test set to estimate the generalization error.\n",
            "\n",
            "--- Chunk 17147 ---\n",
            "Don’t tweak your model after measuring the generalization error:\n",
            "you would just start overfitting the test set.\n",
            "\n",
            "--- Chunk 17148 ---\n",
            "Present Your Solution\n",
            "1. Document what you have done.\n",
            "2. Create a nice presentation.\n",
            "\n",
            "• Make sure you highlight the big picture first.\n",
            "\n",
            "--- Chunk 17149 ---\n",
            "3. Explain why your solution achieves the business objective.\n",
            "4. Don’t forget to present interesting points you noticed along the way.\n",
            "\n",
            "--- Chunk 17150 ---\n",
            "• Describe what worked and what did not.\n",
            "• List your assumptions and your system’s limitations.\n",
            "\n",
            "--- Chunk 17151 ---\n",
            "1 Jasper Snoek et al., “Practical Bayesian Optimization of Machine Learning Algorithms,” Proceedings of the 25th\n",
            "\n",
            "--- Chunk 17152 ---\n",
            "International Conference on Neural Information Processing Systems 2 (2012): 2951–2959.\n",
            "\n",
            "--- Chunk 17153 ---\n",
            "Machine Learning Project Checklist | 759\n",
            "\n",
            "--- Chunk 17154 ---\n",
            "5. Ensure your key findings are communicated through beautiful visualizations or\n",
            "\n",
            "--- Chunk 17155 ---\n",
            "easy-to-remember statements (e.g., “the median income is the number-one pre‐\n",
            "dictor of housing prices”).\n",
            "\n",
            "--- Chunk 17156 ---\n",
            "Launch!\n",
            "1. Get your solution ready for production (plug into production data inputs, write\n",
            "\n",
            "--- Chunk 17157 ---\n",
            "unit tests, etc.).\n",
            "2. Write monitoring code to check your system’s live performance at regular inter‐\n",
            "\n",
            "--- Chunk 17158 ---\n",
            "vals and trigger alerts when it drops.\n",
            "• Beware of slow degradation: models tend to “rot” as data evolves.\n",
            "\n",
            "--- Chunk 17159 ---\n",
            "• Measuring performance may require a human pipeline (e.g., via a crowdsourc‐\n",
            "\n",
            "--- Chunk 17160 ---\n",
            "ing service).\n",
            "• Also monitor your inputs’ quality (e.g., a malfunctioning sensor sending ran‐\n",
            "\n",
            "--- Chunk 17161 ---\n",
            "dom values, or another team’s output becoming stale). This is particularly\n",
            "important for online learning systems.\n",
            "\n",
            "--- Chunk 17162 ---\n",
            "3. Retrain your models on a regular basis on fresh data (automate as much as\n",
            "possible).\n",
            "\n",
            "760 | Appendix B: Machine Learning Project Checklist\n",
            "\n",
            "--- Chunk 17163 ---\n",
            "APPENDIX C\n",
            "SVM Dual Problem\n",
            "\n",
            "--- Chunk 17164 ---\n",
            "To understand duality, you first need to understand the Lagrange multipliers method.\n",
            "\n",
            "--- Chunk 17165 ---\n",
            "The general idea is to transform a constrained optimization objective into an uncon‐\n",
            "\n",
            "--- Chunk 17166 ---\n",
            "strained one, by moving the constraints into the objective function. Let’s look at a\n",
            "\n",
            "--- Chunk 17167 ---\n",
            "simple example. Suppose you want to find the values of x and y that minimize the\n",
            "\n",
            "--- Chunk 17168 ---\n",
            "function f(x, y) = x2 + 2y, subject to an equality constraint: 3x + 2y + 1 = 0. Using the\n",
            "\n",
            "--- Chunk 17169 ---\n",
            "Lagrange multipliers method, we start by defining a new function called the Lagran‐\n",
            "\n",
            "--- Chunk 17170 ---\n",
            "gian (or Lagrange function): g(x, y, α) = f(x, y) – α(3x + 2y + 1). Each constraint (in\n",
            "\n",
            "--- Chunk 17171 ---\n",
            "this case just one) is subtracted from the original objective, multiplied by a new vari‐\n",
            "able called a Lagrange multiplier.\n",
            "\n",
            "--- Chunk 17172 ---\n",
            "Joseph-Louis Lagrange showed that if x , y  is a solution to the constrained optimiza‐\n",
            "\n",
            "--- Chunk 17173 ---\n",
            "tion problem, then there must exist an α such that x , y, α  is a stationary point of the\n",
            "\n",
            "--- Chunk 17174 ---\n",
            "Lagrangian (a stationary point is a point where all partial derivatives are equal to\n",
            "\n",
            "--- Chunk 17175 ---\n",
            "zero). In other words, we can compute the partial derivatives of g(x, y, α) with regard\n",
            "\n",
            "--- Chunk 17176 ---\n",
            "to x, y, and α; we can find the points where these derivatives are all equal to zero; and\n",
            "\n",
            "--- Chunk 17177 ---\n",
            "the solutions to the constrained optimization problem (if they exist) must be among\n",
            "these stationary points.\n",
            "\n",
            "--- Chunk 17178 ---\n",
            "∂\n",
            "∂x g x, y, α = 2x − 3α\n",
            "\n",
            "In this example the partial derivatives are: ∂\n",
            "∂y g x, y, α = 2 − 2α\n",
            "∂\n",
            "\n",
            "--- Chunk 17179 ---\n",
            "∂α g x, y, α = − 3x − 2y − 1\n",
            "When all these partial derivatives are equal to 0, we find that\n",
            "\n",
            "--- Chunk 17180 ---\n",
            "2x − 3α = 2 − 2α = −3x − 2y − 1 = 0, from which we can easily find that x = 3\n",
            "\n",
            "--- Chunk 17181 ---\n",
            "2 ,\n",
            "y = − 11\n",
            "\n",
            "--- Chunk 17182 ---\n",
            "4 , and α = 1. This is the only stationary point, and as it respects the con‐\n",
            "\n",
            "--- Chunk 17183 ---\n",
            "straint, it must be the solution to the constrained optimization problem.\n",
            "\n",
            "--- Chunk 17184 ---\n",
            "761\n",
            "\n",
            "--- Chunk 17185 ---\n",
            "However, this method applies only to equality constraints. Fortunately, under some\n",
            "\n",
            "--- Chunk 17186 ---\n",
            "regularity conditions (which are respected by the SVM objectives), this method can\n",
            "\n",
            "--- Chunk 17187 ---\n",
            "be generalized to inequality constraints as well (e.g., 3x + 2y + 1 ≥ 0). The generalized\n",
            "\n",
            "--- Chunk 17188 ---\n",
            "Lagrangian for the hard margin problem is given by Equation C-1, where the α(i) vari‐\n",
            "\n",
            "--- Chunk 17189 ---\n",
            "ables are called the Karush–Kuhn–Tucker (KKT) multipliers, and they must be greater\n",
            "or equal to zero.\n",
            "\n",
            "--- Chunk 17190 ---\n",
            "Equation C-1. Generalized Lagrangian for the hard margin problem\n",
            "m\n",
            "\n",
            "ℒ w, b, α = 1\n",
            "2w⊺w − ∑ α i t i w⊺x i + b − 1\n",
            "\n",
            "i = 1\n",
            "\n",
            "--- Chunk 17191 ---\n",
            "i = 1\n",
            "\n",
            "with α i ≥ 0 for i = 1, 2,⋯, m\n",
            "\n",
            "--- Chunk 17192 ---\n",
            "Just like with the Lagrange multipliers method, you can compute the partial deriva‐\n",
            "\n",
            "--- Chunk 17193 ---\n",
            "tives and locate the stationary points. If there is a solution, it will necessarily be\n",
            "\n",
            "--- Chunk 17194 ---\n",
            "among the stationary points w, b , α  that respect the KKT conditions:\n",
            "\n",
            "--- Chunk 17195 ---\n",
            "• Respect the problem’s constraints: t i w⊺x i + b ≥ 1   for i = 1, 2, …, m.\n",
            "• Verify α i ≥ 0 for i = 1, 2,⋯, m.\n",
            "\n",
            "--- Chunk 17196 ---\n",
            "• Either α i = 0 or the ith constraint must be an active constraint, meaning it must\n",
            "\n",
            "--- Chunk 17197 ---\n",
            "hold by equality: t i w⊺x i + b = 1. This condition is called the complementary\n",
            "\n",
            "--- Chunk 17198 ---\n",
            "slackness condition. It implies that either α i = 0 or the ith instance lies on the\n",
            "boundary (it is a support vector).\n",
            "\n",
            "--- Chunk 17199 ---\n",
            "Note that the KKT conditions are necessary conditions for a stationary point to be a\n",
            "\n",
            "--- Chunk 17200 ---\n",
            "solution of the constrained optimization problem. Under some conditions, they are\n",
            "\n",
            "--- Chunk 17201 ---\n",
            "also sufficient conditions. Luckily, the SVM optimization problem happens to meet\n",
            "\n",
            "--- Chunk 17202 ---\n",
            "these conditions, so any stationary point that meets the KKT conditions is guaranteed\n",
            "to be a solution to the constrained optimization problem.\n",
            "\n",
            "--- Chunk 17203 ---\n",
            "We can compute the partial derivatives of the generalized Lagrangian with regard to\n",
            "w and b with Equation C-2.\n",
            "\n",
            "--- Chunk 17204 ---\n",
            "Equation C-2. Partial derivatives of the generalized Lagrangian\n",
            "m\n",
            "\n",
            "∇wℒ w, b, α = w − ∑ α i t i x i\n",
            "i = 1\n",
            "\n",
            "∂ m\n",
            "∂bℒ w, b, α = − ∑ α i t i\n",
            "\n",
            "i = 1\n",
            "\n",
            "--- Chunk 17205 ---\n",
            "i = 1\n",
            "\n",
            "762 | Appendix C: SVM Dual Problem\n",
            "\n",
            "\n",
            "\n",
            "When these partial derivatives are equal to zero, we have Equation C-3.\n",
            "\n",
            "--- Chunk 17206 ---\n",
            "Equation C-3. Properties of the stationary points\n",
            "m\n",
            "\n",
            "w = ∑ α i t i x i\n",
            "i = 1\n",
            "m\n",
            "∑ α i t i = 0\n",
            "\n",
            "i = 1\n",
            "\n",
            "--- Chunk 17207 ---\n",
            "i = 1\n",
            "\n",
            "If we plug these results into the definition of the generalized Lagrangian, some terms\n",
            "disappear and we find Equation C-4.\n",
            "\n",
            "--- Chunk 17208 ---\n",
            "Equation C-4. Dual form of the SVM problem\n",
            "m m m\n",
            "\n",
            "ℒ w, b , α = 1\n",
            "2 ∑ ∑ α i α j t i t j x i ⊺x j − ∑ α i\n",
            "\n",
            "i = 1 j = 1 i = 1\n",
            "\n",
            "--- Chunk 17209 ---\n",
            "i = 1 j = 1 i = 1\n",
            "\n",
            "with α i ≥ 0 for i = 1, 2,⋯, m\n",
            "\n",
            "--- Chunk 17210 ---\n",
            "The goal is now to find the vector α that minimizes this function, with α i ≥ 0 for all\n",
            "\n",
            "--- Chunk 17211 ---\n",
            "instances. This constrained optimization problem is the dual problem we were look‐\n",
            "ing for.\n",
            "\n",
            "--- Chunk 17212 ---\n",
            "ing for.\n",
            "Once you find the optimal α, you can compute w using the first line of Equation C-3.\n",
            "\n",
            "--- Chunk 17213 ---\n",
            "To compute b , you can use the fact that a support vector must verify t(i)(w⊺ x(i) + b) =\n",
            "\n",
            "--- Chunk 17214 ---\n",
            "1, so if the kth instance is a support vector (i.e., α k > 0), you can use it to compute\n",
            "\n",
            "--- Chunk 17215 ---\n",
            "b = t k − w⊺x k . However, it is often preferred to compute the average over all sup‐\n",
            "\n",
            "--- Chunk 17216 ---\n",
            "port vectors to get a more stable and precise value, as in Equation C-5.\n",
            "\n",
            "--- Chunk 17217 ---\n",
            "Equation C-5. Bias term estimation using the dual form\n",
            "\n",
            "b = 1 m\n",
            "n ∑ t i − w⊺x i\n",
            "\n",
            "s i = 1\n",
            "α i > 0\n",
            "\n",
            "SVM Dual Problem | 763\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "APPENDIX D\n",
            "Autodiff\n",
            "\n",
            "--- Chunk 17218 ---\n",
            "This appendix explains how TensorFlow’s autodifferentiation (autodiff) feature\n",
            "works, and how it compares to other solutions.\n",
            "\n",
            "--- Chunk 17219 ---\n",
            "Suppose you define a function f(x, y) = x2y + y + 2, and you need its partial derivatives\n",
            "\n",
            "--- Chunk 17220 ---\n",
            "∂f/∂x and ∂f/∂y, typically to perform Gradient Descent (or some other optimization\n",
            "\n",
            "--- Chunk 17221 ---\n",
            "algorithm). Your main options are manual differentiation, finite difference approxi‐\n",
            "\n",
            "--- Chunk 17222 ---\n",
            "mation, forward-mode autodiff, and reverse-mode autodiff. TensorFlow implements\n",
            "\n",
            "--- Chunk 17223 ---\n",
            "reverse-mode autodiff, but to understand it, it’s useful to look at the other options\n",
            "\n",
            "--- Chunk 17224 ---\n",
            "first. So let’s go through each of them, starting with manual differentiation.\n",
            "\n",
            "--- Chunk 17225 ---\n",
            "Manual Differentiation\n",
            "The first approach to compute derivatives is to pick up a pencil and a piece of paper\n",
            "\n",
            "--- Chunk 17226 ---\n",
            "and use your calculus knowledge to derive the appropriate equation. For the function\n",
            "\n",
            "--- Chunk 17227 ---\n",
            "f(x, y) just defined, it is not too hard; you just need to use five rules:\n",
            "\n",
            "--- Chunk 17228 ---\n",
            "• The derivative of a constant is 0.\n",
            "• The derivative of λx is λ (where λ is a constant).\n",
            "\n",
            "--- Chunk 17229 ---\n",
            "• The derivative of xλ is λxλ – 1, so the derivative of x2 is 2x.\n",
            "• The derivative of a sum of functions is the sum of these functions’ derivatives.\n",
            "\n",
            "--- Chunk 17230 ---\n",
            "• The derivative of λ times a function is λ times its derivative.\n",
            "\n",
            "--- Chunk 17231 ---\n",
            "765\n",
            "\n",
            "\n",
            "\n",
            "From these rules, you can derive Equation D-1.\n",
            "\n",
            "Equation D-1. Partial derivatives of f(x, y)\n",
            "\n",
            "∂ f ∂ x2y ∂ 2\n",
            "\n",
            "∂x = ∂x + ∂y\n",
            "∂x + ∂2 x\n",
            "\n",
            "--- Chunk 17232 ---\n",
            "∂x = y ∂x + 0 + 0 = 2xy\n",
            "\n",
            "∂ f ∂ x2y ∂\n",
            "∂y = ∂y 2\n",
            "\n",
            "∂y + ∂y + ∂y = x2 + 1 + 0 = x2 + 1\n",
            "\n",
            "--- Chunk 17233 ---\n",
            "This approach can become very tedious for more complex functions, and you run the\n",
            "\n",
            "--- Chunk 17234 ---\n",
            "risk of making mistakes. Fortunately, there are other options. Let’s look at finite dif‐\n",
            "ference approximation now.\n",
            "\n",
            "--- Chunk 17235 ---\n",
            "Finite Difference Approximation\n",
            "Recall that the derivative h′(x0) of a function h(x) at a point x0 is the slope of the func‐\n",
            "\n",
            "--- Chunk 17236 ---\n",
            "tion at that point. More precisely, the derivative is defined as the limit of the slope of a\n",
            "\n",
            "--- Chunk 17237 ---\n",
            "straight line going through this point x0 and another point x on the function, as x gets\n",
            "infinitely close to x0 (see Equation D-2).\n",
            "\n",
            "--- Chunk 17238 ---\n",
            "Equation D-2. Definition of the derivative of a function h(x) at point x0\n",
            "\n",
            "h x − h x\n",
            "h′ x0 = lim 0\n",
            "\n",
            "x x0 x − x0\n",
            "\n",
            "h x + ε − h x\n",
            "= lim 0 0\n",
            "\n",
            "ε 0 ε\n",
            "\n",
            "--- Chunk 17239 ---\n",
            "So, if we wanted to calculate the partial derivative of f(x, y) with regard to x at x = 3\n",
            "\n",
            "--- Chunk 17240 ---\n",
            "and y = 4, we could compute f(3 + ε, 4) – f(3, 4) and divide the result by ε, using a\n",
            "\n",
            "--- Chunk 17241 ---\n",
            "very small value for ε. This type of numerical approximation of the derivative is called\n",
            "\n",
            "--- Chunk 17242 ---\n",
            "a finite difference approximation, and this specific equation is called Newton’s differ‐\n",
            "ence quotient. That’s exactly what the following code does:\n",
            "\n",
            "--- Chunk 17243 ---\n",
            "def f(x, y):\n",
            "    return x**2*y + y + 2\n",
            "\n",
            "def derivative(f, x, y, x_eps, y_eps):\n",
            "    return (f(x + x_eps, y + y_eps) - f(x, y)) / (x_eps + y_eps)\n",
            "\n",
            "--- Chunk 17244 ---\n",
            "df_dx = derivative(f, 3, 4, 0.00001, 0)\n",
            "df_dy = derivative(f, 3, 4, 0, 0.00001)\n",
            "\n",
            "--- Chunk 17245 ---\n",
            "Unfortunately, the result is imprecise (and it gets worse for more complicated func‐\n",
            "\n",
            "--- Chunk 17246 ---\n",
            "tions). The correct results are respectively 24 and 10, but instead we get:\n",
            "\n",
            "--- Chunk 17247 ---\n",
            "766 | Appendix D: Autodiff\n",
            "\n",
            "\n",
            "\n",
            ">>> print(df_dx)\n",
            "24.000039999805264\n",
            ">>> print(df_dy)\n",
            "10.000000000331966\n",
            "\n",
            "--- Chunk 17248 ---\n",
            "Notice that to compute both partial derivatives, we have to call f() at least three times\n",
            "\n",
            "--- Chunk 17249 ---\n",
            "(we called it four times in the preceding code, but it could be optimized). If there\n",
            "\n",
            "--- Chunk 17250 ---\n",
            "were 1,000 parameters, we would need to call f() at least 1,001 times. When you are\n",
            "\n",
            "--- Chunk 17251 ---\n",
            "dealing with large neural networks, this makes finite difference approximation way\n",
            "too inefficient.\n",
            "\n",
            "--- Chunk 17252 ---\n",
            "too inefficient.\n",
            "However, this method is so simple to implement that it is a great tool to check that the\n",
            "\n",
            "--- Chunk 17253 ---\n",
            "other methods are implemented correctly. For example, if it disagrees with your man‐\n",
            "\n",
            "--- Chunk 17254 ---\n",
            "ually derived function, then your function probably contains a mistake.\n",
            "\n",
            "--- Chunk 17255 ---\n",
            "So far, we have considered two ways to compute gradients: using manual differentia‐\n",
            "\n",
            "--- Chunk 17256 ---\n",
            "tion and using finite difference approximation. Unfortunately, both were fatally\n",
            "\n",
            "--- Chunk 17257 ---\n",
            "flawed to train a large-scale neural network. So let’s turn to autodiff, starting with for‐\n",
            "ward mode.\n",
            "\n",
            "--- Chunk 17258 ---\n",
            "Forward-Mode Autodiff\n",
            "Figure D-1 shows how forward-mode autodiff works on an even simpler function,\n",
            "\n",
            "--- Chunk 17259 ---\n",
            "g(x, y) = 5 + xy. The graph for that function is represented on the left. After forward-\n",
            "\n",
            "--- Chunk 17260 ---\n",
            "mode autodiff, we get the graph on the right, which represents the partial derivative\n",
            "\n",
            "--- Chunk 17261 ---\n",
            "∂g/∂x = 0 + (0 × x + y × 1) = y (we could similarly obtain the partial derivative with\n",
            "regard to y).\n",
            "\n",
            "--- Chunk 17262 ---\n",
            "Figure D-1. Forward-mode autodiff\n",
            "\n",
            "Autodiff | 767\n",
            "\n",
            "--- Chunk 17263 ---\n",
            "The algorithm will go through the computation graph from the inputs to the outputs\n",
            "\n",
            "--- Chunk 17264 ---\n",
            "(hence the name “forward mode”). It starts by getting the partial derivatives of the\n",
            "\n",
            "--- Chunk 17265 ---\n",
            "leaf nodes. The constant node (5) returns the constant 0, since the derivative of a con‐\n",
            "\n",
            "--- Chunk 17266 ---\n",
            "stant is always 0. The variable x returns the constant 1 since ∂x/∂x = 1, and the vari‐\n",
            "\n",
            "--- Chunk 17267 ---\n",
            "able y returns the constant 0 since ∂y/∂x = 0 (if we were looking for the partial\n",
            "derivative with regard to y, it would be the reverse).\n",
            "\n",
            "--- Chunk 17268 ---\n",
            "Now we have all we need to move up the graph to the multiplication node in function\n",
            "\n",
            "--- Chunk 17269 ---\n",
            "g. Calculus tells us that the derivative of the product of two functions u and v is\n",
            "\n",
            "--- Chunk 17270 ---\n",
            "∂(u × v)/∂x = ∂v/∂x × u + v × ∂u/∂x. We can therefore construct a large part of the\n",
            "graph on the right, representing 0 × x + y × 1.\n",
            "\n",
            "--- Chunk 17271 ---\n",
            "Finally, we can go up to the addition node in function g. As mentioned, the derivative\n",
            "\n",
            "--- Chunk 17272 ---\n",
            "of a sum of functions is the sum of these functions’ derivatives. So we just need to\n",
            "\n",
            "--- Chunk 17273 ---\n",
            "create an addition node and connect it to the parts of the graph we have already com‐\n",
            "\n",
            "--- Chunk 17274 ---\n",
            "puted. We get the correct partial derivative: ∂g/∂x = 0 + (0 × x + y × 1).\n",
            "\n",
            "--- Chunk 17275 ---\n",
            "However, this equation can be simplified (a lot). A few pruning steps can be applied\n",
            "\n",
            "--- Chunk 17276 ---\n",
            "to the computation graph to get rid of all unnecessary operations, and we get a much\n",
            "\n",
            "--- Chunk 17277 ---\n",
            "smaller graph with just one node: ∂g/∂x = y. In this case simplification is fairly easy,\n",
            "\n",
            "--- Chunk 17278 ---\n",
            "but for a more complex function forward-mode autodiff can produce a huge graph\n",
            "that may be tough to simplify and lead to suboptimal performance.\n",
            "\n",
            "--- Chunk 17279 ---\n",
            "Note that we started with a computation graph, and forward-mode autodiff produced\n",
            "\n",
            "--- Chunk 17280 ---\n",
            "another computation graph. This is called symbolic differentiation, and it has two nice\n",
            "\n",
            "--- Chunk 17281 ---\n",
            "features: first, once the computation graph of the derivative has been produced, we\n",
            "\n",
            "--- Chunk 17282 ---\n",
            "can use it as many times as we want to compute the derivatives of the given function\n",
            "\n",
            "--- Chunk 17283 ---\n",
            "for any value of x and y; second, we can run forward-mode autodiff again on the\n",
            "\n",
            "--- Chunk 17284 ---\n",
            "resulting graph to get second-order derivatives if we ever need to (i.e., derivatives of\n",
            "\n",
            "--- Chunk 17285 ---\n",
            "derivatives). We could even compute third-order derivatives, and so on.\n",
            "\n",
            "--- Chunk 17286 ---\n",
            "But it is also possible to run forward-mode autodiff without constructing a graph\n",
            "\n",
            "--- Chunk 17287 ---\n",
            "(i.e., numerically, not symbolically), just by computing intermediate results on the fly.\n",
            "\n",
            "--- Chunk 17288 ---\n",
            "One way to do this is to use dual numbers, which are weird but fascinating numbers\n",
            "\n",
            "--- Chunk 17289 ---\n",
            "of the form a + bε, where a and b are real numbers and ε is an infinitesimal number\n",
            "\n",
            "--- Chunk 17290 ---\n",
            "such that ε2 = 0 (but ε ≠ 0). You can think of the dual number 42 + 24ε as something\n",
            "\n",
            "--- Chunk 17291 ---\n",
            "akin to 42.0000⋯000024 with an infinite number of 0s (but of course this is simpli‐\n",
            "\n",
            "--- Chunk 17292 ---\n",
            "fied just to give you some idea of what dual numbers are). A dual number is repre‐\n",
            "\n",
            "--- Chunk 17293 ---\n",
            "sented in memory as a pair of floats. For example, 42 + 24ε is represented by the pair\n",
            "(42.0, 24.0).\n",
            "\n",
            "--- Chunk 17294 ---\n",
            "768 | Appendix D: Autodiff\n",
            "\n",
            "\n",
            "\n",
            "Dual numbers can be added, multiplied, and so on, as shown in Equation D-3.\n",
            "\n",
            "--- Chunk 17295 ---\n",
            "Equation D-3. A few operations with dual numbers\n",
            "λ a + bε = λa + λbε\n",
            "a + bε + c + dε = a + c + b + d ε\n",
            "\n",
            "--- Chunk 17296 ---\n",
            "a + bε × c + dε = ac + ad + bc ε + bd ε2 = ac + ad + bc ε\n",
            "\n",
            "--- Chunk 17297 ---\n",
            "Most importantly, it can be shown that h(a + bε) = h(a) + b × h′(a)ε, so computing\n",
            "\n",
            "--- Chunk 17298 ---\n",
            "h(a + ε) gives you both h(a) and the derivative h′(a) in just one shot. Figure D-2\n",
            "\n",
            "--- Chunk 17299 ---\n",
            "shows that the partial derivative of f(x, y) with regard to x at x = 3 and y = 4 (which\n",
            "\n",
            "--- Chunk 17300 ---\n",
            "we will write ∂f/∂x (3, 4)) can be computed using dual numbers. All we need to do is\n",
            "\n",
            "--- Chunk 17301 ---\n",
            "compute f(3 + ε, 4); this will output a dual number whose first component is equal to\n",
            "f(3, 4) and whose second component is equal to ∂f/∂x (3, 4).\n",
            "\n",
            "--- Chunk 17302 ---\n",
            "Figure D-2. Forward-mode autodiff using dual numbers\n",
            "\n",
            "--- Chunk 17303 ---\n",
            "To compute ∂f/∂x (3, 4) we would have to go through the graph again, but this time\n",
            "with x = 3 and y = 4 + ε.\n",
            "\n",
            "--- Chunk 17304 ---\n",
            "So forward-mode autodiff is much more accurate than finite difference approxima‐\n",
            "\n",
            "--- Chunk 17305 ---\n",
            "tion, but it suffers from the same major flaw, at least when there are many inputs and\n",
            "\n",
            "--- Chunk 17306 ---\n",
            "few outputs (as is the case when dealing with neural networks): if there were 1,000\n",
            "\n",
            "--- Chunk 17307 ---\n",
            "parameters, it would require 1,000 passes through the graph to compute all the partial\n",
            "\n",
            "--- Chunk 17308 ---\n",
            "Autodiff | 769\n",
            "\n",
            "--- Chunk 17309 ---\n",
            "derivatives. This is where reverse-mode autodiff shines: it can compute all of them in\n",
            "just two passes through the graph. Let’s see how.\n",
            "\n",
            "--- Chunk 17310 ---\n",
            "Reverse-Mode Autodiff\n",
            "Reverse-mode autodiff is the solution implemented by TensorFlow. It first goes\n",
            "\n",
            "--- Chunk 17311 ---\n",
            "through the graph in the forward direction (i.e., from the inputs to the output) to\n",
            "\n",
            "--- Chunk 17312 ---\n",
            "compute the value of each node. Then it does a second pass, this time in the reverse\n",
            "\n",
            "--- Chunk 17313 ---\n",
            "direction (i.e., from the output to the inputs), to compute all the partial derivatives.\n",
            "\n",
            "--- Chunk 17314 ---\n",
            "The name “reverse mode” comes from this second pass through the graph, where gra‐\n",
            "\n",
            "--- Chunk 17315 ---\n",
            "dients flow in the reverse direction. Figure D-3 represents the second pass. During\n",
            "\n",
            "--- Chunk 17316 ---\n",
            "the first pass, all the node values were computed, starting from x = 3 and y = 4. You\n",
            "\n",
            "--- Chunk 17317 ---\n",
            "can see those values at the bottom right of each node (e.g., x × x = 9). The nodes are\n",
            "\n",
            "--- Chunk 17318 ---\n",
            "labeled n1 to n7 for clarity. The output node is n7: f(3, 4) = n7 = 42.\n",
            "\n",
            "--- Chunk 17319 ---\n",
            "Figure D-3. Reverse-mode autodiff\n",
            "\n",
            "770 | Appendix D: Autodiff\n",
            "\n",
            "--- Chunk 17320 ---\n",
            "The idea is to gradually go down the graph, computing the partial derivative of f(x, y)\n",
            "\n",
            "--- Chunk 17321 ---\n",
            "with regard to each consecutive node, until we reach the variable nodes. For this,\n",
            "\n",
            "--- Chunk 17322 ---\n",
            "reverse-mode autodiff relies heavily on the chain rule, shown in Equation D-4.\n",
            "\n",
            "--- Chunk 17323 ---\n",
            "Equation D-4. Chain rule\n",
            "∂ f ∂\n",
            "∂x = ∂ f n\n",
            "\n",
            "× i\n",
            "∂ni ∂x\n",
            "\n",
            "--- Chunk 17324 ---\n",
            "Since n7 is the output node, f = n7 so ∂f/∂n7 = 1.\n",
            "Let’s continue down the graph to n5: how much does f vary when n5 varies? The\n",
            "\n",
            "--- Chunk 17325 ---\n",
            "answer is ∂f/∂n5 = ∂f/∂n7 × ∂n7/∂n5. We already know that ∂f/∂n7 = 1, so all we need is\n",
            "\n",
            "--- Chunk 17326 ---\n",
            "∂n7/∂n5. Since n7 simply performs the sum n5 + n6, we find that ∂n7/∂n5 = 1, so ∂f/∂n5\n",
            "= 1 × 1 = 1.\n",
            "\n",
            "--- Chunk 17327 ---\n",
            "= 1 × 1 = 1.\n",
            "Now we can proceed to node n4: how much does f vary when n4 varies? The answer is\n",
            "\n",
            "--- Chunk 17328 ---\n",
            "∂f/∂n4 = ∂f/∂n5 × ∂n5/∂n4. Since n5 = n4 × n2, we find that ∂n5/∂n4 = n2, so ∂f/∂n4 = 1 ×\n",
            "n2 = 4.\n",
            "\n",
            "--- Chunk 17329 ---\n",
            "n2 = 4.\n",
            "The process continues until we reach the bottom of the graph. At that point we will\n",
            "\n",
            "--- Chunk 17330 ---\n",
            "have calculated all the partial derivatives of f(x, y) at the point x = 3 and y = 4. In this\n",
            "\n",
            "--- Chunk 17331 ---\n",
            "example, we find ∂f/∂x = 24 and ∂f/∂y = 10. Sounds about right!\n",
            "Reverse-mode autodiff is a very powerful and accurate technique, especially when\n",
            "\n",
            "--- Chunk 17332 ---\n",
            "there are many inputs and few outputs, since it requires only one forward pass plus\n",
            "\n",
            "--- Chunk 17333 ---\n",
            "one reverse pass per output to compute all the partial derivatives for all outputs with\n",
            "\n",
            "--- Chunk 17334 ---\n",
            "regard to all the inputs. When training neural networks, we generally want to mini‐\n",
            "\n",
            "--- Chunk 17335 ---\n",
            "mize the loss, so there is a single output (the loss), and hence only two passes through\n",
            "\n",
            "--- Chunk 17336 ---\n",
            "the graph are needed to compute the gradients. Reverse-mode autodiff can also han‐\n",
            "\n",
            "--- Chunk 17337 ---\n",
            "dle functions that are not entirely differentiable, as long as you ask it to compute the\n",
            "partial derivatives at points that are differentiable.\n",
            "\n",
            "--- Chunk 17338 ---\n",
            "In Figure D-3, the numerical results are computed on the fly, at each node. However,\n",
            "\n",
            "--- Chunk 17339 ---\n",
            "that’s not exactly what TensorFlow does: instead, it creates a new computation graph.\n",
            "\n",
            "--- Chunk 17340 ---\n",
            "In other words, it implements symbolic reverse-mode autodiff. This way, the compu‐\n",
            "\n",
            "--- Chunk 17341 ---\n",
            "tation graph to compute the gradients of the loss with regard to all the parameters in\n",
            "\n",
            "--- Chunk 17342 ---\n",
            "the neural network only needs to be generated once, and then it can be executed over\n",
            "\n",
            "--- Chunk 17343 ---\n",
            "and over again, whenever the optimizer needs to compute the gradients. Moreover,\n",
            "\n",
            "--- Chunk 17344 ---\n",
            "this makes it possible to compute higher-order derivatives if needed.\n",
            "\n",
            "--- Chunk 17345 ---\n",
            "Autodiff | 771\n",
            "\n",
            "--- Chunk 17346 ---\n",
            "If you ever want to implement a new type of low-level TensorFlow\n",
            "operation in C++, and you want to make it compatible with auto‐\n",
            "\n",
            "--- Chunk 17347 ---\n",
            "diff, then you will need to provide a function that returns the par‐\n",
            "tial derivatives of the function’s outputs with regard to its inputs.\n",
            "\n",
            "--- Chunk 17348 ---\n",
            "For example, suppose you implement a function that computes the\n",
            "square of its input: f(x) = x2. In that case you would need to provide\n",
            "\n",
            "--- Chunk 17349 ---\n",
            "the corresponding derivative function: f′(x) = 2x.\n",
            "\n",
            "--- Chunk 17350 ---\n",
            "772 | Appendix D: Autodiff\n",
            "\n",
            "\n",
            "\n",
            "APPENDIX E\n",
            "Other Popular ANN Architectures\n",
            "\n",
            "--- Chunk 17351 ---\n",
            "In this appendix I will give a quick overview of a few historically important neural\n",
            "\n",
            "--- Chunk 17352 ---\n",
            "network architectures that are much less used today than deep Multilayer Perceptrons\n",
            "\n",
            "--- Chunk 17353 ---\n",
            "(Chapter 10), convolutional neural networks (Chapter 14), recurrent neural networks\n",
            "\n",
            "--- Chunk 17354 ---\n",
            "(Chapter 15), or autoencoders (Chapter 17). They are often mentioned in the litera‐\n",
            "\n",
            "--- Chunk 17355 ---\n",
            "ture, and some are still used in a range of applications, so it is worth knowing about\n",
            "\n",
            "--- Chunk 17356 ---\n",
            "them. Additionally, we will discuss deep belief nets, which were the state of the art in\n",
            "\n",
            "--- Chunk 17357 ---\n",
            "Deep Learning until the early 2010s. They are still the subject of very active research,\n",
            "so they may well come back with a vengeance in the future.\n",
            "\n",
            "--- Chunk 17358 ---\n",
            "Hopfield Networks\n",
            "Hopfield networks were first introduced by W. A. Little in 1974, then popularized by J.\n",
            "\n",
            "--- Chunk 17359 ---\n",
            "Hopfield in 1982. They are associative memory networks: you first teach them some\n",
            "\n",
            "--- Chunk 17360 ---\n",
            "patterns, and then when they see a new pattern they (hopefully) output the closest\n",
            "\n",
            "--- Chunk 17361 ---\n",
            "learned pattern. This made them useful for character recognition, in particular,\n",
            "\n",
            "--- Chunk 17362 ---\n",
            "before they were outperformed by other approaches: you first train the network by\n",
            "\n",
            "--- Chunk 17363 ---\n",
            "showing it examples of character images (each binary pixel maps to one neuron), and\n",
            "\n",
            "--- Chunk 17364 ---\n",
            "then when you show it a new character image, after a few iterations it outputs the\n",
            "closest learned character.\n",
            "\n",
            "--- Chunk 17365 ---\n",
            "Hopfield networks are fully connected graphs (see Figure E-1); that is, every neuron\n",
            "\n",
            "--- Chunk 17366 ---\n",
            "is connected to every other neuron. Note that in the diagram the images are 6 × 6\n",
            "\n",
            "--- Chunk 17367 ---\n",
            "pixels, so the neural network on the left should contain 36 neurons (and 630 connec‐\n",
            "\n",
            "--- Chunk 17368 ---\n",
            "tions), but for visual clarity a much smaller network is represented.\n",
            "\n",
            "--- Chunk 17369 ---\n",
            "773\n",
            "\n",
            "\n",
            "\n",
            "Figure E-1. Hopfield network\n",
            "\n",
            "--- Chunk 17370 ---\n",
            "The training algorithm works by using Hebb’s rule (see “The Perceptron” on page\n",
            "\n",
            "--- Chunk 17371 ---\n",
            "284): for each training image, the weight between two neurons is increased if the cor‐\n",
            "\n",
            "--- Chunk 17372 ---\n",
            "responding pixels are both on or both off, but decreased if one pixel is on and the\n",
            "other is off.\n",
            "\n",
            "--- Chunk 17373 ---\n",
            "other is off.\n",
            "To show a new image to the network, you just activate the neurons that correspond to\n",
            "\n",
            "--- Chunk 17374 ---\n",
            "active pixels. The network then computes the output of every neuron, and this gives\n",
            "\n",
            "--- Chunk 17375 ---\n",
            "you a new image. You can then take this new image and repeat the whole process.\n",
            "\n",
            "--- Chunk 17376 ---\n",
            "After a while, the network reaches a stable state. Generally, this corresponds to the\n",
            "training image that most resembles the input image.\n",
            "\n",
            "--- Chunk 17377 ---\n",
            "A so-called energy function is associated with Hopfield nets. At each iteration, the\n",
            "\n",
            "--- Chunk 17378 ---\n",
            "energy decreases, so the network is guaranteed to eventually stabilize to a low-energy\n",
            "\n",
            "--- Chunk 17379 ---\n",
            "state. The training algorithm tweaks the weights in a way that decreases the energy\n",
            "\n",
            "--- Chunk 17380 ---\n",
            "level of the training patterns, so the network is likely to stabilize in one of these low-\n",
            "\n",
            "--- Chunk 17381 ---\n",
            "energy configurations. Unfortunately, some patterns that were not in the training set\n",
            "\n",
            "--- Chunk 17382 ---\n",
            "also end up with low energy, so the network sometimes stabilizes in a configuration\n",
            "that was not learned. These are called spurious patterns.\n",
            "\n",
            "--- Chunk 17383 ---\n",
            "Another major flaw with Hopfield nets is that they don’t scale very well—their mem‐\n",
            "\n",
            "--- Chunk 17384 ---\n",
            "ory capacity is roughly equal to 14% of the number of neurons. For example, to clas‐\n",
            "\n",
            "--- Chunk 17385 ---\n",
            "sify 28 × 28–pixel images, you would need a Hopfield net with 784 fully connected\n",
            "\n",
            "--- Chunk 17386 ---\n",
            "neurons and 306,936 weights. Such a network would only be able to learn about 110\n",
            "\n",
            "--- Chunk 17387 ---\n",
            "different characters (14% of 784). That’s a lot of parameters for such a small memory.\n",
            "\n",
            "--- Chunk 17388 ---\n",
            "774 | Appendix E: Other Popular ANN Architectures\n",
            "\n",
            "--- Chunk 17389 ---\n",
            "Boltzmann Machines\n",
            "Boltzmann machines were invented in 1985 by Geoffrey Hinton and Terrence Sejnow‐\n",
            "\n",
            "--- Chunk 17390 ---\n",
            "ski. Just like Hopfield nets, they are fully connected ANNs, but they are based on sto‐\n",
            "\n",
            "--- Chunk 17391 ---\n",
            "chastic neurons: instead of using a deterministic step function to decide what value to\n",
            "\n",
            "--- Chunk 17392 ---\n",
            "output, these neurons output 1 with some probability, and 0 otherwise. The probabil‐\n",
            "\n",
            "--- Chunk 17393 ---\n",
            "ity function that these ANNs use is based on the Boltzmann distribution (used in\n",
            "\n",
            "--- Chunk 17394 ---\n",
            "statistical mechanics), hence their name. Equation E-1 gives the probability that a\n",
            "particular neuron will output 1.\n",
            "\n",
            "--- Chunk 17395 ---\n",
            "Equation E-1. Probability that the ith neuron will output 1\n",
            "\n",
            "p s next step ∑N w\n",
            "= 1 = σ j = 1 i, js j + bi\n",
            "\n",
            "i T\n",
            "\n",
            "--- Chunk 17396 ---\n",
            "• sj is the jth neuron’s state (0 or 1).\n",
            "• wi,j is the connection weight between the ith and jth neurons. Note that wi,i = 0.\n",
            "\n",
            "--- Chunk 17397 ---\n",
            "• bi is the ith neuron’s bias term. We can implement this term by adding a bias neu‐\n",
            "\n",
            "--- Chunk 17398 ---\n",
            "ron to the network.\n",
            "• N is the number of neurons in the network.\n",
            "• T is a number called the network’s temperature; the higher the temperature, the\n",
            "\n",
            "--- Chunk 17399 ---\n",
            "more random the output is (i.e., the more the probability approaches 50%).\n",
            "• σ is the logistic function.\n",
            "\n",
            "--- Chunk 17400 ---\n",
            "Neurons in Boltzmann machines are separated into two groups: visible units and hid‐\n",
            "\n",
            "--- Chunk 17401 ---\n",
            "den units (see Figure E-2). All neurons work in the same stochastic way, but the visi‐\n",
            "\n",
            "--- Chunk 17402 ---\n",
            "ble units are the ones that receive the inputs and from which outputs are read.\n",
            "\n",
            "--- Chunk 17403 ---\n",
            "Because of its stochastic nature, a Boltzmann machine will never stabilize into a fixed\n",
            "\n",
            "--- Chunk 17404 ---\n",
            "configuration; instead, it will keep switching between many configurations. If it is left\n",
            "\n",
            "--- Chunk 17405 ---\n",
            "running for a sufficiently long time, the probability of observing a particular configu‐\n",
            "\n",
            "--- Chunk 17406 ---\n",
            "ration will only be a function of the connection weights and bias terms, not of the\n",
            "\n",
            "--- Chunk 17407 ---\n",
            "original configuration (similarly, after you shuffle a deck of cards for long enough, the\n",
            "\n",
            "--- Chunk 17408 ---\n",
            "configuration of the deck does not depend on the initial state). When the network\n",
            "\n",
            "--- Chunk 17409 ---\n",
            "reaches this state where the original configuration is “forgotten,” it is said to be in\n",
            "\n",
            "--- Chunk 17410 ---\n",
            "thermal equilibrium (although its configuration keeps changing all the time). By set‐\n",
            "\n",
            "--- Chunk 17411 ---\n",
            "ting the network parameters appropriately, letting the network reach thermal equili‐\n",
            "\n",
            "--- Chunk 17412 ---\n",
            "brium, and then observing its state, we can simulate a wide range of probability\n",
            "distributions. This is called a generative model.\n",
            "\n",
            "--- Chunk 17413 ---\n",
            "Other Popular ANN Architectures | 775\n",
            "\n",
            "\n",
            "\n",
            "Figure E-2. Boltzmann machine\n",
            "\n",
            "--- Chunk 17414 ---\n",
            "Training a Boltzmann machine means finding the parameters that will make the net‐\n",
            "\n",
            "--- Chunk 17415 ---\n",
            "work approximate the training set’s probability distribution. For example, if there are\n",
            "\n",
            "--- Chunk 17416 ---\n",
            "three visible neurons and the training set contains 75% (0, 1, 1) triplets, 10% (0, 0, 1)\n",
            "\n",
            "--- Chunk 17417 ---\n",
            "triplets, and 15% (1, 1, 1) triplets, then after training a Boltzmann machine, you could\n",
            "\n",
            "--- Chunk 17418 ---\n",
            "use it to generate random binary triplets with about the same probability distribu‐\n",
            "\n",
            "--- Chunk 17419 ---\n",
            "tion. For example, about 75% of the time it would output the (0, 1, 1) triplet.\n",
            "\n",
            "--- Chunk 17420 ---\n",
            "Such a generative model can be used in a variety of ways. For example, if it is trained\n",
            "\n",
            "--- Chunk 17421 ---\n",
            "on images, and you provide an incomplete or noisy image to the network, it will\n",
            "\n",
            "--- Chunk 17422 ---\n",
            "automatically “repair” the image in a reasonable way. You can also use a generative\n",
            "\n",
            "--- Chunk 17423 ---\n",
            "model for classification. Just add a few visible neurons to encode the training image’s\n",
            "\n",
            "--- Chunk 17424 ---\n",
            "class (e.g., add 10 visible neurons and turn on only the fifth neuron when the training\n",
            "\n",
            "--- Chunk 17425 ---\n",
            "image represents a 5). Then, when given a new image, the network will automatically\n",
            "\n",
            "--- Chunk 17426 ---\n",
            "turn on the appropriate visible neurons, indicating the image’s class (e.g., it will turn\n",
            "on the fifth visible neuron if the image represents a 5).\n",
            "\n",
            "--- Chunk 17427 ---\n",
            "Unfortunately, there is no efficient technique to train Boltzmann machines. However,\n",
            "\n",
            "--- Chunk 17428 ---\n",
            "fairly efficient algorithms have been developed to train restricted Boltzmann machines\n",
            "(RBMs).\n",
            "\n",
            "--- Chunk 17429 ---\n",
            "Restricted Boltzmann Machines\n",
            "An RBM is simply a Boltzmann machine in which there are no connections between\n",
            "\n",
            "--- Chunk 17430 ---\n",
            "visible units or between hidden units, only between visible and hidden units. For\n",
            "\n",
            "--- Chunk 17431 ---\n",
            "example, Figure E-3 represents an RBM with three visible units and four hidden\n",
            "units.\n",
            "\n",
            "--- Chunk 17432 ---\n",
            "776 | Appendix E: Other Popular ANN Architectures\n",
            "\n",
            "\n",
            "\n",
            "Figure E-3. Restricted Boltzmann machine\n",
            "\n",
            "--- Chunk 17433 ---\n",
            "A very efficient training algorithm called Contrastive Divergence was introduced in\n",
            "\n",
            "--- Chunk 17434 ---\n",
            "2005 by Miguel Á. Carreira-Perpiñán and Geoffrey Hinton.1 Here is how it works: for\n",
            "\n",
            "--- Chunk 17435 ---\n",
            "each training instance x, the algorithm starts by feeding it to the network by setting\n",
            "\n",
            "--- Chunk 17436 ---\n",
            "the state of the visible units to x1, x2, ⋯, xn. Then you compute the state of the hidden\n",
            "\n",
            "--- Chunk 17437 ---\n",
            "units by applying the stochastic equation described before (Equation E-1). This gives\n",
            "\n",
            "--- Chunk 17438 ---\n",
            "you a hidden vector h (where hi is equal to the state of the ith unit). Next you compute\n",
            "\n",
            "--- Chunk 17439 ---\n",
            "the state of the visible units, by applying the same stochastic equation. This gives you\n",
            "\n",
            "--- Chunk 17440 ---\n",
            "a vector xʹ. Then once again you compute the state of the hidden units, which gives\n",
            "\n",
            "--- Chunk 17441 ---\n",
            "you a vector hʹ. Now you can update each connection weight by applying the rule in\n",
            "Equation E-2, where η is the learning rate.\n",
            "\n",
            "--- Chunk 17442 ---\n",
            "Equation E-2. Contrastive divergence weight update\n",
            "\n",
            "wi, j wi, j + η xh⊺ − x′h′⊺\n",
            "\n",
            "--- Chunk 17443 ---\n",
            "The great benefit of this algorithm is that it does not require waiting for the network\n",
            "\n",
            "--- Chunk 17444 ---\n",
            "to reach thermal equilibrium: it just goes forward, backward, and forward again, and\n",
            "\n",
            "--- Chunk 17445 ---\n",
            "that’s it. This makes it incomparably more efficient than previous algorithms, and it\n",
            "\n",
            "--- Chunk 17446 ---\n",
            "was a key ingredient to the first success of Deep Learning based on multiple stacked\n",
            "RBMs.\n",
            "\n",
            "--- Chunk 17447 ---\n",
            "Deep Belief Nets\n",
            "Several layers of RBMs can be stacked; the hidden units of the first-level RBM serve\n",
            "\n",
            "--- Chunk 17448 ---\n",
            "as the visible units for the second-layer RBM, and so on. Such an RBM stack is called\n",
            "a deep belief net (DBN).\n",
            "\n",
            "--- Chunk 17449 ---\n",
            "1 Miguel Á. Carreira-Perpiñán and Geoffrey E. Hinton, “On Contrastive Divergence Learning,” Proceedings of\n",
            "\n",
            "--- Chunk 17450 ---\n",
            "the 10th International Workshop on Artificial Intelligence and Statistics (2005): 59–66.\n",
            "\n",
            "--- Chunk 17451 ---\n",
            "Other Popular ANN Architectures | 777\n",
            "\n",
            "--- Chunk 17452 ---\n",
            "Yee-Whye Teh, one of Geoffrey Hinton’s students, observed that it was possible to\n",
            "\n",
            "--- Chunk 17453 ---\n",
            "train DBNs one layer at a time using Contrastive Divergence, starting with the lower\n",
            "\n",
            "--- Chunk 17454 ---\n",
            "layers and then gradually moving up to the top layers. This led to the groundbreaking\n",
            "article that kickstarted the Deep Learning tsunami in 2006.2\n",
            "\n",
            "--- Chunk 17455 ---\n",
            "Just like RBMs, DBNs learn to reproduce the probability distribution of their inputs,\n",
            "\n",
            "--- Chunk 17456 ---\n",
            "without any supervision. However, they are much better at it, for the same reason that\n",
            "\n",
            "--- Chunk 17457 ---\n",
            "deep neural networks are more powerful than shallow ones: real-world data is often\n",
            "\n",
            "--- Chunk 17458 ---\n",
            "organized in hierarchical patterns, and DBNs take advantage of that. Their lower lay‐\n",
            "\n",
            "--- Chunk 17459 ---\n",
            "ers learn low-level features in the input data, while higher layers learn high-level\n",
            "features.\n",
            "\n",
            "--- Chunk 17460 ---\n",
            "features.\n",
            "Just like RBMs, DBNs are fundamentally unsupervised, but you can also train them\n",
            "\n",
            "--- Chunk 17461 ---\n",
            "in a supervised manner by adding some visible units to represent the labels. More‐\n",
            "\n",
            "--- Chunk 17462 ---\n",
            "over, one great feature of DBNs is that they can be trained in a semisupervised fash‐\n",
            "\n",
            "--- Chunk 17463 ---\n",
            "ion. Figure E-4 represents such a DBN configured for semisupervised learning.\n",
            "\n",
            "--- Chunk 17464 ---\n",
            "Figure E-4. A deep belief network configured for semisupervised learning\n",
            "\n",
            "--- Chunk 17465 ---\n",
            "First, RBM 1 is trained without supervision. It learns low-level features in the training\n",
            "\n",
            "--- Chunk 17466 ---\n",
            "data. Then RBM 2 is trained with RBM 1’s hidden units as inputs, again without\n",
            "\n",
            "--- Chunk 17467 ---\n",
            "2 Geoffrey E. Hinton et al., “A Fast Learning Algorithm for Deep Belief Nets,” Neural Computation 18 (2006):\n",
            "1527–1554.\n",
            "\n",
            "--- Chunk 17468 ---\n",
            "778 | Appendix E: Other Popular ANN Architectures\n",
            "\n",
            "--- Chunk 17469 ---\n",
            "supervision: it learns higher-level features (note that RBM 2’s hidden units include\n",
            "\n",
            "--- Chunk 17470 ---\n",
            "only the three rightmost units, not the label units). Several more RBMs could be\n",
            "\n",
            "--- Chunk 17471 ---\n",
            "stacked this way, but you get the idea. So far, training was 100% unsupervised. Lastly,\n",
            "\n",
            "--- Chunk 17472 ---\n",
            "RBM 3 is trained using RBM 2’s hidden units as inputs, as well as extra visible units\n",
            "\n",
            "--- Chunk 17473 ---\n",
            "used to represent the target labels (e.g., a one-hot vector representing the instance\n",
            "\n",
            "--- Chunk 17474 ---\n",
            "class). It learns to associate high-level features with training labels. This is the super‐\n",
            "vised step.\n",
            "\n",
            "--- Chunk 17475 ---\n",
            "vised step.\n",
            "At the end of training, if you feed RBM 1 a new instance, the signal will propagate up\n",
            "\n",
            "--- Chunk 17476 ---\n",
            "to RBM 2, then up to the top of RBM 3, and then back down to the label units; hope‐\n",
            "\n",
            "--- Chunk 17477 ---\n",
            "fully, the appropriate label will light up. This is how a DBN can be used for\n",
            "classification.\n",
            "\n",
            "--- Chunk 17478 ---\n",
            "classification.\n",
            "One great benefit of this semisupervised approach is that you don’t need much\n",
            "\n",
            "--- Chunk 17479 ---\n",
            "labeled training data. If the unsupervised RBMs do a good enough job, then only a\n",
            "\n",
            "--- Chunk 17480 ---\n",
            "small amount of labeled training instances per class will be necessary. Similarly, a\n",
            "\n",
            "--- Chunk 17481 ---\n",
            "baby learns to recognize objects without supervision, so when you point to a chair\n",
            "\n",
            "--- Chunk 17482 ---\n",
            "and say “chair,” the baby can associate the word “chair” with the class of objects it has\n",
            "\n",
            "--- Chunk 17483 ---\n",
            "already learned to recognize on its own. You don’t need to point to every single chair\n",
            "\n",
            "--- Chunk 17484 ---\n",
            "and say “chair”; only a few examples will suffice (just enough so the baby can be sure\n",
            "\n",
            "--- Chunk 17485 ---\n",
            "that you are indeed referring to the chair, not to its color or one of the chair’s parts).\n",
            "\n",
            "--- Chunk 17486 ---\n",
            "Quite amazingly, DBNs can also work in reverse. If you activate one of the label units,\n",
            "\n",
            "--- Chunk 17487 ---\n",
            "the signal will propagate up to the hidden units of RBM 3, then down to RBM 2, and\n",
            "\n",
            "--- Chunk 17488 ---\n",
            "then RBM 1, and a new instance will be output by the visible units of RBM 1. This\n",
            "\n",
            "--- Chunk 17489 ---\n",
            "new instance will usually look like a regular instance of the class whose label unit you\n",
            "\n",
            "--- Chunk 17490 ---\n",
            "activated. This generative capability of DBNs is quite powerful. For example, it has\n",
            "\n",
            "--- Chunk 17491 ---\n",
            "been used to automatically generate captions for images, and vice versa: first a DBN is\n",
            "\n",
            "--- Chunk 17492 ---\n",
            "trained (without supervision) to learn features in images, and another DBN is trained\n",
            "\n",
            "--- Chunk 17493 ---\n",
            "(again without supervision) to learn features in sets of captions (e.g., “car” often\n",
            "\n",
            "--- Chunk 17494 ---\n",
            "comes with “automobile”). Then an RBM is stacked on top of both DBNs and trained\n",
            "\n",
            "--- Chunk 17495 ---\n",
            "with a set of images along with their captions; it learns to associate high-level features\n",
            "\n",
            "--- Chunk 17496 ---\n",
            "in images with high-level features in captions. Next, if you feed the image DBN an\n",
            "\n",
            "--- Chunk 17497 ---\n",
            "image of a car, the signal will propagate through the network, up to the top-level\n",
            "\n",
            "--- Chunk 17498 ---\n",
            "RBM, and back down to the bottom of the caption DBN, producing a caption. Due to\n",
            "\n",
            "--- Chunk 17499 ---\n",
            "the stochastic nature of RBMs and DBNs, the caption will keep changing randomly,\n",
            "\n",
            "--- Chunk 17500 ---\n",
            "but it will generally be appropriate for the image. If you generate a few hundred cap‐\n",
            "\n",
            "--- Chunk 17501 ---\n",
            "tions, the most frequently generated ones will likely be a good description of the\n",
            "image.3\n",
            "\n",
            "--- Chunk 17502 ---\n",
            "3 See this video by Geoffrey Hinton for more details and a demo: https://homl.info/137.\n",
            "\n",
            "Other Popular ANN Architectures | 779\n",
            "\n",
            "--- Chunk 17503 ---\n",
            "Self-Organizing Maps\n",
            "Self-organizing maps (SOMs) are quite different from all the other types of neural net‐\n",
            "\n",
            "--- Chunk 17504 ---\n",
            "works we have discussed so far. They are used to produce a low-dimensional repre‐\n",
            "\n",
            "--- Chunk 17505 ---\n",
            "sentation of a high-dimensional dataset, generally for visualization, clustering, or\n",
            "\n",
            "--- Chunk 17506 ---\n",
            "classification. The neurons are spread across a map (typically 2D for visualization,\n",
            "\n",
            "--- Chunk 17507 ---\n",
            "but it can be any number of dimensions you want), as shown in Figure E-5, and each\n",
            "\n",
            "--- Chunk 17508 ---\n",
            "neuron has a weighted connection to every input (note that the diagram shows just\n",
            "\n",
            "--- Chunk 17509 ---\n",
            "two inputs, but there are typically a very large number, since the whole point of\n",
            "SOMs is to reduce dimensionality).\n",
            "\n",
            "--- Chunk 17510 ---\n",
            "Figure E-5. Self-organizing map\n",
            "\n",
            "--- Chunk 17511 ---\n",
            "Once the network is trained, you can feed it a new instance and this will activate only\n",
            "\n",
            "--- Chunk 17512 ---\n",
            "one neuron (i.e., one point on the map): the neuron whose weight vector is closest to\n",
            "\n",
            "--- Chunk 17513 ---\n",
            "the input vector. In general, instances that are nearby in the original input space will\n",
            "\n",
            "--- Chunk 17514 ---\n",
            "activate neurons that are nearby on the map. This makes SOMs useful not only for\n",
            "\n",
            "--- Chunk 17515 ---\n",
            "visualization (in particular, you can easily identify clusters on the map), but also for\n",
            "\n",
            "--- Chunk 17516 ---\n",
            "applications like speech recognition. For example, if each instance represents an\n",
            "\n",
            "--- Chunk 17517 ---\n",
            "audio recording of a person pronouncing a vowel, then different pronunciations of\n",
            "\n",
            "--- Chunk 17518 ---\n",
            "the vowel “a” will activate neurons in the same area of the map, while instances of the\n",
            "\n",
            "--- Chunk 17519 ---\n",
            "vowel “e” will activate neurons in another area, and intermediate sounds will gener‐\n",
            "ally activate intermediate neurons on the map.\n",
            "\n",
            "--- Chunk 17520 ---\n",
            "780 | Appendix E: Other Popular ANN Architectures\n",
            "\n",
            "--- Chunk 17521 ---\n",
            "One important difference from the other dimensionality reduction\n",
            "techniques discussed in Chapter 8 is that all instances get mapped\n",
            "\n",
            "--- Chunk 17522 ---\n",
            "to a discrete number of points in the low-dimensional space (one\n",
            "point per neuron). When there are very few neurons, this techni‐\n",
            "\n",
            "--- Chunk 17523 ---\n",
            "que is better described as clustering rather than dimensionality\n",
            "reduction.\n",
            "\n",
            "--- Chunk 17524 ---\n",
            "The training algorithm is unsupervised. It works by having all the neurons compete\n",
            "\n",
            "--- Chunk 17525 ---\n",
            "against each other. First, all the weights are initialized randomly. Then a training\n",
            "\n",
            "--- Chunk 17526 ---\n",
            "instance is picked randomly and fed to the network. All neurons compute the dis‐\n",
            "\n",
            "--- Chunk 17527 ---\n",
            "tance between their weight vector and the input vector (this is very different from the\n",
            "\n",
            "--- Chunk 17528 ---\n",
            "artificial neurons we have seen so far). The neuron that measures the smallest dis‐\n",
            "\n",
            "--- Chunk 17529 ---\n",
            "tance wins and tweaks its weight vector to be slightly closer to the input vector, mak‐\n",
            "\n",
            "--- Chunk 17530 ---\n",
            "ing it more likely to win future competitions for other inputs similar to this one. It\n",
            "\n",
            "--- Chunk 17531 ---\n",
            "also recruits its neighboring neurons, and they too update their weight vectors to be\n",
            "\n",
            "--- Chunk 17532 ---\n",
            "slightly closer to the input vector (but they don’t update their weights as much as the\n",
            "\n",
            "--- Chunk 17533 ---\n",
            "winning neuron). Then the algorithm picks another training instance and repeats the\n",
            "\n",
            "--- Chunk 17534 ---\n",
            "process, again and again. This algorithm tends to make nearby neurons gradually\n",
            "specialize in similar inputs.4\n",
            "\n",
            "--- Chunk 17535 ---\n",
            "4 You can imagine a class of young children with roughly similar skills. One child happens to be slightly better\n",
            "\n",
            "--- Chunk 17536 ---\n",
            "at basketball. This motivates them to practice more, especially with their friends. After a while, this group of\n",
            "\n",
            "--- Chunk 17537 ---\n",
            "friends gets so good at basketball that other kids cannot compete. But that’s okay, because the other kids spe‐\n",
            "\n",
            "--- Chunk 17538 ---\n",
            "cialize in other areas. After a while, the class is full of little specialized groups.\n",
            "\n",
            "--- Chunk 17539 ---\n",
            "Other Popular ANN Architectures | 781\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "APPENDIX F\n",
            "Special Data Structures\n",
            "\n",
            "--- Chunk 17540 ---\n",
            "In this appendix we will take a very quick look at the data structures supported by\n",
            "\n",
            "--- Chunk 17541 ---\n",
            "TensorFlow, beyond regular float or integer tensors. This includes strings, ragged ten‐\n",
            "sors, sparse tensors, tensor arrays, sets, and queues.\n",
            "\n",
            "--- Chunk 17542 ---\n",
            "Strings\n",
            "Tensors can hold byte strings, which is useful in particular for natural language pro‐\n",
            "cessing (see Chapter 16):\n",
            "\n",
            "--- Chunk 17543 ---\n",
            ">>> tf.constant(b\"hello world\")\n",
            "<tf.Tensor: id=149, shape=(), dtype=string, numpy=b'hello world'>\n",
            "\n",
            "--- Chunk 17544 ---\n",
            "If you try to build a tensor with a Unicode string, TensorFlow automatically encodes\n",
            "it to UTF-8:\n",
            "\n",
            "--- Chunk 17545 ---\n",
            ">>> tf.constant(\"café\")\n",
            "<tf.Tensor: id=138, shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>\n",
            "\n",
            "--- Chunk 17546 ---\n",
            "It is also possible to create tensors representing Unicode strings. Just create an array\n",
            "\n",
            "--- Chunk 17547 ---\n",
            "of 32-bit integers, each representing a single Unicode code point:1\n",
            "\n",
            "--- Chunk 17548 ---\n",
            ">>> tf.constant([ord(c) for c in \"café\"])\n",
            "<tf.Tensor: id=211, shape=(4,), dtype=int32,\n",
            "            numpy=array([ 99,  97, 102, 233], dtype=int32)>\n",
            "\n",
            "--- Chunk 17549 ---\n",
            "1 If you are not familiar with Unicode code points, please check out https://homl.info/unicode.\n",
            "\n",
            "783\n",
            "\n",
            "--- Chunk 17550 ---\n",
            "In tensors of type tf.string, the string length is not part of the ten‐\n",
            "sor’s shape. In other words, strings are considered as atomic values.\n",
            "\n",
            "--- Chunk 17551 ---\n",
            "However, in a Unicode string tensor (i.e., an int32 tensor), the\n",
            "length of the string is part of the tensor’s shape.\n",
            "\n",
            "--- Chunk 17552 ---\n",
            "The tf.strings package contains several functions to manipulate string tensors,\n",
            "\n",
            "--- Chunk 17553 ---\n",
            "such as length() to count the number of bytes in a byte string (or the number of\n",
            "\n",
            "--- Chunk 17554 ---\n",
            "code points if you set unit=\"UTF8_CHAR\"), unicode_encode() to convert a Unicode\n",
            "\n",
            "--- Chunk 17555 ---\n",
            "string tensor (i.e., int32 tensor) to a byte string tensor, and unicode_decode() to do\n",
            "the reverse:\n",
            "\n",
            "--- Chunk 17556 ---\n",
            ">>> b = tf.strings.unicode_encode(u, \"UTF-8\")\n",
            ">>> tf.strings.length(b, unit=\"UTF8_CHAR\")\n",
            "<tf.Tensor: id=386, shape=(), dtype=int32, numpy=4>\n",
            "\n",
            "--- Chunk 17557 ---\n",
            ">>> tf.strings.unicode_decode(b, \"UTF-8\")\n",
            "<tf.Tensor: id=393, shape=(4,), dtype=int32,\n",
            "            numpy=array([ 99,  97, 102, 233], dtype=int32)>\n",
            "\n",
            "--- Chunk 17558 ---\n",
            "You can also manipulate tensors containing multiple strings:\n",
            ">>> p = tf.constant([\"Café\", \"Coffee\", \"caffè\", \"咖啡\"])\n",
            "\n",
            "--- Chunk 17559 ---\n",
            ">>> tf.strings.length(p, unit=\"UTF8_CHAR\")\n",
            "<tf.Tensor: id=299, shape=(4,), dtype=int32,\n",
            "            numpy=array([4, 6, 5, 2], dtype=int32)>\n",
            "\n",
            "--- Chunk 17560 ---\n",
            ">>> r = tf.strings.unicode_decode(p, \"UTF8\")\n",
            ">>> r\n",
            "tf.RaggedTensor(values=tf.Tensor(\n",
            "\n",
            "--- Chunk 17561 ---\n",
            "[   67    97   102   233    67   111   102   102   101   101    99    97\n",
            "   102   102   232 21654 21857], shape=(17,), dtype=int32),\n",
            "\n",
            "--- Chunk 17562 ---\n",
            "row_splits=tf.Tensor([ 0  4 10 15 17], shape=(5,), dtype=int64))\n",
            ">>> print(r)\n",
            "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
            "\n",
            "--- Chunk 17563 ---\n",
            "[99, 97, 102, 102, 232], [21654, 21857]]>\n",
            "\n",
            "--- Chunk 17564 ---\n",
            "Notice that the decoded strings are stored in a RaggedTensor. What is that?\n",
            "\n",
            "--- Chunk 17565 ---\n",
            "Ragged Tensors\n",
            "A ragged tensor is a special kind of tensor that represents a list of arrays of different\n",
            "\n",
            "--- Chunk 17566 ---\n",
            "sizes. More generally, it is a tensor with one or more ragged dimensions, meaning\n",
            "\n",
            "--- Chunk 17567 ---\n",
            "dimensions whose slices may have different lengths. In the ragged tensor r, the sec‐\n",
            "\n",
            "--- Chunk 17568 ---\n",
            "ond dimension is a ragged dimension. In all ragged tensors, the first dimension is\n",
            "always a regular dimension (also called a uniform dimension).\n",
            "\n",
            "--- Chunk 17569 ---\n",
            "784 | Appendix F: Special Data Structures\n",
            "\n",
            "--- Chunk 17570 ---\n",
            "All the elements of the ragged tensor r are regular tensors. For example, let’s look at\n",
            "the second element of the ragged tensor:\n",
            "\n",
            "--- Chunk 17571 ---\n",
            ">>> print(r[1])\n",
            "tf.Tensor([ 67 111 102 102 101 101], shape=(6,), dtype=int32)\n",
            "\n",
            "--- Chunk 17572 ---\n",
            "The tf.ragged package contains several functions to create and manipulate ragged\n",
            "\n",
            "--- Chunk 17573 ---\n",
            "tensors. Let’s create a second ragged tensor using tf.ragged.constant() and concat‐\n",
            "enate it with the first ragged tensor, along axis 0:\n",
            "\n",
            "--- Chunk 17574 ---\n",
            ">>> r2 = tf.ragged.constant([[65, 66], [], [67]])\n",
            ">>> print(tf.concat([r, r2], axis=0))\n",
            "\n",
            "--- Chunk 17575 ---\n",
            "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97,\n",
            "102, 102, 232], [21654, 21857], [65, 66], [], [67]]>\n",
            "\n",
            "--- Chunk 17576 ---\n",
            "The result is not too surprising: the tensors in r2 were appended after the tensors in r\n",
            "\n",
            "--- Chunk 17577 ---\n",
            "along axis 0. But what if we concatenate r and another ragged tensor along axis 1?\n",
            "\n",
            "--- Chunk 17578 ---\n",
            ">>> r3 = tf.ragged.constant([[68, 69, 70], [71], [], [72, 73]])\n",
            ">>> print(tf.concat([r, r3], axis=1))\n",
            "\n",
            "--- Chunk 17579 ---\n",
            "<tf.RaggedTensor [[67, 97, 102, 233, 68, 69, 70], [67, 111, 102, 102, 101, 101,\n",
            "71], [99, 97, 102, 102, 232], [21654, 21857, 72, 73]]>\n",
            "\n",
            "--- Chunk 17580 ---\n",
            "This time, notice that the ith tensor in r and the ith tensor in r3 were concatenated.\n",
            "\n",
            "--- Chunk 17581 ---\n",
            "Now that’s more unusual, since all of these tensors can have different lengths.\n",
            "\n",
            "--- Chunk 17582 ---\n",
            "If you call the to_tensor() method, it gets converted to a regular tensor, padding\n",
            "\n",
            "--- Chunk 17583 ---\n",
            "shorter tensors with zeros to get tensors of equal lengths (you can change the default\n",
            "value by setting the default_value argument):\n",
            "\n",
            "--- Chunk 17584 ---\n",
            ">>> r.to_tensor()\n",
            "<tf.Tensor: id=1056, shape=(4, 6), dtype=int32, numpy=\n",
            "array([[   67,    97,   102,   233,     0,     0],\n",
            "\n",
            "--- Chunk 17585 ---\n",
            "[   67,   111,   102,   102,   101,   101],\n",
            "       [   99,    97,   102,   102,   232,     0],\n",
            "\n",
            "--- Chunk 17586 ---\n",
            "[21654, 21857,     0,     0,     0,     0]], dtype=int32)>\n",
            "\n",
            "--- Chunk 17587 ---\n",
            "Many TF operations support ragged tensors. For the full list, see the documentation\n",
            "of the tf.RaggedTensor class.\n",
            "\n",
            "--- Chunk 17588 ---\n",
            "Sparse Tensors\n",
            "TensorFlow can also efficiently represent sparse tensors (i.e., tensors containing\n",
            "\n",
            "--- Chunk 17589 ---\n",
            "mostly zeros). Just create a tf.SparseTensor, specifying the indices and values of the\n",
            "\n",
            "--- Chunk 17590 ---\n",
            "nonzero elements and the tensor’s shape. The indices must be listed in “reading\n",
            "\n",
            "--- Chunk 17591 ---\n",
            "order” (from left to right, and top to bottom). If you are unsure, just use\n",
            "\n",
            "--- Chunk 17592 ---\n",
            "tf.sparse.reorder(). You can convert a sparse tensor to a dense tensor (i.e., a regu‐\n",
            "lar tensor) using tf.sparse.to_dense():\n",
            "\n",
            "--- Chunk 17593 ---\n",
            "Special Data Structures | 785\n",
            "\n",
            "--- Chunk 17594 ---\n",
            ">>> s = tf.SparseTensor(indices=[[0, 1], [1, 0], [2, 3]],\n",
            "                        values=[1., 2., 3.],\n",
            "                        dense_shape=[3, 4])\n",
            "\n",
            "--- Chunk 17595 ---\n",
            ">>> tf.sparse.to_dense(s)\n",
            "<tf.Tensor: id=1074, shape=(3, 4), dtype=float32, numpy=\n",
            "array([[0., 1., 0., 0.],\n",
            "       [2., 0., 0., 0.],\n",
            "\n",
            "--- Chunk 17596 ---\n",
            "[0., 0., 0., 3.]], dtype=float32)>\n",
            "\n",
            "--- Chunk 17597 ---\n",
            "Note that sparse tensors do not support as many operations as dense tensors. For\n",
            "\n",
            "--- Chunk 17598 ---\n",
            "example, you can multiply a sparse tensor by any scalar value, and you get a new\n",
            "\n",
            "--- Chunk 17599 ---\n",
            "sparse tensor, but you cannot add a scalar value to a sparse tensor, as this would not\n",
            "return a sparse tensor:\n",
            "\n",
            "--- Chunk 17600 ---\n",
            ">>> s * 3.14\n",
            "<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x13205d470>\n",
            ">>> s + 42.0\n",
            "\n",
            "--- Chunk 17601 ---\n",
            ">>> s + 42.0\n",
            "[...] TypeError: unsupported operand type(s) for +: 'SparseTensor' and 'float'\n",
            "\n",
            "--- Chunk 17602 ---\n",
            "Tensor Arrays\n",
            "A tf.TensorArray represents a list of tensors. This can be handy in dynamic models\n",
            "\n",
            "--- Chunk 17603 ---\n",
            "containing loops, to accumulate results and later compute some statistics. You can\n",
            "read or write tensors at any location in the array:\n",
            "\n",
            "--- Chunk 17604 ---\n",
            "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
            "array = array.write(0, tf.constant([1., 2.]))\n",
            "array = array.write(1, tf.constant([3., 10.]))\n",
            "\n",
            "--- Chunk 17605 ---\n",
            "array = array.write(2, tf.constant([5., 7.]))\n",
            "tensor1 = array.read(1) # => returns (and pops!) tf.constant([3., 10.])\n",
            "\n",
            "--- Chunk 17606 ---\n",
            "Notice that reading an item pops it from the array, replacing it with a tensor of the\n",
            "same shape, full of zeros.\n",
            "\n",
            "--- Chunk 17607 ---\n",
            "When you write to the array, you must assign the output back to\n",
            "the array, as shown in this code example. If you don’t, although\n",
            "\n",
            "--- Chunk 17608 ---\n",
            "your code will work fine in eager mode, it will break in graph mode\n",
            "(these modes were presented in Chapter 12).\n",
            "\n",
            "--- Chunk 17609 ---\n",
            "When creating a TensorArray, you must provide its size, except in graph mode.\n",
            "\n",
            "--- Chunk 17610 ---\n",
            "Alternatively, you can leave the size unset and instead set dynamic_size=True, but\n",
            "\n",
            "--- Chunk 17611 ---\n",
            "this will hinder performance, so if you know the size in advance, you should set it.\n",
            "\n",
            "--- Chunk 17612 ---\n",
            "You must also specify the dtype, and all elements must have the same shape as the\n",
            "first one written to the array.\n",
            "\n",
            "--- Chunk 17613 ---\n",
            "You can stack all the items into a regular tensor by calling the stack() method:\n",
            "\n",
            "--- Chunk 17614 ---\n",
            "786 | Appendix F: Special Data Structures\n",
            "\n",
            "--- Chunk 17615 ---\n",
            ">>> array.stack()\n",
            "<tf.Tensor: id=2110875, shape=(3, 2), dtype=float32, numpy=\n",
            "array([[1., 2.],\n",
            "       [0., 0.],\n",
            "       [5., 7.]], dtype=float32)>\n",
            "\n",
            "--- Chunk 17616 ---\n",
            "Sets\n",
            "TensorFlow supports sets of integers or strings (but not floats). It represents them\n",
            "\n",
            "--- Chunk 17617 ---\n",
            "using regular tensors. For example, the set {1, 5, 9} is just represented as the tensor\n",
            "\n",
            "--- Chunk 17618 ---\n",
            "[[1, 5, 9]]. Note that the tensor must have at least two dimensions, and the sets\n",
            "\n",
            "--- Chunk 17619 ---\n",
            "must be in the last dimension. For example, [[1, 5, 9], [2, 5, 11]] is a tensor\n",
            "\n",
            "--- Chunk 17620 ---\n",
            "holding two independent sets: {1, 5, 9} and {2, 5, 11}. If some sets are shorter\n",
            "\n",
            "--- Chunk 17621 ---\n",
            "than others, you must pad them with a padding value (0 by default, but you can use\n",
            "any other value you prefer).\n",
            "\n",
            "--- Chunk 17622 ---\n",
            "The tf.sets package contains several functions to manipulate sets. For example, let’s\n",
            "\n",
            "--- Chunk 17623 ---\n",
            "create two sets and compute their union (the result is a sparse tensor, so we call\n",
            "to_dense() to display it):\n",
            "\n",
            "--- Chunk 17624 ---\n",
            ">>> a = tf.constant([[1, 5, 9]])\n",
            ">>> b = tf.constant([[5, 6, 9, 11]])\n",
            ">>> u = tf.sets.union(a, b)\n",
            ">>> u\n",
            "\n",
            "--- Chunk 17625 ---\n",
            ">>> u\n",
            "<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x132b60d30>\n",
            ">>> tf.sparse.to_dense(u)\n",
            "\n",
            "--- Chunk 17626 ---\n",
            "<tf.Tensor: [...] numpy=array([[ 1,  5,  6,  9, 11]], dtype=int32)>\n",
            "\n",
            "--- Chunk 17627 ---\n",
            "You can also compute the union of multiple pairs of sets simultaneously:\n",
            ">>> a = tf.constant([[1, 5, 9], [10, 0, 0]])\n",
            "\n",
            "--- Chunk 17628 ---\n",
            ">>> b = tf.constant([[5, 6, 9, 11], [13, 0, 0, 0, 0]])\n",
            ">>> u = tf.sets.union(a, b)\n",
            ">>> tf.sparse.to_dense(u)\n",
            "\n",
            "--- Chunk 17629 ---\n",
            "<tf.Tensor: [...] numpy=array([[ 1,  5,  6,  9, 11],\n",
            "                               [ 0, 10, 13,  0,  0]], dtype=int32)>\n",
            "\n",
            "--- Chunk 17630 ---\n",
            "If you prefer to use a different padding value, you must set default_value when call‐\n",
            "ing to_dense():\n",
            "\n",
            "--- Chunk 17631 ---\n",
            ">>> tf.sparse.to_dense(u, default_value=-1)\n",
            "<tf.Tensor: [...] numpy=array([[ 1,  5,  6,  9, 11],\n",
            "\n",
            "--- Chunk 17632 ---\n",
            "[ 0, 10, 13, -1, -1]], dtype=int32)>\n",
            "\n",
            "--- Chunk 17633 ---\n",
            "The default default_value is 0, so when dealing with string sets,\n",
            "you must set the default_value (e.g., to an empty string).\n",
            "\n",
            "--- Chunk 17634 ---\n",
            "Special Data Structures | 787\n",
            "\n",
            "--- Chunk 17635 ---\n",
            "Other functions available in tf.sets include difference(), intersection(), and\n",
            "\n",
            "--- Chunk 17636 ---\n",
            "size(), which are self-explanatory. If you want to check whether or not a set contains\n",
            "\n",
            "--- Chunk 17637 ---\n",
            "some given values, you can compute the intersection of that set and the values. If you\n",
            "\n",
            "--- Chunk 17638 ---\n",
            "want to add some values to a set, you can compute the union of the set and the values.\n",
            "\n",
            "--- Chunk 17639 ---\n",
            "Queues\n",
            "A queue is a data structure to which you can push data records, and later pull them\n",
            "\n",
            "--- Chunk 17640 ---\n",
            "out. TensorFlow implements several types of queues in the tf.queue package. They\n",
            "\n",
            "--- Chunk 17641 ---\n",
            "used to be very important when implementing efficient data loading and preprocess‐\n",
            "\n",
            "--- Chunk 17642 ---\n",
            "ing pipelines, but the tf.data API has essentially rendered them useless (except per‐\n",
            "\n",
            "--- Chunk 17643 ---\n",
            "haps in some rare cases) because it is much simpler to use and provides all the tools\n",
            "\n",
            "--- Chunk 17644 ---\n",
            "you need to build efficient pipelines. For the sake of completeness, though, let’s take a\n",
            "quick look at them.\n",
            "\n",
            "--- Chunk 17645 ---\n",
            "quick look at them.\n",
            "The simplest kind of queue is the first-in, first-out (FIFO) queue. To build it, you\n",
            "\n",
            "--- Chunk 17646 ---\n",
            "need to specify the maximum number of records it can contain. Moreover, each\n",
            "\n",
            "--- Chunk 17647 ---\n",
            "record is a tuple of tensors, so you must specify the type of each tensor, and option‐\n",
            "\n",
            "--- Chunk 17648 ---\n",
            "ally their shapes. For example, the following code example creates a FIFO queue with\n",
            "\n",
            "--- Chunk 17649 ---\n",
            "maximum three records, each containing a tuple with a 32-bit integer and a string.\n",
            "\n",
            "--- Chunk 17650 ---\n",
            "Then it pushes two records to it, looks at the size (which is 2 at this point), and pulls a\n",
            "record out:\n",
            "\n",
            "--- Chunk 17651 ---\n",
            ">>> q = tf.queue.FIFOQueue(3, [tf.int32, tf.string], shapes=[(), ()])\n",
            ">>> q.enqueue([10, b\"windy\"])\n",
            ">>> q.enqueue([15, b\"sunny\"])\n",
            ">>> q.size()\n",
            "\n",
            "--- Chunk 17652 ---\n",
            ">>> q.size()\n",
            "<tf.Tensor: id=62, shape=(), dtype=int32, numpy=2>\n",
            ">>> q.dequeue()\n",
            "[<tf.Tensor: id=6, shape=(), dtype=int32, numpy=10>,\n",
            "\n",
            "--- Chunk 17653 ---\n",
            "<tf.Tensor: id=7, shape=(), dtype=string, numpy=b'windy'>]\n",
            "\n",
            "--- Chunk 17654 ---\n",
            "It is also possible to enqueue and dequeue multiple records at once (the latter requires\n",
            "specifying the shapes when creating the queue):\n",
            "\n",
            "--- Chunk 17655 ---\n",
            ">>> q.enqueue_many([[13, 16], [b'cloudy', b'rainy']])\n",
            ">>> q.dequeue_many(3)\n",
            "[<tf.Tensor: [...] numpy=array([15, 13, 16], dtype=int32)>,\n",
            "\n",
            "--- Chunk 17656 ---\n",
            "<tf.Tensor: [...] numpy=array([b'sunny', b'cloudy', b'rainy'], dtype=object)>]\n",
            "\n",
            "--- Chunk 17657 ---\n",
            "Other queue types include:\n",
            "PaddingFIFOQueue\n",
            "\n",
            "--- Chunk 17658 ---\n",
            "Same as FIFOQueue, but its dequeue_many() method supports dequeueing multi‐\n",
            "\n",
            "--- Chunk 17659 ---\n",
            "ple records of different shapes. It automatically pads the shortest records to\n",
            "ensure all the records in the batch have the same shape.\n",
            "\n",
            "--- Chunk 17660 ---\n",
            "788 | Appendix F: Special Data Structures\n",
            "\n",
            "--- Chunk 17661 ---\n",
            "PriorityQueue\n",
            "A queue that dequeues records in a prioritized order. The priority must be a 64-\n",
            "\n",
            "--- Chunk 17662 ---\n",
            "bit integer included as the first element of each record. Surprisingly, records with\n",
            "\n",
            "--- Chunk 17663 ---\n",
            "a lower priority will be dequeued first. Records with the same priority will be\n",
            "dequeued in FIFO order.\n",
            "\n",
            "--- Chunk 17664 ---\n",
            "RandomShuffleQueue\n",
            "A queue whose records are dequeued in random order. This was useful to imple‐\n",
            "ment a shuffle buffer before tf.data existed.\n",
            "\n",
            "--- Chunk 17665 ---\n",
            "If a queue is already full and you try to enqueue another record, the enqueue*()\n",
            "\n",
            "--- Chunk 17666 ---\n",
            "method will freeze until a record is dequeued by another thread. Similarly, if a queue\n",
            "\n",
            "--- Chunk 17667 ---\n",
            "is empty and you try to dequeue a record, the dequeue*() method will freeze until\n",
            "records are pushed to the queue by another thread.\n",
            "\n",
            "--- Chunk 17668 ---\n",
            "Special Data Structures | 789\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "APPENDIX G\n",
            "TensorFlow Graphs\n",
            "\n",
            "--- Chunk 17669 ---\n",
            "In this appendix, we will explore the graphs generated by TF Functions (see Chap‐\n",
            "ter 12).\n",
            "\n",
            "--- Chunk 17670 ---\n",
            "TF Functions and Concrete Functions\n",
            "TF Functions are polymorphic, meaning they support inputs of different types (and\n",
            "\n",
            "--- Chunk 17671 ---\n",
            "shapes). For example, consider the following tf_cube() function:\n",
            "\n",
            "--- Chunk 17672 ---\n",
            "@tf.function\n",
            "def tf_cube(x):\n",
            "    return x ** 3\n",
            "\n",
            "--- Chunk 17673 ---\n",
            "Every time you call a TF Function with a new combination of input types or shapes, it\n",
            "\n",
            "--- Chunk 17674 ---\n",
            "generates a new concrete function, with its own graph specialized for this particular\n",
            "\n",
            "--- Chunk 17675 ---\n",
            "combination. Such a combination of argument types and shapes is called an input sig‐\n",
            "\n",
            "--- Chunk 17676 ---\n",
            "nature. If you call the TF Function with an input signature it has already seen before,\n",
            "\n",
            "--- Chunk 17677 ---\n",
            "it will reuse the concrete function it generated earlier. For example, if you call\n",
            "\n",
            "--- Chunk 17678 ---\n",
            "tf_cube(tf.constant(3.0)), the TF Function will reuse the same concrete function\n",
            "\n",
            "--- Chunk 17679 ---\n",
            "it used for tf_cube(tf.constant(2.0)) (for float32 scalar tensors). But it will gener‐\n",
            "\n",
            "--- Chunk 17680 ---\n",
            "ate a new concrete function if you call tf_cube(tf.constant([2.0])) or\n",
            "\n",
            "--- Chunk 17681 ---\n",
            "tf_cube(tf.constant([3.0])) (for float32 tensors of shape [1]), and yet another for\n",
            "\n",
            "--- Chunk 17682 ---\n",
            "tf_cube(tf.constant([[1.0, 2.0], [3.0, 4.0]])) (for float32 tensors of shape\n",
            "\n",
            "--- Chunk 17683 ---\n",
            "[2, 2]). You can get the concrete function for a particular combination of inputs by\n",
            "\n",
            "--- Chunk 17684 ---\n",
            "calling the TF Function’s get_concrete_function() method. It can then be called\n",
            "\n",
            "--- Chunk 17685 ---\n",
            "like a regular function, but it will only support one input signature (in this example,\n",
            "float32 scalar tensors):\n",
            "\n",
            "--- Chunk 17686 ---\n",
            "791\n",
            "\n",
            "--- Chunk 17687 ---\n",
            ">>> concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
            ">>> concrete_function\n",
            "\n",
            "--- Chunk 17688 ---\n",
            "<tensorflow.python.eager.function.ConcreteFunction at 0x155c29240>\n",
            ">>> concrete_function(tf.constant(2.0))\n",
            "\n",
            "--- Chunk 17689 ---\n",
            "<tf.Tensor: id=19068249, shape=(), dtype=float32, numpy=8.0>\n",
            "\n",
            "--- Chunk 17690 ---\n",
            "Figure G-1 shows the tf_cube() TF Function, after we called tf_cube(2) and\n",
            "\n",
            "--- Chunk 17691 ---\n",
            "tf_cube(tf.constant(2.0)): two concrete functions were generated, one for each\n",
            "\n",
            "--- Chunk 17692 ---\n",
            "signature, each with its own optimized function graph (FuncGraph), and its own func‐\n",
            "\n",
            "--- Chunk 17693 ---\n",
            "tion definition (FunctionDef). A function definition points to the parts of the graph\n",
            "\n",
            "--- Chunk 17694 ---\n",
            "that correspond to the function’s inputs and outputs. In each FuncGraph, the nodes\n",
            "\n",
            "--- Chunk 17695 ---\n",
            "(ovals) represent operations (e.g., power, constants, or placeholders for arguments\n",
            "\n",
            "--- Chunk 17696 ---\n",
            "like x), while the edges (the solid arrows between the operations) represent the ten‐\n",
            "\n",
            "--- Chunk 17697 ---\n",
            "sors that will flow through the graph. The concrete function on the left is specialized\n",
            "\n",
            "--- Chunk 17698 ---\n",
            "for x = 2, so TensorFlow managed to simplify it to just output 8 all the time (note\n",
            "\n",
            "--- Chunk 17699 ---\n",
            "that the function definition does not even have an input). The concrete function on\n",
            "\n",
            "--- Chunk 17700 ---\n",
            "the right is specialized for float32 scalar tensors, and it could not be simplified. If we\n",
            "\n",
            "--- Chunk 17701 ---\n",
            "call tf_cube(tf.constant(5.0)), the second concrete function will be called, the\n",
            "\n",
            "--- Chunk 17702 ---\n",
            "placeholder operation for x will output 5.0, then the power operation will compute\n",
            "5.0 ** 3, so the output will be 125.0.\n",
            "\n",
            "--- Chunk 17703 ---\n",
            "Figure G-1. The tf_cube() TF Function, with its ConcreteFunctions and their Function‐\n",
            "Graphs\n",
            "\n",
            "--- Chunk 17704 ---\n",
            "The tensors in these graphs are symbolic tensors, meaning they don’t have an actual\n",
            "\n",
            "--- Chunk 17705 ---\n",
            "value, just a data type, a shape, and a name. They represent the future tensors that will\n",
            "\n",
            "--- Chunk 17706 ---\n",
            "flow through the graph once an actual value is fed to the placeholder x and the graph\n",
            "\n",
            "--- Chunk 17707 ---\n",
            "is executed. Symbolic tensors make it possible to specify ahead of time how to\n",
            "\n",
            "--- Chunk 17708 ---\n",
            "792 | Appendix G: TensorFlow Graphs\n",
            "\n",
            "--- Chunk 17709 ---\n",
            "connect operations, and they also allow TensorFlow to recursively infer the data types\n",
            "\n",
            "--- Chunk 17710 ---\n",
            "and shapes of all tensors, given the data types and shapes of their inputs.\n",
            "\n",
            "--- Chunk 17711 ---\n",
            "Now let’s continue to peek under the hood, and see how to access function definitions\n",
            "\n",
            "--- Chunk 17712 ---\n",
            "and function graphs and how to explore a graph’s operations and tensors.\n",
            "\n",
            "--- Chunk 17713 ---\n",
            "Exploring Function Definitions and Graphs\n",
            "You can access a concrete function’s computation graph using the graph attribute,\n",
            "\n",
            "--- Chunk 17714 ---\n",
            "and get the list of its operations by calling the graph’s get_operations() method:\n",
            "\n",
            "--- Chunk 17715 ---\n",
            ">>> concrete_function.graph\n",
            "<tensorflow.python.framework.func_graph.FuncGraph at 0x14db5ef98>\n",
            ">>> ops = concrete_function.graph.get_operations()\n",
            "\n",
            "--- Chunk 17716 ---\n",
            ">>> ops\n",
            "[<tf.Operation 'x' type=Placeholder>,\n",
            " <tf.Operation 'pow/y' type=Const>,\n",
            " <tf.Operation 'pow' type=Pow>,\n",
            "\n",
            "--- Chunk 17717 ---\n",
            "<tf.Operation 'Identity' type=Identity>]\n",
            "\n",
            "--- Chunk 17718 ---\n",
            "In this example, the first operation represents the input argument x (it is called a\n",
            "\n",
            "--- Chunk 17719 ---\n",
            "placeholder), the second “operation” represents the constant 3, the third operation\n",
            "\n",
            "--- Chunk 17720 ---\n",
            "represents the power operation (**), and the final operation represents the output of\n",
            "\n",
            "--- Chunk 17721 ---\n",
            "this function (it is an identity operation, meaning it will do nothing more than copy\n",
            "\n",
            "--- Chunk 17722 ---\n",
            "the output of the addition operation1). Each operation has a list of input and output\n",
            "\n",
            "--- Chunk 17723 ---\n",
            "tensors that you can easily access using the operation’s inputs and outputs attributes.\n",
            "\n",
            "--- Chunk 17724 ---\n",
            "For example, let’s get the list of inputs and outputs of the power operation:\n",
            "\n",
            "--- Chunk 17725 ---\n",
            ">>> pow_op = ops[2]\n",
            ">>> list(pow_op.inputs)\n",
            "[<tf.Tensor 'x:0' shape=() dtype=float32>,\n",
            " <tf.Tensor 'pow/y:0' shape=() dtype=float32>]\n",
            "\n",
            "--- Chunk 17726 ---\n",
            ">>> pow_op.outputs\n",
            "[<tf.Tensor 'pow:0' shape=() dtype=float32>]\n",
            "\n",
            "--- Chunk 17727 ---\n",
            "This computation graph is represented in Figure G-2.\n",
            "\n",
            "--- Chunk 17728 ---\n",
            "1 You can safely ignore it—it is only here for technical reasons, to ensure that TF Functions don’t leak internal\n",
            "structures.\n",
            "\n",
            "--- Chunk 17729 ---\n",
            "TensorFlow Graphs | 793\n",
            "\n",
            "\n",
            "\n",
            "Figure G-2. Example of a computation graph\n",
            "\n",
            "--- Chunk 17730 ---\n",
            "Note that each operation has a name. It defaults to the name of the operation (e.g.,\n",
            "\n",
            "--- Chunk 17731 ---\n",
            "\"pow\"), but you can define it manually when calling the operation (e.g., tf.pow(x,\n",
            "\n",
            "--- Chunk 17732 ---\n",
            "3, name=\"other_name\")). If a name already exists, TensorFlow automatically adds a\n",
            "\n",
            "--- Chunk 17733 ---\n",
            "unique index (e.g., \"pow_1\", \"pow_2\", etc.). Each tensor also has a unique name: it is\n",
            "\n",
            "--- Chunk 17734 ---\n",
            "always the name of the operation that outputs this tensor, plus :0 if it is the opera‐\n",
            "\n",
            "--- Chunk 17735 ---\n",
            "tion’s first output, or :1 if it is the second output, and so on. You can fetch an opera‐\n",
            "\n",
            "--- Chunk 17736 ---\n",
            "tion or a tensor by name using the graph’s get_operation_by_name() or\n",
            "get_tensor_by_name() methods:\n",
            "\n",
            "--- Chunk 17737 ---\n",
            ">>> concrete_function.graph.get_operation_by_name('x')\n",
            "<tf.Operation 'x' type=Placeholder>\n",
            "\n",
            "--- Chunk 17738 ---\n",
            ">>> concrete_function.graph.get_tensor_by_name('Identity:0')\n",
            "<tf.Tensor 'Identity:0' shape=() dtype=float32>\n",
            "\n",
            "--- Chunk 17739 ---\n",
            "The concrete function also contains the function definition (represented as a protocol\n",
            "\n",
            "--- Chunk 17740 ---\n",
            "buffer2), which includes the function’s signature. This signature allows the concrete\n",
            "\n",
            "--- Chunk 17741 ---\n",
            "function to know which placeholders to feed with the input values, and which tensors\n",
            "to return:\n",
            "\n",
            "--- Chunk 17742 ---\n",
            ">>> concrete_function.function_def.signature\n",
            "name: \"__inference_cube_19068241\"\n",
            "input_arg {\n",
            "  name: \"x\"\n",
            "  type: DT_FLOAT\n",
            "}\n",
            "output_arg {\n",
            "\n",
            "--- Chunk 17743 ---\n",
            "}\n",
            "output_arg {\n",
            "  name: \"identity\"\n",
            "  type: DT_FLOAT\n",
            "}\n",
            "\n",
            "--- Chunk 17744 ---\n",
            "2 A popular binary format discussed in Chapter 13.\n",
            "\n",
            "794 | Appendix G: TensorFlow Graphs\n",
            "\n",
            "\n",
            "\n",
            "Now let’s look more closely at tracing.\n",
            "\n",
            "--- Chunk 17745 ---\n",
            "A Closer Look at Tracing\n",
            "Let’s tweak the tf_cube() function to print its input:\n",
            "\n",
            "@tf.function\n",
            "def tf_cube(x):\n",
            "    print(\"x =\", x)\n",
            "    return x ** 3\n",
            "\n",
            "--- Chunk 17746 ---\n",
            "Now let’s call it:\n",
            ">>> result = tf_cube(tf.constant(2.0))\n",
            "x = Tensor(\"x:0\", shape=(), dtype=float32)\n",
            ">>> result\n",
            "\n",
            "--- Chunk 17747 ---\n",
            ">>> result\n",
            "<tf.Tensor: id=19068290, shape=(), dtype=float32, numpy=8.0>\n",
            "\n",
            "--- Chunk 17748 ---\n",
            "The result looks good, but look at what was printed: x is a symbolic tensor! It has a\n",
            "\n",
            "--- Chunk 17749 ---\n",
            "shape and a data type, but no value. Plus it has a name (\"x:0\"). This is because the\n",
            "\n",
            "--- Chunk 17750 ---\n",
            "print() function is not a TensorFlow operation, so it will only run when the Python\n",
            "\n",
            "--- Chunk 17751 ---\n",
            "function is traced, which happens in graph mode, with arguments replaced with sym‐\n",
            "\n",
            "--- Chunk 17752 ---\n",
            "bolic tensors (same type and shape, but no value). Since the print() function was not\n",
            "\n",
            "--- Chunk 17753 ---\n",
            "captured into the graph, the next times we call tf_cube() with float32 scalar tensors,\n",
            "nothing is printed:\n",
            "\n",
            "--- Chunk 17754 ---\n",
            ">>> result = tf_cube(tf.constant(3.0))\n",
            ">>> result = tf_cube(tf.constant(4.0))\n",
            "\n",
            "--- Chunk 17755 ---\n",
            "But if we call tf_cube() with a tensor of a different type or shape, or with a new\n",
            "\n",
            "--- Chunk 17756 ---\n",
            "Python value, the function will be traced again, so the print() function will be called:\n",
            "\n",
            "--- Chunk 17757 ---\n",
            ">>> result = tf_cube(2) # new Python value: trace!\n",
            "x = 2\n",
            ">>> result = tf_cube(3) # new Python value: trace!\n",
            "x = 3\n",
            "\n",
            "--- Chunk 17758 ---\n",
            "x = 3\n",
            ">>> result = tf_cube(tf.constant([[1., 2.]])) # New shape: trace!\n",
            "x = Tensor(\"x:0\", shape=(1, 2), dtype=float32)\n",
            "\n",
            "--- Chunk 17759 ---\n",
            ">>> result = tf_cube(tf.constant([[3., 4.], [5., 6.]])) # New shape: trace!\n",
            "x = Tensor(\"x:0\", shape=(None, 2), dtype=float32)\n",
            "\n",
            "--- Chunk 17760 ---\n",
            ">>> result = tf_cube(tf.constant([[7., 8.], [9., 10.]])) # Same shape: no trace\n",
            "\n",
            "--- Chunk 17761 ---\n",
            "If your function has Python side effects (e.g., it saves some logs to\n",
            "disk), be aware that this code will only run when the function is\n",
            "\n",
            "--- Chunk 17762 ---\n",
            "traced (i.e., every time the TF Function is called with a new input\n",
            "signature). It best to assume that the function may be traced (or\n",
            "\n",
            "--- Chunk 17763 ---\n",
            "not) any time the TF Function is called.\n",
            "\n",
            "--- Chunk 17764 ---\n",
            "TensorFlow Graphs | 795\n",
            "\n",
            "--- Chunk 17765 ---\n",
            "In some cases, you may want to restrict a TF Function to a specific input signature.\n",
            "\n",
            "--- Chunk 17766 ---\n",
            "For example, suppose you know that you will only ever call a TF Function with\n",
            "\n",
            "--- Chunk 17767 ---\n",
            "batches of 28 × 28–pixel images, but the batches will have very different sizes. You\n",
            "\n",
            "--- Chunk 17768 ---\n",
            "may not want TensorFlow to generate a different concrete function for each batch\n",
            "\n",
            "--- Chunk 17769 ---\n",
            "size, or count on it to figure out on its own when to use None. In this case, you can\n",
            "specify the input signature like this:\n",
            "\n",
            "--- Chunk 17770 ---\n",
            "@tf.function(input_signature=[tf.TensorSpec([None, 28, 28], tf.float32)])\n",
            "def shrink(images):\n",
            "\n",
            "--- Chunk 17771 ---\n",
            "def shrink(images):\n",
            "    return images[:, ::2, ::2] # drop half the rows and columns\n",
            "\n",
            "--- Chunk 17772 ---\n",
            "This TF Function will accept any float32 tensor of shape [*, 28, 28], and it will reuse\n",
            "the same concrete function every time:\n",
            "\n",
            "--- Chunk 17773 ---\n",
            "img_batch_1 = tf.random.uniform(shape=[100, 28, 28])\n",
            "img_batch_2 = tf.random.uniform(shape=[50, 28, 28])\n",
            "\n",
            "--- Chunk 17774 ---\n",
            "preprocessed_images = shrink(img_batch_1) # Works fine. Traces the function.\n",
            "\n",
            "--- Chunk 17775 ---\n",
            "preprocessed_images = shrink(img_batch_2) # Works fine. Same concrete function.\n",
            "\n",
            "--- Chunk 17776 ---\n",
            "However, if you try to call this TF Function with a Python value, or a tensor of an\n",
            "unexpected data type or shape, you will get an exception:\n",
            "\n",
            "--- Chunk 17777 ---\n",
            "img_batch_3 = tf.random.uniform(shape=[2, 2, 2])\n",
            "preprocessed_images = shrink(img_batch_3)  # ValueError! Unexpected signature.\n",
            "\n",
            "--- Chunk 17778 ---\n",
            "Using AutoGraph to Capture Control Flow\n",
            "If your function contains a simple for loop, what do you expect will happen? For\n",
            "\n",
            "--- Chunk 17779 ---\n",
            "example, let’s write a function that will add 10 to its input, by just adding 1 10 times:\n",
            "\n",
            "--- Chunk 17780 ---\n",
            "@tf.function\n",
            "def add_10(x):\n",
            "    for i in range(10):\n",
            "        x += 1\n",
            "    return x\n",
            "\n",
            "--- Chunk 17781 ---\n",
            "It works fine, but when we look at its graph, we find that it does not contain a loop: it\n",
            "just contains 10 addition operations!\n",
            "\n",
            "--- Chunk 17782 ---\n",
            ">>> add_10(tf.constant(0))\n",
            "<tf.Tensor: id=19280066, shape=(), dtype=int32, numpy=10>\n",
            "\n",
            "--- Chunk 17783 ---\n",
            ">>> add_10.get_concrete_function(tf.constant(0)).graph.get_operations()\n",
            "[<tf.Operation 'x' type=Placeholder>, [...],\n",
            "\n",
            "--- Chunk 17784 ---\n",
            "<tf.Operation 'add' type=Add>, [...],\n",
            " <tf.Operation 'add_1' type=Add>, [...],\n",
            " <tf.Operation 'add_2' type=Add>, [...],\n",
            " [...]\n",
            "\n",
            "--- Chunk 17785 ---\n",
            "[...]\n",
            " <tf.Operation 'add_9' type=Add>, [...],\n",
            " <tf.Operation 'Identity' type=Identity>]\n",
            "\n",
            "--- Chunk 17786 ---\n",
            "796 | Appendix G: TensorFlow Graphs\n",
            "\n",
            "--- Chunk 17787 ---\n",
            "This actually makes sense: when the function got traced, the loop ran 10 times, so the\n",
            "\n",
            "--- Chunk 17788 ---\n",
            "x += 1 operation was run 10 times, and since it was in graph mode, it recorded this\n",
            "\n",
            "--- Chunk 17789 ---\n",
            "operation 10 times in the graph. You can think of this for loop as a “static” loop that\n",
            "gets unrolled when the graph is created.\n",
            "\n",
            "--- Chunk 17790 ---\n",
            "If you want the graph to contain a “dynamic” loop instead (i.e., one that runs when\n",
            "\n",
            "--- Chunk 17791 ---\n",
            "the graph is executed), you can create one manually using the tf.while_loop() oper‐\n",
            "\n",
            "--- Chunk 17792 ---\n",
            "ation, but it is not very intuitive (see the “Using AutoGraph to Capture Control Flow”\n",
            "\n",
            "--- Chunk 17793 ---\n",
            "section of the Chapter 12 notebook for an example). Instead, it is much simpler to use\n",
            "\n",
            "--- Chunk 17794 ---\n",
            "TensorFlow’s AutoGraph feature, discussed in Chapter 12. AutoGraph is actually acti‐\n",
            "\n",
            "--- Chunk 17795 ---\n",
            "vated by default (if you ever need to turn it off, you can pass autograph=False to\n",
            "\n",
            "--- Chunk 17796 ---\n",
            "tf.function()). So if it is on, why didn’t it capture the for loop in the add_10()\n",
            "\n",
            "--- Chunk 17797 ---\n",
            "function? Well, it only captures for loops that iterate over tf.range(), not range().\n",
            "This is to give you the choice:\n",
            "\n",
            "--- Chunk 17798 ---\n",
            "• If you use range(), the for loop will be static, meaning it will only be executed\n",
            "\n",
            "--- Chunk 17799 ---\n",
            "when the function is traced. The loop will be “unrolled” into a set of operations\n",
            "for each iteration, as we saw.\n",
            "\n",
            "--- Chunk 17800 ---\n",
            "• If you use tf.range(), the loop will be dynamic, meaning that it will be included\n",
            "in the graph itself (but it will not run during tracing).\n",
            "\n",
            "--- Chunk 17801 ---\n",
            "Let’s look at the graph that gets generated if you just replace range() with tf.range()\n",
            "in the add_10() function:\n",
            "\n",
            "--- Chunk 17802 ---\n",
            ">>> add_10.get_concrete_function(tf.constant(0)).graph.get_operations()\n",
            "[<tf.Operation 'x' type=Placeholder>, [...],\n",
            "\n",
            "--- Chunk 17803 ---\n",
            "<tf.Operation 'range' type=Range>, [...],\n",
            " <tf.Operation 'while' type=While>, [...],\n",
            " <tf.Operation 'Identity' type=Identity>]\n",
            "\n",
            "--- Chunk 17804 ---\n",
            "As you can see, the graph now contains a While loop operation, as if you had called\n",
            "the tf.while_loop() function.\n",
            "\n",
            "--- Chunk 17805 ---\n",
            "Handling Variables and Other Resources in TF Functions\n",
            "In TensorFlow, variables and other stateful objects, such as queues or datasets, are\n",
            "\n",
            "--- Chunk 17806 ---\n",
            "called resources. TF Functions treat them with special care: any operation that reads\n",
            "\n",
            "--- Chunk 17807 ---\n",
            "or updates a resource is considered stateful, and TF Functions ensure that stateful\n",
            "\n",
            "--- Chunk 17808 ---\n",
            "operations are executed in the order they appear (as opposed to stateless operations,\n",
            "\n",
            "--- Chunk 17809 ---\n",
            "which may be run in parallel, so their order of execution is not guaranteed). More‐\n",
            "\n",
            "--- Chunk 17810 ---\n",
            "over, when you pass a resource as an argument to a TF Function, it gets passed by\n",
            "reference, so the function may modify it. For example:\n",
            "\n",
            "--- Chunk 17811 ---\n",
            "TensorFlow Graphs | 797\n",
            "\n",
            "\n",
            "\n",
            "counter = tf.Variable(0)\n",
            "\n",
            "@tf.function\n",
            "def increment(counter, c=1):\n",
            "    return counter.assign_add(c)\n",
            "\n",
            "--- Chunk 17812 ---\n",
            "increment(counter) # counter is now equal to 1\n",
            "increment(counter) # counter is now equal to 2\n",
            "\n",
            "--- Chunk 17813 ---\n",
            "If you peek at the function definition, the first argument is marked as a resource:\n",
            "\n",
            "--- Chunk 17814 ---\n",
            ">>> function_def = increment.get_concrete_function(counter).function_def\n",
            ">>> function_def.signature.input_arg[0]\n",
            "name: \"counter\"\n",
            "type: DT_RESOURCE\n",
            "\n",
            "--- Chunk 17815 ---\n",
            "It is also possible to use a tf.Variable defined outside of the function, without\n",
            "explicitly passing it as an argument:\n",
            "\n",
            "counter = tf.Variable(0)\n",
            "\n",
            "--- Chunk 17816 ---\n",
            "@tf.function\n",
            "def increment(c=1):\n",
            "    return counter.assign_add(c)\n",
            "\n",
            "--- Chunk 17817 ---\n",
            "The TF Function will treat this as an implicit first argument, so it will actually end up\n",
            "\n",
            "--- Chunk 17818 ---\n",
            "with the same signature (except for the name of the argument). However, using global\n",
            "\n",
            "--- Chunk 17819 ---\n",
            "variables can quickly become messy, so you should generally wrap variables (and\n",
            "\n",
            "--- Chunk 17820 ---\n",
            "other resources) inside classes. The good news is @tf.function works fine with\n",
            "methods too:\n",
            "\n",
            "--- Chunk 17821 ---\n",
            "class Counter:\n",
            "    def __init__(self):\n",
            "        self.counter = tf.Variable(0)\n",
            "\n",
            "--- Chunk 17822 ---\n",
            "@tf.function\n",
            "    def increment(self, c=1):\n",
            "        return self.counter.assign_add(c)\n",
            "\n",
            "--- Chunk 17823 ---\n",
            "Do not use =, +=, -=, or any other Python assignment operator with\n",
            "TF variables. Instead, you must use the assign(), assign_add(),\n",
            "\n",
            "--- Chunk 17824 ---\n",
            "or assign_sub() methods. If you try to use a Python assignment\n",
            "operator, you will get an exception when you call the method.\n",
            "\n",
            "--- Chunk 17825 ---\n",
            "A good example of this object-oriented approach is, of course, tf.keras. Let’s see how\n",
            "to use TF Functions with tf.keras.\n",
            "\n",
            "--- Chunk 17826 ---\n",
            "798 | Appendix G: TensorFlow Graphs\n",
            "\n",
            "--- Chunk 17827 ---\n",
            "Using TF Functions with tf.keras (or Not)\n",
            "By default, any custom function, layer, or model you use with tf.keras will automati‐\n",
            "\n",
            "--- Chunk 17828 ---\n",
            "cally be converted to a TF Function; you do not need to do anything at all! However,\n",
            "\n",
            "--- Chunk 17829 ---\n",
            "in some cases you may want to deactivate this automatic conversion—for example, if\n",
            "\n",
            "--- Chunk 17830 ---\n",
            "your custom code cannot be turned into a TF Function, or if you just want to debug\n",
            "\n",
            "--- Chunk 17831 ---\n",
            "your code, which is much easier in eager mode. To do this, you can simply pass\n",
            "dynamic=True when creating the model or any of its layers:\n",
            "\n",
            "--- Chunk 17832 ---\n",
            "model = MyModel(dynamic=True)\n",
            "\n",
            "--- Chunk 17833 ---\n",
            "If your custom model or layer will always be dynamic, you can instead call the base\n",
            "class’s constructor with dynamic=True:\n",
            "\n",
            "--- Chunk 17834 ---\n",
            "class MyLayer(keras.layers.Layer):\n",
            "    def __init__(self, units, **kwargs):\n",
            "        super().__init__(dynamic=True, **kwargs)\n",
            "        [...]\n",
            "\n",
            "--- Chunk 17835 ---\n",
            "Alternatively, you can pass run_eagerly=True when calling the compile() method:\n",
            "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae],\n",
            "\n",
            "--- Chunk 17836 ---\n",
            "run_eagerly=True)\n",
            "\n",
            "--- Chunk 17837 ---\n",
            "Now you know how TF Functions handle polymorphism (with multiple concrete\n",
            "\n",
            "--- Chunk 17838 ---\n",
            "functions), how graphs are automatically generated using AutoGraph and tracing,\n",
            "\n",
            "--- Chunk 17839 ---\n",
            "what graphs look like, how to explore their symbolic operations and tensors, how to\n",
            "\n",
            "--- Chunk 17840 ---\n",
            "handle variables and resources, and how to use TF Functions with tf.keras.\n",
            "\n",
            "--- Chunk 17841 ---\n",
            "TensorFlow Graphs | 799\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Index\n",
            "\n",
            "--- Chunk 17842 ---\n",
            "Symbols adaptive instance normalization (AdaIN), 604\n",
            "1cycle scheduling, 361 adaptive learning rate, 355\n",
            "\n",
            "--- Chunk 17843 ---\n",
            "1D convolutional layers, 520 adaptive moment estimation, 356\n",
            "\n",
            "--- Chunk 17844 ---\n",
            "additive attention, 550\n",
            "A Advantage Actor-Critic (A2C), 663\n",
            "\n",
            "--- Chunk 17845 ---\n",
            "adversarial learning, 495, 568\n",
            "A/B experiments, 667 affine transformations, 604\n",
            "accelerated K-Means, 244 affinity, 237\n",
            "\n",
            "--- Chunk 17846 ---\n",
            "accuracy affinity propagation, 259\n",
            "\n",
            "--- Chunk 17847 ---\n",
            "defined, 89 agents, 14\n",
            "example of, 2 agglomerative clustering, 258\n",
            "measuring using cross-validation, 89 AI Platform, 680\n",
            "\n",
            "--- Chunk 17848 ---\n",
            "action advantage, 620 Akaike information criterion (AIC), 267\n",
            "action step, 656 AlexNet, 464\n",
            "actions algorithms\n",
            "\n",
            "--- Chunk 17849 ---\n",
            "evaluating, 619 Actor-Critic algorithms, 625, 662\n",
            "exploiting versus exploring, 618 Advantage Actor-Critic (A2C), 663\n",
            "\n",
            "--- Chunk 17850 ---\n",
            "activation functions AllReduce algorithm, 705\n",
            "exponential linear unit (ELU), 336-338 Asynchronous Advantage Actor-Critic\n",
            "\n",
            "--- Chunk 17851 ---\n",
            "hyperbolic tangent (tanh), 291 (A3C), 662\n",
            "Logistic (sigmoid), 143, 293, 302, 332 BIRCH algorithm, 259\n",
            "\n",
            "--- Chunk 17852 ---\n",
            "nonsaturating, 335 CART training algorithm, 177, 179\n",
            "Rectified Linear Unit function (ReLU), clustering algorithms, 10\n",
            "\n",
            "--- Chunk 17853 ---\n",
            "292-293 Dueling DQN algorithm, 641\n",
            "Scaled Exponential Linear Unit (SELU), 334, dynamic placer algorithm, 697\n",
            "\n",
            "--- Chunk 17854 ---\n",
            "337-338, 368 Expectation-Maximization (EM) algorithm,\n",
            "softmax, 294, 299, 470, 482, 488, 543 262\n",
            "softplus, 293 for anomaly detection, 274\n",
            "\n",
            "--- Chunk 17855 ---\n",
            "active constraint, 762 genetic algorithms, 612\n",
            "active learning, 255 greedy algorithms, 180\n",
            "\n",
            "--- Chunk 17856 ---\n",
            "Actor-Critic algorithms, 625, 662 hierarchical clustering algorithms, 10\n",
            "AdaBoost, 200 importance of data over, 24\n",
            "\n",
            "--- Chunk 17857 ---\n",
            "AdaGrad, 354 Isolation Forest algorithm, 274\n",
            "Adam and Nadam optimization, 356 isomap algorithm, 233\n",
            "Adaptive Boosting, 200\n",
            "\n",
            "--- Chunk 17858 ---\n",
            "801\n",
            "\n",
            "--- Chunk 17859 ---\n",
            "K-Means algorithm, 238 attributes, 8\n",
            "Lloyd–Forgy algorithm, 238 autoencoders\n",
            "Mean-Shift algorithm, 259 convolutional, 579\n",
            "\n",
            "--- Chunk 17860 ---\n",
            "off-policy algorithms, 632 denoising, 581\n",
            "on-policy algorithms, 632 efficient data representations, 569\n",
            "one-class SVM algorithm, 275 generative, 586\n",
            "\n",
            "--- Chunk 17861 ---\n",
            "Proximal Policy Optimization (PPO), 663 versus Generative Adversarial Networks\n",
            "Randomized PCA algorithm, 225 (GANs), 568\n",
            "\n",
            "--- Chunk 17862 ---\n",
            "REINFORCE algorithms, 620 overview of, 567\n",
            "Soft Actor-Critic algorithm, 663 parts of, 569\n",
            "\n",
            "--- Chunk 17863 ---\n",
            "supervised learning, 8 PCA with undercomplete linear autoencod‐\n",
            "unsupervised learning, 9 ers, 570\n",
            "Value Iteration algorithm, 627 probabilistic, 586\n",
            "\n",
            "--- Chunk 17864 ---\n",
            "visualization algorithms, 11 recurrent, 580\n",
            "\n",
            "--- Chunk 17865 ---\n",
            "AllReduce algorithm, 705 sparse, 582\n",
            "alpha channels, 250 stacked, 572-575\n",
            "anchor boxes, 490 undercomplete, 570\n",
            "\n",
            "--- Chunk 17866 ---\n",
            "anomaly detection unsupervised pretraining using stacked,\n",
            "\n",
            "--- Chunk 17867 ---\n",
            "additional algorithms for, 274 576-579\n",
            "examples of, 12 variational, 586-591\n",
            "goal of, 236 AutoGraphs, 407\n",
            "\n",
            "--- Chunk 17868 ---\n",
            "using clustering, 237 automatic differentiation (autodiff), 290, 399,\n",
            "using Gaussian Mixtures, 266 765-772\n",
            "\n",
            "--- Chunk 17869 ---\n",
            "Approximate Q-Learning, 633 AutoML, 323\n",
            "area under the curve (AUC), 98 autonomous driving systems, 497\n",
            "\n",
            "--- Chunk 17870 ---\n",
            "argmax operator, 149 autoregressive integrated moving average\n",
            "artificial neural networks (ANNs) (ARIMA) models, 506\n",
            "\n",
            "--- Chunk 17871 ---\n",
            "Boltzmann machines, 775 average absolute deviation, 41\n",
            "fine-tuning hyperparameters for, 320-327 average pooling layer, 459\n",
            "\n",
            "--- Chunk 17872 ---\n",
            "from biological to artificial neurons, Average Precision (AP), 491\n",
            "\n",
            "--- Chunk 17873 ---\n",
            "280-295\n",
            "Hopfield networks, 773 B\n",
            "implementing MLPs with Keras, 295-320 backpropagation, 289-292\n",
            "\n",
            "--- Chunk 17874 ---\n",
            "overview of, 279 backpropagation through time (BPTT), 502\n",
            "restricted Boltzmann machines (RBMs), 776 bag of words, 438\n",
            "\n",
            "--- Chunk 17875 ---\n",
            "self-organizing maps (SOMs), 780 bagging and pasting\n",
            "\n",
            "--- Chunk 17876 ---\n",
            "artificial neurons, 283 out-of-bag evaluation, 195\n",
            "association rule learning, 12 overview of, 192\n",
            "\n",
            "--- Chunk 17877 ---\n",
            "associative memory networks, 773 in Scikit-Learn, 194\n",
            "Asynchronous Advantage Actor-Critic (A3C), Bahdanau attention, 550\n",
            "\n",
            "--- Chunk 17878 ---\n",
            "662 bandwidth saturation, 708\n",
            "asynchronous updates, 707 basic cells, 500\n",
            "Atari preprocessing, 645 Batch Gradient Descent, 121\n",
            "\n",
            "--- Chunk 17879 ---\n",
            "attention mechanisms batch learning, 15\n",
            "\n",
            "--- Chunk 17880 ---\n",
            "defined, 526 Batch Normalization (BN), 339\n",
            "explainability and, 553 batch size, 325\n",
            "overview of, 549 batched action step, 657\n",
            "\n",
            "--- Chunk 17881 ---\n",
            "Transformer architecture, 554 batched time step, 657\n",
            "visual attention, 552 batched trajectory, 657\n",
            "\n",
            "--- Chunk 17882 ---\n",
            "802 | Index\n",
            "\n",
            "--- Chunk 17883 ---\n",
            "Bayesian Gaussian Mixture models, 270 chopping sequential datasets, 528\n",
            "Bayesian inference, 586 generating Shakespearean text, 531\n",
            "\n",
            "--- Chunk 17884 ---\n",
            "Bayesian information criterion (BIC), 267 overview of, 526\n",
            "beam search, 547 splitting sequential datasets, 527\n",
            "beam width, 547 stateful RNNs and, 532\n",
            "\n",
            "--- Chunk 17885 ---\n",
            "Bellman Optimality Equation, 627 training dataset creation, 527\n",
            "Better Life Index, 19 using, 531\n",
            "bias neurons, 285 chatbots, 525\n",
            "\n",
            "--- Chunk 17886 ---\n",
            "bias terms, 112 chi-squared test, 182\n",
            "bias/variance trade-off, 134 Classification and Regression Tree (CART),\n",
            "\n",
            "--- Chunk 17887 ---\n",
            "bidirectional recurrent layers, 546 177, 179\n",
            "bidirectional RNNs, 546 classification problems\n",
            "binary classifiers, 88 AdaBoost classifiers, 200\n",
            "\n",
            "--- Chunk 17888 ---\n",
            "binary trees, 177 binary classifiers, 88\n",
            "biological neural networks (BNN), 282 classification and localization, 483\n",
            "\n",
            "--- Chunk 17889 ---\n",
            "biological neurons, 280 classification MLPs, 294\n",
            "BIRCH algorithm, 259 error analysis, 102\n",
            "black box models, 178 example of, 8\n",
            "\n",
            "--- Chunk 17890 ---\n",
            "black box stochastic variational inference Extra-Trees classifier, 198\n",
            "\n",
            "--- Chunk 17891 ---\n",
            "(BBSVI), 273 hard margin classification, 154\n",
            "blenders, 208 image classifiers using Sequential APIs,\n",
            "Boltzmann machines, 775 297-307\n",
            "\n",
            "--- Chunk 17892 ---\n",
            "boosting large margin classification, 153\n",
            "\n",
            "--- Chunk 17893 ---\n",
            "AdaBoost, 200 linear SVM classification, 153\n",
            "Gradient Boosting, 203 MNIST dataset, 85\n",
            "overview of, 199 multiclass classification, 100\n",
            "\n",
            "--- Chunk 17894 ---\n",
            "bottleneck layers, 467 multilabel classification, 106\n",
            "boundary transitions, 660 multioutput classification, 107\n",
            "\n",
            "--- Chunk 17895 ---\n",
            "bounding box priors, 490 multitask classification, 311\n",
            "break the symmetry, 291 nonlinear SVM classification, 157-162\n",
            "\n",
            "--- Chunk 17896 ---\n",
            "Byte-Pair Encoding, 536 performance measures, 88-100\n",
            "\n",
            "--- Chunk 17897 ---\n",
            "soft margin classification, 154\n",
            "C voting classifiers, 189\n",
            "calculus, 112 closed-form solution, 114\n",
            "\n",
            "--- Chunk 17898 ---\n",
            "California Housing Prices dataset, 36 cluster specification, 711\n",
            "callbacks, 315 clustering algorithms\n",
            "canary testing, 684 additional algorithms, 258\n",
            "\n",
            "--- Chunk 17899 ---\n",
            "CART training algorithm, 177, 179 applications for, 10, 237\n",
            "catastrophic forgetting, 637 DBSCAN, 255\n",
            "categorical distribution, 261 goal of, 236\n",
            "\n",
            "--- Chunk 17900 ---\n",
            "categorical features for image segmentation, 238, 249\n",
            "\n",
            "--- Chunk 17901 ---\n",
            "encoding using embeddings, 433 K-Means, 238-249\n",
            "encoding using one-hot vectors, 431 overview of, 236\n",
            "\n",
            "--- Chunk 17902 ---\n",
            "causal models, 510 for preprocessing, 251\n",
            "centroids, 238 for semi-supervised learning, 253\n",
            "chain rule, 290 code examples, obtaining and using, xxi\n",
            "\n",
            "--- Chunk 17903 ---\n",
            "chaining transformations, 415 codings, 567\n",
            "character RNNs (Char-RNNs) Colab Runtime, 693\n",
            "\n",
            "--- Chunk 17904 ---\n",
            "building and training, 530 Colaboratory (Colab), 693\n",
            "\n",
            "Index | 803\n",
            "\n",
            "--- Chunk 17905 ---\n",
            "collect policy, 649 role of, 20\n",
            "color channels, 451 credit assignment problem, 619\n",
            "color segmentation, 249 cross-entropy loss (log loss), 149, 295\n",
            "\n",
            "--- Chunk 17906 ---\n",
            "column vectors, 113 cross-validation, 31, 73, 89\n",
            "comments and questions, xxiii, 718 CUDA Deep Neural Network library (cuDNN),\n",
            "\n",
            "--- Chunk 17907 ---\n",
            "complementary slackness, 762 690\n",
            "components, 38 curiosity-based exploration, 664\n",
            "compression, 224 curse of dimensionality, 214\n",
            "\n",
            "--- Chunk 17908 ---\n",
            "computation graphs, 376 custom models\n",
            "Compute Unified Device Architecture library about, 375\n",
            "\n",
            "--- Chunk 17909 ---\n",
            "(CUDA), 690 activation functions, initializers, regulariz‐\n",
            "concatenative attention, 550 ers, and constraints, 387\n",
            "\n",
            "--- Chunk 17910 ---\n",
            "concrete functions, 791 computing gradients using Autodiff, 399,\n",
            "conditional probability, 547 765-772\n",
            "confusion matrix, 90 layers, 391\n",
            "\n",
            "--- Chunk 17911 ---\n",
            "connectionism, 280 loss functions, 384\n",
            "constrained optimization, 166 losses and metrics, 397\n",
            "Contrastive Divergence, 777 metrics, 388\n",
            "\n",
            "--- Chunk 17912 ---\n",
            "convergence, 118 models, 394\n",
            "convex function, 120 saving and loading, 385\n",
            "convolution kernels, 450 training loops, 402\n",
            "\n",
            "--- Chunk 17913 ---\n",
            "convolutional autoencoders, 579 customer segmentation, 237\n",
            "convolutional layer\n",
            "\n",
            "--- Chunk 17914 ---\n",
            "filters, 450 D\n",
            "memory requirements, 456 data (see also data preparation; data visualiza‐\n",
            "overview of, 448 tion; training data)\n",
            "\n",
            "--- Chunk 17915 ---\n",
            "stacking multiple feature maps, 451 analyzing through clustering, 237\n",
            "TensorFlow implementation, 453 California Housing Prices dataset, 36\n",
            "\n",
            "--- Chunk 17916 ---\n",
            "Convolutional Neural Networks (CNNs) chopping sequential datasets, 528\n",
            "architecture of visual cortex, 446 compressing, 224\n",
            "\n",
            "--- Chunk 17917 ---\n",
            "classification and localization, 483 data mismatch, 32\n",
            "CNN architectures, 460-478 decompressing, 224\n",
            "convolutional layer, 448-456 downloading, 46\n",
            "\n",
            "--- Chunk 17918 ---\n",
            "object detection, 485-492 efficient data representations, 569\n",
            "overview of, 445 Fashion MNIST dataset, 297, 574, 590\n",
            "\n",
            "--- Chunk 17919 ---\n",
            "pooling layer, 456 flat datasets, 529\n",
            "pretrained models for transfer learning, 481 geographical data, 56\n",
            "\n",
            "--- Chunk 17920 ---\n",
            "pretrained models from Keras, 479 Google News 7B corpus, 541\n",
            "ResNet-34 using Keras, 478 helper function creation, 420\n",
            "\n",
            "--- Chunk 17921 ---\n",
            "semantic segmentation, 492 importance of over algorithms, 24\n",
            "\n",
            "--- Chunk 17922 ---\n",
            "core instances, 255 Internet Movie Database, 534\n",
            "corpus development, 24 iris dataset, 145\n",
            "\n",
            "--- Chunk 17923 ---\n",
            "correlation coefficient, 58 loading and preprocessing with TensorFlow,\n",
            "cost functions 413-442\n",
            "\n",
            "--- Chunk 17924 ---\n",
            "cross-entropy loss (log loss), 149 MNIST dataset, 85\n",
            "hinge loss, 155, 173 nested datasets, 529\n",
            "mean absolute error (MAE), 41, 293 noisy data, 19\n",
            "\n",
            "--- Chunk 17925 ---\n",
            "mean squared error, 120, 293, 308, 384, 570, prefetching, 421\n",
            "\n",
            "--- Chunk 17926 ---\n",
            "573, 583, 636 preprocessing, 251, 419, 430-439\n",
            "\n",
            "804 | Index\n",
            "\n",
            "--- Chunk 17927 ---\n",
            "reconstruction error, 224 Gini impurity versus entropy, 180\n",
            "reducing dimensionality of, 222 instability drawbacks, 185\n",
            "\n",
            "--- Chunk 17928 ---\n",
            "shuffling, 416 making predictions, 176\n",
            "skewed datasets, 89 regression tasks, 183\n",
            "sources for, 35 regularization hyperparameters, 181\n",
            "\n",
            "--- Chunk 17929 ---\n",
            "splitting sequential datasets, 527 training and visualizing, 175\n",
            "training dataset creation, 527 decoders, 501, 569\n",
            "\n",
            "--- Chunk 17930 ---\n",
            "training sparse models, 359 decompression, 224\n",
            "using datasets with tf.Keras, 423 deep autoencoders, 572\n",
            "\n",
            "--- Chunk 17931 ---\n",
            "Data API (TensorFlow) deep belief networks (DBNs), 13, 777\n",
            "chaining transformations, 415 deep computer vision (see Convolutional Neu‐\n",
            "\n",
            "--- Chunk 17932 ---\n",
            "helper function creation, 420 ral Networks (CNNs))\n",
            "overview of, 414 deep convolutional GANs, 598\n",
            "prefetching data, 421 Deep Learning VM Images, 692\n",
            "\n",
            "--- Chunk 17933 ---\n",
            "preprocessing data, 419 deep neural networks (DNNs)\n",
            "shuffling data, 416 avoiding overfitting, 364-371\n",
            "\n",
            "--- Chunk 17934 ---\n",
            "using datasets with tf.keras, 423 default configuration, 371\n",
            "\n",
            "--- Chunk 17935 ---\n",
            "data augmentation, 464 defined, xv, 289\n",
            "data parallelism, 701, 704 faster optimizers, 351-364\n",
            "data preparation overview of, 331\n",
            "\n",
            "--- Chunk 17936 ---\n",
            "benefits of functions for, 62 reusing pretrained layers, 345-351\n",
            "custom transformers, 68 vanishing/exploding gradients problems,\n",
            "\n",
            "--- Chunk 17937 ---\n",
            "data cleaning, 63 332-345\n",
            "feature scaling, 69 Deep Neuroevolution, 323\n",
            "handling text and categorical attributes, 65 Deep Q-Learning\n",
            "\n",
            "--- Chunk 17938 ---\n",
            "transformation pipelines, 70 Double DQN, 640\n",
            "\n",
            "--- Chunk 17939 ---\n",
            "data snooping bias, 51 Dueling DQN, 641\n",
            "data visualization fixed Q-Value targets, 639\n",
            "\n",
            "--- Chunk 17940 ---\n",
            "attribute combinations, 61 implementing, 634\n",
            "computing correlations, 58 overview of, 633\n",
            "\n",
            "--- Chunk 17941 ---\n",
            "dimensionality reduction, 213 prioritized experience replay, 640\n",
            "geographical data, 56 variants of, 639\n",
            "\n",
            "--- Chunk 17942 ---\n",
            "test, training, and exploration sets, 56 deep Q-networks (DQNs), 633, 650, 650\n",
            "using TensorBoard for, 317 denoising autoencoders, 581\n",
            "\n",
            "--- Chunk 17943 ---\n",
            "visualizing Fashion MNIST Dataset, 574 dense layer, 285\n",
            "visualizing reconstructions, 574 dense vectors, 556\n",
            "\n",
            "--- Chunk 17944 ---\n",
            "datasets, defined, 414 density estimation, 236, 264\n",
            "DataViz (see data visualization) depth concat layer, 467\n",
            "\n",
            "--- Chunk 17945 ---\n",
            "DBSCAN (density-based spatial clustering of depth radius, 466\n",
            "\n",
            "--- Chunk 17946 ---\n",
            "applications with noise), 255 depthwise separable convolution, 474\n",
            "decision boundaries, 145 deques, 635\n",
            "\n",
            "--- Chunk 17947 ---\n",
            "decision function, 93 development sets (dev sets), 31\n",
            "Decision Stumps, 203 differencing, 506\n",
            "Decision Trees dimensionality reduction\n",
            "\n",
            "--- Chunk 17948 ---\n",
            "benefits of, 175 additional techniques, 232\n",
            "CART training algorithm, 179 approaches for, 215-218\n",
            "computational complexity, 180 using clustering, 237\n",
            "\n",
            "--- Chunk 17949 ---\n",
            "estimating class probabilities, 178 curse of dimensionality, 214\n",
            "evaluating, 73 goal of, 12\n",
            "\n",
            "--- Chunk 17950 ---\n",
            "Index | 805\n",
            "\n",
            "--- Chunk 17951 ---\n",
            "LLE (Locally Linear Embedding), 230 entropy impurity measure, 180\n",
            "overview of, 213 epochs, 125, 290\n",
            "\n",
            "--- Chunk 17952 ---\n",
            "PCA (Principal Component Analysis), equalized learning rates, 603\n",
            "\n",
            "--- Chunk 17953 ---\n",
            "219-230 equivariance, 458\n",
            "discount factors, 619 error analysis, 102\n",
            "discriminators, 568 estimators, 64\n",
            "\n",
            "--- Chunk 17954 ---\n",
            "Distribution Strategies API, 668, 709 Euclidean norm, 41\n",
            "dot product, 551 event files, 317\n",
            "Double DQN, 640 evidence lower bound (ELBO), 272\n",
            "\n",
            "--- Chunk 17955 ---\n",
            "Double Dueling DQN, 642 example project\n",
            "DQN agents, 652 data downloading, 42-55, 756\n",
            "dropout, 365 data preparation, 62-72, 757\n",
            "\n",
            "--- Chunk 17956 ---\n",
            "dual numbers, 768 data visualization, 56-62, 756\n",
            "dual problem, 168, 761 framing the problem, 37, 755\n",
            "\n",
            "--- Chunk 17957 ---\n",
            "duck typing, 68 launching, monitoring, and maintaining, 80,\n",
            "Dueling DQN algorithm, 641 760\n",
            "\n",
            "--- Chunk 17958 ---\n",
            "dummy attributes, 67 Machine Learning project checklist, 37, 755\n",
            "dying ReLUs problem, 335 model fine-tuning, 75-80, 759\n",
            "\n",
            "--- Chunk 17959 ---\n",
            "dynamic models, 313 model selection and training, 72, 758\n",
            "dynamic placer algorithm, 697 overview of, 35\n",
            "Dynamic Programming, 628 project goals, 37\n",
            "\n",
            "--- Chunk 17960 ---\n",
            "real-world data for, 35\n",
            "E selecting performance measure, 39\n",
            "eager execution/eager mode, 408 verifying assumptions, 42\n",
            "\n",
            "--- Chunk 17961 ---\n",
            "early stopping, 141 Exclusive OR (XOR) classification problem,\n",
            "Elastic Net, 140 288\n",
            "\n",
            "--- Chunk 17962 ---\n",
            "ELU (exponential linear unit), 336-338 exercise solutions, 719-753\n",
            "embedded devices, 685 expectation step, 262\n",
            "\n",
            "--- Chunk 17963 ---\n",
            "Embedded Reber grammars, 566 Expectation-Maximization (EM) algorithm,\n",
            "embedding, 68, 413, 433 262\n",
            "embedding matrix, 435 experience replay, 597\n",
            "\n",
            "--- Chunk 17964 ---\n",
            "encoders, 501, 569 explainability, 553\n",
            "Encoder–Decoder model, 501, 542-548 explained variance ratio, 222\n",
            "\n",
            "--- Chunk 17965 ---\n",
            "end-of-sequence (EoS) token, 542, 556 exploding gradients problem, 332\n",
            "energy function, 774 exploration policy, 630, 632\n",
            "\n",
            "--- Chunk 17966 ---\n",
            "Ensemble Learning exploration sets, 56\n",
            "\n",
            "--- Chunk 17967 ---\n",
            "bagging and pasting, 192-196 exponential linear unit (ELU), 336-338\n",
            "benefits of, 74 exponential scheduling, 360\n",
            "\n",
            "--- Chunk 17968 ---\n",
            "best uses of, 191 Extra-Trees classifier, 198\n",
            "boosting, 199-208 Extremely Randomized Trees ensemble, 198\n",
            "defined, 189\n",
            "examples of, 189 F\n",
            "\n",
            "--- Chunk 17969 ---\n",
            "examples of, 189 F\n",
            "Random Forests, 189, 197 F1 score, 92\n",
            "random patches and random subspaces, 196 fake quantization, 687\n",
            "\n",
            "--- Chunk 17970 ---\n",
            "stacking, 208 false positive rate (FPR), 97\n",
            "voting classifiers, 189 fan-in/fan-out numbers, 333\n",
            "\n",
            "--- Chunk 17971 ---\n",
            "Ensemble methods, 189 Fashion MNIST dataset, 297, 574, 590\n",
            "ensembles, 189 Fast-MCD (minimum covariance determi‐\n",
            "entailment, 564 nant), 274\n",
            "\n",
            "--- Chunk 17972 ---\n",
            "806 | Index\n",
            "\n",
            "--- Chunk 17973 ---\n",
            "feature engineering, 27 difficulties of training, 596\n",
            "feature extraction, 12, 27 overview of, 592\n",
            "feature maps, 228, 450 progressive growing of, 601\n",
            "\n",
            "--- Chunk 17974 ---\n",
            "feature scaling, 69 StyleGANs, 604\n",
            "feature selection, 27 uses for, 567\n",
            "feature space, 226 generative autoencoders, 586\n",
            "\n",
            "--- Chunk 17975 ---\n",
            "feature vector, 113 generative models, 263, 567, 775 (see also\n",
            "features, 8 autencoders; Generative Adversarial Net‐\n",
            "\n",
            "--- Chunk 17976 ---\n",
            "feedforward neural networks (FNNs), 289 works (GANs))\n",
            "filters, 450 generative network, 569\n",
            "final trained models, 20 generators, 568\n",
            "\n",
            "--- Chunk 17977 ---\n",
            "finite difference approximation, 766 genetic algorithms, 612\n",
            "First In, First Out (FIFO) queues, 383 Gini impurity measure, 180\n",
            "\n",
            "--- Chunk 17978 ---\n",
            "first-order partial derivatives (Jacobians), 358 global average pooling layer, 460\n",
            "fitness functions, 20 global minimum, 119\n",
            "\n",
            "--- Chunk 17979 ---\n",
            "fixed Q-Value targets, 639 Glorot and He initialization, 333\n",
            "flat datasets, 529 Google Cloud Platform (GCP)\n",
            "\n",
            "--- Chunk 17980 ---\n",
            "folds, 73, 89 prediction service creation, 677-681\n",
            "forecasting, 503 prediction service use, 682-685\n",
            "forget gate, 516 Google Cloud Storage (GCS), 679\n",
            "\n",
            "--- Chunk 17981 ---\n",
            "forward pass, 290 Google News 7B corpus, 541\n",
            "forward-mode autodiff, 767 GoogLeNet, 466\n",
            "fraud detection, 237 GPUs (graphics processing units)\n",
            "\n",
            "--- Chunk 17982 ---\n",
            "Full Gradient Descent, 122 adding to single machines, 689\n",
            "fully connected layer, 285 Colaboratory (Colab), 693\n",
            "\n",
            "--- Chunk 17983 ---\n",
            "fully convolutional networks (FCNs), 487 GPU-equipped virtual machines, 692\n",
            "fully-specified model architecture, 20 managing GPU RAM, 694\n",
            "\n",
            "--- Chunk 17984 ---\n",
            "function definitions, 792 parallel execution across multiple devices,\n",
            "function graphs, 792 699\n",
            "\n",
            "--- Chunk 17985 ---\n",
            "Functional API, 308-313 placing operations and variables on devices,\n",
            "\n",
            "--- Chunk 17986 ---\n",
            "697\n",
            "G selecting, 690\n",
            "gate controllers, 516 speeding computations with, 689\n",
            "\n",
            "--- Chunk 17987 ---\n",
            "Gated Recurrent Unit (GRU) cell, 518 Gradient Boosted Regression Trees (GBRT),\n",
            "Gaussian mixture model (GMM) 203\n",
            "\n",
            "--- Chunk 17988 ---\n",
            "additional algorithms for anomaly and nov‐ Gradient Boosting, 203\n",
            "elty detection, 274 gradient clipping, 345\n",
            "\n",
            "--- Chunk 17989 ---\n",
            "anomaly detection using, 266 Gradient Descent (GD)\n",
            "Bayesian Gaussian Mixture models, 270 Batch Gradient Descent, 121\n",
            "\n",
            "--- Chunk 17990 ---\n",
            "graphical model of, 260 Mini-batch Gradient Descent, 127\n",
            "overview of, 260 overview of, 111, 118\n",
            "\n",
            "--- Chunk 17991 ---\n",
            "selecting cluster number, 267 Stochastic Gradient Descent, 124\n",
            "variants, 260 Gradient Tree Boosting, 203\n",
            "\n",
            "--- Chunk 17992 ---\n",
            "Gaussian Radial Basis Function (RBF), 159 graph mode, 408\n",
            "generalization error, 30 greedy algorithms, 180\n",
            "\n",
            "--- Chunk 17993 ---\n",
            "generalized Lagrangian, 762 greedy layer-wise pretraining, 349\n",
            "Generative Adversarial Networks (GANs) greedy layer-wise training, 578\n",
            "\n",
            "--- Chunk 17994 ---\n",
            "versus autoencoders, 568\n",
            "deep convolutional GANs (DCGANs), 598\n",
            "\n",
            "Index | 807\n",
            "\n",
            "--- Chunk 17995 ---\n",
            "H imputation, 503\n",
            "hard clustering, 240 incremental learning, 16\n",
            "hard margin classification, 154 Incremental PCA (IPCA), 225\n",
            "\n",
            "--- Chunk 17996 ---\n",
            "hard voting classifiers, 190 independent and identically distributed (IID),\n",
            "harmonic mean, 92 126\n",
            "HDF5 format, 314 inequality constraints, 762\n",
            "\n",
            "--- Chunk 17997 ---\n",
            "He initialization, 333 inertia, 243\n",
            "Heaviside step function, 285 inference, 23\n",
            "Hebb's rule, 286 information theory, 180\n",
            "\n",
            "--- Chunk 17998 ---\n",
            "Hebbian learning, 286 initialization\n",
            "helper functions, 420 centroid initialization methods, 243\n",
            "hidden layers Glorot and He initialization, 333\n",
            "\n",
            "--- Chunk 17999 ---\n",
            "in MLPs, 289 LeCun initialization, 334\n",
            "neurons per hidden layer, 324 random initialization, 118\n",
            "number of, 323 Xavier initialization, 333\n",
            "\n",
            "--- Chunk 18000 ---\n",
            "hidden units, 775 inliers, 266\n",
            "hierarchical clustering algorithms, 10 input and output sequences, 501\n",
            "\n",
            "--- Chunk 18001 ---\n",
            "Hierarchical DBSCAN (HDBSCAN), 258 input gate, 516\n",
            "high-dimensional training sets, 213 input layers, 289\n",
            "\n",
            "--- Chunk 18002 ---\n",
            "hinge loss function, 155, 173 input neurons, 285\n",
            "Hinton, Geoffrey, xv input signatures, 791\n",
            "histograms, 50 instability, 185\n",
            "\n",
            "--- Chunk 18003 ---\n",
            "hold outs, 31 instance segmentation, 249, 495\n",
            "holdout validation, 31 instance-based learning, 17, 22\n",
            "Hopfield networks, 773 inter-op thread pool, 699\n",
            "\n",
            "--- Chunk 18004 ---\n",
            "Huber loss, 293, 384 intercept terms, 112\n",
            "Hyperas, 322 Internet Movie Database, 534\n",
            "Hyperband, 323 intra-op thread pool, 699\n",
            "\n",
            "--- Chunk 18005 ---\n",
            "hyperbolic tangent function (tanh), 291 invariance, 457\n",
            "Hyperopt, 322 inverse transformation, 225\n",
            "hyperparameters iris dataset, 145\n",
            "\n",
            "--- Chunk 18006 ---\n",
            "defined, 29 isolated environments, 43\n",
            "fine-tuning for neural networks, 320-327 Isolation Forest algorithm, 274\n",
            "\n",
            "--- Chunk 18007 ---\n",
            "hyperparameter tuning, 31, 75 isomap algorithm, 233\n",
            "learning rate, 118\n",
            "Python libraries for optimization, 322 J\n",
            "\n",
            "--- Chunk 18008 ---\n",
            "regularization hyperparameters, 181 JupyterLab, 692\n",
            "\n",
            "--- Chunk 18009 ---\n",
            "hyperplanes, 165 just-in-time (JIT) compiler, 376\n",
            "hypothesis boosting, 199\n",
            "\n",
            "--- Chunk 18010 ---\n",
            "K\n",
            "I K-fold cross-validation, 73, 89\n",
            "identity matrix, 137 K-Means\n",
            "image classification accelerated and mini-batch, 244\n",
            "\n",
            "--- Chunk 18011 ---\n",
            "multitask classification, 311 centroid initialization methods, 243\n",
            "using Sequential API, 297-307 hard and soft clustering, 240\n",
            "\n",
            "--- Chunk 18012 ---\n",
            "image generation, 495 image segmentation, 249\n",
            "image segmentation, 238, 249 K-Means algorithm, 241\n",
            "importance sampling (IS), 640 limits of, 248\n",
            "\n",
            "--- Chunk 18013 ---\n",
            "impurity, 177, 180 optimal cluster number, 245\n",
            "\n",
            "--- Chunk 18014 ---\n",
            "808 | Index\n",
            "\n",
            "--- Chunk 18015 ---\n",
            "overview of, 238 layers\n",
            "preprocessing with, 251 1D convolutional layer, 520\n",
            "proposed improvement to, 243 adaptive instance normalization (AdaIN),\n",
            "\n",
            "--- Chunk 18016 ---\n",
            "scaling input features, 249 604\n",
            "for semi-supervised learning, 253 bidirectional recurrent layer, 546\n",
            "\n",
            "--- Chunk 18017 ---\n",
            "k-Nearest Neighbors regression, 22 convolutional layer, 448-456\n",
            "Karush–Kuhn–Tucker (KKT) multipliers, 762 dense (fully connected) layer, 285\n",
            "\n",
            "--- Chunk 18018 ---\n",
            "keep probability, 367 hidden layer, 289\n",
            "Keras input layer, 289\n",
            "\n",
            "--- Chunk 18019 ---\n",
            "benefits of, xvi Masked Multi-Head Attention layer, 556\n",
            "complex architectures, 314 minibatch standard deviation layer, 603\n",
            "\n",
            "--- Chunk 18020 ---\n",
            "gradient clipping in, 345 Multi-Head Attention layer, 556, 559\n",
            "implementing Batch Normalization with, output layer, 289\n",
            "\n",
            "--- Chunk 18021 ---\n",
            "341 pooling layer, 456\n",
            "implementing dropout using, 367 recurrent, 498-502\n",
            "implementing MLPs with, 295-320 reusing pretrained, 345-351\n",
            "\n",
            "--- Chunk 18022 ---\n",
            "implementing ResNet-34 with, 478 Scaled Dot-Product Attention layer, 559\n",
            "keras.callbacks package, 316 leaf nodes, 176\n",
            "\n",
            "--- Chunk 18023 ---\n",
            "loading datasets with, 297 leaky ReLU function, 335\n",
            "low-level API, 381 learning curves, 130-134\n",
            "\n",
            "--- Chunk 18024 ---\n",
            "multibackend Keras, 295 learning rate, 16, 118, 325, 603\n",
            "preprocessing layers, 437 learning rate scheduling, 359\n",
            "\n",
            "--- Chunk 18025 ---\n",
            "saving and restoring models in, 314 learning schedules, 125, 360\n",
            "stacked autoencoders using, 572 LeCun initialization, 334\n",
            "\n",
            "--- Chunk 18026 ---\n",
            "transfer learning with, 347 LeNet-5, 463\n",
            "using code examples from keras.io, 300 Levenshtein distance, 161\n",
            "\n",
            "--- Chunk 18027 ---\n",
            "using pretrained models from, 479 liblinear library, 162\n",
            "\n",
            "--- Chunk 18028 ---\n",
            "Keras Tuner, 322 libsvm library, 162\n",
            "Kernel PCA (kPCA), 226-230 likelihood function, 267\n",
            "kernel trick, 158, 228 linear algebra, 112\n",
            "\n",
            "--- Chunk 18029 ---\n",
            "kernelized SVM, 169 linear autoencoders, 570\n",
            "kernels, 170, 226, 377 Linear Discriminant Analysis (LDA), 233\n",
            "kopt library, 322 linear models, 19\n",
            "\n",
            "--- Chunk 18030 ---\n",
            "Kullback–Leibler divergence, 150 Linear Regression model\n",
            "\n",
            "--- Chunk 18031 ---\n",
            "approaches to training, 111, 113\n",
            "L computational complexity, 117\n",
            "label propagation, 254 Normal Equation, 114\n",
            "labels, 8, 39, 239 overview of, 112\n",
            "\n",
            "--- Chunk 18032 ---\n",
            "Lagrange multipliers, 761 linear SVM classification, 153\n",
            "landmarks, 159 lists of lists, using SequenceExample Protobuf,\n",
            "\n",
            "--- Chunk 18033 ---\n",
            "language models, 563 (see also natural language 429\n",
            "\n",
            "--- Chunk 18034 ---\n",
            "processing (NLP)) LLE (Locally Linear Embedding), 230\n",
            "large margin classification, 153 Lloyd-Forgy algorithm, 238\n",
            "\n",
            "--- Chunk 18035 ---\n",
            "Lasso Regression, 137 local minimum, 119\n",
            "latent loss, 587 Local Outlier Factor (LOF), 274\n",
            "\n",
            "--- Chunk 18036 ---\n",
            "latent representations, 567 local response normalization, 465\n",
            "latent variables, 262 localization, 483\n",
            "law of large numbers, 191 log loss, 144\n",
            "\n",
            "--- Chunk 18037 ---\n",
            "Layer Normalization, 512 log-odds, 144\n",
            "\n",
            "--- Chunk 18038 ---\n",
            "Index | 809\n",
            "\n",
            "--- Chunk 18039 ---\n",
            "logical computations, 283 mask tensors, 539\n",
            "logical GPU devices, 695 masked language model (MLM), 564\n",
            "\n",
            "--- Chunk 18040 ---\n",
            "Logistic (sigmoid) function, 143, 293-294, 302, Masked Multi-Head Attention layer, 556\n",
            "\n",
            "--- Chunk 18041 ---\n",
            "332 masking, 538\n",
            "Logistic Regression max pooling layer, 457\n",
            "\n",
            "--- Chunk 18042 ---\n",
            "classification with, 8 max-norm regularization, 370\n",
            "decision boundaries, 145 maximization step, 262\n",
            "\n",
            "--- Chunk 18043 ---\n",
            "estimating probabilities, 143 maximum a-posteriori (MAP) estimation, 269\n",
            "overview of, 142 maximum likelihood estimate (MLE), 269\n",
            "\n",
            "--- Chunk 18044 ---\n",
            "Softmax Regression, 148 mean absolute error (MAE), 41\n",
            "training and cost function, 144 mean Average Precision (mAP), 491\n",
            "\n",
            "--- Chunk 18045 ---\n",
            "logit, 144 mean coding, 586\n",
            "Logit Regression (see Logistic Regression) mean field variational inference, 273\n",
            "\n",
            "--- Chunk 18046 ---\n",
            "long sequences Mean-Shift algorithm, 259\n",
            "\n",
            "--- Chunk 18047 ---\n",
            "overview of, 511 measure of similarity, 18\n",
            "short-term memory problems, 514-523 memory bandwidth, 422\n",
            "\n",
            "--- Chunk 18048 ---\n",
            "unstable gradients problem, 512 memory cells, 500\n",
            "\n",
            "--- Chunk 18049 ---\n",
            "Long Short-Term Memory (LSTM) cell, 514 Mercer's conditions, 171\n",
            "loss functions (see cost functions) Mercer's theorem, 171\n",
            "\n",
            "--- Chunk 18050 ---\n",
            "Luong attention, 551 meta learners, 208\n",
            "\n",
            "--- Chunk 18051 ---\n",
            "metagraphs, 671\n",
            "M metrics\n",
            "Machine Learning (ML) accuracy, 388\n",
            "\n",
            "--- Chunk 18052 ---\n",
            "additional resources, xix area under the curve (AUC), 98\n",
            "applications for, xv, 5 confusion matrix, 90, 90\n",
            "approach to learning, xvi F1 score, 92\n",
            "\n",
            "--- Chunk 18053 ---\n",
            "benefits of, 2 mean absolute error (MAE), 41, 293\n",
            "challenges of, 23-30 mean average precision, 491\n",
            "defined, 1 mean squared error, 183, 505\n",
            "\n",
            "--- Chunk 18054 ---\n",
            "history of, xv precision, 91-97\n",
            "locating papers on, 378 recall, 91-97\n",
            "notations for, 40, 164 RMSE, 39\n",
            "overview of, 30 ROC curve, 97\n",
            "\n",
            "--- Chunk 18055 ---\n",
            "prerequisites to learning, xvii Microsoft Cognitive Toolkit (CNTK), 295\n",
            "testing and validating, 30-33 min-max scaling, 69\n",
            "\n",
            "--- Chunk 18056 ---\n",
            "topics covered, xvii Mini-batch Gradient Descent, 127\n",
            "types of, 7-23 mini-batch K-Means, 244\n",
            "\n",
            "--- Chunk 18057 ---\n",
            "Machine Learning project checklist, 37, 755 mini-batches, 15, 127\n",
            "majority-vote classifiers, 190 minibatch discrimination, 597\n",
            "\n",
            "--- Chunk 18058 ---\n",
            "majority-vote predictions, 187 minibatch standard deviation layer, 603\n",
            "Manhattan norm, 41 mirrored strategy, 704\n",
            "\n",
            "--- Chunk 18059 ---\n",
            "manifold assumption, 218 mixing regularization, 606\n",
            "manifold hypothesis, 218 ML Engine, 680\n",
            "Manifold Learning, 218 MNIST dataset, 85\n",
            "\n",
            "--- Chunk 18060 ---\n",
            "manual differentiation, 765 mobile devices, 685\n",
            "margin violations, 155 mode collapse, 597\n",
            "Markov chains, 625 model parallelism, 701\n",
            "\n",
            "--- Chunk 18061 ---\n",
            "Markov Decision Processes (MDP), 625-629 model parameters, 20\n",
            "Mask R-CNN, 495 model selection, 19, 31, 72\n",
            "\n",
            "--- Chunk 18062 ---\n",
            "810 | Index\n",
            "\n",
            "\n",
            "\n",
            "model-based learning, 18 generating text using character RNNs,\n",
            "models (see also custom models) 526-534\n",
            "\n",
            "--- Chunk 18063 ---\n",
            "causal models, 510 overview of, 525\n",
            "complex using Functional API, 308-313 recent innovations in, 563\n",
            "custom with TensorFlow, 384-405 RNNS for, 497\n",
            "\n",
            "--- Chunk 18064 ---\n",
            "defined, 20 sentiment analysis, 534-542\n",
            "dynamic using Subclassing API, 313 uses for, 351\n",
            "fine-tuning, 75-80 nested datasets, 529\n",
            "\n",
            "--- Chunk 18065 ---\n",
            "parametric versus nonparametric, 181 Nesterov Accelerated Gradient (NAG), 353\n",
            "\n",
            "--- Chunk 18066 ---\n",
            "pretrained models for transfer learning, 481 Nesterov momentum optimization, 353\n",
            "\n",
            "--- Chunk 18067 ---\n",
            "pretrained models from Keras, 479 neural machine translation (NMT), 542-563\n",
            "saving and restoring, 314 (see also natural language processing\n",
            "\n",
            "--- Chunk 18068 ---\n",
            "sequence-to-sequence models, 510 (NLP))\n",
            "training, 20, 72 (see also training models) neurons\n",
            "\n",
            "--- Chunk 18069 ---\n",
            "training across multiple devices, 701-717 bias neurons, 285\n",
            "training sparse models, 359 fan-in/fan-out numbers, 333\n",
            "\n",
            "--- Chunk 18070 ---\n",
            "using callbacks, 315 from biological to artificial, 280-295\n",
            "using TensorBoard for visualization, 317 input neurons, 285\n",
            "\n",
            "--- Chunk 18071 ---\n",
            "white versus black box, 178 logical computations with, 283\n",
            "\n",
            "--- Chunk 18072 ---\n",
            "modules, 540 per hidden layer, 324\n",
            "momentum optimization, 351 recurrent neurons, 498-502\n",
            "momentum vector, 352 stochastic neurons, 775\n",
            "\n",
            "--- Chunk 18073 ---\n",
            "Monte Carlo (MC) dropout, 368 Newton's difference quotient, 766\n",
            "Multi-Head Attention layer, 556, 559 next sentence prediction (NSP), 565\n",
            "\n",
            "--- Chunk 18074 ---\n",
            "multibackend Keras, 295 No Free Lunch (NFL) theorem, 33\n",
            "multiclass classification, 100 noisy data, 19\n",
            "\n",
            "--- Chunk 18075 ---\n",
            "Multidimensional Scaling (MDS), 232 non-max suppression, 486\n",
            "multilabel classification, 106 nonlinear dimensionality reduction (NLDR),\n",
            "\n",
            "--- Chunk 18076 ---\n",
            "Multilayer Perceptrons (MLPs) 230\n",
            "\n",
            "--- Chunk 18077 ---\n",
            "backpropagation and, 289-292 nonlinear SVM classification, 157-162\n",
            "classification MLPs, 294 nonparametric models, 181\n",
            "\n",
            "--- Chunk 18078 ---\n",
            "regression MLPs, 292 nonsaturating activation functions, 335\n",
            "\n",
            "--- Chunk 18079 ---\n",
            "multinomial classifiers, 100 nonsequential neural networks, 308\n",
            "Multinomial Logistic Regression, 148 Normal Equation, 114\n",
            "\n",
            "--- Chunk 18080 ---\n",
            "multioutput classification, 107 normalization, 69, 339, 603\n",
            "multiple outputs, 311 normalized exponential, 148\n",
            "\n",
            "--- Chunk 18081 ---\n",
            "multiple regression problems, 39 novelty detection, 12, 267, 274\n",
            "multiplicative attention, 551 NP-Complete problem, 180\n",
            "\n",
            "--- Chunk 18082 ---\n",
            "multitask classification, 311 null hypothesis, 182\n",
            "multivariate regression problems, 39 NumPy\n",
            "\n",
            "--- Chunk 18083 ---\n",
            "multivariate time series, 503 array_split() function, 226\n",
            "\n",
            "--- Chunk 18084 ---\n",
            "dense arrays, 67\n",
            "N installing, 42\n",
            "naive forecasting, 505 inv() function, 115\n",
            "Nash equilibrium, 596 memmap class, 226\n",
            "\n",
            "--- Chunk 18085 ---\n",
            "natural language processing (NLP) randint() function, 107\n",
            "\n",
            "--- Chunk 18086 ---\n",
            "attention mechanisms, 549-563 serializing large arrays, 75\n",
            "CNNs for, 445 svd() function, 221\n",
            "\n",
            "--- Chunk 18087 ---\n",
            "Encoder–Decoder network for, 542-548 using TensorFlow like, 379-384\n",
            "\n",
            "--- Chunk 18088 ---\n",
            "Index | 811\n",
            "\n",
            "\n",
            "\n",
            "NVIDIA Collective Communications Library limiting risk of, 457\n",
            "(NCCL), 710\n",
            "\n",
            "Nvidia GPU cards, 690 P\n",
            "p (posterior) distribution, 272\n",
            "\n",
            "--- Chunk 18089 ---\n",
            "O p (prior) distribution, 271\n",
            "object detection p-value, 182\n",
            "\n",
            "--- Chunk 18090 ---\n",
            "fully convolutional networks (FCNs), 487 parameter efficiency, 323\n",
            "overview of, 485 parameter matrix, 148\n",
            "\n",
            "--- Chunk 18091 ---\n",
            "You Only Look Once (YOLO), 489 parameter servers, 705\n",
            "\n",
            "--- Chunk 18092 ---\n",
            "objectness output, 486 parameter space, 121\n",
            "observed variables, 262 parameter vector, 113\n",
            "observers, 654 parametric leaky ReLU (PReLU), 335\n",
            "\n",
            "--- Chunk 18093 ---\n",
            "off-policy algorithms, 632 parametric models, 181\n",
            "offline learning, 15 partial derivatives, 121\n",
            "\n",
            "--- Chunk 18094 ---\n",
            "on-policy algorithms, 632 pasting (see bagging and pasting)\n",
            "one-class SVM algorithm, 275 pattern matching, 569\n",
            "\n",
            "--- Chunk 18095 ---\n",
            "one-hot encoding, 67 PCA (Principal Component Analysis)\n",
            "one-hot vectors, 431 anomaly and novelty detection using, 274\n",
            "\n",
            "--- Chunk 18096 ---\n",
            "one-versus-all (OvA) strategy, 100 choosing dimension number, 223\n",
            "one-versus-one (OvO) strategy, 100 for compression, 224\n",
            "\n",
            "--- Chunk 18097 ---\n",
            "one-versus-the-rest (OvR) strategy, 100 explained variance ratio, 222\n",
            "online learning, 15, 88 incremental, 225\n",
            "\n",
            "--- Chunk 18098 ---\n",
            "online model, 639 Kernel PCA (kPCA), 226-230\n",
            "online SVMs, 172 overview of, 219\n",
            "OpenAI Gym, 613-617 preserving variance, 219\n",
            "\n",
            "--- Chunk 18099 ---\n",
            "Optical Character Recognition (OCR), 1 principal component axis, 220\n",
            "optimal state value, 627 projecting down to d dimensions, 221\n",
            "\n",
            "--- Chunk 18100 ---\n",
            "optimizers randomized, 225\n",
            "\n",
            "--- Chunk 18101 ---\n",
            "AdaGrad, 354 using Scikit-Learn, 222\n",
            "Adam and Nadam optimization, 356 undercomplete linear autoencoders for, 570\n",
            "\n",
            "--- Chunk 18102 ---\n",
            "creating faster, 351 Pearson's r, 58\n",
            "first- and second-order partial derivatives, peephole connections, 518\n",
            "\n",
            "--- Chunk 18103 ---\n",
            "358 penalties, 14\n",
            "learning rate scheduling, 359 Perceptron, 284-288\n",
            "momentum optimization, 351 Perceptron convergence theorem, 287\n",
            "\n",
            "--- Chunk 18104 ---\n",
            "Nesterov Accelerated Gradient (NAG), 353 performance measures (see metrics)\n",
            "RMSProp, 355 performance scheduling, 361\n",
            "\n",
            "--- Chunk 18105 ---\n",
            "Stochastic Gradient Descent (SGD), 88, 124 piecewise constant scheduling, 361\n",
            "\n",
            "--- Chunk 18106 ---\n",
            "original space, 226 pipelines, 38, 424\n",
            "out-of-core learning, 16 pixelwise normalization layers, 603\n",
            "out-of-sample error, 30 policies, 14, 612\n",
            "\n",
            "--- Chunk 18107 ---\n",
            "out-of-vocabulary (oov) buckets, 432 policy gradients (PG), 613, 620-625\n",
            "outlier detection, 237, 266 policy parameters, 612\n",
            "\n",
            "--- Chunk 18108 ---\n",
            "output gate, 516 policy search, 612\n",
            "output layers, 289 policy space, 612\n",
            "overcomplete autoencoders, 580, 580 polynomial features, 158\n",
            "\n",
            "--- Chunk 18109 ---\n",
            "overfitting polynomial kernels, 170\n",
            "\n",
            "--- Chunk 18110 ---\n",
            "avoiding through regularization, 364-371 Polynomial Regression, 112, 128\n",
            "defined, 27 pooling kernel, 457\n",
            "\n",
            "812 | Index\n",
            "\n",
            "--- Chunk 18111 ---\n",
            "pooling layer, 456 ragged tensors, 383, 784\n",
            "positional embeddings, 556 Rainbow agent, 642\n",
            "post-training quantization, 686 Random Forests\n",
            "\n",
            "--- Chunk 18112 ---\n",
            "power scheduling, 360 benefits of, 189\n",
            "pre-images, 228 Extra-Trees, 198\n",
            "precision, 91-97 feature importance, 198\n",
            "\n",
            "--- Chunk 18113 ---\n",
            "prediction problems, 8, 17, 189 overview of, 197\n",
            "prediction service random initialization, 118\n",
            "\n",
            "--- Chunk 18114 ---\n",
            "creating on GCP AI, 677-681 random patches and random subspaces, 196\n",
            "using, 682-685 random projections, 232\n",
            "\n",
            "--- Chunk 18115 ---\n",
            "predictors, 65 randomized leaky ReLU (RReLU), 335\n",
            "preprocessing, 251, 430-439 Randomized PCA, 225\n",
            "pretraining recall, 91-97\n",
            "\n",
            "--- Chunk 18116 ---\n",
            "for transfer learning, 481 receiver operating characteristic (ROC) curve,\n",
            "greedy layer-wise pretraining, 349 97\n",
            "\n",
            "--- Chunk 18117 ---\n",
            "models from Keras, 479 recognition network, 569\n",
            "on auxiliary tasks, 350 recommender systems, 237\n",
            "\n",
            "--- Chunk 18118 ---\n",
            "reusing pretrained embeddings, 540 reconstruction error, 224\n",
            "reusing pretrained layers, 345-351 reconstruction loss, 397, 570\n",
            "\n",
            "--- Chunk 18119 ---\n",
            "unsupervised pretraining, 349 reconstruction pre-images, 228\n",
            "using stacked autoencoders, 576-579 reconstructions, 570\n",
            "\n",
            "--- Chunk 18120 ---\n",
            "primal problem, 168 Rectified Linear Unit function (ReLU), 292-293\n",
            "prioritized experience replay (PER), 640 recurrent autoencoders, 580\n",
            "\n",
            "--- Chunk 18121 ---\n",
            "probabilistic autoencoders, 586 recurrent neural networks (RNNs)\n",
            "probability density function (PDF), 236, 264 bidirectional RNNs, 546\n",
            "\n",
            "--- Chunk 18122 ---\n",
            "projection, 215 forecasting time series, 503-511\n",
            "propositional logic, 280 generating text using character RNNS,\n",
            "\n",
            "--- Chunk 18123 ---\n",
            "protocol buffers (protobufs), 425 526-534\n",
            "Proximal Policy Optimization (PPO), 663 handling long sequences, 511-523\n",
            "pruning, 182 overview of, 497\n",
            "\n",
            "--- Chunk 18124 ---\n",
            "PyTorch library, 296 recurrent neurons and layers, 498-502\n",
            "\n",
            "--- Chunk 18125 ---\n",
            "stateless and stateful, 525, 532\n",
            "Q training, 502\n",
            "Q-Learning recurrent neurons, 498\n",
            "\n",
            "--- Chunk 18126 ---\n",
            "Approximate Q-Learning and Deep Q- Region Proposal Network (RPN), 492\n",
            "Learning, 633 regression problems\n",
            "\n",
            "--- Chunk 18127 ---\n",
            "exploration policy, 632 Decision Trees, 183\n",
            "implementing, 631 defined, 8\n",
            "overview of, 630 k-Nearest Neighbors regression, 22\n",
            "\n",
            "--- Chunk 18128 ---\n",
            "Q-Value Iteration, 628 Lasso Regression, 137\n",
            "Q-Values, 628 Linear Regression, 112-117\n",
            "\n",
            "--- Chunk 18129 ---\n",
            "Quadratic Programming (QP) problems, 167 Logistic Regression, 142-151\n",
            "quantization-aware training, 687 multiple regression problems, 39\n",
            "\n",
            "--- Chunk 18130 ---\n",
            "queries per second (QPS), 667 multivariate regression problems, 39\n",
            "questions and comments, xxiii, 718 Polynomial Regression, 128\n",
            "\n",
            "--- Chunk 18131 ---\n",
            "queues, 383, 788 regression MLPs, 292\n",
            "\n",
            "--- Chunk 18132 ---\n",
            "regression MLPs using Sequential API, 307\n",
            "\n",
            "R Ridge Regression, 135\n",
            "Softmax Regression, 148-151\n",
            "\n",
            "Radial Basis Function (RBF), 159\n",
            "\n",
            "Index | 813\n",
            "\n",
            "--- Chunk 18133 ---\n",
            "Index | 813\n",
            "\n",
            "\n",
            "\n",
            "SVM regression, 162 Root Mean Square Error (RMSE), 39, 120\n",
            "univariate regression problems, 39 root nodes, 176\n",
            "\n",
            "--- Chunk 18134 ---\n",
            "regular expressions, 536\n",
            "regularization S\n",
            "\n",
            "--- Chunk 18135 ---\n",
            "avoiding overfitting through, 364-371 SAMME (Stagewise Additive Modeling using a\n",
            "defined, 28 Multiclass Exponential loss function), 203\n",
            "\n",
            "--- Chunk 18136 ---\n",
            "hyperparameters for Decision Trees, 181 sample inefficiency, 625\n",
            "multiple outputs for, 311 sampled softmax technique, 544\n",
            "\n",
            "--- Chunk 18137 ---\n",
            "shrinkage technique, 205 sampling bias, 25\n",
            "\n",
            "--- Chunk 18138 ---\n",
            "regularization terms, 135 sampling noise, 25\n",
            "regularized linear models SavedModel format, 669\n",
            "\n",
            "--- Chunk 18139 ---\n",
            "Elastic Net, 140 saving and restoring models, 314\n",
            "Lasso Regression, 137 Scaled Dot-Product Attention layer, 559\n",
            "\n",
            "--- Chunk 18140 ---\n",
            "overview of, 134 Scaled Exponential Linear Unit (SELU) func‐\n",
            "Ridge Regression, 135 tion, 334, 337-338, 368\n",
            "\n",
            "--- Chunk 18141 ---\n",
            "REINFORCE algorithms, 620 Scikit-Learn\n",
            "Reinforcement Learning (RL) AdaBoost version used in, 203\n",
            "\n",
            "--- Chunk 18142 ---\n",
            "algorithms for, 662 anomaly and novelty detection, 274\n",
            "Deep Q-Learning, 633-638 automatic reconstruction with, 229\n",
            "\n",
            "--- Chunk 18143 ---\n",
            "evaluating actions, 619 bagging and pasting in, 194\n",
            "Markov Decision Processes (MDP), 625-629 benefits of, xvi\n",
            "\n",
            "--- Chunk 18144 ---\n",
            "neural network policies, 617 CART training algorithm, 177, 179\n",
            "OpenAI Gym, 613-617 clustering algorithms in, 258\n",
            "\n",
            "--- Chunk 18145 ---\n",
            "optimizing rewards, 610 computing classifier metrics, 92-107\n",
            "overview of, 14, 609 converting text to numbers, 66\n",
            "\n",
            "--- Chunk 18146 ---\n",
            "policy gradients, 620-625 cross_val_score() function, 89\n",
            "policy search, 612 data centering in, 221\n",
            "\n",
            "--- Chunk 18147 ---\n",
            "Q-Learning, 630-634 dataset dictionary structure, 85\n",
            "Temporal Difference Learning, 629 DecisionTreeRegressor class, 183\n",
            "\n",
            "--- Chunk 18148 ---\n",
            "TF-Agents library, 642-662 design principles, 64\n",
            "\n",
            "--- Chunk 18149 ---\n",
            "ReLU (Rectified Linear Unit function), 292-293 dimensionality reduction in, 232\n",
            "replay buffers, 635, 649, 654 ExtraTreesClassifier class, 198\n",
            "\n",
            "--- Chunk 18150 ---\n",
            "replay memory, 635 feature importance scoring, 198\n",
            "representation learning, 68, 434 (see also feature scaling, 154\n",
            "\n",
            "--- Chunk 18151 ---\n",
            "autoencoders) full SVD approach, 225\n",
            "residual blocks, 395 GBRT ensemble training in, 204\n",
            "residual errors, 203 GridSearchCV, 76\n",
            "\n",
            "--- Chunk 18152 ---\n",
            "residual learning, 471 incremental training in, 207\n",
            "residual units, 471 IncrementalPCA class, 226\n",
            "ResNet (Residual Network), 471 installing, 42\n",
            "\n",
            "--- Chunk 18153 ---\n",
            "ResNet-34 CNN, 478 K-fold cross-validation feature, 73\n",
            "responsibilities (clustering), 262 KernelPCA class, 227\n",
            "\n",
            "--- Chunk 18154 ---\n",
            "restoring models, 314 launching, monitoring, and maintaining\n",
            "restricted Boltzmann machines (RBMs), 13, your system, 80\n",
            "\n",
            "--- Chunk 18155 ---\n",
            "349, 776 linear model using, 21\n",
            "reverse-mode autodiff, 290, 770 linear regression using, 116\n",
            "rewards, 14 LLE (Locally Linear Embedding), 230, 232\n",
            "\n",
            "--- Chunk 18156 ---\n",
            "Ridge Regression, 135 max_depth hyperparameter, 181\n",
            "RMSProp, 355 mean_squared_error function, 72\n",
            "\n",
            "--- Chunk 18157 ---\n",
            "814 | Index\n",
            "\n",
            "--- Chunk 18158 ---\n",
            "missing value handling, 63 sequences\n",
            "one-hot vectors, 67 forecasting time series, 503-511\n",
            "out-of-bag evaluation, 195 handling long, 511-523\n",
            "\n",
            "--- Chunk 18159 ---\n",
            "PCA using, 222 input and output, 501\n",
            "Perceptron class, 287 RNNS for, 497\n",
            "presorting data with, 180 Sequential API\n",
            "\n",
            "--- Chunk 18160 ---\n",
            "Randomized PCA algorithm, 225 image classifiers using, 297-307\n",
            "random_state hyperparameter, 185 regression MLP using, 307\n",
            "\n",
            "--- Chunk 18161 ---\n",
            "saving models, 75 service account, 682\n",
            "SGDClassifier class, 88 sets, 383, 787\n",
            "splitting datasets into subsets, 53 Shannon's information theory, 180\n",
            "\n",
            "--- Chunk 18162 ---\n",
            "stratified sampling using, 54 short-term memory problems, 514-523\n",
            "SVM classification classes, 162 shortcut connections, 471\n",
            "\n",
            "--- Chunk 18163 ---\n",
            "SVM models, 155 shrinkage, 205\n",
            "tolerance hyperparameter, 162 shuffling-buffer approach, 417\n",
            "\n",
            "--- Chunk 18164 ---\n",
            "transformation sequences, 70 sigmoid (Logistic) activation function, 143,\n",
            "transformers and, 68 293-294, 302, 332\n",
            "\n",
            "--- Chunk 18165 ---\n",
            "voting classifiers in, 191 sigmoid kernel, 171\n",
            "\n",
            "--- Chunk 18166 ---\n",
            "Scikit-Optimize, 322 silhouette coefficient, 246\n",
            "SE block, 476 silhouette diagram, 247\n",
            "SE-Inception, 476 silhouette score, 246\n",
            "\n",
            "--- Chunk 18167 ---\n",
            "SE-ResNet, 476 similarity functions, 159\n",
            "search engines, 238 simulated annealing, 125\n",
            "\n",
            "--- Chunk 18168 ---\n",
            "second-order partial derivatives (Hessians), 358 simulated environments, 614\n",
            "self-attention mechanism, 556 single-shot learning, 495\n",
            "\n",
            "--- Chunk 18169 ---\n",
            "self-normalization, 337 Singular Value Decomposition (SVD), 117, 221\n",
            "self-organizing maps (SOMs), 780 skewed datasets, 89\n",
            "\n",
            "--- Chunk 18170 ---\n",
            "self-supervised learning, 351 skip connections, 337, 471\n",
            "SELU (Scaled Exponential Linear Unit) func‐ Sklearn-Deap, 323\n",
            "\n",
            "--- Chunk 18171 ---\n",
            "tion (see Scaled Exponential Linear Unit slack variables, 167\n",
            "(SELU) function) smoothing term, 340\n",
            "\n",
            "--- Chunk 18172 ---\n",
            "semantic interpolation, 590 Soft Actor-Critic algorithm, 663\n",
            "semantic segmentation, 249, 458, 492 soft clustering, 240\n",
            "\n",
            "--- Chunk 18173 ---\n",
            "semi-supervised learning soft margin classification, 154\n",
            "\n",
            "--- Chunk 18174 ---\n",
            "clustering algorithms for, 237, 253 soft voting, 192\n",
            "defined, 13 softmax function, 148, 294, 299, 470, 482, 488,\n",
            "examples of, 13 543\n",
            "\n",
            "--- Chunk 18175 ---\n",
            "SENet (Squeeze-and-Excitation Network), 476 Softmax Regression, 148\n",
            "sensitivity, 91 softplus activation function, 293\n",
            "\n",
            "--- Chunk 18176 ---\n",
            "sentence encoders, 541 spam filters, 1, 2\n",
            "sentiment analysis spare replicas, 706\n",
            "\n",
            "--- Chunk 18177 ---\n",
            "defined, 526 sparse autoencoders, 582\n",
            "masking, 538 sparse matrix, 67\n",
            "overview of, 534 sparse models, 359\n",
            "\n",
            "--- Chunk 18178 ---\n",
            "reusing pretrained embeddings, 540 sparse tensors, 383, 785\n",
            "\n",
            "--- Chunk 18179 ---\n",
            "separable convolution, 474 sparsity, 582\n",
            "sequence-to-sequence models, 510 sparsity loss, 583\n",
            "sequence-to-vector networks, 501 Spearmint library, 322\n",
            "\n",
            "--- Chunk 18180 ---\n",
            "SequenceExample protobuf (TensorFlow), 429 spectral clustering, 259\n",
            "\n",
            "--- Chunk 18181 ---\n",
            "Index | 815\n",
            "\n",
            "\n",
            "\n",
            "spurious patterns, 774 kernelized SVM, 169\n",
            "stacked autoencoders linear SVM classification, 153\n",
            "\n",
            "--- Chunk 18182 ---\n",
            "overview of, 572 nonlinear SVM classification, 157-162\n",
            "stacked denoising autoencoders, 581 online SVMs, 172\n",
            "\n",
            "--- Chunk 18183 ---\n",
            "unsupervised pretraining using, 576-579 SVM regression, 162\n",
            "using Keras, 572 training objective, 166\n",
            "\n",
            "--- Chunk 18184 ---\n",
            "visualizing Fashion MNIST Dataset, 574 support vectors, 154\n",
            "visualizing reconstructions, 574 symbolic differentiation, 768\n",
            "\n",
            "--- Chunk 18185 ---\n",
            "stacked denoising autoencoders, 581 symbolic tensors, 408, 792\n",
            "stacked generalization, 208 symmetry, breaking in backpropagation, 291\n",
            "\n",
            "--- Chunk 18186 ---\n",
            "stacking, 208 synchronous updates, 706\n",
            "stale gradients, 707\n",
            "standard correlation coefficient, 58 T\n",
            "\n",
            "--- Chunk 18187 ---\n",
            "standardization, 69 t-Distributed Stochastic Neighbor Embedding\n",
            "start of sequence (SoS) token, 535 (t-SNE), 233\n",
            "\n",
            "--- Chunk 18188 ---\n",
            "state-action values, 628 tail-heavy histograms, 51\n",
            "stateful metrics, 389 Talos library, 322\n",
            "stationary point, 761 target model, 639\n",
            "\n",
            "--- Chunk 18189 ---\n",
            "statistical mode, 193 TD error, 630\n",
            "statistical significance, 182 TD target, 630\n",
            "step function, 284 temperature\n",
            "\n",
            "--- Chunk 18190 ---\n",
            "Stochastic Gradient Boosting, 207 in Boltzmann machines, 775\n",
            "Stochastic Gradient Descent (SGD), 88, 124 in text generation, 531\n",
            "\n",
            "--- Chunk 18191 ---\n",
            "stochastic neurons, 775 Temporal Difference Learning (TD Learning),\n",
            "stochastic policy, 612 629\n",
            "stratified sampling, 53 tensor arrays, 383, 786\n",
            "\n",
            "--- Chunk 18192 ---\n",
            "streaming metrics, 389 TensorBoard, 317\n",
            "stride, 449 TensorFlow Addons, 545\n",
            "string kernels, 161 TensorFlow cluster, 711\n",
            "\n",
            "--- Chunk 18193 ---\n",
            "string subsequence kernel, 161 TensorFlow Extended (TFX), 440\n",
            "string tensors, 383, 783 TensorFlow Hub, 378, 540\n",
            "\n",
            "--- Chunk 18194 ---\n",
            "strong learners, 190 TensorFlow Lite, 378\n",
            "style mixing, 606 TensorFlow Model Optimization Toolkit (TF-\n",
            "style transfer, 604 MOT), 359\n",
            "\n",
            "--- Chunk 18195 ---\n",
            "StyleGANs, 567, 604 TensorFlow Playground, 295\n",
            "Subclassing API, 313 TensorFlow, basics of\n",
            "subderivatives, 173 architecture, 377\n",
            "\n",
            "--- Chunk 18196 ---\n",
            "subgradient vector, 140 benefits, xvi, 376\n",
            "subsampling, 456 community support, 379\n",
            "subspace, 215 features, 376\n",
            "\n",
            "--- Chunk 18197 ---\n",
            "summaries (TensorFlow), 317 getting help, 379\n",
            "supervised learning installing, 296\n",
            "\n",
            "--- Chunk 18198 ---\n",
            "algorithms covered, 9 library ecosystem, 378\n",
            "common tasks, 8 operating system compatibility, 378\n",
            "defined, 8 PyTorch library and, 296\n",
            "\n",
            "--- Chunk 18199 ---\n",
            "Support Vector Machines (SVMs) versions covered, 375\n",
            "benefits of, 153 TensorFlow, CNNs\n",
            "\n",
            "--- Chunk 18200 ---\n",
            "decision function and prediction, 165 convolution operations, 494\n",
            "dual problem, 168, 761 convolutional layers, 453\n",
            "\n",
            "--- Chunk 18201 ---\n",
            "816 | Index\n",
            "\n",
            "\n",
            "\n",
            "pooling layer, 458 testing and validation\n",
            "TensorFlow, custom models and training data mismatch, 32\n",
            "\n",
            "--- Chunk 18202 ---\n",
            "about, 375 hyperparameter tuning, 31\n",
            "activation functions, initializers, regulariz‐ model selection, 31\n",
            "\n",
            "--- Chunk 18203 ---\n",
            "ers, and constraints, 387 text generation\n",
            "computing gradients using Autodiff, 399, building and training models for, 530\n",
            "\n",
            "--- Chunk 18204 ---\n",
            "765-772 chopping sequential datasets, 528\n",
            "implementing learning rate scheduling, 363 generating Shakespearean text, 531\n",
            "layers, 391 overview of, 526\n",
            "\n",
            "--- Chunk 18205 ---\n",
            "loss functions, 384 splitting sequential datasets, 527\n",
            "losses and metrics, 397 stateful RNNs and, 532\n",
            "metrics, 388 training dataset creation, 527\n",
            "\n",
            "--- Chunk 18206 ---\n",
            "models, 394 using models for, 531\n",
            "saving and loading, 385 TF Datasets (TFDS), 414, 441\n",
            "special data structures, 783-789 TF Functions\n",
            "\n",
            "--- Chunk 18207 ---\n",
            "training loops, 402 graphs generated by, 791-799\n",
            "\n",
            "--- Chunk 18208 ---\n",
            "TensorFlow, data loading and preprocessing rules, 409\n",
            "Data API, 414-424 TF Transform (tf.Transform), 414, 439\n",
            "overview of, 413 TF-Agents library\n",
            "\n",
            "--- Chunk 18209 ---\n",
            "preprocessing input features, 430-439 collect driver, 656\n",
            "TensorFlow Datasets (TFDS) Project, 441, datasets, 658\n",
            "\n",
            "--- Chunk 18210 ---\n",
            "441 deep Q-networks (DQNs), 650\n",
            "TF Transform, 439 DQN agents, 652\n",
            "TFRecord format, 424-430 environment specifications, 644\n",
            "\n",
            "--- Chunk 18211 ---\n",
            "TensorFlow, functions and graphs environment wrappers, 645\n",
            "AutoGraph and tracing, 407, 791-799 environments, 643\n",
            "overview of, 405 installing, 643\n",
            "\n",
            "--- Chunk 18212 ---\n",
            "TF Function rules, 409 overview of, 642\n",
            "\n",
            "--- Chunk 18213 ---\n",
            "TensorFlow, model deployment at scale replay buffer and observer, 654\n",
            "deploying on AI platforms, 81 training architecture, 649\n",
            "\n",
            "--- Chunk 18214 ---\n",
            "deploying to mobile and embedded devices, training loops, 661\n",
            "\n",
            "--- Chunk 18215 ---\n",
            "685-688 training metrics, 655\n",
            "overview of, 667 tf.keras, 295, 363, 363, 423\n",
            "serving TensorFlow models, 668-685 tf.summary package, 319\n",
            "\n",
            "--- Chunk 18216 ---\n",
            "training models across multiple devices, TF.Text library, 536\n",
            "\n",
            "--- Chunk 18217 ---\n",
            "701-717 TFRecord format\n",
            "using GPUs to speed computations, 689-701 compressed TFRecord files, 425\n",
            "\n",
            "--- Chunk 18218 ---\n",
            "TensorFlow, NumPy-like operations lists of lists using SequenceExample Proto‐\n",
            "other data structures, 383 buf, 429\n",
            "\n",
            "--- Chunk 18219 ---\n",
            "tensors and NumPy, 381 loading and parsing examples, 428\n",
            "tensors and operations, 379 overview of, 424\n",
            "\n",
            "--- Chunk 18220 ---\n",
            "type conversions, 381 protocol buffers (protobufs), 425\n",
            "variables, 382 TensorFlow protobufs, 427\n",
            "\n",
            "--- Chunk 18221 ---\n",
            "TensorFlow.js, 378 Theano, 295\n",
            "tensors, 379 theoretical information criterion, 267\n",
            "Term-Frequency × Inverse-Document- thermal equilibrium, 775\n",
            "\n",
            "--- Chunk 18222 ---\n",
            "Frequency (TF-IDF), 439 threshold logic unit (TLU), 284\n",
            "terminal state, 626 Tikhonov regularization, 135\n",
            "test sets, 30, 51 time series data\n",
            "\n",
            "--- Chunk 18223 ---\n",
            "Index | 817\n",
            "\n",
            "--- Chunk 18224 ---\n",
            "additional models for, 506 true negative rate (TNR), 97\n",
            "baseline metrics, 505 true positive rate (TPR), 91\n",
            "\n",
            "--- Chunk 18225 ---\n",
            "deep RNNS, 506 truncated backpropagation through time, 529\n",
            "forecasting several steps ahead, 508 Turing test, 525\n",
            "overview of, 503 tying weights, 577\n",
            "\n",
            "--- Chunk 18226 ---\n",
            "RNNS for, 497 type conversions, 381\n",
            "simple RNNs, 505\n",
            "\n",
            "--- Chunk 18227 ---\n",
            "time step, 498 U\n",
            "tokenization, 536 uncertainty sampling, 255\n",
            "tolerance, 123 undercomplete autoencoders, 570\n",
            "\n",
            "--- Chunk 18228 ---\n",
            "TPUs (tensor processing units), 377 underfitting, 29\n",
            "train-dev sets, 32 undiscounted rewards, 656\n",
            "training data univariate regression problems, 39\n",
            "\n",
            "--- Chunk 18229 ---\n",
            "defined, 2 univariate time series, 503\n",
            "hold outs, 31 unrolling the network through time, 498\n",
            "\n",
            "--- Chunk 18230 ---\n",
            "insufficient quantity of, 23 unstable gradients problem, 512\n",
            "irrelevant features, 27 unsupervised learning\n",
            "\n",
            "--- Chunk 18231 ---\n",
            "nonrepresentative, 25 algorithms covered, 10\n",
            "overfitting, 27 clustering, 236-260\n",
            "poor quality, 26 common tasks, 10\n",
            "\n",
            "--- Chunk 18232 ---\n",
            "training dataset creation, 527 defined, 9\n",
            "underfitting, 29 Gaussian mixtures model (GMM), 260-275\n",
            "\n",
            "--- Chunk 18233 ---\n",
            "training instances, 2, 215 overview of, 235\n",
            "training models pretraining using stacked autoencoders,\n",
            "\n",
            "--- Chunk 18234 ---\n",
            "defined, 20 576-579\n",
            "example project, 72 unsupervised pretraining, 349\n",
            "Gradient Descent, 118-128 upsampling layer, 493\n",
            "\n",
            "--- Chunk 18235 ---\n",
            "learning curves, 130-134 utility functions, 20\n",
            "Linear Regression, 112-117\n",
            "Logistic Regression, 142-151\n",
            "overview of, 111 V\n",
            "\n",
            "--- Chunk 18236 ---\n",
            "overview of, 111 V\n",
            "Polynomial Regression, 128-130 validation sets, 31\n",
            "regularized linear models, 134-142 Value Iteration algorithm, 627\n",
            "\n",
            "--- Chunk 18237 ---\n",
            "training samples, 2 vanishing/exploding gradients problems,\n",
            "training set rotation, 185 332-345\n",
            "training sets, 2, 30, 213 variables, 382\n",
            "\n",
            "--- Chunk 18238 ---\n",
            "training/serving skew, 440 variance\n",
            "trajectories, 649 explained variance ratio, 222\n",
            "trajectory, 650 preserving, 219\n",
            "\n",
            "--- Chunk 18239 ---\n",
            "transfer learning, 324, 345, 481 variational autoencoders, 586-591\n",
            "transformations variational inference, 272\n",
            "\n",
            "--- Chunk 18240 ---\n",
            "affine transformations, 604 variational parameters, 272\n",
            "chaining, 415 vector-to-sequence networks, 501\n",
            "custom, 68 vectors\n",
            "\n",
            "--- Chunk 18241 ---\n",
            "custom, 68 vectors\n",
            "inverse transformation, 225 column vectors, 113\n",
            "purpose of, 64 feature vectors, 113\n",
            "\n",
            "--- Chunk 18242 ---\n",
            "transformation pipelines, 70 momentum vector, 352\n",
            "\n",
            "--- Chunk 18243 ---\n",
            "Transformer architecture, 554 parameter vectors, 113\n",
            "transposed convolutional layer, 493 subgradient vectors, 140\n",
            "\n",
            "VGGNet, 470\n",
            "\n",
            "818 | Index\n",
            "\n",
            "--- Chunk 18244 ---\n",
            "virtual GPU devices, 695 word tokenization, 536\n",
            "visible units, 775 WordTrees, 490\n",
            "visual attention, 552 workspace creation, 42\n",
            "\n",
            "--- Chunk 18245 ---\n",
            "visualization algorithms, 11\n",
            "vocabulary, 432 X\n",
            "voice recognition, 445 Xavier initialization, 333\n",
            "\n",
            "--- Chunk 18246 ---\n",
            "Xception (Extreme Inception), 474\n",
            "W XGBoost, 208\n",
            "wall time, 341\n",
            "warmup phase, 708 Y\n",
            "WaveNet, 498, 521 You Only Look Once (YOLO), 489\n",
            "\n",
            "--- Chunk 18247 ---\n",
            "weak learners, 190\n",
            "weighted moving average model, 506\n",
            "white box models, 178 Z\n",
            "Wide & Deep neural networks, 308 zero padding, 449\n",
            "\n",
            "--- Chunk 18248 ---\n",
            "wisdom of the crowd, 189 zero-shot learning (ZSL), 564\n",
            "word embeddings, 434 ZF Net, 466\n",
            "\n",
            "--- Chunk 18249 ---\n",
            "Index | 819\n",
            "\n",
            "--- Chunk 18250 ---\n",
            "About the Author\n",
            "Aurélien Géron is a Machine Learning consultant and lecturer. A former Googler, he\n",
            "\n",
            "--- Chunk 18251 ---\n",
            "led YouTube’s video classification team from 2013 to 2016. He’s been a founder of and\n",
            "\n",
            "--- Chunk 18252 ---\n",
            "CTO at a few different companies: Wifirst, a leading wireless ISP in France; Polycon‐\n",
            "\n",
            "--- Chunk 18253 ---\n",
            "seil, a consulting firm focused on telecoms, media, and strategy; and Kiwisoft, a con‐\n",
            "sulting firm focused on Machine Learning and data privacy.\n",
            "\n",
            "--- Chunk 18254 ---\n",
            "Before all that he worked as an engineer in a variety of domains: finance (JP Morgan\n",
            "\n",
            "--- Chunk 18255 ---\n",
            "and Société Générale), defense (Canada’s DOD), and healthcare (blood transfusion).\n",
            "\n",
            "--- Chunk 18256 ---\n",
            "He also published a few technical books (on C++, WiFi, and internet architectures)\n",
            "\n",
            "--- Chunk 18257 ---\n",
            "and lectured about computer science at a French engineering school.\n",
            "\n",
            "--- Chunk 18258 ---\n",
            "A few fun facts: he taught his three children to count in binary with their fingers (up\n",
            "\n",
            "--- Chunk 18259 ---\n",
            "to 1,023), he studied microbiology and evolutionary genetics before going into soft‐\n",
            "\n",
            "--- Chunk 18260 ---\n",
            "ware engineering, and his parachute didn’t open on the second jump.\n",
            "\n",
            "--- Chunk 18261 ---\n",
            "Colophon\n",
            "The animal on the cover of Hands-On Machine Learning with Scikit-Learn, Keras, and\n",
            "\n",
            "--- Chunk 18262 ---\n",
            "TensorFlow is the fire salamander (Salamandra salamandra), an amphibian found\n",
            "\n",
            "--- Chunk 18263 ---\n",
            "across most of Europe. Its black, glossy skin features large yellow spots on the head\n",
            "\n",
            "--- Chunk 18264 ---\n",
            "and back, signaling the presence of alkaloid toxins. This is a possible source of this\n",
            "\n",
            "--- Chunk 18265 ---\n",
            "amphibian’s common name: contact with these toxins (which they can also spray\n",
            "\n",
            "--- Chunk 18266 ---\n",
            "short distances) causes convulsions and hyperventilation. Either the painful poisons\n",
            "\n",
            "--- Chunk 18267 ---\n",
            "or the moistness of the salamander’s skin (or both) led to a misguided belief that these\n",
            "\n",
            "--- Chunk 18268 ---\n",
            "creatures not only could survive being placed in fire but could extinguish it as well.\n",
            "\n",
            "--- Chunk 18269 ---\n",
            "Fire salamanders live in shaded forests, hiding in moist crevices and under logs near\n",
            "\n",
            "--- Chunk 18270 ---\n",
            "the pools or other freshwater bodies that facilitate their breeding. Though they spend\n",
            "\n",
            "--- Chunk 18271 ---\n",
            "most of their lives on land, they give birth to their young in water. They subsist\n",
            "\n",
            "--- Chunk 18272 ---\n",
            "mostly on a diet of insects, spiders, slugs, and worms. Fire salamanders can grow up\n",
            "\n",
            "--- Chunk 18273 ---\n",
            "to a foot in length, and in captivity may live as long as 50 years.\n",
            "\n",
            "--- Chunk 18274 ---\n",
            "The fire salamander’s numbers have been reduced by destruction of their forest habi‐\n",
            "\n",
            "--- Chunk 18275 ---\n",
            "tat and capture for the pet trade, but the greatest threat they face is the susceptibility\n",
            "\n",
            "--- Chunk 18276 ---\n",
            "of their moisture-permeable skin to pollutants and microbes. Since 2014, they have\n",
            "\n",
            "--- Chunk 18277 ---\n",
            "become extinct in parts of the Netherlands and Belgium due to an introduced fungus.\n",
            "\n",
            "--- Chunk 18278 ---\n",
            "Many of the animals on O’Reilly covers are endangered; all of them are important to\n",
            "\n",
            "--- Chunk 18279 ---\n",
            "the world. The cover illustration is by Karen Montgomery, based on an engraving\n",
            "\n",
            "--- Chunk 18280 ---\n",
            "from Wood’s Illustrated Natural History. The cover fonts are URW Typewriter and\n",
            "\n",
            "--- Chunk 18281 ---\n",
            "Guardian Sans. The text font is Adobe Minion Pro; the heading font is Adobe Myriad\n",
            "Condensed; and the code font is Dalton Maag’s Ubuntu Mono.\n",
            "\n",
            "--- Chunk 18282 ---\n",
            "There’s much more  \n",
            "where this came from.\n",
            "Experience books, videos, live online  \n",
            "training courses, and more from O’Reilly\n",
            "\n",
            "--- Chunk 18283 ---\n",
            "and our 200+ partners—all in one place.\n",
            "\n",
            "--- Chunk 18284 ---\n",
            "Learn more at oreilly.com/online-learning\n",
            "\n",
            "©2019 O’Reilly Media, Inc. O’Reilly is a registered trademark of O’Reilly Media, Inc. | 175\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Embeddings\n",
        "# now we turn those text chunks into vectors we use a popular lightweight sentence transformer model.its brillient the understanding meaning of sentence"
      ],
      "metadata": {
        "id": "CV_vDRcqM1Q7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "# 1. Load the embedding model\n",
        "# 'all-MiniLM-L6-v2' is a fantastic, fast, and small model.\n",
        "# It runs 100% on your local machine.\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "#  2. Embed all our chunks\n",
        "# This will take a moment as it \"reads\" and \"understands\" each chunk.\n",
        "chunk_embeddings = model.encode(chunks)\n",
        "\n",
        "print(f\"Shape of our embeddings: {chunk_embeddings.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699,
          "referenced_widgets": [
            "5d12ff2c6a9e43e795b2d5fa9b39ec1d",
            "85b6ab180ed34cf28c7f832c929677ae",
            "d75303f81bae4822a2f4905f16fa39a4",
            "736b5b6f5a774d9ea16a5b9f734120bc",
            "a2119b76098042f984a9b17a492476ca",
            "eca30074e63d4c14b16c598138265ad7",
            "dcaf5935469c491dba454de3c30190cf",
            "85e27a322dd5420a84125fbdf1b990fb",
            "038aed1f48b74b948b024eef10985b0d",
            "908c961d6dc1453f8a1b08a5f3f884cd",
            "19ef46162f594764b017b91888d8e945",
            "15070fcef87a4b328e38662ea0cb6ee1",
            "03ec9add99734690a777bc157f91ede9",
            "52d43372a5274c32b831288c63bf08be",
            "7af0c7277af7455e80b05ba6f9dad42e",
            "de596fa468a5449bb3c5eab1668d1d1e",
            "b707c085167f4107bbe45b736aa2c036",
            "e5b8939f7d2942338b7dc011e275d062",
            "d2691def85a940b4a9a6df6447a62d4e",
            "bcec439cc5894c39ac917033182d10aa",
            "b9865dcccb0246c4ab7a852af516a80c",
            "ee04b141710a4155bca570e06ef5175c",
            "fbdae9fae1734b9dbc91703f85d88a07",
            "36d713d77dd74675bf0f5e1fa4ec9f80",
            "f94996fb025046b680181108a6ccae3b",
            "f97c6ffa6f294cbd8cb2c44f21f64537",
            "9c21a02730ba4c19aa4fb89e3fe5fe3c",
            "c2a83400aa6643ab8bbbbfb4e34d0e0e",
            "7e00a1423e39449391d081a4e9192a4e",
            "0a3bf6dedac541ca905478006ee7378c",
            "a307508177784465aa4b5028d4696876",
            "512f37d2e10244fdb89c0520b2126c54",
            "acd7d19bf2204d83ae8fd77b74d79268",
            "5dd424a9a97b4df1ba11836b30751100",
            "2b7b57bfb8d84ceba8d7176b82fae5a9",
            "555fe4d137cd4ef3b2fdf8949b931d26",
            "05f3103539844f6f932cde7221005546",
            "b8e50fcf31f7443bbcdd80b2e1bfc88b",
            "6ce64650708a4508b42c1cff11460b84",
            "ac8f19ce088d46cb987b0a24623f8e9c",
            "9791e33c671545a3906858f47ecd347e",
            "3029b0217cfb48bdafa781908d242fb8",
            "f5cdd396a5d147c696d6ed153696d27f",
            "129ea6797a4043189cfaa998572ed9fc",
            "83b51d613f6c48d6b5191c050865a132",
            "2c235392a6b5440997b3fdea6feb2bf8",
            "33b1434e2de94a58907674f4fa1237ae",
            "21a1d95091454037832aeb30235b439d",
            "e6200c99d3694788a0af04cb5c8b7477",
            "6ad5f69120be4dd687a92bf776b519ab",
            "f3dd7a53a8c348018ccad5d707d17057",
            "aa2069b88d874ffdb0c1c0bede3a6713",
            "aef15b74d3aa4374938f13bd03fda9a1",
            "abe39049655a4fec86164437fa4e89b1",
            "e05de0a631aa411c80c7272e631dcd5c",
            "d4487e2b9e704c68908ce2cee2711822",
            "f35c67ca912e4729a228b48e88b89934",
            "496003d8161a4188b35cb3998ad092f7",
            "d6a949fd8c98429cb44fedcae615b386",
            "3efc44491151457eaaa4630b030f752c",
            "a233c051baa04092a0f53578b32156fb",
            "804164cf17634537a67c4039609b932f",
            "1bf4398ea76c40e9854bf34463fba8ee",
            "b7828c0c759c4f78872c32976df86507",
            "f0bf0ef61ec645af8059e0a51ecc0913",
            "ade7aaa511a34626b0468f852c38eeea",
            "c682d54ed1144b6faaef92484c21d0a4",
            "6e4516fd26f14c2da43c5e908f52d8f5",
            "b6699227c51342d08dd9b85cb886b171",
            "d3513b2cb5ff4514991aa30f4a8f3f31",
            "02f5a56b5a944633aed50d5d82b518a3",
            "a92a57b90c554bcaa5465578381bded3",
            "4375ba8b644d4ef991617f8947273546",
            "28348b6b98c346789edbd62eb020c148",
            "06c5a3d212344dd69b0ee58d70dbcac4",
            "ea6246c14763490d9671f32d0354f970",
            "e0f0cedeba58456785204b4eff6100b2",
            "1c54cadd70a24beabd2acb048fc970c3",
            "e7e1dce0cd3e43ed9dacf7468c7e9b46",
            "25b77992ebf247e682172df2567aef71",
            "2ccf9b6bd74e441984aad0e82bec4c5c",
            "c8c492ca13c84b159438106a66d4b092",
            "cd704bfa269c43ee808ecf911b5b6e0a",
            "71812c830ec24d1e8d3028eee78694c8",
            "fd8e18f48fab49feafe602beb919aec9",
            "c11f2d66218f4e7eb3df6db37f7f94fd",
            "9b52a7872560482695c929ddf889d3d8",
            "969d5c6a4d694999989bc17003c5f7dd",
            "1ee901c530cc4a0bb3f0f8b78c947f05",
            "7d1c387e6dc246cfae29ce88be761c32",
            "805a3495d8af46788e9b692651508e2c",
            "57991fa73ce949198a8af3cbf9cac34b",
            "e211fd99961245b5997665d7b1f57b77",
            "c7529beebedc4372af65d04a32f0d6cf",
            "7cbf74340b8b428fafa46135c68f98f0",
            "644e4e732cfd4448aa5d9eb527f5ac08",
            "71ad05d3a64d4e37b347869ac90b25c3",
            "b3d0ae1a5152438e82e5294b584f2c33",
            "31f017a09add4373a58e024090358fc8",
            "1a7047c35b0648bebb3e1446156a5134",
            "4543f887df544272b6831fc1ffecbea6",
            "0539916615e14eea837e9b70487e77d0",
            "0bbccf87b8c94cfdb5d602dba73fa536",
            "6820e262772c4b539008b79b31ccb38c",
            "61d64cb7741048b0885167fc28adc9e6",
            "64cfcc2e378549aba5abbe9e47769ce2",
            "348c3eb263664464a3e66eb5b8b00ce1",
            "aa0daa80cee641048d80c90d2de28ca3",
            "2166a41190e342ff80d7ed65c09e1e1a",
            "a86ac762603541b39d54c82d28e08f99",
            "55316840b7174199b8ad75a64d80f794",
            "b37bdf2a0f254b068234c0739c6017d9",
            "ba20d46f594641bcac6027c0cc643a24",
            "841910e93e6142cbafeb64ff95fe5f6e",
            "90b27b30fd684d7da7b58d0dbb1b94fb",
            "f77723abe2bd46b08dca858dc3185370",
            "8053fe4a369f4d218c67513042f5a676",
            "e329fd4471a64e60b39df88cb1862250",
            "88b2804de7f049fbae418fb721a27aed",
            "1698e7446a614f6cad9ce1b467d23f39",
            "6927bc77e3734b0581ed1be81e16d8f6",
            "7511a42e18ed4992994cf19a3bfd382b",
            "5aa1cb6fea454dda955765098e398a71",
            "18914457124a40929fe52e1a6a67a216",
            "a7127d2d7f4d409a870ccaa2e313011b",
            "4a8ff325c3fa4e9898d0f65957e5f1f3",
            "0c0898baf1974001bd92c0bdb0fd5d9e",
            "fc83ea9753564da0ae18424f843a0ce5",
            "7c4c04267db5466ab9e2c416ec6461e5",
            "7a98528fcde144ec8ee8322ad5e19270",
            "224e77ffe68f49d5abc219c9c86d2122",
            "aef4a1df4b3e43bf8c51db3d0e6c1694"
          ]
        },
        "id": "YSwMzlZHNitM",
        "outputId": "bf0b28d4-0f9f-46e3-ab6e-fb9cba10906c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d12ff2c6a9e43e795b2d5fa9b39ec1d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15070fcef87a4b328e38662ea0cb6ee1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbdae9fae1734b9dbc91703f85d88a07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5dd424a9a97b4df1ba11836b30751100"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83b51d613f6c48d6b5191c050865a132"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4487e2b9e704c68908ce2cee2711822"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c682d54ed1144b6faaef92484c21d0a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c54cadd70a24beabd2acb048fc970c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ee901c530cc4a0bb3f0f8b78c947f05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a7047c35b0648bebb3e1446156a5134"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55316840b7174199b8ad75a64d80f794"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7511a42e18ed4992994cf19a3bfd382b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of our embeddings: (18284, 384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  vector store with FAISS\n",
        "# we have our vector.now we need a database to store them in a way we can search by similarity.it is where faiss comes .its just few lines of code"
      ],
      "metadata": {
        "id": "pOBmhs82NxbS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "vHF-EtTNQEYq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the dimension of our vector\n",
        "d = chunk_embeddings.shape[1]\n",
        "\n"
      ],
      "metadata": {
        "id": "e0IFbJnBQObZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  create the FAISS index\n",
        "# indexFlatl2 is the simplest most basic index it calculates the exact distance(L2 distance )between our quary and vector.\n",
        "index=faiss.IndexFlatL2(d)\n",
        "#  add our chunk into embeddings to the index\n",
        "# we must convert float32 into FAISS\n",
        "index.add(np.array(chunk_embeddings).astype(np.float32))"
      ],
      "metadata": {
        "id": "HIbGJta8QtjA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"FAISS index created  with {index.ntotal} vectors\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XML2QyQR7g5",
        "outputId": "1c696783-e69a-4807-9d1b-6a43f5f1b9bb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index created  with 18284 vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 5 retrieve,Augment,generate (RAG)\n",
        "# this is a final part here will user ask aquestion."
      ],
      "metadata": {
        "id": "PMI4vZlFST1f"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Load the tokenizer and model for flan-t5-small\n",
        "tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-small')\n",
        "model_generator = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-small')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "eb49c31b4f4147738b2d0ffaa8689776",
            "fca5917cfa7b42068e3db7b9c0ff425d",
            "106662407263469bafaa3f8408e79930",
            "f869c8cf84e745f0969e789b338efd17",
            "7df8dff2403c401a991cebd85ef95323",
            "801a49b29a1c4010a6b6b7b9a0b4e5c6",
            "95d2c11892054f578c44617c97c3397f",
            "ad1227f079dc4320b59e9b9a8260379b",
            "4098167b0da243dc91ae0348e90629c8",
            "a9cd28ac4145465887a4ecfaa6606841",
            "34c4a46ae5d04a7cb357dd58f096378c"
          ]
        },
        "id": "EnZozR5hS05_",
        "outputId": "d07d84b8-f5a8-48ee-eba6-907d1ee0f323"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/190 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb49c31b4f4147738b2d0ffaa8689776"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tied weights mapping and config for this model specifies to tie shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is our RAG pieline function"
      ],
      "metadata": {
        "id": "DLSFPOIpT3ZR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(quary):\n",
        "  # RETRIEVE\n",
        "  # embedd the user quary\n",
        "  quary_embedding=model.encode([quary]).astype('float32')\n",
        "  # Search the faiss index into top (e.g,k=2) most similar chunk\n",
        "  k=2\n",
        "  distance,indices=index.search(quary_embedding,k)\n",
        "  # get the actual text chunk from our original chunk list\n",
        "  retrieved_chunks=[chunks[i] for i in indices[0]]\n",
        "  context=\"\\n\\n.\".join(retrieved_chunks)\n",
        "  # 2 Augment\n",
        "  # this is the magic propmt we combined the retrieved chunks with the uers quary\n",
        "  prompt_template= f\"\"\"\n",
        "  answer the following question using only the provided context.\n",
        "  if the answer is not in the context,say \\\"i don't have any information\\\"\n",
        "\n",
        "  Context:\n",
        "  {context}\n",
        "\n",
        "  Question:\n",
        "  {quary}\n",
        "  Answer:\n",
        "  \"\"\"\n",
        "  # 3 Generate\n",
        "  # Encode the prompt\n",
        "  input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids\n",
        "\n",
        "  # Generate output\n",
        "  outputs = model_generator.generate(input_ids, max_new_tokens=100, do_sample=False)\n",
        "  answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "  print(f\"---CONTEXT----\\n{context}\\n\")\n",
        "  return answer"
      ],
      "metadata": {
        "id": "moGxEvTtTlKY"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uvJCnOyBZTVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "new_cell_1",
        "outputId": "6ad555ca-f014-4400-9664-9bc59ee1f345"
      },
      "source": [
        "# Example usage of the answer_question function\n",
        "question_to_ask = \"What is machine learning?\"\n",
        "response = answer_question(question_to_ask)\n",
        "print(f\"\\n---GENERATED ANSWER---\\n{response}\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Passing `generation_config` together with generation-related arguments=({'max_length'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---CONTEXT----\n",
            "What Is Machine Learning?                                                                                           2\n",
            "\n",
            ".What Is Machine Learning?\n",
            "Machine Learning is the science (and art) of programming computers so they can\n",
            "learn from data.\n",
            "\n",
            "\n",
            "---GENERATED ANSWER---\n",
            "\n",
            "  answer the following question using only the provided context.\n",
            "  if the answer is not in the context,say \" i dont have any information\n",
            "\n",
            "  Context:\n",
            "  What Is Machine Learning?                                                                                           2\n",
            "\n",
            ".What Is Machine Learning?\n",
            "Machine Learning is the science (and art) of programming computers so they can\n",
            "learn from data.\n",
            "\n",
            "  Question:\n",
            "  What is machine learning?\n",
            "  Answer:\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4c388fa",
        "outputId": "23f94aeb-31ea-4ee3-e007-6c6bc14b94ae"
      },
      "source": [
        "# Example usage of the answer_question function\n",
        "question_to_ask = \"What is machine learning?\"\n",
        "response = answer_question(question_to_ask)\n",
        "print(f\"\\n---GENERATED ANSWER---\\n{response}\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---CONTEXT----\n",
            "What Is Machine Learning?                                                                                           2\n",
            "\n",
            ".What Is Machine Learning?\n",
            "Machine Learning is the science (and art) of programming computers so they can\n",
            "learn from data.\n",
            "\n",
            "\n",
            "---GENERATED ANSWER---\n",
            "the science (and art) of programming computers so they can learn from data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f927551",
        "outputId": "30764fee-9c9d-489f-da0c-eb90a0cdf8be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Hello! I am a chatbot based on your document. Ask me anything about it!\")\n",
        "print(\"Type 'exit' or 'quit' to end the conversation.\")\n",
        "\n",
        "while True:\n",
        "    user_question = input(\"\\nYour Question: \")\n",
        "    if user_question.lower() in ['exit', 'quit']:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    response = answer_question(user_question)\n",
        "    print(f\"\\nChatbot: {response}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I am a chatbot based on your document. Ask me anything about it!\n",
            "Type 'exit' or 'quit' to end the conversation.\n",
            "\n",
            "Your Question: what is machine learning\n",
            "---CONTEXT----\n",
            "What Is Machine Learning?                                                                                           2\n",
            "\n",
            ".What Is Machine Learning?\n",
            "Machine Learning is the science (and art) of programming computers so they can\n",
            "learn from data.\n",
            "\n",
            "\n",
            "Chatbot: the science (and art) of programming computers so they can learn from data\n",
            "\n",
            "Your Question: what is LLM\n",
            "---CONTEXT----\n",
            "lem is to use Principal Component Analysis (see Chapter 8), which often results in a\n",
            "better orientation of the training data.\n",
            "\n",
            ".m is the number of training instances and n is the number of features); see Table 4-1.\n",
            "\n",
            "\n",
            "Chatbot: a training data\n",
            "\n",
            "Your Question: what is large language model\n",
            "---CONTEXT----\n",
            "language models, 563 (see also natural language 429\n",
            "\n",
            ".Recent Innovations in Language Models                                                                 563\n",
            "\n",
            "\n",
            "Chatbot: natural language\n",
            "\n",
            "Your Question: explain the regression model\n",
            "---CONTEXT----\n",
            "OK, that’s the Linear Regression model—but how do we train it? Well, recall that\n",
            "\n",
            ".of a regression model is the Root Mean Square Error (RMSE) (Equation 2-1). There‐\n",
            "\n",
            "\n",
            "Chatbot: i don't have any information\n"
          ]
        }
      ]
    }
  ]
}