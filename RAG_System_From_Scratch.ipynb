{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivaprajapati34390-netizen/ML-project/blob/main/RAG_System_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTenZltMVQjp",
        "outputId": "7c46bae2-22ad-4967-c240-a24a20cf9f9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.0.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.3)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.10)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-text-splitters\n",
            "  Downloading langchain_text_splitters-1.1.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.24.3)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.24.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.10.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.10 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.15)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.47)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.4)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.13.1)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.7.6)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.3.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (1.33)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (0.14.1)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (1.0.8)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (0.3.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (3.6.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (0.24.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.10->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.8->langchain) (1.12.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (8.3.1)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (0.0.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (0.1.2)\n",
            "Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.1-py3-none-any.whl (35 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, faiss-cpu, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 faiss-cpu-1.13.2 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-text-splitters-1.1.1 marshmallow-3.26.2 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers sentence-transformers faiss-cpu langchain langchain-community langchain-text-splitters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# This will open a file picker dialog to upload files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "uyeSoluz5daJ",
        "outputId": "7f015476-c260-477e-d1a8-953ddc51dbfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-683607f7-c6c8-4096-96e3-f374c5efdbb4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-683607f7-c6c8-4096-96e3-f374c5efdbb4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving machine.txt to machine (1).txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ku2bB8RPMUTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "XOmZMEXEcX8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Initialize the Text Splitter\n",
        "# This splitter is smart. It tries to split on paragraphs (\"\\n\\n\"),\n",
        "# then newlines (\"\\n\"), then spaces (\" \"), to keep semantically\n",
        "# related text together as much as possible.\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=150,  # Max size of a chunk\n",
        "    chunk_overlap=20, # Overlap to maintain context between chunks\n",
        "    length_function=len\n",
        ")"
      ],
      "metadata": {
        "id": "LFC5V3QJjQs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create the chunks\n",
        "\n",
        "# Get the content of the uploaded file and decode it from bytes to a string\n",
        "file_name = 'machine (1).txt'\n",
        "file_content = uploaded[file_name].decode('utf-8')\n",
        "\n",
        "chunks = text_splitter.split_text(file_content)\n",
        "\n",
        "print(f\"We have {len(chunks)} chunks:\")\n",
        "for i, chunk in enumerate(chunks):\n",
        "    print(f\"\"\"--- Chunk {i+1} ---\n",
        "{chunk}\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCTC0N2aMGp2",
        "outputId": "efeced8c-cf83-411b-f530-748bbc27f676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 9 chunks:\n",
            "--- Chunk 1 ---\n",
            "Machine Learning is a branch of Artificial Intelligence that enables computers to learn from data and make decisions or predictions without being\n",
            "\n",
            "--- Chunk 2 ---\n",
            "without being explicitly programmed. Instead of following fixed instructions, machine learning systems use algorithms to identify patterns in data\n",
            "\n",
            "--- Chunk 3 ---\n",
            "patterns in data and improve their performance over time through experience. It mainly consists of three types: supervised learning, where models are\n",
            "\n",
            "--- Chunk 4 ---\n",
            "where models are trained using labeled data; unsupervised learning, where the system finds hidden patterns in unlabeled data; and reinforcement\n",
            "\n",
            "--- Chunk 5 ---\n",
            "and reinforcement learning, where an agent learns by receiving rewards or penalties based on its actions. Common algorithms include linear\n",
            "\n",
            "--- Chunk 6 ---\n",
            "include linear regression, decision trees, support vector machines, and neural networks. Machine learning is widely used in healthcare for disease\n",
            "\n",
            "--- Chunk 7 ---\n",
            "for disease prediction, in banking for fraud detection, in e-commerce for recommendation systems, and in speech and image recognition. Although it\n",
            "\n",
            "--- Chunk 8 ---\n",
            "Although it requires large amounts of data and computational power, machine learning plays a vital role in modern technology and continues to\n",
            "\n",
            "--- Chunk 9 ---\n",
            "and continues to transform various industries.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Embeddings\n",
        "# now we turn those text chunks into vectors we use a popular lightweight sentence transformer model.its brillient the understanding meaning of sentence"
      ],
      "metadata": {
        "id": "CV_vDRcqM1Q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "# 1. Load the embedding model\n",
        "# 'all-MiniLM-L6-v2' is a fantastic, fast, and small model.\n",
        "# It runs 100% on your local machine.\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "#  2. Embed all our chunks\n",
        "# This will take a moment as it \"reads\" and \"understands\" each chunk.\n",
        "chunk_embeddings = model.encode(chunks)\n",
        "\n",
        "print(f\"Shape of our embeddings: {chunk_embeddings.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699,
          "referenced_widgets": [
            "516053cacad646d9988ae607965356d8",
            "619ba09a436647c88a8cc9774f8ca47f",
            "553881555a804a1aab3654a9709962ea",
            "1473687477f945ad8e426f3a94c3f888",
            "e7ddfb1b1e244e529a92f26b4488a2b9",
            "f6061b0c1f954943982a9fa48a6b68ba",
            "1fa9ac303b8440bd9c2dc4c731b03d5c",
            "6d0e1ee369984862a4d9f9fa2769c255",
            "5409069dc8f04efebf86647990d19ddb",
            "4c953f4282484010a9798aa6e66840e3",
            "b4b811bd370849ad83e92fbabc269eac",
            "20886a4d28c1443098d8ab82ce66f7fa",
            "bf49f58e2e664109bab6b118ecd717d7",
            "9fe52ffd37b14af1a78a08c86debf7e6",
            "0e81f214168846c4a85066d9f1fd37af",
            "40617f6929ed49f8a11295dd623af63b",
            "c4ed5b49bda6441085e9943e190c5a0d",
            "708480e4c79e43179b960624d2878c11",
            "b207ba7924814d1a8f79345c409e0115",
            "653670f34ad14ae3b80d603ece239c98",
            "e710974bdabc46af8535e7a450b6a1c5",
            "499aa400854c43f9bf517668dbf20d7d",
            "99661439544e4fe6be02d452e6d65bd4",
            "6ae29ebd8fed4ebfb776000c18475c9d",
            "9bff7ca47110447facdcf63ac1bf930a",
            "a86861abcfd744bb8c3677bf091a32f6",
            "0e0c87b2b6534b528e762043bcb8ebba",
            "f7f39ed6cf4b4e9e9e8cf4db0966e3a3",
            "9aa6e8e119ea4497990a1847bef7cd6a",
            "18df980642b040678b14be1c32d39b55",
            "9177c25427ae43f1aa9fd3a8f6512d54",
            "a738da9edcd5486fbfb825a1f2dad592",
            "b2bafd61f4a744b78eebbcccdd9820c5",
            "3f0ed18cb4184d68a9fc418268765899",
            "da1d83558e4449b4b83debed8e029810",
            "f41116375e624c8ea7c887cb2b4f4cf5",
            "182074b8673d43219322a696acdb8bf2",
            "542d1af962bd4d4e9443afa8bc2a969c",
            "54312f4284cb41558f9764a007b3ea1d",
            "2ed381f7330842e4a412aa7e90784ae0",
            "fbd3c6b569804373a1ac2354dd0a15d3",
            "37fa58451a5b47188261aa1892170400",
            "92b925bef5974895a8a03a3c4a9009d7",
            "dbbf551140ab47c99d1ea1e72a999b78",
            "b05fad180aa64177a55639c092a638a3",
            "fa2a540cdd5a475f8c3a611207411e16",
            "8ad7107e86ba483ead713ca82959ac85",
            "9abd852caf1d4eb8bda6b8f75b15999b",
            "cd3aa7466bcd4bfe940b31bddbd25ce4",
            "7c0b41b15abf4c51932de67244d3b9a5",
            "1fc636237fba4b29886bd73567969be5",
            "7c635286a0a64efc967dd087a03c2613",
            "d1909571c4d543e9bde260cf342c28c9",
            "c3da4049634d49c2813af583ae059f77",
            "f6715af2fdeb4eb7bff9c1711ae8a1ae",
            "6d88a8b8d6754379b88e4474a761a9ad",
            "80ed215d7c6544e4a5902b42bca8e787",
            "846ea86ca38a454d849cfbc5692009ec",
            "a1bca40e62c74e9b955f5bb5866d0f39",
            "1b64248921704f42859ce8d4b8cef8a4",
            "eac1598af49b4d8ea16378a1571cbabc",
            "720dbb7c20a04834b494efc35f67ffea",
            "38293a7c802243f49688947176687bc1",
            "1c3379ec0c1c42d59349af7bd985103d",
            "6eb0b86dc4cf409095fa1093be17c745",
            "9301f8da34424b4ea22c653ff8a517f3",
            "0d48c6024eba4a72b6e2e9d8ce879912",
            "7ede2d8c0c29413795fad8dbb7d745cf",
            "c624ebb1ac4a4d1d8521ff26f81be27b",
            "58748a41218e4478b13a76186b9f15e6",
            "11f165381c624e99a9852dc08e3c0a10",
            "36afb034feee4098a8ceb30424a8a9b8",
            "855fff35c083470082687c59d5d721ef",
            "bec8e0fb7ecc45cdb624033e789cc0a1",
            "d1fa206e6ec148e9af22d2e0550ffecf",
            "c187d9e0c6284251a2ee62192a525d05",
            "bf00976795814d02be7a927e67f99a4a",
            "48cb7930ae294046b0b2fbf5b8e67f59",
            "1b6d33ba8df0404a8c53f6820bf1482e",
            "91730257b12f4967ba41858240a5c38d",
            "db0fb0c432fc4889b5cc1f3a1d3a028c",
            "a6f777e71529439aa3c9ff233ace90ef",
            "6cc20b476ade42fcac97a6bd294d7464",
            "f2183948a9254f7f94eea74bff4eb209",
            "6721b97868644254b4e75d5f8bdf31d2",
            "6b1bdf0091c143b6b41fecf5a17145c1",
            "6351fbf1392345afaa59330aaf9c8a3b",
            "a6fabe20100a45f2a96d0fd2f4597c94",
            "cfda70ed810f42bf84a1036fdb066ff6",
            "78e42116340746fd9ade792f2e495a94",
            "b56d8db9a9884019bf6aefbfe28b1c40",
            "375fe28d06f54607aec03f8854e86800",
            "38424fa5a47d4648b8dcdecc302b4a97",
            "8a72ead9af84486689db6e8ac46284e2",
            "c47051107d104506848663761b1d4a8d",
            "233ae3c7ffb64c06bd9ff3142c51f813",
            "ac576905fc304f63becb5d80ab3d32a1",
            "880e19e33d7a4dd494af6fbb546039ec",
            "8111a88648254affa85709a426a2bb88",
            "68380c9512d04780bd9583974c62f816",
            "c2d5e3cf0cf24a0d95eb97e0aabc5f2f",
            "7d944a693afb4ffd8aed0df7c4604d35",
            "946309ca67454a86b4fcede7f1622e14",
            "cbf35ffc24494b89b2db62d522ed5c72",
            "745a42320bb04e6982d4c5fe13cc842c",
            "cef38d88b7c44c21bea1d11b3251c7df",
            "edc7254166de4de9acdbbda7a23eefa2",
            "818e20ecc08f4fd689a5c4cc0100b045",
            "56a2f74dd2904d9da1492049a345dfc9",
            "4bf384c3188d47e89b5501ee0c40ab62",
            "d2b5ba076ce341b9957811fc9ef765ff",
            "01ea489b0b754e5bbb96b80e8d562bc1",
            "e909084876b64ffbb58848088313d54c",
            "f36ad05393014cb08d0fe8053d19c029",
            "3e99c3da866f4486b5a9a23ce839bf7c",
            "76e1fd96c47644eb832af7463375f3bd",
            "86fd8e20e303414f954f8297223964f5",
            "3e6d93b5a1104dd2a0bbb4f7a02f5527",
            "6e5cae70a4ad4e789a92bf24973aa60e",
            "8be77970047b48eb989d586417a5587e",
            "a1b6d1aaba1d4071a207f7482d355bf3",
            "8485ba83f490460ab70c6792ac4502b3",
            "441001e24b214bfbb056be58255b295c",
            "17f03ea87c7141328a9c3e62644c645a",
            "97195ae577ec48a591047e1b914c01cb",
            "b8bfe1ac85c147ba88280526ec0d2545",
            "fe21a7dcaf6a47c48b6bbd1e1ae08a36",
            "0fa7d1f5916a4bc9a8c34a60cc7a457d",
            "238cdaa6acd94e4592afe453d1e1cbaa",
            "381b90914ea7413188feff18f3f13d8c",
            "2b7e643f89ea4d4b84df9cdc53cee748",
            "7d49d9e7dd5244e3ad7bc0e7d74d59a0"
          ]
        },
        "id": "YSwMzlZHNitM",
        "outputId": "748eb90a-0199-4873-d42d-4365fe408e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "516053cacad646d9988ae607965356d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20886a4d28c1443098d8ab82ce66f7fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99661439544e4fe6be02d452e6d65bd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f0ed18cb4184d68a9fc418268765899"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b05fad180aa64177a55639c092a638a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d88a8b8d6754379b88e4474a761a9ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d48c6024eba4a72b6e2e9d8ce879912"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48cb7930ae294046b0b2fbf5b8e67f59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfda70ed810f42bf84a1036fdb066ff6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68380c9512d04780bd9583974c62f816"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2b5ba076ce341b9957811fc9ef765ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8485ba83f490460ab70c6792ac4502b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of our embeddings: (9, 384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  vector store with FAISS\n",
        "# we have our vector.now we need a database to store them in a way we can search by similarity.it is where faiss comes .its just few lines of code"
      ],
      "metadata": {
        "id": "pOBmhs82NxbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "vHF-EtTNQEYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the dimension of our vector\n",
        "d = chunk_embeddings.shape[1]\n",
        "\n"
      ],
      "metadata": {
        "id": "e0IFbJnBQObZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  create the FAISS index\n",
        "# indexFlatl2 is the simplest most basic index it calculates the exact distance(L2 distance )between our quary and vector.\n",
        "index=faiss.IndexFlatL2(d)\n",
        "#  add our chunk into embeddings to the index\n",
        "# we must convert float32 into FAISS\n",
        "index.add(np.array(chunk_embeddings).astype(np.float32))"
      ],
      "metadata": {
        "id": "HIbGJta8QtjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"FAISS index created  with {index.ntotal} vectors\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XML2QyQR7g5",
        "outputId": "727ddf5c-0ee6-4941-d05f-88f6b9b8afb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index created  with 9 vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 5 retrieve,Augment,generate (RAG)\n",
        "# this is a final part here will user ask aquestion."
      ],
      "metadata": {
        "id": "PMI4vZlFST1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Load the tokenizer and model for flan-t5-small\n",
        "tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-small')\n",
        "model_generator = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-small')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310,
          "referenced_widgets": [
            "ec3cb9774c3d413aaf17d3ff8b003347",
            "f81912b1baa548c0a2ef863dca1a2afd",
            "7ed13dc99afc4a0ea8fbc71d1747ffab",
            "4c1532ff61544408b7c45dcef2f4e197",
            "96393e3cf6714ef4b535a702bc67a2c0",
            "f49001a9c6f542e4a348887440ff6834",
            "9db92b5f904949d2814c6fe58fd1013a",
            "59b0bb90ee974894a65df846e2aa23d3",
            "c112b56886cf42059a5f742147f55642",
            "3d14ce2333194c7ba3960d41d0dd41fd",
            "fe080c35c5634637ae1a87ff8c263854",
            "16e28d6fa96c40228e80f2e37d92286b",
            "efbadb88052741bcbe570d725e08e7c2",
            "3a742a83f2ca4800ba0825a722f01bf9",
            "06054a0512374c528922b12eb4dc433d",
            "ae7637d4565349fea8bfc7f342438f41",
            "9857280d0a8b48438e5841705bb73a1e",
            "b39ce6f5b37245fca77dd28fa7af99a5",
            "6d5afbb6bfcf4cd88b268ed437c7f661",
            "5058eb1bf75c4bbaa5e869eacb2987fe",
            "79f8d689126944bc9e88b1490ebbafa3",
            "548bf2f3105c446d99293f6ca4e1a4b5",
            "db88d4f633e344e8bc444cebd84b5e1b",
            "c61bb3929e3c4438a209b7e636107015",
            "79d4ea959d89410b86d1de6b12fd3c5d",
            "c995cea5da9c4beba8e2574820411a19",
            "8f62b6d5ff294226941fdad0bc4b6f89",
            "c07c987fbab84da1965402b6da9731ce",
            "f79f95d5bddd4acda45ffb93854b8a71",
            "5d578448844248d1bffc60d338b0e4c4",
            "0f07b5c8de254889bceae28071ddbf15",
            "b88b50b0416748e2abf0f9758eaf147f",
            "37eea523c36e4677b32c3818efde37d6",
            "3974f202b5ac418db99522388536f546",
            "482fce52d67c4afd855c766d8ff8eb6b",
            "298042d9a4ce4c77808b22de7cffe05f",
            "f17920cc01e7417ca725d29843966feb",
            "64218ff20e5647449e9119b39c2ba305",
            "5f08862d7b544cf495bd220256b164cf",
            "9825b75d4e5b4ae8a1f61e922d378457",
            "54acff4f842e4e35a126b370e96bf099",
            "29ce47b9b1ca4ab4a3e67e96a9d0ecd1",
            "7fa4d38ce82246d9b6a485c9dffe9760",
            "33ac7246305a4f5d801e008dd657acf9",
            "dbce9b90ed2e47df8e2d540aca707451",
            "6bbcf0d8195c4393843623fc7dfa40dd",
            "1e309f19109c43a8b79b8624e942021a",
            "59e341d4350c49f9bbec9732f87c513d",
            "be6c1f3501214f3684fd68f5328e9926",
            "b36daa8a1d49491794ebf3ad8c3534dc",
            "d5d397c9ef77488c993ac656f21f6162",
            "e4aefe6abc8240599119f869c6ed8f81",
            "dde27b401a11499398929b65accc9986",
            "a202cac4fce74e248cb4239e5da8d7ce",
            "965fbeb6a26f426c8c5c2d11c8716beb",
            "3241ec5c412341ed83a4cf3371721326",
            "9871f35a863e415b81abab8d2224c6a0",
            "1cc2a8715f974dd885fa957ff9416aa9",
            "e25ccf09ca6d44e1a0e89e312462328f",
            "404da43417aa44a88c7d6cc45183ecc9",
            "a175bbbc4ef9461e9889b2eff2426320",
            "11730965e9ef4be5b809df7bbd153561",
            "0f910787ed0344378d1dd4d6b7e9e444",
            "063959367b2e41808bcd2d4788533d44",
            "a5e9069612b24b7995eb638b39fedbe5",
            "d3b9461b28614b4fbd924604c9f5c1fc",
            "0d79ced4c42145709502f87f62dbfa3e",
            "c04b0f068c2b4487b3ecc1bd6d06b058",
            "8e0fb0b7c426421ba912fc4a136cf470",
            "2275e016d8d84375bee02f0b981bf472",
            "e22d60b0b9b747b5af49324ae90322f5",
            "e24674da6c8c43bfbc682a1333d08891",
            "5dc672e0e58b4941a2738556c38c4810",
            "362db973cd5b47c69a27e6a11af6444d",
            "5395aca7dd0744c39453f74ec79b3075",
            "2fef983af6814b639e789662e188f589",
            "b76f26ed1ac140298c3af713dcb91d78",
            "acfc8d5c214749e5bcdc61dc4ab627df",
            "6b1debef58694b8183053eb8f1bbccb7",
            "e59e6378bcbf4f12877dc06d2adde970",
            "ff87ce938f104a5f80ac80626e60cf36",
            "0a1ad6cd8ee841f79bd2f14ee4bacff3",
            "7a996517fb3f4f629cb2ff231f2be3a5",
            "29efdf64d4794be787e9f5316f68cd0e",
            "c1da640fd975456793970099c581b2d6",
            "08018e181bb5499d8b338782b69e0d90",
            "082c2871f8cf4dfbb4c9a2b1871a14b6",
            "194381df20fc45db9939b1a563f5107a"
          ]
        },
        "id": "EnZozR5hS05_",
        "outputId": "5d87b7b2-602a-45b8-d555-56288c0c6a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec3cb9774c3d413aaf17d3ff8b003347"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16e28d6fa96c40228e80f2e37d92286b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db88d4f633e344e8bc444cebd84b5e1b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3974f202b5ac418db99522388536f546"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbce9b90ed2e47df8e2d540aca707451"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3241ec5c412341ed83a4cf3371721326"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/190 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d79ced4c42145709502f87f62dbfa3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tied weights mapping and config for this model specifies to tie shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acfc8d5c214749e5bcdc61dc4ab627df"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is our RAG pieline function"
      ],
      "metadata": {
        "id": "DLSFPOIpT3ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(quary):\n",
        "  # RETRIEVE\n",
        "  # embedd the user quary\n",
        "  quary_embedding=model.encode([quary]).astype('float32')\n",
        "  # Search the faiss index into top (e.g,k=2) most similar chunk\n",
        "  k=2\n",
        "  distance,indices=index.search(quary_embedding,k)\n",
        "  # get the actual text chunk from our original chunk list\n",
        "  retrieved_chunks=[chunks[i] for i in indices[0]]\n",
        "  context=\"\\n\\n.\".join(retrieved_chunks)\n",
        "  # 2 Augment\n",
        "  # this is the magic propmt we combined the retrieved chunks with the uers quary\n",
        "  prompt_template= f\"\"\"\n",
        "  answer the following question using only the provided context.\n",
        "  if the answer is not in the context,say \\\"i don't have any information\\\"\n",
        "\n",
        "  Context:\n",
        "  {context}\n",
        "\n",
        "  Question:\n",
        "  {quary}\n",
        "  Answer:\n",
        "  \"\"\"\n",
        "  # 3 Generate\n",
        "  # Encode the prompt\n",
        "  input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids\n",
        "\n",
        "  # Generate output\n",
        "  outputs = model_generator.generate(input_ids, max_new_tokens=100, do_sample=False)\n",
        "  answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "  print(f\"---CONTEXT----\\n{context}\\n\")\n",
        "  return answer"
      ],
      "metadata": {
        "id": "moGxEvTtTlKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "new_cell_1",
        "outputId": "68110cfc-ac27-4fb5-d196-44eeb4b8b6fc"
      },
      "source": [
        "# Example usage of the answer_question function\n",
        "question_to_ask = \"What is machine learning?\"\n",
        "response = answer_question(question_to_ask)\n",
        "print(f\"\\n---GENERATED ANSWER---\\n{response}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---CONTEXT----\n",
            "Machine Learning is a branch of Artificial Intelligence that enables computers to learn from data and make decisions or predictions without being\n",
            "\n",
            ".without being explicitly programmed. Instead of following fixed instructions, machine learning systems use algorithms to identify patterns in data\n",
            "\n",
            "\n",
            "---GENERATED ANSWER---\n",
            "a branch of Artificial Intelligence that enables computers to learn from data and make decisions or predictions without being .without being explicitly programmed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4c388fa",
        "outputId": "bb9bfcd5-961f-4c10-93fb-326826f52a81"
      },
      "source": [
        "# Example usage of the answer_question function\n",
        "question_to_ask = \"What is machine learning?\"\n",
        "response = answer_question(question_to_ask)\n",
        "print(f\"\\n---GENERATED ANSWER---\\n{response}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---CONTEXT----\n",
            "Machine Learning is a branch of Artificial Intelligence that enables computers to learn from data and make decisions or predictions without being\n",
            "\n",
            ".without being explicitly programmed. Instead of following fixed instructions, machine learning systems use algorithms to identify patterns in data\n",
            "\n",
            "\n",
            "---GENERATED ANSWER---\n",
            "a branch of Artificial Intelligence that enables computers to learn from data and make decisions or predictions without being .without being explicitly programmed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f927551",
        "outputId": "b4b7e307-5dd0-4ed1-ca50-b974789a5d8d"
      },
      "source": [
        "print(\"Hello! I am a chatbot based on your document. Ask me anything about it!\")\n",
        "print(\"Type 'exit' or 'quit' to end the conversation.\")\n",
        "\n",
        "while True:\n",
        "    user_question = input(\"\\nYour Question: \")\n",
        "    if user_question.lower() in ['exit', 'quit']:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    response = answer_question(user_question)\n",
        "    print(f\"\\nChatbot: {response}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I am a chatbot based on your document. Ask me anything about it!\n",
            "Type 'exit' or 'quit' to end the conversation.\n",
            "\n",
            "Your Question: what is machine learning\n",
            "---CONTEXT----\n",
            "Machine Learning is a branch of Artificial Intelligence that enables computers to learn from data and make decisions or predictions without being\n",
            "\n",
            ".Although it requires large amounts of data and computational power, machine learning plays a vital role in modern technology and continues to\n",
            "\n",
            "\n",
            "Chatbot: a branch of Artificial Intelligence that enables computers to learn from data and make decisions or predictions without being\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yri25ipx8buI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}