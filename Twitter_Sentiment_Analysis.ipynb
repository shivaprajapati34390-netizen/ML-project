{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhLIbfF5KVx+Ong+w0bAre",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivaprajapati34390-netizen/ML-project/blob/main/Twitter_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "163aRZwlvktU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "O60TwPo2xWAF"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nitk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import re\n",
        "import nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY9AUUOaxZku",
        "outputId": "5af7d3d3-29e7-4be6-d5ba-eee40b5651e1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nitk in /usr/local/lib/python3.12/dist-packages (0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"https://raw.githubusercontent.com/amankharwal/Website-data/master/twitter.csv\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQwYp-nuxsG1",
        "outputId": "dd1e88d6-7529-4835-e1be-c1fba117174e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
            "0           0      3            0                   0        3      2   \n",
            "1           1      3            0                   3        0      1   \n",
            "2           2      3            0                   3        0      1   \n",
            "3           3      3            0                   2        1      1   \n",
            "4           4      6            0                   6        0      1   \n",
            "\n",
            "                                               tweet  \n",
            "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
            "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
            "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
            "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
            "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The tweet column in the above dataset contains the tweets that we need to use to analyze the feelings of those engaged in the discussion. But to go further, we have to clean up a lot of errors and other special symbols because these tweets contain a lot of language errors. So here is how we can clean up the tweet column:"
      ],
      "metadata": {
        "id": "d2hXpDPUz2fm"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stemmer=nltk.SnowballStemmer(\"english\")\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "stopword=set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR76cznX0KNW",
        "outputId": "20df6aa9-c18b-4be2-b49f-0f8aadc6915d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(text):\n",
        "  text=str(text).lower()\n",
        "  text = re.sub('\\[.*?\\]', '', text)\n",
        "  text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "  text = re.sub('<.*?>+', '', text)\n",
        "  text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "  text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "  text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "  text = re.sub('\\n', '', text)\n",
        "  text = re.sub('\\w*\\d\\w*', '', text)\n",
        "  text = [word for word in text.split(' ') if word not in stopword]\n",
        "  text=\" \".join(text)\n",
        "  text = [stemmer.stem(word) for word in text.split(' ')]\n",
        "  text=\" \".join(text)\n",
        "  return text\n",
        "data[\"tweet\"]=data[\"tweet\"].apply(clean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuJxlJun1ZQ2",
        "outputId": "8b27c920-3599-4c49-be21-83d56ca4b035"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:3: SyntaxWarning: invalid escape sequence '\\['\n",
            "<>:4: SyntaxWarning: invalid escape sequence '\\S'\n",
            "<>:10: SyntaxWarning: invalid escape sequence '\\w'\n",
            "<>:3: SyntaxWarning: invalid escape sequence '\\['\n",
            "<>:4: SyntaxWarning: invalid escape sequence '\\S'\n",
            "<>:10: SyntaxWarning: invalid escape sequence '\\w'\n",
            "/tmp/ipython-input-2051620220.py:3: SyntaxWarning: invalid escape sequence '\\['\n",
            "  text = re.sub('\\[.*?\\]', '', text)\n",
            "/tmp/ipython-input-2051620220.py:4: SyntaxWarning: invalid escape sequence '\\S'\n",
            "  text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
            "/tmp/ipython-input-2051620220.py:10: SyntaxWarning: invalid escape sequence '\\w'\n",
            "  text = re.sub('\\w*\\d\\w*', '', text)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Now, the next step is to calculate the sentiment scores of these tweets and assign a label to the tweets as positive, negative, or neutral. Here is how you can calculate the sentiment scores of the tweets:"
      ],
      "metadata": {
        "id": "m4W0Brev2oPL"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "sentiments=SentimentIntensityAnalyzer()\n",
        "data[\"Positive\"]=[sentiments.polarity_scores(i)[\"pos\"] for i in data[\"tweet\"]]\n",
        "data[\"Negative\"]=[sentiments.polarity_scores(i)[\"neg\"] for i in data[\"tweet\"]]\n",
        "data[\"Neutral\"]=[sentiments.polarity_scores(i)[\"neu\"]for i in data[\"tweet\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waWz4sg73F3p",
        "outputId": "7fbb1ff1-2ce6-4773-f1cb-0f63558d81db"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=data[[\"tweet\",\"Positive\",\"Negative\",\"Neutral\"]]\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtYuYTHB5KQ3",
        "outputId": "4ce37769-6610-471b-ffc2-ee218e1a30f6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               tweet  Positive  Negative  \\\n",
            "0   rt mayasolov woman shouldnt complain clean ho...     0.147     0.157   \n",
            "1   rt  boy dat coldtyga dwn bad cuffin dat hoe  ...     0.000     0.280   \n",
            "2   rt urkindofbrand dawg rt  ever fuck bitch sta...     0.000     0.577   \n",
            "3             rt cganderson vivabas look like tranni     0.333     0.000   \n",
            "4   rt shenikarobert shit hear might true might f...     0.154     0.407   \n",
            "\n",
            "   Neutral  \n",
            "0    0.696  \n",
            "1    0.720  \n",
            "2    0.423  \n",
            "3    0.667  \n",
            "4    0.440  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now letâ€™s have a look at the most frequent label assigned to the tweets according to the sentiment scores:"
      ],
      "metadata": {
        "id": "p2R1YU9Z5x9N"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=sum(data[\"Positive\"])\n",
        "y=sum(data[\"Negative\"])\n",
        "z=sum(data[\"Neutral\"])\n",
        "\n",
        "def sentiment_scores_analyzer(a,b,c):\n",
        "  if (a>b)and (a>c):\n",
        "    print(\"PositiveðŸ˜Š\")\n",
        "  elif (b>a) and (b>c):\n",
        "    print(\"NegativeðŸ˜ \")\n",
        "  else:\n",
        "    print(\"NeutralðŸ™‚\")\n",
        "\n",
        "sentiment_scores_analyzer(x,y,z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-h1c45l54C1",
        "outputId": "b54998b4-17a8-4dd8-fa76-e494ab4cc523"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeutralðŸ™‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x_YpJvre8qQp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}