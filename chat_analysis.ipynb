{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTuaq7nh6XfU+ywRJULJd4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivaprajapati34390-netizen/ML-project/blob/main/chat_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SZafnf12LyX3"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "dOms_YBRMop4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x29YvpI_MsyO",
        "outputId": "95c468f4-4102-46ff-8503-ab0e19197a6a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji"
      ],
      "metadata": {
        "id": "lNYFAcx-M3Nf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "vHR_jWGUNYRH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RzAakprCNp1H"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "UDjnVmv4NvlH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
      ],
      "metadata": {
        "id": "DyqTE5VTORGf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract time\n",
        "def date_time(s):\n",
        " pattern='^(0?[1-9]|1[0-2])\\/(0?[1-9]|[12][0-9]|3[01])\\/([0-9]{2}|[0-9]{4})$'\n",
        " result=re.match(pattern,s)\n",
        " if result:\n",
        "  return True\n",
        " else:\n",
        "  return False"
      ],
      "metadata": {
        "id": "xSYemRlJPYuZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca77727-fe8a-42a7-8eed-22d759f3b84d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:3: SyntaxWarning: invalid escape sequence '\\/'\n",
            "<>:3: SyntaxWarning: invalid escape sequence '\\/'\n",
            "/tmp/ipython-input-4019334591.py:3: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  pattern='^(0?[1-9]|1[0-2])\\/(0?[1-9]|[12][0-9]|3[01])\\/([0-9]{2}|[0-9]{4})$'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find author and contact\n",
        "def author_contact(s):\n",
        "  s=s.split(\":\")\n",
        "  if len(s)==2:\n",
        "    return True\n",
        "  else:\n",
        "      return False"
      ],
      "metadata": {
        "id": "yjrTOBGaKYQz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# find the message\n",
        "def datapoint(line):\n",
        "  splitline=line.split(' - ', 1) # Split only on the first occurrence of ' - '\n",
        "  dateTime=splitline[0]\n",
        "  date,time=dateTime.split(',', 1) # Split date and time\n",
        "  message=\" \".join(splitline[1:])\n",
        "\n",
        "  # Ensure author_contact is defined or use directly\n",
        "  # Assuming author_contact is available in the notebook\n",
        "  if author_contact(message):\n",
        "    splitmessage=message.split(\": \", 1) # Split on ': ' for author and message\n",
        "    author=splitmessage[0]\n",
        "    message=\" \".join(splitmessage[1:])\n",
        "  else:\n",
        "    author= None\n",
        "  return date.strip(),time.strip(),author,message.strip()"
      ],
      "metadata": {
        "id": "_4vcC1KbNBej"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# it doesn‚Äôt matter if you are using a group chat dataset or your conversation with one person. All the functions defined above will prepare your data for the task of sentiment analysis as well as for any data science task. Now here is how we can prepare the data we collected from WhatsApp by using the above functions:\n",
        "\n"
      ],
      "metadata": {
        "id": "SNyNidHgPO41"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=[]\n",
        "conversation='Whatsaap chat with rasti.txt'\n",
        "with open(conversation,encoding='utf-8') as fp:\n",
        "  fp.readline() # Discard the first line (often chat export header)\n",
        "  messageBuffer=[]\n",
        "  current_date, current_time, current_author = None, None, None\n",
        "\n",
        "  while True:\n",
        "    line=fp.readline()\n",
        "    if not line:\n",
        "      break # End of file\n",
        "\n",
        "    line=line.strip()\n",
        "    if not line: # Skip empty lines\n",
        "      continue\n",
        "\n",
        "    # Check if the line starts with a date pattern, indicating a new message\n",
        "    # Example: '12/25/2023, 10:30 AM - Author: Message'\n",
        "    # We need to extract '12/25/2023' to check with date_time function\n",
        "    parts = line.split(' - ', 1)\n",
        "    if len(parts) > 0: # Ensure there's a date-time part\n",
        "        dt_part = parts[0]\n",
        "        date_part_of_line = dt_part.split(',', 1)[0].strip() # Get '12/25/2023'\n",
        "\n",
        "        if date_time(date_part_of_line):\n",
        "            # This is a new message line\n",
        "            if current_author is not None: # If we have a previous message buffered, save it\n",
        "                data.append([current_date, current_time, current_author, ' '.join(messageBuffer)])\n",
        "                messageBuffer.clear()\n",
        "\n",
        "            # Process the current line as a new message\n",
        "            current_date, current_time, current_author, message_part = datapoint(line)\n",
        "            messageBuffer.append(message_part)\n",
        "        else:\n",
        "            # This is a continuation of the previous message\n",
        "            if messageBuffer: # Only append if there's an ongoing message\n",
        "                messageBuffer.append(line)\n",
        "            else:\n",
        "                # This case might happen if the file doesn't start with a valid date line\n",
        "                # or if a non-date line appears before any date line.\n",
        "                # For now, let's just append it to the buffer and hope a date line follows or previous message exists.\n",
        "                messageBuffer.append(line)\n",
        "\n",
        "  # After the loop, append any remaining message in the buffer\n",
        "  if current_author is not None and len(messageBuffer) > 0:\n",
        "    data.append([current_date, current_time, current_author, ' '.join(messageBuffer)])"
      ],
      "metadata": {
        "id": "vwYTf-OGQIUc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  now here we can analyze the whatsaap chat message"
      ],
      "metadata": {
        "id": "3j6qVWKZSoCV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(data,columns=[\"Date\",'Time','Author','Message'])\n",
        "df['Date']=pd.to_datetime(df['Date'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKk_SeLwk1CI",
        "outputId": "5930a117-f8e3-4bdc-ad04-78a812ea8c4b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1815550880.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['Date']=pd.to_datetime(df['Date'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.dropna()"
      ],
      "metadata": {
        "id": "Tp233sWonDxQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sentiment= SentimentIntensityAnalyzer()\n",
        "data['Positive']=[sentiment.polarity_scores(i)[\"pos\"] for i in data [\"Message\"]]\n",
        "data['Negative']=[sentiment.polarity_scores(i)[\"neg\"]for i in data [\"Message\"]]\n",
        "data['Neutal']=[sentiment.polarity_scores(i) for i in data [\"Message\"]]\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC9475kgnzay",
        "outputId": "c09f8950-b614-48d1-bdc8-0a16f071014e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Date      Time                     Author  \\\n",
            "0 2026-02-04   9:32‚ÄØAM   Rasti Sih Section B sahu   \n",
            "1 2026-02-04  10:05‚ÄØAM  Rasti Sih Section B sahu:   \n",
            "2 2026-02-04   9:37‚ÄØAM   Rasti Sih Section B sahu   \n",
            "3 2026-02-04  10:22‚ÄØAM       SHIVA PRAJAPATI ---‚ö°   \n",
            "4 2026-02-04  11:24‚ÄØAM   Rasti Sih Section B sahu   \n",
            "\n",
            "                                  Message  Positive  Negative  \\\n",
            "0                                     Hmm       0.0       0.0   \n",
            "1                                               0.0       0.0   \n",
            "2  Yar kuch nhi padh rhi kha se start kru       0.0       0.0   \n",
            "3                               Unit 1 se       0.0       0.0   \n",
            "4                         <Media omitted>       0.0       0.0   \n",
            "\n",
            "                                              Neutal  \n",
            "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
            "1  {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...  \n",
            "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
            "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
            "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=sum(data['Positive'])\n",
        "y=sum(data['Negative'])\n",
        "z=sum(item['neu'] for item in data['Neutal'])\n",
        "\n",
        "def sentiment_score(a,b,c):\n",
        "  if (a>b) and (a>c):\n",
        "    print(\"positive üòä\")\n",
        "  elif (b>a) and (b>c):\n",
        "    print(\"Negative üò†\")\n",
        "  else:\n",
        "    print(\"Neutal üôÇ\")\n",
        "sentiment_score(x,y,z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm75psAKqPW0",
        "outputId": "599df453-6980-47eb-a9b0-7df4c2f0aaca"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neutal üôÇ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  so ,the data is used to indicates that most of  the message between me and other person are neutral.which means it is neither positive or netural"
      ],
      "metadata": {
        "id": "2VGPhO3As5NI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}